I1024 17:17:58.081890      19 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-464213187
I1024 17:17:58.082199      19 e2e.go:240] Starting e2e run "38199a21-f682-11e9-8e41-6682758dfd28" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1571937475 - Will randomize all specs
Will run 204 of 3586 specs

Oct 24 17:17:58.405: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 17:17:58.411: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Oct 24 17:17:58.439: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct 24 17:17:58.505: INFO: 17 / 17 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct 24 17:17:58.505: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Oct 24 17:17:58.505: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct 24 17:17:58.521: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Oct 24 17:17:58.521: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Oct 24 17:17:58.521: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kubedirector-fsmount' (0 seconds elapsed)
Oct 24 17:17:58.521: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-device-plugin-daemonset' (0 seconds elapsed)
Oct 24 17:17:58.521: INFO: e2e test version: v1.14.6
Oct 24 17:17:58.523: INFO: kube-apiserver version: v1.14.6
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:17:58.523: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename statefulset
Oct 24 17:17:58.578: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6489
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-6489
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6489
Oct 24 17:17:58.612: INFO: Found 0 stateful pods, waiting for 1
Oct 24 17:18:08.619: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Oct 24 17:18:08.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-6489 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 24 17:18:08.951: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 24 17:18:08.951: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 24 17:18:08.951: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 24 17:18:08.956: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 24 17:18:18.963: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 17:18:18.963: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 17:18:18.982: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999322s
Oct 24 17:18:19.989: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995240124s
Oct 24 17:18:20.995: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.988700976s
Oct 24 17:18:22.001: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.982842336s
Oct 24 17:18:23.007: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.976623234s
Oct 24 17:18:24.013: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.970232742s
Oct 24 17:18:25.019: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.96433811s
Oct 24 17:18:26.025: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.958325137s
Oct 24 17:18:27.030: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.953144447s
Oct 24 17:18:28.037: INFO: Verifying statefulset ss doesn't scale past 1 for another 947.412278ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6489
Oct 24 17:18:29.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-6489 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 24 17:18:29.371: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 24 17:18:29.372: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 24 17:18:29.372: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 24 17:18:29.376: INFO: Found 1 stateful pods, waiting for 3
Oct 24 17:18:39.382: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 17:18:39.382: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 17:18:39.382: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Oct 24 17:18:39.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-6489 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 24 17:18:39.695: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 24 17:18:39.695: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 24 17:18:39.695: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 24 17:18:39.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-6489 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 24 17:18:40.018: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 24 17:18:40.018: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 24 17:18:40.018: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 24 17:18:40.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-6489 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 24 17:18:40.324: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 24 17:18:40.324: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 24 17:18:40.324: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 24 17:18:40.324: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 17:18:40.329: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct 24 17:18:50.339: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 17:18:50.340: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 17:18:50.340: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 17:18:50.354: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999409s
Oct 24 17:18:51.361: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994674819s
Oct 24 17:18:52.367: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.987710427s
Oct 24 17:18:53.372: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98188534s
Oct 24 17:18:54.378: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.976484545s
Oct 24 17:18:55.384: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.97075391s
Oct 24 17:18:56.389: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.965020245s
Oct 24 17:18:57.396: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.958712768s
Oct 24 17:18:58.402: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.953089691s
Oct 24 17:18:59.408: INFO: Verifying statefulset ss doesn't scale past 3 for another 946.9425ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6489
Oct 24 17:19:00.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-6489 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 24 17:19:00.724: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 24 17:19:00.724: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 24 17:19:00.724: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 24 17:19:00.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-6489 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 24 17:19:01.037: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 24 17:19:01.037: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 24 17:19:01.037: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 24 17:19:01.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-6489 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 24 17:19:01.344: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 24 17:19:01.345: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 24 17:19:01.345: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 24 17:19:01.345: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 24 17:19:11.367: INFO: Deleting all statefulset in ns statefulset-6489
Oct 24 17:19:11.371: INFO: Scaling statefulset ss to 0
Oct 24 17:19:11.385: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 17:19:11.389: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:19:11.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6489" for this suite.
Oct 24 17:19:25.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:19:25.586: INFO: namespace statefulset-6489 deletion completed in 14.172721694s

• [SLOW TEST:87.063 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:19:25.586: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Oct 24 17:19:25.645: INFO: Waiting up to 5m0s for pod "var-expansion-6d97fab0-f682-11e9-8e41-6682758dfd28" in namespace "var-expansion-4261" to be "success or failure"
Oct 24 17:19:25.649: INFO: Pod "var-expansion-6d97fab0-f682-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 3.823524ms
Oct 24 17:19:27.656: INFO: Pod "var-expansion-6d97fab0-f682-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010276516s
Oct 24 17:19:29.661: INFO: Pod "var-expansion-6d97fab0-f682-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016133523s
Oct 24 17:19:31.667: INFO: Pod "var-expansion-6d97fab0-f682-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02207074s
STEP: Saw pod success
Oct 24 17:19:31.667: INFO: Pod "var-expansion-6d97fab0-f682-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:19:31.672: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod var-expansion-6d97fab0-f682-11e9-8e41-6682758dfd28 container dapi-container: <nil>
STEP: delete the pod
Oct 24 17:19:31.724: INFO: Waiting for pod var-expansion-6d97fab0-f682-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:19:31.729: INFO: Pod var-expansion-6d97fab0-f682-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:19:31.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4261" for this suite.
Oct 24 17:19:37.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:19:37.914: INFO: namespace var-expansion-4261 deletion completed in 6.179364406s

• [SLOW TEST:12.328 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:19:37.915: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2545.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2545.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 24 17:20:06.055: INFO: DNS probes using dns-2545/dns-test-74f352c1-f682-11e9-8e41-6682758dfd28 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:20:06.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2545" for this suite.
Oct 24 17:20:12.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:20:12.254: INFO: namespace dns-2545 deletion completed in 6.173509799s

• [SLOW TEST:34.340 seconds]
[sig-network] DNS
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:20:12.255: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1649
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 24 17:20:12.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1505'
Oct 24 17:20:12.603: INFO: stderr: ""
Oct 24 17:20:12.603: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1654
Oct 24 17:20:12.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 delete pods e2e-test-nginx-pod --namespace=kubectl-1505'
Oct 24 17:20:13.549: INFO: stderr: ""
Oct 24 17:20:13.549: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:20:13.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1505" for this suite.
Oct 24 17:20:19.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:20:19.722: INFO: namespace kubectl-1505 deletion completed in 6.168218691s

• [SLOW TEST:7.468 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:20:19.723: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-9004
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9004 to expose endpoints map[]
Oct 24 17:20:19.793: INFO: Get endpoints failed (5.668619ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Oct 24 17:20:20.798: INFO: successfully validated that service multi-endpoint-test in namespace services-9004 exposes endpoints map[] (1.011171477s elapsed)
STEP: Creating pod pod1 in namespace services-9004
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9004 to expose endpoints map[pod1:[100]]
Oct 24 17:20:22.854: INFO: successfully validated that service multi-endpoint-test in namespace services-9004 exposes endpoints map[pod1:[100]] (2.035123867s elapsed)
STEP: Creating pod pod2 in namespace services-9004
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9004 to expose endpoints map[pod1:[100] pod2:[101]]
Oct 24 17:20:24.901: INFO: successfully validated that service multi-endpoint-test in namespace services-9004 exposes endpoints map[pod1:[100] pod2:[101]] (2.042031292s elapsed)
STEP: Deleting pod pod1 in namespace services-9004
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9004 to expose endpoints map[pod2:[101]]
Oct 24 17:20:25.932: INFO: successfully validated that service multi-endpoint-test in namespace services-9004 exposes endpoints map[pod2:[101]] (1.023366462s elapsed)
STEP: Deleting pod pod2 in namespace services-9004
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9004 to expose endpoints map[]
Oct 24 17:20:25.947: INFO: successfully validated that service multi-endpoint-test in namespace services-9004 exposes endpoints map[] (7.624071ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:20:25.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9004" for this suite.
Oct 24 17:20:48.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:20:48.145: INFO: namespace services-9004 deletion completed in 22.160024608s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:28.422 seconds]
[sig-network] Services
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:20:48.145: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 17:20:48.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 create -f - --namespace=kubectl-5375'
Oct 24 17:20:48.638: INFO: stderr: ""
Oct 24 17:20:48.638: INFO: stdout: "replicationcontroller/redis-master created\n"
Oct 24 17:20:48.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 create -f - --namespace=kubectl-5375'
Oct 24 17:20:48.971: INFO: stderr: ""
Oct 24 17:20:48.971: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 24 17:20:49.976: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 17:20:49.977: INFO: Found 0 / 1
Oct 24 17:20:50.977: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 17:20:50.977: INFO: Found 0 / 1
Oct 24 17:20:51.978: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 17:20:51.978: INFO: Found 0 / 1
Oct 24 17:20:52.977: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 17:20:52.977: INFO: Found 1 / 1
Oct 24 17:20:52.977: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 24 17:20:52.982: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 17:20:52.982: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 24 17:20:52.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 describe pod redis-master-2vhc9 --namespace=kubectl-5375'
Oct 24 17:20:53.177: INFO: stderr: ""
Oct 24 17:20:53.177: INFO: stdout: "Name:               redis-master-2vhc9\nNamespace:          kubectl-5375\nPriority:           0\nPriorityClassName:  <none>\nNode:               mip-bd-vm41.mip.storage.hpecorp.net/16.143.20.138\nStart Time:         Thu, 24 Oct 2019 17:20:48 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.244.1.8/32\nStatus:             Running\nIP:                 10.244.1.8\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://e1c90f30050df926af74f0d13ac532301f4e30c240f72372d36a7afd8b188b0e\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 24 Oct 2019 17:20:52 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7mj8n (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-7mj8n:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-7mj8n\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                          Message\n  ----    ------     ----  ----                                          -------\n  Normal  Scheduled  5s    default-scheduler                             Successfully assigned kubectl-5375/redis-master-2vhc9 to mip-bd-vm41.mip.storage.hpecorp.net\n  Normal  Pulling    4s    kubelet, mip-bd-vm41.mip.storage.hpecorp.net  Pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     1s    kubelet, mip-bd-vm41.mip.storage.hpecorp.net  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    1s    kubelet, mip-bd-vm41.mip.storage.hpecorp.net  Created container redis-master\n  Normal  Started    1s    kubelet, mip-bd-vm41.mip.storage.hpecorp.net  Started container redis-master\n"
Oct 24 17:20:53.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 describe rc redis-master --namespace=kubectl-5375'
Oct 24 17:20:53.387: INFO: stderr: ""
Oct 24 17:20:53.387: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-5375\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  5s    replication-controller  Created pod: redis-master-2vhc9\n"
Oct 24 17:20:53.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 describe service redis-master --namespace=kubectl-5375'
Oct 24 17:20:53.575: INFO: stderr: ""
Oct 24 17:20:53.575: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-5375\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.96.17.196\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.1.8:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct 24 17:20:53.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 describe node mip-bd-vm39.mip.storage.hpecorp.net'
Oct 24 17:20:53.797: INFO: stderr: ""
Oct 24 17:20:53.797: INFO: stdout: "Name:               mip-bd-vm39.mip.storage.hpecorp.net\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=mip-bd-vm39.mip.storage.hpecorp.net\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"ee:fc:89:7f:b5:3c\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 16.143.20.136\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 24 Oct 2019 17:08:44 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Thu, 24 Oct 2019 17:19:55 +0000   Thu, 24 Oct 2019 17:08:44 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 24 Oct 2019 17:19:55 +0000   Thu, 24 Oct 2019 17:08:44 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 24 Oct 2019 17:19:55 +0000   Thu, 24 Oct 2019 17:08:44 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 24 Oct 2019 17:19:55 +0000   Thu, 24 Oct 2019 17:10:44 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  16.143.20.136\n  Hostname:    mip-bd-vm39.mip.storage.hpecorp.net\nCapacity:\n cpu:                4\n ephemeral-storage:  401682812Ki\n hugepages-2Mi:      0\n memory:             32780580Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  370190878927\n hugepages-2Mi:      0\n memory:             32678180Ki\n pods:               110\nSystem Info:\n Machine ID:                 e5bf42bded154965be4edc4be6e4615f\n System UUID:                54D22B42-093C-E1CA-E7F7-88C7E15728CA\n Boot ID:                    39afc37f-049b-44de-89ed-20d435c65bf6\n Kernel Version:             3.10.0-1062.4.1.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://1.13.1\n Kubelet Version:            v1.14.6\n Kube-Proxy Version:         v1.14.6\nPodCIDR:                     10.244.0.0/24\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                           CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                           ------------  ----------  ---------------  -------------  ---\n  kube-system                canal-8dc7f                                                    250m (6%)     0 (0%)      0 (0%)           0 (0%)         10m\n  kube-system                coredns-584795fc57-sd8z9                                       100m (2%)     0 (0%)      70Mi (0%)        170Mi (0%)     11m\n  kube-system                coredns-584795fc57-sxlsv                                       100m (2%)     0 (0%)      70Mi (0%)        170Mi (0%)     11m\n  kube-system                etcd-mip-bd-vm39.mip.storage.hpecorp.net                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                kube-apiserver-mip-bd-vm39.mip.storage.hpecorp.net             250m (6%)     0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                kube-controller-manager-mip-bd-vm39.mip.storage.hpecorp.net    200m (5%)     0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                kube-proxy-86pcn                                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                kube-scheduler-mip-bd-vm39.mip.storage.hpecorp.net             100m (2%)     0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                kubernetes-dashboard-5f7b999d65-gkrk6                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         10m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-db3f66083eff4fdd-k2h7g        0 (0%)        0 (0%)      0 (0%)           0 (0%)         4m4s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                1 (25%)     0 (0%)\n  memory             140Mi (0%)  340Mi (1%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                From                                             Message\n  ----    ------                   ----               ----                                             -------\n  Normal  Starting                 12m                kubelet, mip-bd-vm39.mip.storage.hpecorp.net     Starting kubelet.\n  Normal  NodeHasSufficientMemory  12m (x8 over 12m)  kubelet, mip-bd-vm39.mip.storage.hpecorp.net     Node mip-bd-vm39.mip.storage.hpecorp.net status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    12m (x7 over 12m)  kubelet, mip-bd-vm39.mip.storage.hpecorp.net     Node mip-bd-vm39.mip.storage.hpecorp.net status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     12m (x8 over 12m)  kubelet, mip-bd-vm39.mip.storage.hpecorp.net     Node mip-bd-vm39.mip.storage.hpecorp.net status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  12m                kubelet, mip-bd-vm39.mip.storage.hpecorp.net     Updated Node Allocatable limit across pods\n  Normal  Starting                 11m                kube-proxy, mip-bd-vm39.mip.storage.hpecorp.net  Starting kube-proxy.\n"
Oct 24 17:20:53.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 describe namespace kubectl-5375'
Oct 24 17:20:53.983: INFO: stderr: ""
Oct 24 17:20:53.983: INFO: stdout: "Name:         kubectl-5375\nLabels:       e2e-framework=kubectl\n              e2e-run=38199a21-f682-11e9-8e41-6682758dfd28\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:20:53.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5375" for this suite.
Oct 24 17:21:16.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:21:16.158: INFO: namespace kubectl-5375 deletion completed in 22.169321708s

• [SLOW TEST:28.012 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:21:16.158: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Oct 24 17:21:16.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 create -f - --namespace=kubectl-6285'
Oct 24 17:21:16.529: INFO: stderr: ""
Oct 24 17:21:16.529: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 24 17:21:17.534: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 17:21:17.534: INFO: Found 0 / 1
Oct 24 17:21:18.536: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 17:21:18.536: INFO: Found 0 / 1
Oct 24 17:21:19.534: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 17:21:19.534: INFO: Found 0 / 1
Oct 24 17:21:20.535: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 17:21:20.535: INFO: Found 0 / 1
Oct 24 17:21:21.535: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 17:21:21.535: INFO: Found 1 / 1
Oct 24 17:21:21.535: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Oct 24 17:21:21.541: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 17:21:21.541: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 24 17:21:21.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 patch pod redis-master-gh69x --namespace=kubectl-6285 -p {"metadata":{"annotations":{"x":"y"}}}'
Oct 24 17:21:21.718: INFO: stderr: ""
Oct 24 17:21:21.718: INFO: stdout: "pod/redis-master-gh69x patched\n"
STEP: checking annotations
Oct 24 17:21:21.724: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 17:21:21.724: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:21:21.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6285" for this suite.
Oct 24 17:21:43.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:21:43.904: INFO: namespace kubectl-6285 deletion completed in 22.175424696s

• [SLOW TEST:27.746 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:21:43.904: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:21:50.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3064" for this suite.
Oct 24 17:22:38.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:22:38.177: INFO: namespace kubelet-test-3064 deletion completed in 48.160072433s

• [SLOW TEST:54.273 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:22:38.178: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-p4jqb in namespace proxy-1122
I1024 17:22:38.245622      19 runners.go:184] Created replication controller with name: proxy-service-p4jqb, namespace: proxy-1122, replica count: 1
I1024 17:22:39.297453      19 runners.go:184] proxy-service-p4jqb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1024 17:22:40.297862      19 runners.go:184] proxy-service-p4jqb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1024 17:22:41.298235      19 runners.go:184] proxy-service-p4jqb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1024 17:22:42.298565      19 runners.go:184] proxy-service-p4jqb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1024 17:22:43.298907      19 runners.go:184] proxy-service-p4jqb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1024 17:22:44.299191      19 runners.go:184] proxy-service-p4jqb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1024 17:22:45.299552      19 runners.go:184] proxy-service-p4jqb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1024 17:22:46.299827      19 runners.go:184] proxy-service-p4jqb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1024 17:22:47.300296      19 runners.go:184] proxy-service-p4jqb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1024 17:22:48.300653      19 runners.go:184] proxy-service-p4jqb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1024 17:22:49.301114      19 runners.go:184] proxy-service-p4jqb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1024 17:22:50.301657      19 runners.go:184] proxy-service-p4jqb Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 24 17:22:50.306: INFO: setup took 12.080574807s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Oct 24 17:22:50.322: INFO: (0) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 15.607065ms)
Oct 24 17:22:50.322: INFO: (0) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 16.277031ms)
Oct 24 17:22:50.324: INFO: (0) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 17.554299ms)
Oct 24 17:22:50.328: INFO: (0) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 21.688583ms)
Oct 24 17:22:50.331: INFO: (0) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 24.769746ms)
Oct 24 17:22:50.332: INFO: (0) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 25.329803ms)
Oct 24 17:22:50.332: INFO: (0) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 25.843955ms)
Oct 24 17:22:50.332: INFO: (0) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 25.580823ms)
Oct 24 17:22:50.332: INFO: (0) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 25.587731ms)
Oct 24 17:22:50.342: INFO: (0) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 35.969005ms)
Oct 24 17:22:50.342: INFO: (0) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 36.022287ms)
Oct 24 17:22:50.344: INFO: (0) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 37.762599ms)
Oct 24 17:22:50.345: INFO: (0) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 39.534066ms)
Oct 24 17:22:50.346: INFO: (0) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 39.706143ms)
Oct 24 17:22:50.351: INFO: (0) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 45.171066ms)
Oct 24 17:22:50.351: INFO: (0) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 45.090493ms)
Oct 24 17:22:50.363: INFO: (1) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 10.617292ms)
Oct 24 17:22:50.363: INFO: (1) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 10.526777ms)
Oct 24 17:22:50.367: INFO: (1) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 14.270762ms)
Oct 24 17:22:50.368: INFO: (1) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 15.196617ms)
Oct 24 17:22:50.368: INFO: (1) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 16.662909ms)
Oct 24 17:22:50.369: INFO: (1) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 15.202358ms)
Oct 24 17:22:50.369: INFO: (1) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 15.295436ms)
Oct 24 17:22:50.369: INFO: (1) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 15.598268ms)
Oct 24 17:22:50.369: INFO: (1) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 16.727851ms)
Oct 24 17:22:50.369: INFO: (1) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 15.742991ms)
Oct 24 17:22:50.369: INFO: (1) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 17.159381ms)
Oct 24 17:22:50.369: INFO: (1) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 15.68342ms)
Oct 24 17:22:50.369: INFO: (1) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 17.052547ms)
Oct 24 17:22:50.370: INFO: (1) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 17.185795ms)
Oct 24 17:22:50.371: INFO: (1) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 17.495428ms)
Oct 24 17:22:50.371: INFO: (1) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 17.822246ms)
Oct 24 17:22:50.381: INFO: (2) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 10.195713ms)
Oct 24 17:22:50.382: INFO: (2) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 10.94396ms)
Oct 24 17:22:50.382: INFO: (2) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 10.79093ms)
Oct 24 17:22:50.385: INFO: (2) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 13.77795ms)
Oct 24 17:22:50.385: INFO: (2) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 14.011144ms)
Oct 24 17:22:50.385: INFO: (2) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 14.366686ms)
Oct 24 17:22:50.385: INFO: (2) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 14.193856ms)
Oct 24 17:22:50.386: INFO: (2) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 15.388057ms)
Oct 24 17:22:50.386: INFO: (2) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 14.909085ms)
Oct 24 17:22:50.386: INFO: (2) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 15.581668ms)
Oct 24 17:22:50.386: INFO: (2) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 15.299321ms)
Oct 24 17:22:50.387: INFO: (2) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 16.530482ms)
Oct 24 17:22:50.387: INFO: (2) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 16.421536ms)
Oct 24 17:22:50.387: INFO: (2) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 15.748582ms)
Oct 24 17:22:50.388: INFO: (2) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 17.236166ms)
Oct 24 17:22:50.389: INFO: (2) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 17.409911ms)
Oct 24 17:22:50.399: INFO: (3) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 9.754327ms)
Oct 24 17:22:50.399: INFO: (3) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 10.422179ms)
Oct 24 17:22:50.399: INFO: (3) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 10.536989ms)
Oct 24 17:22:50.400: INFO: (3) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 11.107811ms)
Oct 24 17:22:50.401: INFO: (3) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 12.186011ms)
Oct 24 17:22:50.401: INFO: (3) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 11.976247ms)
Oct 24 17:22:50.401: INFO: (3) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 11.905031ms)
Oct 24 17:22:50.401: INFO: (3) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 12.359004ms)
Oct 24 17:22:50.401: INFO: (3) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 12.398952ms)
Oct 24 17:22:50.402: INFO: (3) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 12.190602ms)
Oct 24 17:22:50.402: INFO: (3) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 12.599394ms)
Oct 24 17:22:50.402: INFO: (3) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 12.931312ms)
Oct 24 17:22:50.402: INFO: (3) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 12.941062ms)
Oct 24 17:22:50.406: INFO: (3) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 16.600212ms)
Oct 24 17:22:50.406: INFO: (3) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 17.056826ms)
Oct 24 17:22:50.406: INFO: (3) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 17.135653ms)
Oct 24 17:22:50.418: INFO: (4) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 10.986232ms)
Oct 24 17:22:50.418: INFO: (4) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 11.312137ms)
Oct 24 17:22:50.418: INFO: (4) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 11.524497ms)
Oct 24 17:22:50.418: INFO: (4) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 11.333739ms)
Oct 24 17:22:50.418: INFO: (4) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 11.56442ms)
Oct 24 17:22:50.418: INFO: (4) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 11.481658ms)
Oct 24 17:22:50.418: INFO: (4) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 11.364281ms)
Oct 24 17:22:50.418: INFO: (4) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 11.454963ms)
Oct 24 17:22:50.418: INFO: (4) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 11.567169ms)
Oct 24 17:22:50.422: INFO: (4) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 15.441279ms)
Oct 24 17:22:50.422: INFO: (4) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 15.177177ms)
Oct 24 17:22:50.422: INFO: (4) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 15.465363ms)
Oct 24 17:22:50.423: INFO: (4) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 16.0197ms)
Oct 24 17:22:50.423: INFO: (4) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 15.98584ms)
Oct 24 17:22:50.423: INFO: (4) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 16.002242ms)
Oct 24 17:22:50.423: INFO: (4) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 16.082288ms)
Oct 24 17:22:50.427: INFO: (5) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 4.335628ms)
Oct 24 17:22:50.435: INFO: (5) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 11.516812ms)
Oct 24 17:22:50.435: INFO: (5) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 10.539835ms)
Oct 24 17:22:50.435: INFO: (5) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 11.436085ms)
Oct 24 17:22:50.435: INFO: (5) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 10.807275ms)
Oct 24 17:22:50.435: INFO: (5) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 11.217303ms)
Oct 24 17:22:50.437: INFO: (5) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 12.845729ms)
Oct 24 17:22:50.437: INFO: (5) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 13.078946ms)
Oct 24 17:22:50.441: INFO: (5) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 17.122861ms)
Oct 24 17:22:50.441: INFO: (5) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 16.997206ms)
Oct 24 17:22:50.441: INFO: (5) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 17.022586ms)
Oct 24 17:22:50.441: INFO: (5) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 16.930586ms)
Oct 24 17:22:50.441: INFO: (5) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 16.763519ms)
Oct 24 17:22:50.441: INFO: (5) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 16.849068ms)
Oct 24 17:22:50.441: INFO: (5) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 17.688821ms)
Oct 24 17:22:50.441: INFO: (5) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 17.109624ms)
Oct 24 17:22:50.449: INFO: (6) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 7.097336ms)
Oct 24 17:22:50.450: INFO: (6) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 8.046484ms)
Oct 24 17:22:50.450: INFO: (6) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 8.110358ms)
Oct 24 17:22:50.459: INFO: (6) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 15.996573ms)
Oct 24 17:22:50.459: INFO: (6) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 16.174723ms)
Oct 24 17:22:50.459: INFO: (6) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 16.743983ms)
Oct 24 17:22:50.459: INFO: (6) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 16.618887ms)
Oct 24 17:22:50.459: INFO: (6) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 17.091316ms)
Oct 24 17:22:50.460: INFO: (6) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 17.294688ms)
Oct 24 17:22:50.460: INFO: (6) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 17.581023ms)
Oct 24 17:22:50.460: INFO: (6) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 18.122245ms)
Oct 24 17:22:50.460: INFO: (6) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 17.963428ms)
Oct 24 17:22:50.460: INFO: (6) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 18.124511ms)
Oct 24 17:22:50.461: INFO: (6) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 18.316333ms)
Oct 24 17:22:50.461: INFO: (6) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 18.843487ms)
Oct 24 17:22:50.461: INFO: (6) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 19.152312ms)
Oct 24 17:22:50.474: INFO: (7) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 11.715836ms)
Oct 24 17:22:50.474: INFO: (7) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 11.947641ms)
Oct 24 17:22:50.475: INFO: (7) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 12.61961ms)
Oct 24 17:22:50.475: INFO: (7) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 12.203164ms)
Oct 24 17:22:50.475: INFO: (7) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 12.37213ms)
Oct 24 17:22:50.475: INFO: (7) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 12.407855ms)
Oct 24 17:22:50.476: INFO: (7) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 13.920572ms)
Oct 24 17:22:50.477: INFO: (7) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 14.644562ms)
Oct 24 17:22:50.478: INFO: (7) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 15.631326ms)
Oct 24 17:22:50.478: INFO: (7) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 16.764097ms)
Oct 24 17:22:50.478: INFO: (7) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 15.462037ms)
Oct 24 17:22:50.478: INFO: (7) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 15.985507ms)
Oct 24 17:22:50.478: INFO: (7) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 16.605599ms)
Oct 24 17:22:50.479: INFO: (7) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 16.483197ms)
Oct 24 17:22:50.479: INFO: (7) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 16.563167ms)
Oct 24 17:22:50.479: INFO: (7) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 17.84245ms)
Oct 24 17:22:50.489: INFO: (8) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 7.060414ms)
Oct 24 17:22:50.491: INFO: (8) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 11.482601ms)
Oct 24 17:22:50.493: INFO: (8) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 11.989443ms)
Oct 24 17:22:50.493: INFO: (8) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 13.869265ms)
Oct 24 17:22:50.494: INFO: (8) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 11.643511ms)
Oct 24 17:22:50.494: INFO: (8) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 11.566352ms)
Oct 24 17:22:50.498: INFO: (8) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 16.490184ms)
Oct 24 17:22:50.498: INFO: (8) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 16.220963ms)
Oct 24 17:22:50.498: INFO: (8) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 16.063711ms)
Oct 24 17:22:50.498: INFO: (8) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 17.537697ms)
Oct 24 17:22:50.498: INFO: (8) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 17.395461ms)
Oct 24 17:22:50.498: INFO: (8) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 17.904192ms)
Oct 24 17:22:50.498: INFO: (8) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 16.81927ms)
Oct 24 17:22:50.498: INFO: (8) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 15.731732ms)
Oct 24 17:22:50.498: INFO: (8) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 17.789475ms)
Oct 24 17:22:50.498: INFO: (8) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 18.55265ms)
Oct 24 17:22:50.508: INFO: (9) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 8.909441ms)
Oct 24 17:22:50.508: INFO: (9) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 9.213253ms)
Oct 24 17:22:50.508: INFO: (9) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 9.565849ms)
Oct 24 17:22:50.508: INFO: (9) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 9.917493ms)
Oct 24 17:22:50.512: INFO: (9) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 12.917846ms)
Oct 24 17:22:50.516: INFO: (9) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 17.051442ms)
Oct 24 17:22:50.516: INFO: (9) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 17.601974ms)
Oct 24 17:22:50.518: INFO: (9) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 19.118015ms)
Oct 24 17:22:50.518: INFO: (9) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 19.306087ms)
Oct 24 17:22:50.518: INFO: (9) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 19.295434ms)
Oct 24 17:22:50.518: INFO: (9) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 19.326614ms)
Oct 24 17:22:50.518: INFO: (9) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 19.491605ms)
Oct 24 17:22:50.518: INFO: (9) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 19.450107ms)
Oct 24 17:22:50.519: INFO: (9) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 19.610299ms)
Oct 24 17:22:50.519: INFO: (9) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 20.022748ms)
Oct 24 17:22:50.520: INFO: (9) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 21.301818ms)
Oct 24 17:22:50.542: INFO: (10) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 20.587513ms)
Oct 24 17:22:50.544: INFO: (10) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 22.771913ms)
Oct 24 17:22:50.544: INFO: (10) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 23.638648ms)
Oct 24 17:22:50.545: INFO: (10) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 24.21271ms)
Oct 24 17:22:50.546: INFO: (10) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 25.19264ms)
Oct 24 17:22:50.546: INFO: (10) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 24.737149ms)
Oct 24 17:22:50.546: INFO: (10) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 24.924131ms)
Oct 24 17:22:50.546: INFO: (10) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 24.857555ms)
Oct 24 17:22:50.546: INFO: (10) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 24.823788ms)
Oct 24 17:22:50.549: INFO: (10) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 27.792308ms)
Oct 24 17:22:50.551: INFO: (10) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 30.176506ms)
Oct 24 17:22:50.551: INFO: (10) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 29.877302ms)
Oct 24 17:22:50.551: INFO: (10) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 30.34653ms)
Oct 24 17:22:50.551: INFO: (10) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 30.305241ms)
Oct 24 17:22:50.552: INFO: (10) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 30.830664ms)
Oct 24 17:22:50.556: INFO: (10) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 34.931249ms)
Oct 24 17:22:50.564: INFO: (11) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 7.976202ms)
Oct 24 17:22:50.564: INFO: (11) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 8.279448ms)
Oct 24 17:22:50.565: INFO: (11) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 8.802337ms)
Oct 24 17:22:50.565: INFO: (11) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 9.550514ms)
Oct 24 17:22:50.565: INFO: (11) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 8.506484ms)
Oct 24 17:22:50.567: INFO: (11) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 10.130791ms)
Oct 24 17:22:50.567: INFO: (11) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 11.140586ms)
Oct 24 17:22:50.567: INFO: (11) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 10.909595ms)
Oct 24 17:22:50.567: INFO: (11) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 10.683485ms)
Oct 24 17:22:50.567: INFO: (11) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 10.543002ms)
Oct 24 17:22:50.571: INFO: (11) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 14.675414ms)
Oct 24 17:22:50.572: INFO: (11) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 15.503631ms)
Oct 24 17:22:50.572: INFO: (11) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 15.858159ms)
Oct 24 17:22:50.572: INFO: (11) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 15.813231ms)
Oct 24 17:22:50.572: INFO: (11) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 15.485361ms)
Oct 24 17:22:50.572: INFO: (11) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 15.096025ms)
Oct 24 17:22:50.585: INFO: (12) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 12.17701ms)
Oct 24 17:22:50.585: INFO: (12) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 12.682893ms)
Oct 24 17:22:50.586: INFO: (12) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 12.863396ms)
Oct 24 17:22:50.586: INFO: (12) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 13.596005ms)
Oct 24 17:22:50.586: INFO: (12) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 13.813077ms)
Oct 24 17:22:50.586: INFO: (12) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 13.232531ms)
Oct 24 17:22:50.586: INFO: (12) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 14.004476ms)
Oct 24 17:22:50.586: INFO: (12) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 13.912143ms)
Oct 24 17:22:50.586: INFO: (12) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 14.163186ms)
Oct 24 17:22:50.587: INFO: (12) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 13.7898ms)
Oct 24 17:22:50.587: INFO: (12) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 15.085489ms)
Oct 24 17:22:50.588: INFO: (12) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 15.184368ms)
Oct 24 17:22:50.588: INFO: (12) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 15.417949ms)
Oct 24 17:22:50.589: INFO: (12) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 16.792252ms)
Oct 24 17:22:50.589: INFO: (12) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 16.160079ms)
Oct 24 17:22:50.589: INFO: (12) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 16.244377ms)
Oct 24 17:22:50.595: INFO: (13) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 6.215083ms)
Oct 24 17:22:50.596: INFO: (13) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 6.166421ms)
Oct 24 17:22:50.598: INFO: (13) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 7.571517ms)
Oct 24 17:22:50.603: INFO: (13) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 13.299535ms)
Oct 24 17:22:50.604: INFO: (13) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 13.64074ms)
Oct 24 17:22:50.604: INFO: (13) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 13.473911ms)
Oct 24 17:22:50.604: INFO: (13) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 13.642355ms)
Oct 24 17:22:50.605: INFO: (13) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 14.547409ms)
Oct 24 17:22:50.605: INFO: (13) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 15.443388ms)
Oct 24 17:22:50.605: INFO: (13) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 14.519296ms)
Oct 24 17:22:50.606: INFO: (13) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 16.366252ms)
Oct 24 17:22:50.606: INFO: (13) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 16.160426ms)
Oct 24 17:22:50.606: INFO: (13) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 15.918762ms)
Oct 24 17:22:50.606: INFO: (13) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 16.754859ms)
Oct 24 17:22:50.606: INFO: (13) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 16.022143ms)
Oct 24 17:22:50.606: INFO: (13) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 15.923247ms)
Oct 24 17:22:50.613: INFO: (14) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 6.132231ms)
Oct 24 17:22:50.620: INFO: (14) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 11.976911ms)
Oct 24 17:22:50.621: INFO: (14) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 12.961106ms)
Oct 24 17:22:50.629: INFO: (14) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 20.970837ms)
Oct 24 17:22:50.637: INFO: (14) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 28.825465ms)
Oct 24 17:22:50.637: INFO: (14) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 28.642203ms)
Oct 24 17:22:50.638: INFO: (14) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 30.05693ms)
Oct 24 17:22:50.642: INFO: (14) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 33.303811ms)
Oct 24 17:22:50.642: INFO: (14) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 33.758222ms)
Oct 24 17:22:50.642: INFO: (14) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 34.879178ms)
Oct 24 17:22:50.643: INFO: (14) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 34.503007ms)
Oct 24 17:22:50.644: INFO: (14) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 37.543235ms)
Oct 24 17:22:50.645: INFO: (14) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 36.623374ms)
Oct 24 17:22:50.645: INFO: (14) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 37.397119ms)
Oct 24 17:22:50.645: INFO: (14) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 38.277821ms)
Oct 24 17:22:50.652: INFO: (14) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 43.590421ms)
Oct 24 17:22:50.683: INFO: (15) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 30.906336ms)
Oct 24 17:22:50.683: INFO: (15) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 31.466047ms)
Oct 24 17:22:50.685: INFO: (15) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 33.217134ms)
Oct 24 17:22:50.686: INFO: (15) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 33.603472ms)
Oct 24 17:22:50.687: INFO: (15) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 34.760771ms)
Oct 24 17:22:50.687: INFO: (15) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 34.800767ms)
Oct 24 17:22:50.688: INFO: (15) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 35.880843ms)
Oct 24 17:22:50.688: INFO: (15) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 36.02406ms)
Oct 24 17:22:50.688: INFO: (15) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 36.222456ms)
Oct 24 17:22:50.688: INFO: (15) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 36.389764ms)
Oct 24 17:22:50.689: INFO: (15) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 36.333876ms)
Oct 24 17:22:50.689: INFO: (15) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 36.426286ms)
Oct 24 17:22:50.689: INFO: (15) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 36.519204ms)
Oct 24 17:22:50.689: INFO: (15) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 37.012649ms)
Oct 24 17:22:50.689: INFO: (15) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 37.112978ms)
Oct 24 17:22:50.690: INFO: (15) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 37.845581ms)
Oct 24 17:22:50.727: INFO: (16) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 37.521063ms)
Oct 24 17:22:50.737: INFO: (16) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 45.791399ms)
Oct 24 17:22:50.739: INFO: (16) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 47.605556ms)
Oct 24 17:22:50.739: INFO: (16) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 48.28199ms)
Oct 24 17:22:50.740: INFO: (16) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 48.287558ms)
Oct 24 17:22:50.740: INFO: (16) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 48.855573ms)
Oct 24 17:22:50.740: INFO: (16) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 50.085121ms)
Oct 24 17:22:50.740: INFO: (16) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 48.966958ms)
Oct 24 17:22:50.741: INFO: (16) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 50.711905ms)
Oct 24 17:22:50.741: INFO: (16) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 50.387709ms)
Oct 24 17:22:50.742: INFO: (16) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 50.998834ms)
Oct 24 17:22:50.742: INFO: (16) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 50.50637ms)
Oct 24 17:22:50.742: INFO: (16) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 51.259956ms)
Oct 24 17:22:50.742: INFO: (16) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 51.157295ms)
Oct 24 17:22:50.742: INFO: (16) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 51.041764ms)
Oct 24 17:22:50.742: INFO: (16) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 51.588692ms)
Oct 24 17:22:50.754: INFO: (17) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 11.086331ms)
Oct 24 17:22:50.755: INFO: (17) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 11.906934ms)
Oct 24 17:22:50.756: INFO: (17) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 12.397856ms)
Oct 24 17:22:50.756: INFO: (17) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 12.922064ms)
Oct 24 17:22:50.756: INFO: (17) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 12.63627ms)
Oct 24 17:22:50.761: INFO: (17) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 17.835318ms)
Oct 24 17:22:50.761: INFO: (17) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 17.675823ms)
Oct 24 17:22:50.761: INFO: (17) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 18.022245ms)
Oct 24 17:22:50.761: INFO: (17) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 18.425573ms)
Oct 24 17:22:50.762: INFO: (17) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 19.390555ms)
Oct 24 17:22:50.762: INFO: (17) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 18.503196ms)
Oct 24 17:22:50.762: INFO: (17) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 18.670864ms)
Oct 24 17:22:50.762: INFO: (17) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 19.065504ms)
Oct 24 17:22:50.762: INFO: (17) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 18.46099ms)
Oct 24 17:22:50.762: INFO: (17) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 19.319582ms)
Oct 24 17:22:50.763: INFO: (17) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 19.488319ms)
Oct 24 17:22:50.772: INFO: (18) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 8.121651ms)
Oct 24 17:22:50.773: INFO: (18) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 9.96047ms)
Oct 24 17:22:50.773: INFO: (18) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 9.713133ms)
Oct 24 17:22:50.773: INFO: (18) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 9.769539ms)
Oct 24 17:22:50.773: INFO: (18) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 10.301538ms)
Oct 24 17:22:50.778: INFO: (18) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 15.11171ms)
Oct 24 17:22:50.778: INFO: (18) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 14.259858ms)
Oct 24 17:22:50.778: INFO: (18) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 14.748269ms)
Oct 24 17:22:50.778: INFO: (18) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 14.153242ms)
Oct 24 17:22:50.779: INFO: (18) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 15.388864ms)
Oct 24 17:22:50.779: INFO: (18) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 16.076259ms)
Oct 24 17:22:50.779: INFO: (18) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 16.013179ms)
Oct 24 17:22:50.779: INFO: (18) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 15.28373ms)
Oct 24 17:22:50.779: INFO: (18) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 15.954537ms)
Oct 24 17:22:50.780: INFO: (18) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 15.877281ms)
Oct 24 17:22:50.780: INFO: (18) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 17.316286ms)
Oct 24 17:22:50.789: INFO: (19) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:462/proxy/: tls qux (200; 9.072396ms)
Oct 24 17:22:50.790: INFO: (19) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:160/proxy/: foo (200; 8.783068ms)
Oct 24 17:22:50.790: INFO: (19) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592/proxy/rewriteme">test</a> (200; 9.02924ms)
Oct 24 17:22:50.790: INFO: (19) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:160/proxy/: foo (200; 8.90307ms)
Oct 24 17:22:50.791: INFO: (19) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:1080/proxy/rewriteme">test<... (200; 10.03825ms)
Oct 24 17:22:50.791: INFO: (19) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:162/proxy/: bar (200; 10.079738ms)
Oct 24 17:22:50.791: INFO: (19) /api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/http:proxy-service-p4jqb-6m592:1080/proxy/rewriteme">... (200; 10.276056ms)
Oct 24 17:22:50.792: INFO: (19) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:460/proxy/: tls baz (200; 11.043956ms)
Oct 24 17:22:50.792: INFO: (19) /api/v1/namespaces/proxy-1122/pods/proxy-service-p4jqb-6m592:162/proxy/: bar (200; 11.298371ms)
Oct 24 17:22:50.792: INFO: (19) /api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/: <a href="/api/v1/namespaces/proxy-1122/pods/https:proxy-service-p4jqb-6m592:443/proxy/tlsrewritem... (200; 11.54118ms)
Oct 24 17:22:50.794: INFO: (19) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname2/proxy/: tls qux (200; 14.230155ms)
Oct 24 17:22:50.795: INFO: (19) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname1/proxy/: foo (200; 14.407413ms)
Oct 24 17:22:50.795: INFO: (19) /api/v1/namespaces/proxy-1122/services/http:proxy-service-p4jqb:portname2/proxy/: bar (200; 14.279725ms)
Oct 24 17:22:50.796: INFO: (19) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname1/proxy/: foo (200; 14.635287ms)
Oct 24 17:22:50.796: INFO: (19) /api/v1/namespaces/proxy-1122/services/https:proxy-service-p4jqb:tlsportname1/proxy/: tls baz (200; 15.00471ms)
Oct 24 17:22:50.796: INFO: (19) /api/v1/namespaces/proxy-1122/services/proxy-service-p4jqb:portname2/proxy/: bar (200; 14.882054ms)
STEP: deleting ReplicationController proxy-service-p4jqb in namespace proxy-1122, will wait for the garbage collector to delete the pods
Oct 24 17:22:50.858: INFO: Deleting ReplicationController proxy-service-p4jqb took: 7.805481ms
Oct 24 17:22:51.258: INFO: Terminating ReplicationController proxy-service-p4jqb pods took: 400.318206ms
[AfterEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:22:53.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1122" for this suite.
Oct 24 17:22:59.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:22:59.822: INFO: namespace proxy-1122 deletion completed in 6.158554742s

• [SLOW TEST:21.644 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:22:59.823: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Oct 24 17:22:59.877: INFO: Waiting up to 5m0s for pod "client-containers-ed4904c1-f682-11e9-8e41-6682758dfd28" in namespace "containers-7751" to be "success or failure"
Oct 24 17:22:59.883: INFO: Pod "client-containers-ed4904c1-f682-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.350094ms
Oct 24 17:23:01.889: INFO: Pod "client-containers-ed4904c1-f682-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011711559s
Oct 24 17:23:03.895: INFO: Pod "client-containers-ed4904c1-f682-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 4.017392589s
Oct 24 17:23:05.900: INFO: Pod "client-containers-ed4904c1-f682-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02249108s
STEP: Saw pod success
Oct 24 17:23:05.900: INFO: Pod "client-containers-ed4904c1-f682-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:23:05.904: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod client-containers-ed4904c1-f682-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 17:23:05.932: INFO: Waiting for pod client-containers-ed4904c1-f682-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:23:05.937: INFO: Pod client-containers-ed4904c1-f682-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:23:05.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7751" for this suite.
Oct 24 17:23:11.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:23:12.104: INFO: namespace containers-7751 deletion completed in 6.162807232s

• [SLOW TEST:12.282 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:23:12.104: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 17:23:12.150: INFO: Creating deployment "nginx-deployment"
Oct 24 17:23:12.156: INFO: Waiting for observed generation 1
Oct 24 17:23:14.165: INFO: Waiting for all required pods to come up
Oct 24 17:23:14.171: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Oct 24 17:23:16.188: INFO: Waiting for deployment "nginx-deployment" to complete
Oct 24 17:23:16.196: INFO: Updating deployment "nginx-deployment" with a non-existent image
Oct 24 17:23:16.206: INFO: Updating deployment nginx-deployment
Oct 24 17:23:16.206: INFO: Waiting for observed generation 2
Oct 24 17:23:18.218: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct 24 17:23:18.222: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct 24 17:23:18.226: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 24 17:23:18.237: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct 24 17:23:18.237: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct 24 17:23:18.241: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 24 17:23:18.248: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Oct 24 17:23:18.248: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Oct 24 17:23:18.258: INFO: Updating deployment nginx-deployment
Oct 24 17:23:18.258: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Oct 24 17:23:18.267: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct 24 17:23:18.273: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 24 17:23:20.289: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-9145,SelfLink:/apis/apps/v1/namespaces/deployment-9145/deployments/nginx-deployment,UID:f49b86c0-f682-11e9-a6ac-005056ab7215,ResourceVersion:2973,Generation:3,CreationTimestamp:2019-10-24 17:23:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-10-24 17:23:18 +0000 UTC 2019-10-24 17:23:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-10-24 17:23:18 +0000 UTC 2019-10-24 17:23:12 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-b79c9d74d" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Oct 24 17:23:20.296: INFO: New ReplicaSet "nginx-deployment-b79c9d74d" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d,GenerateName:,Namespace:deployment-9145,SelfLink:/apis/apps/v1/namespaces/deployment-9145/replicasets/nginx-deployment-b79c9d74d,UID:f7068e59-f682-11e9-a6ac-005056ab7215,ResourceVersion:2966,Generation:3,CreationTimestamp:2019-10-24 17:23:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f49b86c0-f682-11e9-a6ac-005056ab7215 0xc0020ba357 0xc0020ba358}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 24 17:23:20.296: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Oct 24 17:23:20.296: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5,GenerateName:,Namespace:deployment-9145,SelfLink:/apis/apps/v1/namespaces/deployment-9145/replicasets/nginx-deployment-85db8c99c5,UID:f49c9fa2-f682-11e9-a6ac-005056ab7215,ResourceVersion:2972,Generation:3,CreationTimestamp:2019-10-24 17:23:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f49b86c0-f682-11e9-a6ac-005056ab7215 0xc0020ba287 0xc0020ba288}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Oct 24 17:23:20.310: INFO: Pod "nginx-deployment-85db8c99c5-5fk9z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-5fk9z,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-5fk9z,UID:f84772d5-f682-11e9-a6ac-005056ab7215,ResourceVersion:3057,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.23/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc000df1eb0 0xc000df1eb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000df1f10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000df1f30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:,StartTime:2019-10-24 17:23:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.311: INFO: Pod "nginx-deployment-85db8c99c5-5ttpj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-5ttpj,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-5ttpj,UID:f847c738-f682-11e9-a6ac-005056ab7215,ResourceVersion:3037,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.24/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264e007 0xc00264e008}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264e070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264e090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:,StartTime:2019-10-24 17:23:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.311: INFO: Pod "nginx-deployment-85db8c99c5-6f6z5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-6f6z5,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-6f6z5,UID:f4a5bcc5-f682-11e9-a6ac-005056ab7215,ResourceVersion:2820,Generation:0,CreationTimestamp:2019-10-24 17:23:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.12/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264e167 0xc00264e168}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264e1d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264e1f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:12 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.2.12,StartTime:2019-10-24 17:23:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-24 17:23:13 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b565d6124f876f14ffc31c462574a03486f09f61bbc736499f0030a325c95b20}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.311: INFO: Pod "nginx-deployment-85db8c99c5-6nr2h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-6nr2h,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-6nr2h,UID:f8421388-f682-11e9-a6ac-005056ab7215,ResourceVersion:3020,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.18/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264e2d0 0xc00264e2d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264e330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264e350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:,StartTime:2019-10-24 17:23:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.311: INFO: Pod "nginx-deployment-85db8c99c5-7rwkc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-7rwkc,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-7rwkc,UID:f4a521e8-f682-11e9-a6ac-005056ab7215,ResourceVersion:2830,Generation:0,CreationTimestamp:2019-10-24 17:23:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.14/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264e427 0xc00264e428}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264e490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264e4b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:12 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.1.14,StartTime:2019-10-24 17:23:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-24 17:23:13 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f52bb56bd0955d6195fc54c807d85f6627d861f25dda365868b549528df9eb30}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.312: INFO: Pod "nginx-deployment-85db8c99c5-9zzxh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-9zzxh,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-9zzxh,UID:f84d5aaa-f682-11e9-a6ac-005056ab7215,ResourceVersion:3046,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.25/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264e590 0xc00264e591}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264e5f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264e610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:,StartTime:2019-10-24 17:23:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.312: INFO: Pod "nginx-deployment-85db8c99c5-dldzr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-dldzr,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-dldzr,UID:f847ac15-f682-11e9-a6ac-005056ab7215,ResourceVersion:3030,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.22/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264e6e7 0xc00264e6e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264e750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264e770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:,StartTime:2019-10-24 17:23:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.312: INFO: Pod "nginx-deployment-85db8c99c5-fdpjm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-fdpjm,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-fdpjm,UID:f84d2df0-f682-11e9-a6ac-005056ab7215,ResourceVersion:3060,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.26/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264e847 0xc00264e848}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264e8b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264e8d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.312: INFO: Pod "nginx-deployment-85db8c99c5-hpxrp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-hpxrp,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-hpxrp,UID:f84d7bb2-f682-11e9-a6ac-005056ab7215,ResourceVersion:3047,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.26/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264e960 0xc00264e961}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264e9c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264e9e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.313: INFO: Pod "nginx-deployment-85db8c99c5-khhv8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-khhv8,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-khhv8,UID:f4a1e011-f682-11e9-a6ac-005056ab7215,ResourceVersion:2809,Generation:0,CreationTimestamp:2019-10-24 17:23:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.11/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264ea70 0xc00264ea71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264ead0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264eaf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:12 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.2.11,StartTime:2019-10-24 17:23:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-24 17:23:13 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://87fe42b7dd910550351788346ebb9a63575196edc2230829348f5f0b528e9026}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.316: INFO: Pod "nginx-deployment-85db8c99c5-knbnl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-knbnl,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-knbnl,UID:f4a1c792-f682-11e9-a6ac-005056ab7215,ResourceVersion:2803,Generation:0,CreationTimestamp:2019-10-24 17:23:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.15/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264ebd0 0xc00264ebd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264ec30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264ec50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:12 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.1.15,StartTime:2019-10-24 17:23:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-24 17:23:13 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d4c623997395dc2ce0d2bd2424c19c66d7d79b452714101ec4c5f5b56787a011}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.316: INFO: Pod "nginx-deployment-85db8c99c5-lv79f" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-lv79f,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-lv79f,UID:f49f652b-f682-11e9-a6ac-005056ab7215,ResourceVersion:2817,Generation:0,CreationTimestamp:2019-10-24 17:23:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.11/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264ed30 0xc00264ed31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264ed90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264edb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:12 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.1.11,StartTime:2019-10-24 17:23:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-24 17:23:13 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a16cb7e5f9fe79713676718998e26d5776ae8c84d65157097e4e720029543b60}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.316: INFO: Pod "nginx-deployment-85db8c99c5-n8f9k" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-n8f9k,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-n8f9k,UID:f49f8e51-f682-11e9-a6ac-005056ab7215,ResourceVersion:2811,Generation:0,CreationTimestamp:2019-10-24 17:23:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.12/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264ee90 0xc00264ee91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264eef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264ef10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:12 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.1.12,StartTime:2019-10-24 17:23:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-24 17:23:13 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://58d49627ec4a5b36fd904e0c0056d96c0a6667b959fe185f9bb251766ea5b12f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.317: INFO: Pod "nginx-deployment-85db8c99c5-pzxgm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-pzxgm,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-pzxgm,UID:f84dc8e6-f682-11e9-a6ac-005056ab7215,ResourceVersion:3065,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.28/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264eff0 0xc00264eff1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264f050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264f070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:,StartTime:2019-10-24 17:23:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.317: INFO: Pod "nginx-deployment-85db8c99c5-qd8rr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-qd8rr,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-qd8rr,UID:f843fd6a-f682-11e9-a6ac-005056ab7215,ResourceVersion:3027,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.21/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264f147 0xc00264f148}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264f1b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264f1d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:,StartTime:2019-10-24 17:23:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.317: INFO: Pod "nginx-deployment-85db8c99c5-r447d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-r447d,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-r447d,UID:f8476795-f682-11e9-a6ac-005056ab7215,ResourceVersion:3063,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.27/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264f2a7 0xc00264f2a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264f310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264f330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:,StartTime:2019-10-24 17:23:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.324: INFO: Pod "nginx-deployment-85db8c99c5-rkplz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-rkplz,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-rkplz,UID:f8441153-f682-11e9-a6ac-005056ab7215,ResourceVersion:3042,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.20/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264f407 0xc00264f408}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264f470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264f490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:,StartTime:2019-10-24 17:23:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.325: INFO: Pod "nginx-deployment-85db8c99c5-vlfvk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-vlfvk,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-vlfvk,UID:f4a18b01-f682-11e9-a6ac-005056ab7215,ResourceVersion:2824,Generation:0,CreationTimestamp:2019-10-24 17:23:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.14/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264f567 0xc00264f568}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264f5d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264f5f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:12 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.2.14,StartTime:2019-10-24 17:23:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-24 17:23:13 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://4b1977502b06696ea1b1891aa77b7b2dfe881c017432f353074f4b19270a9130}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.325: INFO: Pod "nginx-deployment-85db8c99c5-xqxjk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-xqxjk,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-xqxjk,UID:f4a5c935-f682-11e9-a6ac-005056ab7215,ResourceVersion:2806,Generation:0,CreationTimestamp:2019-10-24 17:23:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.13/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264f6d0 0xc00264f6d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264f730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264f750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:12 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.1.13,StartTime:2019-10-24 17:23:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-24 17:23:13 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d52c01a88c77e71e5503febdcfe5bf2aa2d177a1bde4714b3e6f68dc104d3651}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.325: INFO: Pod "nginx-deployment-85db8c99c5-xz9cp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-xz9cp,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-85db8c99c5-xz9cp,UID:f84ccae6-f682-11e9-a6ac-005056ab7215,ResourceVersion:3056,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.24/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f49c9fa2-f682-11e9-a6ac-005056ab7215 0xc00264f830 0xc00264f831}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264f890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264f8b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.326: INFO: Pod "nginx-deployment-b79c9d74d-59mbz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-59mbz,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-b79c9d74d-59mbz,UID:f71559d4-f682-11e9-a6ac-005056ab7215,ResourceVersion:2899,Generation:0,CreationTimestamp:2019-10-24 17:23:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.16/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f7068e59-f682-11e9-a6ac-005056ab7215 0xc00264f940 0xc00264f941}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264f9b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264f9d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:,StartTime:2019-10-24 17:23:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.326: INFO: Pod "nginx-deployment-b79c9d74d-82ld7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-82ld7,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-b79c9d74d-82ld7,UID:f84983bf-f682-11e9-a6ac-005056ab7215,ResourceVersion:3058,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.25/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f7068e59-f682-11e9-a6ac-005056ab7215 0xc00264fab0 0xc00264fab1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264fb20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264fb40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:,StartTime:2019-10-24 17:23:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.326: INFO: Pod "nginx-deployment-b79c9d74d-8kwfl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-8kwfl,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-b79c9d74d-8kwfl,UID:f7088b6f-f682-11e9-a6ac-005056ab7215,ResourceVersion:3015,Generation:0,CreationTimestamp:2019-10-24 17:23:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.16/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f7068e59-f682-11e9-a6ac-005056ab7215 0xc00264fc20 0xc00264fc21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264fc90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264fcb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.1.16,StartTime:2019-10-24 17:23:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = manifest for docker.io/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.326: INFO: Pod "nginx-deployment-b79c9d74d-c2dsw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-c2dsw,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-b79c9d74d-c2dsw,UID:f8432c92-f682-11e9-a6ac-005056ab7215,ResourceVersion:3033,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.23/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f7068e59-f682-11e9-a6ac-005056ab7215 0xc00264fdb0 0xc00264fdb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264fe20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264fe40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:,StartTime:2019-10-24 17:23:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.327: INFO: Pod "nginx-deployment-b79c9d74d-gsq4v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-gsq4v,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-b79c9d74d-gsq4v,UID:f8468b5e-f682-11e9-a6ac-005056ab7215,ResourceVersion:3022,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.18/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f7068e59-f682-11e9-a6ac-005056ab7215 0xc00264ff20 0xc00264ff21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00264ff90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00264ffb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:,StartTime:2019-10-24 17:23:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.327: INFO: Pod "nginx-deployment-b79c9d74d-hgmc9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-hgmc9,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-b79c9d74d-hgmc9,UID:f849e673-f682-11e9-a6ac-005056ab7215,ResourceVersion:3025,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.20/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f7068e59-f682-11e9-a6ac-005056ab7215 0xc0024a8090 0xc0024a8091}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024a8100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024a8120}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:,StartTime:2019-10-24 17:23:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.327: INFO: Pod "nginx-deployment-b79c9d74d-htns2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-htns2,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-b79c9d74d-htns2,UID:f7133a59-f682-11e9-a6ac-005056ab7215,ResourceVersion:2900,Generation:0,CreationTimestamp:2019-10-24 17:23:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.17/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f7068e59-f682-11e9-a6ac-005056ab7215 0xc0024a8200 0xc0024a8201}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024a8270} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024a8290}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:,StartTime:2019-10-24 17:23:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.328: INFO: Pod "nginx-deployment-b79c9d74d-hzw55" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-hzw55,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-b79c9d74d-hzw55,UID:f84e75cc-f682-11e9-a6ac-005056ab7215,ResourceVersion:3050,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.21/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f7068e59-f682-11e9-a6ac-005056ab7215 0xc0024a8370 0xc0024a8371}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024a83e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024a8400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.328: INFO: Pod "nginx-deployment-b79c9d74d-mk48q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-mk48q,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-b79c9d74d-mk48q,UID:f846bd69-f682-11e9-a6ac-005056ab7215,ResourceVersion:3040,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.19/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f7068e59-f682-11e9-a6ac-005056ab7215 0xc0024a8490 0xc0024a8491}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024a8500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024a8520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:,StartTime:2019-10-24 17:23:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.328: INFO: Pod "nginx-deployment-b79c9d74d-r7rn9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-r7rn9,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-b79c9d74d-r7rn9,UID:f7076ef2-f682-11e9-a6ac-005056ab7215,ResourceVersion:2895,Generation:0,CreationTimestamp:2019-10-24 17:23:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.15/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f7068e59-f682-11e9-a6ac-005056ab7215 0xc0024a8600 0xc0024a8601}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024a8670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024a8690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:,StartTime:2019-10-24 17:23:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.328: INFO: Pod "nginx-deployment-b79c9d74d-rpkmc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-rpkmc,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-b79c9d74d-rpkmc,UID:f849ca3d-f682-11e9-a6ac-005056ab7215,ResourceVersion:3053,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.22/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f7068e59-f682-11e9-a6ac-005056ab7215 0xc0024a8770 0xc0024a8771}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024a87e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024a8800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:,StartTime:2019-10-24 17:23:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.329: INFO: Pod "nginx-deployment-b79c9d74d-sl4vg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-sl4vg,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-b79c9d74d-sl4vg,UID:f70862e9-f682-11e9-a6ac-005056ab7215,ResourceVersion:2896,Generation:0,CreationTimestamp:2019-10-24 17:23:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.17/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f7068e59-f682-11e9-a6ac-005056ab7215 0xc0024a88e0 0xc0024a88e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024a8950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024a8970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:16 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:,StartTime:2019-10-24 17:23:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 24 17:23:20.329: INFO: Pod "nginx-deployment-b79c9d74d-v5dck" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-v5dck,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9145,SelfLink:/api/v1/namespaces/deployment-9145/pods/nginx-deployment-b79c9d74d-v5dck,UID:f849bfc5-f682-11e9-a6ac-005056ab7215,ResourceVersion:3024,Generation:0,CreationTimestamp:2019-10-24 17:23:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.19/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f7068e59-f682-11e9-a6ac-005056ab7215 0xc0024a8a50 0xc0024a8a51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-msp4t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msp4t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msp4t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024a8ac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024a8ae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:23:18 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:,StartTime:2019-10-24 17:23:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:23:20.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9145" for this suite.
Oct 24 17:23:28.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:23:28.498: INFO: namespace deployment-9145 deletion completed in 8.157275882s

• [SLOW TEST:16.394 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:23:28.499: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1383
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Oct 24 17:23:28.567: INFO: Found 0 stateful pods, waiting for 3
Oct 24 17:23:38.574: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 17:23:38.574: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 17:23:38.574: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 17:23:38.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-1383 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 24 17:23:38.899: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 24 17:23:38.899: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 24 17:23:38.899: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 24 17:23:48.945: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Oct 24 17:23:58.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-1383 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 24 17:23:59.285: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 24 17:23:59.285: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 24 17:23:59.285: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 24 17:24:29.315: INFO: Waiting for StatefulSet statefulset-1383/ss2 to complete update
STEP: Rolling back to a previous revision
Oct 24 17:24:39.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-1383 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 24 17:24:39.646: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 24 17:24:39.646: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 24 17:24:39.646: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 24 17:24:49.686: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Oct 24 17:24:59.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-1383 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 24 17:25:00.034: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 24 17:25:00.034: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 24 17:25:00.034: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 24 17:25:30.063: INFO: Deleting all statefulset in ns statefulset-1383
Oct 24 17:25:30.067: INFO: Scaling statefulset ss2 to 0
Oct 24 17:25:40.088: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 17:25:40.093: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:25:40.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1383" for this suite.
Oct 24 17:25:56.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:25:56.304: INFO: namespace statefulset-1383 deletion completed in 16.185973073s

• [SLOW TEST:147.805 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:25:56.304: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-567a598c-f683-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume configMaps
Oct 24 17:25:56.368: INFO: Waiting up to 5m0s for pod "pod-configmaps-567b7799-f683-11e9-8e41-6682758dfd28" in namespace "configmap-5687" to be "success or failure"
Oct 24 17:25:56.373: INFO: Pod "pod-configmaps-567b7799-f683-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.530947ms
Oct 24 17:25:58.380: INFO: Pod "pod-configmaps-567b7799-f683-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01194732s
Oct 24 17:26:00.386: INFO: Pod "pod-configmaps-567b7799-f683-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017975993s
Oct 24 17:26:02.394: INFO: Pod "pod-configmaps-567b7799-f683-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026547204s
STEP: Saw pod success
Oct 24 17:26:02.394: INFO: Pod "pod-configmaps-567b7799-f683-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:26:02.398: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-567b7799-f683-11e9-8e41-6682758dfd28 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 17:26:02.430: INFO: Waiting for pod pod-configmaps-567b7799-f683-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:26:02.434: INFO: Pod pod-configmaps-567b7799-f683-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:26:02.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5687" for this suite.
Oct 24 17:26:08.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:26:08.616: INFO: namespace configmap-5687 deletion completed in 6.177158614s

• [SLOW TEST:12.312 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:26:08.616: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct 24 17:26:08.671: INFO: Waiting up to 5m0s for pod "downward-api-5dd09d71-f683-11e9-8e41-6682758dfd28" in namespace "downward-api-1545" to be "success or failure"
Oct 24 17:26:08.676: INFO: Pod "downward-api-5dd09d71-f683-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.512957ms
Oct 24 17:26:10.682: INFO: Pod "downward-api-5dd09d71-f683-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010184923s
STEP: Saw pod success
Oct 24 17:26:10.682: INFO: Pod "downward-api-5dd09d71-f683-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:26:10.686: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downward-api-5dd09d71-f683-11e9-8e41-6682758dfd28 container dapi-container: <nil>
STEP: delete the pod
Oct 24 17:26:10.714: INFO: Waiting for pod downward-api-5dd09d71-f683-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:26:10.717: INFO: Pod downward-api-5dd09d71-f683-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:26:10.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1545" for this suite.
Oct 24 17:26:16.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:26:16.897: INFO: namespace downward-api-1545 deletion completed in 6.174742206s

• [SLOW TEST:8.281 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:26:16.898: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct 24 17:26:16.947: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 24 17:26:16.956: INFO: Waiting for terminating namespaces to be deleted...
Oct 24 17:26:16.960: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm40.mip.storage.hpecorp.net before test
Oct 24 17:26:16.970: INFO: kubedirector-fsmount-r4npk from kube-system started at 2019-10-24 17:11:25 +0000 UTC (1 container statuses recorded)
Oct 24 17:26:16.970: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 24 17:26:16.970: INFO: sonobuoy-e2e-job-b8b444507c5f4f4c from sonobuoy started at 2019-10-24 17:16:49 +0000 UTC (2 container statuses recorded)
Oct 24 17:26:16.970: INFO: 	Container e2e ready: true, restart count 0
Oct 24 17:26:16.970: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 17:26:16.970: INFO: sonobuoy-systemd-logs-daemon-set-db3f66083eff4fdd-wtw9h from sonobuoy started at 2019-10-24 17:16:49 +0000 UTC (2 container statuses recorded)
Oct 24 17:26:16.970: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 17:26:16.970: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 17:26:16.970: INFO: kube-proxy-cvhqm from kube-system started at 2019-10-24 17:09:39 +0000 UTC (1 container statuses recorded)
Oct 24 17:26:16.970: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 24 17:26:16.970: INFO: kubedirector-5b9c586b87-256s7 from kube-system started at 2019-10-24 17:10:11 +0000 UTC (1 container statuses recorded)
Oct 24 17:26:16.970: INFO: 	Container kubedirector ready: true, restart count 0
Oct 24 17:26:16.970: INFO: canal-llqpj from kube-system started at 2019-10-24 17:10:17 +0000 UTC (3 container statuses recorded)
Oct 24 17:26:16.970: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 17:26:16.970: INFO: 	Container install-cni ready: true, restart count 0
Oct 24 17:26:16.970: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 24 17:26:16.970: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm41.mip.storage.hpecorp.net before test
Oct 24 17:26:16.980: INFO: kube-state-metrics-69cb568659-hmp7h from kube-system started at 2019-10-24 17:10:07 +0000 UTC (1 container statuses recorded)
Oct 24 17:26:16.980: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 24 17:26:16.980: INFO: canal-jnk4h from kube-system started at 2019-10-24 17:10:17 +0000 UTC (3 container statuses recorded)
Oct 24 17:26:16.980: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 17:26:16.980: INFO: 	Container install-cni ready: true, restart count 0
Oct 24 17:26:16.980: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 24 17:26:16.980: INFO: kube-proxy-vgccc from kube-system started at 2019-10-24 17:09:35 +0000 UTC (1 container statuses recorded)
Oct 24 17:26:16.980: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 24 17:26:16.980: INFO: sonobuoy-systemd-logs-daemon-set-db3f66083eff4fdd-scddt from sonobuoy started at 2019-10-24 17:16:49 +0000 UTC (2 container statuses recorded)
Oct 24 17:26:16.980: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 17:26:16.980: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 17:26:16.980: INFO: kubedirector-fsmount-rnkvz from kube-system started at 2019-10-24 17:11:25 +0000 UTC (1 container statuses recorded)
Oct 24 17:26:16.980: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 24 17:26:16.980: INFO: sonobuoy from sonobuoy started at 2019-10-24 17:16:37 +0000 UTC (1 container statuses recorded)
Oct 24 17:26:16.980: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-63fd1f07-f683-11e9-8e41-6682758dfd28 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-63fd1f07-f683-11e9-8e41-6682758dfd28 off the node mip-bd-vm40.mip.storage.hpecorp.net
STEP: verifying the node doesn't have the label kubernetes.io/e2e-63fd1f07-f683-11e9-8e41-6682758dfd28
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:26:21.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1490" for this suite.
Oct 24 17:26:41.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:26:41.249: INFO: namespace sched-pred-1490 deletion completed in 20.165606561s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:24.351 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:26:41.250: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:26:43.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1812" for this suite.
Oct 24 17:27:27.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:27:27.500: INFO: namespace kubelet-test-1812 deletion completed in 44.164252836s

• [SLOW TEST:46.250 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:27:27.500: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Oct 24 17:27:27.552: INFO: namespace kubectl-6421
Oct 24 17:27:27.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 create -f - --namespace=kubectl-6421'
Oct 24 17:27:27.868: INFO: stderr: ""
Oct 24 17:27:27.868: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 24 17:27:28.874: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 17:27:28.874: INFO: Found 0 / 1
Oct 24 17:27:29.873: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 17:27:29.873: INFO: Found 1 / 1
Oct 24 17:27:29.873: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 24 17:27:29.878: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 17:27:29.878: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 24 17:27:29.878: INFO: wait on redis-master startup in kubectl-6421 
Oct 24 17:27:29.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 logs redis-master-ssqrl redis-master --namespace=kubectl-6421'
Oct 24 17:27:30.070: INFO: stderr: ""
Oct 24 17:27:30.070: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 24 Oct 17:27:28.932 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 24 Oct 17:27:28.932 # Server started, Redis version 3.2.12\n1:M 24 Oct 17:27:28.932 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Oct 24 17:27:30.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-6421'
Oct 24 17:27:30.276: INFO: stderr: ""
Oct 24 17:27:30.276: INFO: stdout: "service/rm2 exposed\n"
Oct 24 17:27:30.282: INFO: Service rm2 in namespace kubectl-6421 found.
STEP: exposing service
Oct 24 17:27:32.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-6421'
Oct 24 17:27:32.480: INFO: stderr: ""
Oct 24 17:27:32.480: INFO: stdout: "service/rm3 exposed\n"
Oct 24 17:27:32.486: INFO: Service rm3 in namespace kubectl-6421 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:27:34.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6421" for this suite.
Oct 24 17:27:56.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:27:56.669: INFO: namespace kubectl-6421 deletion completed in 22.169173089s

• [SLOW TEST:29.169 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:27:56.669: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 17:27:56.734: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e399a66-f683-11e9-8e41-6682758dfd28" in namespace "projected-3367" to be "success or failure"
Oct 24 17:27:56.738: INFO: Pod "downwardapi-volume-9e399a66-f683-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.065638ms
Oct 24 17:27:58.744: INFO: Pod "downwardapi-volume-9e399a66-f683-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010096597s
Oct 24 17:28:00.750: INFO: Pod "downwardapi-volume-9e399a66-f683-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01616246s
STEP: Saw pod success
Oct 24 17:28:00.750: INFO: Pod "downwardapi-volume-9e399a66-f683-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:28:00.754: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-9e399a66-f683-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 17:28:00.786: INFO: Waiting for pod downwardapi-volume-9e399a66-f683-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:28:00.790: INFO: Pod downwardapi-volume-9e399a66-f683-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:28:00.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3367" for this suite.
Oct 24 17:28:06.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:28:06.958: INFO: namespace projected-3367 deletion completed in 6.159996579s

• [SLOW TEST:10.289 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:28:06.959: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 17:28:07.015: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a45ac0d8-f683-11e9-8e41-6682758dfd28" in namespace "downward-api-2099" to be "success or failure"
Oct 24 17:28:07.020: INFO: Pod "downwardapi-volume-a45ac0d8-f683-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.592682ms
Oct 24 17:28:09.027: INFO: Pod "downwardapi-volume-a45ac0d8-f683-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011401884s
STEP: Saw pod success
Oct 24 17:28:09.027: INFO: Pod "downwardapi-volume-a45ac0d8-f683-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:28:09.031: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-a45ac0d8-f683-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 17:28:09.056: INFO: Waiting for pod downwardapi-volume-a45ac0d8-f683-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:28:09.065: INFO: Pod downwardapi-volume-a45ac0d8-f683-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:28:09.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2099" for this suite.
Oct 24 17:28:15.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:28:15.232: INFO: namespace downward-api-2099 deletion completed in 6.162577756s

• [SLOW TEST:8.274 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:28:15.233: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-6538
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 24 17:28:15.366: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 24 17:28:39.475: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.39:8080/dial?request=hostName&protocol=udp&host=10.244.1.38&port=8081&tries=1'] Namespace:pod-network-test-6538 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 17:28:39.475: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 17:28:39.638: INFO: Waiting for endpoints: map[]
Oct 24 17:28:39.643: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.39:8080/dial?request=hostName&protocol=udp&host=10.244.2.41&port=8081&tries=1'] Namespace:pod-network-test-6538 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 17:28:39.643: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 17:28:39.795: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:28:39.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6538" for this suite.
Oct 24 17:29:01.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:29:01.991: INFO: namespace pod-network-test-6538 deletion completed in 22.189820088s

• [SLOW TEST:46.759 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:29:01.992: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Oct 24 17:29:02.055: INFO: Pod name pod-release: Found 0 pods out of 1
Oct 24 17:29:07.061: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:29:08.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5380" for this suite.
Oct 24 17:29:14.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:29:14.247: INFO: namespace replication-controller-5380 deletion completed in 6.163205741s

• [SLOW TEST:12.255 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:29:14.248: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-cc76243e-f683-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume configMaps
Oct 24 17:29:14.309: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cc76dec4-f683-11e9-8e41-6682758dfd28" in namespace "projected-3480" to be "success or failure"
Oct 24 17:29:14.314: INFO: Pod "pod-projected-configmaps-cc76dec4-f683-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.951852ms
Oct 24 17:29:16.320: INFO: Pod "pod-projected-configmaps-cc76dec4-f683-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.01119489s
Oct 24 17:29:18.326: INFO: Pod "pod-projected-configmaps-cc76dec4-f683-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017378606s
STEP: Saw pod success
Oct 24 17:29:18.326: INFO: Pod "pod-projected-configmaps-cc76dec4-f683-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:29:18.331: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-projected-configmaps-cc76dec4-f683-11e9-8e41-6682758dfd28 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 17:29:18.364: INFO: Waiting for pod pod-projected-configmaps-cc76dec4-f683-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:29:18.368: INFO: Pod pod-projected-configmaps-cc76dec4-f683-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:29:18.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3480" for this suite.
Oct 24 17:29:24.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:29:24.524: INFO: namespace projected-3480 deletion completed in 6.150832593s

• [SLOW TEST:10.277 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:29:24.524: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Oct 24 17:29:24.595: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-4934,SelfLink:/api/v1/namespaces/watch-4934/configmaps/e2e-watch-test-resource-version,UID:d295d45b-f683-11e9-a6ac-005056ab7215,ResourceVersion:4610,Generation:0,CreationTimestamp:2019-10-24 17:29:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 24 17:29:24.595: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-4934,SelfLink:/api/v1/namespaces/watch-4934/configmaps/e2e-watch-test-resource-version,UID:d295d45b-f683-11e9-a6ac-005056ab7215,ResourceVersion:4611,Generation:0,CreationTimestamp:2019-10-24 17:29:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:29:24.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4934" for this suite.
Oct 24 17:29:30.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:29:30.780: INFO: namespace watch-4934 deletion completed in 6.179946641s

• [SLOW TEST:6.256 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:29:30.780: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-d6524f20-f683-11e9-8e41-6682758dfd28
STEP: Creating secret with name s-test-opt-upd-d652501e-f683-11e9-8e41-6682758dfd28
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-d6524f20-f683-11e9-8e41-6682758dfd28
STEP: Updating secret s-test-opt-upd-d652501e-f683-11e9-8e41-6682758dfd28
STEP: Creating secret with name s-test-opt-create-d652504a-f683-11e9-8e41-6682758dfd28
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:31:03.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6659" for this suite.
Oct 24 17:31:25.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:31:25.901: INFO: namespace secrets-6659 deletion completed in 22.184629459s

• [SLOW TEST:115.121 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:31:25.901: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 17:31:25.972: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1af0e6e3-f684-11e9-8e41-6682758dfd28" in namespace "downward-api-8280" to be "success or failure"
Oct 24 17:31:25.976: INFO: Pod "downwardapi-volume-1af0e6e3-f684-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 3.882405ms
Oct 24 17:31:27.981: INFO: Pod "downwardapi-volume-1af0e6e3-f684-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008866077s
STEP: Saw pod success
Oct 24 17:31:27.981: INFO: Pod "downwardapi-volume-1af0e6e3-f684-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:31:27.986: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-1af0e6e3-f684-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 17:31:28.012: INFO: Waiting for pod downwardapi-volume-1af0e6e3-f684-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:31:28.022: INFO: Pod downwardapi-volume-1af0e6e3-f684-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:31:28.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8280" for this suite.
Oct 24 17:31:34.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:31:34.196: INFO: namespace downward-api-8280 deletion completed in 6.170238242s

• [SLOW TEST:8.295 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:31:34.198: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Oct 24 17:31:34.252: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Oct 24 17:31:41.296: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:31:41.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6313" for this suite.
Oct 24 17:31:47.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:31:47.482: INFO: namespace pods-6313 deletion completed in 6.177334455s

• [SLOW TEST:13.284 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:31:47.482: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Oct 24 17:31:53.564: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-27cc5159-f684-11e9-8e41-6682758dfd28,GenerateName:,Namespace:events-7880,SelfLink:/api/v1/namespaces/events-7880/pods/send-events-27cc5159-f684-11e9-8e41-6682758dfd28,UID:27cd18cb-f684-11e9-a6ac-005056ab7215,ResourceVersion:4941,Generation:0,CreationTimestamp:2019-10-24 17:31:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 532843068,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.43/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4mwpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mwpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-4mwpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030e4950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030e4970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:31:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:31:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:31:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:31:47 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.1.43,StartTime:2019-10-24 17:31:47 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-10-24 17:31:51 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://349975675b0d2c0a518099be1956ff104f43a427cde0685dcda5a05bc51b7512}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Oct 24 17:31:55.570: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Oct 24 17:31:57.575: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:31:57.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7880" for this suite.
Oct 24 17:32:37.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:32:37.762: INFO: namespace events-7880 deletion completed in 40.171808843s

• [SLOW TEST:50.279 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:32:37.762: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 24 17:32:37.824: INFO: Waiting up to 5m0s for pod "pod-45c4d9e8-f684-11e9-8e41-6682758dfd28" in namespace "emptydir-6723" to be "success or failure"
Oct 24 17:32:37.831: INFO: Pod "pod-45c4d9e8-f684-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 6.294082ms
Oct 24 17:32:39.839: INFO: Pod "pod-45c4d9e8-f684-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014413773s
STEP: Saw pod success
Oct 24 17:32:39.839: INFO: Pod "pod-45c4d9e8-f684-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:32:39.843: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-45c4d9e8-f684-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 17:32:39.869: INFO: Waiting for pod pod-45c4d9e8-f684-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:32:39.874: INFO: Pod pod-45c4d9e8-f684-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:32:39.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6723" for this suite.
Oct 24 17:32:45.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:32:46.065: INFO: namespace emptydir-6723 deletion completed in 6.185904529s

• [SLOW TEST:8.303 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:32:46.065: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Oct 24 17:32:46.115: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-464213187 proxy --unix-socket=/tmp/kubectl-proxy-unix622174534/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:32:46.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7050" for this suite.
Oct 24 17:32:52.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:32:52.429: INFO: namespace kubectl-7050 deletion completed in 6.172379043s

• [SLOW TEST:6.364 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:32:52.429: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Oct 24 17:32:52.489: INFO: Waiting up to 5m0s for pod "pod-4e8296db-f684-11e9-8e41-6682758dfd28" in namespace "emptydir-2216" to be "success or failure"
Oct 24 17:32:52.494: INFO: Pod "pod-4e8296db-f684-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.282279ms
Oct 24 17:32:54.501: INFO: Pod "pod-4e8296db-f684-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.012628303s
Oct 24 17:32:56.508: INFO: Pod "pod-4e8296db-f684-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019608759s
STEP: Saw pod success
Oct 24 17:32:56.508: INFO: Pod "pod-4e8296db-f684-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:32:56.514: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-4e8296db-f684-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 17:32:56.547: INFO: Waiting for pod pod-4e8296db-f684-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:32:56.550: INFO: Pod pod-4e8296db-f684-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:32:56.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2216" for this suite.
Oct 24 17:33:02.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:33:02.761: INFO: namespace emptydir-2216 deletion completed in 6.205121523s

• [SLOW TEST:10.331 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:33:02.761: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 17:33:08.874: INFO: Waiting up to 5m0s for pod "client-envvars-584702c2-f684-11e9-8e41-6682758dfd28" in namespace "pods-906" to be "success or failure"
Oct 24 17:33:08.882: INFO: Pod "client-envvars-584702c2-f684-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 8.330163ms
Oct 24 17:33:10.887: INFO: Pod "client-envvars-584702c2-f684-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013232253s
Oct 24 17:33:12.893: INFO: Pod "client-envvars-584702c2-f684-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019086881s
STEP: Saw pod success
Oct 24 17:33:12.893: INFO: Pod "client-envvars-584702c2-f684-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:33:12.897: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod client-envvars-584702c2-f684-11e9-8e41-6682758dfd28 container env3cont: <nil>
STEP: delete the pod
Oct 24 17:33:12.927: INFO: Waiting for pod client-envvars-584702c2-f684-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:33:12.932: INFO: Pod client-envvars-584702c2-f684-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:33:12.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-906" for this suite.
Oct 24 17:34:00.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:34:01.106: INFO: namespace pods-906 deletion completed in 48.168972138s

• [SLOW TEST:58.345 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:34:01.106: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1024 17:34:11.196969      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 24 17:34:11.197: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:34:11.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-163" for this suite.
Oct 24 17:34:17.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:34:17.371: INFO: namespace gc-163 deletion completed in 6.169074301s

• [SLOW TEST:16.266 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:34:17.372: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-81235adb-f684-11e9-8e41-6682758dfd28
Oct 24 17:34:17.430: INFO: Pod name my-hostname-basic-81235adb-f684-11e9-8e41-6682758dfd28: Found 0 pods out of 1
Oct 24 17:34:22.436: INFO: Pod name my-hostname-basic-81235adb-f684-11e9-8e41-6682758dfd28: Found 1 pods out of 1
Oct 24 17:34:22.436: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-81235adb-f684-11e9-8e41-6682758dfd28" are running
Oct 24 17:34:22.440: INFO: Pod "my-hostname-basic-81235adb-f684-11e9-8e41-6682758dfd28-ptfkj" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-24 17:34:17 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-24 17:34:18 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-24 17:34:18 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-24 17:34:17 +0000 UTC Reason: Message:}])
Oct 24 17:34:22.440: INFO: Trying to dial the pod
Oct 24 17:34:27.455: INFO: Controller my-hostname-basic-81235adb-f684-11e9-8e41-6682758dfd28: Got expected result from replica 1 [my-hostname-basic-81235adb-f684-11e9-8e41-6682758dfd28-ptfkj]: "my-hostname-basic-81235adb-f684-11e9-8e41-6682758dfd28-ptfkj", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:34:27.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9577" for this suite.
Oct 24 17:34:33.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:34:33.615: INFO: namespace replication-controller-9577 deletion completed in 6.154833895s

• [SLOW TEST:16.243 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:34:33.616: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 17:34:33.670: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8ad18682-f684-11e9-8e41-6682758dfd28" in namespace "downward-api-7776" to be "success or failure"
Oct 24 17:34:33.674: INFO: Pod "downwardapi-volume-8ad18682-f684-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.260977ms
Oct 24 17:34:35.680: INFO: Pod "downwardapi-volume-8ad18682-f684-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.010274145s
Oct 24 17:34:37.686: INFO: Pod "downwardapi-volume-8ad18682-f684-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016683447s
STEP: Saw pod success
Oct 24 17:34:37.686: INFO: Pod "downwardapi-volume-8ad18682-f684-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:34:37.692: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-8ad18682-f684-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 17:34:37.729: INFO: Waiting for pod downwardapi-volume-8ad18682-f684-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:34:37.733: INFO: Pod downwardapi-volume-8ad18682-f684-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:34:37.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7776" for this suite.
Oct 24 17:34:43.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:34:43.913: INFO: namespace downward-api-7776 deletion completed in 6.175293046s

• [SLOW TEST:10.297 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:34:43.913: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Oct 24 17:34:43.976: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9103,SelfLink:/api/v1/namespaces/watch-9103/configmaps/e2e-watch-test-watch-closed,UID:90f5cc1f-f684-11e9-a6ac-005056ab7215,ResourceVersion:5434,Generation:0,CreationTimestamp:2019-10-24 17:34:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 24 17:34:43.976: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9103,SelfLink:/api/v1/namespaces/watch-9103/configmaps/e2e-watch-test-watch-closed,UID:90f5cc1f-f684-11e9-a6ac-005056ab7215,ResourceVersion:5435,Generation:0,CreationTimestamp:2019-10-24 17:34:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Oct 24 17:34:43.994: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9103,SelfLink:/api/v1/namespaces/watch-9103/configmaps/e2e-watch-test-watch-closed,UID:90f5cc1f-f684-11e9-a6ac-005056ab7215,ResourceVersion:5436,Generation:0,CreationTimestamp:2019-10-24 17:34:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 24 17:34:43.995: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9103,SelfLink:/api/v1/namespaces/watch-9103/configmaps/e2e-watch-test-watch-closed,UID:90f5cc1f-f684-11e9-a6ac-005056ab7215,ResourceVersion:5437,Generation:0,CreationTimestamp:2019-10-24 17:34:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:34:43.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9103" for this suite.
Oct 24 17:34:50.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:34:50.296: INFO: namespace watch-9103 deletion completed in 6.296328017s

• [SLOW TEST:6.382 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:34:50.296: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-94c3238f-f684-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume secrets
Oct 24 17:34:50.359: INFO: Waiting up to 5m0s for pod "pod-secrets-94c3f9db-f684-11e9-8e41-6682758dfd28" in namespace "secrets-8026" to be "success or failure"
Oct 24 17:34:50.363: INFO: Pod "pod-secrets-94c3f9db-f684-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.080791ms
Oct 24 17:34:52.369: INFO: Pod "pod-secrets-94c3f9db-f684-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010073529s
STEP: Saw pod success
Oct 24 17:34:52.369: INFO: Pod "pod-secrets-94c3f9db-f684-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:34:52.373: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-secrets-94c3f9db-f684-11e9-8e41-6682758dfd28 container secret-volume-test: <nil>
STEP: delete the pod
Oct 24 17:34:52.407: INFO: Waiting for pod pod-secrets-94c3f9db-f684-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:34:52.410: INFO: Pod pod-secrets-94c3f9db-f684-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:34:52.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8026" for this suite.
Oct 24 17:34:58.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:34:58.587: INFO: namespace secrets-8026 deletion completed in 6.170924186s

• [SLOW TEST:8.291 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:34:58.588: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Oct 24 17:34:58.680: INFO: Waiting up to 5m0s for pod "client-containers-99b9ad64-f684-11e9-8e41-6682758dfd28" in namespace "containers-6813" to be "success or failure"
Oct 24 17:34:58.686: INFO: Pod "client-containers-99b9ad64-f684-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 6.041256ms
Oct 24 17:35:00.692: INFO: Pod "client-containers-99b9ad64-f684-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012237312s
STEP: Saw pod success
Oct 24 17:35:00.692: INFO: Pod "client-containers-99b9ad64-f684-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:35:00.696: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod client-containers-99b9ad64-f684-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 17:35:00.722: INFO: Waiting for pod client-containers-99b9ad64-f684-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:35:00.743: INFO: Pod client-containers-99b9ad64-f684-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:35:00.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6813" for this suite.
Oct 24 17:35:06.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:35:06.924: INFO: namespace containers-6813 deletion completed in 6.17663943s

• [SLOW TEST:8.337 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:35:06.925: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-9ead404c-f684-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume configMaps
Oct 24 17:35:06.992: INFO: Waiting up to 5m0s for pod "pod-configmaps-9eae2037-f684-11e9-8e41-6682758dfd28" in namespace "configmap-8788" to be "success or failure"
Oct 24 17:35:06.997: INFO: Pod "pod-configmaps-9eae2037-f684-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.325259ms
Oct 24 17:35:09.003: INFO: Pod "pod-configmaps-9eae2037-f684-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010513864s
STEP: Saw pod success
Oct 24 17:35:09.003: INFO: Pod "pod-configmaps-9eae2037-f684-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:35:09.007: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-9eae2037-f684-11e9-8e41-6682758dfd28 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 17:35:09.038: INFO: Waiting for pod pod-configmaps-9eae2037-f684-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:35:09.042: INFO: Pod pod-configmaps-9eae2037-f684-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:35:09.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8788" for this suite.
Oct 24 17:35:15.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:35:15.228: INFO: namespace configmap-8788 deletion completed in 6.180577763s

• [SLOW TEST:8.303 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:35:15.228: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 24 17:35:15.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7780'
Oct 24 17:35:15.597: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 24 17:35:15.597: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Oct 24 17:35:15.611: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-7z996]
Oct 24 17:35:15.612: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-7z996" in namespace "kubectl-7780" to be "running and ready"
Oct 24 17:35:15.617: INFO: Pod "e2e-test-nginx-rc-7z996": Phase="Pending", Reason="", readiness=false. Elapsed: 5.194227ms
Oct 24 17:35:17.622: INFO: Pod "e2e-test-nginx-rc-7z996": Phase="Running", Reason="", readiness=true. Elapsed: 2.010814699s
Oct 24 17:35:17.622: INFO: Pod "e2e-test-nginx-rc-7z996" satisfied condition "running and ready"
Oct 24 17:35:17.623: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-7z996]
Oct 24 17:35:17.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 logs rc/e2e-test-nginx-rc --namespace=kubectl-7780'
Oct 24 17:35:17.830: INFO: stderr: ""
Oct 24 17:35:17.830: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1425
Oct 24 17:35:17.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 delete rc e2e-test-nginx-rc --namespace=kubectl-7780'
Oct 24 17:35:18.004: INFO: stderr: ""
Oct 24 17:35:18.004: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:35:18.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7780" for this suite.
Oct 24 17:35:40.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:35:40.169: INFO: namespace kubectl-7780 deletion completed in 22.159105006s

• [SLOW TEST:24.941 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:35:40.170: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 24 17:35:44.266: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 24 17:35:44.270: INFO: Pod pod-with-prestop-http-hook still exists
Oct 24 17:35:46.271: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 24 17:35:46.277: INFO: Pod pod-with-prestop-http-hook still exists
Oct 24 17:35:48.270: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 24 17:35:48.276: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:35:48.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4392" for this suite.
Oct 24 17:36:10.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:36:10.458: INFO: namespace container-lifecycle-hook-4392 deletion completed in 22.162117696s

• [SLOW TEST:30.288 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:36:10.458: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-c48abf87-f684-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume configMaps
Oct 24 17:36:10.519: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c48b7917-f684-11e9-8e41-6682758dfd28" in namespace "projected-2771" to be "success or failure"
Oct 24 17:36:10.523: INFO: Pod "pod-projected-configmaps-c48b7917-f684-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 3.824949ms
Oct 24 17:36:12.529: INFO: Pod "pod-projected-configmaps-c48b7917-f684-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01000973s
STEP: Saw pod success
Oct 24 17:36:12.529: INFO: Pod "pod-projected-configmaps-c48b7917-f684-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:36:12.533: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-configmaps-c48b7917-f684-11e9-8e41-6682758dfd28 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 17:36:12.565: INFO: Waiting for pod pod-projected-configmaps-c48b7917-f684-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:36:12.570: INFO: Pod pod-projected-configmaps-c48b7917-f684-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:36:12.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2771" for this suite.
Oct 24 17:36:18.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:36:18.748: INFO: namespace projected-2771 deletion completed in 6.173339437s

• [SLOW TEST:8.289 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:36:18.748: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1024 17:36:24.843831      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 24 17:36:24.843: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:36:24.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3965" for this suite.
Oct 24 17:36:30.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:36:31.020: INFO: namespace gc-3965 deletion completed in 6.168733072s

• [SLOW TEST:12.272 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:36:31.021: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-1648
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1648 to expose endpoints map[]
Oct 24 17:36:31.084: INFO: Get endpoints failed (5.116206ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Oct 24 17:36:32.092: INFO: successfully validated that service endpoint-test2 in namespace services-1648 exposes endpoints map[] (1.013244697s elapsed)
STEP: Creating pod pod1 in namespace services-1648
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1648 to expose endpoints map[pod1:[80]]
Oct 24 17:36:34.136: INFO: successfully validated that service endpoint-test2 in namespace services-1648 exposes endpoints map[pod1:[80]] (2.031693449s elapsed)
STEP: Creating pod pod2 in namespace services-1648
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1648 to expose endpoints map[pod1:[80] pod2:[80]]
Oct 24 17:36:36.195: INFO: successfully validated that service endpoint-test2 in namespace services-1648 exposes endpoints map[pod1:[80] pod2:[80]] (2.05009154s elapsed)
STEP: Deleting pod pod1 in namespace services-1648
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1648 to expose endpoints map[pod2:[80]]
Oct 24 17:36:37.231: INFO: successfully validated that service endpoint-test2 in namespace services-1648 exposes endpoints map[pod2:[80]] (1.029181504s elapsed)
STEP: Deleting pod pod2 in namespace services-1648
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1648 to expose endpoints map[]
Oct 24 17:36:38.251: INFO: successfully validated that service endpoint-test2 in namespace services-1648 exposes endpoints map[] (1.012922264s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:36:38.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1648" for this suite.
Oct 24 17:37:00.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:37:00.458: INFO: namespace services-1648 deletion completed in 22.178157435s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:29.437 seconds]
[sig-network] Services
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:37:00.458: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:37:02.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7013" for this suite.
Oct 24 17:37:08.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:37:08.742: INFO: namespace emptydir-wrapper-7013 deletion completed in 6.164788501s

• [SLOW TEST:8.284 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:37:08.743: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1521
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 24 17:37:08.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-7198'
Oct 24 17:37:09.000: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 24 17:37:09.000: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1526
Oct 24 17:37:11.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 delete deployment e2e-test-nginx-deployment --namespace=kubectl-7198'
Oct 24 17:37:11.205: INFO: stderr: ""
Oct 24 17:37:11.205: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:37:11.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7198" for this suite.
Oct 24 17:37:33.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:37:33.379: INFO: namespace kubectl-7198 deletion completed in 22.169666393s

• [SLOW TEST:24.637 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:37:33.380: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 17:37:33.427: INFO: Creating ReplicaSet my-hostname-basic-f5f7acde-f684-11e9-8e41-6682758dfd28
Oct 24 17:37:33.440: INFO: Pod name my-hostname-basic-f5f7acde-f684-11e9-8e41-6682758dfd28: Found 0 pods out of 1
Oct 24 17:37:38.446: INFO: Pod name my-hostname-basic-f5f7acde-f684-11e9-8e41-6682758dfd28: Found 1 pods out of 1
Oct 24 17:37:38.447: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-f5f7acde-f684-11e9-8e41-6682758dfd28" is running
Oct 24 17:37:38.451: INFO: Pod "my-hostname-basic-f5f7acde-f684-11e9-8e41-6682758dfd28-rv76q" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-24 17:37:33 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-24 17:37:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-24 17:37:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-24 17:37:33 +0000 UTC Reason: Message:}])
Oct 24 17:37:38.451: INFO: Trying to dial the pod
Oct 24 17:37:43.469: INFO: Controller my-hostname-basic-f5f7acde-f684-11e9-8e41-6682758dfd28: Got expected result from replica 1 [my-hostname-basic-f5f7acde-f684-11e9-8e41-6682758dfd28-rv76q]: "my-hostname-basic-f5f7acde-f684-11e9-8e41-6682758dfd28-rv76q", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:37:43.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9767" for this suite.
Oct 24 17:37:49.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:37:49.640: INFO: namespace replicaset-9767 deletion completed in 6.165710404s

• [SLOW TEST:16.260 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:37:49.640: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 24 17:37:49.694: INFO: Waiting up to 5m0s for pod "pod-ffa89083-f684-11e9-8e41-6682758dfd28" in namespace "emptydir-8984" to be "success or failure"
Oct 24 17:37:49.707: INFO: Pod "pod-ffa89083-f684-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 13.170218ms
Oct 24 17:37:51.713: INFO: Pod "pod-ffa89083-f684-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018820499s
STEP: Saw pod success
Oct 24 17:37:51.713: INFO: Pod "pod-ffa89083-f684-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:37:51.717: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-ffa89083-f684-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 17:37:51.748: INFO: Waiting for pod pod-ffa89083-f684-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:37:51.752: INFO: Pod pod-ffa89083-f684-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:37:51.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8984" for this suite.
Oct 24 17:37:57.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:37:57.956: INFO: namespace emptydir-8984 deletion completed in 6.197561157s

• [SLOW TEST:8.315 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:37:57.956: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Oct 24 17:37:58.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 create -f - --namespace=kubectl-5965'
Oct 24 17:37:58.342: INFO: stderr: ""
Oct 24 17:37:58.342: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 24 17:37:58.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5965'
Oct 24 17:37:58.524: INFO: stderr: ""
Oct 24 17:37:58.524: INFO: stdout: "update-demo-nautilus-m8wbd update-demo-nautilus-sdf8p "
Oct 24 17:37:58.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-m8wbd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5965'
Oct 24 17:37:58.697: INFO: stderr: ""
Oct 24 17:37:58.697: INFO: stdout: ""
Oct 24 17:37:58.697: INFO: update-demo-nautilus-m8wbd is created but not running
Oct 24 17:38:03.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5965'
Oct 24 17:38:03.887: INFO: stderr: ""
Oct 24 17:38:03.887: INFO: stdout: "update-demo-nautilus-m8wbd update-demo-nautilus-sdf8p "
Oct 24 17:38:03.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-m8wbd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5965'
Oct 24 17:38:04.053: INFO: stderr: ""
Oct 24 17:38:04.053: INFO: stdout: "true"
Oct 24 17:38:04.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-m8wbd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5965'
Oct 24 17:38:04.233: INFO: stderr: ""
Oct 24 17:38:04.233: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 17:38:04.233: INFO: validating pod update-demo-nautilus-m8wbd
Oct 24 17:38:04.242: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 17:38:04.242: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 17:38:04.242: INFO: update-demo-nautilus-m8wbd is verified up and running
Oct 24 17:38:04.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-sdf8p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5965'
Oct 24 17:38:04.419: INFO: stderr: ""
Oct 24 17:38:04.419: INFO: stdout: "true"
Oct 24 17:38:04.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-sdf8p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5965'
Oct 24 17:38:04.597: INFO: stderr: ""
Oct 24 17:38:04.597: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 17:38:04.597: INFO: validating pod update-demo-nautilus-sdf8p
Oct 24 17:38:04.605: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 17:38:04.606: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 17:38:04.606: INFO: update-demo-nautilus-sdf8p is verified up and running
STEP: using delete to clean up resources
Oct 24 17:38:04.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 delete --grace-period=0 --force -f - --namespace=kubectl-5965'
Oct 24 17:38:04.786: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 17:38:04.786: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 24 17:38:04.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5965'
Oct 24 17:38:04.995: INFO: stderr: "No resources found.\n"
Oct 24 17:38:04.995: INFO: stdout: ""
Oct 24 17:38:04.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods -l name=update-demo --namespace=kubectl-5965 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 24 17:38:05.184: INFO: stderr: ""
Oct 24 17:38:05.184: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:38:05.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5965" for this suite.
Oct 24 17:38:27.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:38:27.366: INFO: namespace kubectl-5965 deletion completed in 22.175370317s

• [SLOW TEST:29.410 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:38:27.367: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 24 17:38:27.420: INFO: Waiting up to 5m0s for pod "pod-16252254-f685-11e9-8e41-6682758dfd28" in namespace "emptydir-1342" to be "success or failure"
Oct 24 17:38:27.430: INFO: Pod "pod-16252254-f685-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 10.372741ms
Oct 24 17:38:29.437: INFO: Pod "pod-16252254-f685-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016808606s
STEP: Saw pod success
Oct 24 17:38:29.437: INFO: Pod "pod-16252254-f685-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:38:29.440: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-16252254-f685-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 17:38:29.470: INFO: Waiting for pod pod-16252254-f685-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:38:29.474: INFO: Pod pod-16252254-f685-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:38:29.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1342" for this suite.
Oct 24 17:38:35.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:38:35.653: INFO: namespace emptydir-1342 deletion completed in 6.173366351s

• [SLOW TEST:8.286 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:38:35.653: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct 24 17:38:35.704: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 24 17:38:35.714: INFO: Waiting for terminating namespaces to be deleted...
Oct 24 17:38:35.718: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm40.mip.storage.hpecorp.net before test
Oct 24 17:38:35.727: INFO: kubedirector-fsmount-r4npk from kube-system started at 2019-10-24 17:11:25 +0000 UTC (1 container statuses recorded)
Oct 24 17:38:35.727: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 24 17:38:35.727: INFO: sonobuoy-e2e-job-b8b444507c5f4f4c from sonobuoy started at 2019-10-24 17:16:49 +0000 UTC (2 container statuses recorded)
Oct 24 17:38:35.727: INFO: 	Container e2e ready: true, restart count 0
Oct 24 17:38:35.727: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 17:38:35.727: INFO: sonobuoy-systemd-logs-daemon-set-db3f66083eff4fdd-wtw9h from sonobuoy started at 2019-10-24 17:16:49 +0000 UTC (2 container statuses recorded)
Oct 24 17:38:35.727: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 17:38:35.727: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 17:38:35.727: INFO: canal-llqpj from kube-system started at 2019-10-24 17:10:17 +0000 UTC (3 container statuses recorded)
Oct 24 17:38:35.727: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 17:38:35.727: INFO: 	Container install-cni ready: true, restart count 0
Oct 24 17:38:35.727: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 24 17:38:35.727: INFO: kube-proxy-cvhqm from kube-system started at 2019-10-24 17:09:39 +0000 UTC (1 container statuses recorded)
Oct 24 17:38:35.727: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 24 17:38:35.727: INFO: kubedirector-5b9c586b87-256s7 from kube-system started at 2019-10-24 17:10:11 +0000 UTC (1 container statuses recorded)
Oct 24 17:38:35.727: INFO: 	Container kubedirector ready: true, restart count 0
Oct 24 17:38:35.727: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm41.mip.storage.hpecorp.net before test
Oct 24 17:38:35.738: INFO: kube-state-metrics-69cb568659-hmp7h from kube-system started at 2019-10-24 17:10:07 +0000 UTC (1 container statuses recorded)
Oct 24 17:38:35.738: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 24 17:38:35.738: INFO: canal-jnk4h from kube-system started at 2019-10-24 17:10:17 +0000 UTC (3 container statuses recorded)
Oct 24 17:38:35.739: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 17:38:35.739: INFO: 	Container install-cni ready: true, restart count 0
Oct 24 17:38:35.739: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 24 17:38:35.739: INFO: kube-proxy-vgccc from kube-system started at 2019-10-24 17:09:35 +0000 UTC (1 container statuses recorded)
Oct 24 17:38:35.739: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 24 17:38:35.739: INFO: sonobuoy-systemd-logs-daemon-set-db3f66083eff4fdd-scddt from sonobuoy started at 2019-10-24 17:16:49 +0000 UTC (2 container statuses recorded)
Oct 24 17:38:35.739: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 17:38:35.739: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 17:38:35.739: INFO: kubedirector-fsmount-rnkvz from kube-system started at 2019-10-24 17:11:25 +0000 UTC (1 container statuses recorded)
Oct 24 17:38:35.739: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 24 17:38:35.739: INFO: sonobuoy from sonobuoy started at 2019-10-24 17:16:37 +0000 UTC (1 container statuses recorded)
Oct 24 17:38:35.739: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d0a5eef9fce1a7], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:38:36.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8063" for this suite.
Oct 24 17:38:42.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:38:42.946: INFO: namespace sched-pred-8063 deletion completed in 6.168600388s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.293 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:38:42.946: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1384
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 24 17:38:42.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2431'
Oct 24 17:38:43.184: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 24 17:38:43.185: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1390
Oct 24 17:38:45.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 delete deployment e2e-test-nginx-deployment --namespace=kubectl-2431'
Oct 24 17:38:45.379: INFO: stderr: ""
Oct 24 17:38:45.379: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:38:45.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2431" for this suite.
Oct 24 17:38:51.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:38:51.563: INFO: namespace kubectl-2431 deletion completed in 6.175607092s

• [SLOW TEST:8.617 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:38:51.563: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:38:51.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4204" for this suite.
Oct 24 17:38:57.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:38:57.834: INFO: namespace kubelet-test-4204 deletion completed in 6.171992708s

• [SLOW TEST:6.271 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:38:57.835: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct 24 17:38:57.887: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:39:01.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4970" for this suite.
Oct 24 17:39:07.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:39:07.484: INFO: namespace init-container-4970 deletion completed in 6.175635136s

• [SLOW TEST:9.649 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:39:07.485: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-3721
Oct 24 17:39:13.544: INFO: Started pod liveness-http in namespace container-probe-3721
STEP: checking the pod's current state and verifying that restartCount is present
Oct 24 17:39:13.549: INFO: Initial restart count of pod liveness-http is 0
Oct 24 17:39:27.593: INFO: Restart count of pod container-probe-3721/liveness-http is now 1 (14.044027019s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:39:27.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3721" for this suite.
Oct 24 17:39:33.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:39:33.774: INFO: namespace container-probe-3721 deletion completed in 6.161431986s

• [SLOW TEST:26.289 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:39:33.774: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 24 17:39:33.870: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:39:33.873: INFO: Number of nodes with available pods: 0
Oct 24 17:39:33.873: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:39:34.879: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:39:34.884: INFO: Number of nodes with available pods: 0
Oct 24 17:39:34.884: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:39:35.879: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:39:35.883: INFO: Number of nodes with available pods: 2
Oct 24 17:39:35.883: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Oct 24 17:39:35.903: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:39:35.914: INFO: Number of nodes with available pods: 1
Oct 24 17:39:35.914: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:39:36.920: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:39:36.924: INFO: Number of nodes with available pods: 1
Oct 24 17:39:36.924: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:39:37.920: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:39:37.924: INFO: Number of nodes with available pods: 2
Oct 24 17:39:37.924: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1542, will wait for the garbage collector to delete the pods
Oct 24 17:39:37.997: INFO: Deleting DaemonSet.extensions daemon-set took: 7.919951ms
Oct 24 17:39:38.397: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.257474ms
Oct 24 17:39:49.202: INFO: Number of nodes with available pods: 0
Oct 24 17:39:49.202: INFO: Number of running nodes: 0, number of available pods: 0
Oct 24 17:39:49.209: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1542/daemonsets","resourceVersion":"6789"},"items":null}

Oct 24 17:39:49.213: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1542/pods","resourceVersion":"6789"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:39:49.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1542" for this suite.
Oct 24 17:39:55.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:39:55.388: INFO: namespace daemonsets-1542 deletion completed in 6.157278186s

• [SLOW TEST:21.614 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:39:55.389: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 24 17:39:55.443: INFO: Waiting up to 5m0s for pod "pod-4a9c598c-f685-11e9-8e41-6682758dfd28" in namespace "emptydir-526" to be "success or failure"
Oct 24 17:39:55.448: INFO: Pod "pod-4a9c598c-f685-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.426229ms
Oct 24 17:39:57.453: INFO: Pod "pod-4a9c598c-f685-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010011919s
Oct 24 17:39:59.460: INFO: Pod "pod-4a9c598c-f685-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016437712s
STEP: Saw pod success
Oct 24 17:39:59.460: INFO: Pod "pod-4a9c598c-f685-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:39:59.463: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-4a9c598c-f685-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 17:39:59.486: INFO: Waiting for pod pod-4a9c598c-f685-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:39:59.489: INFO: Pod pod-4a9c598c-f685-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:39:59.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-526" for this suite.
Oct 24 17:40:05.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:40:05.668: INFO: namespace emptydir-526 deletion completed in 6.174987498s

• [SLOW TEST:10.280 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:40:05.669: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-50bcb42d-f685-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume secrets
Oct 24 17:40:05.764: INFO: Waiting up to 5m0s for pod "pod-secrets-50c354f6-f685-11e9-8e41-6682758dfd28" in namespace "secrets-1654" to be "success or failure"
Oct 24 17:40:05.768: INFO: Pod "pod-secrets-50c354f6-f685-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 3.963055ms
Oct 24 17:40:07.777: INFO: Pod "pod-secrets-50c354f6-f685-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013413967s
STEP: Saw pod success
Oct 24 17:40:07.778: INFO: Pod "pod-secrets-50c354f6-f685-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:40:07.792: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-secrets-50c354f6-f685-11e9-8e41-6682758dfd28 container secret-volume-test: <nil>
STEP: delete the pod
Oct 24 17:40:07.888: INFO: Waiting for pod pod-secrets-50c354f6-f685-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:40:07.891: INFO: Pod pod-secrets-50c354f6-f685-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:40:07.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1654" for this suite.
Oct 24 17:40:13.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:40:14.075: INFO: namespace secrets-1654 deletion completed in 6.180047158s
STEP: Destroying namespace "secret-namespace-59" for this suite.
Oct 24 17:40:20.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:40:20.250: INFO: namespace secret-namespace-59 deletion completed in 6.174671945s

• [SLOW TEST:14.581 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:40:20.250: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 24 17:40:20.301: INFO: Waiting up to 5m0s for pod "pod-596d43c5-f685-11e9-8e41-6682758dfd28" in namespace "emptydir-9430" to be "success or failure"
Oct 24 17:40:20.305: INFO: Pod "pod-596d43c5-f685-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.292848ms
Oct 24 17:40:22.311: INFO: Pod "pod-596d43c5-f685-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.010312187s
Oct 24 17:40:24.317: INFO: Pod "pod-596d43c5-f685-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015691086s
STEP: Saw pod success
Oct 24 17:40:24.317: INFO: Pod "pod-596d43c5-f685-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:40:24.325: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-596d43c5-f685-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 17:40:24.354: INFO: Waiting for pod pod-596d43c5-f685-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:40:24.357: INFO: Pod pod-596d43c5-f685-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:40:24.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9430" for this suite.
Oct 24 17:40:30.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:40:30.512: INFO: namespace emptydir-9430 deletion completed in 6.150019732s

• [SLOW TEST:10.261 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:40:30.512: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-5f8ae669-f685-11e9-8e41-6682758dfd28
STEP: Creating secret with name s-test-opt-upd-5f8ae6e3-f685-11e9-8e41-6682758dfd28
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-5f8ae669-f685-11e9-8e41-6682758dfd28
STEP: Updating secret s-test-opt-upd-5f8ae6e3-f685-11e9-8e41-6682758dfd28
STEP: Creating secret with name s-test-opt-create-5f8ae70f-f685-11e9-8e41-6682758dfd28
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:40:34.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-524" for this suite.
Oct 24 17:40:56.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:40:56.837: INFO: namespace projected-524 deletion completed in 22.15578498s

• [SLOW TEST:26.325 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:40:56.837: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-6f3d03a3-f685-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume configMaps
Oct 24 17:40:56.906: INFO: Waiting up to 5m0s for pod "pod-configmaps-6f3de3a6-f685-11e9-8e41-6682758dfd28" in namespace "configmap-8295" to be "success or failure"
Oct 24 17:40:56.921: INFO: Pod "pod-configmaps-6f3de3a6-f685-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 15.315617ms
Oct 24 17:40:58.927: INFO: Pod "pod-configmaps-6f3de3a6-f685-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02103773s
Oct 24 17:41:00.932: INFO: Pod "pod-configmaps-6f3de3a6-f685-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026393169s
STEP: Saw pod success
Oct 24 17:41:00.933: INFO: Pod "pod-configmaps-6f3de3a6-f685-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:41:00.936: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-6f3de3a6-f685-11e9-8e41-6682758dfd28 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 17:41:00.963: INFO: Waiting for pod pod-configmaps-6f3de3a6-f685-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:41:00.968: INFO: Pod pod-configmaps-6f3de3a6-f685-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:41:00.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8295" for this suite.
Oct 24 17:41:06.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:41:07.131: INFO: namespace configmap-8295 deletion completed in 6.156980764s

• [SLOW TEST:10.294 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:41:07.131: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct 24 17:41:07.176: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 24 17:41:07.184: INFO: Waiting for terminating namespaces to be deleted...
Oct 24 17:41:07.187: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm40.mip.storage.hpecorp.net before test
Oct 24 17:41:07.196: INFO: kubedirector-fsmount-r4npk from kube-system started at 2019-10-24 17:11:25 +0000 UTC (1 container statuses recorded)
Oct 24 17:41:07.196: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 24 17:41:07.196: INFO: sonobuoy-e2e-job-b8b444507c5f4f4c from sonobuoy started at 2019-10-24 17:16:49 +0000 UTC (2 container statuses recorded)
Oct 24 17:41:07.196: INFO: 	Container e2e ready: true, restart count 0
Oct 24 17:41:07.196: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 17:41:07.196: INFO: sonobuoy-systemd-logs-daemon-set-db3f66083eff4fdd-wtw9h from sonobuoy started at 2019-10-24 17:16:49 +0000 UTC (2 container statuses recorded)
Oct 24 17:41:07.196: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 17:41:07.196: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 17:41:07.196: INFO: kube-proxy-cvhqm from kube-system started at 2019-10-24 17:09:39 +0000 UTC (1 container statuses recorded)
Oct 24 17:41:07.196: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 24 17:41:07.196: INFO: kubedirector-5b9c586b87-256s7 from kube-system started at 2019-10-24 17:10:11 +0000 UTC (1 container statuses recorded)
Oct 24 17:41:07.196: INFO: 	Container kubedirector ready: true, restart count 0
Oct 24 17:41:07.196: INFO: canal-llqpj from kube-system started at 2019-10-24 17:10:17 +0000 UTC (3 container statuses recorded)
Oct 24 17:41:07.196: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 17:41:07.196: INFO: 	Container install-cni ready: true, restart count 0
Oct 24 17:41:07.196: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 24 17:41:07.196: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm41.mip.storage.hpecorp.net before test
Oct 24 17:41:07.205: INFO: kube-proxy-vgccc from kube-system started at 2019-10-24 17:09:35 +0000 UTC (1 container statuses recorded)
Oct 24 17:41:07.205: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 24 17:41:07.205: INFO: sonobuoy-systemd-logs-daemon-set-db3f66083eff4fdd-scddt from sonobuoy started at 2019-10-24 17:16:49 +0000 UTC (2 container statuses recorded)
Oct 24 17:41:07.205: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 17:41:07.205: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 17:41:07.205: INFO: kubedirector-fsmount-rnkvz from kube-system started at 2019-10-24 17:11:25 +0000 UTC (1 container statuses recorded)
Oct 24 17:41:07.205: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 24 17:41:07.205: INFO: sonobuoy from sonobuoy started at 2019-10-24 17:16:37 +0000 UTC (1 container statuses recorded)
Oct 24 17:41:07.205: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 24 17:41:07.205: INFO: kube-state-metrics-69cb568659-hmp7h from kube-system started at 2019-10-24 17:10:07 +0000 UTC (1 container statuses recorded)
Oct 24 17:41:07.205: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 24 17:41:07.205: INFO: canal-jnk4h from kube-system started at 2019-10-24 17:10:17 +0000 UTC (3 container statuses recorded)
Oct 24 17:41:07.205: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 17:41:07.205: INFO: 	Container install-cni ready: true, restart count 0
Oct 24 17:41:07.205: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node mip-bd-vm40.mip.storage.hpecorp.net
STEP: verifying the node has the label node mip-bd-vm41.mip.storage.hpecorp.net
Oct 24 17:41:07.248: INFO: Pod canal-jnk4h requesting resource cpu=250m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 24 17:41:07.248: INFO: Pod canal-llqpj requesting resource cpu=250m on Node mip-bd-vm40.mip.storage.hpecorp.net
Oct 24 17:41:07.248: INFO: Pod kube-proxy-cvhqm requesting resource cpu=0m on Node mip-bd-vm40.mip.storage.hpecorp.net
Oct 24 17:41:07.248: INFO: Pod kube-proxy-vgccc requesting resource cpu=0m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 24 17:41:07.248: INFO: Pod kube-state-metrics-69cb568659-hmp7h requesting resource cpu=0m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 24 17:41:07.248: INFO: Pod kubedirector-5b9c586b87-256s7 requesting resource cpu=0m on Node mip-bd-vm40.mip.storage.hpecorp.net
Oct 24 17:41:07.248: INFO: Pod kubedirector-fsmount-r4npk requesting resource cpu=250m on Node mip-bd-vm40.mip.storage.hpecorp.net
Oct 24 17:41:07.248: INFO: Pod kubedirector-fsmount-rnkvz requesting resource cpu=250m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 24 17:41:07.248: INFO: Pod sonobuoy requesting resource cpu=0m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 24 17:41:07.248: INFO: Pod sonobuoy-e2e-job-b8b444507c5f4f4c requesting resource cpu=0m on Node mip-bd-vm40.mip.storage.hpecorp.net
Oct 24 17:41:07.248: INFO: Pod sonobuoy-systemd-logs-daemon-set-db3f66083eff4fdd-scddt requesting resource cpu=0m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 24 17:41:07.248: INFO: Pod sonobuoy-systemd-logs-daemon-set-db3f66083eff4fdd-wtw9h requesting resource cpu=0m on Node mip-bd-vm40.mip.storage.hpecorp.net
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-756a2848-f685-11e9-8e41-6682758dfd28.15d0a6123ff366d3], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3556/filler-pod-756a2848-f685-11e9-8e41-6682758dfd28 to mip-bd-vm41.mip.storage.hpecorp.net]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-756a2848-f685-11e9-8e41-6682758dfd28.15d0a6126d76256c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-756a2848-f685-11e9-8e41-6682758dfd28.15d0a6126f7824d6], Reason = [Created], Message = [Created container filler-pod-756a2848-f685-11e9-8e41-6682758dfd28]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-756a2848-f685-11e9-8e41-6682758dfd28.15d0a61279fe962a], Reason = [Started], Message = [Started container filler-pod-756a2848-f685-11e9-8e41-6682758dfd28]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-756b7e05-f685-11e9-8e41-6682758dfd28.15d0a61240307d0f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3556/filler-pod-756b7e05-f685-11e9-8e41-6682758dfd28 to mip-bd-vm40.mip.storage.hpecorp.net]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-756b7e05-f685-11e9-8e41-6682758dfd28.15d0a612710b46ba], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-756b7e05-f685-11e9-8e41-6682758dfd28.15d0a6127347bb8e], Reason = [Created], Message = [Created container filler-pod-756b7e05-f685-11e9-8e41-6682758dfd28]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-756b7e05-f685-11e9-8e41-6682758dfd28.15d0a6127e9ca884], Reason = [Started], Message = [Started container filler-pod-756b7e05-f685-11e9-8e41-6682758dfd28]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15d0a61330494261], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node mip-bd-vm40.mip.storage.hpecorp.net
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node mip-bd-vm41.mip.storage.hpecorp.net
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:41:12.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3556" for this suite.
Oct 24 17:41:18.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:41:18.519: INFO: namespace sched-pred-3556 deletion completed in 6.17578278s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.388 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:41:18.520: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:41:22.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4460" for this suite.
Oct 24 17:41:28.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:41:28.788: INFO: namespace kubelet-test-4460 deletion completed in 6.191721142s

• [SLOW TEST:10.268 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:41:28.789: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct 24 17:41:28.874: INFO: Waiting up to 5m0s for pod "downward-api-824a778b-f685-11e9-8e41-6682758dfd28" in namespace "downward-api-5407" to be "success or failure"
Oct 24 17:41:28.913: INFO: Pod "downward-api-824a778b-f685-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 39.604077ms
Oct 24 17:41:30.919: INFO: Pod "downward-api-824a778b-f685-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.045307142s
STEP: Saw pod success
Oct 24 17:41:30.919: INFO: Pod "downward-api-824a778b-f685-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:41:30.923: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downward-api-824a778b-f685-11e9-8e41-6682758dfd28 container dapi-container: <nil>
STEP: delete the pod
Oct 24 17:41:30.953: INFO: Waiting for pod downward-api-824a778b-f685-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:41:30.956: INFO: Pod downward-api-824a778b-f685-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:41:30.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5407" for this suite.
Oct 24 17:41:36.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:41:37.124: INFO: namespace downward-api-5407 deletion completed in 6.160304802s

• [SLOW TEST:8.335 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:41:37.124: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 24 17:41:41.235: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 24 17:41:41.239: INFO: Pod pod-with-poststart-http-hook still exists
Oct 24 17:41:43.239: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 24 17:41:43.245: INFO: Pod pod-with-poststart-http-hook still exists
Oct 24 17:41:45.239: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 24 17:41:45.244: INFO: Pod pod-with-poststart-http-hook still exists
Oct 24 17:41:47.239: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 24 17:41:47.244: INFO: Pod pod-with-poststart-http-hook still exists
Oct 24 17:41:49.239: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 24 17:41:49.243: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:41:49.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-810" for this suite.
Oct 24 17:42:11.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:42:11.396: INFO: namespace container-lifecycle-hook-810 deletion completed in 22.147478825s

• [SLOW TEST:34.272 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:42:11.397: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Oct 24 17:42:13.974: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4906 pod-service-account-9bfba020-f685-11e9-8e41-6682758dfd28 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Oct 24 17:42:14.282: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4906 pod-service-account-9bfba020-f685-11e9-8e41-6682758dfd28 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Oct 24 17:42:14.594: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4906 pod-service-account-9bfba020-f685-11e9-8e41-6682758dfd28 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:42:14.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4906" for this suite.
Oct 24 17:42:20.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:42:21.108: INFO: namespace svcaccounts-4906 deletion completed in 6.16944926s

• [SLOW TEST:9.711 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:42:21.109: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:42:45.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6452" for this suite.
Oct 24 17:42:51.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:42:51.507: INFO: namespace namespaces-6452 deletion completed in 6.1678252s
STEP: Destroying namespace "nsdeletetest-3407" for this suite.
Oct 24 17:42:51.513: INFO: Namespace nsdeletetest-3407 was already deleted
STEP: Destroying namespace "nsdeletetest-4205" for this suite.
Oct 24 17:42:57.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:42:57.694: INFO: namespace nsdeletetest-4205 deletion completed in 6.181343708s

• [SLOW TEST:36.585 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:42:57.695: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-b7474c6a-f685-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume configMaps
Oct 24 17:42:57.764: INFO: Waiting up to 5m0s for pod "pod-configmaps-b747fe11-f685-11e9-8e41-6682758dfd28" in namespace "configmap-2461" to be "success or failure"
Oct 24 17:42:57.768: INFO: Pod "pod-configmaps-b747fe11-f685-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.669732ms
Oct 24 17:42:59.775: INFO: Pod "pod-configmaps-b747fe11-f685-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.01126658s
Oct 24 17:43:01.784: INFO: Pod "pod-configmaps-b747fe11-f685-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020585556s
STEP: Saw pod success
Oct 24 17:43:01.784: INFO: Pod "pod-configmaps-b747fe11-f685-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:43:01.792: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-configmaps-b747fe11-f685-11e9-8e41-6682758dfd28 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 17:43:01.828: INFO: Waiting for pod pod-configmaps-b747fe11-f685-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:43:01.833: INFO: Pod pod-configmaps-b747fe11-f685-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:43:01.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2461" for this suite.
Oct 24 17:43:07.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:43:08.125: INFO: namespace configmap-2461 deletion completed in 6.285700134s

• [SLOW TEST:10.430 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:43:08.126: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 17:43:08.177: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:43:10.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8170" for this suite.
Oct 24 17:43:50.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:43:50.388: INFO: namespace pods-8170 deletion completed in 40.159868893s

• [SLOW TEST:42.263 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:43:50.389: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-d6af0497-f685-11e9-8e41-6682758dfd28
STEP: Creating configMap with name cm-test-opt-upd-d6af050e-f685-11e9-8e41-6682758dfd28
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d6af0497-f685-11e9-8e41-6682758dfd28
STEP: Updating configmap cm-test-opt-upd-d6af050e-f685-11e9-8e41-6682758dfd28
STEP: Creating configMap with name cm-test-opt-create-d6af053b-f685-11e9-8e41-6682758dfd28
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:43:54.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-485" for this suite.
Oct 24 17:44:16.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:44:16.723: INFO: namespace configmap-485 deletion completed in 22.148617465s

• [SLOW TEST:26.335 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:44:16.724: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct 24 17:44:16.774: INFO: Waiting up to 5m0s for pod "downward-api-e66065c7-f685-11e9-8e41-6682758dfd28" in namespace "downward-api-3446" to be "success or failure"
Oct 24 17:44:16.777: INFO: Pod "downward-api-e66065c7-f685-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 3.547801ms
Oct 24 17:44:18.783: INFO: Pod "downward-api-e66065c7-f685-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008755826s
STEP: Saw pod success
Oct 24 17:44:18.783: INFO: Pod "downward-api-e66065c7-f685-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:44:18.787: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downward-api-e66065c7-f685-11e9-8e41-6682758dfd28 container dapi-container: <nil>
STEP: delete the pod
Oct 24 17:44:18.813: INFO: Waiting for pod downward-api-e66065c7-f685-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:44:18.816: INFO: Pod downward-api-e66065c7-f685-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:44:18.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3446" for this suite.
Oct 24 17:44:24.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:44:24.981: INFO: namespace downward-api-3446 deletion completed in 6.15989183s

• [SLOW TEST:8.257 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:44:24.981: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 24 17:44:25.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-3629'
Oct 24 17:44:25.224: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 24 17:44:25.224: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Oct 24 17:44:25.236: INFO: scanned /root for discovery docs: <nil>
Oct 24 17:44:25.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-3629'
Oct 24 17:44:41.146: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 24 17:44:41.146: INFO: stdout: "Created e2e-test-nginx-rc-0cf7ee157f0d7694ce2ce3f19a84fc6d\nScaling up e2e-test-nginx-rc-0cf7ee157f0d7694ce2ce3f19a84fc6d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0cf7ee157f0d7694ce2ce3f19a84fc6d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0cf7ee157f0d7694ce2ce3f19a84fc6d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Oct 24 17:44:41.146: INFO: stdout: "Created e2e-test-nginx-rc-0cf7ee157f0d7694ce2ce3f19a84fc6d\nScaling up e2e-test-nginx-rc-0cf7ee157f0d7694ce2ce3f19a84fc6d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0cf7ee157f0d7694ce2ce3f19a84fc6d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0cf7ee157f0d7694ce2ce3f19a84fc6d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Oct 24 17:44:41.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-3629'
Oct 24 17:44:41.318: INFO: stderr: ""
Oct 24 17:44:41.318: INFO: stdout: "e2e-test-nginx-rc-0cf7ee157f0d7694ce2ce3f19a84fc6d-vldxh "
Oct 24 17:44:41.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods e2e-test-nginx-rc-0cf7ee157f0d7694ce2ce3f19a84fc6d-vldxh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3629'
Oct 24 17:44:41.478: INFO: stderr: ""
Oct 24 17:44:41.478: INFO: stdout: "true"
Oct 24 17:44:41.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods e2e-test-nginx-rc-0cf7ee157f0d7694ce2ce3f19a84fc6d-vldxh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3629'
Oct 24 17:44:41.641: INFO: stderr: ""
Oct 24 17:44:41.641: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Oct 24 17:44:41.641: INFO: e2e-test-nginx-rc-0cf7ee157f0d7694ce2ce3f19a84fc6d-vldxh is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1486
Oct 24 17:44:41.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 delete rc e2e-test-nginx-rc --namespace=kubectl-3629'
Oct 24 17:44:41.816: INFO: stderr: ""
Oct 24 17:44:41.816: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:44:41.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3629" for this suite.
Oct 24 17:44:47.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:44:48.062: INFO: namespace kubectl-3629 deletion completed in 6.238838021s

• [SLOW TEST:23.081 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:44:48.063: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-7527
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-7527
STEP: Deleting pre-stop pod
Oct 24 17:45:01.162: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:45:01.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-7527" for this suite.
Oct 24 17:45:41.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:45:41.354: INFO: namespace prestop-7527 deletion completed in 40.179115163s

• [SLOW TEST:53.291 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:45:41.354: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-18d2c397-f686-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume secrets
Oct 24 17:45:41.418: INFO: Waiting up to 5m0s for pod "pod-secrets-18d39c41-f686-11e9-8e41-6682758dfd28" in namespace "secrets-2819" to be "success or failure"
Oct 24 17:45:41.422: INFO: Pod "pod-secrets-18d39c41-f686-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 3.96167ms
Oct 24 17:45:43.428: INFO: Pod "pod-secrets-18d39c41-f686-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.010443639s
Oct 24 17:45:45.435: INFO: Pod "pod-secrets-18d39c41-f686-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016763864s
STEP: Saw pod success
Oct 24 17:45:45.435: INFO: Pod "pod-secrets-18d39c41-f686-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:45:45.439: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-secrets-18d39c41-f686-11e9-8e41-6682758dfd28 container secret-volume-test: <nil>
STEP: delete the pod
Oct 24 17:45:45.468: INFO: Waiting for pod pod-secrets-18d39c41-f686-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:45:45.472: INFO: Pod pod-secrets-18d39c41-f686-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:45:45.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2819" for this suite.
Oct 24 17:45:51.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:45:51.650: INFO: namespace secrets-2819 deletion completed in 6.173824319s

• [SLOW TEST:10.296 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:45:51.652: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 17:45:51.714: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct 24 17:45:56.722: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 24 17:45:56.722: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 24 17:45:56.754: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-6941,SelfLink:/apis/apps/v1/namespaces/deployment-6941/deployments/test-cleanup-deployment,UID:21f5ca3c-f686-11e9-a6ac-005056ab7215,ResourceVersion:8046,Generation:1,CreationTimestamp:2019-10-24 17:45:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Oct 24 17:45:56.761: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Oct 24 17:45:56.761: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Oct 24 17:45:56.761: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-6941,SelfLink:/apis/apps/v1/namespaces/deployment-6941/replicasets/test-cleanup-controller,UID:1ef6fcd1-f686-11e9-a6ac-005056ab7215,ResourceVersion:8047,Generation:1,CreationTimestamp:2019-10-24 17:45:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 21f5ca3c-f686-11e9-a6ac-005056ab7215 0xc002efb0ff 0xc002efb110}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 24 17:45:56.780: INFO: Pod "test-cleanup-controller-2kgb5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-2kgb5,GenerateName:test-cleanup-controller-,Namespace:deployment-6941,SelfLink:/api/v1/namespaces/deployment-6941/pods/test-cleanup-controller-2kgb5,UID:1ef87baa-f686-11e9-a6ac-005056ab7215,ResourceVersion:8038,Generation:0,CreationTimestamp:2019-10-24 17:45:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.2.77/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 1ef6fcd1-f686-11e9-a6ac-005056ab7215 0xc002efb76f 0xc002efb790}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-glw9s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-glw9s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-glw9s true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002efb7f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002efb810}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:45:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:45:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:45:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:45:51 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.2.77,StartTime:2019-10-24 17:45:51 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-24 17:45:52 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2fd9d303b67a0f04ececf7652ba40876db0d40553f90db20d170151973f0861d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:45:56.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6941" for this suite.
Oct 24 17:46:02.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:46:02.985: INFO: namespace deployment-6941 deletion completed in 6.192477351s

• [SLOW TEST:11.334 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:46:02.986: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-25b8cf6e-f686-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume configMaps
Oct 24 17:46:03.057: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-25b992dc-f686-11e9-8e41-6682758dfd28" in namespace "projected-8044" to be "success or failure"
Oct 24 17:46:03.066: INFO: Pod "pod-projected-configmaps-25b992dc-f686-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 8.624087ms
Oct 24 17:46:05.071: INFO: Pod "pod-projected-configmaps-25b992dc-f686-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.014030532s
Oct 24 17:46:07.079: INFO: Pod "pod-projected-configmaps-25b992dc-f686-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022109969s
STEP: Saw pod success
Oct 24 17:46:07.079: INFO: Pod "pod-projected-configmaps-25b992dc-f686-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:46:07.084: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-configmaps-25b992dc-f686-11e9-8e41-6682758dfd28 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 17:46:07.113: INFO: Waiting for pod pod-projected-configmaps-25b992dc-f686-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:46:07.116: INFO: Pod pod-projected-configmaps-25b992dc-f686-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:46:07.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8044" for this suite.
Oct 24 17:46:13.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:46:13.295: INFO: namespace projected-8044 deletion completed in 6.172284487s

• [SLOW TEST:10.309 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:46:13.295: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-2bdce6e4-f686-11e9-8e41-6682758dfd28
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:46:13.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2850" for this suite.
Oct 24 17:46:19.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:46:19.523: INFO: namespace configmap-2850 deletion completed in 6.170242228s

• [SLOW TEST:6.228 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:46:19.523: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 24 17:46:19.590: INFO: Waiting up to 5m0s for pod "pod-2f945324-f686-11e9-8e41-6682758dfd28" in namespace "emptydir-9500" to be "success or failure"
Oct 24 17:46:19.594: INFO: Pod "pod-2f945324-f686-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.255021ms
Oct 24 17:46:21.601: INFO: Pod "pod-2f945324-f686-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010622007s
Oct 24 17:46:23.607: INFO: Pod "pod-2f945324-f686-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 4.016680023s
Oct 24 17:46:25.613: INFO: Pod "pod-2f945324-f686-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022996958s
STEP: Saw pod success
Oct 24 17:46:25.613: INFO: Pod "pod-2f945324-f686-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:46:25.618: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-2f945324-f686-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 17:46:25.649: INFO: Waiting for pod pod-2f945324-f686-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:46:25.654: INFO: Pod pod-2f945324-f686-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:46:25.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9500" for this suite.
Oct 24 17:46:31.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:46:31.812: INFO: namespace emptydir-9500 deletion completed in 6.153388095s

• [SLOW TEST:12.289 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:46:31.813: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1024 17:46:32.929561      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 24 17:46:32.929: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:46:32.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1877" for this suite.
Oct 24 17:46:38.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:46:39.105: INFO: namespace gc-1877 deletion completed in 6.170874949s

• [SLOW TEST:7.292 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:46:39.105: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-3b3f715f-f686-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume configMaps
Oct 24 17:46:39.171: INFO: Waiting up to 5m0s for pod "pod-configmaps-3b402153-f686-11e9-8e41-6682758dfd28" in namespace "configmap-1641" to be "success or failure"
Oct 24 17:46:39.177: INFO: Pod "pod-configmaps-3b402153-f686-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.619504ms
Oct 24 17:46:41.185: INFO: Pod "pod-configmaps-3b402153-f686-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013641127s
STEP: Saw pod success
Oct 24 17:46:41.185: INFO: Pod "pod-configmaps-3b402153-f686-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:46:41.189: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-3b402153-f686-11e9-8e41-6682758dfd28 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 17:46:41.215: INFO: Waiting for pod pod-configmaps-3b402153-f686-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:46:41.221: INFO: Pod pod-configmaps-3b402153-f686-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:46:41.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1641" for this suite.
Oct 24 17:46:47.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:46:47.385: INFO: namespace configmap-1641 deletion completed in 6.159869023s

• [SLOW TEST:8.279 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:46:47.385: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct 24 17:46:49.994: INFO: Successfully updated pod "labelsupdate402ee337-f686-11e9-8e41-6682758dfd28"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:46:54.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5730" for this suite.
Oct 24 17:47:16.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:47:16.210: INFO: namespace downward-api-5730 deletion completed in 22.169352499s

• [SLOW TEST:28.825 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:47:16.210: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Oct 24 17:47:16.270: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9896" to be "success or failure"
Oct 24 17:47:16.274: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.591544ms
Oct 24 17:47:18.281: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010906893s
STEP: Saw pod success
Oct 24 17:47:18.281: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Oct 24 17:47:18.285: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Oct 24 17:47:18.314: INFO: Waiting for pod pod-host-path-test to disappear
Oct 24 17:47:18.321: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:47:18.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-9896" for this suite.
Oct 24 17:47:24.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:47:24.507: INFO: namespace hostpath-9896 deletion completed in 6.176812309s

• [SLOW TEST:8.297 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:47:24.508: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1024 17:47:55.097221      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 24 17:47:55.097: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:47:55.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7675" for this suite.
Oct 24 17:48:01.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:48:01.405: INFO: namespace gc-7675 deletion completed in 6.303782181s

• [SLOW TEST:36.898 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:48:01.407: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 17:48:01.464: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6c4cf5bc-f686-11e9-8e41-6682758dfd28" in namespace "projected-8010" to be "success or failure"
Oct 24 17:48:01.471: INFO: Pod "downwardapi-volume-6c4cf5bc-f686-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 6.83251ms
Oct 24 17:48:03.477: INFO: Pod "downwardapi-volume-6c4cf5bc-f686-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012874902s
STEP: Saw pod success
Oct 24 17:48:03.477: INFO: Pod "downwardapi-volume-6c4cf5bc-f686-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:48:03.481: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-6c4cf5bc-f686-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 17:48:03.508: INFO: Waiting for pod downwardapi-volume-6c4cf5bc-f686-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:48:03.512: INFO: Pod downwardapi-volume-6c4cf5bc-f686-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:48:03.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8010" for this suite.
Oct 24 17:48:09.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:48:09.679: INFO: namespace projected-8010 deletion completed in 6.161243234s

• [SLOW TEST:8.272 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:48:09.680: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-713c728e-f686-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume secrets
Oct 24 17:48:09.753: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-713d8f93-f686-11e9-8e41-6682758dfd28" in namespace "projected-6186" to be "success or failure"
Oct 24 17:48:09.772: INFO: Pod "pod-projected-secrets-713d8f93-f686-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 18.392324ms
Oct 24 17:48:11.778: INFO: Pod "pod-projected-secrets-713d8f93-f686-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.025051064s
Oct 24 17:48:13.785: INFO: Pod "pod-projected-secrets-713d8f93-f686-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031378937s
STEP: Saw pod success
Oct 24 17:48:13.785: INFO: Pod "pod-projected-secrets-713d8f93-f686-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:48:13.789: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-secrets-713d8f93-f686-11e9-8e41-6682758dfd28 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 24 17:48:13.814: INFO: Waiting for pod pod-projected-secrets-713d8f93-f686-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:48:13.818: INFO: Pod pod-projected-secrets-713d8f93-f686-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:48:13.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6186" for this suite.
Oct 24 17:48:19.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:48:20.000: INFO: namespace projected-6186 deletion completed in 6.17743577s

• [SLOW TEST:10.320 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:48:20.000: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 17:48:20.083: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"77647b44-f686-11e9-a6ac-005056ab7215", Controller:(*bool)(0xc0028d0faa), BlockOwnerDeletion:(*bool)(0xc0028d0fab)}}
Oct 24 17:48:20.097: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"7762cb8b-f686-11e9-a6ac-005056ab7215", Controller:(*bool)(0xc002a75376), BlockOwnerDeletion:(*bool)(0xc002a75377)}}
Oct 24 17:48:20.112: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"7763b13f-f686-11e9-a6ac-005056ab7215", Controller:(*bool)(0xc002a75516), BlockOwnerDeletion:(*bool)(0xc002a75517)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:48:25.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9188" for this suite.
Oct 24 17:48:31.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:48:31.292: INFO: namespace gc-9188 deletion completed in 6.160099281s

• [SLOW TEST:11.292 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:48:31.292: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-8727
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-8727
STEP: Creating statefulset with conflicting port in namespace statefulset-8727
STEP: Waiting until pod test-pod will start running in namespace statefulset-8727
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-8727
Oct 24 17:48:35.396: INFO: Observed stateful pod in namespace: statefulset-8727, name: ss-0, uid: 804b3ab2-f686-11e9-a6ac-005056ab7215, status phase: Pending. Waiting for statefulset controller to delete.
Oct 24 17:48:35.576: INFO: Observed stateful pod in namespace: statefulset-8727, name: ss-0, uid: 804b3ab2-f686-11e9-a6ac-005056ab7215, status phase: Failed. Waiting for statefulset controller to delete.
Oct 24 17:48:35.585: INFO: Observed stateful pod in namespace: statefulset-8727, name: ss-0, uid: 804b3ab2-f686-11e9-a6ac-005056ab7215, status phase: Failed. Waiting for statefulset controller to delete.
Oct 24 17:48:35.590: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-8727
STEP: Removing pod with conflicting port in namespace statefulset-8727
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-8727 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 24 17:48:39.633: INFO: Deleting all statefulset in ns statefulset-8727
Oct 24 17:48:39.637: INFO: Scaling statefulset ss to 0
Oct 24 17:48:49.658: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 17:48:49.662: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:48:49.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8727" for this suite.
Oct 24 17:49:03.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:49:03.857: INFO: namespace statefulset-8727 deletion completed in 14.170655733s

• [SLOW TEST:32.565 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:49:03.857: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 17:49:03.915: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91860ed2-f686-11e9-8e41-6682758dfd28" in namespace "projected-7667" to be "success or failure"
Oct 24 17:49:03.921: INFO: Pod "downwardapi-volume-91860ed2-f686-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.988991ms
Oct 24 17:49:05.926: INFO: Pod "downwardapi-volume-91860ed2-f686-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010947082s
STEP: Saw pod success
Oct 24 17:49:05.926: INFO: Pod "downwardapi-volume-91860ed2-f686-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:49:05.930: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-91860ed2-f686-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 17:49:05.955: INFO: Waiting for pod downwardapi-volume-91860ed2-f686-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:49:05.959: INFO: Pod downwardapi-volume-91860ed2-f686-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:49:05.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7667" for this suite.
Oct 24 17:49:11.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:49:12.134: INFO: namespace projected-7667 deletion completed in 6.170102374s

• [SLOW TEST:8.277 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:49:12.134: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Oct 24 17:49:12.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 create -f - --namespace=kubectl-7301'
Oct 24 17:49:12.632: INFO: stderr: ""
Oct 24 17:49:12.632: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 24 17:49:12.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7301'
Oct 24 17:49:12.813: INFO: stderr: ""
Oct 24 17:49:12.813: INFO: stdout: "update-demo-nautilus-9t5pq update-demo-nautilus-cr47d "
Oct 24 17:49:12.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-9t5pq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7301'
Oct 24 17:49:12.991: INFO: stderr: ""
Oct 24 17:49:12.991: INFO: stdout: ""
Oct 24 17:49:12.991: INFO: update-demo-nautilus-9t5pq is created but not running
Oct 24 17:49:17.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7301'
Oct 24 17:49:18.173: INFO: stderr: ""
Oct 24 17:49:18.173: INFO: stdout: "update-demo-nautilus-9t5pq update-demo-nautilus-cr47d "
Oct 24 17:49:18.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-9t5pq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7301'
Oct 24 17:49:18.351: INFO: stderr: ""
Oct 24 17:49:18.351: INFO: stdout: "true"
Oct 24 17:49:18.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-9t5pq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7301'
Oct 24 17:49:18.518: INFO: stderr: ""
Oct 24 17:49:18.518: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 17:49:18.518: INFO: validating pod update-demo-nautilus-9t5pq
Oct 24 17:49:18.525: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 17:49:18.525: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 17:49:18.525: INFO: update-demo-nautilus-9t5pq is verified up and running
Oct 24 17:49:18.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-cr47d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7301'
Oct 24 17:49:18.691: INFO: stderr: ""
Oct 24 17:49:18.691: INFO: stdout: "true"
Oct 24 17:49:18.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-cr47d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7301'
Oct 24 17:49:18.851: INFO: stderr: ""
Oct 24 17:49:18.851: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 17:49:18.851: INFO: validating pod update-demo-nautilus-cr47d
Oct 24 17:49:18.858: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 17:49:18.858: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 17:49:18.858: INFO: update-demo-nautilus-cr47d is verified up and running
STEP: scaling down the replication controller
Oct 24 17:49:18.861: INFO: scanned /root for discovery docs: <nil>
Oct 24 17:49:18.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-7301'
Oct 24 17:49:20.069: INFO: stderr: ""
Oct 24 17:49:20.069: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 24 17:49:20.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7301'
Oct 24 17:49:20.256: INFO: stderr: ""
Oct 24 17:49:20.256: INFO: stdout: "update-demo-nautilus-9t5pq update-demo-nautilus-cr47d "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 24 17:49:25.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7301'
Oct 24 17:49:25.429: INFO: stderr: ""
Oct 24 17:49:25.429: INFO: stdout: "update-demo-nautilus-9t5pq "
Oct 24 17:49:25.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-9t5pq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7301'
Oct 24 17:49:25.611: INFO: stderr: ""
Oct 24 17:49:25.611: INFO: stdout: "true"
Oct 24 17:49:25.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-9t5pq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7301'
Oct 24 17:49:25.781: INFO: stderr: ""
Oct 24 17:49:25.781: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 17:49:25.781: INFO: validating pod update-demo-nautilus-9t5pq
Oct 24 17:49:25.787: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 17:49:25.787: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 17:49:25.787: INFO: update-demo-nautilus-9t5pq is verified up and running
STEP: scaling up the replication controller
Oct 24 17:49:25.790: INFO: scanned /root for discovery docs: <nil>
Oct 24 17:49:25.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-7301'
Oct 24 17:49:27.005: INFO: stderr: ""
Oct 24 17:49:27.005: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 24 17:49:27.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7301'
Oct 24 17:49:27.191: INFO: stderr: ""
Oct 24 17:49:27.191: INFO: stdout: "update-demo-nautilus-6rql6 update-demo-nautilus-9t5pq "
Oct 24 17:49:27.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-6rql6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7301'
Oct 24 17:49:27.357: INFO: stderr: ""
Oct 24 17:49:27.357: INFO: stdout: ""
Oct 24 17:49:27.357: INFO: update-demo-nautilus-6rql6 is created but not running
Oct 24 17:49:32.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7301'
Oct 24 17:49:32.527: INFO: stderr: ""
Oct 24 17:49:32.527: INFO: stdout: "update-demo-nautilus-6rql6 update-demo-nautilus-9t5pq "
Oct 24 17:49:32.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-6rql6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7301'
Oct 24 17:49:32.698: INFO: stderr: ""
Oct 24 17:49:32.698: INFO: stdout: "true"
Oct 24 17:49:32.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-6rql6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7301'
Oct 24 17:49:32.859: INFO: stderr: ""
Oct 24 17:49:32.859: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 17:49:32.859: INFO: validating pod update-demo-nautilus-6rql6
Oct 24 17:49:32.868: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 17:49:32.868: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 17:49:32.868: INFO: update-demo-nautilus-6rql6 is verified up and running
Oct 24 17:49:32.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-9t5pq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7301'
Oct 24 17:49:33.051: INFO: stderr: ""
Oct 24 17:49:33.051: INFO: stdout: "true"
Oct 24 17:49:33.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-9t5pq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7301'
Oct 24 17:49:33.229: INFO: stderr: ""
Oct 24 17:49:33.229: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 17:49:33.229: INFO: validating pod update-demo-nautilus-9t5pq
Oct 24 17:49:33.235: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 17:49:33.235: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 17:49:33.235: INFO: update-demo-nautilus-9t5pq is verified up and running
STEP: using delete to clean up resources
Oct 24 17:49:33.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 delete --grace-period=0 --force -f - --namespace=kubectl-7301'
Oct 24 17:49:33.400: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 17:49:33.400: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 24 17:49:33.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7301'
Oct 24 17:49:33.567: INFO: stderr: "No resources found.\n"
Oct 24 17:49:33.567: INFO: stdout: ""
Oct 24 17:49:33.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods -l name=update-demo --namespace=kubectl-7301 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 24 17:49:33.743: INFO: stderr: ""
Oct 24 17:49:33.743: INFO: stdout: "update-demo-nautilus-6rql6\nupdate-demo-nautilus-9t5pq\n"
Oct 24 17:49:34.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7301'
Oct 24 17:49:34.422: INFO: stderr: "No resources found.\n"
Oct 24 17:49:34.422: INFO: stdout: ""
Oct 24 17:49:34.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods -l name=update-demo --namespace=kubectl-7301 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 24 17:49:34.588: INFO: stderr: ""
Oct 24 17:49:34.588: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:49:34.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7301" for this suite.
Oct 24 17:49:40.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:49:40.767: INFO: namespace kubectl-7301 deletion completed in 6.170966102s

• [SLOW TEST:28.634 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:49:40.768: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 17:49:40.817: INFO: Creating deployment "test-recreate-deployment"
Oct 24 17:49:40.840: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct 24 17:49:40.853: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Oct 24 17:49:42.864: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct 24 17:49:42.869: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct 24 17:49:42.880: INFO: Updating deployment test-recreate-deployment
Oct 24 17:49:42.880: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 24 17:49:42.979: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-3832,SelfLink:/apis/apps/v1/namespaces/deployment-3832/deployments/test-recreate-deployment,UID:a786d1ba-f686-11e9-a6ac-005056ab7215,ResourceVersion:9084,Generation:2,CreationTimestamp:2019-10-24 17:49:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-10-24 17:49:42 +0000 UTC 2019-10-24 17:49:42 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-10-24 17:49:42 +0000 UTC 2019-10-24 17:49:40 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-745fb9c84c" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Oct 24 17:49:42.984: INFO: New ReplicaSet "test-recreate-deployment-745fb9c84c" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c,GenerateName:,Namespace:deployment-3832,SelfLink:/apis/apps/v1/namespaces/deployment-3832/replicasets/test-recreate-deployment-745fb9c84c,UID:a8c879a1-f686-11e9-a6ac-005056ab7215,ResourceVersion:9081,Generation:1,CreationTimestamp:2019-10-24 17:49:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment a786d1ba-f686-11e9-a6ac-005056ab7215 0xc002dcee97 0xc002dcee98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 24 17:49:42.984: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct 24 17:49:42.984: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6566d46b4b,GenerateName:,Namespace:deployment-3832,SelfLink:/apis/apps/v1/namespaces/deployment-3832/replicasets/test-recreate-deployment-6566d46b4b,UID:a78a25a1-f686-11e9-a6ac-005056ab7215,ResourceVersion:9071,Generation:2,CreationTimestamp:2019-10-24 17:49:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment a786d1ba-f686-11e9-a6ac-005056ab7215 0xc002dcec17 0xc002dcec18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 24 17:49:42.990: INFO: Pod "test-recreate-deployment-745fb9c84c-2lcmt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c-2lcmt,GenerateName:test-recreate-deployment-745fb9c84c-,Namespace:deployment-3832,SelfLink:/api/v1/namespaces/deployment-3832/pods/test-recreate-deployment-745fb9c84c-2lcmt,UID:a8c93bd3-f686-11e9-a6ac-005056ab7215,ResourceVersion:9083,Generation:0,CreationTimestamp:2019-10-24 17:49:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-745fb9c84c a8c879a1-f686-11e9-a6ac-005056ab7215 0xc002de4fa7 0xc002de4fa8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fndl6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fndl6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fndl6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002de50a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002de5130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:49:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:49:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:49:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:49:42 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:,StartTime:2019-10-24 17:49:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:49:42.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3832" for this suite.
Oct 24 17:49:49.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:49:49.158: INFO: namespace deployment-3832 deletion completed in 6.161977265s

• [SLOW TEST:8.390 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:49:49.158: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 17:49:49.245: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Oct 24 17:49:49.258: INFO: Number of nodes with available pods: 0
Oct 24 17:49:49.258: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Oct 24 17:49:49.281: INFO: Number of nodes with available pods: 0
Oct 24 17:49:49.281: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:49:50.288: INFO: Number of nodes with available pods: 0
Oct 24 17:49:50.288: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:49:51.288: INFO: Number of nodes with available pods: 1
Oct 24 17:49:51.288: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Oct 24 17:49:51.311: INFO: Number of nodes with available pods: 1
Oct 24 17:49:51.311: INFO: Number of running nodes: 0, number of available pods: 1
Oct 24 17:49:52.317: INFO: Number of nodes with available pods: 0
Oct 24 17:49:52.317: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Oct 24 17:49:52.335: INFO: Number of nodes with available pods: 0
Oct 24 17:49:52.335: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:49:53.342: INFO: Number of nodes with available pods: 0
Oct 24 17:49:53.342: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:49:54.341: INFO: Number of nodes with available pods: 0
Oct 24 17:49:54.341: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:49:55.341: INFO: Number of nodes with available pods: 0
Oct 24 17:49:55.341: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:49:56.342: INFO: Number of nodes with available pods: 0
Oct 24 17:49:56.342: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:49:57.343: INFO: Number of nodes with available pods: 0
Oct 24 17:49:57.343: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:49:58.341: INFO: Number of nodes with available pods: 0
Oct 24 17:49:58.342: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:49:59.340: INFO: Number of nodes with available pods: 0
Oct 24 17:49:59.340: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:50:00.340: INFO: Number of nodes with available pods: 0
Oct 24 17:50:00.340: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:50:01.342: INFO: Number of nodes with available pods: 1
Oct 24 17:50:01.342: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9886, will wait for the garbage collector to delete the pods
Oct 24 17:50:01.415: INFO: Deleting DaemonSet.extensions daemon-set took: 10.818191ms
Oct 24 17:50:01.515: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.323481ms
Oct 24 17:50:09.222: INFO: Number of nodes with available pods: 0
Oct 24 17:50:09.222: INFO: Number of running nodes: 0, number of available pods: 0
Oct 24 17:50:09.226: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9886/daemonsets","resourceVersion":"9202"},"items":null}

Oct 24 17:50:09.229: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9886/pods","resourceVersion":"9202"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:50:09.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9886" for this suite.
Oct 24 17:50:15.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:50:15.421: INFO: namespace daemonsets-9886 deletion completed in 6.162081159s

• [SLOW TEST:26.263 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:50:15.422: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-bc2de68e-f686-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume configMaps
Oct 24 17:50:15.484: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bc2e98b7-f686-11e9-8e41-6682758dfd28" in namespace "projected-9081" to be "success or failure"
Oct 24 17:50:15.489: INFO: Pod "pod-projected-configmaps-bc2e98b7-f686-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.259724ms
Oct 24 17:50:17.495: INFO: Pod "pod-projected-configmaps-bc2e98b7-f686-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011380385s
STEP: Saw pod success
Oct 24 17:50:17.495: INFO: Pod "pod-projected-configmaps-bc2e98b7-f686-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:50:17.499: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-configmaps-bc2e98b7-f686-11e9-8e41-6682758dfd28 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 17:50:17.526: INFO: Waiting for pod pod-projected-configmaps-bc2e98b7-f686-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:50:17.530: INFO: Pod pod-projected-configmaps-bc2e98b7-f686-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:50:17.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9081" for this suite.
Oct 24 17:50:23.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:50:23.697: INFO: namespace projected-9081 deletion completed in 6.162050196s

• [SLOW TEST:8.275 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:50:23.697: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Oct 24 17:50:23.752: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Oct 24 17:50:23.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 create -f - --namespace=kubectl-489'
Oct 24 17:50:24.090: INFO: stderr: ""
Oct 24 17:50:24.090: INFO: stdout: "service/redis-slave created\n"
Oct 24 17:50:24.090: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Oct 24 17:50:24.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 create -f - --namespace=kubectl-489'
Oct 24 17:50:24.437: INFO: stderr: ""
Oct 24 17:50:24.437: INFO: stdout: "service/redis-master created\n"
Oct 24 17:50:24.438: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct 24 17:50:24.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 create -f - --namespace=kubectl-489'
Oct 24 17:50:24.764: INFO: stderr: ""
Oct 24 17:50:24.764: INFO: stdout: "service/frontend created\n"
Oct 24 17:50:24.764: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Oct 24 17:50:24.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 create -f - --namespace=kubectl-489'
Oct 24 17:50:25.112: INFO: stderr: ""
Oct 24 17:50:25.112: INFO: stdout: "deployment.apps/frontend created\n"
Oct 24 17:50:25.112: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct 24 17:50:25.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 create -f - --namespace=kubectl-489'
Oct 24 17:50:25.436: INFO: stderr: ""
Oct 24 17:50:25.436: INFO: stdout: "deployment.apps/redis-master created\n"
Oct 24 17:50:25.437: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Oct 24 17:50:25.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 create -f - --namespace=kubectl-489'
Oct 24 17:50:25.770: INFO: stderr: ""
Oct 24 17:50:25.770: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Oct 24 17:50:25.770: INFO: Waiting for all frontend pods to be Running.
Oct 24 17:51:25.824: INFO: Waiting for frontend to serve content.
Oct 24 17:51:25.854: INFO: Trying to add a new entry to the guestbook.
Oct 24 17:51:25.875: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Oct 24 17:51:25.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 delete --grace-period=0 --force -f - --namespace=kubectl-489'
Oct 24 17:51:26.098: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 17:51:26.099: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Oct 24 17:51:26.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 delete --grace-period=0 --force -f - --namespace=kubectl-489'
Oct 24 17:51:26.311: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 17:51:26.311: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 24 17:51:26.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 delete --grace-period=0 --force -f - --namespace=kubectl-489'
Oct 24 17:51:26.522: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 17:51:26.522: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 24 17:51:26.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 delete --grace-period=0 --force -f - --namespace=kubectl-489'
Oct 24 17:51:26.727: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 17:51:26.728: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 24 17:51:26.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 delete --grace-period=0 --force -f - --namespace=kubectl-489'
Oct 24 17:51:26.909: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 17:51:26.909: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 24 17:51:26.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 delete --grace-period=0 --force -f - --namespace=kubectl-489'
Oct 24 17:51:27.107: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 17:51:27.107: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:51:27.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-489" for this suite.
Oct 24 17:52:07.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:52:07.300: INFO: namespace kubectl-489 deletion completed in 40.183674053s

• [SLOW TEST:103.603 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:52:07.301: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 17:52:07.363: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fedde8f1-f686-11e9-8e41-6682758dfd28" in namespace "projected-4830" to be "success or failure"
Oct 24 17:52:07.368: INFO: Pod "downwardapi-volume-fedde8f1-f686-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.01979ms
Oct 24 17:52:09.375: INFO: Pod "downwardapi-volume-fedde8f1-f686-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011547102s
STEP: Saw pod success
Oct 24 17:52:09.375: INFO: Pod "downwardapi-volume-fedde8f1-f686-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:52:09.380: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-fedde8f1-f686-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 17:52:09.410: INFO: Waiting for pod downwardapi-volume-fedde8f1-f686-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:52:09.415: INFO: Pod downwardapi-volume-fedde8f1-f686-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:52:09.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4830" for this suite.
Oct 24 17:52:15.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:52:15.568: INFO: namespace projected-4830 deletion completed in 6.147760251s

• [SLOW TEST:8.267 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:52:15.568: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-299
Oct 24 17:52:21.631: INFO: Started pod liveness-http in namespace container-probe-299
STEP: checking the pod's current state and verifying that restartCount is present
Oct 24 17:52:21.635: INFO: Initial restart count of pod liveness-http is 0
Oct 24 17:52:33.673: INFO: Restart count of pod container-probe-299/liveness-http is now 1 (12.038220493s elapsed)
Oct 24 17:52:53.731: INFO: Restart count of pod container-probe-299/liveness-http is now 2 (32.095947549s elapsed)
Oct 24 17:53:13.800: INFO: Restart count of pod container-probe-299/liveness-http is now 3 (52.164831079s elapsed)
Oct 24 17:53:33.863: INFO: Restart count of pod container-probe-299/liveness-http is now 4 (1m12.228337799s elapsed)
Oct 24 17:54:46.078: INFO: Restart count of pod container-probe-299/liveness-http is now 5 (2m24.442771667s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:54:46.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-299" for this suite.
Oct 24 17:54:52.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:54:52.271: INFO: namespace container-probe-299 deletion completed in 6.174706242s

• [SLOW TEST:156.702 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:54:52.272: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 24 17:54:52.358: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:54:52.362: INFO: Number of nodes with available pods: 0
Oct 24 17:54:52.362: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:54:53.371: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:54:53.376: INFO: Number of nodes with available pods: 0
Oct 24 17:54:53.376: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:54:54.369: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:54:54.373: INFO: Number of nodes with available pods: 2
Oct 24 17:54:54.373: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Oct 24 17:54:54.393: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:54:54.399: INFO: Number of nodes with available pods: 1
Oct 24 17:54:54.399: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:54:55.407: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:54:55.411: INFO: Number of nodes with available pods: 1
Oct 24 17:54:55.412: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:54:56.407: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:54:56.411: INFO: Number of nodes with available pods: 1
Oct 24 17:54:56.411: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:54:57.407: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:54:57.412: INFO: Number of nodes with available pods: 1
Oct 24 17:54:57.412: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:54:58.405: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:54:58.411: INFO: Number of nodes with available pods: 1
Oct 24 17:54:58.411: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:54:59.407: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:54:59.413: INFO: Number of nodes with available pods: 2
Oct 24 17:54:59.413: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4467, will wait for the garbage collector to delete the pods
Oct 24 17:54:59.484: INFO: Deleting DaemonSet.extensions daemon-set took: 12.611356ms
Oct 24 17:54:59.885: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.299107ms
Oct 24 17:55:09.189: INFO: Number of nodes with available pods: 0
Oct 24 17:55:09.189: INFO: Number of running nodes: 0, number of available pods: 0
Oct 24 17:55:09.193: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4467/daemonsets","resourceVersion":"10034"},"items":null}

Oct 24 17:55:09.196: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4467/pods","resourceVersion":"10034"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:55:09.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4467" for this suite.
Oct 24 17:55:15.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:55:15.358: INFO: namespace daemonsets-4467 deletion completed in 6.143053485s

• [SLOW TEST:23.086 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:55:15.358: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 17:55:15.421: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Oct 24 17:55:15.430: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:15.433: INFO: Number of nodes with available pods: 0
Oct 24 17:55:15.434: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:55:16.441: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:16.444: INFO: Number of nodes with available pods: 0
Oct 24 17:55:16.444: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:55:17.440: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:17.443: INFO: Number of nodes with available pods: 2
Oct 24 17:55:17.443: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Oct 24 17:55:17.469: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:17.469: INFO: Wrong image for pod: daemon-set-8c6mc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:17.475: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:18.480: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:18.480: INFO: Wrong image for pod: daemon-set-8c6mc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:18.485: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:19.480: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:19.480: INFO: Wrong image for pod: daemon-set-8c6mc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:19.485: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:20.481: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:20.481: INFO: Wrong image for pod: daemon-set-8c6mc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:20.481: INFO: Pod daemon-set-8c6mc is not available
Oct 24 17:55:20.485: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:21.481: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:21.481: INFO: Pod daemon-set-dbvzw is not available
Oct 24 17:55:21.486: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:22.481: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:22.485: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:23.481: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:23.486: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:24.482: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:24.482: INFO: Pod daemon-set-2vq6d is not available
Oct 24 17:55:24.487: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:25.481: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:25.481: INFO: Pod daemon-set-2vq6d is not available
Oct 24 17:55:25.486: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:26.481: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:26.481: INFO: Pod daemon-set-2vq6d is not available
Oct 24 17:55:26.487: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:27.482: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:27.482: INFO: Pod daemon-set-2vq6d is not available
Oct 24 17:55:27.487: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:28.481: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:28.481: INFO: Pod daemon-set-2vq6d is not available
Oct 24 17:55:28.486: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:29.482: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:29.482: INFO: Pod daemon-set-2vq6d is not available
Oct 24 17:55:29.487: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:30.481: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:30.481: INFO: Pod daemon-set-2vq6d is not available
Oct 24 17:55:30.486: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:31.480: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:31.480: INFO: Pod daemon-set-2vq6d is not available
Oct 24 17:55:31.485: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:32.482: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:32.482: INFO: Pod daemon-set-2vq6d is not available
Oct 24 17:55:32.487: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:33.481: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:33.481: INFO: Pod daemon-set-2vq6d is not available
Oct 24 17:55:33.486: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:34.481: INFO: Wrong image for pod: daemon-set-2vq6d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 24 17:55:34.481: INFO: Pod daemon-set-2vq6d is not available
Oct 24 17:55:34.487: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:35.481: INFO: Pod daemon-set-jgb9q is not available
Oct 24 17:55:35.486: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Oct 24 17:55:35.490: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:35.494: INFO: Number of nodes with available pods: 1
Oct 24 17:55:35.494: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:55:36.501: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:36.505: INFO: Number of nodes with available pods: 1
Oct 24 17:55:36.505: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 17:55:37.502: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 17:55:37.507: INFO: Number of nodes with available pods: 2
Oct 24 17:55:37.507: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4457, will wait for the garbage collector to delete the pods
Oct 24 17:55:37.596: INFO: Deleting DaemonSet.extensions daemon-set took: 9.780157ms
Oct 24 17:55:37.996: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.327105ms
Oct 24 17:55:45.400: INFO: Number of nodes with available pods: 0
Oct 24 17:55:45.400: INFO: Number of running nodes: 0, number of available pods: 0
Oct 24 17:55:45.404: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4457/daemonsets","resourceVersion":"10195"},"items":null}

Oct 24 17:55:45.407: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4457/pods","resourceVersion":"10195"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:55:45.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4457" for this suite.
Oct 24 17:55:51.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:55:51.575: INFO: namespace daemonsets-4457 deletion completed in 6.148387038s

• [SLOW TEST:36.217 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:55:51.575: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 17:55:51.628: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct 24 17:55:56.635: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 24 17:55:56.635: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct 24 17:55:58.641: INFO: Creating deployment "test-rollover-deployment"
Oct 24 17:55:58.652: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct 24 17:56:00.662: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct 24 17:56:00.671: INFO: Ensure that both replica sets have 1 created replica
Oct 24 17:56:00.679: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct 24 17:56:00.690: INFO: Updating deployment test-rollover-deployment
Oct 24 17:56:00.690: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct 24 17:56:02.700: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct 24 17:56:02.707: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct 24 17:56:02.715: INFO: all replica sets need to contain the pod-template-hash label
Oct 24 17:56:02.715: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536558, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536558, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536562, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536558, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 17:56:04.725: INFO: all replica sets need to contain the pod-template-hash label
Oct 24 17:56:04.725: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536558, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536558, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536562, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536558, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 17:56:06.727: INFO: all replica sets need to contain the pod-template-hash label
Oct 24 17:56:06.727: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536558, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536558, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536562, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536558, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 17:56:08.728: INFO: all replica sets need to contain the pod-template-hash label
Oct 24 17:56:08.728: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536558, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536558, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536562, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536558, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 17:56:10.730: INFO: all replica sets need to contain the pod-template-hash label
Oct 24 17:56:10.730: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536558, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536558, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536562, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707536558, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 17:56:12.725: INFO: 
Oct 24 17:56:12.725: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 24 17:56:12.737: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-7448,SelfLink:/apis/apps/v1/namespaces/deployment-7448/deployments/test-rollover-deployment,UID:88ba4d25-f687-11e9-a6ac-005056ab7215,ResourceVersion:10344,Generation:2,CreationTimestamp:2019-10-24 17:55:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-24 17:55:58 +0000 UTC 2019-10-24 17:55:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-24 17:56:12 +0000 UTC 2019-10-24 17:55:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-659c699649" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 24 17:56:12.741: INFO: New ReplicaSet "test-rollover-deployment-659c699649" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649,GenerateName:,Namespace:deployment-7448,SelfLink:/apis/apps/v1/namespaces/deployment-7448/replicasets/test-rollover-deployment-659c699649,UID:89f2f38f-f687-11e9-a6ac-005056ab7215,ResourceVersion:10334,Generation:2,CreationTimestamp:2019-10-24 17:56:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 88ba4d25-f687-11e9-a6ac-005056ab7215 0xc0030c6a57 0xc0030c6a58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 24 17:56:12.742: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct 24 17:56:12.742: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-7448,SelfLink:/apis/apps/v1/namespaces/deployment-7448/replicasets/test-rollover-controller,UID:848af467-f687-11e9-a6ac-005056ab7215,ResourceVersion:10343,Generation:2,CreationTimestamp:2019-10-24 17:55:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 88ba4d25-f687-11e9-a6ac-005056ab7215 0xc0030c6987 0xc0030c6988}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 24 17:56:12.742: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-7b45b6464,GenerateName:,Namespace:deployment-7448,SelfLink:/apis/apps/v1/namespaces/deployment-7448/replicasets/test-rollover-deployment-7b45b6464,UID:88bdb85f-f687-11e9-a6ac-005056ab7215,ResourceVersion:10304,Generation:2,CreationTimestamp:2019-10-24 17:55:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 88ba4d25-f687-11e9-a6ac-005056ab7215 0xc0030c6b20 0xc0030c6b21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 24 17:56:12.746: INFO: Pod "test-rollover-deployment-659c699649-pjdrp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649-pjdrp,GenerateName:test-rollover-deployment-659c699649-,Namespace:deployment-7448,SelfLink:/api/v1/namespaces/deployment-7448/pods/test-rollover-deployment-659c699649-pjdrp,UID:89fc411c-f687-11e9-a6ac-005056ab7215,ResourceVersion:10317,Generation:0,CreationTimestamp:2019-10-24 17:56:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.92/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-659c699649 89f2f38f-f687-11e9-a6ac-005056ab7215 0xc0030c76f7 0xc0030c76f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2zlmz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2zlmz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-2zlmz true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030c7760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030c7780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:56:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:56:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:56:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 17:56:00 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.1.92,StartTime:2019-10-24 17:56:00 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-24 17:56:01 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e950a60278f3f204484e8f1cb29381175546f24d4b87f16be433e11bfdebdae0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:56:12.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7448" for this suite.
Oct 24 17:56:18.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:56:18.917: INFO: namespace deployment-7448 deletion completed in 6.165499421s

• [SLOW TEST:27.342 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:56:18.917: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct 24 17:56:18.987: INFO: Waiting up to 5m0s for pod "downward-api-94d932e0-f687-11e9-8e41-6682758dfd28" in namespace "downward-api-8405" to be "success or failure"
Oct 24 17:56:18.992: INFO: Pod "downward-api-94d932e0-f687-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.523664ms
Oct 24 17:56:20.997: INFO: Pod "downward-api-94d932e0-f687-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.00934793s
Oct 24 17:56:23.002: INFO: Pod "downward-api-94d932e0-f687-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014305188s
STEP: Saw pod success
Oct 24 17:56:23.002: INFO: Pod "downward-api-94d932e0-f687-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:56:23.006: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downward-api-94d932e0-f687-11e9-8e41-6682758dfd28 container dapi-container: <nil>
STEP: delete the pod
Oct 24 17:56:23.036: INFO: Waiting for pod downward-api-94d932e0-f687-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:56:23.043: INFO: Pod downward-api-94d932e0-f687-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:56:23.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8405" for this suite.
Oct 24 17:56:29.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:56:29.233: INFO: namespace downward-api-8405 deletion completed in 6.182956236s

• [SLOW TEST:10.316 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:56:29.233: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Oct 24 17:56:29.544: INFO: Pod name wrapped-volume-race-9b22be78-f687-11e9-8e41-6682758dfd28: Found 0 pods out of 5
Oct 24 17:56:34.555: INFO: Pod name wrapped-volume-race-9b22be78-f687-11e9-8e41-6682758dfd28: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9b22be78-f687-11e9-8e41-6682758dfd28 in namespace emptydir-wrapper-5111, will wait for the garbage collector to delete the pods
Oct 24 17:56:44.663: INFO: Deleting ReplicationController wrapped-volume-race-9b22be78-f687-11e9-8e41-6682758dfd28 took: 10.556652ms
Oct 24 17:56:45.163: INFO: Terminating ReplicationController wrapped-volume-race-9b22be78-f687-11e9-8e41-6682758dfd28 pods took: 500.404237ms
STEP: Creating RC which spawns configmap-volume pods
Oct 24 17:57:21.685: INFO: Pod name wrapped-volume-race-ba3627e3-f687-11e9-8e41-6682758dfd28: Found 0 pods out of 5
Oct 24 17:57:26.694: INFO: Pod name wrapped-volume-race-ba3627e3-f687-11e9-8e41-6682758dfd28: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-ba3627e3-f687-11e9-8e41-6682758dfd28 in namespace emptydir-wrapper-5111, will wait for the garbage collector to delete the pods
Oct 24 17:57:36.803: INFO: Deleting ReplicationController wrapped-volume-race-ba3627e3-f687-11e9-8e41-6682758dfd28 took: 9.524852ms
Oct 24 17:57:37.303: INFO: Terminating ReplicationController wrapped-volume-race-ba3627e3-f687-11e9-8e41-6682758dfd28 pods took: 500.438698ms
STEP: Creating RC which spawns configmap-volume pods
Oct 24 17:58:19.230: INFO: Pod name wrapped-volume-race-dc8221a9-f687-11e9-8e41-6682758dfd28: Found 0 pods out of 5
Oct 24 17:58:24.240: INFO: Pod name wrapped-volume-race-dc8221a9-f687-11e9-8e41-6682758dfd28: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-dc8221a9-f687-11e9-8e41-6682758dfd28 in namespace emptydir-wrapper-5111, will wait for the garbage collector to delete the pods
Oct 24 17:58:34.345: INFO: Deleting ReplicationController wrapped-volume-race-dc8221a9-f687-11e9-8e41-6682758dfd28 took: 10.684363ms
Oct 24 17:58:34.845: INFO: Terminating ReplicationController wrapped-volume-race-dc8221a9-f687-11e9-8e41-6682758dfd28 pods took: 500.483909ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:59:10.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5111" for this suite.
Oct 24 17:59:18.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:59:18.311: INFO: namespace emptydir-wrapper-5111 deletion completed in 8.172972696s

• [SLOW TEST:169.078 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:59:18.311: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 24 17:59:18.370: INFO: Waiting up to 5m0s for pod "pod-ffc4ecad-f687-11e9-8e41-6682758dfd28" in namespace "emptydir-1947" to be "success or failure"
Oct 24 17:59:18.376: INFO: Pod "pod-ffc4ecad-f687-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.672851ms
Oct 24 17:59:20.382: INFO: Pod "pod-ffc4ecad-f687-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011338485s
STEP: Saw pod success
Oct 24 17:59:20.382: INFO: Pod "pod-ffc4ecad-f687-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:59:20.386: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-ffc4ecad-f687-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 17:59:20.416: INFO: Waiting for pod pod-ffc4ecad-f687-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:59:20.421: INFO: Pod pod-ffc4ecad-f687-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:59:20.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1947" for this suite.
Oct 24 17:59:26.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:59:26.593: INFO: namespace emptydir-1947 deletion completed in 6.166562694s

• [SLOW TEST:8.282 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:59:26.593: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-04b40aff-f688-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume secrets
Oct 24 17:59:26.655: INFO: Waiting up to 5m0s for pod "pod-secrets-04b4e15d-f688-11e9-8e41-6682758dfd28" in namespace "secrets-4130" to be "success or failure"
Oct 24 17:59:26.672: INFO: Pod "pod-secrets-04b4e15d-f688-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 17.666398ms
Oct 24 17:59:28.678: INFO: Pod "pod-secrets-04b4e15d-f688-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023706198s
STEP: Saw pod success
Oct 24 17:59:28.678: INFO: Pod "pod-secrets-04b4e15d-f688-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 17:59:28.682: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-secrets-04b4e15d-f688-11e9-8e41-6682758dfd28 container secret-volume-test: <nil>
STEP: delete the pod
Oct 24 17:59:28.711: INFO: Waiting for pod pod-secrets-04b4e15d-f688-11e9-8e41-6682758dfd28 to disappear
Oct 24 17:59:28.714: INFO: Pod pod-secrets-04b4e15d-f688-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:59:28.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4130" for this suite.
Oct 24 17:59:34.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:59:34.884: INFO: namespace secrets-4130 deletion completed in 6.165354417s

• [SLOW TEST:8.291 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:59:34.885: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1576
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 24 17:59:34.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-6813'
Oct 24 17:59:35.241: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 24 17:59:35.241: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1581
Oct 24 17:59:35.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 delete jobs e2e-test-nginx-job --namespace=kubectl-6813'
Oct 24 17:59:35.431: INFO: stderr: ""
Oct 24 17:59:35.431: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:59:35.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6813" for this suite.
Oct 24 17:59:41.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:59:41.604: INFO: namespace kubectl-6813 deletion completed in 6.16741249s

• [SLOW TEST:6.720 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:59:41.605: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 17:59:41.666: INFO: (0) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 9.214604ms)
Oct 24 17:59:41.671: INFO: (1) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.658265ms)
Oct 24 17:59:41.678: INFO: (2) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 6.288147ms)
Oct 24 17:59:41.684: INFO: (3) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.847358ms)
Oct 24 17:59:41.693: INFO: (4) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 9.698954ms)
Oct 24 17:59:41.707: INFO: (5) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 13.129064ms)
Oct 24 17:59:41.713: INFO: (6) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.983381ms)
Oct 24 17:59:41.719: INFO: (7) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 6.119486ms)
Oct 24 17:59:41.725: INFO: (8) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.859739ms)
Oct 24 17:59:41.731: INFO: (9) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.910059ms)
Oct 24 17:59:41.736: INFO: (10) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.610028ms)
Oct 24 17:59:41.743: INFO: (11) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 6.50843ms)
Oct 24 17:59:41.749: INFO: (12) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.541952ms)
Oct 24 17:59:41.754: INFO: (13) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.417845ms)
Oct 24 17:59:41.759: INFO: (14) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.429192ms)
Oct 24 17:59:41.765: INFO: (15) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.184829ms)
Oct 24 17:59:41.771: INFO: (16) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.70062ms)
Oct 24 17:59:41.776: INFO: (17) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.103674ms)
Oct 24 17:59:41.781: INFO: (18) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.594333ms)
Oct 24 17:59:41.786: INFO: (19) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.076504ms)
[AfterEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 17:59:41.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-645" for this suite.
Oct 24 17:59:47.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 17:59:47.968: INFO: namespace proxy-645 deletion completed in 6.177106333s

• [SLOW TEST:6.363 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 17:59:47.968: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Oct 24 17:59:48.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 create -f - --namespace=kubectl-4973'
Oct 24 17:59:48.342: INFO: stderr: ""
Oct 24 17:59:48.342: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 24 17:59:48.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4973'
Oct 24 17:59:48.521: INFO: stderr: ""
Oct 24 17:59:48.521: INFO: stdout: "update-demo-nautilus-bdjxj update-demo-nautilus-hhlrl "
Oct 24 17:59:48.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-bdjxj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4973'
Oct 24 17:59:48.687: INFO: stderr: ""
Oct 24 17:59:48.687: INFO: stdout: ""
Oct 24 17:59:48.687: INFO: update-demo-nautilus-bdjxj is created but not running
Oct 24 17:59:53.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4973'
Oct 24 17:59:53.852: INFO: stderr: ""
Oct 24 17:59:53.852: INFO: stdout: "update-demo-nautilus-bdjxj update-demo-nautilus-hhlrl "
Oct 24 17:59:53.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-bdjxj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4973'
Oct 24 17:59:54.016: INFO: stderr: ""
Oct 24 17:59:54.016: INFO: stdout: "true"
Oct 24 17:59:54.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-bdjxj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4973'
Oct 24 17:59:54.183: INFO: stderr: ""
Oct 24 17:59:54.183: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 17:59:54.183: INFO: validating pod update-demo-nautilus-bdjxj
Oct 24 17:59:54.191: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 17:59:54.191: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 17:59:54.191: INFO: update-demo-nautilus-bdjxj is verified up and running
Oct 24 17:59:54.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-hhlrl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4973'
Oct 24 17:59:54.360: INFO: stderr: ""
Oct 24 17:59:54.360: INFO: stdout: "true"
Oct 24 17:59:54.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-nautilus-hhlrl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4973'
Oct 24 17:59:54.514: INFO: stderr: ""
Oct 24 17:59:54.514: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 17:59:54.514: INFO: validating pod update-demo-nautilus-hhlrl
Oct 24 17:59:54.521: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 17:59:54.521: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 17:59:54.521: INFO: update-demo-nautilus-hhlrl is verified up and running
STEP: rolling-update to new replication controller
Oct 24 17:59:54.524: INFO: scanned /root for discovery docs: <nil>
Oct 24 17:59:54.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-4973'
Oct 24 18:00:17.171: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 24 18:00:17.171: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 24 18:00:17.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4973'
Oct 24 18:00:17.347: INFO: stderr: ""
Oct 24 18:00:17.347: INFO: stdout: "update-demo-kitten-8rtl7 update-demo-kitten-dgsn9 "
Oct 24 18:00:17.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-kitten-8rtl7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4973'
Oct 24 18:00:17.516: INFO: stderr: ""
Oct 24 18:00:17.516: INFO: stdout: "true"
Oct 24 18:00:17.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-kitten-8rtl7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4973'
Oct 24 18:00:17.693: INFO: stderr: ""
Oct 24 18:00:17.693: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 24 18:00:17.693: INFO: validating pod update-demo-kitten-8rtl7
Oct 24 18:00:17.701: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 24 18:00:17.701: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 24 18:00:17.701: INFO: update-demo-kitten-8rtl7 is verified up and running
Oct 24 18:00:17.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-kitten-dgsn9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4973'
Oct 24 18:00:17.869: INFO: stderr: ""
Oct 24 18:00:17.869: INFO: stdout: "true"
Oct 24 18:00:17.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods update-demo-kitten-dgsn9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4973'
Oct 24 18:00:18.033: INFO: stderr: ""
Oct 24 18:00:18.033: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 24 18:00:18.033: INFO: validating pod update-demo-kitten-dgsn9
Oct 24 18:00:18.040: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 24 18:00:18.041: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 24 18:00:18.041: INFO: update-demo-kitten-dgsn9 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:00:18.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4973" for this suite.
Oct 24 18:00:40.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:00:40.249: INFO: namespace kubectl-4973 deletion completed in 22.202928023s

• [SLOW TEST:52.280 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:00:40.249: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:00:40.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7108" for this suite.
Oct 24 18:00:46.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:00:46.467: INFO: namespace services-7108 deletion completed in 6.161692073s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.218 seconds]
[sig-network] Services
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:00:46.467: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:00:49.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8768" for this suite.
Oct 24 18:01:11.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:01:11.748: INFO: namespace replication-controller-8768 deletion completed in 22.170106437s

• [SLOW TEST:25.281 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:01:11.748: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 18:01:11.805: INFO: Waiting up to 5m0s for pod "downwardapi-volume-43616550-f688-11e9-8e41-6682758dfd28" in namespace "downward-api-9966" to be "success or failure"
Oct 24 18:01:11.809: INFO: Pod "downwardapi-volume-43616550-f688-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.392926ms
Oct 24 18:01:13.816: INFO: Pod "downwardapi-volume-43616550-f688-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01129453s
STEP: Saw pod success
Oct 24 18:01:13.816: INFO: Pod "downwardapi-volume-43616550-f688-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:01:13.821: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-43616550-f688-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 18:01:13.851: INFO: Waiting for pod downwardapi-volume-43616550-f688-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:01:13.856: INFO: Pod downwardapi-volume-43616550-f688-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:01:13.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9966" for this suite.
Oct 24 18:01:19.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:01:20.036: INFO: namespace downward-api-9966 deletion completed in 6.174620098s

• [SLOW TEST:8.287 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:01:20.037: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-48544909-f688-11e9-8e41-6682758dfd28
STEP: Creating configMap with name cm-test-opt-upd-4854499d-f688-11e9-8e41-6682758dfd28
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-48544909-f688-11e9-8e41-6682758dfd28
STEP: Updating configmap cm-test-opt-upd-4854499d-f688-11e9-8e41-6682758dfd28
STEP: Creating configMap with name cm-test-opt-create-485449e4-f688-11e9-8e41-6682758dfd28
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:01:24.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-280" for this suite.
Oct 24 18:01:46.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:01:46.418: INFO: namespace projected-280 deletion completed in 22.159055103s

• [SLOW TEST:26.382 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:01:46.418: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:01:48.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3347" for this suite.
Oct 24 18:02:36.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:02:36.677: INFO: namespace kubelet-test-3347 deletion completed in 48.172438345s

• [SLOW TEST:50.259 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:02:36.678: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-7601bd02-f688-11e9-8e41-6682758dfd28
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-7601bd02-f688-11e9-8e41-6682758dfd28
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:03:45.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8401" for this suite.
Oct 24 18:04:03.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:04:03.487: INFO: namespace projected-8401 deletion completed in 18.171085813s

• [SLOW TEST:86.809 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:04:03.488: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-a9bec1f2-f688-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume secrets
Oct 24 18:04:03.549: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a9bf7aef-f688-11e9-8e41-6682758dfd28" in namespace "projected-6314" to be "success or failure"
Oct 24 18:04:03.554: INFO: Pod "pod-projected-secrets-a9bf7aef-f688-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.845969ms
Oct 24 18:04:05.558: INFO: Pod "pod-projected-secrets-a9bf7aef-f688-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009364011s
STEP: Saw pod success
Oct 24 18:04:05.559: INFO: Pod "pod-projected-secrets-a9bf7aef-f688-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:04:05.562: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-projected-secrets-a9bf7aef-f688-11e9-8e41-6682758dfd28 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 24 18:04:05.586: INFO: Waiting for pod pod-projected-secrets-a9bf7aef-f688-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:04:05.591: INFO: Pod pod-projected-secrets-a9bf7aef-f688-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:04:05.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6314" for this suite.
Oct 24 18:04:11.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:04:11.761: INFO: namespace projected-6314 deletion completed in 6.164783638s

• [SLOW TEST:8.273 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:04:11.761: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 18:04:11.816: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aead1166-f688-11e9-8e41-6682758dfd28" in namespace "downward-api-9090" to be "success or failure"
Oct 24 18:04:11.820: INFO: Pod "downwardapi-volume-aead1166-f688-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 3.716205ms
Oct 24 18:04:13.827: INFO: Pod "downwardapi-volume-aead1166-f688-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.010162978s
Oct 24 18:04:15.832: INFO: Pod "downwardapi-volume-aead1166-f688-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016016562s
STEP: Saw pod success
Oct 24 18:04:15.833: INFO: Pod "downwardapi-volume-aead1166-f688-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:04:15.837: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-aead1166-f688-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 18:04:15.864: INFO: Waiting for pod downwardapi-volume-aead1166-f688-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:04:15.869: INFO: Pod downwardapi-volume-aead1166-f688-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:04:15.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9090" for this suite.
Oct 24 18:04:21.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:04:22.042: INFO: namespace downward-api-9090 deletion completed in 6.166970127s

• [SLOW TEST:10.281 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:04:22.043: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1174
STEP: creating the pod
Oct 24 18:04:22.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 create -f - --namespace=kubectl-3928'
Oct 24 18:04:22.449: INFO: stderr: ""
Oct 24 18:04:22.449: INFO: stdout: "pod/pause created\n"
Oct 24 18:04:22.449: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct 24 18:04:22.449: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3928" to be "running and ready"
Oct 24 18:04:22.455: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.945454ms
Oct 24 18:04:24.461: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.011707081s
Oct 24 18:04:24.461: INFO: Pod "pause" satisfied condition "running and ready"
Oct 24 18:04:24.461: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Oct 24 18:04:24.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 label pods pause testing-label=testing-label-value --namespace=kubectl-3928'
Oct 24 18:04:24.639: INFO: stderr: ""
Oct 24 18:04:24.639: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Oct 24 18:04:24.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pod pause -L testing-label --namespace=kubectl-3928'
Oct 24 18:04:24.815: INFO: stderr: ""
Oct 24 18:04:24.815: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Oct 24 18:04:24.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 label pods pause testing-label- --namespace=kubectl-3928'
Oct 24 18:04:24.953: INFO: stderr: ""
Oct 24 18:04:24.953: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Oct 24 18:04:24.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pod pause -L testing-label --namespace=kubectl-3928'
Oct 24 18:04:25.131: INFO: stderr: ""
Oct 24 18:04:25.132: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1181
STEP: using delete to clean up resources
Oct 24 18:04:25.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 delete --grace-period=0 --force -f - --namespace=kubectl-3928'
Oct 24 18:04:25.335: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 18:04:25.335: INFO: stdout: "pod \"pause\" force deleted\n"
Oct 24 18:04:25.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get rc,svc -l name=pause --no-headers --namespace=kubectl-3928'
Oct 24 18:04:25.521: INFO: stderr: "No resources found.\n"
Oct 24 18:04:25.521: INFO: stdout: ""
Oct 24 18:04:25.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods -l name=pause --namespace=kubectl-3928 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 24 18:04:25.727: INFO: stderr: ""
Oct 24 18:04:25.727: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:04:25.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3928" for this suite.
Oct 24 18:04:31.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:04:31.924: INFO: namespace kubectl-3928 deletion completed in 6.191034857s

• [SLOW TEST:9.882 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:04:31.924: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 24 18:04:34.524: INFO: Successfully updated pod "pod-update-activedeadlineseconds-bab3a21e-f688-11e9-8e41-6682758dfd28"
Oct 24 18:04:34.524: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-bab3a21e-f688-11e9-8e41-6682758dfd28" in namespace "pods-9861" to be "terminated due to deadline exceeded"
Oct 24 18:04:34.528: INFO: Pod "pod-update-activedeadlineseconds-bab3a21e-f688-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 3.663558ms
Oct 24 18:04:36.534: INFO: Pod "pod-update-activedeadlineseconds-bab3a21e-f688-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.009557426s
Oct 24 18:04:38.540: INFO: Pod "pod-update-activedeadlineseconds-bab3a21e-f688-11e9-8e41-6682758dfd28": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.015466701s
Oct 24 18:04:38.540: INFO: Pod "pod-update-activedeadlineseconds-bab3a21e-f688-11e9-8e41-6682758dfd28" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:04:38.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9861" for this suite.
Oct 24 18:04:44.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:04:44.721: INFO: namespace pods-9861 deletion completed in 6.175969806s

• [SLOW TEST:12.797 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:04:44.721: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 18:04:44.767: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:04:46.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5478" for this suite.
Oct 24 18:05:26.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:05:27.137: INFO: namespace pods-5478 deletion completed in 40.195835671s

• [SLOW TEST:42.416 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:05:27.138: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Oct 24 18:05:30.246: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:05:31.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5881" for this suite.
Oct 24 18:05:53.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:05:53.432: INFO: namespace replicaset-5881 deletion completed in 22.160323083s

• [SLOW TEST:26.293 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:05:53.433: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 18:05:53.478: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct 24 18:05:53.489: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 24 18:05:58.495: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 24 18:05:58.495: INFO: Creating deployment "test-rolling-update-deployment"
Oct 24 18:05:58.501: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct 24 18:05:58.511: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Oct 24 18:06:00.520: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct 24 18:06:00.524: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 24 18:06:00.537: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-9722,SelfLink:/apis/apps/v1/namespaces/deployment-9722/deployments/test-rolling-update-deployment,UID:ee44b200-f688-11e9-a6ac-005056ab7215,ResourceVersion:12742,Generation:1,CreationTimestamp:2019-10-24 18:05:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-24 18:05:58 +0000 UTC 2019-10-24 18:05:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-24 18:05:59 +0000 UTC 2019-10-24 18:05:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-57b6b5bb54" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 24 18:06:00.541: INFO: New ReplicaSet "test-rolling-update-deployment-57b6b5bb54" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54,GenerateName:,Namespace:deployment-9722,SelfLink:/apis/apps/v1/namespaces/deployment-9722/replicasets/test-rolling-update-deployment-57b6b5bb54,UID:ee47d918-f688-11e9-a6ac-005056ab7215,ResourceVersion:12731,Generation:1,CreationTimestamp:2019-10-24 18:05:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ee44b200-f688-11e9-a6ac-005056ab7215 0xc002bc61f7 0xc002bc61f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 24 18:06:00.542: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct 24 18:06:00.542: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-9722,SelfLink:/apis/apps/v1/namespaces/deployment-9722/replicasets/test-rolling-update-controller,UID:eb47777c-f688-11e9-a6ac-005056ab7215,ResourceVersion:12740,Generation:2,CreationTimestamp:2019-10-24 18:05:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ee44b200-f688-11e9-a6ac-005056ab7215 0xc002bc6127 0xc002bc6128}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 24 18:06:00.550: INFO: Pod "test-rolling-update-deployment-57b6b5bb54-gbphd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54-gbphd,GenerateName:test-rolling-update-deployment-57b6b5bb54-,Namespace:deployment-9722,SelfLink:/api/v1/namespaces/deployment-9722/pods/test-rolling-update-deployment-57b6b5bb54-gbphd,UID:ee48cea7-f688-11e9-a6ac-005056ab7215,ResourceVersion:12730,Generation:0,CreationTimestamp:2019-10-24 18:05:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.1.103/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-57b6b5bb54 ee47d918-f688-11e9-a6ac-005056ab7215 0xc002f5d1c7 0xc002f5d1c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-x5lzw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-x5lzw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-x5lzw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f5d230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f5d250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:05:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:05:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:05:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:05:58 +0000 UTC  }],Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.1.103,StartTime:2019-10-24 18:05:58 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-24 18:05:59 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e17725e7790cc770a20d1906e1415679ea8280a28b3ff6189f08435502157c1b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:06:00.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9722" for this suite.
Oct 24 18:06:06.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:06:06.720: INFO: namespace deployment-9722 deletion completed in 6.164165695s

• [SLOW TEST:13.287 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:06:06.721: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-f3335878-f688-11e9-8e41-6682758dfd28
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-f3335878-f688-11e9-8e41-6682758dfd28
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:06:10.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7237" for this suite.
Oct 24 18:06:32.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:06:33.023: INFO: namespace configmap-7237 deletion completed in 22.168783048s

• [SLOW TEST:26.302 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:06:33.023: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 24 18:06:33.094: INFO: Waiting up to 5m0s for pod "pod-02e21fbb-f689-11e9-8e41-6682758dfd28" in namespace "emptydir-6297" to be "success or failure"
Oct 24 18:06:33.098: INFO: Pod "pod-02e21fbb-f689-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.284478ms
Oct 24 18:06:35.103: INFO: Pod "pod-02e21fbb-f689-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009368107s
STEP: Saw pod success
Oct 24 18:06:35.103: INFO: Pod "pod-02e21fbb-f689-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:06:35.108: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-02e21fbb-f689-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 18:06:35.136: INFO: Waiting for pod pod-02e21fbb-f689-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:06:35.139: INFO: Pod pod-02e21fbb-f689-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:06:35.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6297" for this suite.
Oct 24 18:06:41.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:06:41.313: INFO: namespace emptydir-6297 deletion completed in 6.168303626s

• [SLOW TEST:8.290 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:06:41.313: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-5165/secret-test-07d14b97-f689-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume secrets
Oct 24 18:06:41.375: INFO: Waiting up to 5m0s for pod "pod-configmaps-07d1fe5c-f689-11e9-8e41-6682758dfd28" in namespace "secrets-5165" to be "success or failure"
Oct 24 18:06:41.379: INFO: Pod "pod-configmaps-07d1fe5c-f689-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.259482ms
Oct 24 18:06:43.385: INFO: Pod "pod-configmaps-07d1fe5c-f689-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.010507418s
Oct 24 18:06:45.392: INFO: Pod "pod-configmaps-07d1fe5c-f689-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017236401s
STEP: Saw pod success
Oct 24 18:06:45.392: INFO: Pod "pod-configmaps-07d1fe5c-f689-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:06:45.397: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-07d1fe5c-f689-11e9-8e41-6682758dfd28 container env-test: <nil>
STEP: delete the pod
Oct 24 18:06:45.430: INFO: Waiting for pod pod-configmaps-07d1fe5c-f689-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:06:45.436: INFO: Pod pod-configmaps-07d1fe5c-f689-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:06:45.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5165" for this suite.
Oct 24 18:06:51.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:06:51.611: INFO: namespace secrets-5165 deletion completed in 6.168394859s

• [SLOW TEST:10.298 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:06:51.612: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-0df50e0d-f689-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume secrets
Oct 24 18:06:51.675: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0df5c508-f689-11e9-8e41-6682758dfd28" in namespace "projected-6687" to be "success or failure"
Oct 24 18:06:51.680: INFO: Pod "pod-projected-secrets-0df5c508-f689-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.986522ms
Oct 24 18:06:53.685: INFO: Pod "pod-projected-secrets-0df5c508-f689-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009895122s
STEP: Saw pod success
Oct 24 18:06:53.685: INFO: Pod "pod-projected-secrets-0df5c508-f689-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:06:53.689: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-projected-secrets-0df5c508-f689-11e9-8e41-6682758dfd28 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 24 18:06:53.713: INFO: Waiting for pod pod-projected-secrets-0df5c508-f689-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:06:53.718: INFO: Pod pod-projected-secrets-0df5c508-f689-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:06:53.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6687" for this suite.
Oct 24 18:06:59.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:06:59.893: INFO: namespace projected-6687 deletion completed in 6.170413123s

• [SLOW TEST:8.281 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:06:59.893: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-pn5t
STEP: Creating a pod to test atomic-volume-subpath
Oct 24 18:06:59.993: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-pn5t" in namespace "subpath-8835" to be "success or failure"
Oct 24 18:06:59.998: INFO: Pod "pod-subpath-test-configmap-pn5t": Phase="Pending", Reason="", readiness=false. Elapsed: 4.839691ms
Oct 24 18:07:02.004: INFO: Pod "pod-subpath-test-configmap-pn5t": Phase="Running", Reason="", readiness=true. Elapsed: 2.011071906s
Oct 24 18:07:04.010: INFO: Pod "pod-subpath-test-configmap-pn5t": Phase="Running", Reason="", readiness=true. Elapsed: 4.016441572s
Oct 24 18:07:06.014: INFO: Pod "pod-subpath-test-configmap-pn5t": Phase="Running", Reason="", readiness=true. Elapsed: 6.021150336s
Oct 24 18:07:08.020: INFO: Pod "pod-subpath-test-configmap-pn5t": Phase="Running", Reason="", readiness=true. Elapsed: 8.026662211s
Oct 24 18:07:10.026: INFO: Pod "pod-subpath-test-configmap-pn5t": Phase="Running", Reason="", readiness=true. Elapsed: 10.033037671s
Oct 24 18:07:12.032: INFO: Pod "pod-subpath-test-configmap-pn5t": Phase="Running", Reason="", readiness=true. Elapsed: 12.038880736s
Oct 24 18:07:14.038: INFO: Pod "pod-subpath-test-configmap-pn5t": Phase="Running", Reason="", readiness=true. Elapsed: 14.044847188s
Oct 24 18:07:16.044: INFO: Pod "pod-subpath-test-configmap-pn5t": Phase="Running", Reason="", readiness=true. Elapsed: 16.05076436s
Oct 24 18:07:18.050: INFO: Pod "pod-subpath-test-configmap-pn5t": Phase="Running", Reason="", readiness=true. Elapsed: 18.05700151s
Oct 24 18:07:20.056: INFO: Pod "pod-subpath-test-configmap-pn5t": Phase="Running", Reason="", readiness=true. Elapsed: 20.063159881s
Oct 24 18:07:22.062: INFO: Pod "pod-subpath-test-configmap-pn5t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.069333076s
STEP: Saw pod success
Oct 24 18:07:22.063: INFO: Pod "pod-subpath-test-configmap-pn5t" satisfied condition "success or failure"
Oct 24 18:07:22.066: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-subpath-test-configmap-pn5t container test-container-subpath-configmap-pn5t: <nil>
STEP: delete the pod
Oct 24 18:07:22.098: INFO: Waiting for pod pod-subpath-test-configmap-pn5t to disappear
Oct 24 18:07:22.102: INFO: Pod pod-subpath-test-configmap-pn5t no longer exists
STEP: Deleting pod pod-subpath-test-configmap-pn5t
Oct 24 18:07:22.102: INFO: Deleting pod "pod-subpath-test-configmap-pn5t" in namespace "subpath-8835"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:07:22.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8835" for this suite.
Oct 24 18:07:28.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:07:28.306: INFO: namespace subpath-8835 deletion completed in 6.19523881s

• [SLOW TEST:28.413 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:07:28.306: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1256
STEP: creating an rc
Oct 24 18:07:28.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 create -f - --namespace=kubectl-7619'
Oct 24 18:07:28.669: INFO: stderr: ""
Oct 24 18:07:28.669: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Oct 24 18:07:29.674: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 18:07:29.674: INFO: Found 0 / 1
Oct 24 18:07:30.674: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 18:07:30.674: INFO: Found 1 / 1
Oct 24 18:07:30.674: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 24 18:07:30.679: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 18:07:30.679: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Oct 24 18:07:30.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 logs redis-master-z7m5q redis-master --namespace=kubectl-7619'
Oct 24 18:07:30.874: INFO: stderr: ""
Oct 24 18:07:30.874: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 24 Oct 18:07:29.691 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 24 Oct 18:07:29.691 # Server started, Redis version 3.2.12\n1:M 24 Oct 18:07:29.691 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Oct 24 18:07:30.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 log redis-master-z7m5q redis-master --namespace=kubectl-7619 --tail=1'
Oct 24 18:07:31.063: INFO: stderr: ""
Oct 24 18:07:31.063: INFO: stdout: "1:M 24 Oct 18:07:29.691 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Oct 24 18:07:31.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 log redis-master-z7m5q redis-master --namespace=kubectl-7619 --limit-bytes=1'
Oct 24 18:07:31.255: INFO: stderr: ""
Oct 24 18:07:31.255: INFO: stdout: " "
STEP: exposing timestamps
Oct 24 18:07:31.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 log redis-master-z7m5q redis-master --namespace=kubectl-7619 --tail=1 --timestamps'
Oct 24 18:07:31.446: INFO: stderr: ""
Oct 24 18:07:31.446: INFO: stdout: "2019-10-24T18:07:29.692347204Z 1:M 24 Oct 18:07:29.691 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Oct 24 18:07:33.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 log redis-master-z7m5q redis-master --namespace=kubectl-7619 --since=1s'
Oct 24 18:07:34.140: INFO: stderr: ""
Oct 24 18:07:34.140: INFO: stdout: ""
Oct 24 18:07:34.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 log redis-master-z7m5q redis-master --namespace=kubectl-7619 --since=24h'
Oct 24 18:07:34.341: INFO: stderr: ""
Oct 24 18:07:34.341: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 24 Oct 18:07:29.691 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 24 Oct 18:07:29.691 # Server started, Redis version 3.2.12\n1:M 24 Oct 18:07:29.691 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
STEP: using delete to clean up resources
Oct 24 18:07:34.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 delete --grace-period=0 --force -f - --namespace=kubectl-7619'
Oct 24 18:07:34.511: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 18:07:34.511: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Oct 24 18:07:34.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get rc,svc -l name=nginx --no-headers --namespace=kubectl-7619'
Oct 24 18:07:34.684: INFO: stderr: "No resources found.\n"
Oct 24 18:07:34.684: INFO: stdout: ""
Oct 24 18:07:34.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pods -l name=nginx --namespace=kubectl-7619 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 24 18:07:34.853: INFO: stderr: ""
Oct 24 18:07:34.853: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:07:34.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7619" for this suite.
Oct 24 18:07:56.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:07:57.064: INFO: namespace kubectl-7619 deletion completed in 22.204071917s

• [SLOW TEST:28.758 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:07:57.065: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-34fa95cd-f689-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume secrets
Oct 24 18:07:57.146: INFO: Waiting up to 5m0s for pod "pod-secrets-34fbd451-f689-11e9-8e41-6682758dfd28" in namespace "secrets-8237" to be "success or failure"
Oct 24 18:07:57.153: INFO: Pod "pod-secrets-34fbd451-f689-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 6.441863ms
Oct 24 18:07:59.159: INFO: Pod "pod-secrets-34fbd451-f689-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013149722s
STEP: Saw pod success
Oct 24 18:07:59.159: INFO: Pod "pod-secrets-34fbd451-f689-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:07:59.163: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-secrets-34fbd451-f689-11e9-8e41-6682758dfd28 container secret-volume-test: <nil>
STEP: delete the pod
Oct 24 18:07:59.197: INFO: Waiting for pod pod-secrets-34fbd451-f689-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:07:59.203: INFO: Pod pod-secrets-34fbd451-f689-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:07:59.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8237" for this suite.
Oct 24 18:08:05.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:08:05.377: INFO: namespace secrets-8237 deletion completed in 6.169037464s

• [SLOW TEST:8.313 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:08:05.378: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-39ec5e0b-f689-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume configMaps
Oct 24 18:08:05.443: INFO: Waiting up to 5m0s for pod "pod-configmaps-39ed2170-f689-11e9-8e41-6682758dfd28" in namespace "configmap-2032" to be "success or failure"
Oct 24 18:08:05.449: INFO: Pod "pod-configmaps-39ed2170-f689-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.950744ms
Oct 24 18:08:07.455: INFO: Pod "pod-configmaps-39ed2170-f689-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011696323s
STEP: Saw pod success
Oct 24 18:08:07.455: INFO: Pod "pod-configmaps-39ed2170-f689-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:08:07.460: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-configmaps-39ed2170-f689-11e9-8e41-6682758dfd28 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 18:08:07.488: INFO: Waiting for pod pod-configmaps-39ed2170-f689-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:08:07.493: INFO: Pod pod-configmaps-39ed2170-f689-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:08:07.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2032" for this suite.
Oct 24 18:08:13.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:08:13.673: INFO: namespace configmap-2032 deletion completed in 6.174553033s

• [SLOW TEST:8.295 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:08:13.673: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 18:08:13.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 version'
Oct 24 18:08:13.922: INFO: stderr: ""
Oct 24 18:08:13.923: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.6\", GitCommit:\"96fac5cd13a5dc064f7d9f4f23030a6aeface6cc\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:13:49Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.6\", GitCommit:\"96fac5cd13a5dc064f7d9f4f23030a6aeface6cc\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:05:16Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:08:13.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-257" for this suite.
Oct 24 18:08:19.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:08:20.108: INFO: namespace kubectl-257 deletion completed in 6.179555206s

• [SLOW TEST:6.435 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:08:20.109: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-3026/configmap-test-42b580b7-f689-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume configMaps
Oct 24 18:08:20.189: INFO: Waiting up to 5m0s for pod "pod-configmaps-42b6b55b-f689-11e9-8e41-6682758dfd28" in namespace "configmap-3026" to be "success or failure"
Oct 24 18:08:20.197: INFO: Pod "pod-configmaps-42b6b55b-f689-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 8.165672ms
Oct 24 18:08:22.203: INFO: Pod "pod-configmaps-42b6b55b-f689-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014249514s
STEP: Saw pod success
Oct 24 18:08:22.203: INFO: Pod "pod-configmaps-42b6b55b-f689-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:08:22.207: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-42b6b55b-f689-11e9-8e41-6682758dfd28 container env-test: <nil>
STEP: delete the pod
Oct 24 18:08:22.242: INFO: Waiting for pod pod-configmaps-42b6b55b-f689-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:08:22.245: INFO: Pod pod-configmaps-42b6b55b-f689-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:08:22.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3026" for this suite.
Oct 24 18:08:28.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:08:28.433: INFO: namespace configmap-3026 deletion completed in 6.182852767s

• [SLOW TEST:8.324 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:08:28.433: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-7146
Oct 24 18:08:30.499: INFO: Started pod liveness-exec in namespace container-probe-7146
STEP: checking the pod's current state and verifying that restartCount is present
Oct 24 18:08:30.503: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:12:31.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7146" for this suite.
Oct 24 18:12:37.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:12:37.401: INFO: namespace container-probe-7146 deletion completed in 6.182103257s

• [SLOW TEST:248.968 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:12:37.402: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-dc10cc03-f689-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume secrets
Oct 24 18:12:37.467: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dc1173d7-f689-11e9-8e41-6682758dfd28" in namespace "projected-6307" to be "success or failure"
Oct 24 18:12:37.472: INFO: Pod "pod-projected-secrets-dc1173d7-f689-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.684365ms
Oct 24 18:12:39.478: INFO: Pod "pod-projected-secrets-dc1173d7-f689-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.010394246s
Oct 24 18:12:41.483: INFO: Pod "pod-projected-secrets-dc1173d7-f689-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015880802s
STEP: Saw pod success
Oct 24 18:12:41.483: INFO: Pod "pod-projected-secrets-dc1173d7-f689-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:12:41.487: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-secrets-dc1173d7-f689-11e9-8e41-6682758dfd28 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 24 18:12:41.524: INFO: Waiting for pod pod-projected-secrets-dc1173d7-f689-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:12:41.528: INFO: Pod pod-projected-secrets-dc1173d7-f689-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:12:41.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6307" for this suite.
Oct 24 18:12:47.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:12:47.693: INFO: namespace projected-6307 deletion completed in 6.160128337s

• [SLOW TEST:10.291 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:12:47.693: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-9044
Oct 24 18:12:49.762: INFO: Started pod liveness-exec in namespace container-probe-9044
STEP: checking the pod's current state and verifying that restartCount is present
Oct 24 18:12:49.766: INFO: Initial restart count of pod liveness-exec is 0
Oct 24 18:13:39.918: INFO: Restart count of pod container-probe-9044/liveness-exec is now 1 (50.152539221s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:13:39.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9044" for this suite.
Oct 24 18:13:45.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:13:46.110: INFO: namespace container-probe-9044 deletion completed in 6.169481758s

• [SLOW TEST:58.417 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:13:46.111: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 24 18:13:46.167: INFO: Waiting up to 5m0s for pod "pod-0504361e-f68a-11e9-8e41-6682758dfd28" in namespace "emptydir-6936" to be "success or failure"
Oct 24 18:13:46.173: INFO: Pod "pod-0504361e-f68a-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.979337ms
Oct 24 18:13:48.180: INFO: Pod "pod-0504361e-f68a-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.012703657s
Oct 24 18:13:50.186: INFO: Pod "pod-0504361e-f68a-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018729045s
STEP: Saw pod success
Oct 24 18:13:50.186: INFO: Pod "pod-0504361e-f68a-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:13:50.190: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-0504361e-f68a-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 18:13:50.221: INFO: Waiting for pod pod-0504361e-f68a-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:13:50.227: INFO: Pod pod-0504361e-f68a-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:13:50.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6936" for this suite.
Oct 24 18:13:56.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:13:56.411: INFO: namespace emptydir-6936 deletion completed in 6.178550392s

• [SLOW TEST:10.301 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:13:56.412: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct 24 18:13:56.469: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:13:59.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1778" for this suite.
Oct 24 18:14:05.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:14:05.848: INFO: namespace init-container-1778 deletion completed in 6.170386818s

• [SLOW TEST:9.437 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:14:05.849: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-10c7dacc-f68a-11e9-8e41-6682758dfd28
STEP: Creating secret with name secret-projected-all-test-volume-10c7daa5-f68a-11e9-8e41-6682758dfd28
STEP: Creating a pod to test Check all projections for projected volume plugin
Oct 24 18:14:05.916: INFO: Waiting up to 5m0s for pod "projected-volume-10c7da45-f68a-11e9-8e41-6682758dfd28" in namespace "projected-7228" to be "success or failure"
Oct 24 18:14:05.920: INFO: Pod "projected-volume-10c7da45-f68a-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.223277ms
Oct 24 18:14:07.926: INFO: Pod "projected-volume-10c7da45-f68a-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009822501s
STEP: Saw pod success
Oct 24 18:14:07.926: INFO: Pod "projected-volume-10c7da45-f68a-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:14:07.930: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod projected-volume-10c7da45-f68a-11e9-8e41-6682758dfd28 container projected-all-volume-test: <nil>
STEP: delete the pod
Oct 24 18:14:07.957: INFO: Waiting for pod projected-volume-10c7da45-f68a-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:14:07.961: INFO: Pod projected-volume-10c7da45-f68a-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:14:07.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7228" for this suite.
Oct 24 18:14:13.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:14:14.137: INFO: namespace projected-7228 deletion completed in 6.171198757s

• [SLOW TEST:8.289 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:14:14.137: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct 24 18:14:16.747: INFO: Successfully updated pod "annotationupdate15b8973d-f68a-11e9-8e41-6682758dfd28"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:14:18.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1893" for this suite.
Oct 24 18:14:40.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:14:40.943: INFO: namespace downward-api-1893 deletion completed in 22.16274527s

• [SLOW TEST:26.806 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:14:40.944: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Oct 24 18:14:41.000: INFO: Waiting up to 5m0s for pod "client-containers-25b2f167-f68a-11e9-8e41-6682758dfd28" in namespace "containers-9607" to be "success or failure"
Oct 24 18:14:41.004: INFO: Pod "client-containers-25b2f167-f68a-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.271626ms
Oct 24 18:14:43.010: INFO: Pod "client-containers-25b2f167-f68a-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010392991s
Oct 24 18:14:45.021: INFO: Pod "client-containers-25b2f167-f68a-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021474922s
STEP: Saw pod success
Oct 24 18:14:45.021: INFO: Pod "client-containers-25b2f167-f68a-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:14:45.025: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod client-containers-25b2f167-f68a-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 18:14:45.058: INFO: Waiting for pod client-containers-25b2f167-f68a-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:14:45.062: INFO: Pod client-containers-25b2f167-f68a-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:14:45.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9607" for this suite.
Oct 24 18:14:51.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:14:51.265: INFO: namespace containers-9607 deletion completed in 6.197736128s

• [SLOW TEST:10.322 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:14:51.266: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 18:14:51.321: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2bd9ba4c-f68a-11e9-8e41-6682758dfd28" in namespace "downward-api-7953" to be "success or failure"
Oct 24 18:14:51.325: INFO: Pod "downwardapi-volume-2bd9ba4c-f68a-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 3.943012ms
Oct 24 18:14:53.331: INFO: Pod "downwardapi-volume-2bd9ba4c-f68a-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009922339s
Oct 24 18:14:55.337: INFO: Pod "downwardapi-volume-2bd9ba4c-f68a-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01562354s
STEP: Saw pod success
Oct 24 18:14:55.337: INFO: Pod "downwardapi-volume-2bd9ba4c-f68a-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:14:55.341: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-2bd9ba4c-f68a-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 18:14:55.368: INFO: Waiting for pod downwardapi-volume-2bd9ba4c-f68a-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:14:55.372: INFO: Pod downwardapi-volume-2bd9ba4c-f68a-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:14:55.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7953" for this suite.
Oct 24 18:15:01.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:15:01.542: INFO: namespace downward-api-7953 deletion completed in 6.162809485s

• [SLOW TEST:10.276 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:15:01.542: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-8913
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-8913
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8913
Oct 24 18:15:01.620: INFO: Found 0 stateful pods, waiting for 1
Oct 24 18:15:11.627: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Oct 24 18:15:11.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-8913 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 24 18:15:11.946: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 24 18:15:11.946: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 24 18:15:11.946: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 24 18:15:11.951: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 24 18:15:21.957: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 18:15:21.957: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 18:15:21.977: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 24 18:15:21.977: INFO: ss-0  mip-bd-vm40.mip.storage.hpecorp.net  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:01 +0000 UTC  }]
Oct 24 18:15:21.977: INFO: 
Oct 24 18:15:21.977: INFO: StatefulSet ss has not reached scale 3, at 1
Oct 24 18:15:22.982: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993720987s
Oct 24 18:15:23.989: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988027516s
Oct 24 18:15:24.994: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981387178s
Oct 24 18:15:26.000: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.976002969s
Oct 24 18:15:27.006: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.970464394s
Oct 24 18:15:28.013: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.964044943s
Oct 24 18:15:29.021: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.956841065s
Oct 24 18:15:30.028: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.949013329s
Oct 24 18:15:31.034: INFO: Verifying statefulset ss doesn't scale past 3 for another 942.318927ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8913
Oct 24 18:15:32.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-8913 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 24 18:15:32.378: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 24 18:15:32.378: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 24 18:15:32.378: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 24 18:15:32.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-8913 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 24 18:15:32.693: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 24 18:15:32.693: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 24 18:15:32.693: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 24 18:15:32.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-8913 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 24 18:15:33.011: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 24 18:15:33.011: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 24 18:15:33.011: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 24 18:15:33.016: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 18:15:33.016: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 18:15:33.016: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Oct 24 18:15:33.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-8913 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 24 18:15:33.350: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 24 18:15:33.350: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 24 18:15:33.350: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 24 18:15:33.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-8913 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 24 18:15:33.666: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 24 18:15:33.666: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 24 18:15:33.666: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 24 18:15:33.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 exec --namespace=statefulset-8913 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 24 18:15:33.982: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 24 18:15:33.982: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 24 18:15:33.982: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 24 18:15:33.982: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 18:15:33.987: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct 24 18:15:43.997: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 18:15:43.997: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 18:15:43.997: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 18:15:44.016: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 24 18:15:44.016: INFO: ss-0  mip-bd-vm40.mip.storage.hpecorp.net  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:01 +0000 UTC  }]
Oct 24 18:15:44.016: INFO: ss-1  mip-bd-vm41.mip.storage.hpecorp.net  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:21 +0000 UTC  }]
Oct 24 18:15:44.016: INFO: ss-2  mip-bd-vm41.mip.storage.hpecorp.net  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:21 +0000 UTC  }]
Oct 24 18:15:44.016: INFO: 
Oct 24 18:15:44.016: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 24 18:15:45.023: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 24 18:15:45.023: INFO: ss-0  mip-bd-vm40.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:01 +0000 UTC  }]
Oct 24 18:15:45.023: INFO: ss-1  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:21 +0000 UTC  }]
Oct 24 18:15:45.023: INFO: ss-2  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:21 +0000 UTC  }]
Oct 24 18:15:45.023: INFO: 
Oct 24 18:15:45.023: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 24 18:15:46.029: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 24 18:15:46.029: INFO: ss-1  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:21 +0000 UTC  }]
Oct 24 18:15:46.029: INFO: ss-2  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 18:15:21 +0000 UTC  }]
Oct 24 18:15:46.029: INFO: 
Oct 24 18:15:46.029: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 24 18:15:47.035: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.980750123s
Oct 24 18:15:48.040: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.975020797s
Oct 24 18:15:49.045: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.969738833s
Oct 24 18:15:50.050: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.964615321s
Oct 24 18:15:51.055: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.959706667s
Oct 24 18:15:52.061: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.95438125s
Oct 24 18:15:53.067: INFO: Verifying statefulset ss doesn't scale past 0 for another 948.326277ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8913
Oct 24 18:15:54.073: INFO: Scaling statefulset ss to 0
Oct 24 18:15:54.087: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 24 18:15:54.091: INFO: Deleting all statefulset in ns statefulset-8913
Oct 24 18:15:54.095: INFO: Scaling statefulset ss to 0
Oct 24 18:15:54.108: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 18:15:54.113: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:15:54.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8913" for this suite.
Oct 24 18:16:08.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:16:08.305: INFO: namespace statefulset-8913 deletion completed in 14.160852631s

• [SLOW TEST:66.763 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:16:08.305: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 18:16:08.408: INFO: Waiting up to 5m0s for pod "downwardapi-volume-59c84dd2-f68a-11e9-8e41-6682758dfd28" in namespace "downward-api-6204" to be "success or failure"
Oct 24 18:16:08.419: INFO: Pod "downwardapi-volume-59c84dd2-f68a-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 10.990912ms
Oct 24 18:16:10.425: INFO: Pod "downwardapi-volume-59c84dd2-f68a-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.017233174s
Oct 24 18:16:12.431: INFO: Pod "downwardapi-volume-59c84dd2-f68a-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023340993s
STEP: Saw pod success
Oct 24 18:16:12.431: INFO: Pod "downwardapi-volume-59c84dd2-f68a-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:16:12.435: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-59c84dd2-f68a-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 18:16:12.462: INFO: Waiting for pod downwardapi-volume-59c84dd2-f68a-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:16:12.466: INFO: Pod downwardapi-volume-59c84dd2-f68a-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:16:12.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6204" for this suite.
Oct 24 18:16:18.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:16:18.625: INFO: namespace downward-api-6204 deletion completed in 6.154369805s

• [SLOW TEST:10.320 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:16:18.625: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:16:18.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7383" for this suite.
Oct 24 18:16:40.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:16:40.891: INFO: namespace pods-7383 deletion completed in 22.197110889s

• [SLOW TEST:22.266 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:16:40.892: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Oct 24 18:16:40.957: INFO: Waiting up to 5m0s for pod "pod-6d32d4d3-f68a-11e9-8e41-6682758dfd28" in namespace "emptydir-8995" to be "success or failure"
Oct 24 18:16:40.961: INFO: Pod "pod-6d32d4d3-f68a-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 3.986564ms
Oct 24 18:16:42.965: INFO: Pod "pod-6d32d4d3-f68a-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008301846s
STEP: Saw pod success
Oct 24 18:16:42.965: INFO: Pod "pod-6d32d4d3-f68a-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:16:42.969: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-6d32d4d3-f68a-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 18:16:43.007: INFO: Waiting for pod pod-6d32d4d3-f68a-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:16:43.011: INFO: Pod pod-6d32d4d3-f68a-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:16:43.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8995" for this suite.
Oct 24 18:16:49.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:16:49.185: INFO: namespace emptydir-8995 deletion completed in 6.169482399s

• [SLOW TEST:8.294 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:16:49.186: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-4kmp
STEP: Creating a pod to test atomic-volume-subpath
Oct 24 18:16:49.254: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-4kmp" in namespace "subpath-89" to be "success or failure"
Oct 24 18:16:49.259: INFO: Pod "pod-subpath-test-configmap-4kmp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.492753ms
Oct 24 18:16:51.264: INFO: Pod "pod-subpath-test-configmap-4kmp": Phase="Running", Reason="", readiness=true. Elapsed: 2.009760368s
Oct 24 18:16:53.270: INFO: Pod "pod-subpath-test-configmap-4kmp": Phase="Running", Reason="", readiness=true. Elapsed: 4.015380605s
Oct 24 18:16:55.276: INFO: Pod "pod-subpath-test-configmap-4kmp": Phase="Running", Reason="", readiness=true. Elapsed: 6.021397693s
Oct 24 18:16:57.281: INFO: Pod "pod-subpath-test-configmap-4kmp": Phase="Running", Reason="", readiness=true. Elapsed: 8.026464766s
Oct 24 18:16:59.286: INFO: Pod "pod-subpath-test-configmap-4kmp": Phase="Running", Reason="", readiness=true. Elapsed: 10.031721208s
Oct 24 18:17:01.292: INFO: Pod "pod-subpath-test-configmap-4kmp": Phase="Running", Reason="", readiness=true. Elapsed: 12.037317984s
Oct 24 18:17:03.298: INFO: Pod "pod-subpath-test-configmap-4kmp": Phase="Running", Reason="", readiness=true. Elapsed: 14.043495381s
Oct 24 18:17:05.304: INFO: Pod "pod-subpath-test-configmap-4kmp": Phase="Running", Reason="", readiness=true. Elapsed: 16.049196619s
Oct 24 18:17:07.309: INFO: Pod "pod-subpath-test-configmap-4kmp": Phase="Running", Reason="", readiness=true. Elapsed: 18.054950678s
Oct 24 18:17:09.316: INFO: Pod "pod-subpath-test-configmap-4kmp": Phase="Running", Reason="", readiness=true. Elapsed: 20.061238196s
Oct 24 18:17:11.320: INFO: Pod "pod-subpath-test-configmap-4kmp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.065803814s
STEP: Saw pod success
Oct 24 18:17:11.320: INFO: Pod "pod-subpath-test-configmap-4kmp" satisfied condition "success or failure"
Oct 24 18:17:11.325: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-subpath-test-configmap-4kmp container test-container-subpath-configmap-4kmp: <nil>
STEP: delete the pod
Oct 24 18:17:11.356: INFO: Waiting for pod pod-subpath-test-configmap-4kmp to disappear
Oct 24 18:17:11.360: INFO: Pod pod-subpath-test-configmap-4kmp no longer exists
STEP: Deleting pod pod-subpath-test-configmap-4kmp
Oct 24 18:17:11.360: INFO: Deleting pod "pod-subpath-test-configmap-4kmp" in namespace "subpath-89"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:17:11.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-89" for this suite.
Oct 24 18:17:17.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:17:17.532: INFO: namespace subpath-89 deletion completed in 6.159024458s

• [SLOW TEST:28.347 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:17:17.533: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Oct 24 18:17:18.932: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Oct 24 18:17:21.000: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 18:17:23.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 18:17:25.005: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 18:17:27.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 18:17:29.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 18:17:31.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707537838, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 18:17:34.058: INFO: Waited 1.040217541s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:17:34.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-719" for this suite.
Oct 24 18:17:40.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:17:40.919: INFO: namespace aggregator-719 deletion completed in 6.254633836s

• [SLOW TEST:23.387 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:17:40.920: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-4825
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Oct 24 18:17:40.997: INFO: Found 0 stateful pods, waiting for 3
Oct 24 18:17:51.004: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 18:17:51.004: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 18:17:51.004: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 24 18:17:51.039: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Oct 24 18:18:01.082: INFO: Updating stateful set ss2
Oct 24 18:18:01.097: INFO: Waiting for Pod statefulset-4825/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Oct 24 18:18:11.174: INFO: Found 2 stateful pods, waiting for 3
Oct 24 18:18:21.182: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 18:18:21.182: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 18:18:21.182: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Oct 24 18:18:21.212: INFO: Updating stateful set ss2
Oct 24 18:18:21.223: INFO: Waiting for Pod statefulset-4825/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 24 18:18:31.257: INFO: Updating stateful set ss2
Oct 24 18:18:31.271: INFO: Waiting for StatefulSet statefulset-4825/ss2 to complete update
Oct 24 18:18:31.271: INFO: Waiting for Pod statefulset-4825/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 24 18:18:41.282: INFO: Deleting all statefulset in ns statefulset-4825
Oct 24 18:18:41.287: INFO: Scaling statefulset ss2 to 0
Oct 24 18:19:01.306: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 18:19:01.312: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:19:01.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4825" for this suite.
Oct 24 18:19:17.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:19:17.498: INFO: namespace statefulset-4825 deletion completed in 16.164396614s

• [SLOW TEST:96.578 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:19:17.498: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4649.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4649.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4649.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4649.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4649.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4649.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4649.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4649.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4649.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4649.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4649.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4649.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4649.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 172.2.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.2.172_udp@PTR;check="$$(dig +tcp +noall +answer +search 172.2.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.2.172_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4649.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4649.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4649.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4649.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4649.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4649.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4649.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4649.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4649.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4649.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4649.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4649.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4649.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 172.2.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.2.172_udp@PTR;check="$$(dig +tcp +noall +answer +search 172.2.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.2.172_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 24 18:19:43.637: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4649.svc.cluster.local from pod dns-4649/dns-test-ca8e12ea-f68a-11e9-8e41-6682758dfd28: the server could not find the requested resource (get pods dns-test-ca8e12ea-f68a-11e9-8e41-6682758dfd28)
Oct 24 18:19:43.670: INFO: Unable to read jessie_udp@dns-test-service.dns-4649.svc.cluster.local from pod dns-4649/dns-test-ca8e12ea-f68a-11e9-8e41-6682758dfd28: the server could not find the requested resource (get pods dns-test-ca8e12ea-f68a-11e9-8e41-6682758dfd28)
Oct 24 18:19:43.680: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4649.svc.cluster.local from pod dns-4649/dns-test-ca8e12ea-f68a-11e9-8e41-6682758dfd28: the server could not find the requested resource (get pods dns-test-ca8e12ea-f68a-11e9-8e41-6682758dfd28)
Oct 24 18:19:43.686: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4649.svc.cluster.local from pod dns-4649/dns-test-ca8e12ea-f68a-11e9-8e41-6682758dfd28: the server could not find the requested resource (get pods dns-test-ca8e12ea-f68a-11e9-8e41-6682758dfd28)
Oct 24 18:19:43.718: INFO: Lookups using dns-4649/dns-test-ca8e12ea-f68a-11e9-8e41-6682758dfd28 failed for: [wheezy_tcp@_http._tcp.dns-test-service.dns-4649.svc.cluster.local jessie_udp@dns-test-service.dns-4649.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4649.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4649.svc.cluster.local]

Oct 24 18:19:48.828: INFO: DNS probes using dns-4649/dns-test-ca8e12ea-f68a-11e9-8e41-6682758dfd28 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:19:48.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4649" for this suite.
Oct 24 18:19:54.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:19:55.107: INFO: namespace dns-4649 deletion completed in 6.198158138s

• [SLOW TEST:37.609 seconds]
[sig-network] DNS
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:19:55.107: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Oct 24 18:19:55.170: INFO: Waiting up to 5m0s for pod "var-expansion-e0f52ccb-f68a-11e9-8e41-6682758dfd28" in namespace "var-expansion-2827" to be "success or failure"
Oct 24 18:19:55.177: INFO: Pod "var-expansion-e0f52ccb-f68a-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 6.382674ms
Oct 24 18:19:57.183: INFO: Pod "var-expansion-e0f52ccb-f68a-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012698341s
STEP: Saw pod success
Oct 24 18:19:57.183: INFO: Pod "var-expansion-e0f52ccb-f68a-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:19:57.192: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod var-expansion-e0f52ccb-f68a-11e9-8e41-6682758dfd28 container dapi-container: <nil>
STEP: delete the pod
Oct 24 18:19:57.234: INFO: Waiting for pod var-expansion-e0f52ccb-f68a-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:19:57.240: INFO: Pod var-expansion-e0f52ccb-f68a-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:19:57.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2827" for this suite.
Oct 24 18:20:03.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:20:03.413: INFO: namespace var-expansion-2827 deletion completed in 6.168397264s

• [SLOW TEST:8.306 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:20:03.414: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 24 18:20:03.473: INFO: Waiting up to 5m0s for pod "pod-e5e8667c-f68a-11e9-8e41-6682758dfd28" in namespace "emptydir-9186" to be "success or failure"
Oct 24 18:20:03.477: INFO: Pod "pod-e5e8667c-f68a-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 3.848303ms
Oct 24 18:20:05.482: INFO: Pod "pod-e5e8667c-f68a-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008824316s
STEP: Saw pod success
Oct 24 18:20:05.482: INFO: Pod "pod-e5e8667c-f68a-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:20:05.486: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-e5e8667c-f68a-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 18:20:05.513: INFO: Waiting for pod pod-e5e8667c-f68a-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:20:05.517: INFO: Pod pod-e5e8667c-f68a-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:20:05.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9186" for this suite.
Oct 24 18:20:11.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:20:11.680: INFO: namespace emptydir-9186 deletion completed in 6.158487954s

• [SLOW TEST:8.266 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:20:11.681: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct 24 18:20:14.279: INFO: Successfully updated pod "annotationupdateead542c3-f68a-11e9-8e41-6682758dfd28"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:20:18.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7755" for this suite.
Oct 24 18:20:40.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:20:40.509: INFO: namespace projected-7755 deletion completed in 22.179251537s

• [SLOW TEST:28.828 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:20:40.509: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-6696/configmap-test-fc0417cc-f68a-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume configMaps
Oct 24 18:20:40.572: INFO: Waiting up to 5m0s for pod "pod-configmaps-fc04b999-f68a-11e9-8e41-6682758dfd28" in namespace "configmap-6696" to be "success or failure"
Oct 24 18:20:40.577: INFO: Pod "pod-configmaps-fc04b999-f68a-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.037414ms
Oct 24 18:20:42.582: INFO: Pod "pod-configmaps-fc04b999-f68a-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.009608312s
Oct 24 18:20:44.587: INFO: Pod "pod-configmaps-fc04b999-f68a-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015073903s
STEP: Saw pod success
Oct 24 18:20:44.587: INFO: Pod "pod-configmaps-fc04b999-f68a-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:20:44.591: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-fc04b999-f68a-11e9-8e41-6682758dfd28 container env-test: <nil>
STEP: delete the pod
Oct 24 18:20:44.623: INFO: Waiting for pod pod-configmaps-fc04b999-f68a-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:20:44.627: INFO: Pod pod-configmaps-fc04b999-f68a-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:20:44.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6696" for this suite.
Oct 24 18:20:50.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:20:50.793: INFO: namespace configmap-6696 deletion completed in 6.161310688s

• [SLOW TEST:10.284 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:20:50.794: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-vth5
STEP: Creating a pod to test atomic-volume-subpath
Oct 24 18:20:50.858: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-vth5" in namespace "subpath-3457" to be "success or failure"
Oct 24 18:20:50.862: INFO: Pod "pod-subpath-test-projected-vth5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.146859ms
Oct 24 18:20:52.868: INFO: Pod "pod-subpath-test-projected-vth5": Phase="Running", Reason="", readiness=true. Elapsed: 2.009234435s
Oct 24 18:20:54.873: INFO: Pod "pod-subpath-test-projected-vth5": Phase="Running", Reason="", readiness=true. Elapsed: 4.014489145s
Oct 24 18:20:56.879: INFO: Pod "pod-subpath-test-projected-vth5": Phase="Running", Reason="", readiness=true. Elapsed: 6.020439232s
Oct 24 18:20:58.885: INFO: Pod "pod-subpath-test-projected-vth5": Phase="Running", Reason="", readiness=true. Elapsed: 8.026353777s
Oct 24 18:21:00.890: INFO: Pod "pod-subpath-test-projected-vth5": Phase="Running", Reason="", readiness=true. Elapsed: 10.031420302s
Oct 24 18:21:02.895: INFO: Pod "pod-subpath-test-projected-vth5": Phase="Running", Reason="", readiness=true. Elapsed: 12.037154759s
Oct 24 18:21:04.901: INFO: Pod "pod-subpath-test-projected-vth5": Phase="Running", Reason="", readiness=true. Elapsed: 14.042584655s
Oct 24 18:21:06.907: INFO: Pod "pod-subpath-test-projected-vth5": Phase="Running", Reason="", readiness=true. Elapsed: 16.048377439s
Oct 24 18:21:08.912: INFO: Pod "pod-subpath-test-projected-vth5": Phase="Running", Reason="", readiness=true. Elapsed: 18.053812559s
Oct 24 18:21:10.918: INFO: Pod "pod-subpath-test-projected-vth5": Phase="Running", Reason="", readiness=true. Elapsed: 20.059484993s
Oct 24 18:21:12.922: INFO: Pod "pod-subpath-test-projected-vth5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.064113301s
STEP: Saw pod success
Oct 24 18:21:12.923: INFO: Pod "pod-subpath-test-projected-vth5" satisfied condition "success or failure"
Oct 24 18:21:12.927: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-subpath-test-projected-vth5 container test-container-subpath-projected-vth5: <nil>
STEP: delete the pod
Oct 24 18:21:12.967: INFO: Waiting for pod pod-subpath-test-projected-vth5 to disappear
Oct 24 18:21:12.971: INFO: Pod pod-subpath-test-projected-vth5 no longer exists
STEP: Deleting pod pod-subpath-test-projected-vth5
Oct 24 18:21:12.971: INFO: Deleting pod "pod-subpath-test-projected-vth5" in namespace "subpath-3457"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:21:12.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3457" for this suite.
Oct 24 18:21:18.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:21:19.151: INFO: namespace subpath-3457 deletion completed in 6.171500507s

• [SLOW TEST:28.358 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:21:19.152: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 18:21:19.207: INFO: Waiting up to 5m0s for pod "downwardapi-volume-130c726d-f68b-11e9-8e41-6682758dfd28" in namespace "projected-8810" to be "success or failure"
Oct 24 18:21:19.214: INFO: Pod "downwardapi-volume-130c726d-f68b-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 7.584918ms
Oct 24 18:21:21.220: INFO: Pod "downwardapi-volume-130c726d-f68b-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.013424921s
Oct 24 18:21:23.225: INFO: Pod "downwardapi-volume-130c726d-f68b-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018436451s
STEP: Saw pod success
Oct 24 18:21:23.225: INFO: Pod "downwardapi-volume-130c726d-f68b-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:21:23.229: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-130c726d-f68b-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 18:21:23.259: INFO: Waiting for pod downwardapi-volume-130c726d-f68b-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:21:23.263: INFO: Pod downwardapi-volume-130c726d-f68b-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:21:23.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8810" for this suite.
Oct 24 18:21:29.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:21:29.427: INFO: namespace projected-8810 deletion completed in 6.159086451s

• [SLOW TEST:10.276 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:21:29.428: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 24 18:21:29.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-3235'
Oct 24 18:21:29.768: INFO: stderr: ""
Oct 24 18:21:29.768: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Oct 24 18:21:34.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 get pod e2e-test-nginx-pod --namespace=kubectl-3235 -o json'
Oct 24 18:21:34.990: INFO: stderr: ""
Oct 24 18:21:34.990: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.244.1.126/32\"\n        },\n        \"creationTimestamp\": \"2019-10-24T18:21:29Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-3235\",\n        \"resourceVersion\": \"15553\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-3235/pods/e2e-test-nginx-pod\",\n        \"uid\": \"19565006-f68b-11e9-a6ac-005056ab7215\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-74f6t\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"mip-bd-vm41.mip.storage.hpecorp.net\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-74f6t\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-74f6t\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-24T18:21:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-24T18:21:30Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-24T18:21:30Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-24T18:21:29Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f62244c7e7bfeb6d5da4524514d790680859aa1365288c1a68242e18cf787840\",\n                \"image\": \"docker.io/nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-10-24T18:21:30Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"16.143.20.138\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.126\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-10-24T18:21:29Z\"\n    }\n}\n"
STEP: replace the image in the pod
Oct 24 18:21:34.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 replace -f - --namespace=kubectl-3235'
Oct 24 18:21:35.476: INFO: stderr: ""
Oct 24 18:21:35.476: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Oct 24 18:21:35.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 delete pods e2e-test-nginx-pod --namespace=kubectl-3235'
Oct 24 18:21:45.361: INFO: stderr: ""
Oct 24 18:21:45.361: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:21:45.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3235" for this suite.
Oct 24 18:21:51.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:21:51.545: INFO: namespace kubectl-3235 deletion completed in 6.179182751s

• [SLOW TEST:22.117 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:21:51.545: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-265daffd-f68b-11e9-8e41-6682758dfd28
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:21:53.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3058" for this suite.
Oct 24 18:22:15.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:22:15.816: INFO: namespace configmap-3058 deletion completed in 22.151510451s

• [SLOW TEST:24.271 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:22:15.817: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Oct 24 18:22:16.391: INFO: created pod pod-service-account-defaultsa
Oct 24 18:22:16.392: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct 24 18:22:16.399: INFO: created pod pod-service-account-mountsa
Oct 24 18:22:16.399: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct 24 18:22:16.410: INFO: created pod pod-service-account-nomountsa
Oct 24 18:22:16.410: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct 24 18:22:16.422: INFO: created pod pod-service-account-defaultsa-mountspec
Oct 24 18:22:16.422: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct 24 18:22:16.433: INFO: created pod pod-service-account-mountsa-mountspec
Oct 24 18:22:16.434: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct 24 18:22:16.443: INFO: created pod pod-service-account-nomountsa-mountspec
Oct 24 18:22:16.443: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct 24 18:22:16.455: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct 24 18:22:16.455: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct 24 18:22:16.463: INFO: created pod pod-service-account-mountsa-nomountspec
Oct 24 18:22:16.463: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct 24 18:22:16.474: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct 24 18:22:16.474: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:22:16.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2706" for this suite.
Oct 24 18:22:22.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:22:22.663: INFO: namespace svcaccounts-2706 deletion completed in 6.180939165s

• [SLOW TEST:6.847 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:22:22.664: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-38ef9941-f68b-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume configMaps
Oct 24 18:22:22.779: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-38f05eee-f68b-11e9-8e41-6682758dfd28" in namespace "projected-2935" to be "success or failure"
Oct 24 18:22:22.785: INFO: Pod "pod-projected-configmaps-38f05eee-f68b-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.766735ms
Oct 24 18:22:24.790: INFO: Pod "pod-projected-configmaps-38f05eee-f68b-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.011008847s
Oct 24 18:22:26.796: INFO: Pod "pod-projected-configmaps-38f05eee-f68b-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01730671s
STEP: Saw pod success
Oct 24 18:22:26.796: INFO: Pod "pod-projected-configmaps-38f05eee-f68b-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:22:26.801: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-configmaps-38f05eee-f68b-11e9-8e41-6682758dfd28 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 18:22:26.830: INFO: Waiting for pod pod-projected-configmaps-38f05eee-f68b-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:22:26.833: INFO: Pod pod-projected-configmaps-38f05eee-f68b-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:22:26.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2935" for this suite.
Oct 24 18:22:32.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:22:33.019: INFO: namespace projected-2935 deletion completed in 6.180981961s

• [SLOW TEST:10.355 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:22:33.019: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-3f156fcf-f68b-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume configMaps
Oct 24 18:22:33.091: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3f162efd-f68b-11e9-8e41-6682758dfd28" in namespace "projected-1208" to be "success or failure"
Oct 24 18:22:33.096: INFO: Pod "pod-projected-configmaps-3f162efd-f68b-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.222766ms
Oct 24 18:22:35.101: INFO: Pod "pod-projected-configmaps-3f162efd-f68b-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009884959s
STEP: Saw pod success
Oct 24 18:22:35.101: INFO: Pod "pod-projected-configmaps-3f162efd-f68b-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:22:35.105: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-projected-configmaps-3f162efd-f68b-11e9-8e41-6682758dfd28 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 18:22:35.131: INFO: Waiting for pod pod-projected-configmaps-3f162efd-f68b-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:22:35.135: INFO: Pod pod-projected-configmaps-3f162efd-f68b-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:22:35.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1208" for this suite.
Oct 24 18:22:41.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:22:41.291: INFO: namespace projected-1208 deletion completed in 6.15091564s

• [SLOW TEST:8.272 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:22:41.291: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-3794
Oct 24 18:22:43.361: INFO: Started pod liveness-http in namespace container-probe-3794
STEP: checking the pod's current state and verifying that restartCount is present
Oct 24 18:22:43.365: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:26:44.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3794" for this suite.
Oct 24 18:26:50.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:26:50.303: INFO: namespace container-probe-3794 deletion completed in 6.189850966s

• [SLOW TEST:249.012 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:26:50.303: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-d86ebb1b-f68b-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume secrets
Oct 24 18:26:50.369: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d86f8357-f68b-11e9-8e41-6682758dfd28" in namespace "projected-139" to be "success or failure"
Oct 24 18:26:50.373: INFO: Pod "pod-projected-secrets-d86f8357-f68b-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.377997ms
Oct 24 18:26:52.378: INFO: Pod "pod-projected-secrets-d86f8357-f68b-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009547024s
STEP: Saw pod success
Oct 24 18:26:52.378: INFO: Pod "pod-projected-secrets-d86f8357-f68b-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:26:52.383: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-projected-secrets-d86f8357-f68b-11e9-8e41-6682758dfd28 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 24 18:26:52.417: INFO: Waiting for pod pod-projected-secrets-d86f8357-f68b-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:26:52.421: INFO: Pod pod-projected-secrets-d86f8357-f68b-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:26:52.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-139" for this suite.
Oct 24 18:26:58.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:26:58.590: INFO: namespace projected-139 deletion completed in 6.164578901s

• [SLOW TEST:8.287 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:26:58.591: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Oct 24 18:26:58.646: INFO: Waiting up to 5m0s for pod "client-containers-dd5ec783-f68b-11e9-8e41-6682758dfd28" in namespace "containers-1248" to be "success or failure"
Oct 24 18:26:58.650: INFO: Pod "client-containers-dd5ec783-f68b-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.206532ms
Oct 24 18:27:00.655: INFO: Pod "client-containers-dd5ec783-f68b-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009492711s
STEP: Saw pod success
Oct 24 18:27:00.655: INFO: Pod "client-containers-dd5ec783-f68b-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:27:00.660: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod client-containers-dd5ec783-f68b-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 18:27:00.690: INFO: Waiting for pod client-containers-dd5ec783-f68b-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:27:00.693: INFO: Pod client-containers-dd5ec783-f68b-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:27:00.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1248" for this suite.
Oct 24 18:27:06.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:27:06.865: INFO: namespace containers-1248 deletion completed in 6.16762203s

• [SLOW TEST:8.275 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:27:06.866: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Oct 24 18:27:06.922: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7209,SelfLink:/api/v1/namespaces/watch-7209/configmaps/e2e-watch-test-configmap-a,UID:e24e9e38-f68b-11e9-a6ac-005056ab7215,ResourceVersion:16329,Generation:0,CreationTimestamp:2019-10-24 18:27:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 24 18:27:06.922: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7209,SelfLink:/api/v1/namespaces/watch-7209/configmaps/e2e-watch-test-configmap-a,UID:e24e9e38-f68b-11e9-a6ac-005056ab7215,ResourceVersion:16329,Generation:0,CreationTimestamp:2019-10-24 18:27:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Oct 24 18:27:16.933: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7209,SelfLink:/api/v1/namespaces/watch-7209/configmaps/e2e-watch-test-configmap-a,UID:e24e9e38-f68b-11e9-a6ac-005056ab7215,ResourceVersion:16344,Generation:0,CreationTimestamp:2019-10-24 18:27:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 24 18:27:16.934: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7209,SelfLink:/api/v1/namespaces/watch-7209/configmaps/e2e-watch-test-configmap-a,UID:e24e9e38-f68b-11e9-a6ac-005056ab7215,ResourceVersion:16344,Generation:0,CreationTimestamp:2019-10-24 18:27:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Oct 24 18:27:26.944: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7209,SelfLink:/api/v1/namespaces/watch-7209/configmaps/e2e-watch-test-configmap-a,UID:e24e9e38-f68b-11e9-a6ac-005056ab7215,ResourceVersion:16359,Generation:0,CreationTimestamp:2019-10-24 18:27:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 24 18:27:26.945: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7209,SelfLink:/api/v1/namespaces/watch-7209/configmaps/e2e-watch-test-configmap-a,UID:e24e9e38-f68b-11e9-a6ac-005056ab7215,ResourceVersion:16359,Generation:0,CreationTimestamp:2019-10-24 18:27:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Oct 24 18:27:36.956: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7209,SelfLink:/api/v1/namespaces/watch-7209/configmaps/e2e-watch-test-configmap-a,UID:e24e9e38-f68b-11e9-a6ac-005056ab7215,ResourceVersion:16374,Generation:0,CreationTimestamp:2019-10-24 18:27:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 24 18:27:36.956: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7209,SelfLink:/api/v1/namespaces/watch-7209/configmaps/e2e-watch-test-configmap-a,UID:e24e9e38-f68b-11e9-a6ac-005056ab7215,ResourceVersion:16374,Generation:0,CreationTimestamp:2019-10-24 18:27:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Oct 24 18:27:46.966: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7209,SelfLink:/api/v1/namespaces/watch-7209/configmaps/e2e-watch-test-configmap-b,UID:fa2c3839-f68b-11e9-a6ac-005056ab7215,ResourceVersion:16391,Generation:0,CreationTimestamp:2019-10-24 18:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 24 18:27:46.966: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7209,SelfLink:/api/v1/namespaces/watch-7209/configmaps/e2e-watch-test-configmap-b,UID:fa2c3839-f68b-11e9-a6ac-005056ab7215,ResourceVersion:16391,Generation:0,CreationTimestamp:2019-10-24 18:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Oct 24 18:27:56.975: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7209,SelfLink:/api/v1/namespaces/watch-7209/configmaps/e2e-watch-test-configmap-b,UID:fa2c3839-f68b-11e9-a6ac-005056ab7215,ResourceVersion:16406,Generation:0,CreationTimestamp:2019-10-24 18:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 24 18:27:56.975: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7209,SelfLink:/api/v1/namespaces/watch-7209/configmaps/e2e-watch-test-configmap-b,UID:fa2c3839-f68b-11e9-a6ac-005056ab7215,ResourceVersion:16406,Generation:0,CreationTimestamp:2019-10-24 18:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:28:06.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7209" for this suite.
Oct 24 18:28:13.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:28:13.148: INFO: namespace watch-7209 deletion completed in 6.164258423s

• [SLOW TEST:66.282 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:28:13.148: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Oct 24 18:28:13.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 --namespace=kubectl-8115 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Oct 24 18:28:15.246: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Oct 24 18:28:15.246: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:28:17.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8115" for this suite.
Oct 24 18:28:27.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:28:27.424: INFO: namespace kubectl-8115 deletion completed in 10.164666371s

• [SLOW TEST:14.276 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:28:27.425: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:29:27.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1536" for this suite.
Oct 24 18:29:49.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:29:49.660: INFO: namespace container-probe-1536 deletion completed in 22.165996164s

• [SLOW TEST:82.235 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:29:49.660: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct 24 18:29:52.256: INFO: Successfully updated pod "labelsupdate4355e5bc-f68c-11e9-8e41-6682758dfd28"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:29:56.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5331" for this suite.
Oct 24 18:30:18.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:30:18.477: INFO: namespace projected-5331 deletion completed in 22.167881296s

• [SLOW TEST:28.817 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:30:18.477: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 18:30:38.551: INFO: Container started at 2019-10-24 18:30:19 +0000 UTC, pod became ready at 2019-10-24 18:30:36 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:30:38.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5676" for this suite.
Oct 24 18:31:00.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:31:00.710: INFO: namespace container-probe-5676 deletion completed in 22.152013646s

• [SLOW TEST:42.233 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:31:00.711: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Oct 24 18:31:06.807: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8503 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 18:31:06.807: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 18:31:06.956: INFO: Exec stderr: ""
Oct 24 18:31:06.956: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8503 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 18:31:06.956: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 18:31:07.099: INFO: Exec stderr: ""
Oct 24 18:31:07.099: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8503 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 18:31:07.099: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 18:31:07.240: INFO: Exec stderr: ""
Oct 24 18:31:07.240: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8503 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 18:31:07.240: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 18:31:07.371: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Oct 24 18:31:07.371: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8503 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 18:31:07.371: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 18:31:07.515: INFO: Exec stderr: ""
Oct 24 18:31:07.515: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8503 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 18:31:07.515: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 18:31:07.661: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Oct 24 18:31:07.661: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8503 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 18:31:07.661: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 18:31:07.809: INFO: Exec stderr: ""
Oct 24 18:31:07.810: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8503 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 18:31:07.810: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 18:31:07.956: INFO: Exec stderr: ""
Oct 24 18:31:07.956: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8503 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 18:31:07.956: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 18:31:08.105: INFO: Exec stderr: ""
Oct 24 18:31:08.105: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8503 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 18:31:08.105: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 18:31:08.262: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:31:08.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-8503" for this suite.
Oct 24 18:32:02.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:32:02.433: INFO: namespace e2e-kubelet-etc-hosts-8503 deletion completed in 54.164607089s

• [SLOW TEST:61.722 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:32:02.433: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3952.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3952.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3952.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3952.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3952.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3952.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 24 18:32:06.591: INFO: DNS probes using dns-3952/dns-test-927aa867-f68c-11e9-8e41-6682758dfd28 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:32:06.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3952" for this suite.
Oct 24 18:32:12.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:32:12.791: INFO: namespace dns-3952 deletion completed in 6.173177766s

• [SLOW TEST:10.358 seconds]
[sig-network] DNS
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:32:12.792: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1024 18:32:22.964880      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 24 18:32:22.964: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:32:22.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4840" for this suite.
Oct 24 18:32:28.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:32:29.162: INFO: namespace gc-4840 deletion completed in 6.192746877s

• [SLOW TEST:16.371 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:32:29.163: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Oct 24 18:32:29.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 cluster-info'
Oct 24 18:32:29.500: INFO: stderr: ""
Oct 24 18:32:29.500: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:32:29.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7315" for this suite.
Oct 24 18:32:35.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:32:35.672: INFO: namespace kubectl-7315 deletion completed in 6.165633103s

• [SLOW TEST:6.510 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:32:35.673: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Oct 24 18:32:35.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-464213187 api-versions'
Oct 24 18:32:35.865: INFO: stderr: ""
Oct 24 18:32:35.865: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nkubedirector.bluedata.io/v1alpha1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nsettings.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:32:35.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7911" for this suite.
Oct 24 18:32:41.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:32:42.035: INFO: namespace kubectl-7911 deletion completed in 6.164234249s

• [SLOW TEST:6.362 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:32:42.035: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Oct 24 18:32:44.118: INFO: Pod pod-hostip-aa149c44-f68c-11e9-8e41-6682758dfd28 has hostIP: 16.143.20.137
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:32:44.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7942" for this suite.
Oct 24 18:33:06.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:33:06.288: INFO: namespace pods-7942 deletion completed in 22.1651297s

• [SLOW TEST:24.253 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:33:06.289: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct 24 18:33:06.337: INFO: PodSpec: initContainers in spec.initContainers
Oct 24 18:33:53.183: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-b8894e7a-f68c-11e9-8e41-6682758dfd28", GenerateName:"", Namespace:"init-container-222", SelfLink:"/api/v1/namespaces/init-container-222/pods/pod-init-b8894e7a-f68c-11e9-8e41-6682758dfd28", UID:"b88a1f7d-f68c-11e9-a6ac-005056ab7215", ResourceVersion:"17460", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63707538786, loc:(*time.Location)(0x8825120)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"337147589"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.244.1.144/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-hft5t", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0023de700), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hft5t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hft5t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hft5t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002327ed8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"mip-bd-vm41.mip.storage.hpecorp.net", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002ffc420), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002327f50)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002327f70)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002327f78), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002327f7c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707538786, loc:(*time.Location)(0x8825120)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707538786, loc:(*time.Location)(0x8825120)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707538786, loc:(*time.Location)(0x8825120)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707538786, loc:(*time.Location)(0x8825120)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"16.143.20.138", PodIP:"10.244.1.144", StartTime:(*v1.Time)(0xc002580880), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001e64850)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001e648c0)}, Ready:false, RestartCount:3, Image:"docker.io/busybox:1.29", ImageID:"docker-pullable://docker.io/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://a329479b219e3d2156d7c9dec76aab61fa3d5247f02b662d98a1698f5924c572"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002580a00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002580940), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:33:53.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-222" for this suite.
Oct 24 18:34:15.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:34:15.348: INFO: namespace init-container-222 deletion completed in 22.158060872s

• [SLOW TEST:69.060 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:34:15.349: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct 24 18:34:15.397: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:34:19.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7722" for this suite.
Oct 24 18:34:41.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:34:41.879: INFO: namespace init-container-7722 deletion completed in 22.158737283s

• [SLOW TEST:26.530 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:34:41.879: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 24 18:34:45.987: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 18:34:45.991: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 24 18:34:47.992: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 18:34:47.997: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 24 18:34:49.992: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 18:34:49.997: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 24 18:34:51.992: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 18:34:51.996: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 24 18:34:53.992: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 18:34:53.997: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 24 18:34:55.992: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 18:34:55.996: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 24 18:34:57.992: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 18:34:57.997: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 24 18:34:59.992: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 18:34:59.996: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 24 18:35:01.992: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 18:35:01.998: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 24 18:35:03.992: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 18:35:03.997: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 24 18:35:05.992: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 18:35:05.997: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 24 18:35:07.992: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 18:35:07.996: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 24 18:35:09.992: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 18:35:09.996: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:35:10.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9418" for this suite.
Oct 24 18:35:32.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:35:32.252: INFO: namespace container-lifecycle-hook-9418 deletion completed in 22.232646814s

• [SLOW TEST:50.373 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:35:32.253: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-g6c8
STEP: Creating a pod to test atomic-volume-subpath
Oct 24 18:35:32.328: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-g6c8" in namespace "subpath-1009" to be "success or failure"
Oct 24 18:35:32.332: INFO: Pod "pod-subpath-test-secret-g6c8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.850826ms
Oct 24 18:35:34.338: INFO: Pod "pod-subpath-test-secret-g6c8": Phase="Running", Reason="", readiness=true. Elapsed: 2.0093542s
Oct 24 18:35:36.344: INFO: Pod "pod-subpath-test-secret-g6c8": Phase="Running", Reason="", readiness=true. Elapsed: 4.016011165s
Oct 24 18:35:38.350: INFO: Pod "pod-subpath-test-secret-g6c8": Phase="Running", Reason="", readiness=true. Elapsed: 6.021876447s
Oct 24 18:35:40.356: INFO: Pod "pod-subpath-test-secret-g6c8": Phase="Running", Reason="", readiness=true. Elapsed: 8.028146386s
Oct 24 18:35:42.362: INFO: Pod "pod-subpath-test-secret-g6c8": Phase="Running", Reason="", readiness=true. Elapsed: 10.034168315s
Oct 24 18:35:44.368: INFO: Pod "pod-subpath-test-secret-g6c8": Phase="Running", Reason="", readiness=true. Elapsed: 12.03945633s
Oct 24 18:35:46.374: INFO: Pod "pod-subpath-test-secret-g6c8": Phase="Running", Reason="", readiness=true. Elapsed: 14.045640977s
Oct 24 18:35:48.380: INFO: Pod "pod-subpath-test-secret-g6c8": Phase="Running", Reason="", readiness=true. Elapsed: 16.051558649s
Oct 24 18:35:50.386: INFO: Pod "pod-subpath-test-secret-g6c8": Phase="Running", Reason="", readiness=true. Elapsed: 18.057443092s
Oct 24 18:35:52.391: INFO: Pod "pod-subpath-test-secret-g6c8": Phase="Running", Reason="", readiness=true. Elapsed: 20.063181976s
Oct 24 18:35:54.397: INFO: Pod "pod-subpath-test-secret-g6c8": Phase="Running", Reason="", readiness=true. Elapsed: 22.068878306s
Oct 24 18:35:56.403: INFO: Pod "pod-subpath-test-secret-g6c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.074538821s
STEP: Saw pod success
Oct 24 18:35:56.403: INFO: Pod "pod-subpath-test-secret-g6c8" satisfied condition "success or failure"
Oct 24 18:35:56.407: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-subpath-test-secret-g6c8 container test-container-subpath-secret-g6c8: <nil>
STEP: delete the pod
Oct 24 18:35:56.436: INFO: Waiting for pod pod-subpath-test-secret-g6c8 to disappear
Oct 24 18:35:56.441: INFO: Pod pod-subpath-test-secret-g6c8 no longer exists
STEP: Deleting pod pod-subpath-test-secret-g6c8
Oct 24 18:35:56.441: INFO: Deleting pod "pod-subpath-test-secret-g6c8" in namespace "subpath-1009"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:35:56.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1009" for this suite.
Oct 24 18:36:02.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:36:02.616: INFO: namespace subpath-1009 deletion completed in 6.167550253s

• [SLOW TEST:30.363 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:36:02.616: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Oct 24 18:36:02.677: INFO: Waiting up to 5m0s for pod "var-expansion-21a36a93-f68d-11e9-8e41-6682758dfd28" in namespace "var-expansion-8345" to be "success or failure"
Oct 24 18:36:02.681: INFO: Pod "var-expansion-21a36a93-f68d-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.246404ms
Oct 24 18:36:04.687: INFO: Pod "var-expansion-21a36a93-f68d-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009968709s
STEP: Saw pod success
Oct 24 18:36:04.687: INFO: Pod "var-expansion-21a36a93-f68d-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:36:04.691: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod var-expansion-21a36a93-f68d-11e9-8e41-6682758dfd28 container dapi-container: <nil>
STEP: delete the pod
Oct 24 18:36:04.723: INFO: Waiting for pod var-expansion-21a36a93-f68d-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:36:04.727: INFO: Pod var-expansion-21a36a93-f68d-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:36:04.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8345" for this suite.
Oct 24 18:36:10.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:36:10.897: INFO: namespace var-expansion-8345 deletion completed in 6.164933886s

• [SLOW TEST:8.281 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:36:10.898: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1024 18:36:51.001232      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 24 18:36:51.001: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:36:51.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3486" for this suite.
Oct 24 18:36:57.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:36:57.241: INFO: namespace gc-3486 deletion completed in 6.235678416s

• [SLOW TEST:46.343 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:36:57.241: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 24 18:37:01.396: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 18:37:01.400: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 18:37:03.400: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 18:37:03.405: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 18:37:05.401: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 18:37:05.406: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 18:37:07.401: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 18:37:07.405: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 18:37:09.401: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 18:37:09.405: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 18:37:11.401: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 18:37:11.407: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 18:37:13.401: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 18:37:13.406: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 18:37:15.401: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 18:37:15.407: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 18:37:17.401: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 18:37:17.407: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 18:37:19.401: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 18:37:19.406: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 18:37:21.401: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 18:37:21.407: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 18:37:23.401: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 18:37:23.406: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 18:37:25.401: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 18:37:25.406: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 18:37:27.401: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 18:37:27.406: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 18:37:29.401: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 18:37:29.406: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:37:29.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9026" for this suite.
Oct 24 18:37:51.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:37:51.588: INFO: namespace container-lifecycle-hook-9026 deletion completed in 22.176875389s

• [SLOW TEST:54.347 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:37:51.589: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 18:37:51.662: INFO: Create a RollingUpdate DaemonSet
Oct 24 18:37:51.670: INFO: Check that daemon pods launch on every node of the cluster
Oct 24 18:37:51.679: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 18:37:51.683: INFO: Number of nodes with available pods: 0
Oct 24 18:37:51.683: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 18:37:52.690: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 18:37:52.694: INFO: Number of nodes with available pods: 0
Oct 24 18:37:52.694: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 18:37:53.695: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 18:37:53.699: INFO: Number of nodes with available pods: 2
Oct 24 18:37:53.699: INFO: Number of running nodes: 2, number of available pods: 2
Oct 24 18:37:53.699: INFO: Update the DaemonSet to trigger a rollout
Oct 24 18:37:53.709: INFO: Updating DaemonSet daemon-set
Oct 24 18:37:57.726: INFO: Roll back the DaemonSet before rollout is complete
Oct 24 18:37:57.740: INFO: Updating DaemonSet daemon-set
Oct 24 18:37:57.740: INFO: Make sure DaemonSet rollback is complete
Oct 24 18:37:57.748: INFO: Wrong image for pod: daemon-set-m49dn. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 24 18:37:57.748: INFO: Pod daemon-set-m49dn is not available
Oct 24 18:37:57.754: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 18:37:58.760: INFO: Wrong image for pod: daemon-set-m49dn. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 24 18:37:58.760: INFO: Pod daemon-set-m49dn is not available
Oct 24 18:37:58.766: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 18:37:59.759: INFO: Pod daemon-set-ppjs6 is not available
Oct 24 18:37:59.764: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4280, will wait for the garbage collector to delete the pods
Oct 24 18:37:59.834: INFO: Deleting DaemonSet.extensions daemon-set took: 8.689447ms
Oct 24 18:38:00.235: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.327373ms
Oct 24 18:38:09.139: INFO: Number of nodes with available pods: 0
Oct 24 18:38:09.139: INFO: Number of running nodes: 0, number of available pods: 0
Oct 24 18:38:09.143: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4280/daemonsets","resourceVersion":"18319"},"items":null}

Oct 24 18:38:09.146: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4280/pods","resourceVersion":"18319"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:38:09.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4280" for this suite.
Oct 24 18:38:15.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:38:15.327: INFO: namespace daemonsets-4280 deletion completed in 6.162005878s

• [SLOW TEST:23.738 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:38:15.327: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 18:38:15.374: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:38:16.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5058" for this suite.
Oct 24 18:38:22.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:38:22.622: INFO: namespace custom-resource-definition-5058 deletion completed in 6.167101035s

• [SLOW TEST:7.295 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:32
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:38:22.623: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-7516356e-f68d-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume secrets
Oct 24 18:38:22.685: INFO: Waiting up to 5m0s for pod "pod-secrets-7516ed9d-f68d-11e9-8e41-6682758dfd28" in namespace "secrets-134" to be "success or failure"
Oct 24 18:38:22.693: INFO: Pod "pod-secrets-7516ed9d-f68d-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 8.324877ms
Oct 24 18:38:24.699: INFO: Pod "pod-secrets-7516ed9d-f68d-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.014257489s
Oct 24 18:38:26.705: INFO: Pod "pod-secrets-7516ed9d-f68d-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020107585s
STEP: Saw pod success
Oct 24 18:38:26.705: INFO: Pod "pod-secrets-7516ed9d-f68d-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:38:26.710: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-secrets-7516ed9d-f68d-11e9-8e41-6682758dfd28 container secret-volume-test: <nil>
STEP: delete the pod
Oct 24 18:38:26.744: INFO: Waiting for pod pod-secrets-7516ed9d-f68d-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:38:26.748: INFO: Pod pod-secrets-7516ed9d-f68d-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:38:26.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-134" for this suite.
Oct 24 18:38:32.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:38:32.940: INFO: namespace secrets-134 deletion completed in 6.184878841s

• [SLOW TEST:10.318 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:38:32.941: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 18:38:32.999: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7b3c96b6-f68d-11e9-8e41-6682758dfd28" in namespace "projected-7566" to be "success or failure"
Oct 24 18:38:33.005: INFO: Pod "downwardapi-volume-7b3c96b6-f68d-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.778674ms
Oct 24 18:38:35.012: INFO: Pod "downwardapi-volume-7b3c96b6-f68d-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013054267s
STEP: Saw pod success
Oct 24 18:38:35.012: INFO: Pod "downwardapi-volume-7b3c96b6-f68d-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:38:35.017: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-7b3c96b6-f68d-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 18:38:35.049: INFO: Waiting for pod downwardapi-volume-7b3c96b6-f68d-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:38:35.053: INFO: Pod downwardapi-volume-7b3c96b6-f68d-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:38:35.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7566" for this suite.
Oct 24 18:38:41.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:38:41.230: INFO: namespace projected-7566 deletion completed in 6.172835179s

• [SLOW TEST:8.290 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:38:41.231: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-802d2777-f68d-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume configMaps
Oct 24 18:38:41.292: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-802de991-f68d-11e9-8e41-6682758dfd28" in namespace "projected-7495" to be "success or failure"
Oct 24 18:38:41.295: INFO: Pod "pod-projected-configmaps-802de991-f68d-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 3.330822ms
Oct 24 18:38:43.302: INFO: Pod "pod-projected-configmaps-802de991-f68d-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009728076s
STEP: Saw pod success
Oct 24 18:38:43.302: INFO: Pod "pod-projected-configmaps-802de991-f68d-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:38:43.306: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-projected-configmaps-802de991-f68d-11e9-8e41-6682758dfd28 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 18:38:43.336: INFO: Waiting for pod pod-projected-configmaps-802de991-f68d-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:38:43.340: INFO: Pod pod-projected-configmaps-802de991-f68d-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:38:43.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7495" for this suite.
Oct 24 18:38:49.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:38:49.516: INFO: namespace projected-7495 deletion completed in 6.171033548s

• [SLOW TEST:8.286 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:38:49.516: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 18:38:49.573: INFO: Waiting up to 5m0s for pod "downwardapi-volume-851d7559-f68d-11e9-8e41-6682758dfd28" in namespace "projected-3419" to be "success or failure"
Oct 24 18:38:49.580: INFO: Pod "downwardapi-volume-851d7559-f68d-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 6.500068ms
Oct 24 18:38:51.585: INFO: Pod "downwardapi-volume-851d7559-f68d-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011922433s
STEP: Saw pod success
Oct 24 18:38:51.585: INFO: Pod "downwardapi-volume-851d7559-f68d-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:38:51.589: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-851d7559-f68d-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 18:38:51.621: INFO: Waiting for pod downwardapi-volume-851d7559-f68d-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:38:51.626: INFO: Pod downwardapi-volume-851d7559-f68d-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:38:51.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3419" for this suite.
Oct 24 18:38:57.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:38:57.800: INFO: namespace projected-3419 deletion completed in 6.169540778s

• [SLOW TEST:8.284 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:38:57.801: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Oct 24 18:38:57.856: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-464213187 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:38:58.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5066" for this suite.
Oct 24 18:39:04.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:39:04.220: INFO: namespace kubectl-5066 deletion completed in 6.187593135s

• [SLOW TEST:6.419 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:39:04.220: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-8de0ca04-f68d-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume configMaps
Oct 24 18:39:04.279: INFO: Waiting up to 5m0s for pod "pod-configmaps-8de19b6f-f68d-11e9-8e41-6682758dfd28" in namespace "configmap-7581" to be "success or failure"
Oct 24 18:39:04.285: INFO: Pod "pod-configmaps-8de19b6f-f68d-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.338811ms
Oct 24 18:39:06.290: INFO: Pod "pod-configmaps-8de19b6f-f68d-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.0110821s
Oct 24 18:39:08.296: INFO: Pod "pod-configmaps-8de19b6f-f68d-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016254321s
STEP: Saw pod success
Oct 24 18:39:08.296: INFO: Pod "pod-configmaps-8de19b6f-f68d-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:39:08.300: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-configmaps-8de19b6f-f68d-11e9-8e41-6682758dfd28 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 18:39:08.329: INFO: Waiting for pod pod-configmaps-8de19b6f-f68d-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:39:08.333: INFO: Pod pod-configmaps-8de19b6f-f68d-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:39:08.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7581" for this suite.
Oct 24 18:39:14.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:39:14.502: INFO: namespace configmap-7581 deletion completed in 6.163483707s

• [SLOW TEST:10.282 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:39:14.502: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 18:39:14.565: INFO: Waiting up to 5m0s for pod "downwardapi-volume-940317a0-f68d-11e9-8e41-6682758dfd28" in namespace "projected-4145" to be "success or failure"
Oct 24 18:39:14.573: INFO: Pod "downwardapi-volume-940317a0-f68d-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 7.527156ms
Oct 24 18:39:16.579: INFO: Pod "downwardapi-volume-940317a0-f68d-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.01323197s
Oct 24 18:39:18.584: INFO: Pod "downwardapi-volume-940317a0-f68d-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018736402s
STEP: Saw pod success
Oct 24 18:39:18.584: INFO: Pod "downwardapi-volume-940317a0-f68d-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:39:18.588: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-940317a0-f68d-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 18:39:18.615: INFO: Waiting for pod downwardapi-volume-940317a0-f68d-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:39:18.619: INFO: Pod downwardapi-volume-940317a0-f68d-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:39:18.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4145" for this suite.
Oct 24 18:39:24.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:39:24.798: INFO: namespace projected-4145 deletion completed in 6.173190814s

• [SLOW TEST:10.296 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:39:24.798: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct 24 18:39:24.857: INFO: Waiting up to 5m0s for pod "downward-api-9a2586df-f68d-11e9-8e41-6682758dfd28" in namespace "downward-api-7928" to be "success or failure"
Oct 24 18:39:24.862: INFO: Pod "downward-api-9a2586df-f68d-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.290098ms
Oct 24 18:39:26.868: INFO: Pod "downward-api-9a2586df-f68d-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010386787s
STEP: Saw pod success
Oct 24 18:39:26.868: INFO: Pod "downward-api-9a2586df-f68d-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:39:26.872: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downward-api-9a2586df-f68d-11e9-8e41-6682758dfd28 container dapi-container: <nil>
STEP: delete the pod
Oct 24 18:39:26.914: INFO: Waiting for pod downward-api-9a2586df-f68d-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:39:26.919: INFO: Pod downward-api-9a2586df-f68d-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:39:26.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7928" for this suite.
Oct 24 18:39:32.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:39:33.125: INFO: namespace downward-api-7928 deletion completed in 6.201045819s

• [SLOW TEST:8.327 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:39:33.126: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Oct 24 18:39:33.215: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7761,SelfLink:/api/v1/namespaces/watch-7761/configmaps/e2e-watch-test-label-changed,UID:9f1db01e-f68d-11e9-a6ac-005056ab7215,ResourceVersion:18687,Generation:0,CreationTimestamp:2019-10-24 18:39:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 24 18:39:33.215: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7761,SelfLink:/api/v1/namespaces/watch-7761/configmaps/e2e-watch-test-label-changed,UID:9f1db01e-f68d-11e9-a6ac-005056ab7215,ResourceVersion:18688,Generation:0,CreationTimestamp:2019-10-24 18:39:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 24 18:39:33.215: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7761,SelfLink:/api/v1/namespaces/watch-7761/configmaps/e2e-watch-test-label-changed,UID:9f1db01e-f68d-11e9-a6ac-005056ab7215,ResourceVersion:18689,Generation:0,CreationTimestamp:2019-10-24 18:39:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Oct 24 18:39:43.254: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7761,SelfLink:/api/v1/namespaces/watch-7761/configmaps/e2e-watch-test-label-changed,UID:9f1db01e-f68d-11e9-a6ac-005056ab7215,ResourceVersion:18706,Generation:0,CreationTimestamp:2019-10-24 18:39:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 24 18:39:43.255: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7761,SelfLink:/api/v1/namespaces/watch-7761/configmaps/e2e-watch-test-label-changed,UID:9f1db01e-f68d-11e9-a6ac-005056ab7215,ResourceVersion:18707,Generation:0,CreationTimestamp:2019-10-24 18:39:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Oct 24 18:39:43.255: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7761,SelfLink:/api/v1/namespaces/watch-7761/configmaps/e2e-watch-test-label-changed,UID:9f1db01e-f68d-11e9-a6ac-005056ab7215,ResourceVersion:18708,Generation:0,CreationTimestamp:2019-10-24 18:39:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:39:43.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7761" for this suite.
Oct 24 18:39:49.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:39:49.428: INFO: namespace watch-7761 deletion completed in 6.168921357s

• [SLOW TEST:16.303 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:39:49.429: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 18:39:49.488: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a8d3af91-f68d-11e9-8e41-6682758dfd28" in namespace "downward-api-7310" to be "success or failure"
Oct 24 18:39:49.495: INFO: Pod "downwardapi-volume-a8d3af91-f68d-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 6.840679ms
Oct 24 18:39:51.501: INFO: Pod "downwardapi-volume-a8d3af91-f68d-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012203277s
STEP: Saw pod success
Oct 24 18:39:51.501: INFO: Pod "downwardapi-volume-a8d3af91-f68d-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:39:51.505: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-a8d3af91-f68d-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 18:39:51.545: INFO: Waiting for pod downwardapi-volume-a8d3af91-f68d-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:39:51.548: INFO: Pod downwardapi-volume-a8d3af91-f68d-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:39:51.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7310" for this suite.
Oct 24 18:39:57.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:39:57.722: INFO: namespace downward-api-7310 deletion completed in 6.168874569s

• [SLOW TEST:8.294 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:39:57.723: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-6132
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 24 18:39:57.779: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 24 18:40:19.881: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.176:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6132 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 18:40:19.881: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 18:40:20.029: INFO: Found all expected endpoints: [netserver-0]
Oct 24 18:40:20.034: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.158:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6132 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 18:40:20.034: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 18:40:20.184: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:40:20.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6132" for this suite.
Oct 24 18:40:42.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:40:42.370: INFO: namespace pod-network-test-6132 deletion completed in 22.168952329s

• [SLOW TEST:44.647 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:40:42.371: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 24 18:40:42.434: INFO: (0) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 8.870674ms)
Oct 24 18:40:42.439: INFO: (1) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.379829ms)
Oct 24 18:40:42.444: INFO: (2) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.148891ms)
Oct 24 18:40:42.450: INFO: (3) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.150257ms)
Oct 24 18:40:42.455: INFO: (4) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.9013ms)
Oct 24 18:40:42.460: INFO: (5) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.186945ms)
Oct 24 18:40:42.465: INFO: (6) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.043799ms)
Oct 24 18:40:42.470: INFO: (7) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.127867ms)
Oct 24 18:40:42.476: INFO: (8) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.494265ms)
Oct 24 18:40:42.481: INFO: (9) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.361514ms)
Oct 24 18:40:42.486: INFO: (10) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.267632ms)
Oct 24 18:40:42.492: INFO: (11) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.105534ms)
Oct 24 18:40:42.497: INFO: (12) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.988471ms)
Oct 24 18:40:42.503: INFO: (13) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 6.233578ms)
Oct 24 18:40:42.508: INFO: (14) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.461761ms)
Oct 24 18:40:42.514: INFO: (15) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.225593ms)
Oct 24 18:40:42.519: INFO: (16) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.400923ms)
Oct 24 18:40:42.524: INFO: (17) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.885185ms)
Oct 24 18:40:42.530: INFO: (18) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.863226ms)
Oct 24 18:40:42.535: INFO: (19) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.253125ms)
[AfterEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:40:42.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9633" for this suite.
Oct 24 18:40:48.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:40:48.699: INFO: namespace proxy-9633 deletion completed in 6.158501302s

• [SLOW TEST:6.328 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:40:48.699: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6809
I1024 18:40:48.752802      19 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6809, replica count: 1
I1024 18:40:49.803397      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1024 18:40:50.803702      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 24 18:40:50.918: INFO: Created: latency-svc-s954g
Oct 24 18:40:50.925: INFO: Got endpoints: latency-svc-s954g [21.773749ms]
Oct 24 18:40:50.963: INFO: Created: latency-svc-qr7dd
Oct 24 18:40:50.966: INFO: Got endpoints: latency-svc-qr7dd [39.40613ms]
Oct 24 18:40:50.982: INFO: Created: latency-svc-k6pbs
Oct 24 18:40:50.988: INFO: Got endpoints: latency-svc-k6pbs [62.403471ms]
Oct 24 18:40:50.992: INFO: Created: latency-svc-5qdfm
Oct 24 18:40:51.004: INFO: Got endpoints: latency-svc-5qdfm [75.48409ms]
Oct 24 18:40:51.006: INFO: Created: latency-svc-bzgc9
Oct 24 18:40:51.013: INFO: Got endpoints: latency-svc-bzgc9 [85.889447ms]
Oct 24 18:40:51.023: INFO: Created: latency-svc-9jbvb
Oct 24 18:40:51.030: INFO: Got endpoints: latency-svc-9jbvb [103.051037ms]
Oct 24 18:40:51.036: INFO: Created: latency-svc-29nnf
Oct 24 18:40:51.042: INFO: Created: latency-svc-hvdmd
Oct 24 18:40:51.045: INFO: Got endpoints: latency-svc-29nnf [117.666469ms]
Oct 24 18:40:51.052: INFO: Got endpoints: latency-svc-hvdmd [124.733614ms]
Oct 24 18:40:51.059: INFO: Created: latency-svc-cw2vc
Oct 24 18:40:51.065: INFO: Created: latency-svc-nm7v8
Oct 24 18:40:51.067: INFO: Got endpoints: latency-svc-cw2vc [139.152791ms]
Oct 24 18:40:51.073: INFO: Got endpoints: latency-svc-nm7v8 [145.099358ms]
Oct 24 18:40:51.075: INFO: Created: latency-svc-j6zlg
Oct 24 18:40:51.083: INFO: Got endpoints: latency-svc-j6zlg [155.351637ms]
Oct 24 18:40:51.088: INFO: Created: latency-svc-nv2jw
Oct 24 18:40:51.094: INFO: Got endpoints: latency-svc-nv2jw [165.944547ms]
Oct 24 18:40:51.096: INFO: Created: latency-svc-zv9xx
Oct 24 18:40:51.107: INFO: Got endpoints: latency-svc-zv9xx [178.957594ms]
Oct 24 18:40:51.110: INFO: Created: latency-svc-kgnph
Oct 24 18:40:51.114: INFO: Got endpoints: latency-svc-kgnph [186.388167ms]
Oct 24 18:40:51.120: INFO: Created: latency-svc-8fsqt
Oct 24 18:40:51.126: INFO: Got endpoints: latency-svc-8fsqt [197.699121ms]
Oct 24 18:40:51.133: INFO: Created: latency-svc-vslrk
Oct 24 18:40:51.139: INFO: Got endpoints: latency-svc-vslrk [211.115795ms]
Oct 24 18:40:51.140: INFO: Created: latency-svc-gfq2d
Oct 24 18:40:51.146: INFO: Got endpoints: latency-svc-gfq2d [180.449851ms]
Oct 24 18:40:51.149: INFO: Created: latency-svc-bllcl
Oct 24 18:40:51.157: INFO: Created: latency-svc-xcp2w
Oct 24 18:40:51.157: INFO: Got endpoints: latency-svc-bllcl [169.076993ms]
Oct 24 18:40:51.165: INFO: Got endpoints: latency-svc-xcp2w [25.888949ms]
Oct 24 18:40:51.175: INFO: Created: latency-svc-p2n5r
Oct 24 18:40:51.184: INFO: Got endpoints: latency-svc-p2n5r [180.799226ms]
Oct 24 18:40:51.188: INFO: Created: latency-svc-657m6
Oct 24 18:40:51.190: INFO: Got endpoints: latency-svc-657m6 [176.646691ms]
Oct 24 18:40:51.199: INFO: Created: latency-svc-km9wn
Oct 24 18:40:51.209: INFO: Got endpoints: latency-svc-km9wn [178.40195ms]
Oct 24 18:40:51.211: INFO: Created: latency-svc-wzxzh
Oct 24 18:40:51.219: INFO: Got endpoints: latency-svc-wzxzh [174.078493ms]
Oct 24 18:40:51.224: INFO: Created: latency-svc-69wtq
Oct 24 18:40:51.231: INFO: Got endpoints: latency-svc-69wtq [178.915539ms]
Oct 24 18:40:51.236: INFO: Created: latency-svc-pqmr5
Oct 24 18:40:51.241: INFO: Got endpoints: latency-svc-pqmr5 [174.674928ms]
Oct 24 18:40:51.244: INFO: Created: latency-svc-h9k2z
Oct 24 18:40:51.254: INFO: Got endpoints: latency-svc-h9k2z [181.429314ms]
Oct 24 18:40:51.255: INFO: Created: latency-svc-xjxqx
Oct 24 18:40:51.264: INFO: Got endpoints: latency-svc-xjxqx [180.748351ms]
Oct 24 18:40:51.268: INFO: Created: latency-svc-h4c8c
Oct 24 18:40:51.276: INFO: Got endpoints: latency-svc-h4c8c [182.138225ms]
Oct 24 18:40:51.280: INFO: Created: latency-svc-h6tnt
Oct 24 18:40:51.287: INFO: Got endpoints: latency-svc-h6tnt [179.924728ms]
Oct 24 18:40:51.291: INFO: Created: latency-svc-57xl5
Oct 24 18:40:51.296: INFO: Got endpoints: latency-svc-57xl5 [181.771957ms]
Oct 24 18:40:51.303: INFO: Created: latency-svc-lp5hf
Oct 24 18:40:51.312: INFO: Got endpoints: latency-svc-lp5hf [185.905817ms]
Oct 24 18:40:51.315: INFO: Created: latency-svc-g2m4v
Oct 24 18:40:51.316: INFO: Got endpoints: latency-svc-g2m4v [169.43011ms]
Oct 24 18:40:51.324: INFO: Created: latency-svc-8vrm4
Oct 24 18:40:51.338: INFO: Got endpoints: latency-svc-8vrm4 [181.073124ms]
Oct 24 18:40:51.343: INFO: Created: latency-svc-m5zt7
Oct 24 18:40:51.346: INFO: Got endpoints: latency-svc-m5zt7 [180.45526ms]
Oct 24 18:40:51.352: INFO: Created: latency-svc-pdlqd
Oct 24 18:40:51.358: INFO: Got endpoints: latency-svc-pdlqd [173.074045ms]
Oct 24 18:40:51.364: INFO: Created: latency-svc-829tq
Oct 24 18:40:51.369: INFO: Got endpoints: latency-svc-829tq [179.0714ms]
Oct 24 18:40:51.374: INFO: Created: latency-svc-pcgxb
Oct 24 18:40:51.382: INFO: Created: latency-svc-xbq8v
Oct 24 18:40:51.383: INFO: Got endpoints: latency-svc-pcgxb [174.240454ms]
Oct 24 18:40:51.387: INFO: Got endpoints: latency-svc-xbq8v [168.21786ms]
Oct 24 18:40:51.388: INFO: Created: latency-svc-9rr2n
Oct 24 18:40:51.396: INFO: Got endpoints: latency-svc-9rr2n [165.078877ms]
Oct 24 18:40:51.398: INFO: Created: latency-svc-nrgx7
Oct 24 18:40:51.415: INFO: Created: latency-svc-2kb6n
Oct 24 18:40:51.422: INFO: Created: latency-svc-lcwgn
Oct 24 18:40:51.427: INFO: Got endpoints: latency-svc-nrgx7 [185.188242ms]
Oct 24 18:40:51.434: INFO: Created: latency-svc-xsn42
Oct 24 18:40:51.440: INFO: Created: latency-svc-b97px
Oct 24 18:40:51.445: INFO: Created: latency-svc-s2flm
Oct 24 18:40:51.456: INFO: Created: latency-svc-86mqp
Oct 24 18:40:51.468: INFO: Created: latency-svc-8zs44
Oct 24 18:40:51.476: INFO: Created: latency-svc-d7fnf
Oct 24 18:40:51.479: INFO: Got endpoints: latency-svc-2kb6n [224.778098ms]
Oct 24 18:40:51.488: INFO: Created: latency-svc-mp6s6
Oct 24 18:40:51.493: INFO: Created: latency-svc-2xw4j
Oct 24 18:40:51.497: INFO: Created: latency-svc-8lqmk
Oct 24 18:40:51.506: INFO: Created: latency-svc-5vccn
Oct 24 18:40:51.512: INFO: Created: latency-svc-5s22b
Oct 24 18:40:51.520: INFO: Created: latency-svc-s5tkn
Oct 24 18:40:51.525: INFO: Got endpoints: latency-svc-lcwgn [260.495768ms]
Oct 24 18:40:51.538: INFO: Created: latency-svc-s8pmb
Oct 24 18:40:51.545: INFO: Created: latency-svc-8pdxt
Oct 24 18:40:51.553: INFO: Created: latency-svc-cnf78
Oct 24 18:40:51.573: INFO: Got endpoints: latency-svc-xsn42 [296.599871ms]
Oct 24 18:40:51.584: INFO: Created: latency-svc-x5sk9
Oct 24 18:40:51.625: INFO: Got endpoints: latency-svc-b97px [338.237005ms]
Oct 24 18:40:51.638: INFO: Created: latency-svc-wjk8l
Oct 24 18:40:51.673: INFO: Got endpoints: latency-svc-s2flm [376.766195ms]
Oct 24 18:40:51.688: INFO: Created: latency-svc-kl9qr
Oct 24 18:40:51.724: INFO: Got endpoints: latency-svc-86mqp [412.182184ms]
Oct 24 18:40:51.736: INFO: Created: latency-svc-srcks
Oct 24 18:40:51.774: INFO: Got endpoints: latency-svc-8zs44 [457.852831ms]
Oct 24 18:40:51.785: INFO: Created: latency-svc-6ntc4
Oct 24 18:40:51.823: INFO: Got endpoints: latency-svc-d7fnf [484.236223ms]
Oct 24 18:40:51.838: INFO: Created: latency-svc-vd9rq
Oct 24 18:40:51.874: INFO: Got endpoints: latency-svc-mp6s6 [528.122732ms]
Oct 24 18:40:51.888: INFO: Created: latency-svc-sjwts
Oct 24 18:40:51.927: INFO: Got endpoints: latency-svc-2xw4j [568.971809ms]
Oct 24 18:40:51.941: INFO: Created: latency-svc-lzwj6
Oct 24 18:40:51.974: INFO: Got endpoints: latency-svc-8lqmk [604.94803ms]
Oct 24 18:40:51.988: INFO: Created: latency-svc-2s9l8
Oct 24 18:40:52.024: INFO: Got endpoints: latency-svc-5vccn [640.387674ms]
Oct 24 18:40:52.037: INFO: Created: latency-svc-nfg8l
Oct 24 18:40:52.073: INFO: Got endpoints: latency-svc-5s22b [685.762044ms]
Oct 24 18:40:52.087: INFO: Created: latency-svc-lwkrw
Oct 24 18:40:52.125: INFO: Got endpoints: latency-svc-s5tkn [728.521847ms]
Oct 24 18:40:52.141: INFO: Created: latency-svc-v725z
Oct 24 18:40:52.174: INFO: Got endpoints: latency-svc-s8pmb [747.78083ms]
Oct 24 18:40:52.186: INFO: Created: latency-svc-k48cw
Oct 24 18:40:52.224: INFO: Got endpoints: latency-svc-8pdxt [744.477139ms]
Oct 24 18:40:52.237: INFO: Created: latency-svc-9n97z
Oct 24 18:40:52.273: INFO: Got endpoints: latency-svc-cnf78 [748.829718ms]
Oct 24 18:40:52.288: INFO: Created: latency-svc-kw8wl
Oct 24 18:40:52.325: INFO: Got endpoints: latency-svc-x5sk9 [752.222497ms]
Oct 24 18:40:52.342: INFO: Created: latency-svc-wqqkw
Oct 24 18:40:52.374: INFO: Got endpoints: latency-svc-wjk8l [749.110532ms]
Oct 24 18:40:52.389: INFO: Created: latency-svc-2mdd6
Oct 24 18:40:52.427: INFO: Got endpoints: latency-svc-kl9qr [753.765861ms]
Oct 24 18:40:52.442: INFO: Created: latency-svc-f9xhp
Oct 24 18:40:52.475: INFO: Got endpoints: latency-svc-srcks [750.523234ms]
Oct 24 18:40:52.487: INFO: Created: latency-svc-hrwhm
Oct 24 18:40:52.524: INFO: Got endpoints: latency-svc-6ntc4 [750.014053ms]
Oct 24 18:40:52.544: INFO: Created: latency-svc-pl8zp
Oct 24 18:40:52.576: INFO: Got endpoints: latency-svc-vd9rq [753.027684ms]
Oct 24 18:40:52.587: INFO: Created: latency-svc-ck689
Oct 24 18:40:52.624: INFO: Got endpoints: latency-svc-sjwts [750.147971ms]
Oct 24 18:40:52.642: INFO: Created: latency-svc-lwzk9
Oct 24 18:40:52.674: INFO: Got endpoints: latency-svc-lzwj6 [747.130986ms]
Oct 24 18:40:52.688: INFO: Created: latency-svc-8v28r
Oct 24 18:40:52.723: INFO: Got endpoints: latency-svc-2s9l8 [749.210037ms]
Oct 24 18:40:52.738: INFO: Created: latency-svc-k9k8h
Oct 24 18:40:52.778: INFO: Got endpoints: latency-svc-nfg8l [753.858451ms]
Oct 24 18:40:52.791: INFO: Created: latency-svc-xzjzb
Oct 24 18:40:52.824: INFO: Got endpoints: latency-svc-lwkrw [751.037977ms]
Oct 24 18:40:52.836: INFO: Created: latency-svc-l46vr
Oct 24 18:40:52.874: INFO: Got endpoints: latency-svc-v725z [748.758346ms]
Oct 24 18:40:52.887: INFO: Created: latency-svc-w6xz8
Oct 24 18:40:52.924: INFO: Got endpoints: latency-svc-k48cw [749.244643ms]
Oct 24 18:40:52.941: INFO: Created: latency-svc-hf8wj
Oct 24 18:40:52.974: INFO: Got endpoints: latency-svc-9n97z [750.107441ms]
Oct 24 18:40:52.988: INFO: Created: latency-svc-zfsk8
Oct 24 18:40:53.024: INFO: Got endpoints: latency-svc-kw8wl [750.383017ms]
Oct 24 18:40:53.057: INFO: Created: latency-svc-gh79x
Oct 24 18:40:53.075: INFO: Got endpoints: latency-svc-wqqkw [749.598812ms]
Oct 24 18:40:53.089: INFO: Created: latency-svc-sblqp
Oct 24 18:40:53.124: INFO: Got endpoints: latency-svc-2mdd6 [749.78237ms]
Oct 24 18:40:53.136: INFO: Created: latency-svc-vgwks
Oct 24 18:40:53.173: INFO: Got endpoints: latency-svc-f9xhp [746.564773ms]
Oct 24 18:40:53.187: INFO: Created: latency-svc-cs98d
Oct 24 18:40:53.223: INFO: Got endpoints: latency-svc-hrwhm [748.823195ms]
Oct 24 18:40:53.236: INFO: Created: latency-svc-wkk78
Oct 24 18:40:53.274: INFO: Got endpoints: latency-svc-pl8zp [750.093107ms]
Oct 24 18:40:53.288: INFO: Created: latency-svc-95srw
Oct 24 18:40:53.324: INFO: Got endpoints: latency-svc-ck689 [748.415435ms]
Oct 24 18:40:53.337: INFO: Created: latency-svc-bws2g
Oct 24 18:40:53.373: INFO: Got endpoints: latency-svc-lwzk9 [749.068616ms]
Oct 24 18:40:53.386: INFO: Created: latency-svc-st55s
Oct 24 18:40:53.423: INFO: Got endpoints: latency-svc-8v28r [749.072824ms]
Oct 24 18:40:53.437: INFO: Created: latency-svc-fm75w
Oct 24 18:40:53.478: INFO: Got endpoints: latency-svc-k9k8h [754.956775ms]
Oct 24 18:40:53.490: INFO: Created: latency-svc-wwhlm
Oct 24 18:40:53.524: INFO: Got endpoints: latency-svc-xzjzb [746.523007ms]
Oct 24 18:40:53.536: INFO: Created: latency-svc-dslm5
Oct 24 18:40:53.573: INFO: Got endpoints: latency-svc-l46vr [748.855809ms]
Oct 24 18:40:53.584: INFO: Created: latency-svc-sjscq
Oct 24 18:40:53.622: INFO: Got endpoints: latency-svc-w6xz8 [748.546978ms]
Oct 24 18:40:53.633: INFO: Created: latency-svc-xbfvw
Oct 24 18:40:53.674: INFO: Got endpoints: latency-svc-hf8wj [750.153677ms]
Oct 24 18:40:53.688: INFO: Created: latency-svc-vlwbc
Oct 24 18:40:53.723: INFO: Got endpoints: latency-svc-zfsk8 [749.154686ms]
Oct 24 18:40:53.739: INFO: Created: latency-svc-whg95
Oct 24 18:40:53.775: INFO: Got endpoints: latency-svc-gh79x [750.820344ms]
Oct 24 18:40:53.789: INFO: Created: latency-svc-4d2lh
Oct 24 18:40:53.823: INFO: Got endpoints: latency-svc-sblqp [748.845982ms]
Oct 24 18:40:53.836: INFO: Created: latency-svc-qm9t9
Oct 24 18:40:53.874: INFO: Got endpoints: latency-svc-vgwks [749.645462ms]
Oct 24 18:40:53.888: INFO: Created: latency-svc-k5s46
Oct 24 18:40:53.933: INFO: Got endpoints: latency-svc-cs98d [759.950935ms]
Oct 24 18:40:53.949: INFO: Created: latency-svc-sfc8t
Oct 24 18:40:53.974: INFO: Got endpoints: latency-svc-wkk78 [750.18643ms]
Oct 24 18:40:53.986: INFO: Created: latency-svc-csmrn
Oct 24 18:40:54.024: INFO: Got endpoints: latency-svc-95srw [749.751648ms]
Oct 24 18:40:54.038: INFO: Created: latency-svc-gnbwv
Oct 24 18:40:54.073: INFO: Got endpoints: latency-svc-bws2g [748.326432ms]
Oct 24 18:40:54.096: INFO: Created: latency-svc-8wr7c
Oct 24 18:40:54.124: INFO: Got endpoints: latency-svc-st55s [750.301919ms]
Oct 24 18:40:54.144: INFO: Created: latency-svc-n8rz2
Oct 24 18:40:54.173: INFO: Got endpoints: latency-svc-fm75w [749.605488ms]
Oct 24 18:40:54.188: INFO: Created: latency-svc-cptnd
Oct 24 18:40:54.224: INFO: Got endpoints: latency-svc-wwhlm [745.472372ms]
Oct 24 18:40:54.238: INFO: Created: latency-svc-lm6hj
Oct 24 18:40:54.274: INFO: Got endpoints: latency-svc-dslm5 [749.66986ms]
Oct 24 18:40:54.287: INFO: Created: latency-svc-2g67x
Oct 24 18:40:54.326: INFO: Got endpoints: latency-svc-sjscq [752.828309ms]
Oct 24 18:40:54.340: INFO: Created: latency-svc-mkt8r
Oct 24 18:40:54.373: INFO: Got endpoints: latency-svc-xbfvw [750.659831ms]
Oct 24 18:40:54.388: INFO: Created: latency-svc-952l4
Oct 24 18:40:54.423: INFO: Got endpoints: latency-svc-vlwbc [748.99081ms]
Oct 24 18:40:54.434: INFO: Created: latency-svc-z668b
Oct 24 18:40:54.475: INFO: Got endpoints: latency-svc-whg95 [752.104833ms]
Oct 24 18:40:54.485: INFO: Created: latency-svc-t4qxc
Oct 24 18:40:54.524: INFO: Got endpoints: latency-svc-4d2lh [749.611787ms]
Oct 24 18:40:54.536: INFO: Created: latency-svc-bl5wn
Oct 24 18:40:54.574: INFO: Got endpoints: latency-svc-qm9t9 [750.271565ms]
Oct 24 18:40:54.585: INFO: Created: latency-svc-7xsk9
Oct 24 18:40:54.624: INFO: Got endpoints: latency-svc-k5s46 [749.892215ms]
Oct 24 18:40:54.636: INFO: Created: latency-svc-cv9l9
Oct 24 18:40:54.674: INFO: Got endpoints: latency-svc-sfc8t [740.41357ms]
Oct 24 18:40:54.686: INFO: Created: latency-svc-5fk9g
Oct 24 18:40:54.725: INFO: Got endpoints: latency-svc-csmrn [751.628763ms]
Oct 24 18:40:54.738: INFO: Created: latency-svc-gl5sq
Oct 24 18:40:54.774: INFO: Got endpoints: latency-svc-gnbwv [750.245875ms]
Oct 24 18:40:54.788: INFO: Created: latency-svc-6jxzj
Oct 24 18:40:54.825: INFO: Got endpoints: latency-svc-8wr7c [752.007451ms]
Oct 24 18:40:54.838: INFO: Created: latency-svc-qgcwx
Oct 24 18:40:54.875: INFO: Got endpoints: latency-svc-n8rz2 [751.292145ms]
Oct 24 18:40:54.887: INFO: Created: latency-svc-pjjc2
Oct 24 18:40:54.926: INFO: Got endpoints: latency-svc-cptnd [753.698242ms]
Oct 24 18:40:54.944: INFO: Created: latency-svc-wvc69
Oct 24 18:40:54.976: INFO: Got endpoints: latency-svc-lm6hj [752.648845ms]
Oct 24 18:40:54.999: INFO: Created: latency-svc-fk2bc
Oct 24 18:40:55.024: INFO: Got endpoints: latency-svc-2g67x [749.762874ms]
Oct 24 18:40:55.038: INFO: Created: latency-svc-jnsq7
Oct 24 18:40:55.074: INFO: Got endpoints: latency-svc-mkt8r [748.149491ms]
Oct 24 18:40:55.088: INFO: Created: latency-svc-2tjzk
Oct 24 18:40:55.124: INFO: Got endpoints: latency-svc-952l4 [750.625885ms]
Oct 24 18:40:55.141: INFO: Created: latency-svc-j8htw
Oct 24 18:40:55.174: INFO: Got endpoints: latency-svc-z668b [750.958942ms]
Oct 24 18:40:55.186: INFO: Created: latency-svc-wqn4g
Oct 24 18:40:55.224: INFO: Got endpoints: latency-svc-t4qxc [748.979994ms]
Oct 24 18:40:55.238: INFO: Created: latency-svc-ll2q2
Oct 24 18:40:55.274: INFO: Got endpoints: latency-svc-bl5wn [749.003838ms]
Oct 24 18:40:55.286: INFO: Created: latency-svc-986mj
Oct 24 18:40:55.323: INFO: Got endpoints: latency-svc-7xsk9 [749.071213ms]
Oct 24 18:40:55.355: INFO: Created: latency-svc-92fwt
Oct 24 18:40:55.373: INFO: Got endpoints: latency-svc-cv9l9 [749.293173ms]
Oct 24 18:40:55.384: INFO: Created: latency-svc-g8cfd
Oct 24 18:40:55.423: INFO: Got endpoints: latency-svc-5fk9g [749.001031ms]
Oct 24 18:40:55.435: INFO: Created: latency-svc-sln92
Oct 24 18:40:55.473: INFO: Got endpoints: latency-svc-gl5sq [747.311545ms]
Oct 24 18:40:55.488: INFO: Created: latency-svc-sv2mk
Oct 24 18:40:55.524: INFO: Got endpoints: latency-svc-6jxzj [749.573058ms]
Oct 24 18:40:55.537: INFO: Created: latency-svc-7524s
Oct 24 18:40:55.574: INFO: Got endpoints: latency-svc-qgcwx [749.109274ms]
Oct 24 18:40:55.589: INFO: Created: latency-svc-bqz9j
Oct 24 18:40:55.625: INFO: Got endpoints: latency-svc-pjjc2 [750.198973ms]
Oct 24 18:40:55.639: INFO: Created: latency-svc-8fxk7
Oct 24 18:40:55.675: INFO: Got endpoints: latency-svc-wvc69 [747.860599ms]
Oct 24 18:40:55.687: INFO: Created: latency-svc-t2vql
Oct 24 18:40:55.725: INFO: Got endpoints: latency-svc-fk2bc [748.087416ms]
Oct 24 18:40:55.739: INFO: Created: latency-svc-l5fjw
Oct 24 18:40:55.773: INFO: Got endpoints: latency-svc-jnsq7 [749.23255ms]
Oct 24 18:40:55.790: INFO: Created: latency-svc-6prkc
Oct 24 18:40:55.823: INFO: Got endpoints: latency-svc-2tjzk [748.807801ms]
Oct 24 18:40:55.834: INFO: Created: latency-svc-6c5k7
Oct 24 18:40:55.876: INFO: Got endpoints: latency-svc-j8htw [751.677959ms]
Oct 24 18:40:55.890: INFO: Created: latency-svc-9pxkk
Oct 24 18:40:55.925: INFO: Got endpoints: latency-svc-wqn4g [750.741206ms]
Oct 24 18:40:55.942: INFO: Created: latency-svc-2ct5j
Oct 24 18:40:55.976: INFO: Got endpoints: latency-svc-ll2q2 [752.094234ms]
Oct 24 18:40:55.988: INFO: Created: latency-svc-8dsbc
Oct 24 18:40:56.024: INFO: Got endpoints: latency-svc-986mj [749.954039ms]
Oct 24 18:40:56.036: INFO: Created: latency-svc-znwrb
Oct 24 18:40:56.074: INFO: Got endpoints: latency-svc-92fwt [751.13245ms]
Oct 24 18:40:56.088: INFO: Created: latency-svc-n5z9x
Oct 24 18:40:56.124: INFO: Got endpoints: latency-svc-g8cfd [751.452571ms]
Oct 24 18:40:56.143: INFO: Created: latency-svc-vzz7b
Oct 24 18:40:56.173: INFO: Got endpoints: latency-svc-sln92 [749.806592ms]
Oct 24 18:40:56.194: INFO: Created: latency-svc-gqjmj
Oct 24 18:40:56.226: INFO: Got endpoints: latency-svc-sv2mk [753.059755ms]
Oct 24 18:40:56.239: INFO: Created: latency-svc-6cv4d
Oct 24 18:40:56.276: INFO: Got endpoints: latency-svc-7524s [751.818803ms]
Oct 24 18:40:56.307: INFO: Created: latency-svc-2wkvt
Oct 24 18:40:56.325: INFO: Got endpoints: latency-svc-bqz9j [751.03557ms]
Oct 24 18:40:56.346: INFO: Created: latency-svc-d654v
Oct 24 18:40:56.375: INFO: Got endpoints: latency-svc-8fxk7 [749.188308ms]
Oct 24 18:40:56.388: INFO: Created: latency-svc-nvvsf
Oct 24 18:40:56.426: INFO: Got endpoints: latency-svc-t2vql [751.033538ms]
Oct 24 18:40:56.439: INFO: Created: latency-svc-jn877
Oct 24 18:40:56.476: INFO: Got endpoints: latency-svc-l5fjw [751.521978ms]
Oct 24 18:40:56.487: INFO: Created: latency-svc-s2fnj
Oct 24 18:40:56.527: INFO: Got endpoints: latency-svc-6prkc [753.907628ms]
Oct 24 18:40:56.544: INFO: Created: latency-svc-82tjh
Oct 24 18:40:56.575: INFO: Got endpoints: latency-svc-6c5k7 [752.214974ms]
Oct 24 18:40:56.589: INFO: Created: latency-svc-xsqzk
Oct 24 18:40:56.622: INFO: Got endpoints: latency-svc-9pxkk [746.633474ms]
Oct 24 18:40:56.638: INFO: Created: latency-svc-t9pmm
Oct 24 18:40:56.673: INFO: Got endpoints: latency-svc-2ct5j [747.9286ms]
Oct 24 18:40:56.687: INFO: Created: latency-svc-sk2qv
Oct 24 18:40:56.726: INFO: Got endpoints: latency-svc-8dsbc [749.75809ms]
Oct 24 18:40:56.744: INFO: Created: latency-svc-49dsx
Oct 24 18:40:56.777: INFO: Got endpoints: latency-svc-znwrb [753.257396ms]
Oct 24 18:40:56.796: INFO: Created: latency-svc-48b2j
Oct 24 18:40:56.825: INFO: Got endpoints: latency-svc-n5z9x [751.152496ms]
Oct 24 18:40:56.842: INFO: Created: latency-svc-km9zv
Oct 24 18:40:56.874: INFO: Got endpoints: latency-svc-vzz7b [749.356676ms]
Oct 24 18:40:56.939: INFO: Got endpoints: latency-svc-gqjmj [766.242001ms]
Oct 24 18:40:56.959: INFO: Created: latency-svc-75clz
Oct 24 18:40:56.965: INFO: Created: latency-svc-8mrkt
Oct 24 18:40:56.973: INFO: Got endpoints: latency-svc-6cv4d [747.364855ms]
Oct 24 18:40:57.007: INFO: Created: latency-svc-pvfs4
Oct 24 18:40:57.027: INFO: Got endpoints: latency-svc-2wkvt [751.264647ms]
Oct 24 18:40:57.043: INFO: Created: latency-svc-9hbbw
Oct 24 18:40:57.074: INFO: Got endpoints: latency-svc-d654v [748.493359ms]
Oct 24 18:40:57.089: INFO: Created: latency-svc-qzdtc
Oct 24 18:40:57.126: INFO: Got endpoints: latency-svc-nvvsf [751.036865ms]
Oct 24 18:40:57.141: INFO: Created: latency-svc-wb4nv
Oct 24 18:40:57.177: INFO: Got endpoints: latency-svc-jn877 [751.026693ms]
Oct 24 18:40:57.193: INFO: Created: latency-svc-md6hl
Oct 24 18:40:57.227: INFO: Got endpoints: latency-svc-s2fnj [750.785503ms]
Oct 24 18:40:57.246: INFO: Created: latency-svc-7t6dm
Oct 24 18:40:57.306: INFO: Got endpoints: latency-svc-82tjh [778.880625ms]
Oct 24 18:40:57.344: INFO: Got endpoints: latency-svc-xsqzk [768.341803ms]
Oct 24 18:40:57.376: INFO: Created: latency-svc-vddzb
Oct 24 18:40:57.380: INFO: Got endpoints: latency-svc-t9pmm [757.971188ms]
Oct 24 18:40:57.430: INFO: Got endpoints: latency-svc-sk2qv [756.842816ms]
Oct 24 18:40:57.481: INFO: Created: latency-svc-7zfxp
Oct 24 18:40:57.481: INFO: Got endpoints: latency-svc-49dsx [754.623295ms]
Oct 24 18:40:57.496: INFO: Created: latency-svc-gwnk8
Oct 24 18:40:57.502: INFO: Created: latency-svc-4b8qb
Oct 24 18:40:57.506: INFO: Created: latency-svc-wnd9c
Oct 24 18:40:57.527: INFO: Got endpoints: latency-svc-48b2j [750.231561ms]
Oct 24 18:40:57.538: INFO: Created: latency-svc-bwc59
Oct 24 18:40:57.573: INFO: Got endpoints: latency-svc-km9zv [747.548557ms]
Oct 24 18:40:57.584: INFO: Created: latency-svc-lxkv2
Oct 24 18:40:57.623: INFO: Got endpoints: latency-svc-75clz [749.133029ms]
Oct 24 18:40:57.637: INFO: Created: latency-svc-nx859
Oct 24 18:40:57.674: INFO: Got endpoints: latency-svc-8mrkt [734.451895ms]
Oct 24 18:40:57.688: INFO: Created: latency-svc-blqrw
Oct 24 18:40:57.725: INFO: Got endpoints: latency-svc-pvfs4 [751.670414ms]
Oct 24 18:40:57.740: INFO: Created: latency-svc-75ttv
Oct 24 18:40:57.778: INFO: Got endpoints: latency-svc-9hbbw [751.145036ms]
Oct 24 18:40:57.795: INFO: Created: latency-svc-xqzn5
Oct 24 18:40:57.827: INFO: Got endpoints: latency-svc-qzdtc [753.576138ms]
Oct 24 18:40:57.842: INFO: Created: latency-svc-cb5vj
Oct 24 18:40:57.880: INFO: Got endpoints: latency-svc-wb4nv [754.5083ms]
Oct 24 18:40:57.896: INFO: Created: latency-svc-f82dv
Oct 24 18:40:57.936: INFO: Got endpoints: latency-svc-md6hl [758.545128ms]
Oct 24 18:40:57.959: INFO: Created: latency-svc-4xdtv
Oct 24 18:40:57.973: INFO: Got endpoints: latency-svc-7t6dm [746.391212ms]
Oct 24 18:40:57.985: INFO: Created: latency-svc-qlnql
Oct 24 18:40:58.028: INFO: Got endpoints: latency-svc-vddzb [722.30936ms]
Oct 24 18:40:58.043: INFO: Created: latency-svc-4j6cb
Oct 24 18:40:58.074: INFO: Got endpoints: latency-svc-7zfxp [730.748582ms]
Oct 24 18:40:58.095: INFO: Created: latency-svc-zwdxv
Oct 24 18:40:58.129: INFO: Got endpoints: latency-svc-gwnk8 [748.733288ms]
Oct 24 18:40:58.147: INFO: Created: latency-svc-9gvc2
Oct 24 18:40:58.176: INFO: Got endpoints: latency-svc-4b8qb [745.80658ms]
Oct 24 18:40:58.192: INFO: Created: latency-svc-5gwlq
Oct 24 18:40:58.227: INFO: Got endpoints: latency-svc-wnd9c [746.30873ms]
Oct 24 18:40:58.244: INFO: Created: latency-svc-8bmz5
Oct 24 18:40:58.277: INFO: Got endpoints: latency-svc-bwc59 [749.345864ms]
Oct 24 18:40:58.291: INFO: Created: latency-svc-ffpmx
Oct 24 18:40:58.326: INFO: Got endpoints: latency-svc-lxkv2 [753.035938ms]
Oct 24 18:40:58.346: INFO: Created: latency-svc-mrjlt
Oct 24 18:40:58.378: INFO: Got endpoints: latency-svc-nx859 [754.425927ms]
Oct 24 18:40:58.391: INFO: Created: latency-svc-tt6pr
Oct 24 18:40:58.424: INFO: Got endpoints: latency-svc-blqrw [750.247907ms]
Oct 24 18:40:58.436: INFO: Created: latency-svc-dp9cc
Oct 24 18:40:58.473: INFO: Got endpoints: latency-svc-75ttv [748.149119ms]
Oct 24 18:40:58.484: INFO: Created: latency-svc-fm72l
Oct 24 18:40:58.525: INFO: Got endpoints: latency-svc-xqzn5 [747.090312ms]
Oct 24 18:40:58.539: INFO: Created: latency-svc-xxqck
Oct 24 18:40:58.573: INFO: Got endpoints: latency-svc-cb5vj [745.991009ms]
Oct 24 18:40:58.587: INFO: Created: latency-svc-j4qzp
Oct 24 18:40:58.623: INFO: Got endpoints: latency-svc-f82dv [743.035606ms]
Oct 24 18:40:58.635: INFO: Created: latency-svc-b5fh2
Oct 24 18:40:58.673: INFO: Got endpoints: latency-svc-4xdtv [737.390146ms]
Oct 24 18:40:58.686: INFO: Created: latency-svc-qs5pb
Oct 24 18:40:58.724: INFO: Got endpoints: latency-svc-qlnql [750.675386ms]
Oct 24 18:40:58.738: INFO: Created: latency-svc-5lrkf
Oct 24 18:40:58.774: INFO: Got endpoints: latency-svc-4j6cb [745.639822ms]
Oct 24 18:40:58.823: INFO: Got endpoints: latency-svc-zwdxv [748.386293ms]
Oct 24 18:40:58.875: INFO: Got endpoints: latency-svc-9gvc2 [745.666599ms]
Oct 24 18:40:58.924: INFO: Got endpoints: latency-svc-5gwlq [748.789668ms]
Oct 24 18:40:58.974: INFO: Got endpoints: latency-svc-8bmz5 [746.443387ms]
Oct 24 18:40:59.025: INFO: Got endpoints: latency-svc-ffpmx [748.218707ms]
Oct 24 18:40:59.075: INFO: Got endpoints: latency-svc-mrjlt [749.145363ms]
Oct 24 18:40:59.125: INFO: Got endpoints: latency-svc-tt6pr [746.94793ms]
Oct 24 18:40:59.174: INFO: Got endpoints: latency-svc-dp9cc [749.655862ms]
Oct 24 18:40:59.223: INFO: Got endpoints: latency-svc-fm72l [750.018506ms]
Oct 24 18:40:59.274: INFO: Got endpoints: latency-svc-xxqck [748.265506ms]
Oct 24 18:40:59.326: INFO: Got endpoints: latency-svc-j4qzp [752.603088ms]
Oct 24 18:40:59.374: INFO: Got endpoints: latency-svc-b5fh2 [750.356477ms]
Oct 24 18:40:59.423: INFO: Got endpoints: latency-svc-qs5pb [750.193631ms]
Oct 24 18:40:59.473: INFO: Got endpoints: latency-svc-5lrkf [749.041211ms]
Oct 24 18:40:59.473: INFO: Latencies: [25.888949ms 39.40613ms 62.403471ms 75.48409ms 85.889447ms 103.051037ms 117.666469ms 124.733614ms 139.152791ms 145.099358ms 155.351637ms 165.078877ms 165.944547ms 168.21786ms 169.076993ms 169.43011ms 173.074045ms 174.078493ms 174.240454ms 174.674928ms 176.646691ms 178.40195ms 178.915539ms 178.957594ms 179.0714ms 179.924728ms 180.449851ms 180.45526ms 180.748351ms 180.799226ms 181.073124ms 181.429314ms 181.771957ms 182.138225ms 185.188242ms 185.905817ms 186.388167ms 197.699121ms 211.115795ms 224.778098ms 260.495768ms 296.599871ms 338.237005ms 376.766195ms 412.182184ms 457.852831ms 484.236223ms 528.122732ms 568.971809ms 604.94803ms 640.387674ms 685.762044ms 722.30936ms 728.521847ms 730.748582ms 734.451895ms 737.390146ms 740.41357ms 743.035606ms 744.477139ms 745.472372ms 745.639822ms 745.666599ms 745.80658ms 745.991009ms 746.30873ms 746.391212ms 746.443387ms 746.523007ms 746.564773ms 746.633474ms 746.94793ms 747.090312ms 747.130986ms 747.311545ms 747.364855ms 747.548557ms 747.78083ms 747.860599ms 747.9286ms 748.087416ms 748.149119ms 748.149491ms 748.218707ms 748.265506ms 748.326432ms 748.386293ms 748.415435ms 748.493359ms 748.546978ms 748.733288ms 748.758346ms 748.789668ms 748.807801ms 748.823195ms 748.829718ms 748.845982ms 748.855809ms 748.979994ms 748.99081ms 749.001031ms 749.003838ms 749.041211ms 749.068616ms 749.071213ms 749.072824ms 749.109274ms 749.110532ms 749.133029ms 749.145363ms 749.154686ms 749.188308ms 749.210037ms 749.23255ms 749.244643ms 749.293173ms 749.345864ms 749.356676ms 749.573058ms 749.598812ms 749.605488ms 749.611787ms 749.645462ms 749.655862ms 749.66986ms 749.751648ms 749.75809ms 749.762874ms 749.78237ms 749.806592ms 749.892215ms 749.954039ms 750.014053ms 750.018506ms 750.093107ms 750.107441ms 750.147971ms 750.153677ms 750.18643ms 750.193631ms 750.198973ms 750.231561ms 750.245875ms 750.247907ms 750.271565ms 750.301919ms 750.356477ms 750.383017ms 750.523234ms 750.625885ms 750.659831ms 750.675386ms 750.741206ms 750.785503ms 750.820344ms 750.958942ms 751.026693ms 751.033538ms 751.03557ms 751.036865ms 751.037977ms 751.13245ms 751.145036ms 751.152496ms 751.264647ms 751.292145ms 751.452571ms 751.521978ms 751.628763ms 751.670414ms 751.677959ms 751.818803ms 752.007451ms 752.094234ms 752.104833ms 752.214974ms 752.222497ms 752.603088ms 752.648845ms 752.828309ms 753.027684ms 753.035938ms 753.059755ms 753.257396ms 753.576138ms 753.698242ms 753.765861ms 753.858451ms 753.907628ms 754.425927ms 754.5083ms 754.623295ms 754.956775ms 756.842816ms 757.971188ms 758.545128ms 759.950935ms 766.242001ms 768.341803ms 778.880625ms]
Oct 24 18:40:59.474: INFO: 50 %ile: 749.001031ms
Oct 24 18:40:59.474: INFO: 90 %ile: 753.027684ms
Oct 24 18:40:59.474: INFO: 99 %ile: 768.341803ms
Oct 24 18:40:59.474: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:40:59.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6809" for this suite.
Oct 24 18:41:29.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:41:29.643: INFO: namespace svc-latency-6809 deletion completed in 30.16387414s

• [SLOW TEST:40.945 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:41:29.644: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-e48f30a7-f68d-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume secrets
Oct 24 18:41:29.712: INFO: Waiting up to 5m0s for pod "pod-secrets-e49098a4-f68d-11e9-8e41-6682758dfd28" in namespace "secrets-6134" to be "success or failure"
Oct 24 18:41:29.718: INFO: Pod "pod-secrets-e49098a4-f68d-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.646973ms
Oct 24 18:41:31.723: INFO: Pod "pod-secrets-e49098a4-f68d-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010797008s
STEP: Saw pod success
Oct 24 18:41:31.723: INFO: Pod "pod-secrets-e49098a4-f68d-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:41:31.733: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-secrets-e49098a4-f68d-11e9-8e41-6682758dfd28 container secret-env-test: <nil>
STEP: delete the pod
Oct 24 18:41:31.768: INFO: Waiting for pod pod-secrets-e49098a4-f68d-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:41:31.775: INFO: Pod pod-secrets-e49098a4-f68d-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:41:31.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6134" for this suite.
Oct 24 18:41:37.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:41:37.952: INFO: namespace secrets-6134 deletion completed in 6.167039215s

• [SLOW TEST:8.308 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:41:37.952: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 18:41:38.007: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e982b841-f68d-11e9-8e41-6682758dfd28" in namespace "projected-3541" to be "success or failure"
Oct 24 18:41:38.012: INFO: Pod "downwardapi-volume-e982b841-f68d-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.574108ms
Oct 24 18:41:40.018: INFO: Pod "downwardapi-volume-e982b841-f68d-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.010875832s
Oct 24 18:41:42.023: INFO: Pod "downwardapi-volume-e982b841-f68d-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015936807s
STEP: Saw pod success
Oct 24 18:41:42.023: INFO: Pod "downwardapi-volume-e982b841-f68d-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:41:42.027: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-e982b841-f68d-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 18:41:42.061: INFO: Waiting for pod downwardapi-volume-e982b841-f68d-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:41:42.064: INFO: Pod downwardapi-volume-e982b841-f68d-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:41:42.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3541" for this suite.
Oct 24 18:41:48.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:41:48.235: INFO: namespace projected-3541 deletion completed in 6.165578522s

• [SLOW TEST:10.283 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:41:48.235: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 24 18:41:48.292: INFO: Waiting up to 5m0s for pod "downwardapi-volume-efa4280f-f68d-11e9-8e41-6682758dfd28" in namespace "downward-api-7861" to be "success or failure"
Oct 24 18:41:48.297: INFO: Pod "downwardapi-volume-efa4280f-f68d-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.986801ms
Oct 24 18:41:50.305: INFO: Pod "downwardapi-volume-efa4280f-f68d-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012655037s
STEP: Saw pod success
Oct 24 18:41:50.305: INFO: Pod "downwardapi-volume-efa4280f-f68d-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:41:50.309: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-efa4280f-f68d-11e9-8e41-6682758dfd28 container client-container: <nil>
STEP: delete the pod
Oct 24 18:41:50.338: INFO: Waiting for pod downwardapi-volume-efa4280f-f68d-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:41:50.343: INFO: Pod downwardapi-volume-efa4280f-f68d-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:41:50.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7861" for this suite.
Oct 24 18:41:56.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:41:56.518: INFO: namespace downward-api-7861 deletion completed in 6.167497517s

• [SLOW TEST:8.283 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:41:56.519: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-f494e00e-f68d-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume secrets
Oct 24 18:41:56.587: INFO: Waiting up to 5m0s for pod "pod-secrets-f4958490-f68d-11e9-8e41-6682758dfd28" in namespace "secrets-8408" to be "success or failure"
Oct 24 18:41:56.594: INFO: Pod "pod-secrets-f4958490-f68d-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 6.918731ms
Oct 24 18:41:58.599: INFO: Pod "pod-secrets-f4958490-f68d-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012333806s
STEP: Saw pod success
Oct 24 18:41:58.599: INFO: Pod "pod-secrets-f4958490-f68d-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:41:58.603: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-secrets-f4958490-f68d-11e9-8e41-6682758dfd28 container secret-volume-test: <nil>
STEP: delete the pod
Oct 24 18:41:58.630: INFO: Waiting for pod pod-secrets-f4958490-f68d-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:41:58.635: INFO: Pod pod-secrets-f4958490-f68d-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:41:58.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8408" for this suite.
Oct 24 18:42:04.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:42:04.818: INFO: namespace secrets-8408 deletion completed in 6.177417202s

• [SLOW TEST:8.300 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:42:04.819: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-bxjv
STEP: Creating a pod to test atomic-volume-subpath
Oct 24 18:42:04.889: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-bxjv" in namespace "subpath-9313" to be "success or failure"
Oct 24 18:42:04.893: INFO: Pod "pod-subpath-test-downwardapi-bxjv": Phase="Pending", Reason="", readiness=false. Elapsed: 3.870501ms
Oct 24 18:42:06.900: INFO: Pod "pod-subpath-test-downwardapi-bxjv": Phase="Running", Reason="", readiness=true. Elapsed: 2.01077002s
Oct 24 18:42:08.906: INFO: Pod "pod-subpath-test-downwardapi-bxjv": Phase="Running", Reason="", readiness=true. Elapsed: 4.017058509s
Oct 24 18:42:10.912: INFO: Pod "pod-subpath-test-downwardapi-bxjv": Phase="Running", Reason="", readiness=true. Elapsed: 6.023420166s
Oct 24 18:42:12.918: INFO: Pod "pod-subpath-test-downwardapi-bxjv": Phase="Running", Reason="", readiness=true. Elapsed: 8.028922159s
Oct 24 18:42:14.924: INFO: Pod "pod-subpath-test-downwardapi-bxjv": Phase="Running", Reason="", readiness=true. Elapsed: 10.035166305s
Oct 24 18:42:16.930: INFO: Pod "pod-subpath-test-downwardapi-bxjv": Phase="Running", Reason="", readiness=true. Elapsed: 12.041297664s
Oct 24 18:42:18.936: INFO: Pod "pod-subpath-test-downwardapi-bxjv": Phase="Running", Reason="", readiness=true. Elapsed: 14.047111262s
Oct 24 18:42:20.941: INFO: Pod "pod-subpath-test-downwardapi-bxjv": Phase="Running", Reason="", readiness=true. Elapsed: 16.052418891s
Oct 24 18:42:22.947: INFO: Pod "pod-subpath-test-downwardapi-bxjv": Phase="Running", Reason="", readiness=true. Elapsed: 18.058459077s
Oct 24 18:42:24.952: INFO: Pod "pod-subpath-test-downwardapi-bxjv": Phase="Running", Reason="", readiness=true. Elapsed: 20.063354125s
Oct 24 18:42:26.958: INFO: Pod "pod-subpath-test-downwardapi-bxjv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.069543187s
STEP: Saw pod success
Oct 24 18:42:26.958: INFO: Pod "pod-subpath-test-downwardapi-bxjv" satisfied condition "success or failure"
Oct 24 18:42:26.963: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-subpath-test-downwardapi-bxjv container test-container-subpath-downwardapi-bxjv: <nil>
STEP: delete the pod
Oct 24 18:42:26.994: INFO: Waiting for pod pod-subpath-test-downwardapi-bxjv to disappear
Oct 24 18:42:26.999: INFO: Pod pod-subpath-test-downwardapi-bxjv no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-bxjv
Oct 24 18:42:26.999: INFO: Deleting pod "pod-subpath-test-downwardapi-bxjv" in namespace "subpath-9313"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:42:27.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9313" for this suite.
Oct 24 18:42:33.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:42:33.188: INFO: namespace subpath-9313 deletion completed in 6.178539674s

• [SLOW TEST:28.369 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:42:33.188: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-0a72431b-f68e-11e9-8e41-6682758dfd28
STEP: Creating a pod to test consume secrets
Oct 24 18:42:33.272: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0a7329d7-f68e-11e9-8e41-6682758dfd28" in namespace "projected-190" to be "success or failure"
Oct 24 18:42:33.281: INFO: Pod "pod-projected-secrets-0a7329d7-f68e-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 9.087059ms
Oct 24 18:42:35.288: INFO: Pod "pod-projected-secrets-0a7329d7-f68e-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016020761s
STEP: Saw pod success
Oct 24 18:42:35.288: INFO: Pod "pod-projected-secrets-0a7329d7-f68e-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:42:35.293: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-projected-secrets-0a7329d7-f68e-11e9-8e41-6682758dfd28 container secret-volume-test: <nil>
STEP: delete the pod
Oct 24 18:42:35.320: INFO: Waiting for pod pod-projected-secrets-0a7329d7-f68e-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:42:35.324: INFO: Pod pod-projected-secrets-0a7329d7-f68e-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:42:35.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-190" for this suite.
Oct 24 18:42:41.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:42:41.497: INFO: namespace projected-190 deletion completed in 6.167940107s

• [SLOW TEST:8.309 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:42:41.498: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 24 18:42:41.554: INFO: Waiting up to 5m0s for pod "pod-0f62dcc3-f68e-11e9-8e41-6682758dfd28" in namespace "emptydir-6311" to be "success or failure"
Oct 24 18:42:41.560: INFO: Pod "pod-0f62dcc3-f68e-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.472556ms
Oct 24 18:42:43.565: INFO: Pod "pod-0f62dcc3-f68e-11e9-8e41-6682758dfd28": Phase="Running", Reason="", readiness=true. Elapsed: 2.010953383s
Oct 24 18:42:45.571: INFO: Pod "pod-0f62dcc3-f68e-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016978846s
STEP: Saw pod success
Oct 24 18:42:45.571: INFO: Pod "pod-0f62dcc3-f68e-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:42:45.575: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-0f62dcc3-f68e-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 18:42:45.608: INFO: Waiting for pod pod-0f62dcc3-f68e-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:42:45.612: INFO: Pod pod-0f62dcc3-f68e-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:42:45.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6311" for this suite.
Oct 24 18:42:51.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:42:51.783: INFO: namespace emptydir-6311 deletion completed in 6.166223151s

• [SLOW TEST:10.285 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:42:51.783: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-55
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 24 18:42:51.837: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 24 18:43:11.939: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.164 8081 | grep -v '^\s*$'] Namespace:pod-network-test-55 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 18:43:11.939: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 18:43:13.088: INFO: Found all expected endpoints: [netserver-0]
Oct 24 18:43:13.094: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.2.181 8081 | grep -v '^\s*$'] Namespace:pod-network-test-55 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 18:43:13.094: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 18:43:14.241: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:43:14.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-55" for this suite.
Oct 24 18:43:36.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:43:36.425: INFO: namespace pod-network-test-55 deletion completed in 22.177651009s

• [SLOW TEST:44.642 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:43:36.426: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 24 18:43:39.026: INFO: Successfully updated pod "pod-update-30211041-f68e-11e9-8e41-6682758dfd28"
STEP: verifying the updated pod is in kubernetes
Oct 24 18:43:39.033: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:43:39.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2611" for this suite.
Oct 24 18:44:01.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:44:01.214: INFO: namespace pods-2611 deletion completed in 22.175517552s

• [SLOW TEST:24.788 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:44:01.214: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-3500
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 24 18:44:01.265: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 24 18:44:25.374: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.168:8080/dial?request=hostName&protocol=http&host=10.244.2.182&port=8080&tries=1'] Namespace:pod-network-test-3500 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 18:44:25.374: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 18:44:25.526: INFO: Waiting for endpoints: map[]
Oct 24 18:44:25.530: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.168:8080/dial?request=hostName&protocol=http&host=10.244.1.167&port=8080&tries=1'] Namespace:pod-network-test-3500 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 18:44:25.530: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
Oct 24 18:44:25.686: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:44:25.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3500" for this suite.
Oct 24 18:44:47.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:44:47.853: INFO: namespace pod-network-test-3500 deletion completed in 22.161448832s

• [SLOW TEST:46.640 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:44:47.854: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:45:02.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7535" for this suite.
Oct 24 18:45:08.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:45:08.348: INFO: namespace namespaces-7535 deletion completed in 6.264361061s
STEP: Destroying namespace "nsdeletetest-2880" for this suite.
Oct 24 18:45:08.351: INFO: Namespace nsdeletetest-2880 was already deleted
STEP: Destroying namespace "nsdeletetest-321" for this suite.
Oct 24 18:45:14.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:45:14.525: INFO: namespace nsdeletetest-321 deletion completed in 6.173133884s

• [SLOW TEST:26.671 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:45:14.525: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:45:35.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1706" for this suite.
Oct 24 18:45:41.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:45:42.029: INFO: namespace container-runtime-1706 deletion completed in 6.182152819s

• [SLOW TEST:27.504 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 24 18:45:42.030: INFO: >>> kubeConfig: /tmp/kubeconfig-464213187
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 24 18:45:42.083: INFO: Waiting up to 5m0s for pod "pod-7afdcfcb-f68e-11e9-8e41-6682758dfd28" in namespace "emptydir-4125" to be "success or failure"
Oct 24 18:45:42.088: INFO: Pod "pod-7afdcfcb-f68e-11e9-8e41-6682758dfd28": Phase="Pending", Reason="", readiness=false. Elapsed: 5.066736ms
Oct 24 18:45:44.094: INFO: Pod "pod-7afdcfcb-f68e-11e9-8e41-6682758dfd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010880959s
STEP: Saw pod success
Oct 24 18:45:44.094: INFO: Pod "pod-7afdcfcb-f68e-11e9-8e41-6682758dfd28" satisfied condition "success or failure"
Oct 24 18:45:44.098: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod pod-7afdcfcb-f68e-11e9-8e41-6682758dfd28 container test-container: <nil>
STEP: delete the pod
Oct 24 18:45:44.126: INFO: Waiting for pod pod-7afdcfcb-f68e-11e9-8e41-6682758dfd28 to disappear
Oct 24 18:45:44.130: INFO: Pod pod-7afdcfcb-f68e-11e9-8e41-6682758dfd28 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 24 18:45:44.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4125" for this suite.
Oct 24 18:45:50.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 18:45:50.316: INFO: namespace emptydir-4125 deletion completed in 6.179195954s

• [SLOW TEST:8.286 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SOct 24 18:45:50.316: INFO: Running AfterSuite actions on all nodes
Oct 24 18:45:50.316: INFO: Running AfterSuite actions on node 1
Oct 24 18:45:50.316: INFO: Skipping dumping logs from cluster

Ran 204 of 3586 Specs in 5271.912 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3382 Skipped PASS

Ginkgo ran 1 suite in 1h27m54.600853525s
Test Suite Passed
