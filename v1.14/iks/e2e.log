I0715 21:58:33.775448      16 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-077690921
I0715 21:58:33.775547      16 e2e.go:240] Starting e2e run "affc0452-a74b-11e9-983d-d6ce37abd03c" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1563227912 - Will randomize all specs
Will run 204 of 3586 specs

Jul 15 21:58:33.937: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 21:58:33.939: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jul 15 21:58:33.988: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jul 15 21:58:34.054: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jul 15 21:58:34.054: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Jul 15 21:58:34.054: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jul 15 21:58:34.071: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Jul 15 21:58:34.071: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Jul 15 21:58:34.071: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
Jul 15 21:58:34.071: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Jul 15 21:58:34.071: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Jul 15 21:58:34.071: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Jul 15 21:58:34.071: INFO: e2e test version: v1.14.4
Jul 15 21:58:34.075: INFO: kube-apiserver version: v1.14.4+IKS
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 21:58:34.075: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
Jul 15 21:58:34.179: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Jul 15 21:58:34.220: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-163
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-b0e2ba30-a74b-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume configMaps
Jul 15 21:58:34.385: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b0e3ecb3-a74b-11e9-983d-d6ce37abd03c" in namespace "projected-163" to be "success or failure"
Jul 15 21:58:34.405: INFO: Pod "pod-projected-configmaps-b0e3ecb3-a74b-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 20.162429ms
Jul 15 21:58:36.416: INFO: Pod "pod-projected-configmaps-b0e3ecb3-a74b-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030922214s
Jul 15 21:58:38.428: INFO: Pod "pod-projected-configmaps-b0e3ecb3-a74b-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042903334s
STEP: Saw pod success
Jul 15 21:58:38.428: INFO: Pod "pod-projected-configmaps-b0e3ecb3-a74b-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 21:58:38.439: INFO: Trying to get logs from node 10.190.211.93 pod pod-projected-configmaps-b0e3ecb3-a74b-11e9-983d-d6ce37abd03c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 21:58:38.491: INFO: Waiting for pod pod-projected-configmaps-b0e3ecb3-a74b-11e9-983d-d6ce37abd03c to disappear
Jul 15 21:58:38.501: INFO: Pod pod-projected-configmaps-b0e3ecb3-a74b-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 21:58:38.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-163" for this suite.
Jul 15 21:58:44.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 21:58:44.889: INFO: namespace projected-163 deletion completed in 6.371358983s

• [SLOW TEST:10.814 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 21:58:44.889: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-9715
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Jul 15 21:58:45.130: INFO: Waiting up to 5m0s for pod "var-expansion-b74b339f-a74b-11e9-983d-d6ce37abd03c" in namespace "var-expansion-9715" to be "success or failure"
Jul 15 21:58:45.144: INFO: Pod "var-expansion-b74b339f-a74b-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.114033ms
Jul 15 21:58:47.155: INFO: Pod "var-expansion-b74b339f-a74b-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025172524s
Jul 15 21:58:49.165: INFO: Pod "var-expansion-b74b339f-a74b-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035872728s
STEP: Saw pod success
Jul 15 21:58:49.166: INFO: Pod "var-expansion-b74b339f-a74b-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 21:58:49.175: INFO: Trying to get logs from node 10.190.211.93 pod var-expansion-b74b339f-a74b-11e9-983d-d6ce37abd03c container dapi-container: <nil>
STEP: delete the pod
Jul 15 21:58:49.261: INFO: Waiting for pod var-expansion-b74b339f-a74b-11e9-983d-d6ce37abd03c to disappear
Jul 15 21:58:49.270: INFO: Pod var-expansion-b74b339f-a74b-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 21:58:49.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9715" for this suite.
Jul 15 21:58:55.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 21:58:55.660: INFO: namespace var-expansion-9715 deletion completed in 6.376547671s

• [SLOW TEST:10.771 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 21:58:55.660: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2293
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul 15 21:58:55.996: INFO: Number of nodes with available pods: 0
Jul 15 21:58:55.996: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 21:58:57.023: INFO: Number of nodes with available pods: 0
Jul 15 21:58:57.023: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 21:58:58.022: INFO: Number of nodes with available pods: 0
Jul 15 21:58:58.022: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 21:58:59.020: INFO: Number of nodes with available pods: 2
Jul 15 21:58:59.020: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 21:59:00.025: INFO: Number of nodes with available pods: 3
Jul 15 21:59:00.025: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jul 15 21:59:00.096: INFO: Number of nodes with available pods: 2
Jul 15 21:59:00.096: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 21:59:01.123: INFO: Number of nodes with available pods: 2
Jul 15 21:59:01.123: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 21:59:02.122: INFO: Number of nodes with available pods: 2
Jul 15 21:59:02.122: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 21:59:03.121: INFO: Number of nodes with available pods: 3
Jul 15 21:59:03.121: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2293, will wait for the garbage collector to delete the pods
Jul 15 21:59:03.241: INFO: Deleting DaemonSet.extensions daemon-set took: 25.626509ms
Jul 15 21:59:03.441: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.44341ms
Jul 15 21:59:12.552: INFO: Number of nodes with available pods: 0
Jul 15 21:59:12.552: INFO: Number of running nodes: 0, number of available pods: 0
Jul 15 21:59:12.564: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2293/daemonsets","resourceVersion":"9247"},"items":null}

Jul 15 21:59:12.576: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2293/pods","resourceVersion":"9247"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 21:59:12.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2293" for this suite.
Jul 15 21:59:20.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 21:59:21.012: INFO: namespace daemonsets-2293 deletion completed in 8.378751701s

• [SLOW TEST:25.352 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 21:59:21.012: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5755
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jul 15 21:59:21.231: INFO: PodSpec: initContainers in spec.initContainers
Jul 15 22:00:06.857: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-ccd38f31-a74b-11e9-983d-d6ce37abd03c", GenerateName:"", Namespace:"init-container-5755", SelfLink:"/api/v1/namespaces/init-container-5755/pods/pod-init-ccd38f31-a74b-11e9-983d-d6ce37abd03c", UID:"ccd4c610-a74b-11e9-a496-5e4367ce3703", ResourceVersion:"9412", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63698824761, loc:(*time.Location)(0x8a1e140)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"231346329"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-j5qlw", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00289c700), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-j5qlw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-j5qlw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-j5qlw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0024ce448), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.190.211.93", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00281bf20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0024ce4d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0024ce4f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0024ce4f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0024ce4fc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698824761, loc:(*time.Location)(0x8a1e140)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698824761, loc:(*time.Location)(0x8a1e140)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698824761, loc:(*time.Location)(0x8a1e140)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698824761, loc:(*time.Location)(0x8a1e140)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.190.211.93", PodIP:"172.30.19.8", StartTime:(*v1.Time)(0xc0020fd400), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0025bb7a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0025bb810)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://d421d9ef101306840c38dec9fcfa055ea5c1a66d9d2b91b4c4647d25179b95bf"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0020fd460), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0020fd440), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:00:06.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5755" for this suite.
Jul 15 22:00:30.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:00:31.248: INFO: namespace init-container-5755 deletion completed in 24.360544338s

• [SLOW TEST:70.236 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:00:31.249: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9009
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-f6b2b64b-a74b-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume configMaps
Jul 15 22:00:31.516: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f6b4a075-a74b-11e9-983d-d6ce37abd03c" in namespace "projected-9009" to be "success or failure"
Jul 15 22:00:31.534: INFO: Pod "pod-projected-configmaps-f6b4a075-a74b-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.99155ms
Jul 15 22:00:33.548: INFO: Pod "pod-projected-configmaps-f6b4a075-a74b-11e9-983d-d6ce37abd03c": Phase="Running", Reason="", readiness=true. Elapsed: 2.031577137s
Jul 15 22:00:35.560: INFO: Pod "pod-projected-configmaps-f6b4a075-a74b-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044092139s
STEP: Saw pod success
Jul 15 22:00:35.560: INFO: Pod "pod-projected-configmaps-f6b4a075-a74b-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:00:35.570: INFO: Trying to get logs from node 10.190.211.93 pod pod-projected-configmaps-f6b4a075-a74b-11e9-983d-d6ce37abd03c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 22:00:35.636: INFO: Waiting for pod pod-projected-configmaps-f6b4a075-a74b-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:00:35.648: INFO: Pod pod-projected-configmaps-f6b4a075-a74b-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:00:35.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9009" for this suite.
Jul 15 22:00:41.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:00:42.057: INFO: namespace projected-9009 deletion completed in 6.394151337s

• [SLOW TEST:10.809 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:00:42.058: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5917
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jul 15 22:00:44.905: INFO: Successfully updated pod "pod-update-fd2471c1-a74b-11e9-983d-d6ce37abd03c"
STEP: verifying the updated pod is in kubernetes
Jul 15 22:00:44.929: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:00:44.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5917" for this suite.
Jul 15 22:01:08.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:01:09.353: INFO: namespace pods-5917 deletion completed in 24.410023408s

• [SLOW TEST:27.295 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:01:09.353: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4367
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jul 15 22:01:09.589: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:01:13.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4367" for this suite.
Jul 15 22:01:38.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:01:38.379: INFO: namespace init-container-4367 deletion completed in 24.404021296s

• [SLOW TEST:29.026 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:01:38.380: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7805
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 22:01:38.634: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1eb64672-a74c-11e9-983d-d6ce37abd03c" in namespace "projected-7805" to be "success or failure"
Jul 15 22:01:38.649: INFO: Pod "downwardapi-volume-1eb64672-a74c-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 15.38004ms
Jul 15 22:01:40.660: INFO: Pod "downwardapi-volume-1eb64672-a74c-11e9-983d-d6ce37abd03c": Phase="Running", Reason="", readiness=true. Elapsed: 2.02593954s
Jul 15 22:01:42.672: INFO: Pod "downwardapi-volume-1eb64672-a74c-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038583402s
STEP: Saw pod success
Jul 15 22:01:42.672: INFO: Pod "downwardapi-volume-1eb64672-a74c-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:01:42.688: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-1eb64672-a74c-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 22:01:42.747: INFO: Waiting for pod downwardapi-volume-1eb64672-a74c-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:01:42.765: INFO: Pod downwardapi-volume-1eb64672-a74c-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:01:42.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7805" for this suite.
Jul 15 22:01:48.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:01:49.156: INFO: namespace projected-7805 deletion completed in 6.376948877s

• [SLOW TEST:10.776 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:01:49.156: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7430
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:02:49.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7430" for this suite.
Jul 15 22:03:13.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:03:13.833: INFO: namespace container-probe-7430 deletion completed in 24.401409726s

• [SLOW TEST:84.677 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:03:13.835: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8730
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-579a48b6-a74c-11e9-983d-d6ce37abd03c
Jul 15 22:03:14.080: INFO: Pod name my-hostname-basic-579a48b6-a74c-11e9-983d-d6ce37abd03c: Found 0 pods out of 1
Jul 15 22:03:19.090: INFO: Pod name my-hostname-basic-579a48b6-a74c-11e9-983d-d6ce37abd03c: Found 1 pods out of 1
Jul 15 22:03:19.090: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-579a48b6-a74c-11e9-983d-d6ce37abd03c" are running
Jul 15 22:03:19.101: INFO: Pod "my-hostname-basic-579a48b6-a74c-11e9-983d-d6ce37abd03c-hvk9l" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-15 22:03:14 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-15 22:03:17 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-15 22:03:17 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-15 22:03:14 +0000 UTC Reason: Message:}])
Jul 15 22:03:19.101: INFO: Trying to dial the pod
Jul 15 22:03:24.144: INFO: Controller my-hostname-basic-579a48b6-a74c-11e9-983d-d6ce37abd03c: Got expected result from replica 1 [my-hostname-basic-579a48b6-a74c-11e9-983d-d6ce37abd03c-hvk9l]: "my-hostname-basic-579a48b6-a74c-11e9-983d-d6ce37abd03c-hvk9l", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:03:24.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8730" for this suite.
Jul 15 22:03:30.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:03:30.543: INFO: namespace replication-controller-8730 deletion completed in 6.385522252s

• [SLOW TEST:16.709 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:03:30.543: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8734
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jul 15 22:03:33.376: INFO: Successfully updated pod "labelsupdate618f8e45-a74c-11e9-983d-d6ce37abd03c"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:03:37.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8734" for this suite.
Jul 15 22:04:01.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:04:02.011: INFO: namespace projected-8734 deletion completed in 24.538024612s

• [SLOW TEST:31.468 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:04:02.012: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9628
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 22:04:02.288: INFO: (0) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 48.443616ms)
Jul 15 22:04:02.308: INFO: (1) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 19.381102ms)
Jul 15 22:04:02.327: INFO: (2) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 19.496758ms)
Jul 15 22:04:02.345: INFO: (3) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.912063ms)
Jul 15 22:04:02.359: INFO: (4) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.017838ms)
Jul 15 22:04:02.373: INFO: (5) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 13.649335ms)
Jul 15 22:04:02.397: INFO: (6) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.768504ms)
Jul 15 22:04:02.420: INFO: (7) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.304413ms)
Jul 15 22:04:02.444: INFO: (8) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.927228ms)
Jul 15 22:04:02.462: INFO: (9) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.568347ms)
Jul 15 22:04:02.477: INFO: (10) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.937972ms)
Jul 15 22:04:02.491: INFO: (11) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 13.955625ms)
Jul 15 22:04:02.506: INFO: (12) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.885033ms)
Jul 15 22:04:02.521: INFO: (13) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.475806ms)
Jul 15 22:04:02.539: INFO: (14) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.929369ms)
Jul 15 22:04:02.557: INFO: (15) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.819692ms)
Jul 15 22:04:02.572: INFO: (16) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.349772ms)
Jul 15 22:04:02.587: INFO: (17) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.724693ms)
Jul 15 22:04:02.607: INFO: (18) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.102205ms)
Jul 15 22:04:02.625: INFO: (19) /api/v1/nodes/10.190.211.91/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 18.041017ms)
[AfterEach] version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:04:02.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9628" for this suite.
Jul 15 22:04:08.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:04:09.057: INFO: namespace proxy-9628 deletion completed in 6.41921901s

• [SLOW TEST:7.045 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:04:09.058: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8098
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0715 22:04:19.385647      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 15 22:04:19.385: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:04:19.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8098" for this suite.
Jul 15 22:04:25.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:04:25.821: INFO: namespace gc-8098 deletion completed in 6.424432446s

• [SLOW TEST:16.763 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:04:25.822: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8510
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 22:04:26.126: INFO: Create a RollingUpdate DaemonSet
Jul 15 22:04:26.143: INFO: Check that daemon pods launch on every node of the cluster
Jul 15 22:04:26.164: INFO: Number of nodes with available pods: 0
Jul 15 22:04:26.164: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 22:04:27.188: INFO: Number of nodes with available pods: 0
Jul 15 22:04:27.188: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 22:04:28.190: INFO: Number of nodes with available pods: 1
Jul 15 22:04:28.190: INFO: Node 10.190.211.93 is running more than one daemon pod
Jul 15 22:04:29.193: INFO: Number of nodes with available pods: 3
Jul 15 22:04:29.193: INFO: Number of running nodes: 3, number of available pods: 3
Jul 15 22:04:29.193: INFO: Update the DaemonSet to trigger a rollout
Jul 15 22:04:29.214: INFO: Updating DaemonSet daemon-set
Jul 15 22:04:43.259: INFO: Roll back the DaemonSet before rollout is complete
Jul 15 22:04:43.281: INFO: Updating DaemonSet daemon-set
Jul 15 22:04:43.281: INFO: Make sure DaemonSet rollback is complete
Jul 15 22:04:43.292: INFO: Wrong image for pod: daemon-set-zv7kk. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Jul 15 22:04:43.292: INFO: Pod daemon-set-zv7kk is not available
Jul 15 22:04:44.318: INFO: Wrong image for pod: daemon-set-zv7kk. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Jul 15 22:04:44.318: INFO: Pod daemon-set-zv7kk is not available
Jul 15 22:04:45.442: INFO: Wrong image for pod: daemon-set-zv7kk. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Jul 15 22:04:45.442: INFO: Pod daemon-set-zv7kk is not available
Jul 15 22:04:46.318: INFO: Pod daemon-set-228p5 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8510, will wait for the garbage collector to delete the pods
Jul 15 22:04:46.446: INFO: Deleting DaemonSet.extensions daemon-set took: 30.250061ms
Jul 15 22:04:46.647: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.179609ms
Jul 15 22:04:49.456: INFO: Number of nodes with available pods: 0
Jul 15 22:04:49.456: INFO: Number of running nodes: 0, number of available pods: 0
Jul 15 22:04:49.465: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8510/daemonsets","resourceVersion":"10412"},"items":null}

Jul 15 22:04:49.474: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8510/pods","resourceVersion":"10412"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:04:49.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8510" for this suite.
Jul 15 22:04:57.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:04:57.926: INFO: namespace daemonsets-8510 deletion completed in 8.395975997s

• [SLOW TEST:32.105 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:04:57.927: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2719
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul 15 22:04:58.204: INFO: Waiting up to 5m0s for pod "downward-api-95aa9087-a74c-11e9-983d-d6ce37abd03c" in namespace "downward-api-2719" to be "success or failure"
Jul 15 22:04:58.218: INFO: Pod "downward-api-95aa9087-a74c-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.456333ms
Jul 15 22:05:00.233: INFO: Pod "downward-api-95aa9087-a74c-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028536577s
Jul 15 22:05:02.245: INFO: Pod "downward-api-95aa9087-a74c-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040497664s
STEP: Saw pod success
Jul 15 22:05:02.245: INFO: Pod "downward-api-95aa9087-a74c-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:05:02.256: INFO: Trying to get logs from node 10.190.211.93 pod downward-api-95aa9087-a74c-11e9-983d-d6ce37abd03c container dapi-container: <nil>
STEP: delete the pod
Jul 15 22:05:02.321: INFO: Waiting for pod downward-api-95aa9087-a74c-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:05:02.342: INFO: Pod downward-api-95aa9087-a74c-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:05:02.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2719" for this suite.
Jul 15 22:05:08.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:05:08.856: INFO: namespace downward-api-2719 deletion completed in 6.499914152s

• [SLOW TEST:10.929 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:05:08.858: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1139
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-9c2b2354-a74c-11e9-983d-d6ce37abd03c
STEP: Creating secret with name s-test-opt-upd-9c2b23a5-a74c-11e9-983d-d6ce37abd03c
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-9c2b2354-a74c-11e9-983d-d6ce37abd03c
STEP: Updating secret s-test-opt-upd-9c2b23a5-a74c-11e9-983d-d6ce37abd03c
STEP: Creating secret with name s-test-opt-create-9c2b23c8-a74c-11e9-983d-d6ce37abd03c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:05:15.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1139" for this suite.
Jul 15 22:05:33.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:05:33.783: INFO: namespace secrets-1139 deletion completed in 18.365364507s

• [SLOW TEST:24.925 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:05:33.784: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-7596
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-7596
I0715 22:05:34.018135      16 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-7596, replica count: 1
I0715 22:05:35.068462      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0715 22:05:36.068744      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 15 22:05:36.194: INFO: Created: latency-svc-d6lqp
Jul 15 22:05:36.210: INFO: Got endpoints: latency-svc-d6lqp [41.366269ms]
Jul 15 22:05:36.237: INFO: Created: latency-svc-6qj4g
Jul 15 22:05:36.251: INFO: Got endpoints: latency-svc-6qj4g [40.731933ms]
Jul 15 22:05:36.257: INFO: Created: latency-svc-5xvzz
Jul 15 22:05:36.267: INFO: Got endpoints: latency-svc-5xvzz [56.124403ms]
Jul 15 22:05:36.277: INFO: Created: latency-svc-rb7b7
Jul 15 22:05:36.290: INFO: Got endpoints: latency-svc-rb7b7 [79.431962ms]
Jul 15 22:05:36.301: INFO: Created: latency-svc-rfzg6
Jul 15 22:05:36.311: INFO: Got endpoints: latency-svc-rfzg6 [99.614593ms]
Jul 15 22:05:36.316: INFO: Created: latency-svc-v48ml
Jul 15 22:05:36.325: INFO: Got endpoints: latency-svc-v48ml [114.975372ms]
Jul 15 22:05:36.343: INFO: Created: latency-svc-qwpmr
Jul 15 22:05:36.356: INFO: Got endpoints: latency-svc-qwpmr [144.443699ms]
Jul 15 22:05:36.375: INFO: Created: latency-svc-xgvsr
Jul 15 22:05:36.405: INFO: Created: latency-svc-6bmf2
Jul 15 22:05:36.405: INFO: Got endpoints: latency-svc-xgvsr [194.014089ms]
Jul 15 22:05:36.407: INFO: Got endpoints: latency-svc-6bmf2 [195.570079ms]
Jul 15 22:05:36.426: INFO: Created: latency-svc-k8xl4
Jul 15 22:05:36.437: INFO: Got endpoints: latency-svc-k8xl4 [225.270016ms]
Jul 15 22:05:36.442: INFO: Created: latency-svc-4j7tw
Jul 15 22:05:36.465: INFO: Got endpoints: latency-svc-4j7tw [253.388865ms]
Jul 15 22:05:36.465: INFO: Created: latency-svc-xgkqb
Jul 15 22:05:36.474: INFO: Got endpoints: latency-svc-xgkqb [262.27076ms]
Jul 15 22:05:36.479: INFO: Created: latency-svc-5nrpz
Jul 15 22:05:36.513: INFO: Got endpoints: latency-svc-5nrpz [301.099211ms]
Jul 15 22:05:36.518: INFO: Created: latency-svc-9fcmd
Jul 15 22:05:36.529: INFO: Got endpoints: latency-svc-9fcmd [316.172919ms]
Jul 15 22:05:36.533: INFO: Created: latency-svc-ksblg
Jul 15 22:05:36.547: INFO: Got endpoints: latency-svc-ksblg [335.281367ms]
Jul 15 22:05:36.553: INFO: Created: latency-svc-jc2hp
Jul 15 22:05:36.564: INFO: Got endpoints: latency-svc-jc2hp [351.542358ms]
Jul 15 22:05:36.569: INFO: Created: latency-svc-9jjkq
Jul 15 22:05:36.584: INFO: Got endpoints: latency-svc-9jjkq [332.775885ms]
Jul 15 22:05:36.592: INFO: Created: latency-svc-8hrsn
Jul 15 22:05:36.607: INFO: Created: latency-svc-bshgv
Jul 15 22:05:36.608: INFO: Got endpoints: latency-svc-8hrsn [340.911319ms]
Jul 15 22:05:36.617: INFO: Got endpoints: latency-svc-bshgv [326.444979ms]
Jul 15 22:05:36.633: INFO: Created: latency-svc-s9hlz
Jul 15 22:05:36.645: INFO: Got endpoints: latency-svc-s9hlz [334.374842ms]
Jul 15 22:05:36.651: INFO: Created: latency-svc-mnl6z
Jul 15 22:05:36.662: INFO: Got endpoints: latency-svc-mnl6z [336.288519ms]
Jul 15 22:05:36.669: INFO: Created: latency-svc-2w54t
Jul 15 22:05:36.678: INFO: Got endpoints: latency-svc-2w54t [322.122014ms]
Jul 15 22:05:36.689: INFO: Created: latency-svc-m7hg4
Jul 15 22:05:36.703: INFO: Got endpoints: latency-svc-m7hg4 [297.629284ms]
Jul 15 22:05:36.712: INFO: Created: latency-svc-6cq6n
Jul 15 22:05:36.723: INFO: Got endpoints: latency-svc-6cq6n [315.478993ms]
Jul 15 22:05:36.725: INFO: Created: latency-svc-d2nvh
Jul 15 22:05:36.737: INFO: Got endpoints: latency-svc-d2nvh [300.220881ms]
Jul 15 22:05:36.743: INFO: Created: latency-svc-84z48
Jul 15 22:05:36.754: INFO: Got endpoints: latency-svc-84z48 [289.297187ms]
Jul 15 22:05:36.761: INFO: Created: latency-svc-gxr76
Jul 15 22:05:36.770: INFO: Got endpoints: latency-svc-gxr76 [295.969595ms]
Jul 15 22:05:36.774: INFO: Created: latency-svc-bwtmh
Jul 15 22:05:36.782: INFO: Got endpoints: latency-svc-bwtmh [269.064319ms]
Jul 15 22:05:36.793: INFO: Created: latency-svc-5bvz7
Jul 15 22:05:36.804: INFO: Got endpoints: latency-svc-5bvz7 [275.776643ms]
Jul 15 22:05:36.809: INFO: Created: latency-svc-bmqhr
Jul 15 22:05:36.821: INFO: Got endpoints: latency-svc-bmqhr [274.135743ms]
Jul 15 22:05:36.824: INFO: Created: latency-svc-dlx7q
Jul 15 22:05:36.837: INFO: Got endpoints: latency-svc-dlx7q [272.993624ms]
Jul 15 22:05:36.841: INFO: Created: latency-svc-jszf6
Jul 15 22:05:36.850: INFO: Got endpoints: latency-svc-jszf6 [265.82691ms]
Jul 15 22:05:36.860: INFO: Created: latency-svc-ctzd8
Jul 15 22:05:36.870: INFO: Got endpoints: latency-svc-ctzd8 [262.186534ms]
Jul 15 22:05:36.875: INFO: Created: latency-svc-xgt9g
Jul 15 22:05:36.887: INFO: Got endpoints: latency-svc-xgt9g [269.938705ms]
Jul 15 22:05:36.901: INFO: Created: latency-svc-v7pmn
Jul 15 22:05:36.925: INFO: Got endpoints: latency-svc-v7pmn [279.9007ms]
Jul 15 22:05:36.925: INFO: Created: latency-svc-h5sjr
Jul 15 22:05:36.930: INFO: Got endpoints: latency-svc-h5sjr [268.805313ms]
Jul 15 22:05:36.934: INFO: Created: latency-svc-96sbk
Jul 15 22:05:36.948: INFO: Got endpoints: latency-svc-96sbk [270.320278ms]
Jul 15 22:05:36.951: INFO: Created: latency-svc-kcqtm
Jul 15 22:05:36.961: INFO: Got endpoints: latency-svc-kcqtm [258.191481ms]
Jul 15 22:05:36.965: INFO: Created: latency-svc-85kxl
Jul 15 22:05:36.977: INFO: Got endpoints: latency-svc-85kxl [254.493445ms]
Jul 15 22:05:36.984: INFO: Created: latency-svc-276rn
Jul 15 22:05:36.995: INFO: Got endpoints: latency-svc-276rn [257.872538ms]
Jul 15 22:05:37.010: INFO: Created: latency-svc-5jlv6
Jul 15 22:05:37.025: INFO: Got endpoints: latency-svc-5jlv6 [271.00604ms]
Jul 15 22:05:37.035: INFO: Created: latency-svc-l5g9w
Jul 15 22:05:37.051: INFO: Got endpoints: latency-svc-l5g9w [280.802673ms]
Jul 15 22:05:37.058: INFO: Created: latency-svc-2rrf7
Jul 15 22:05:37.071: INFO: Got endpoints: latency-svc-2rrf7 [288.91149ms]
Jul 15 22:05:37.077: INFO: Created: latency-svc-pg29m
Jul 15 22:05:37.086: INFO: Got endpoints: latency-svc-pg29m [281.297069ms]
Jul 15 22:05:37.100: INFO: Created: latency-svc-8p5l8
Jul 15 22:05:37.116: INFO: Got endpoints: latency-svc-8p5l8 [294.800603ms]
Jul 15 22:05:37.126: INFO: Created: latency-svc-4nv5c
Jul 15 22:05:37.137: INFO: Got endpoints: latency-svc-4nv5c [299.944136ms]
Jul 15 22:05:37.144: INFO: Created: latency-svc-d5hzt
Jul 15 22:05:37.159: INFO: Got endpoints: latency-svc-d5hzt [308.803357ms]
Jul 15 22:05:37.162: INFO: Created: latency-svc-skc9p
Jul 15 22:05:37.174: INFO: Got endpoints: latency-svc-skc9p [303.463439ms]
Jul 15 22:05:37.181: INFO: Created: latency-svc-xg2v6
Jul 15 22:05:37.198: INFO: Got endpoints: latency-svc-xg2v6 [311.267478ms]
Jul 15 22:05:37.204: INFO: Created: latency-svc-cwt57
Jul 15 22:05:37.224: INFO: Got endpoints: latency-svc-cwt57 [298.934226ms]
Jul 15 22:05:37.231: INFO: Created: latency-svc-n9lvw
Jul 15 22:05:37.241: INFO: Got endpoints: latency-svc-n9lvw [311.011913ms]
Jul 15 22:05:37.260: INFO: Created: latency-svc-rr6zh
Jul 15 22:05:37.278: INFO: Got endpoints: latency-svc-rr6zh [329.27189ms]
Jul 15 22:05:37.279: INFO: Created: latency-svc-8sfxc
Jul 15 22:05:37.293: INFO: Got endpoints: latency-svc-8sfxc [331.481655ms]
Jul 15 22:05:37.318: INFO: Created: latency-svc-kbx8f
Jul 15 22:05:37.330: INFO: Got endpoints: latency-svc-kbx8f [352.317069ms]
Jul 15 22:05:37.348: INFO: Created: latency-svc-xr6lb
Jul 15 22:05:37.358: INFO: Got endpoints: latency-svc-xr6lb [362.416015ms]
Jul 15 22:05:37.364: INFO: Created: latency-svc-lzvqj
Jul 15 22:05:37.372: INFO: Got endpoints: latency-svc-lzvqj [346.850169ms]
Jul 15 22:05:37.376: INFO: Created: latency-svc-ct8lh
Jul 15 22:05:37.387: INFO: Got endpoints: latency-svc-ct8lh [336.105808ms]
Jul 15 22:05:37.393: INFO: Created: latency-svc-xcmh5
Jul 15 22:05:37.406: INFO: Got endpoints: latency-svc-xcmh5 [334.395119ms]
Jul 15 22:05:37.409: INFO: Created: latency-svc-8zz9z
Jul 15 22:05:37.419: INFO: Got endpoints: latency-svc-8zz9z [333.173385ms]
Jul 15 22:05:37.427: INFO: Created: latency-svc-5vk8b
Jul 15 22:05:37.437: INFO: Got endpoints: latency-svc-5vk8b [320.948805ms]
Jul 15 22:05:37.442: INFO: Created: latency-svc-xbvws
Jul 15 22:05:37.457: INFO: Got endpoints: latency-svc-xbvws [319.77869ms]
Jul 15 22:05:37.465: INFO: Created: latency-svc-qlgtc
Jul 15 22:05:37.475: INFO: Got endpoints: latency-svc-qlgtc [315.849166ms]
Jul 15 22:05:37.496: INFO: Created: latency-svc-bjn4x
Jul 15 22:05:37.509: INFO: Got endpoints: latency-svc-bjn4x [334.830004ms]
Jul 15 22:05:37.515: INFO: Created: latency-svc-54mgb
Jul 15 22:05:37.535: INFO: Got endpoints: latency-svc-54mgb [336.985801ms]
Jul 15 22:05:37.542: INFO: Created: latency-svc-n8gdq
Jul 15 22:05:37.551: INFO: Got endpoints: latency-svc-n8gdq [327.389121ms]
Jul 15 22:05:37.568: INFO: Created: latency-svc-j8qs8
Jul 15 22:05:37.579: INFO: Got endpoints: latency-svc-j8qs8 [337.835248ms]
Jul 15 22:05:37.585: INFO: Created: latency-svc-4jltx
Jul 15 22:05:37.598: INFO: Got endpoints: latency-svc-4jltx [320.549848ms]
Jul 15 22:05:37.600: INFO: Created: latency-svc-xb4n8
Jul 15 22:05:37.611: INFO: Got endpoints: latency-svc-xb4n8 [317.984189ms]
Jul 15 22:05:37.619: INFO: Created: latency-svc-xt4mt
Jul 15 22:05:37.629: INFO: Got endpoints: latency-svc-xt4mt [299.502099ms]
Jul 15 22:05:37.647: INFO: Created: latency-svc-pkd2z
Jul 15 22:05:37.666: INFO: Got endpoints: latency-svc-pkd2z [308.712947ms]
Jul 15 22:05:37.676: INFO: Created: latency-svc-9gkgv
Jul 15 22:05:37.696: INFO: Got endpoints: latency-svc-9gkgv [323.668534ms]
Jul 15 22:05:37.703: INFO: Created: latency-svc-wnmc2
Jul 15 22:05:37.719: INFO: Got endpoints: latency-svc-wnmc2 [331.89871ms]
Jul 15 22:05:37.727: INFO: Created: latency-svc-dxd8q
Jul 15 22:05:37.741: INFO: Got endpoints: latency-svc-dxd8q [334.718806ms]
Jul 15 22:05:37.747: INFO: Created: latency-svc-4r8kd
Jul 15 22:05:37.770: INFO: Created: latency-svc-vfs6b
Jul 15 22:05:37.772: INFO: Got endpoints: latency-svc-4r8kd [353.002151ms]
Jul 15 22:05:37.786: INFO: Got endpoints: latency-svc-vfs6b [348.827994ms]
Jul 15 22:05:37.792: INFO: Created: latency-svc-2npl4
Jul 15 22:05:37.805: INFO: Got endpoints: latency-svc-2npl4 [347.887247ms]
Jul 15 22:05:37.807: INFO: Created: latency-svc-4xgh6
Jul 15 22:05:37.818: INFO: Got endpoints: latency-svc-4xgh6 [343.56406ms]
Jul 15 22:05:37.826: INFO: Created: latency-svc-tsh6t
Jul 15 22:05:37.840: INFO: Got endpoints: latency-svc-tsh6t [331.258892ms]
Jul 15 22:05:37.844: INFO: Created: latency-svc-582cv
Jul 15 22:05:37.875: INFO: Got endpoints: latency-svc-582cv [339.835115ms]
Jul 15 22:05:37.885: INFO: Created: latency-svc-9pmvf
Jul 15 22:05:37.894: INFO: Got endpoints: latency-svc-9pmvf [342.358385ms]
Jul 15 22:05:37.900: INFO: Created: latency-svc-vx7p2
Jul 15 22:05:37.910: INFO: Got endpoints: latency-svc-vx7p2 [331.099678ms]
Jul 15 22:05:37.915: INFO: Created: latency-svc-fpjg4
Jul 15 22:05:37.925: INFO: Got endpoints: latency-svc-fpjg4 [326.565347ms]
Jul 15 22:05:37.941: INFO: Created: latency-svc-nm6x8
Jul 15 22:05:37.963: INFO: Got endpoints: latency-svc-nm6x8 [351.944435ms]
Jul 15 22:05:37.970: INFO: Created: latency-svc-x4cm8
Jul 15 22:05:37.989: INFO: Got endpoints: latency-svc-x4cm8 [359.79988ms]
Jul 15 22:05:37.995: INFO: Created: latency-svc-wtl9b
Jul 15 22:05:38.004: INFO: Got endpoints: latency-svc-wtl9b [338.009792ms]
Jul 15 22:05:38.008: INFO: Created: latency-svc-xlvjc
Jul 15 22:05:38.027: INFO: Got endpoints: latency-svc-xlvjc [330.579671ms]
Jul 15 22:05:38.032: INFO: Created: latency-svc-vr22n
Jul 15 22:05:38.043: INFO: Got endpoints: latency-svc-vr22n [323.466841ms]
Jul 15 22:05:38.054: INFO: Created: latency-svc-55284
Jul 15 22:05:38.069: INFO: Got endpoints: latency-svc-55284 [327.877704ms]
Jul 15 22:05:38.076: INFO: Created: latency-svc-48zc9
Jul 15 22:05:38.087: INFO: Got endpoints: latency-svc-48zc9 [314.554587ms]
Jul 15 22:05:38.094: INFO: Created: latency-svc-ntzfx
Jul 15 22:05:38.106: INFO: Got endpoints: latency-svc-ntzfx [319.972536ms]
Jul 15 22:05:38.113: INFO: Created: latency-svc-ncv7h
Jul 15 22:05:38.127: INFO: Got endpoints: latency-svc-ncv7h [322.291309ms]
Jul 15 22:05:38.137: INFO: Created: latency-svc-hmcjz
Jul 15 22:05:38.150: INFO: Got endpoints: latency-svc-hmcjz [331.344298ms]
Jul 15 22:05:38.157: INFO: Created: latency-svc-9nkgz
Jul 15 22:05:38.185: INFO: Got endpoints: latency-svc-9nkgz [344.981401ms]
Jul 15 22:05:38.185: INFO: Created: latency-svc-bdqlw
Jul 15 22:05:38.188: INFO: Got endpoints: latency-svc-bdqlw [313.44182ms]
Jul 15 22:05:38.195: INFO: Created: latency-svc-vslsg
Jul 15 22:05:38.204: INFO: Got endpoints: latency-svc-vslsg [310.4013ms]
Jul 15 22:05:38.209: INFO: Created: latency-svc-5hjqq
Jul 15 22:05:38.220: INFO: Got endpoints: latency-svc-5hjqq [309.698397ms]
Jul 15 22:05:38.226: INFO: Created: latency-svc-br6v2
Jul 15 22:05:38.234: INFO: Got endpoints: latency-svc-br6v2 [309.170891ms]
Jul 15 22:05:38.251: INFO: Created: latency-svc-mfjlm
Jul 15 22:05:38.261: INFO: Got endpoints: latency-svc-mfjlm [298.534067ms]
Jul 15 22:05:38.270: INFO: Created: latency-svc-jk4nz
Jul 15 22:05:38.279: INFO: Got endpoints: latency-svc-jk4nz [290.151157ms]
Jul 15 22:05:38.289: INFO: Created: latency-svc-xx85r
Jul 15 22:05:38.304: INFO: Got endpoints: latency-svc-xx85r [299.565259ms]
Jul 15 22:05:38.309: INFO: Created: latency-svc-vvtks
Jul 15 22:05:38.321: INFO: Got endpoints: latency-svc-vvtks [41.313549ms]
Jul 15 22:05:38.326: INFO: Created: latency-svc-8c6dt
Jul 15 22:05:38.341: INFO: Got endpoints: latency-svc-8c6dt [313.983021ms]
Jul 15 22:05:38.345: INFO: Created: latency-svc-jcnhc
Jul 15 22:05:38.355: INFO: Got endpoints: latency-svc-jcnhc [311.732823ms]
Jul 15 22:05:38.360: INFO: Created: latency-svc-tmc74
Jul 15 22:05:38.373: INFO: Got endpoints: latency-svc-tmc74 [304.585522ms]
Jul 15 22:05:38.375: INFO: Created: latency-svc-7sf56
Jul 15 22:05:38.385: INFO: Got endpoints: latency-svc-7sf56 [298.555384ms]
Jul 15 22:05:38.392: INFO: Created: latency-svc-tpnf5
Jul 15 22:05:38.403: INFO: Got endpoints: latency-svc-tpnf5 [296.780183ms]
Jul 15 22:05:38.409: INFO: Created: latency-svc-j4hj9
Jul 15 22:05:38.419: INFO: Got endpoints: latency-svc-j4hj9 [291.966392ms]
Jul 15 22:05:38.432: INFO: Created: latency-svc-8lhhb
Jul 15 22:05:38.439: INFO: Got endpoints: latency-svc-8lhhb [289.560649ms]
Jul 15 22:05:38.452: INFO: Created: latency-svc-dlpfv
Jul 15 22:05:38.464: INFO: Got endpoints: latency-svc-dlpfv [278.766785ms]
Jul 15 22:05:38.471: INFO: Created: latency-svc-vpk2t
Jul 15 22:05:38.485: INFO: Got endpoints: latency-svc-vpk2t [297.003739ms]
Jul 15 22:05:38.497: INFO: Created: latency-svc-sq72j
Jul 15 22:05:38.509: INFO: Got endpoints: latency-svc-sq72j [304.574276ms]
Jul 15 22:05:38.518: INFO: Created: latency-svc-6c27b
Jul 15 22:05:38.533: INFO: Got endpoints: latency-svc-6c27b [312.787775ms]
Jul 15 22:05:38.534: INFO: Created: latency-svc-5xd48
Jul 15 22:05:38.546: INFO: Created: latency-svc-qlfdf
Jul 15 22:05:38.550: INFO: Got endpoints: latency-svc-5xd48 [316.179531ms]
Jul 15 22:05:38.557: INFO: Got endpoints: latency-svc-qlfdf [295.532367ms]
Jul 15 22:05:38.569: INFO: Created: latency-svc-cchlc
Jul 15 22:05:38.578: INFO: Got endpoints: latency-svc-cchlc [273.548918ms]
Jul 15 22:05:38.593: INFO: Created: latency-svc-5d7j5
Jul 15 22:05:38.607: INFO: Got endpoints: latency-svc-5d7j5 [286.317226ms]
Jul 15 22:05:38.616: INFO: Created: latency-svc-rgbdg
Jul 15 22:05:38.635: INFO: Created: latency-svc-85t2n
Jul 15 22:05:38.635: INFO: Got endpoints: latency-svc-rgbdg [294.258755ms]
Jul 15 22:05:38.646: INFO: Got endpoints: latency-svc-85t2n [290.991793ms]
Jul 15 22:05:38.661: INFO: Created: latency-svc-q24q5
Jul 15 22:05:38.673: INFO: Got endpoints: latency-svc-q24q5 [299.849903ms]
Jul 15 22:05:38.681: INFO: Created: latency-svc-bvqsf
Jul 15 22:05:38.694: INFO: Got endpoints: latency-svc-bvqsf [308.615545ms]
Jul 15 22:05:38.700: INFO: Created: latency-svc-cprtx
Jul 15 22:05:38.710: INFO: Got endpoints: latency-svc-cprtx [307.382555ms]
Jul 15 22:05:38.728: INFO: Created: latency-svc-c5xbc
Jul 15 22:05:38.747: INFO: Got endpoints: latency-svc-c5xbc [327.61065ms]
Jul 15 22:05:38.765: INFO: Created: latency-svc-qxkl9
Jul 15 22:05:38.765: INFO: Got endpoints: latency-svc-qxkl9 [325.861943ms]
Jul 15 22:05:38.772: INFO: Created: latency-svc-mp8pg
Jul 15 22:05:38.784: INFO: Got endpoints: latency-svc-mp8pg [320.20274ms]
Jul 15 22:05:38.791: INFO: Created: latency-svc-26m6k
Jul 15 22:05:38.807: INFO: Got endpoints: latency-svc-26m6k [322.028301ms]
Jul 15 22:05:38.818: INFO: Created: latency-svc-sl9gn
Jul 15 22:05:38.828: INFO: Got endpoints: latency-svc-sl9gn [318.660548ms]
Jul 15 22:05:38.832: INFO: Created: latency-svc-6494s
Jul 15 22:05:38.845: INFO: Got endpoints: latency-svc-6494s [312.225598ms]
Jul 15 22:05:38.850: INFO: Created: latency-svc-tk9q5
Jul 15 22:05:38.862: INFO: Got endpoints: latency-svc-tk9q5 [311.789144ms]
Jul 15 22:05:38.869: INFO: Created: latency-svc-hl2wb
Jul 15 22:05:38.879: INFO: Got endpoints: latency-svc-hl2wb [321.697882ms]
Jul 15 22:05:38.884: INFO: Created: latency-svc-vbwt7
Jul 15 22:05:38.894: INFO: Got endpoints: latency-svc-vbwt7 [316.497043ms]
Jul 15 22:05:38.908: INFO: Created: latency-svc-kxcpr
Jul 15 22:05:38.921: INFO: Got endpoints: latency-svc-kxcpr [313.732877ms]
Jul 15 22:05:38.931: INFO: Created: latency-svc-rrbds
Jul 15 22:05:38.946: INFO: Got endpoints: latency-svc-rrbds [310.496313ms]
Jul 15 22:05:38.949: INFO: Created: latency-svc-fvnf8
Jul 15 22:05:38.959: INFO: Got endpoints: latency-svc-fvnf8 [313.275862ms]
Jul 15 22:05:38.980: INFO: Created: latency-svc-pnpx8
Jul 15 22:05:38.988: INFO: Got endpoints: latency-svc-pnpx8 [314.642285ms]
Jul 15 22:05:38.991: INFO: Created: latency-svc-xrrrj
Jul 15 22:05:39.002: INFO: Got endpoints: latency-svc-xrrrj [308.330367ms]
Jul 15 22:05:39.012: INFO: Created: latency-svc-5mlcv
Jul 15 22:05:39.024: INFO: Got endpoints: latency-svc-5mlcv [313.944141ms]
Jul 15 22:05:39.030: INFO: Created: latency-svc-srdbz
Jul 15 22:05:39.043: INFO: Got endpoints: latency-svc-srdbz [295.924222ms]
Jul 15 22:05:39.048: INFO: Created: latency-svc-j6s5h
Jul 15 22:05:39.060: INFO: Got endpoints: latency-svc-j6s5h [294.989906ms]
Jul 15 22:05:39.066: INFO: Created: latency-svc-2fcxf
Jul 15 22:05:39.077: INFO: Got endpoints: latency-svc-2fcxf [292.81867ms]
Jul 15 22:05:39.083: INFO: Created: latency-svc-xtrv6
Jul 15 22:05:39.094: INFO: Got endpoints: latency-svc-xtrv6 [286.70284ms]
Jul 15 22:05:39.098: INFO: Created: latency-svc-tjfzx
Jul 15 22:05:39.111: INFO: Got endpoints: latency-svc-tjfzx [282.863356ms]
Jul 15 22:05:39.116: INFO: Created: latency-svc-rnmv8
Jul 15 22:05:39.127: INFO: Got endpoints: latency-svc-rnmv8 [281.33797ms]
Jul 15 22:05:39.131: INFO: Created: latency-svc-d98ch
Jul 15 22:05:39.140: INFO: Got endpoints: latency-svc-d98ch [277.810817ms]
Jul 15 22:05:39.148: INFO: Created: latency-svc-zcktc
Jul 15 22:05:39.156: INFO: Got endpoints: latency-svc-zcktc [277.345544ms]
Jul 15 22:05:39.161: INFO: Created: latency-svc-x24rp
Jul 15 22:05:39.170: INFO: Got endpoints: latency-svc-x24rp [276.164758ms]
Jul 15 22:05:39.180: INFO: Created: latency-svc-rxhzk
Jul 15 22:05:39.193: INFO: Got endpoints: latency-svc-rxhzk [272.530918ms]
Jul 15 22:05:39.198: INFO: Created: latency-svc-klwqf
Jul 15 22:05:39.217: INFO: Got endpoints: latency-svc-klwqf [270.785291ms]
Jul 15 22:05:39.219: INFO: Created: latency-svc-6q5xz
Jul 15 22:05:39.230: INFO: Got endpoints: latency-svc-6q5xz [271.35317ms]
Jul 15 22:05:39.240: INFO: Created: latency-svc-qpkpl
Jul 15 22:05:39.249: INFO: Got endpoints: latency-svc-qpkpl [261.330564ms]
Jul 15 22:05:39.253: INFO: Created: latency-svc-xfqj8
Jul 15 22:05:39.268: INFO: Got endpoints: latency-svc-xfqj8 [265.377688ms]
Jul 15 22:05:39.274: INFO: Created: latency-svc-ks7mg
Jul 15 22:05:39.284: INFO: Got endpoints: latency-svc-ks7mg [259.471113ms]
Jul 15 22:05:39.301: INFO: Created: latency-svc-7tlt5
Jul 15 22:05:39.311: INFO: Got endpoints: latency-svc-7tlt5 [268.46084ms]
Jul 15 22:05:39.320: INFO: Created: latency-svc-5mbt5
Jul 15 22:05:39.332: INFO: Got endpoints: latency-svc-5mbt5 [271.39032ms]
Jul 15 22:05:39.336: INFO: Created: latency-svc-bts76
Jul 15 22:05:39.360: INFO: Created: latency-svc-bdjjs
Jul 15 22:05:39.375: INFO: Got endpoints: latency-svc-bts76 [297.621524ms]
Jul 15 22:05:39.384: INFO: Got endpoints: latency-svc-bdjjs [289.875042ms]
Jul 15 22:05:39.403: INFO: Created: latency-svc-m7lrr
Jul 15 22:05:39.413: INFO: Got endpoints: latency-svc-m7lrr [301.877253ms]
Jul 15 22:05:39.446: INFO: Created: latency-svc-jf2l2
Jul 15 22:05:39.458: INFO: Got endpoints: latency-svc-jf2l2 [331.312767ms]
Jul 15 22:05:39.465: INFO: Created: latency-svc-4r4x8
Jul 15 22:05:39.482: INFO: Got endpoints: latency-svc-4r4x8 [341.892756ms]
Jul 15 22:05:39.488: INFO: Created: latency-svc-fl4dq
Jul 15 22:05:39.502: INFO: Got endpoints: latency-svc-fl4dq [345.57547ms]
Jul 15 22:05:39.509: INFO: Created: latency-svc-fp5w9
Jul 15 22:05:39.520: INFO: Got endpoints: latency-svc-fp5w9 [349.896387ms]
Jul 15 22:05:39.525: INFO: Created: latency-svc-r27cf
Jul 15 22:05:39.544: INFO: Got endpoints: latency-svc-r27cf [350.652724ms]
Jul 15 22:05:39.556: INFO: Created: latency-svc-5rzqv
Jul 15 22:05:39.567: INFO: Got endpoints: latency-svc-5rzqv [350.844049ms]
Jul 15 22:05:39.574: INFO: Created: latency-svc-xbtmq
Jul 15 22:05:39.582: INFO: Got endpoints: latency-svc-xbtmq [351.714496ms]
Jul 15 22:05:39.587: INFO: Created: latency-svc-rkkv2
Jul 15 22:05:39.599: INFO: Got endpoints: latency-svc-rkkv2 [349.962875ms]
Jul 15 22:05:39.614: INFO: Created: latency-svc-6pgx5
Jul 15 22:05:39.629: INFO: Got endpoints: latency-svc-6pgx5 [360.793802ms]
Jul 15 22:05:39.633: INFO: Created: latency-svc-n5l75
Jul 15 22:05:39.648: INFO: Got endpoints: latency-svc-n5l75 [363.887153ms]
Jul 15 22:05:39.658: INFO: Created: latency-svc-m6z9p
Jul 15 22:05:39.665: INFO: Got endpoints: latency-svc-m6z9p [354.277633ms]
Jul 15 22:05:39.677: INFO: Created: latency-svc-26m4x
Jul 15 22:05:39.689: INFO: Got endpoints: latency-svc-26m4x [357.638803ms]
Jul 15 22:05:39.696: INFO: Created: latency-svc-wkjh5
Jul 15 22:05:39.713: INFO: Created: latency-svc-thmz8
Jul 15 22:05:39.719: INFO: Got endpoints: latency-svc-wkjh5 [344.215104ms]
Jul 15 22:05:39.724: INFO: Got endpoints: latency-svc-thmz8 [339.861864ms]
Jul 15 22:05:39.738: INFO: Created: latency-svc-r86bs
Jul 15 22:05:39.754: INFO: Got endpoints: latency-svc-r86bs [341.345492ms]
Jul 15 22:05:39.755: INFO: Created: latency-svc-l85db
Jul 15 22:05:39.769: INFO: Got endpoints: latency-svc-l85db [311.296684ms]
Jul 15 22:05:39.776: INFO: Created: latency-svc-l7c5j
Jul 15 22:05:39.795: INFO: Got endpoints: latency-svc-l7c5j [312.743521ms]
Jul 15 22:05:39.804: INFO: Created: latency-svc-5m8f5
Jul 15 22:05:39.815: INFO: Got endpoints: latency-svc-5m8f5 [313.190908ms]
Jul 15 22:05:39.835: INFO: Created: latency-svc-qgkbw
Jul 15 22:05:39.845: INFO: Got endpoints: latency-svc-qgkbw [324.378141ms]
Jul 15 22:05:39.851: INFO: Created: latency-svc-tqx48
Jul 15 22:05:39.866: INFO: Got endpoints: latency-svc-tqx48 [321.829816ms]
Jul 15 22:05:39.870: INFO: Created: latency-svc-szjxf
Jul 15 22:05:39.885: INFO: Got endpoints: latency-svc-szjxf [317.963136ms]
Jul 15 22:05:39.893: INFO: Created: latency-svc-x8pd4
Jul 15 22:05:39.913: INFO: Got endpoints: latency-svc-x8pd4 [331.041244ms]
Jul 15 22:05:39.918: INFO: Created: latency-svc-mt8b8
Jul 15 22:05:39.929: INFO: Got endpoints: latency-svc-mt8b8 [330.10105ms]
Jul 15 22:05:39.943: INFO: Created: latency-svc-sspf6
Jul 15 22:05:39.953: INFO: Got endpoints: latency-svc-sspf6 [324.641322ms]
Jul 15 22:05:39.959: INFO: Created: latency-svc-npbnk
Jul 15 22:05:39.971: INFO: Got endpoints: latency-svc-npbnk [322.948338ms]
Jul 15 22:05:39.984: INFO: Created: latency-svc-c6nfb
Jul 15 22:05:39.994: INFO: Got endpoints: latency-svc-c6nfb [328.672868ms]
Jul 15 22:05:40.008: INFO: Created: latency-svc-5lpj8
Jul 15 22:05:40.025: INFO: Created: latency-svc-pgx2v
Jul 15 22:05:40.028: INFO: Got endpoints: latency-svc-5lpj8 [338.700558ms]
Jul 15 22:05:40.040: INFO: Got endpoints: latency-svc-pgx2v [321.195756ms]
Jul 15 22:05:40.051: INFO: Created: latency-svc-lhf4d
Jul 15 22:05:40.064: INFO: Got endpoints: latency-svc-lhf4d [339.829414ms]
Jul 15 22:05:40.070: INFO: Created: latency-svc-wm6g6
Jul 15 22:05:40.082: INFO: Got endpoints: latency-svc-wm6g6 [328.171648ms]
Jul 15 22:05:40.101: INFO: Created: latency-svc-zdv24
Jul 15 22:05:40.114: INFO: Got endpoints: latency-svc-zdv24 [344.160692ms]
Jul 15 22:05:40.121: INFO: Created: latency-svc-fwg8c
Jul 15 22:05:40.133: INFO: Got endpoints: latency-svc-fwg8c [338.183003ms]
Jul 15 22:05:40.142: INFO: Created: latency-svc-smj8w
Jul 15 22:05:40.162: INFO: Got endpoints: latency-svc-smj8w [346.921399ms]
Jul 15 22:05:40.162: INFO: Created: latency-svc-z52wv
Jul 15 22:05:40.174: INFO: Got endpoints: latency-svc-z52wv [329.23567ms]
Jul 15 22:05:40.179: INFO: Created: latency-svc-fnwhf
Jul 15 22:05:40.206: INFO: Got endpoints: latency-svc-fnwhf [340.112587ms]
Jul 15 22:05:40.215: INFO: Created: latency-svc-wmskj
Jul 15 22:05:40.228: INFO: Got endpoints: latency-svc-wmskj [341.999032ms]
Jul 15 22:05:40.234: INFO: Created: latency-svc-lcwbc
Jul 15 22:05:40.255: INFO: Got endpoints: latency-svc-lcwbc [341.462103ms]
Jul 15 22:05:40.260: INFO: Created: latency-svc-2rxcp
Jul 15 22:05:40.293: INFO: Got endpoints: latency-svc-2rxcp [363.511343ms]
Jul 15 22:05:40.300: INFO: Created: latency-svc-rwnxx
Jul 15 22:05:40.311: INFO: Got endpoints: latency-svc-rwnxx [357.391651ms]
Jul 15 22:05:40.326: INFO: Created: latency-svc-tjr68
Jul 15 22:05:40.336: INFO: Got endpoints: latency-svc-tjr68 [365.161969ms]
Jul 15 22:05:40.341: INFO: Created: latency-svc-nglvw
Jul 15 22:05:40.352: INFO: Got endpoints: latency-svc-nglvw [357.379777ms]
Jul 15 22:05:40.361: INFO: Created: latency-svc-jg9vp
Jul 15 22:05:40.382: INFO: Got endpoints: latency-svc-jg9vp [353.826932ms]
Jul 15 22:05:40.385: INFO: Created: latency-svc-4lscr
Jul 15 22:05:40.396: INFO: Got endpoints: latency-svc-4lscr [355.731153ms]
Jul 15 22:05:40.401: INFO: Created: latency-svc-89h6v
Jul 15 22:05:40.418: INFO: Got endpoints: latency-svc-89h6v [353.846147ms]
Jul 15 22:05:40.423: INFO: Created: latency-svc-ctcph
Jul 15 22:05:40.433: INFO: Got endpoints: latency-svc-ctcph [350.237603ms]
Jul 15 22:05:40.433: INFO: Latencies: [40.731933ms 41.313549ms 56.124403ms 79.431962ms 99.614593ms 114.975372ms 144.443699ms 194.014089ms 195.570079ms 225.270016ms 253.388865ms 254.493445ms 257.872538ms 258.191481ms 259.471113ms 261.330564ms 262.186534ms 262.27076ms 265.377688ms 265.82691ms 268.46084ms 268.805313ms 269.064319ms 269.938705ms 270.320278ms 270.785291ms 271.00604ms 271.35317ms 271.39032ms 272.530918ms 272.993624ms 273.548918ms 274.135743ms 275.776643ms 276.164758ms 277.345544ms 277.810817ms 278.766785ms 279.9007ms 280.802673ms 281.297069ms 281.33797ms 282.863356ms 286.317226ms 286.70284ms 288.91149ms 289.297187ms 289.560649ms 289.875042ms 290.151157ms 290.991793ms 291.966392ms 292.81867ms 294.258755ms 294.800603ms 294.989906ms 295.532367ms 295.924222ms 295.969595ms 296.780183ms 297.003739ms 297.621524ms 297.629284ms 298.534067ms 298.555384ms 298.934226ms 299.502099ms 299.565259ms 299.849903ms 299.944136ms 300.220881ms 301.099211ms 301.877253ms 303.463439ms 304.574276ms 304.585522ms 307.382555ms 308.330367ms 308.615545ms 308.712947ms 308.803357ms 309.170891ms 309.698397ms 310.4013ms 310.496313ms 311.011913ms 311.267478ms 311.296684ms 311.732823ms 311.789144ms 312.225598ms 312.743521ms 312.787775ms 313.190908ms 313.275862ms 313.44182ms 313.732877ms 313.944141ms 313.983021ms 314.554587ms 314.642285ms 315.478993ms 315.849166ms 316.172919ms 316.179531ms 316.497043ms 317.963136ms 317.984189ms 318.660548ms 319.77869ms 319.972536ms 320.20274ms 320.549848ms 320.948805ms 321.195756ms 321.697882ms 321.829816ms 322.028301ms 322.122014ms 322.291309ms 322.948338ms 323.466841ms 323.668534ms 324.378141ms 324.641322ms 325.861943ms 326.444979ms 326.565347ms 327.389121ms 327.61065ms 327.877704ms 328.171648ms 328.672868ms 329.23567ms 329.27189ms 330.10105ms 330.579671ms 331.041244ms 331.099678ms 331.258892ms 331.312767ms 331.344298ms 331.481655ms 331.89871ms 332.775885ms 333.173385ms 334.374842ms 334.395119ms 334.718806ms 334.830004ms 335.281367ms 336.105808ms 336.288519ms 336.985801ms 337.835248ms 338.009792ms 338.183003ms 338.700558ms 339.829414ms 339.835115ms 339.861864ms 340.112587ms 340.911319ms 341.345492ms 341.462103ms 341.892756ms 341.999032ms 342.358385ms 343.56406ms 344.160692ms 344.215104ms 344.981401ms 345.57547ms 346.850169ms 346.921399ms 347.887247ms 348.827994ms 349.896387ms 349.962875ms 350.237603ms 350.652724ms 350.844049ms 351.542358ms 351.714496ms 351.944435ms 352.317069ms 353.002151ms 353.826932ms 353.846147ms 354.277633ms 355.731153ms 357.379777ms 357.391651ms 357.638803ms 359.79988ms 360.793802ms 362.416015ms 363.511343ms 363.887153ms 365.161969ms]
Jul 15 22:05:40.433: INFO: 50 %ile: 314.642285ms
Jul 15 22:05:40.433: INFO: 90 %ile: 350.652724ms
Jul 15 22:05:40.433: INFO: 99 %ile: 363.887153ms
Jul 15 22:05:40.433: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:05:40.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-7596" for this suite.
Jul 15 22:06:18.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:06:18.837: INFO: namespace svc-latency-7596 deletion completed in 38.390488546s

• [SLOW TEST:45.053 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:06:18.837: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6098
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jul 15 22:06:19.096: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6098,SelfLink:/api/v1/namespaces/watch-6098/configmaps/e2e-watch-test-label-changed,UID:c5de8710-a74c-11e9-a496-5e4367ce3703,ResourceVersion:11949,Generation:0,CreationTimestamp:2019-07-15 22:06:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 15 22:06:19.096: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6098,SelfLink:/api/v1/namespaces/watch-6098/configmaps/e2e-watch-test-label-changed,UID:c5de8710-a74c-11e9-a496-5e4367ce3703,ResourceVersion:11950,Generation:0,CreationTimestamp:2019-07-15 22:06:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jul 15 22:06:19.096: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6098,SelfLink:/api/v1/namespaces/watch-6098/configmaps/e2e-watch-test-label-changed,UID:c5de8710-a74c-11e9-a496-5e4367ce3703,ResourceVersion:11951,Generation:0,CreationTimestamp:2019-07-15 22:06:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jul 15 22:06:29.173: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6098,SelfLink:/api/v1/namespaces/watch-6098/configmaps/e2e-watch-test-label-changed,UID:c5de8710-a74c-11e9-a496-5e4367ce3703,ResourceVersion:11972,Generation:0,CreationTimestamp:2019-07-15 22:06:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 15 22:06:29.173: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6098,SelfLink:/api/v1/namespaces/watch-6098/configmaps/e2e-watch-test-label-changed,UID:c5de8710-a74c-11e9-a496-5e4367ce3703,ResourceVersion:11973,Generation:0,CreationTimestamp:2019-07-15 22:06:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jul 15 22:06:29.173: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6098,SelfLink:/api/v1/namespaces/watch-6098/configmaps/e2e-watch-test-label-changed,UID:c5de8710-a74c-11e9-a496-5e4367ce3703,ResourceVersion:11974,Generation:0,CreationTimestamp:2019-07-15 22:06:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:06:29.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6098" for this suite.
Jul 15 22:06:35.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:06:35.557: INFO: namespace watch-6098 deletion completed in 6.368520526s

• [SLOW TEST:16.720 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:06:35.557: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6218
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1652
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 15 22:06:35.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-6218'
Jul 15 22:06:36.206: INFO: stderr: ""
Jul 15 22:06:36.206: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1657
Jul 15 22:06:36.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 delete pods e2e-test-nginx-pod --namespace=kubectl-6218'
Jul 15 22:06:52.439: INFO: stderr: ""
Jul 15 22:06:52.439: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:06:52.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6218" for this suite.
Jul 15 22:07:00.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:07:00.866: INFO: namespace kubectl-6218 deletion completed in 8.406207153s

• [SLOW TEST:25.309 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:07:00.867: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2060
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Jul 15 22:07:01.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 create -f - --namespace=kubectl-2060'
Jul 15 22:07:01.432: INFO: stderr: ""
Jul 15 22:07:01.432: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jul 15 22:07:02.447: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 22:07:02.448: INFO: Found 0 / 1
Jul 15 22:07:03.445: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 22:07:03.445: INFO: Found 0 / 1
Jul 15 22:07:04.445: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 22:07:04.445: INFO: Found 0 / 1
Jul 15 22:07:05.444: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 22:07:05.444: INFO: Found 1 / 1
Jul 15 22:07:05.444: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jul 15 22:07:05.457: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 22:07:05.457: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 15 22:07:05.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 patch pod redis-master-85gvr --namespace=kubectl-2060 -p {"metadata":{"annotations":{"x":"y"}}}'
Jul 15 22:07:05.632: INFO: stderr: ""
Jul 15 22:07:05.633: INFO: stdout: "pod/redis-master-85gvr patched\n"
STEP: checking annotations
Jul 15 22:07:05.644: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 22:07:05.644: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:07:05.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2060" for this suite.
Jul 15 22:07:29.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:07:30.026: INFO: namespace kubectl-2060 deletion completed in 24.3620635s

• [SLOW TEST:29.159 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:07:30.026: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6484
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1259
STEP: creating an rc
Jul 15 22:07:30.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 create -f - --namespace=kubectl-6484'
Jul 15 22:07:30.449: INFO: stderr: ""
Jul 15 22:07:30.449: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Jul 15 22:07:31.459: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 22:07:31.459: INFO: Found 0 / 1
Jul 15 22:07:32.460: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 22:07:32.460: INFO: Found 0 / 1
Jul 15 22:07:33.462: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 22:07:33.462: INFO: Found 1 / 1
Jul 15 22:07:33.462: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul 15 22:07:33.472: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 22:07:33.472: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jul 15 22:07:33.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 logs redis-master-ntckz redis-master --namespace=kubectl-6484'
Jul 15 22:07:33.613: INFO: stderr: ""
Jul 15 22:07:33.613: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Jul 22:07:31.795 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Jul 22:07:31.795 # Server started, Redis version 3.2.12\n1:M 15 Jul 22:07:31.795 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Jul 22:07:31.795 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jul 15 22:07:33.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 log redis-master-ntckz redis-master --namespace=kubectl-6484 --tail=1'
Jul 15 22:07:33.825: INFO: stderr: ""
Jul 15 22:07:33.825: INFO: stdout: "1:M 15 Jul 22:07:31.795 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jul 15 22:07:33.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 log redis-master-ntckz redis-master --namespace=kubectl-6484 --limit-bytes=1'
Jul 15 22:07:33.973: INFO: stderr: ""
Jul 15 22:07:33.973: INFO: stdout: " "
STEP: exposing timestamps
Jul 15 22:07:33.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 log redis-master-ntckz redis-master --namespace=kubectl-6484 --tail=1 --timestamps'
Jul 15 22:07:34.103: INFO: stderr: ""
Jul 15 22:07:34.103: INFO: stdout: "2019-07-15T22:07:31.79541411Z 1:M 15 Jul 22:07:31.795 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jul 15 22:07:36.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 log redis-master-ntckz redis-master --namespace=kubectl-6484 --since=1s'
Jul 15 22:07:36.733: INFO: stderr: ""
Jul 15 22:07:36.733: INFO: stdout: ""
Jul 15 22:07:36.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 log redis-master-ntckz redis-master --namespace=kubectl-6484 --since=24h'
Jul 15 22:07:36.874: INFO: stderr: ""
Jul 15 22:07:36.874: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Jul 22:07:31.795 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Jul 22:07:31.795 # Server started, Redis version 3.2.12\n1:M 15 Jul 22:07:31.795 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Jul 22:07:31.795 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1265
STEP: using delete to clean up resources
Jul 15 22:07:36.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 delete --grace-period=0 --force -f - --namespace=kubectl-6484'
Jul 15 22:07:37.013: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 22:07:37.013: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jul 15 22:07:37.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get rc,svc -l name=nginx --no-headers --namespace=kubectl-6484'
Jul 15 22:07:37.130: INFO: stderr: "No resources found.\n"
Jul 15 22:07:37.130: INFO: stdout: ""
Jul 15 22:07:37.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -l name=nginx --namespace=kubectl-6484 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 15 22:07:37.395: INFO: stderr: ""
Jul 15 22:07:37.395: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:07:37.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6484" for this suite.
Jul 15 22:07:45.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:07:45.825: INFO: namespace kubectl-6484 deletion completed in 8.40784426s

• [SLOW TEST:15.798 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:07:45.825: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-483
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Jul 15 22:07:46.061: INFO: Waiting up to 5m0s for pod "client-containers-f9b6ec68-a74c-11e9-983d-d6ce37abd03c" in namespace "containers-483" to be "success or failure"
Jul 15 22:07:46.072: INFO: Pod "client-containers-f9b6ec68-a74c-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.352966ms
Jul 15 22:07:48.087: INFO: Pod "client-containers-f9b6ec68-a74c-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025544493s
Jul 15 22:07:50.097: INFO: Pod "client-containers-f9b6ec68-a74c-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035678985s
STEP: Saw pod success
Jul 15 22:07:50.097: INFO: Pod "client-containers-f9b6ec68-a74c-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:07:50.109: INFO: Trying to get logs from node 10.190.211.93 pod client-containers-f9b6ec68-a74c-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 22:07:50.167: INFO: Waiting for pod client-containers-f9b6ec68-a74c-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:07:50.177: INFO: Pod client-containers-f9b6ec68-a74c-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:07:50.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-483" for this suite.
Jul 15 22:07:56.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:07:56.749: INFO: namespace containers-483 deletion completed in 6.386553328s

• [SLOW TEST:10.924 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:07:56.750: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1620
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul 15 22:07:56.993: INFO: Waiting up to 5m0s for pod "downward-api-003b761f-a74d-11e9-983d-d6ce37abd03c" in namespace "downward-api-1620" to be "success or failure"
Jul 15 22:07:57.002: INFO: Pod "downward-api-003b761f-a74d-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.430528ms
Jul 15 22:07:59.014: INFO: Pod "downward-api-003b761f-a74d-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021125989s
STEP: Saw pod success
Jul 15 22:07:59.014: INFO: Pod "downward-api-003b761f-a74d-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:07:59.025: INFO: Trying to get logs from node 10.190.211.93 pod downward-api-003b761f-a74d-11e9-983d-d6ce37abd03c container dapi-container: <nil>
STEP: delete the pod
Jul 15 22:07:59.080: INFO: Waiting for pod downward-api-003b761f-a74d-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:07:59.093: INFO: Pod downward-api-003b761f-a74d-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:07:59.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1620" for this suite.
Jul 15 22:08:05.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:08:05.497: INFO: namespace downward-api-1620 deletion completed in 6.39025477s

• [SLOW TEST:8.748 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:08:05.498: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2066
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 22:08:05.737: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0570784e-a74d-11e9-983d-d6ce37abd03c" in namespace "downward-api-2066" to be "success or failure"
Jul 15 22:08:05.751: INFO: Pod "downwardapi-volume-0570784e-a74d-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.408482ms
Jul 15 22:08:07.762: INFO: Pod "downwardapi-volume-0570784e-a74d-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024921914s
STEP: Saw pod success
Jul 15 22:08:07.762: INFO: Pod "downwardapi-volume-0570784e-a74d-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:08:07.771: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-0570784e-a74d-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 22:08:07.846: INFO: Waiting for pod downwardapi-volume-0570784e-a74d-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:08:07.875: INFO: Pod downwardapi-volume-0570784e-a74d-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:08:07.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2066" for this suite.
Jul 15 22:08:13.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:08:14.312: INFO: namespace downward-api-2066 deletion completed in 6.422331629s

• [SLOW TEST:8.815 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:08:14.313: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3046
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-756
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7264
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:08:40.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3046" for this suite.
Jul 15 22:08:48.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:08:48.467: INFO: namespace namespaces-3046 deletion completed in 8.366936259s
STEP: Destroying namespace "nsdeletetest-756" for this suite.
Jul 15 22:08:48.478: INFO: Namespace nsdeletetest-756 was already deleted
STEP: Destroying namespace "nsdeletetest-7264" for this suite.
Jul 15 22:08:54.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:08:54.862: INFO: namespace nsdeletetest-7264 deletion completed in 6.384740715s

• [SLOW TEST:40.550 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:08:54.863: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-874
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-22e0de40-a74d-11e9-983d-d6ce37abd03c
STEP: Creating secret with name s-test-opt-upd-22e0de91-a74d-11e9-983d-d6ce37abd03c
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-22e0de40-a74d-11e9-983d-d6ce37abd03c
STEP: Updating secret s-test-opt-upd-22e0de91-a74d-11e9-983d-d6ce37abd03c
STEP: Creating secret with name s-test-opt-create-22e0deb9-a74d-11e9-983d-d6ce37abd03c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:10:02.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-874" for this suite.
Jul 15 22:10:26.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:10:26.900: INFO: namespace projected-874 deletion completed in 24.417202713s

• [SLOW TEST:92.037 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:10:26.902: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2573
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Jul 15 22:10:27.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 create -f - --namespace=kubectl-2573'
Jul 15 22:10:27.477: INFO: stderr: ""
Jul 15 22:10:27.477: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 15 22:10:27.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2573'
Jul 15 22:10:27.616: INFO: stderr: ""
Jul 15 22:10:27.616: INFO: stdout: "update-demo-nautilus-44gsm update-demo-nautilus-kftnv "
Jul 15 22:10:27.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-44gsm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2573'
Jul 15 22:10:27.745: INFO: stderr: ""
Jul 15 22:10:27.746: INFO: stdout: ""
Jul 15 22:10:27.746: INFO: update-demo-nautilus-44gsm is created but not running
Jul 15 22:10:32.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2573'
Jul 15 22:10:32.869: INFO: stderr: ""
Jul 15 22:10:32.869: INFO: stdout: "update-demo-nautilus-44gsm update-demo-nautilus-kftnv "
Jul 15 22:10:32.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-44gsm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2573'
Jul 15 22:10:32.977: INFO: stderr: ""
Jul 15 22:10:32.977: INFO: stdout: "true"
Jul 15 22:10:32.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-44gsm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2573'
Jul 15 22:10:33.089: INFO: stderr: ""
Jul 15 22:10:33.089: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 22:10:33.089: INFO: validating pod update-demo-nautilus-44gsm
Jul 15 22:10:33.110: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 22:10:33.110: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 22:10:33.110: INFO: update-demo-nautilus-44gsm is verified up and running
Jul 15 22:10:33.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-kftnv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2573'
Jul 15 22:10:33.236: INFO: stderr: ""
Jul 15 22:10:33.236: INFO: stdout: "true"
Jul 15 22:10:33.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-kftnv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2573'
Jul 15 22:10:33.336: INFO: stderr: ""
Jul 15 22:10:33.336: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 22:10:33.336: INFO: validating pod update-demo-nautilus-kftnv
Jul 15 22:10:33.356: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 22:10:33.356: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 22:10:33.356: INFO: update-demo-nautilus-kftnv is verified up and running
STEP: rolling-update to new replication controller
Jul 15 22:10:33.358: INFO: scanned /root for discovery docs: <nil>
Jul 15 22:10:33.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-2573'
Jul 15 22:10:56.546: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jul 15 22:10:56.546: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 15 22:10:56.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2573'
Jul 15 22:10:56.673: INFO: stderr: ""
Jul 15 22:10:56.673: INFO: stdout: "update-demo-kitten-bqr2c update-demo-kitten-n4pcg "
Jul 15 22:10:56.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-kitten-bqr2c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2573'
Jul 15 22:10:56.786: INFO: stderr: ""
Jul 15 22:10:56.786: INFO: stdout: "true"
Jul 15 22:10:56.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-kitten-bqr2c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2573'
Jul 15 22:10:56.893: INFO: stderr: ""
Jul 15 22:10:56.893: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jul 15 22:10:56.893: INFO: validating pod update-demo-kitten-bqr2c
Jul 15 22:10:56.921: INFO: got data: {
  "image": "kitten.jpg"
}

Jul 15 22:10:56.921: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jul 15 22:10:56.921: INFO: update-demo-kitten-bqr2c is verified up and running
Jul 15 22:10:56.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-kitten-n4pcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2573'
Jul 15 22:10:57.013: INFO: stderr: ""
Jul 15 22:10:57.013: INFO: stdout: "true"
Jul 15 22:10:57.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-kitten-n4pcg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2573'
Jul 15 22:10:57.137: INFO: stderr: ""
Jul 15 22:10:57.137: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jul 15 22:10:57.137: INFO: validating pod update-demo-kitten-n4pcg
Jul 15 22:10:57.158: INFO: got data: {
  "image": "kitten.jpg"
}

Jul 15 22:10:57.158: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jul 15 22:10:57.158: INFO: update-demo-kitten-n4pcg is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:10:57.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2573" for this suite.
Jul 15 22:11:21.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:11:21.560: INFO: namespace kubectl-2573 deletion completed in 24.387757235s

• [SLOW TEST:54.658 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:11:21.561: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7319
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:11:21.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7319" for this suite.
Jul 15 22:11:45.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:11:46.234: INFO: namespace pods-7319 deletion completed in 24.387245645s

• [SLOW TEST:24.673 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:11:46.235: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1430
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 22:11:46.469: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8902adb3-a74d-11e9-983d-d6ce37abd03c" in namespace "downward-api-1430" to be "success or failure"
Jul 15 22:11:46.486: INFO: Pod "downwardapi-volume-8902adb3-a74d-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.717561ms
Jul 15 22:11:48.496: INFO: Pod "downwardapi-volume-8902adb3-a74d-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026520614s
STEP: Saw pod success
Jul 15 22:11:48.496: INFO: Pod "downwardapi-volume-8902adb3-a74d-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:11:48.505: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-8902adb3-a74d-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 22:11:48.554: INFO: Waiting for pod downwardapi-volume-8902adb3-a74d-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:11:48.564: INFO: Pod downwardapi-volume-8902adb3-a74d-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:11:48.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1430" for this suite.
Jul 15 22:11:54.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:11:55.118: INFO: namespace downward-api-1430 deletion completed in 6.538909708s

• [SLOW TEST:8.883 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:11:55.119: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6341
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Jul 15 22:11:55.367: INFO: Waiting up to 5m0s for pod "client-containers-8e50b791-a74d-11e9-983d-d6ce37abd03c" in namespace "containers-6341" to be "success or failure"
Jul 15 22:11:55.380: INFO: Pod "client-containers-8e50b791-a74d-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.17976ms
Jul 15 22:11:57.391: INFO: Pod "client-containers-8e50b791-a74d-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024198728s
STEP: Saw pod success
Jul 15 22:11:57.391: INFO: Pod "client-containers-8e50b791-a74d-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:11:57.400: INFO: Trying to get logs from node 10.190.211.93 pod client-containers-8e50b791-a74d-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 22:11:57.458: INFO: Waiting for pod client-containers-8e50b791-a74d-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:11:57.468: INFO: Pod client-containers-8e50b791-a74d-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:11:57.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6341" for this suite.
Jul 15 22:12:03.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:12:03.883: INFO: namespace containers-6341 deletion completed in 6.399650579s

• [SLOW TEST:8.764 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:12:03.884: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1983
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-93897ff5-a74d-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume secrets
Jul 15 22:12:04.141: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-938b55fb-a74d-11e9-983d-d6ce37abd03c" in namespace "projected-1983" to be "success or failure"
Jul 15 22:12:04.154: INFO: Pod "pod-projected-secrets-938b55fb-a74d-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.759758ms
Jul 15 22:12:06.167: INFO: Pod "pod-projected-secrets-938b55fb-a74d-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025948506s
STEP: Saw pod success
Jul 15 22:12:06.167: INFO: Pod "pod-projected-secrets-938b55fb-a74d-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:12:06.185: INFO: Trying to get logs from node 10.190.211.93 pod pod-projected-secrets-938b55fb-a74d-11e9-983d-d6ce37abd03c container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 15 22:12:06.248: INFO: Waiting for pod pod-projected-secrets-938b55fb-a74d-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:12:06.260: INFO: Pod pod-projected-secrets-938b55fb-a74d-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:12:06.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1983" for this suite.
Jul 15 22:12:12.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:12:12.665: INFO: namespace projected-1983 deletion completed in 6.389473399s

• [SLOW TEST:8.781 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:12:12.668: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-88
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-88/configmap-test-98c58c09-a74d-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume configMaps
Jul 15 22:12:12.921: INFO: Waiting up to 5m0s for pod "pod-configmaps-98c707e6-a74d-11e9-983d-d6ce37abd03c" in namespace "configmap-88" to be "success or failure"
Jul 15 22:12:12.939: INFO: Pod "pod-configmaps-98c707e6-a74d-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.969108ms
Jul 15 22:12:14.949: INFO: Pod "pod-configmaps-98c707e6-a74d-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027853441s
Jul 15 22:12:16.966: INFO: Pod "pod-configmaps-98c707e6-a74d-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044207125s
STEP: Saw pod success
Jul 15 22:12:16.966: INFO: Pod "pod-configmaps-98c707e6-a74d-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:12:16.976: INFO: Trying to get logs from node 10.190.211.93 pod pod-configmaps-98c707e6-a74d-11e9-983d-d6ce37abd03c container env-test: <nil>
STEP: delete the pod
Jul 15 22:12:17.040: INFO: Waiting for pod pod-configmaps-98c707e6-a74d-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:12:17.061: INFO: Pod pod-configmaps-98c707e6-a74d-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:12:17.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-88" for this suite.
Jul 15 22:12:23.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:12:23.474: INFO: namespace configmap-88 deletion completed in 6.387950685s

• [SLOW TEST:10.806 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:12:23.474: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4192
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-9f3431dd-a74d-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume configMaps
Jul 15 22:12:23.718: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9f35a554-a74d-11e9-983d-d6ce37abd03c" in namespace "projected-4192" to be "success or failure"
Jul 15 22:12:23.736: INFO: Pod "pod-projected-configmaps-9f35a554-a74d-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.548974ms
Jul 15 22:12:25.755: INFO: Pod "pod-projected-configmaps-9f35a554-a74d-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036520009s
STEP: Saw pod success
Jul 15 22:12:25.755: INFO: Pod "pod-projected-configmaps-9f35a554-a74d-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:12:25.764: INFO: Trying to get logs from node 10.190.211.93 pod pod-projected-configmaps-9f35a554-a74d-11e9-983d-d6ce37abd03c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 22:12:25.815: INFO: Waiting for pod pod-projected-configmaps-9f35a554-a74d-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:12:25.824: INFO: Pod pod-projected-configmaps-9f35a554-a74d-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:12:25.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4192" for this suite.
Jul 15 22:12:31.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:12:32.227: INFO: namespace projected-4192 deletion completed in 6.390548689s

• [SLOW TEST:8.753 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:12:32.227: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3397
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-a46c4971-a74d-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume secrets
Jul 15 22:12:32.476: INFO: Waiting up to 5m0s for pod "pod-secrets-a46e2cd9-a74d-11e9-983d-d6ce37abd03c" in namespace "secrets-3397" to be "success or failure"
Jul 15 22:12:32.493: INFO: Pod "pod-secrets-a46e2cd9-a74d-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.463265ms
Jul 15 22:12:34.504: INFO: Pod "pod-secrets-a46e2cd9-a74d-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028305171s
STEP: Saw pod success
Jul 15 22:12:34.504: INFO: Pod "pod-secrets-a46e2cd9-a74d-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:12:34.513: INFO: Trying to get logs from node 10.190.211.93 pod pod-secrets-a46e2cd9-a74d-11e9-983d-d6ce37abd03c container secret-volume-test: <nil>
STEP: delete the pod
Jul 15 22:12:34.580: INFO: Waiting for pod pod-secrets-a46e2cd9-a74d-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:12:34.589: INFO: Pod pod-secrets-a46e2cd9-a74d-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:12:34.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3397" for this suite.
Jul 15 22:12:40.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:12:41.086: INFO: namespace secrets-3397 deletion completed in 6.484844223s

• [SLOW TEST:8.859 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:12:41.086: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7560
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 22:12:41.341: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a9b71cd3-a74d-11e9-983d-d6ce37abd03c" in namespace "downward-api-7560" to be "success or failure"
Jul 15 22:12:41.357: INFO: Pod "downwardapi-volume-a9b71cd3-a74d-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.505605ms
Jul 15 22:12:43.374: INFO: Pod "downwardapi-volume-a9b71cd3-a74d-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033159277s
STEP: Saw pod success
Jul 15 22:12:43.374: INFO: Pod "downwardapi-volume-a9b71cd3-a74d-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:12:43.385: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-a9b71cd3-a74d-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 22:12:43.444: INFO: Waiting for pod downwardapi-volume-a9b71cd3-a74d-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:12:43.457: INFO: Pod downwardapi-volume-a9b71cd3-a74d-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:12:43.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7560" for this suite.
Jul 15 22:12:49.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:12:49.817: INFO: namespace downward-api-7560 deletion completed in 6.347174466s

• [SLOW TEST:8.731 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:12:49.818: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5537
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0715 22:12:51.142130      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 15 22:12:51.142: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:12:51.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5537" for this suite.
Jul 15 22:12:57.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:12:57.537: INFO: namespace gc-5537 deletion completed in 6.383809854s

• [SLOW TEST:7.719 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:12:57.537: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-6360
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jul 15 22:13:00.858: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:13:00.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6360" for this suite.
Jul 15 22:13:24.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:13:25.312: INFO: namespace replicaset-6360 deletion completed in 24.385190888s

• [SLOW TEST:27.775 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:13:25.312: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5977
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-c411cde4-a74d-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume secrets
Jul 15 22:13:25.566: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c4138529-a74d-11e9-983d-d6ce37abd03c" in namespace "projected-5977" to be "success or failure"
Jul 15 22:13:25.575: INFO: Pod "pod-projected-secrets-c4138529-a74d-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.300779ms
Jul 15 22:13:27.585: INFO: Pod "pod-projected-secrets-c4138529-a74d-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019091836s
STEP: Saw pod success
Jul 15 22:13:27.585: INFO: Pod "pod-projected-secrets-c4138529-a74d-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:13:27.605: INFO: Trying to get logs from node 10.190.211.93 pod pod-projected-secrets-c4138529-a74d-11e9-983d-d6ce37abd03c container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 15 22:13:27.658: INFO: Waiting for pod pod-projected-secrets-c4138529-a74d-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:13:27.668: INFO: Pod pod-projected-secrets-c4138529-a74d-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:13:27.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5977" for this suite.
Jul 15 22:13:33.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:13:34.042: INFO: namespace projected-5977 deletion completed in 6.357865406s

• [SLOW TEST:8.730 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:13:34.043: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9301
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Jul 15 22:13:34.281: INFO: Waiting up to 5m0s for pod "pod-c945c5b7-a74d-11e9-983d-d6ce37abd03c" in namespace "emptydir-9301" to be "success or failure"
Jul 15 22:13:34.295: INFO: Pod "pod-c945c5b7-a74d-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.314197ms
Jul 15 22:13:36.306: INFO: Pod "pod-c945c5b7-a74d-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024636773s
Jul 15 22:13:38.317: INFO: Pod "pod-c945c5b7-a74d-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035827087s
STEP: Saw pod success
Jul 15 22:13:38.317: INFO: Pod "pod-c945c5b7-a74d-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:13:38.328: INFO: Trying to get logs from node 10.190.211.93 pod pod-c945c5b7-a74d-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 22:13:38.455: INFO: Waiting for pod pod-c945c5b7-a74d-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:13:38.469: INFO: Pod pod-c945c5b7-a74d-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:13:38.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9301" for this suite.
Jul 15 22:13:44.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:13:44.858: INFO: namespace emptydir-9301 deletion completed in 6.374326183s

• [SLOW TEST:10.816 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:13:44.859: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8177
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 22:13:45.118: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cfbb30c5-a74d-11e9-983d-d6ce37abd03c" in namespace "downward-api-8177" to be "success or failure"
Jul 15 22:13:45.131: INFO: Pod "downwardapi-volume-cfbb30c5-a74d-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.120257ms
Jul 15 22:13:47.141: INFO: Pod "downwardapi-volume-cfbb30c5-a74d-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022920644s
Jul 15 22:13:49.152: INFO: Pod "downwardapi-volume-cfbb30c5-a74d-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033764236s
STEP: Saw pod success
Jul 15 22:13:49.152: INFO: Pod "downwardapi-volume-cfbb30c5-a74d-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:13:49.163: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-cfbb30c5-a74d-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 22:13:49.226: INFO: Waiting for pod downwardapi-volume-cfbb30c5-a74d-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:13:49.239: INFO: Pod downwardapi-volume-cfbb30c5-a74d-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:13:49.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8177" for this suite.
Jul 15 22:13:55.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:13:55.652: INFO: namespace downward-api-8177 deletion completed in 6.395432971s

• [SLOW TEST:10.793 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:13:55.652: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9934
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 22:13:55.897: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d627e63a-a74d-11e9-983d-d6ce37abd03c" in namespace "downward-api-9934" to be "success or failure"
Jul 15 22:13:55.906: INFO: Pod "downwardapi-volume-d627e63a-a74d-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.323589ms
Jul 15 22:13:57.918: INFO: Pod "downwardapi-volume-d627e63a-a74d-11e9-983d-d6ce37abd03c": Phase="Running", Reason="", readiness=true. Elapsed: 2.021212281s
Jul 15 22:13:59.929: INFO: Pod "downwardapi-volume-d627e63a-a74d-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032079385s
STEP: Saw pod success
Jul 15 22:13:59.929: INFO: Pod "downwardapi-volume-d627e63a-a74d-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:13:59.940: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-d627e63a-a74d-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 22:13:59.998: INFO: Waiting for pod downwardapi-volume-d627e63a-a74d-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:14:00.019: INFO: Pod downwardapi-volume-d627e63a-a74d-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:14:00.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9934" for this suite.
Jul 15 22:14:06.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:14:06.464: INFO: namespace downward-api-9934 deletion completed in 6.430678778s

• [SLOW TEST:10.811 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:14:06.466: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5320
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-5320/secret-test-dc9b3f11-a74d-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume secrets
Jul 15 22:14:06.731: INFO: Waiting up to 5m0s for pod "pod-configmaps-dc9d156e-a74d-11e9-983d-d6ce37abd03c" in namespace "secrets-5320" to be "success or failure"
Jul 15 22:14:06.747: INFO: Pod "pod-configmaps-dc9d156e-a74d-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.03758ms
Jul 15 22:14:08.757: INFO: Pod "pod-configmaps-dc9d156e-a74d-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025976107s
STEP: Saw pod success
Jul 15 22:14:08.757: INFO: Pod "pod-configmaps-dc9d156e-a74d-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:14:08.767: INFO: Trying to get logs from node 10.190.211.93 pod pod-configmaps-dc9d156e-a74d-11e9-983d-d6ce37abd03c container env-test: <nil>
STEP: delete the pod
Jul 15 22:14:08.820: INFO: Waiting for pod pod-configmaps-dc9d156e-a74d-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:14:08.830: INFO: Pod pod-configmaps-dc9d156e-a74d-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:14:08.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5320" for this suite.
Jul 15 22:14:14.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:14:15.228: INFO: namespace secrets-5320 deletion completed in 6.385535261s

• [SLOW TEST:8.763 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:14:15.228: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-547
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jul 15 22:14:16.014: INFO: Pod name wrapped-volume-race-e221fc40-a74d-11e9-983d-d6ce37abd03c: Found 0 pods out of 5
Jul 15 22:14:21.030: INFO: Pod name wrapped-volume-race-e221fc40-a74d-11e9-983d-d6ce37abd03c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e221fc40-a74d-11e9-983d-d6ce37abd03c in namespace emptydir-wrapper-547, will wait for the garbage collector to delete the pods
Jul 15 22:14:21.197: INFO: Deleting ReplicationController wrapped-volume-race-e221fc40-a74d-11e9-983d-d6ce37abd03c took: 27.37779ms
Jul 15 22:14:21.398: INFO: Terminating ReplicationController wrapped-volume-race-e221fc40-a74d-11e9-983d-d6ce37abd03c pods took: 200.374476ms
STEP: Creating RC which spawns configmap-volume pods
Jul 15 22:14:59.151: INFO: Pod name wrapped-volume-race-fbd6bc15-a74d-11e9-983d-d6ce37abd03c: Found 0 pods out of 5
Jul 15 22:15:04.182: INFO: Pod name wrapped-volume-race-fbd6bc15-a74d-11e9-983d-d6ce37abd03c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-fbd6bc15-a74d-11e9-983d-d6ce37abd03c in namespace emptydir-wrapper-547, will wait for the garbage collector to delete the pods
Jul 15 22:15:04.335: INFO: Deleting ReplicationController wrapped-volume-race-fbd6bc15-a74d-11e9-983d-d6ce37abd03c took: 27.98325ms
Jul 15 22:15:04.736: INFO: Terminating ReplicationController wrapped-volume-race-fbd6bc15-a74d-11e9-983d-d6ce37abd03c pods took: 400.608353ms
STEP: Creating RC which spawns configmap-volume pods
Jul 15 22:15:39.083: INFO: Pod name wrapped-volume-race-13a4cc73-a74e-11e9-983d-d6ce37abd03c: Found 0 pods out of 5
Jul 15 22:15:44.100: INFO: Pod name wrapped-volume-race-13a4cc73-a74e-11e9-983d-d6ce37abd03c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-13a4cc73-a74e-11e9-983d-d6ce37abd03c in namespace emptydir-wrapper-547, will wait for the garbage collector to delete the pods
Jul 15 22:15:44.261: INFO: Deleting ReplicationController wrapped-volume-race-13a4cc73-a74e-11e9-983d-d6ce37abd03c took: 25.764617ms
Jul 15 22:15:44.461: INFO: Terminating ReplicationController wrapped-volume-race-13a4cc73-a74e-11e9-983d-d6ce37abd03c pods took: 200.246794ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:16:29.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-547" for this suite.
Jul 15 22:16:37.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:16:38.147: INFO: namespace emptydir-wrapper-547 deletion completed in 8.431046149s

• [SLOW TEST:142.919 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:16:38.147: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-9382
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-9382
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-9382
STEP: Deleting pre-stop pod
Jul 15 22:16:51.505: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:16:51.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9382" for this suite.
Jul 15 22:17:31.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:17:31.931: INFO: namespace prestop-9382 deletion completed in 40.383932051s

• [SLOW TEST:53.784 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:17:31.931: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6087
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 22:17:52.228: INFO: Container started at 2019-07-15 22:17:33 +0000 UTC, pod became ready at 2019-07-15 22:17:52 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:17:52.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6087" for this suite.
Jul 15 22:18:16.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:18:16.648: INFO: namespace container-probe-6087 deletion completed in 24.406224605s

• [SLOW TEST:44.716 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:18:16.648: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5867
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-p72g
STEP: Creating a pod to test atomic-volume-subpath
Jul 15 22:18:16.923: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-p72g" in namespace "subpath-5867" to be "success or failure"
Jul 15 22:18:16.940: INFO: Pod "pod-subpath-test-secret-p72g": Phase="Pending", Reason="", readiness=false. Elapsed: 17.114076ms
Jul 15 22:18:18.951: INFO: Pod "pod-subpath-test-secret-p72g": Phase="Running", Reason="", readiness=true. Elapsed: 2.027900472s
Jul 15 22:18:20.963: INFO: Pod "pod-subpath-test-secret-p72g": Phase="Running", Reason="", readiness=true. Elapsed: 4.040581654s
Jul 15 22:18:22.978: INFO: Pod "pod-subpath-test-secret-p72g": Phase="Running", Reason="", readiness=true. Elapsed: 6.055619047s
Jul 15 22:18:24.990: INFO: Pod "pod-subpath-test-secret-p72g": Phase="Running", Reason="", readiness=true. Elapsed: 8.067452439s
Jul 15 22:18:27.002: INFO: Pod "pod-subpath-test-secret-p72g": Phase="Running", Reason="", readiness=true. Elapsed: 10.079120412s
Jul 15 22:18:29.016: INFO: Pod "pod-subpath-test-secret-p72g": Phase="Running", Reason="", readiness=true. Elapsed: 12.093092117s
Jul 15 22:18:31.029: INFO: Pod "pod-subpath-test-secret-p72g": Phase="Running", Reason="", readiness=true. Elapsed: 14.106695805s
Jul 15 22:18:33.039: INFO: Pod "pod-subpath-test-secret-p72g": Phase="Running", Reason="", readiness=true. Elapsed: 16.115949445s
Jul 15 22:18:35.054: INFO: Pod "pod-subpath-test-secret-p72g": Phase="Running", Reason="", readiness=true. Elapsed: 18.13093895s
Jul 15 22:18:37.063: INFO: Pod "pod-subpath-test-secret-p72g": Phase="Running", Reason="", readiness=true. Elapsed: 20.140622183s
Jul 15 22:18:39.076: INFO: Pod "pod-subpath-test-secret-p72g": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.153218503s
STEP: Saw pod success
Jul 15 22:18:39.076: INFO: Pod "pod-subpath-test-secret-p72g" satisfied condition "success or failure"
Jul 15 22:18:39.088: INFO: Trying to get logs from node 10.190.211.93 pod pod-subpath-test-secret-p72g container test-container-subpath-secret-p72g: <nil>
STEP: delete the pod
Jul 15 22:18:39.165: INFO: Waiting for pod pod-subpath-test-secret-p72g to disappear
Jul 15 22:18:39.175: INFO: Pod pod-subpath-test-secret-p72g no longer exists
STEP: Deleting pod pod-subpath-test-secret-p72g
Jul 15 22:18:39.175: INFO: Deleting pod "pod-subpath-test-secret-p72g" in namespace "subpath-5867"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:18:39.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5867" for this suite.
Jul 15 22:18:47.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:18:47.640: INFO: namespace subpath-5867 deletion completed in 8.437216308s

• [SLOW TEST:30.992 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:18:47.641: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5596
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 22:18:47.857: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:18:50.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5596" for this suite.
Jul 15 22:19:34.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:19:34.783: INFO: namespace pods-5596 deletion completed in 44.573020547s

• [SLOW TEST:47.143 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:19:34.783: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1232
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-a04e5177-a74e-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume configMaps
Jul 15 22:19:35.059: INFO: Waiting up to 5m0s for pod "pod-configmaps-a04fa055-a74e-11e9-983d-d6ce37abd03c" in namespace "configmap-1232" to be "success or failure"
Jul 15 22:19:35.081: INFO: Pod "pod-configmaps-a04fa055-a74e-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 21.219467ms
Jul 15 22:19:37.093: INFO: Pod "pod-configmaps-a04fa055-a74e-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033376324s
STEP: Saw pod success
Jul 15 22:19:37.093: INFO: Pod "pod-configmaps-a04fa055-a74e-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:19:37.108: INFO: Trying to get logs from node 10.190.211.93 pod pod-configmaps-a04fa055-a74e-11e9-983d-d6ce37abd03c container configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 22:19:37.186: INFO: Waiting for pod pod-configmaps-a04fa055-a74e-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:19:37.195: INFO: Pod pod-configmaps-a04fa055-a74e-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:19:37.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1232" for this suite.
Jul 15 22:19:43.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:19:43.600: INFO: namespace configmap-1232 deletion completed in 6.391967439s

• [SLOW TEST:8.817 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:19:43.600: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9970
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Jul 15 22:19:43.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 cluster-info'
Jul 15 22:19:44.013: INFO: stderr: ""
Jul 15 22:19:44.013: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:19:44.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9970" for this suite.
Jul 15 22:19:50.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:19:50.429: INFO: namespace kubectl-9970 deletion completed in 6.404306569s

• [SLOW TEST:6.829 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:19:50.431: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9022
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Jul 15 22:19:50.687: INFO: Waiting up to 5m0s for pod "pod-a9a054cb-a74e-11e9-983d-d6ce37abd03c" in namespace "emptydir-9022" to be "success or failure"
Jul 15 22:19:50.702: INFO: Pod "pod-a9a054cb-a74e-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.696833ms
Jul 15 22:19:52.714: INFO: Pod "pod-a9a054cb-a74e-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026851535s
Jul 15 22:19:54.725: INFO: Pod "pod-a9a054cb-a74e-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038166143s
STEP: Saw pod success
Jul 15 22:19:54.725: INFO: Pod "pod-a9a054cb-a74e-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:19:54.734: INFO: Trying to get logs from node 10.190.211.93 pod pod-a9a054cb-a74e-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 22:19:54.795: INFO: Waiting for pod pod-a9a054cb-a74e-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:19:54.804: INFO: Pod pod-a9a054cb-a74e-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:19:54.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9022" for this suite.
Jul 15 22:20:00.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:20:01.319: INFO: namespace emptydir-9022 deletion completed in 6.491345943s

• [SLOW TEST:10.888 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:20:01.320: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6901
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1483
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 15 22:20:01.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-6901'
Jul 15 22:20:01.708: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 15 22:20:01.708: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Jul 15 22:20:01.728: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Jul 15 22:20:01.738: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Jul 15 22:20:01.776: INFO: scanned /root for discovery docs: <nil>
Jul 15 22:20:01.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-6901'
Jul 15 22:20:17.776: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jul 15 22:20:17.776: INFO: stdout: "Created e2e-test-nginx-rc-ca72d5e408e1599a3ac432cafa2bfc03\nScaling up e2e-test-nginx-rc-ca72d5e408e1599a3ac432cafa2bfc03 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-ca72d5e408e1599a3ac432cafa2bfc03 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-ca72d5e408e1599a3ac432cafa2bfc03 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jul 15 22:20:17.776: INFO: stdout: "Created e2e-test-nginx-rc-ca72d5e408e1599a3ac432cafa2bfc03\nScaling up e2e-test-nginx-rc-ca72d5e408e1599a3ac432cafa2bfc03 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-ca72d5e408e1599a3ac432cafa2bfc03 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-ca72d5e408e1599a3ac432cafa2bfc03 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jul 15 22:20:17.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-6901'
Jul 15 22:20:17.898: INFO: stderr: ""
Jul 15 22:20:17.898: INFO: stdout: "e2e-test-nginx-rc-ca72d5e408e1599a3ac432cafa2bfc03-psfwm "
Jul 15 22:20:17.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods e2e-test-nginx-rc-ca72d5e408e1599a3ac432cafa2bfc03-psfwm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6901'
Jul 15 22:20:18.020: INFO: stderr: ""
Jul 15 22:20:18.020: INFO: stdout: "true"
Jul 15 22:20:18.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods e2e-test-nginx-rc-ca72d5e408e1599a3ac432cafa2bfc03-psfwm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6901'
Jul 15 22:20:18.155: INFO: stderr: ""
Jul 15 22:20:18.155: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Jul 15 22:20:18.155: INFO: e2e-test-nginx-rc-ca72d5e408e1599a3ac432cafa2bfc03-psfwm is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1489
Jul 15 22:20:18.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 delete rc e2e-test-nginx-rc --namespace=kubectl-6901'
Jul 15 22:20:18.305: INFO: stderr: ""
Jul 15 22:20:18.305: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:20:18.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6901" for this suite.
Jul 15 22:20:24.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:20:24.787: INFO: namespace kubectl-6901 deletion completed in 6.464843281s

• [SLOW TEST:23.467 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:20:24.787: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1824
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1824
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Jul 15 22:20:25.056: INFO: Found 0 stateful pods, waiting for 3
Jul 15 22:20:35.069: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 22:20:35.069: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 22:20:35.070: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 22:20:35.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-1824 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 22:20:35.605: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 15 22:20:35.605: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 22:20:35.605: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jul 15 22:20:45.697: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jul 15 22:20:55.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-1824 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:20:56.211: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 15 22:20:56.211: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 22:20:56.211: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 15 22:20:56.253: INFO: Waiting for StatefulSet statefulset-1824/ss2 to complete update
Jul 15 22:20:56.253: INFO: Waiting for Pod statefulset-1824/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jul 15 22:20:56.253: INFO: Waiting for Pod statefulset-1824/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jul 15 22:20:56.253: INFO: Waiting for Pod statefulset-1824/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jul 15 22:21:06.274: INFO: Waiting for StatefulSet statefulset-1824/ss2 to complete update
Jul 15 22:21:06.274: INFO: Waiting for Pod statefulset-1824/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Jul 15 22:21:16.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-1824 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 22:21:16.705: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 15 22:21:16.705: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 22:21:16.705: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 22:21:26.782: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jul 15 22:21:36.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-1824 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:21:37.247: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 15 22:21:37.247: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 22:21:37.247: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 15 22:21:47.316: INFO: Waiting for StatefulSet statefulset-1824/ss2 to complete update
Jul 15 22:21:47.316: INFO: Waiting for Pod statefulset-1824/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Jul 15 22:21:47.316: INFO: Waiting for Pod statefulset-1824/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Jul 15 22:21:47.316: INFO: Waiting for Pod statefulset-1824/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Jul 15 22:21:57.338: INFO: Waiting for StatefulSet statefulset-1824/ss2 to complete update
Jul 15 22:21:57.338: INFO: Waiting for Pod statefulset-1824/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Jul 15 22:21:57.338: INFO: Waiting for Pod statefulset-1824/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 15 22:22:07.340: INFO: Deleting all statefulset in ns statefulset-1824
Jul 15 22:22:07.350: INFO: Scaling statefulset ss2 to 0
Jul 15 22:22:17.398: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 22:22:17.411: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:22:17.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1824" for this suite.
Jul 15 22:22:25.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:22:25.846: INFO: namespace statefulset-1824 deletion completed in 8.373477377s

• [SLOW TEST:121.059 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:22:25.847: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8931
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 22:22:26.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 version'
Jul 15 22:22:26.182: INFO: stderr: ""
Jul 15 22:22:26.182: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.4\", GitCommit:\"a87e9a978f65a8303aa9467537aa59c18122cbf9\", GitTreeState:\"clean\", BuildDate:\"2019-07-08T08:51:16Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.4+IKS\", GitCommit:\"8d1fc7dac0503d725342e28fdfd0f3710b58ccde\", GitTreeState:\"clean\", BuildDate:\"2019-07-11T13:18:41Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:22:26.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8931" for this suite.
Jul 15 22:22:32.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:22:32.909: INFO: namespace kubectl-8931 deletion completed in 6.715324261s

• [SLOW TEST:7.062 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:22:32.910: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8601
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 22:22:33.181: INFO: (0) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 19.467731ms)
Jul 15 22:22:33.194: INFO: (1) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 13.224163ms)
Jul 15 22:22:33.218: INFO: (2) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.945533ms)
Jul 15 22:22:33.239: INFO: (3) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.97535ms)
Jul 15 22:22:33.255: INFO: (4) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.526055ms)
Jul 15 22:22:33.271: INFO: (5) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.083752ms)
Jul 15 22:22:33.287: INFO: (6) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.220703ms)
Jul 15 22:22:33.302: INFO: (7) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.320498ms)
Jul 15 22:22:33.316: INFO: (8) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 13.806263ms)
Jul 15 22:22:33.332: INFO: (9) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.089791ms)
Jul 15 22:22:33.347: INFO: (10) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.181669ms)
Jul 15 22:22:33.361: INFO: (11) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.131706ms)
Jul 15 22:22:33.376: INFO: (12) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.201192ms)
Jul 15 22:22:33.391: INFO: (13) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.934167ms)
Jul 15 22:22:33.409: INFO: (14) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.756919ms)
Jul 15 22:22:33.422: INFO: (15) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 13.389661ms)
Jul 15 22:22:33.441: INFO: (16) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 18.875359ms)
Jul 15 22:22:33.456: INFO: (17) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.63466ms)
Jul 15 22:22:33.471: INFO: (18) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.073789ms)
Jul 15 22:22:33.490: INFO: (19) /api/v1/nodes/10.190.211.91:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 18.919596ms)
[AfterEach] version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:22:33.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8601" for this suite.
Jul 15 22:22:39.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:22:39.982: INFO: namespace proxy-8601 deletion completed in 6.482276186s

• [SLOW TEST:7.072 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:22:39.983: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8795
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jul 15 22:22:40.230: INFO: Pod name pod-release: Found 0 pods out of 1
Jul 15 22:22:45.240: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:22:45.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8795" for this suite.
Jul 15 22:22:51.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:22:51.702: INFO: namespace replication-controller-8795 deletion completed in 6.405620679s

• [SLOW TEST:11.720 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:22:51.703: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7960
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 22:22:52.256: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jul 15 22:22:57.266: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul 15 22:22:57.266: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jul 15 22:22:59.280: INFO: Creating deployment "test-rollover-deployment"
Jul 15 22:22:59.297: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jul 15 22:23:01.315: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jul 15 22:23:01.334: INFO: Ensure that both replica sets have 1 created replica
Jul 15 22:23:01.360: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jul 15 22:23:01.382: INFO: Updating deployment test-rollover-deployment
Jul 15 22:23:01.382: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jul 15 22:23:03.400: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jul 15 22:23:03.420: INFO: Make sure deployment "test-rollover-deployment" is complete
Jul 15 22:23:03.447: INFO: all replica sets need to contain the pod-template-hash label
Jul 15 22:23:03.447: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826179, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826179, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826183, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826179, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 15 22:23:05.471: INFO: all replica sets need to contain the pod-template-hash label
Jul 15 22:23:05.471: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826179, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826179, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826183, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826179, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 15 22:23:07.468: INFO: all replica sets need to contain the pod-template-hash label
Jul 15 22:23:07.468: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826179, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826179, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826183, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826179, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 15 22:23:09.468: INFO: all replica sets need to contain the pod-template-hash label
Jul 15 22:23:09.468: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826179, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826179, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826183, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826179, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 15 22:23:11.468: INFO: all replica sets need to contain the pod-template-hash label
Jul 15 22:23:11.468: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826179, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826179, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826183, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826179, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 15 22:23:13.469: INFO: 
Jul 15 22:23:13.469: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 15 22:23:13.501: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-7960,SelfLink:/apis/apps/v1/namespaces/deployment-7960/deployments/test-rollover-deployment,UID:1a0c2cdb-a74f-11e9-a496-5e4367ce3703,ResourceVersion:16262,Generation:2,CreationTimestamp:2019-07-15 22:22:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-07-15 22:22:59 +0000 UTC 2019-07-15 22:22:59 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-07-15 22:23:13 +0000 UTC 2019-07-15 22:22:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-659c699649" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jul 15 22:23:13.512: INFO: New ReplicaSet "test-rollover-deployment-659c699649" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649,GenerateName:,Namespace:deployment-7960,SelfLink:/apis/apps/v1/namespaces/deployment-7960/replicasets/test-rollover-deployment-659c699649,UID:1b4ca2ee-a74f-11e9-a496-5e4367ce3703,ResourceVersion:16252,Generation:2,CreationTimestamp:2019-07-15 22:23:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 1a0c2cdb-a74f-11e9-a496-5e4367ce3703 0xc002ce85e7 0xc002ce85e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul 15 22:23:13.512: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jul 15 22:23:13.512: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-7960,SelfLink:/apis/apps/v1/namespaces/deployment-7960/replicasets/test-rollover-controller,UID:15d918bc-a74f-11e9-a496-5e4367ce3703,ResourceVersion:16261,Generation:2,CreationTimestamp:2019-07-15 22:22:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 1a0c2cdb-a74f-11e9-a496-5e4367ce3703 0xc002ce8517 0xc002ce8518}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 15 22:23:13.512: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-7b45b6464,GenerateName:,Namespace:deployment-7960,SelfLink:/apis/apps/v1/namespaces/deployment-7960/replicasets/test-rollover-deployment-7b45b6464,UID:1a115647-a74f-11e9-a496-5e4367ce3703,ResourceVersion:16218,Generation:2,CreationTimestamp:2019-07-15 22:22:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 1a0c2cdb-a74f-11e9-a496-5e4367ce3703 0xc002ce86b0 0xc002ce86b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 15 22:23:13.524: INFO: Pod "test-rollover-deployment-659c699649-ttj4m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649-ttj4m,GenerateName:test-rollover-deployment-659c699649-,Namespace:deployment-7960,SelfLink:/api/v1/namespaces/deployment-7960/pods/test-rollover-deployment-659c699649-ttj4m,UID:1b573814-a74f-11e9-a496-5e4367ce3703,ResourceVersion:16233,Generation:0,CreationTimestamp:2019-07-15 22:23:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-659c699649 1b4ca2ee-a74f-11e9-a496-5e4367ce3703 0xc002ce9277 0xc002ce9278}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-954dt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-954dt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-954dt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002ce92f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002ce9320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:23:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:23:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:23:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:23:01 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.93,PodIP:172.30.19.7,StartTime:2019-07-15 22:23:01 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-07-15 22:23:02 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://3eff2d738f1bf01f3237a8df85323fe5e7194c4d72a8b86549cc179d5cc23039}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:23:13.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7960" for this suite.
Jul 15 22:23:21.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:23:21.959: INFO: namespace deployment-7960 deletion completed in 8.420426879s

• [SLOW TEST:30.257 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:23:21.961: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1216
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-27b2d6d3-a74f-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume secrets
Jul 15 22:23:22.214: INFO: Waiting up to 5m0s for pod "pod-secrets-27b4c44c-a74f-11e9-983d-d6ce37abd03c" in namespace "secrets-1216" to be "success or failure"
Jul 15 22:23:22.227: INFO: Pod "pod-secrets-27b4c44c-a74f-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.309424ms
Jul 15 22:23:24.238: INFO: Pod "pod-secrets-27b4c44c-a74f-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024698354s
Jul 15 22:23:26.250: INFO: Pod "pod-secrets-27b4c44c-a74f-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036372188s
STEP: Saw pod success
Jul 15 22:23:26.250: INFO: Pod "pod-secrets-27b4c44c-a74f-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:23:26.262: INFO: Trying to get logs from node 10.190.211.93 pod pod-secrets-27b4c44c-a74f-11e9-983d-d6ce37abd03c container secret-volume-test: <nil>
STEP: delete the pod
Jul 15 22:23:26.362: INFO: Waiting for pod pod-secrets-27b4c44c-a74f-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:23:26.372: INFO: Pod pod-secrets-27b4c44c-a74f-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:23:26.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1216" for this suite.
Jul 15 22:23:32.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:23:32.919: INFO: namespace secrets-1216 deletion completed in 6.513563878s

• [SLOW TEST:10.958 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:23:32.921: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3294
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-3294
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 15 22:23:33.138: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 15 22:23:59.728: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.19.10:8080/dial?request=hostName&protocol=http&host=172.30.19.9&port=8080&tries=1'] Namespace:pod-network-test-3294 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 22:23:59.728: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 22:24:00.029: INFO: Waiting for endpoints: map[]
Jul 15 22:24:00.040: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.19.10:8080/dial?request=hostName&protocol=http&host=172.30.176.139&port=8080&tries=1'] Namespace:pod-network-test-3294 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 22:24:00.040: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 22:24:00.388: INFO: Waiting for endpoints: map[]
Jul 15 22:24:00.398: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.19.10:8080/dial?request=hostName&protocol=http&host=172.30.43.220&port=8080&tries=1'] Namespace:pod-network-test-3294 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 22:24:00.398: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 22:24:00.703: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:24:00.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3294" for this suite.
Jul 15 22:24:24.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:24:25.627: INFO: namespace pod-network-test-3294 deletion completed in 24.910566906s

• [SLOW TEST:52.707 seconds]
[sig-network] Networking
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:24:25.629: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1699
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 22:24:26.009: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4da4e90f-a74f-11e9-983d-d6ce37abd03c" in namespace "downward-api-1699" to be "success or failure"
Jul 15 22:24:26.022: INFO: Pod "downwardapi-volume-4da4e90f-a74f-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.832035ms
Jul 15 22:24:28.034: INFO: Pod "downwardapi-volume-4da4e90f-a74f-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025257257s
STEP: Saw pod success
Jul 15 22:24:28.034: INFO: Pod "downwardapi-volume-4da4e90f-a74f-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:24:28.045: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-4da4e90f-a74f-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 22:24:28.106: INFO: Waiting for pod downwardapi-volume-4da4e90f-a74f-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:24:28.116: INFO: Pod downwardapi-volume-4da4e90f-a74f-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:24:28.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1699" for this suite.
Jul 15 22:24:34.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:24:34.518: INFO: namespace downward-api-1699 deletion completed in 6.384900525s

• [SLOW TEST:8.889 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:24:34.518: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9645
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1177
STEP: creating the pod
Jul 15 22:24:34.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 create -f - --namespace=kubectl-9645'
Jul 15 22:24:35.116: INFO: stderr: ""
Jul 15 22:24:35.116: INFO: stdout: "pod/pause created\n"
Jul 15 22:24:35.116: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jul 15 22:24:35.116: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9645" to be "running and ready"
Jul 15 22:24:35.132: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 15.822695ms
Jul 15 22:24:37.144: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.028237667s
Jul 15 22:24:37.144: INFO: Pod "pause" satisfied condition "running and ready"
Jul 15 22:24:37.144: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Jul 15 22:24:37.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 label pods pause testing-label=testing-label-value --namespace=kubectl-9645'
Jul 15 22:24:37.290: INFO: stderr: ""
Jul 15 22:24:37.290: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jul 15 22:24:37.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pod pause -L testing-label --namespace=kubectl-9645'
Jul 15 22:24:37.404: INFO: stderr: ""
Jul 15 22:24:37.404: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jul 15 22:24:37.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 label pods pause testing-label- --namespace=kubectl-9645'
Jul 15 22:24:37.553: INFO: stderr: ""
Jul 15 22:24:37.553: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jul 15 22:24:37.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pod pause -L testing-label --namespace=kubectl-9645'
Jul 15 22:24:37.676: INFO: stderr: ""
Jul 15 22:24:37.676: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1184
STEP: using delete to clean up resources
Jul 15 22:24:37.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 delete --grace-period=0 --force -f - --namespace=kubectl-9645'
Jul 15 22:24:37.807: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 22:24:37.807: INFO: stdout: "pod \"pause\" force deleted\n"
Jul 15 22:24:37.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get rc,svc -l name=pause --no-headers --namespace=kubectl-9645'
Jul 15 22:24:37.949: INFO: stderr: "No resources found.\n"
Jul 15 22:24:37.949: INFO: stdout: ""
Jul 15 22:24:37.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -l name=pause --namespace=kubectl-9645 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 15 22:24:38.089: INFO: stderr: ""
Jul 15 22:24:38.089: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:24:38.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9645" for this suite.
Jul 15 22:24:44.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:24:44.529: INFO: namespace kubectl-9645 deletion completed in 6.407515178s

• [SLOW TEST:10.011 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:24:44.530: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4501
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 22:24:44.848: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"58f11414-a74f-11e9-a496-5e4367ce3703", Controller:(*bool)(0xc002dac52a), BlockOwnerDeletion:(*bool)(0xc002dac52b)}}
Jul 15 22:24:44.863: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"58ecec34-a74f-11e9-a496-5e4367ce3703", Controller:(*bool)(0xc002dac736), BlockOwnerDeletion:(*bool)(0xc002dac737)}}
Jul 15 22:24:44.881: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"58eeb6d5-a74f-11e9-a496-5e4367ce3703", Controller:(*bool)(0xc0025d4ec6), BlockOwnerDeletion:(*bool)(0xc0025d4ec7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:24:49.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4501" for this suite.
Jul 15 22:24:55.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:24:56.551: INFO: namespace gc-4501 deletion completed in 6.605873789s

• [SLOW TEST:12.021 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:24:56.551: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5982
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-5982
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5982
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5982
Jul 15 22:24:56.799: INFO: Found 0 stateful pods, waiting for 1
Jul 15 22:25:06.812: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jul 15 22:25:06.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-5982 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 22:25:07.227: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 15 22:25:07.227: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 22:25:07.227: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 22:25:07.236: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 15 22:25:07.236: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 22:25:07.279: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998323s
Jul 15 22:25:08.297: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.990734351s
Jul 15 22:25:09.310: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.97250556s
Jul 15 22:25:10.321: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.959119423s
Jul 15 22:25:11.332: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.948501465s
Jul 15 22:25:12.345: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.937170486s
Jul 15 22:25:13.356: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.924649547s
Jul 15 22:25:14.369: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.913106321s
Jul 15 22:25:15.378: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.900709021s
Jul 15 22:25:16.390: INFO: Verifying statefulset ss doesn't scale past 1 for another 891.032231ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5982
Jul 15 22:25:17.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-5982 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:25:17.837: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 15 22:25:17.837: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 22:25:17.837: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 15 22:25:17.847: INFO: Found 1 stateful pods, waiting for 3
Jul 15 22:25:27.859: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 22:25:27.859: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 22:25:27.859: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jul 15 22:25:27.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-5982 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 22:25:28.294: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 15 22:25:28.294: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 22:25:28.294: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 22:25:28.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-5982 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 22:25:28.717: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 15 22:25:28.718: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 22:25:28.718: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 22:25:28.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-5982 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 22:25:29.087: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 15 22:25:29.087: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 22:25:29.087: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 22:25:29.087: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 22:25:29.096: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jul 15 22:25:39.124: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 15 22:25:39.124: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul 15 22:25:39.124: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul 15 22:25:39.165: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999855s
Jul 15 22:25:40.177: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.983563047s
Jul 15 22:25:41.205: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.971492325s
Jul 15 22:25:42.216: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.94374961s
Jul 15 22:25:43.227: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.932297283s
Jul 15 22:25:44.238: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.921739324s
Jul 15 22:25:45.248: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.910601449s
Jul 15 22:25:46.265: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.900670417s
Jul 15 22:25:47.276: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.883567302s
Jul 15 22:25:48.288: INFO: Verifying statefulset ss doesn't scale past 3 for another 872.746722ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5982
Jul 15 22:25:49.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-5982 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:25:49.706: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 15 22:25:49.706: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 22:25:49.706: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 15 22:25:49.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-5982 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:25:50.134: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 15 22:25:50.134: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 22:25:50.134: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 15 22:25:50.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-5982 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:25:50.555: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 15 22:25:50.555: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 22:25:50.555: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 15 22:25:50.555: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 15 22:26:10.607: INFO: Deleting all statefulset in ns statefulset-5982
Jul 15 22:26:10.624: INFO: Scaling statefulset ss to 0
Jul 15 22:26:10.659: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 22:26:10.669: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:26:10.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5982" for this suite.
Jul 15 22:26:18.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:26:19.103: INFO: namespace statefulset-5982 deletion completed in 8.37702587s

• [SLOW TEST:82.552 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:26:19.104: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1667
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jul 15 22:26:19.360: INFO: Waiting up to 5m0s for pod "pod-914b1496-a74f-11e9-983d-d6ce37abd03c" in namespace "emptydir-1667" to be "success or failure"
Jul 15 22:26:19.376: INFO: Pod "pod-914b1496-a74f-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 15.910933ms
Jul 15 22:26:21.386: INFO: Pod "pod-914b1496-a74f-11e9-983d-d6ce37abd03c": Phase="Running", Reason="", readiness=true. Elapsed: 2.026671703s
Jul 15 22:26:23.399: INFO: Pod "pod-914b1496-a74f-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039863849s
STEP: Saw pod success
Jul 15 22:26:23.400: INFO: Pod "pod-914b1496-a74f-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:26:23.414: INFO: Trying to get logs from node 10.190.211.93 pod pod-914b1496-a74f-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 22:26:23.478: INFO: Waiting for pod pod-914b1496-a74f-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:26:23.489: INFO: Pod pod-914b1496-a74f-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:26:23.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1667" for this suite.
Jul 15 22:26:29.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:26:29.899: INFO: namespace emptydir-1667 deletion completed in 6.382594763s

• [SLOW TEST:10.796 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:26:29.900: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1856
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Jul 15 22:26:32.196: INFO: Pod pod-hostip-97b7ce86-a74f-11e9-983d-d6ce37abd03c has hostIP: 10.190.211.93
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:26:32.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1856" for this suite.
Jul 15 22:26:56.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:26:56.621: INFO: namespace pods-1856 deletion completed in 24.411273507s

• [SLOW TEST:26.721 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:26:56.622: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8072
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-a7a48055-a74f-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume secrets
Jul 15 22:26:56.878: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a7a6d35a-a74f-11e9-983d-d6ce37abd03c" in namespace "projected-8072" to be "success or failure"
Jul 15 22:26:56.891: INFO: Pod "pod-projected-secrets-a7a6d35a-a74f-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.112749ms
Jul 15 22:26:58.903: INFO: Pod "pod-projected-secrets-a7a6d35a-a74f-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025487734s
STEP: Saw pod success
Jul 15 22:26:58.903: INFO: Pod "pod-projected-secrets-a7a6d35a-a74f-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:26:58.913: INFO: Trying to get logs from node 10.190.211.93 pod pod-projected-secrets-a7a6d35a-a74f-11e9-983d-d6ce37abd03c container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 15 22:26:58.969: INFO: Waiting for pod pod-projected-secrets-a7a6d35a-a74f-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:26:58.980: INFO: Pod pod-projected-secrets-a7a6d35a-a74f-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:26:58.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8072" for this suite.
Jul 15 22:27:05.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:27:05.387: INFO: namespace projected-8072 deletion completed in 6.389881824s

• [SLOW TEST:8.766 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:27:05.388: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5563
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0715 22:27:15.860657      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 15 22:27:15.860: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:27:15.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5563" for this suite.
Jul 15 22:27:23.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:27:24.241: INFO: namespace gc-5563 deletion completed in 8.369309711s

• [SLOW TEST:18.853 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:27:24.242: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-4091
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Jul 15 22:27:24.914: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Jul 15 22:27:27.222: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826444, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826444, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826444, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826444, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 15 22:27:29.337: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826444, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826444, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826444, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698826444, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 15 22:27:36.414: INFO: Waited 5.171593879s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:27:36.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4091" for this suite.
Jul 15 22:27:42.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:27:43.334: INFO: namespace aggregator-4091 deletion completed in 6.397540719s

• [SLOW TEST:19.092 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:27:43.334: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5556
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 22:27:43.593: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c38037cf-a74f-11e9-983d-d6ce37abd03c" in namespace "downward-api-5556" to be "success or failure"
Jul 15 22:27:43.614: INFO: Pod "downwardapi-volume-c38037cf-a74f-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 21.37546ms
Jul 15 22:27:45.625: INFO: Pod "downwardapi-volume-c38037cf-a74f-11e9-983d-d6ce37abd03c": Phase="Running", Reason="", readiness=true. Elapsed: 2.031914064s
Jul 15 22:27:47.637: INFO: Pod "downwardapi-volume-c38037cf-a74f-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044366351s
STEP: Saw pod success
Jul 15 22:27:47.638: INFO: Pod "downwardapi-volume-c38037cf-a74f-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:27:47.649: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-c38037cf-a74f-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 22:27:47.725: INFO: Waiting for pod downwardapi-volume-c38037cf-a74f-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:27:47.738: INFO: Pod downwardapi-volume-c38037cf-a74f-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:27:47.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5556" for this suite.
Jul 15 22:27:53.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:27:54.163: INFO: namespace downward-api-5556 deletion completed in 6.410377971s

• [SLOW TEST:10.830 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:27:54.164: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2520
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-c9f7fbc4-a74f-11e9-983d-d6ce37abd03c
STEP: Creating configMap with name cm-test-opt-upd-c9f7fc13-a74f-11e9-983d-d6ce37abd03c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-c9f7fbc4-a74f-11e9-983d-d6ce37abd03c
STEP: Updating configmap cm-test-opt-upd-c9f7fc13-a74f-11e9-983d-d6ce37abd03c
STEP: Creating configMap with name cm-test-opt-create-c9f7fc39-a74f-11e9-983d-d6ce37abd03c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:28:00.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2520" for this suite.
Jul 15 22:28:24.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:28:25.095: INFO: namespace configmap-2520 deletion completed in 24.364466718s

• [SLOW TEST:30.932 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:28:25.097: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7055
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-7055
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7055 to expose endpoints map[]
Jul 15 22:28:25.357: INFO: Get endpoints failed (9.949806ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jul 15 22:28:26.367: INFO: successfully validated that service multi-endpoint-test in namespace services-7055 exposes endpoints map[] (1.01992782s elapsed)
STEP: Creating pod pod1 in namespace services-7055
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7055 to expose endpoints map[pod1:[100]]
Jul 15 22:28:28.449: INFO: successfully validated that service multi-endpoint-test in namespace services-7055 exposes endpoints map[pod1:[100]] (2.062257528s elapsed)
STEP: Creating pod pod2 in namespace services-7055
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7055 to expose endpoints map[pod1:[100] pod2:[101]]
Jul 15 22:28:31.601: INFO: successfully validated that service multi-endpoint-test in namespace services-7055 exposes endpoints map[pod1:[100] pod2:[101]] (3.136631541s elapsed)
STEP: Deleting pod pod1 in namespace services-7055
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7055 to expose endpoints map[pod2:[101]]
Jul 15 22:28:31.667: INFO: successfully validated that service multi-endpoint-test in namespace services-7055 exposes endpoints map[pod2:[101]] (40.50203ms elapsed)
STEP: Deleting pod pod2 in namespace services-7055
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7055 to expose endpoints map[]
Jul 15 22:28:32.712: INFO: successfully validated that service multi-endpoint-test in namespace services-7055 exposes endpoints map[] (1.025251989s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:28:32.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7055" for this suite.
Jul 15 22:28:56.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:28:57.183: INFO: namespace services-7055 deletion completed in 24.393164396s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:32.086 seconds]
[sig-network] Services
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:28:57.183: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3567
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-ef80bace-a74f-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume secrets
Jul 15 22:28:57.433: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ef82c20f-a74f-11e9-983d-d6ce37abd03c" in namespace "projected-3567" to be "success or failure"
Jul 15 22:28:57.450: INFO: Pod "pod-projected-secrets-ef82c20f-a74f-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.96444ms
Jul 15 22:28:59.463: INFO: Pod "pod-projected-secrets-ef82c20f-a74f-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03055089s
STEP: Saw pod success
Jul 15 22:28:59.464: INFO: Pod "pod-projected-secrets-ef82c20f-a74f-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:28:59.475: INFO: Trying to get logs from node 10.190.211.93 pod pod-projected-secrets-ef82c20f-a74f-11e9-983d-d6ce37abd03c container secret-volume-test: <nil>
STEP: delete the pod
Jul 15 22:28:59.599: INFO: Waiting for pod pod-projected-secrets-ef82c20f-a74f-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:28:59.607: INFO: Pod pod-projected-secrets-ef82c20f-a74f-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:28:59.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3567" for this suite.
Jul 15 22:29:05.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:29:06.546: INFO: namespace projected-3567 deletion completed in 6.923581346s

• [SLOW TEST:9.363 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:29:06.546: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1879
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-f51937b1-a74f-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume configMaps
Jul 15 22:29:06.820: INFO: Waiting up to 5m0s for pod "pod-configmaps-f51b6780-a74f-11e9-983d-d6ce37abd03c" in namespace "configmap-1879" to be "success or failure"
Jul 15 22:29:06.840: INFO: Pod "pod-configmaps-f51b6780-a74f-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 20.076709ms
Jul 15 22:29:08.850: INFO: Pod "pod-configmaps-f51b6780-a74f-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029917057s
Jul 15 22:29:10.861: INFO: Pod "pod-configmaps-f51b6780-a74f-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040422364s
STEP: Saw pod success
Jul 15 22:29:10.861: INFO: Pod "pod-configmaps-f51b6780-a74f-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:29:10.872: INFO: Trying to get logs from node 10.190.211.93 pod pod-configmaps-f51b6780-a74f-11e9-983d-d6ce37abd03c container configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 22:29:10.929: INFO: Waiting for pod pod-configmaps-f51b6780-a74f-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:29:10.938: INFO: Pod pod-configmaps-f51b6780-a74f-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:29:10.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1879" for this suite.
Jul 15 22:29:18.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:29:19.327: INFO: namespace configmap-1879 deletion completed in 8.374183905s

• [SLOW TEST:12.780 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:29:19.327: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8690
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jul 15 22:29:22.191: INFO: Successfully updated pod "labelsupdatefcb838f9-a74f-11e9-983d-d6ce37abd03c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:29:26.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8690" for this suite.
Jul 15 22:29:50.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:29:50.680: INFO: namespace downward-api-8690 deletion completed in 24.401135052s

• [SLOW TEST:31.353 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:29:50.682: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2179
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jul 15 22:29:55.577: INFO: Successfully updated pod "annotationupdate0f6830d6-a750-11e9-983d-d6ce37abd03c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:29:57.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2179" for this suite.
Jul 15 22:30:21.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:30:22.034: INFO: namespace downward-api-2179 deletion completed in 24.393829933s

• [SLOW TEST:31.352 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:30:22.034: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-821
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 22:30:22.339: INFO: Waiting up to 5m0s for pod "downwardapi-volume-221ef25c-a750-11e9-983d-d6ce37abd03c" in namespace "projected-821" to be "success or failure"
Jul 15 22:30:22.350: INFO: Pod "downwardapi-volume-221ef25c-a750-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.948758ms
Jul 15 22:30:24.362: INFO: Pod "downwardapi-volume-221ef25c-a750-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022489013s
STEP: Saw pod success
Jul 15 22:30:24.362: INFO: Pod "downwardapi-volume-221ef25c-a750-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:30:24.377: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-221ef25c-a750-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 22:30:24.448: INFO: Waiting for pod downwardapi-volume-221ef25c-a750-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:30:24.464: INFO: Pod downwardapi-volume-221ef25c-a750-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:30:24.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-821" for this suite.
Jul 15 22:30:30.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:30:30.878: INFO: namespace projected-821 deletion completed in 6.399385862s

• [SLOW TEST:8.845 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:30:30.879: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9820
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 22:30:31.122: INFO: Waiting up to 5m0s for pod "downwardapi-volume-275a7a72-a750-11e9-983d-d6ce37abd03c" in namespace "downward-api-9820" to be "success or failure"
Jul 15 22:30:31.136: INFO: Pod "downwardapi-volume-275a7a72-a750-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.524398ms
Jul 15 22:30:33.147: INFO: Pod "downwardapi-volume-275a7a72-a750-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024662921s
Jul 15 22:30:35.157: INFO: Pod "downwardapi-volume-275a7a72-a750-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035206677s
STEP: Saw pod success
Jul 15 22:30:35.157: INFO: Pod "downwardapi-volume-275a7a72-a750-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:30:35.167: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-275a7a72-a750-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 22:30:35.245: INFO: Waiting for pod downwardapi-volume-275a7a72-a750-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:30:35.257: INFO: Pod downwardapi-volume-275a7a72-a750-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:30:35.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9820" for this suite.
Jul 15 22:30:41.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:30:41.653: INFO: namespace downward-api-9820 deletion completed in 6.382564552s

• [SLOW TEST:10.774 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:30:41.655: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2484
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 22:30:41.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 version --client'
Jul 15 22:30:41.940: INFO: stderr: ""
Jul 15 22:30:41.940: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.4\", GitCommit:\"a87e9a978f65a8303aa9467537aa59c18122cbf9\", GitTreeState:\"clean\", BuildDate:\"2019-07-08T08:51:16Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jul 15 22:30:41.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 create -f - --namespace=kubectl-2484'
Jul 15 22:30:42.306: INFO: stderr: ""
Jul 15 22:30:42.306: INFO: stdout: "replicationcontroller/redis-master created\n"
Jul 15 22:30:42.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 create -f - --namespace=kubectl-2484'
Jul 15 22:30:42.538: INFO: stderr: ""
Jul 15 22:30:42.538: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jul 15 22:30:43.549: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 22:30:43.549: INFO: Found 0 / 1
Jul 15 22:30:44.550: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 22:30:44.550: INFO: Found 1 / 1
Jul 15 22:30:44.550: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul 15 22:30:44.560: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 22:30:44.560: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 15 22:30:44.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 describe pod redis-master-dwhxh --namespace=kubectl-2484'
Jul 15 22:30:44.811: INFO: stderr: ""
Jul 15 22:30:44.811: INFO: stdout: "Name:               redis-master-dwhxh\nNamespace:          kubectl-2484\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.190.211.93/10.190.211.93\nStart Time:         Mon, 15 Jul 2019 22:30:42 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 172.30.19.34\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://ea1bb58f4cfbaf306340aba9cf25835dbe53bc836fce183f73c4bca8c42cfc68\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 15 Jul 2019 22:30:43 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-t45t4 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-t45t4:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-t45t4\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                    Message\n  ----    ------     ----  ----                    -------\n  Normal  Scheduled  2s    default-scheduler       Successfully assigned kubectl-2484/redis-master-dwhxh to 10.190.211.93\n  Normal  Pulled     1s    kubelet, 10.190.211.93  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, 10.190.211.93  Created container redis-master\n  Normal  Started    1s    kubelet, 10.190.211.93  Started container redis-master\n"
Jul 15 22:30:44.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 describe rc redis-master --namespace=kubectl-2484'
Jul 15 22:30:44.967: INFO: stderr: ""
Jul 15 22:30:44.967: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-2484\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-dwhxh\n"
Jul 15 22:30:44.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 describe service redis-master --namespace=kubectl-2484'
Jul 15 22:30:45.123: INFO: stderr: ""
Jul 15 22:30:45.123: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-2484\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.13.135\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.19.34:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jul 15 22:30:45.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 describe node 10.190.211.91'
Jul 15 22:30:45.547: INFO: stderr: ""
Jul 15 22:30:45.547: INFO: stdout: "Name:               10.190.211.91\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east\n                    failure-domain.beta.kubernetes.io/zone=wdc07\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=169.62.43.188\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.190.211.91\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=us-east\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-wdc07-crf7531fcdf3c4443f99d3792052463a22-w2\n                    ibm-cloud.kubernetes.io/worker-pool-id=f7531fcdf3c4443f99d3792052463a22-72dd28d\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.14.3_1525\n                    ibm-cloud.kubernetes.io/zone=wdc07\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.190.211.91\n                    kubernetes.io/os=linux\n                    privateVLAN=2631249\n                    publicVLAN=2631247\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 15 Jul 2019 20:52:20 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 15 Jul 2019 22:29:57 +0000   Mon, 15 Jul 2019 20:52:20 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 15 Jul 2019 22:29:57 +0000   Mon, 15 Jul 2019 20:52:20 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 15 Jul 2019 22:29:57 +0000   Mon, 15 Jul 2019 20:52:20 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 15 Jul 2019 22:29:57 +0000   Mon, 15 Jul 2019 20:52:30 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.190.211.91\n  ExternalIP:  169.62.43.188\n  Hostname:    10.190.211.91\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419920Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627472Ki\n pods:               110\nSystem Info:\n Machine ID:                 aeaa3801b2f74709ac33870e0d328aa5\n System UUID:                87B078A7-99C2-3342-9D71-1EA8C5B6DC1D\n Boot ID:                    1be09f02-acf7-4376-990d-e33daf2d7768\n Kernel Version:             4.15.0-54-generic\n OS Image:                   Ubuntu 18.04.2 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.7\n Kubelet Version:            v1.14.3+IKS\n Kube-Proxy Version:         v1.14.3+IKS\nProviderID:                  ibm://d18c889395112a40d2f4e3065f237a7d///f7531fcdf3c4443f99d3792052463a22/kube-wdc07-crf7531fcdf3c4443f99d3792052463a22-w2\nNon-terminated Pods:         (13 in total)\n  Namespace                  Name                                                               CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                               ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-e8a5b131278f47ce-msplm            0 (0%)        0 (0%)      0 (0%)           0 (0%)         32m\n  ibm-system                 ibm-cloud-provider-ip-169-62-60-229-5746bf8754-pvhns               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         96m\n  kube-system                calico-kube-controllers-658bc54b6f-dngkt                           10m (0%)      0 (0%)      25Mi (0%)        0 (0%)         104m\n  kube-system                calico-node-296f7                                                  250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         98m\n  kube-system                coredns-74d7dffd76-4skkd                                           100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     97m\n  kube-system                coredns-autoscaler-6d8b6f867-lm5sc                                 20m (0%)      0 (0%)      10Mi (0%)        0 (0%)         103m\n  kube-system                ibm-file-plugin-76564988db-lwwst                                   50m (1%)      200m (5%)   100Mi (0%)       0 (0%)         102m\n  kube-system                ibm-keepalived-watcher-7hbvk                                       5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         98m\n  kube-system                ibm-kube-fluentd-qq2vb                                             25m (0%)      300m (7%)   150Mi (1%)       800M (5%)      97m\n  kube-system                ibm-master-proxy-static-10.190.211.91                              25m (0%)      300m (7%)   32M (0%)         512M (3%)      98m\n  kube-system                metrics-server-6cdf95ffc5-rgpxg                                    53m (1%)      148m (3%)   154Mi (1%)       404Mi (3%)     97m\n  kube-system                public-crf7531fcdf3c4443f99d3792052463a22-alb1-5c8744f6fb-lq8qt    896m (22%)    0 (0%)      800Mi (6%)       0 (0%)         94m\n  kube-system                vpn-84dbfcd799-q9rz6                                               5m (0%)       0 (0%)      5Mi (0%)         0 (0%)         99m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests         Limits\n  --------           --------         ------\n  cpu                1444m (36%)      948m (24%)\n  memory             1479186Ki (10%)  2104546Ki (15%)\n  ephemeral-storage  0 (0%)           0 (0%)\nEvents:              <none>\n"
Jul 15 22:30:45.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 describe namespace kubectl-2484'
Jul 15 22:30:45.697: INFO: stderr: ""
Jul 15 22:30:45.697: INFO: stdout: "Name:         kubectl-2484\nLabels:       e2e-framework=kubectl\n              e2e-run=affc0452-a74b-11e9-983d-d6ce37abd03c\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:30:45.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2484" for this suite.
Jul 15 22:31:09.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:31:10.149: INFO: namespace kubectl-2484 deletion completed in 24.438905582s

• [SLOW TEST:28.494 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:31:10.150: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6574
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0715 22:31:50.462472      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 15 22:31:50.462: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:31:50.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6574" for this suite.
Jul 15 22:31:58.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:31:59.043: INFO: namespace gc-6574 deletion completed in 8.566234615s

• [SLOW TEST:48.893 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:31:59.043: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-891
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-5xxzm in namespace proxy-891
I0715 22:31:59.358051      16 runners.go:184] Created replication controller with name: proxy-service-5xxzm, namespace: proxy-891, replica count: 1
I0715 22:32:00.408547      16 runners.go:184] proxy-service-5xxzm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0715 22:32:01.408836      16 runners.go:184] proxy-service-5xxzm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0715 22:32:02.409055      16 runners.go:184] proxy-service-5xxzm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0715 22:32:03.409278      16 runners.go:184] proxy-service-5xxzm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0715 22:32:04.409601      16 runners.go:184] proxy-service-5xxzm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0715 22:32:05.409861      16 runners.go:184] proxy-service-5xxzm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0715 22:32:06.410093      16 runners.go:184] proxy-service-5xxzm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0715 22:32:07.410352      16 runners.go:184] proxy-service-5xxzm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0715 22:32:08.410600      16 runners.go:184] proxy-service-5xxzm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0715 22:32:09.410791      16 runners.go:184] proxy-service-5xxzm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0715 22:32:10.410982      16 runners.go:184] proxy-service-5xxzm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0715 22:32:11.411279      16 runners.go:184] proxy-service-5xxzm Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 15 22:32:11.421: INFO: setup took 12.10992069s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jul 15 22:32:11.455: INFO: (0) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 33.222336ms)
Jul 15 22:32:11.459: INFO: (0) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 37.21089ms)
Jul 15 22:32:11.463: INFO: (0) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 41.600439ms)
Jul 15 22:32:11.464: INFO: (0) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 42.668057ms)
Jul 15 22:32:11.465: INFO: (0) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 42.572486ms)
Jul 15 22:32:11.465: INFO: (0) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 42.618763ms)
Jul 15 22:32:11.465: INFO: (0) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 43.630198ms)
Jul 15 22:32:11.465: INFO: (0) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 43.820452ms)
Jul 15 22:32:11.465: INFO: (0) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 43.356784ms)
Jul 15 22:32:11.465: INFO: (0) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 43.401699ms)
Jul 15 22:32:11.466: INFO: (0) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 44.490824ms)
Jul 15 22:32:11.467: INFO: (0) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 44.894774ms)
Jul 15 22:32:11.474: INFO: (0) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 52.336668ms)
Jul 15 22:32:11.475: INFO: (0) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 52.968971ms)
Jul 15 22:32:11.479: INFO: (0) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 57.357171ms)
Jul 15 22:32:11.479: INFO: (0) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 57.1748ms)
Jul 15 22:32:11.495: INFO: (1) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 15.39377ms)
Jul 15 22:32:11.498: INFO: (1) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 17.912428ms)
Jul 15 22:32:11.499: INFO: (1) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 18.582346ms)
Jul 15 22:32:11.499: INFO: (1) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 18.026546ms)
Jul 15 22:32:11.499: INFO: (1) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 18.357496ms)
Jul 15 22:32:11.499: INFO: (1) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 18.713276ms)
Jul 15 22:32:11.501: INFO: (1) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 21.206565ms)
Jul 15 22:32:11.501: INFO: (1) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 21.299493ms)
Jul 15 22:32:11.501: INFO: (1) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 20.986897ms)
Jul 15 22:32:11.502: INFO: (1) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 21.509034ms)
Jul 15 22:32:11.508: INFO: (1) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 28.197499ms)
Jul 15 22:32:11.508: INFO: (1) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 28.242201ms)
Jul 15 22:32:11.511: INFO: (1) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 30.710965ms)
Jul 15 22:32:11.511: INFO: (1) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 31.706838ms)
Jul 15 22:32:11.511: INFO: (1) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 31.752036ms)
Jul 15 22:32:11.512: INFO: (1) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 31.554955ms)
Jul 15 22:32:11.525: INFO: (2) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 13.456718ms)
Jul 15 22:32:11.538: INFO: (2) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 25.490543ms)
Jul 15 22:32:11.538: INFO: (2) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 24.86736ms)
Jul 15 22:32:11.538: INFO: (2) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 25.181183ms)
Jul 15 22:32:11.538: INFO: (2) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 25.595944ms)
Jul 15 22:32:11.538: INFO: (2) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 24.701065ms)
Jul 15 22:32:11.538: INFO: (2) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 25.542195ms)
Jul 15 22:32:11.538: INFO: (2) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 24.754675ms)
Jul 15 22:32:11.538: INFO: (2) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 25.699396ms)
Jul 15 22:32:11.539: INFO: (2) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 25.949531ms)
Jul 15 22:32:11.541: INFO: (2) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 29.215854ms)
Jul 15 22:32:11.542: INFO: (2) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 28.719636ms)
Jul 15 22:32:11.542: INFO: (2) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 28.642723ms)
Jul 15 22:32:11.542: INFO: (2) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 29.451723ms)
Jul 15 22:32:11.542: INFO: (2) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 29.387158ms)
Jul 15 22:32:11.542: INFO: (2) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 29.888826ms)
Jul 15 22:32:11.556: INFO: (3) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 13.788893ms)
Jul 15 22:32:11.561: INFO: (3) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 18.069676ms)
Jul 15 22:32:11.561: INFO: (3) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 18.254524ms)
Jul 15 22:32:11.561: INFO: (3) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 19.242273ms)
Jul 15 22:32:11.561: INFO: (3) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 18.220929ms)
Jul 15 22:32:11.561: INFO: (3) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 18.40253ms)
Jul 15 22:32:11.561: INFO: (3) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 18.950304ms)
Jul 15 22:32:11.561: INFO: (3) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 19.012347ms)
Jul 15 22:32:11.561: INFO: (3) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 18.762258ms)
Jul 15 22:32:11.563: INFO: (3) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 20.785569ms)
Jul 15 22:32:11.566: INFO: (3) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 23.944507ms)
Jul 15 22:32:11.568: INFO: (3) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 25.996189ms)
Jul 15 22:32:11.568: INFO: (3) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 25.578795ms)
Jul 15 22:32:11.568: INFO: (3) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 25.129797ms)
Jul 15 22:32:11.568: INFO: (3) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 26.09879ms)
Jul 15 22:32:11.568: INFO: (3) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 25.811948ms)
Jul 15 22:32:11.582: INFO: (4) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 13.881895ms)
Jul 15 22:32:11.588: INFO: (4) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 18.590335ms)
Jul 15 22:32:11.588: INFO: (4) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 18.903972ms)
Jul 15 22:32:11.588: INFO: (4) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 19.395418ms)
Jul 15 22:32:11.588: INFO: (4) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 19.752531ms)
Jul 15 22:32:11.588: INFO: (4) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 19.300929ms)
Jul 15 22:32:11.588: INFO: (4) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 19.389175ms)
Jul 15 22:32:11.592: INFO: (4) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 22.75584ms)
Jul 15 22:32:11.592: INFO: (4) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 22.584811ms)
Jul 15 22:32:11.592: INFO: (4) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 22.844305ms)
Jul 15 22:32:11.595: INFO: (4) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 26.43216ms)
Jul 15 22:32:11.597: INFO: (4) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 28.290391ms)
Jul 15 22:32:11.602: INFO: (4) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 32.858062ms)
Jul 15 22:32:11.602: INFO: (4) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 32.543787ms)
Jul 15 22:32:11.602: INFO: (4) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 32.969851ms)
Jul 15 22:32:11.602: INFO: (4) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 33.00423ms)
Jul 15 22:32:11.617: INFO: (5) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 14.570867ms)
Jul 15 22:32:11.629: INFO: (5) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 25.889993ms)
Jul 15 22:32:11.629: INFO: (5) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 25.843823ms)
Jul 15 22:32:11.629: INFO: (5) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 26.199531ms)
Jul 15 22:32:11.631: INFO: (5) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 28.027538ms)
Jul 15 22:32:11.631: INFO: (5) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 28.112634ms)
Jul 15 22:32:11.631: INFO: (5) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 28.451927ms)
Jul 15 22:32:11.632: INFO: (5) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 28.697086ms)
Jul 15 22:32:11.632: INFO: (5) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 29.180806ms)
Jul 15 22:32:11.632: INFO: (5) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 28.956844ms)
Jul 15 22:32:11.632: INFO: (5) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 29.273186ms)
Jul 15 22:32:11.632: INFO: (5) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 29.556454ms)
Jul 15 22:32:11.632: INFO: (5) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 29.701045ms)
Jul 15 22:32:11.635: INFO: (5) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 32.114141ms)
Jul 15 22:32:11.636: INFO: (5) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 33.081405ms)
Jul 15 22:32:11.636: INFO: (5) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 32.945585ms)
Jul 15 22:32:11.652: INFO: (6) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 15.843931ms)
Jul 15 22:32:11.655: INFO: (6) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 18.564008ms)
Jul 15 22:32:11.656: INFO: (6) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 19.317584ms)
Jul 15 22:32:11.656: INFO: (6) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 19.714636ms)
Jul 15 22:32:11.656: INFO: (6) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 20.28236ms)
Jul 15 22:32:11.656: INFO: (6) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 20.118842ms)
Jul 15 22:32:11.656: INFO: (6) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 20.314471ms)
Jul 15 22:32:11.656: INFO: (6) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 20.31713ms)
Jul 15 22:32:11.656: INFO: (6) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 20.344748ms)
Jul 15 22:32:11.657: INFO: (6) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 20.609723ms)
Jul 15 22:32:11.659: INFO: (6) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 22.641698ms)
Jul 15 22:32:11.662: INFO: (6) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 26.106653ms)
Jul 15 22:32:11.670: INFO: (6) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 34.327241ms)
Jul 15 22:32:11.670: INFO: (6) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 34.393937ms)
Jul 15 22:32:11.671: INFO: (6) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 35.263573ms)
Jul 15 22:32:11.672: INFO: (6) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 35.846534ms)
Jul 15 22:32:11.686: INFO: (7) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 13.701973ms)
Jul 15 22:32:11.696: INFO: (7) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 23.065793ms)
Jul 15 22:32:11.697: INFO: (7) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 24.359483ms)
Jul 15 22:32:11.697: INFO: (7) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 24.538224ms)
Jul 15 22:32:11.697: INFO: (7) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 24.466813ms)
Jul 15 22:32:11.697: INFO: (7) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 24.715009ms)
Jul 15 22:32:11.697: INFO: (7) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 24.811229ms)
Jul 15 22:32:11.697: INFO: (7) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 24.684445ms)
Jul 15 22:32:11.697: INFO: (7) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 24.533366ms)
Jul 15 22:32:11.697: INFO: (7) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 25.072944ms)
Jul 15 22:32:11.698: INFO: (7) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 24.851079ms)
Jul 15 22:32:11.701: INFO: (7) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 28.751637ms)
Jul 15 22:32:11.704: INFO: (7) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 31.618749ms)
Jul 15 22:32:11.705: INFO: (7) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 31.775409ms)
Jul 15 22:32:11.705: INFO: (7) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 31.908139ms)
Jul 15 22:32:11.705: INFO: (7) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 31.953917ms)
Jul 15 22:32:11.723: INFO: (8) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 18.08273ms)
Jul 15 22:32:11.724: INFO: (8) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 19.263476ms)
Jul 15 22:32:11.725: INFO: (8) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 19.781342ms)
Jul 15 22:32:11.725: INFO: (8) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 20.231563ms)
Jul 15 22:32:11.725: INFO: (8) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 20.024147ms)
Jul 15 22:32:11.726: INFO: (8) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 20.567761ms)
Jul 15 22:32:11.726: INFO: (8) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 20.90981ms)
Jul 15 22:32:11.726: INFO: (8) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 21.229964ms)
Jul 15 22:32:11.726: INFO: (8) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 21.360096ms)
Jul 15 22:32:11.727: INFO: (8) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 21.453986ms)
Jul 15 22:32:11.727: INFO: (8) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 21.81346ms)
Jul 15 22:32:11.730: INFO: (8) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 25.190833ms)
Jul 15 22:32:11.734: INFO: (8) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 29.049433ms)
Jul 15 22:32:11.735: INFO: (8) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 29.443424ms)
Jul 15 22:32:11.735: INFO: (8) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 29.38609ms)
Jul 15 22:32:11.735: INFO: (8) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 29.876393ms)
Jul 15 22:32:11.748: INFO: (9) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 13.245917ms)
Jul 15 22:32:11.751: INFO: (9) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 16.290344ms)
Jul 15 22:32:11.752: INFO: (9) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 16.344296ms)
Jul 15 22:32:11.752: INFO: (9) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 16.461245ms)
Jul 15 22:32:11.752: INFO: (9) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 16.364272ms)
Jul 15 22:32:11.752: INFO: (9) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 16.549451ms)
Jul 15 22:32:11.752: INFO: (9) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 16.394242ms)
Jul 15 22:32:11.752: INFO: (9) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 16.818657ms)
Jul 15 22:32:11.752: INFO: (9) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 16.625818ms)
Jul 15 22:32:11.754: INFO: (9) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 19.213496ms)
Jul 15 22:32:11.755: INFO: (9) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 19.476424ms)
Jul 15 22:32:11.760: INFO: (9) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 25.299318ms)
Jul 15 22:32:11.765: INFO: (9) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 29.419611ms)
Jul 15 22:32:11.766: INFO: (9) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 30.354742ms)
Jul 15 22:32:11.766: INFO: (9) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 30.422614ms)
Jul 15 22:32:11.767: INFO: (9) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 31.218566ms)
Jul 15 22:32:11.781: INFO: (10) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 13.95148ms)
Jul 15 22:32:11.790: INFO: (10) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 23.38422ms)
Jul 15 22:32:11.790: INFO: (10) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 23.608038ms)
Jul 15 22:32:11.790: INFO: (10) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 23.666002ms)
Jul 15 22:32:11.790: INFO: (10) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 23.7792ms)
Jul 15 22:32:11.791: INFO: (10) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 23.681026ms)
Jul 15 22:32:11.791: INFO: (10) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 23.654777ms)
Jul 15 22:32:11.791: INFO: (10) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 24.324449ms)
Jul 15 22:32:11.794: INFO: (10) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 27.357707ms)
Jul 15 22:32:11.796: INFO: (10) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 29.49939ms)
Jul 15 22:32:11.802: INFO: (10) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 34.640293ms)
Jul 15 22:32:11.802: INFO: (10) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 34.731645ms)
Jul 15 22:32:11.802: INFO: (10) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 34.788202ms)
Jul 15 22:32:11.802: INFO: (10) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 34.729548ms)
Jul 15 22:32:11.802: INFO: (10) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 34.762968ms)
Jul 15 22:32:11.802: INFO: (10) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 35.426971ms)
Jul 15 22:32:11.821: INFO: (11) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 19.143806ms)
Jul 15 22:32:11.825: INFO: (11) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 22.015168ms)
Jul 15 22:32:11.825: INFO: (11) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 22.451296ms)
Jul 15 22:32:11.826: INFO: (11) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 22.726696ms)
Jul 15 22:32:11.826: INFO: (11) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 23.408781ms)
Jul 15 22:32:11.826: INFO: (11) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 23.214844ms)
Jul 15 22:32:11.826: INFO: (11) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 23.283409ms)
Jul 15 22:32:11.826: INFO: (11) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 23.050426ms)
Jul 15 22:32:11.826: INFO: (11) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 23.963246ms)
Jul 15 22:32:11.826: INFO: (11) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 24.237673ms)
Jul 15 22:32:11.828: INFO: (11) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 25.432147ms)
Jul 15 22:32:11.835: INFO: (11) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 32.992384ms)
Jul 15 22:32:11.839: INFO: (11) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 36.250638ms)
Jul 15 22:32:11.839: INFO: (11) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 36.582841ms)
Jul 15 22:32:11.839: INFO: (11) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 36.275537ms)
Jul 15 22:32:11.839: INFO: (11) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 35.971666ms)
Jul 15 22:32:11.856: INFO: (12) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 17.270015ms)
Jul 15 22:32:11.857: INFO: (12) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 18.38019ms)
Jul 15 22:32:11.858: INFO: (12) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 18.876478ms)
Jul 15 22:32:11.858: INFO: (12) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 19.137246ms)
Jul 15 22:32:11.858: INFO: (12) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 19.039397ms)
Jul 15 22:32:11.859: INFO: (12) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 19.606351ms)
Jul 15 22:32:11.859: INFO: (12) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 20.173572ms)
Jul 15 22:32:11.859: INFO: (12) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 20.097079ms)
Jul 15 22:32:11.860: INFO: (12) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 20.93378ms)
Jul 15 22:32:11.863: INFO: (12) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 24.255203ms)
Jul 15 22:32:11.864: INFO: (12) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 24.299676ms)
Jul 15 22:32:11.868: INFO: (12) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 28.541694ms)
Jul 15 22:32:11.872: INFO: (12) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 33.062609ms)
Jul 15 22:32:11.872: INFO: (12) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 32.889285ms)
Jul 15 22:32:11.872: INFO: (12) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 32.909249ms)
Jul 15 22:32:11.872: INFO: (12) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 33.165274ms)
Jul 15 22:32:11.888: INFO: (13) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 15.693961ms)
Jul 15 22:32:11.897: INFO: (13) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 24.415454ms)
Jul 15 22:32:11.897: INFO: (13) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 24.556246ms)
Jul 15 22:32:11.898: INFO: (13) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 25.160336ms)
Jul 15 22:32:11.899: INFO: (13) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 26.528038ms)
Jul 15 22:32:11.899: INFO: (13) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 26.563746ms)
Jul 15 22:32:11.899: INFO: (13) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 26.310385ms)
Jul 15 22:32:11.899: INFO: (13) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 26.317805ms)
Jul 15 22:32:11.899: INFO: (13) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 26.210045ms)
Jul 15 22:32:11.900: INFO: (13) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 27.119052ms)
Jul 15 22:32:11.902: INFO: (13) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 29.600953ms)
Jul 15 22:32:11.902: INFO: (13) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 29.496234ms)
Jul 15 22:32:11.905: INFO: (13) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 32.557536ms)
Jul 15 22:32:11.905: INFO: (13) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 32.605342ms)
Jul 15 22:32:11.905: INFO: (13) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 32.94475ms)
Jul 15 22:32:11.905: INFO: (13) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 32.526135ms)
Jul 15 22:32:11.920: INFO: (14) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 13.492277ms)
Jul 15 22:32:11.927: INFO: (14) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 20.723559ms)
Jul 15 22:32:11.927: INFO: (14) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 20.817674ms)
Jul 15 22:32:11.927: INFO: (14) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 20.510023ms)
Jul 15 22:32:11.927: INFO: (14) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 20.727836ms)
Jul 15 22:32:11.927: INFO: (14) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 20.613922ms)
Jul 15 22:32:11.927: INFO: (14) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 20.291597ms)
Jul 15 22:32:11.927: INFO: (14) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 20.488146ms)
Jul 15 22:32:11.927: INFO: (14) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 20.878857ms)
Jul 15 22:32:11.927: INFO: (14) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 21.017872ms)
Jul 15 22:32:11.931: INFO: (14) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 24.80005ms)
Jul 15 22:32:11.938: INFO: (14) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 31.643789ms)
Jul 15 22:32:11.942: INFO: (14) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 35.255415ms)
Jul 15 22:32:11.942: INFO: (14) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 35.528796ms)
Jul 15 22:32:11.942: INFO: (14) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 35.539526ms)
Jul 15 22:32:11.942: INFO: (14) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 35.841358ms)
Jul 15 22:32:11.958: INFO: (15) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 15.66182ms)
Jul 15 22:32:11.962: INFO: (15) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 19.776334ms)
Jul 15 22:32:11.963: INFO: (15) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 21.150368ms)
Jul 15 22:32:11.964: INFO: (15) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 21.481621ms)
Jul 15 22:32:11.964: INFO: (15) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 22.075672ms)
Jul 15 22:32:11.965: INFO: (15) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 22.612108ms)
Jul 15 22:32:11.965: INFO: (15) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 22.554329ms)
Jul 15 22:32:11.965: INFO: (15) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 22.445104ms)
Jul 15 22:32:11.965: INFO: (15) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 22.587447ms)
Jul 15 22:32:11.965: INFO: (15) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 22.483991ms)
Jul 15 22:32:11.967: INFO: (15) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 25.100393ms)
Jul 15 22:32:11.967: INFO: (15) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 25.256197ms)
Jul 15 22:32:11.973: INFO: (15) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 30.721656ms)
Jul 15 22:32:11.973: INFO: (15) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 31.066169ms)
Jul 15 22:32:11.973: INFO: (15) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 31.310985ms)
Jul 15 22:32:11.974: INFO: (15) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 31.892498ms)
Jul 15 22:32:11.990: INFO: (16) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 16.130284ms)
Jul 15 22:32:11.994: INFO: (16) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 19.092839ms)
Jul 15 22:32:11.994: INFO: (16) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 19.376515ms)
Jul 15 22:32:11.994: INFO: (16) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 19.539355ms)
Jul 15 22:32:11.994: INFO: (16) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 19.850082ms)
Jul 15 22:32:11.994: INFO: (16) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 19.69858ms)
Jul 15 22:32:11.994: INFO: (16) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 19.778542ms)
Jul 15 22:32:11.994: INFO: (16) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 19.86159ms)
Jul 15 22:32:11.994: INFO: (16) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 20.072514ms)
Jul 15 22:32:11.994: INFO: (16) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 20.217626ms)
Jul 15 22:32:11.997: INFO: (16) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 23.155426ms)
Jul 15 22:32:12.000: INFO: (16) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 25.582341ms)
Jul 15 22:32:12.000: INFO: (16) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 25.993297ms)
Jul 15 22:32:12.001: INFO: (16) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 26.17764ms)
Jul 15 22:32:12.001: INFO: (16) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 27.011399ms)
Jul 15 22:32:12.003: INFO: (16) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 28.86306ms)
Jul 15 22:32:12.017: INFO: (17) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 13.59464ms)
Jul 15 22:32:12.024: INFO: (17) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 20.860753ms)
Jul 15 22:32:12.024: INFO: (17) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 20.387089ms)
Jul 15 22:32:12.024: INFO: (17) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 20.357901ms)
Jul 15 22:32:12.024: INFO: (17) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 20.916696ms)
Jul 15 22:32:12.024: INFO: (17) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 21.211939ms)
Jul 15 22:32:12.024: INFO: (17) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 21.171671ms)
Jul 15 22:32:12.025: INFO: (17) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 21.636905ms)
Jul 15 22:32:12.025: INFO: (17) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 21.838034ms)
Jul 15 22:32:12.026: INFO: (17) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 22.742896ms)
Jul 15 22:32:12.028: INFO: (17) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 23.93209ms)
Jul 15 22:32:12.028: INFO: (17) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 24.244708ms)
Jul 15 22:32:12.034: INFO: (17) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 30.480325ms)
Jul 15 22:32:12.034: INFO: (17) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 31.044303ms)
Jul 15 22:32:12.035: INFO: (17) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 31.630376ms)
Jul 15 22:32:12.035: INFO: (17) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 31.099074ms)
Jul 15 22:32:12.049: INFO: (18) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 14.614518ms)
Jul 15 22:32:12.054: INFO: (18) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 19.117716ms)
Jul 15 22:32:12.054: INFO: (18) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 19.234968ms)
Jul 15 22:32:12.054: INFO: (18) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 18.999351ms)
Jul 15 22:32:12.054: INFO: (18) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 19.13682ms)
Jul 15 22:32:12.054: INFO: (18) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 18.97395ms)
Jul 15 22:32:12.054: INFO: (18) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 19.203301ms)
Jul 15 22:32:12.054: INFO: (18) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 19.29895ms)
Jul 15 22:32:12.054: INFO: (18) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 19.535855ms)
Jul 15 22:32:12.055: INFO: (18) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 19.798465ms)
Jul 15 22:32:12.057: INFO: (18) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 21.589592ms)
Jul 15 22:32:12.061: INFO: (18) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 25.972367ms)
Jul 15 22:32:12.064: INFO: (18) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 29.102439ms)
Jul 15 22:32:12.064: INFO: (18) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 29.503265ms)
Jul 15 22:32:12.065: INFO: (18) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 29.790695ms)
Jul 15 22:32:12.065: INFO: (18) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 29.913117ms)
Jul 15 22:32:12.086: INFO: (19) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:460/proxy/: tls baz (200; 20.832436ms)
Jul 15 22:32:12.086: INFO: (19) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">t... (200; 21.354457ms)
Jul 15 22:32:12.086: INFO: (19) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 21.27407ms)
Jul 15 22:32:12.087: INFO: (19) /api/v1/namespaces/proxy-891/pods/http:proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 21.785526ms)
Jul 15 22:32:12.089: INFO: (19) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:1080/proxy/rewriteme">test</... (200; 23.478835ms)
Jul 15 22:32:12.096: INFO: (19) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname2/proxy/: bar (200; 30.381035ms)
Jul 15 22:32:12.096: INFO: (19) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname2/proxy/: bar (200; 31.110898ms)
Jul 15 22:32:12.097: INFO: (19) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:462/proxy/: tls qux (200; 31.541859ms)
Jul 15 22:32:12.097: INFO: (19) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q/proxy/rewriteme">test</a> (200; 31.784912ms)
Jul 15 22:32:12.097: INFO: (19) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname1/proxy/: tls baz (200; 32.159663ms)
Jul 15 22:32:12.097: INFO: (19) /api/v1/namespaces/proxy-891/services/proxy-service-5xxzm:portname1/proxy/: foo (200; 31.908968ms)
Jul 15 22:32:12.097: INFO: (19) /api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/: <a href="/api/v1/namespaces/proxy-891/pods/https:proxy-service-5xxzm-hrh7q:443/proxy/tlsrewriteme... (200; 32.173506ms)
Jul 15 22:32:12.097: INFO: (19) /api/v1/namespaces/proxy-891/services/https:proxy-service-5xxzm:tlsportname2/proxy/: tls qux (200; 32.35106ms)
Jul 15 22:32:12.097: INFO: (19) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:160/proxy/: foo (200; 32.664092ms)
Jul 15 22:32:12.100: INFO: (19) /api/v1/namespaces/proxy-891/pods/proxy-service-5xxzm-hrh7q:162/proxy/: bar (200; 34.890263ms)
Jul 15 22:32:12.101: INFO: (19) /api/v1/namespaces/proxy-891/services/http:proxy-service-5xxzm:portname1/proxy/: foo (200; 35.502151ms)
STEP: deleting ReplicationController proxy-service-5xxzm in namespace proxy-891, will wait for the garbage collector to delete the pods
Jul 15 22:32:12.191: INFO: Deleting ReplicationController proxy-service-5xxzm took: 29.556261ms
Jul 15 22:32:12.391: INFO: Terminating ReplicationController proxy-service-5xxzm pods took: 200.20292ms
[AfterEach] version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:32:14.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-891" for this suite.
Jul 15 22:32:20.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:32:21.287: INFO: namespace proxy-891 deletion completed in 6.680497798s

• [SLOW TEST:22.244 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:32:21.287: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6883
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0715 22:32:27.626994      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 15 22:32:27.627: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:32:27.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6883" for this suite.
Jul 15 22:32:35.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:32:36.016: INFO: namespace gc-6883 deletion completed in 8.374893423s

• [SLOW TEST:14.729 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:32:36.017: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4758
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Jul 15 22:32:36.299: INFO: Waiting up to 5m0s for pod "pod-71f71e86-a750-11e9-983d-d6ce37abd03c" in namespace "emptydir-4758" to be "success or failure"
Jul 15 22:32:36.309: INFO: Pod "pod-71f71e86-a750-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.711171ms
Jul 15 22:32:38.321: INFO: Pod "pod-71f71e86-a750-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022235901s
Jul 15 22:32:40.332: INFO: Pod "pod-71f71e86-a750-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032639081s
STEP: Saw pod success
Jul 15 22:32:40.332: INFO: Pod "pod-71f71e86-a750-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:32:40.354: INFO: Trying to get logs from node 10.190.211.93 pod pod-71f71e86-a750-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 22:32:40.414: INFO: Waiting for pod pod-71f71e86-a750-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:32:40.425: INFO: Pod pod-71f71e86-a750-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:32:40.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4758" for this suite.
Jul 15 22:32:46.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:32:46.835: INFO: namespace emptydir-4758 deletion completed in 6.394068747s

• [SLOW TEST:10.819 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:32:46.836: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-392
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-7864795b-a750-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume configMaps
Jul 15 22:32:47.088: INFO: Waiting up to 5m0s for pod "pod-configmaps-7865c929-a750-11e9-983d-d6ce37abd03c" in namespace "configmap-392" to be "success or failure"
Jul 15 22:32:47.101: INFO: Pod "pod-configmaps-7865c929-a750-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.733368ms
Jul 15 22:32:49.114: INFO: Pod "pod-configmaps-7865c929-a750-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026161367s
STEP: Saw pod success
Jul 15 22:32:49.114: INFO: Pod "pod-configmaps-7865c929-a750-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:32:49.127: INFO: Trying to get logs from node 10.190.211.93 pod pod-configmaps-7865c929-a750-11e9-983d-d6ce37abd03c container configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 22:32:49.194: INFO: Waiting for pod pod-configmaps-7865c929-a750-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:32:49.204: INFO: Pod pod-configmaps-7865c929-a750-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:32:49.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-392" for this suite.
Jul 15 22:32:55.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:32:55.578: INFO: namespace configmap-392 deletion completed in 6.359921713s

• [SLOW TEST:8.743 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:32:55.579: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2263
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-kqvj
STEP: Creating a pod to test atomic-volume-subpath
Jul 15 22:32:55.849: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-kqvj" in namespace "subpath-2263" to be "success or failure"
Jul 15 22:32:55.866: INFO: Pod "pod-subpath-test-configmap-kqvj": Phase="Pending", Reason="", readiness=false. Elapsed: 17.091729ms
Jul 15 22:32:57.878: INFO: Pod "pod-subpath-test-configmap-kqvj": Phase="Running", Reason="", readiness=true. Elapsed: 2.028374476s
Jul 15 22:32:59.890: INFO: Pod "pod-subpath-test-configmap-kqvj": Phase="Running", Reason="", readiness=true. Elapsed: 4.04110341s
Jul 15 22:33:01.903: INFO: Pod "pod-subpath-test-configmap-kqvj": Phase="Running", Reason="", readiness=true. Elapsed: 6.053590926s
Jul 15 22:33:03.917: INFO: Pod "pod-subpath-test-configmap-kqvj": Phase="Running", Reason="", readiness=true. Elapsed: 8.0674361s
Jul 15 22:33:05.927: INFO: Pod "pod-subpath-test-configmap-kqvj": Phase="Running", Reason="", readiness=true. Elapsed: 10.078082141s
Jul 15 22:33:07.937: INFO: Pod "pod-subpath-test-configmap-kqvj": Phase="Running", Reason="", readiness=true. Elapsed: 12.088151438s
Jul 15 22:33:09.950: INFO: Pod "pod-subpath-test-configmap-kqvj": Phase="Running", Reason="", readiness=true. Elapsed: 14.100873987s
Jul 15 22:33:11.964: INFO: Pod "pod-subpath-test-configmap-kqvj": Phase="Running", Reason="", readiness=true. Elapsed: 16.114773762s
Jul 15 22:33:13.974: INFO: Pod "pod-subpath-test-configmap-kqvj": Phase="Running", Reason="", readiness=true. Elapsed: 18.124983207s
Jul 15 22:33:15.984: INFO: Pod "pod-subpath-test-configmap-kqvj": Phase="Running", Reason="", readiness=true. Elapsed: 20.135153063s
Jul 15 22:33:17.995: INFO: Pod "pod-subpath-test-configmap-kqvj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.146286782s
STEP: Saw pod success
Jul 15 22:33:17.995: INFO: Pod "pod-subpath-test-configmap-kqvj" satisfied condition "success or failure"
Jul 15 22:33:18.007: INFO: Trying to get logs from node 10.190.211.93 pod pod-subpath-test-configmap-kqvj container test-container-subpath-configmap-kqvj: <nil>
STEP: delete the pod
Jul 15 22:33:18.084: INFO: Waiting for pod pod-subpath-test-configmap-kqvj to disappear
Jul 15 22:33:18.099: INFO: Pod pod-subpath-test-configmap-kqvj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-kqvj
Jul 15 22:33:18.099: INFO: Deleting pod "pod-subpath-test-configmap-kqvj" in namespace "subpath-2263"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:33:18.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2263" for this suite.
Jul 15 22:33:24.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:33:24.534: INFO: namespace subpath-2263 deletion completed in 6.400232945s

• [SLOW TEST:28.956 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:33:24.535: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2771
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-8ede943b-a750-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume secrets
Jul 15 22:33:24.964: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8ee089a4-a750-11e9-983d-d6ce37abd03c" in namespace "projected-2771" to be "success or failure"
Jul 15 22:33:24.988: INFO: Pod "pod-projected-secrets-8ee089a4-a750-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 24.029844ms
Jul 15 22:33:26.999: INFO: Pod "pod-projected-secrets-8ee089a4-a750-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035463455s
STEP: Saw pod success
Jul 15 22:33:26.999: INFO: Pod "pod-projected-secrets-8ee089a4-a750-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:33:27.011: INFO: Trying to get logs from node 10.190.211.93 pod pod-projected-secrets-8ee089a4-a750-11e9-983d-d6ce37abd03c container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 15 22:33:27.074: INFO: Waiting for pod pod-projected-secrets-8ee089a4-a750-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:33:27.083: INFO: Pod pod-projected-secrets-8ee089a4-a750-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:33:27.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2771" for this suite.
Jul 15 22:33:33.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:33:33.462: INFO: namespace projected-2771 deletion completed in 6.363137708s

• [SLOW TEST:8.927 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:33:33.463: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9956
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 22:33:35.781: INFO: Waiting up to 5m0s for pod "client-envvars-956d5419-a750-11e9-983d-d6ce37abd03c" in namespace "pods-9956" to be "success or failure"
Jul 15 22:33:35.792: INFO: Pod "client-envvars-956d5419-a750-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.719553ms
Jul 15 22:33:37.805: INFO: Pod "client-envvars-956d5419-a750-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023894026s
STEP: Saw pod success
Jul 15 22:33:37.805: INFO: Pod "client-envvars-956d5419-a750-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:33:37.817: INFO: Trying to get logs from node 10.190.211.93 pod client-envvars-956d5419-a750-11e9-983d-d6ce37abd03c container env3cont: <nil>
STEP: delete the pod
Jul 15 22:33:37.879: INFO: Waiting for pod client-envvars-956d5419-a750-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:33:37.891: INFO: Pod client-envvars-956d5419-a750-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:33:37.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9956" for this suite.
Jul 15 22:34:23.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:34:24.333: INFO: namespace pods-9956 deletion completed in 46.427565395s

• [SLOW TEST:50.869 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:34:24.333: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7514
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-7tw8
STEP: Creating a pod to test atomic-volume-subpath
Jul 15 22:34:24.631: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-7tw8" in namespace "subpath-7514" to be "success or failure"
Jul 15 22:34:24.644: INFO: Pod "pod-subpath-test-projected-7tw8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.045954ms
Jul 15 22:34:26.658: INFO: Pod "pod-subpath-test-projected-7tw8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027135567s
Jul 15 22:34:28.669: INFO: Pod "pod-subpath-test-projected-7tw8": Phase="Running", Reason="", readiness=true. Elapsed: 4.037671766s
Jul 15 22:34:30.679: INFO: Pod "pod-subpath-test-projected-7tw8": Phase="Running", Reason="", readiness=true. Elapsed: 6.048575498s
Jul 15 22:34:32.693: INFO: Pod "pod-subpath-test-projected-7tw8": Phase="Running", Reason="", readiness=true. Elapsed: 8.06241789s
Jul 15 22:34:34.705: INFO: Pod "pod-subpath-test-projected-7tw8": Phase="Running", Reason="", readiness=true. Elapsed: 10.074281762s
Jul 15 22:34:36.715: INFO: Pod "pod-subpath-test-projected-7tw8": Phase="Running", Reason="", readiness=true. Elapsed: 12.084048344s
Jul 15 22:34:38.726: INFO: Pod "pod-subpath-test-projected-7tw8": Phase="Running", Reason="", readiness=true. Elapsed: 14.09529419s
Jul 15 22:34:40.736: INFO: Pod "pod-subpath-test-projected-7tw8": Phase="Running", Reason="", readiness=true. Elapsed: 16.105606782s
Jul 15 22:34:42.747: INFO: Pod "pod-subpath-test-projected-7tw8": Phase="Running", Reason="", readiness=true. Elapsed: 18.11589468s
Jul 15 22:34:44.760: INFO: Pod "pod-subpath-test-projected-7tw8": Phase="Running", Reason="", readiness=true. Elapsed: 20.129364404s
Jul 15 22:34:46.773: INFO: Pod "pod-subpath-test-projected-7tw8": Phase="Running", Reason="", readiness=true. Elapsed: 22.141703773s
Jul 15 22:34:48.785: INFO: Pod "pod-subpath-test-projected-7tw8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.153902683s
STEP: Saw pod success
Jul 15 22:34:48.785: INFO: Pod "pod-subpath-test-projected-7tw8" satisfied condition "success or failure"
Jul 15 22:34:48.794: INFO: Trying to get logs from node 10.190.211.93 pod pod-subpath-test-projected-7tw8 container test-container-subpath-projected-7tw8: <nil>
STEP: delete the pod
Jul 15 22:34:48.844: INFO: Waiting for pod pod-subpath-test-projected-7tw8 to disappear
Jul 15 22:34:48.854: INFO: Pod pod-subpath-test-projected-7tw8 no longer exists
STEP: Deleting pod pod-subpath-test-projected-7tw8
Jul 15 22:34:48.854: INFO: Deleting pod "pod-subpath-test-projected-7tw8" in namespace "subpath-7514"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:34:48.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7514" for this suite.
Jul 15 22:34:54.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:34:55.447: INFO: namespace subpath-7514 deletion completed in 6.560995636s

• [SLOW TEST:31.114 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:34:55.448: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9453
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jul 15 22:35:03.865: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 22:35:03.885: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 22:35:05.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 22:35:05.896: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 22:35:07.886: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 22:35:07.897: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 22:35:09.886: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 22:35:09.897: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 22:35:11.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 22:35:11.895: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 22:35:13.886: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 22:35:13.896: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 22:35:15.886: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 22:35:15.895: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 22:35:17.886: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 22:35:17.896: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 22:35:19.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 22:35:19.899: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 22:35:21.886: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 22:35:21.898: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:35:21.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9453" for this suite.
Jul 15 22:35:33.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:35:34.344: INFO: namespace container-lifecycle-hook-9453 deletion completed in 12.424563217s

• [SLOW TEST:38.896 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:35:34.345: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2414
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-dc40e686-a750-11e9-983d-d6ce37abd03c
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-dc40e686-a750-11e9-983d-d6ce37abd03c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:36:55.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2414" for this suite.
Jul 15 22:37:19.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:37:20.075: INFO: namespace configmap-2414 deletion completed in 24.398196791s

• [SLOW TEST:105.730 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:37:20.079: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9915
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jul 15 22:37:20.349: INFO: Waiting up to 5m0s for pod "pod-1b45c588-a751-11e9-983d-d6ce37abd03c" in namespace "emptydir-9915" to be "success or failure"
Jul 15 22:37:20.361: INFO: Pod "pod-1b45c588-a751-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.640947ms
Jul 15 22:37:22.371: INFO: Pod "pod-1b45c588-a751-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022419575s
STEP: Saw pod success
Jul 15 22:37:22.371: INFO: Pod "pod-1b45c588-a751-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:37:22.384: INFO: Trying to get logs from node 10.190.211.93 pod pod-1b45c588-a751-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 22:37:22.465: INFO: Waiting for pod pod-1b45c588-a751-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:37:22.480: INFO: Pod pod-1b45c588-a751-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:37:22.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9915" for this suite.
Jul 15 22:37:28.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:37:28.875: INFO: namespace emptydir-9915 deletion completed in 6.372429625s

• [SLOW TEST:8.795 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:37:28.876: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8400
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 22:37:29.127: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2080ae52-a751-11e9-983d-d6ce37abd03c" in namespace "projected-8400" to be "success or failure"
Jul 15 22:37:29.137: INFO: Pod "downwardapi-volume-2080ae52-a751-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.417601ms
Jul 15 22:37:31.156: INFO: Pod "downwardapi-volume-2080ae52-a751-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02825087s
STEP: Saw pod success
Jul 15 22:37:31.156: INFO: Pod "downwardapi-volume-2080ae52-a751-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:37:31.185: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-2080ae52-a751-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 22:37:31.255: INFO: Waiting for pod downwardapi-volume-2080ae52-a751-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:37:31.270: INFO: Pod downwardapi-volume-2080ae52-a751-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:37:31.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8400" for this suite.
Jul 15 22:37:37.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:37:37.783: INFO: namespace projected-8400 deletion completed in 6.495390767s

• [SLOW TEST:8.907 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:37:37.783: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8891
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1423
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 15 22:37:38.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-8891'
Jul 15 22:37:38.129: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 15 22:37:38.129: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jul 15 22:37:40.309: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-4vkkt]
Jul 15 22:37:40.309: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-4vkkt" in namespace "kubectl-8891" to be "running and ready"
Jul 15 22:37:40.319: INFO: Pod "e2e-test-nginx-rc-4vkkt": Phase="Running", Reason="", readiness=true. Elapsed: 10.209907ms
Jul 15 22:37:40.319: INFO: Pod "e2e-test-nginx-rc-4vkkt" satisfied condition "running and ready"
Jul 15 22:37:40.319: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-4vkkt]
Jul 15 22:37:40.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 logs rc/e2e-test-nginx-rc --namespace=kubectl-8891'
Jul 15 22:37:40.491: INFO: stderr: ""
Jul 15 22:37:40.492: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1428
Jul 15 22:37:40.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 delete rc e2e-test-nginx-rc --namespace=kubectl-8891'
Jul 15 22:37:40.646: INFO: stderr: ""
Jul 15 22:37:40.646: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:37:40.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8891" for this suite.
Jul 15 22:38:04.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:38:05.119: INFO: namespace kubectl-8891 deletion completed in 24.458092201s

• [SLOW TEST:27.336 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:38:05.120: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9586
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 22:38:05.351: INFO: Creating deployment "nginx-deployment"
Jul 15 22:38:05.363: INFO: Waiting for observed generation 1
Jul 15 22:38:07.385: INFO: Waiting for all required pods to come up
Jul 15 22:38:07.403: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jul 15 22:38:09.465: INFO: Waiting for deployment "nginx-deployment" to complete
Jul 15 22:38:09.483: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jul 15 22:38:09.503: INFO: Updating deployment nginx-deployment
Jul 15 22:38:09.503: INFO: Waiting for observed generation 2
Jul 15 22:38:11.518: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jul 15 22:38:11.533: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jul 15 22:38:11.543: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jul 15 22:38:11.578: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jul 15 22:38:11.578: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jul 15 22:38:11.589: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jul 15 22:38:11.613: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jul 15 22:38:11.614: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jul 15 22:38:11.632: INFO: Updating deployment nginx-deployment
Jul 15 22:38:11.632: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jul 15 22:38:11.691: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jul 15 22:38:11.707: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 15 22:38:11.729: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-9586,SelfLink:/apis/apps/v1/namespaces/deployment-9586/deployments/nginx-deployment,UID:361bb408-a751-11e9-a496-5e4367ce3703,ResourceVersion:20594,Generation:3,CreationTimestamp:2019-07-15 22:38:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-07-15 22:38:09 +0000 UTC 2019-07-15 22:38:05 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-b79c9d74d" is progressing.} {Available False 2019-07-15 22:38:11 +0000 UTC 2019-07-15 22:38:11 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Jul 15 22:38:11.741: INFO: New ReplicaSet "nginx-deployment-b79c9d74d" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d,GenerateName:,Namespace:deployment-9586,SelfLink:/apis/apps/v1/namespaces/deployment-9586/replicasets/nginx-deployment-b79c9d74d,UID:3894efd0-a751-11e9-a496-5e4367ce3703,ResourceVersion:20580,Generation:3,CreationTimestamp:2019-07-15 22:38:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 361bb408-a751-11e9-a496-5e4367ce3703 0xc00016bdf7 0xc00016bdf8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 15 22:38:11.741: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jul 15 22:38:11.741: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5,GenerateName:,Namespace:deployment-9586,SelfLink:/apis/apps/v1/namespaces/deployment-9586/replicasets/nginx-deployment-85db8c99c5,UID:361e0d76-a751-11e9-a496-5e4367ce3703,ResourceVersion:20573,Generation:3,CreationTimestamp:2019-07-15 22:38:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 361bb408-a751-11e9-a496-5e4367ce3703 0xc00016bb47 0xc00016bb48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jul 15 22:38:11.761: INFO: Pod "nginx-deployment-85db8c99c5-2kxlf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-2kxlf,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-2kxlf,UID:39e316bd-a751-11e9-a496-5e4367ce3703,ResourceVersion:20605,Generation:0,CreationTimestamp:2019-07-15 22:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc0004afe57 0xc0004afe58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.94,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0004aff50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0004aff70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.761: INFO: Pod "nginx-deployment-85db8c99c5-65x88" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-65x88,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-65x88,UID:39df405d-a751-11e9-a496-5e4367ce3703,ResourceVersion:20586,Generation:0,CreationTimestamp:2019-07-15 22:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc0008ce270 0xc0008ce271}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008ce410} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008ce470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.761: INFO: Pod "nginx-deployment-85db8c99c5-7h8m2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-7h8m2,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-7h8m2,UID:36274a16-a751-11e9-a496-5e4367ce3703,ResourceVersion:20447,Generation:0,CreationTimestamp:2019-07-15 22:38:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc0008ce5d0 0xc0008ce5d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.94,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008ce660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008ce680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:05 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.94,PodIP:172.30.176.148,StartTime:2019-07-15 22:38:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-15 22:38:07 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://4aa3d16858449f688c2f49d538fd3586324d742a9f219362db376f7385ad8a1b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.761: INFO: Pod "nginx-deployment-85db8c99c5-8mx6h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-8mx6h,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-8mx6h,UID:39e2ef0a-a751-11e9-a496-5e4367ce3703,ResourceVersion:20600,Generation:0,CreationTimestamp:2019-07-15 22:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc0008ce837 0xc0008ce838}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.91,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008ce8c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008ce8f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.761: INFO: Pod "nginx-deployment-85db8c99c5-c7b2d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-c7b2d,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-c7b2d,UID:39e0f4cc-a751-11e9-a496-5e4367ce3703,ResourceVersion:20588,Generation:0,CreationTimestamp:2019-07-15 22:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc0008ce9b0 0xc0008ce9b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.94,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008cea20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008cea40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.762: INFO: Pod "nginx-deployment-85db8c99c5-dd2p7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-dd2p7,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-dd2p7,UID:39e0f2f1-a751-11e9-a496-5e4367ce3703,ResourceVersion:20604,Generation:0,CreationTimestamp:2019-07-15 22:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc0008ceb30 0xc0008ceb31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008ceba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008cebd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:11 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.93,PodIP:,StartTime:2019-07-15 22:38:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.762: INFO: Pod "nginx-deployment-85db8c99c5-f6l69" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-f6l69,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-f6l69,UID:39e2f875-a751-11e9-a496-5e4367ce3703,ResourceVersion:20606,Generation:0,CreationTimestamp:2019-07-15 22:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc0008ceca7 0xc0008ceca8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.91,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008ced80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008ceda0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.762: INFO: Pod "nginx-deployment-85db8c99c5-fcnh4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-fcnh4,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-fcnh4,UID:362a5a5a-a751-11e9-a496-5e4367ce3703,ResourceVersion:20437,Generation:0,CreationTimestamp:2019-07-15 22:38:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc0008cee20 0xc0008cee21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.91,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008ceea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008ceec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:05 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.91,PodIP:172.30.43.229,StartTime:2019-07-15 22:38:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-15 22:38:07 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://298565524f1913635ed95ae19da016f7fc82e253a35a8e8f39819daca168647f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.762: INFO: Pod "nginx-deployment-85db8c99c5-hzczj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-hzczj,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-hzczj,UID:39e56b32-a751-11e9-a496-5e4367ce3703,ResourceVersion:20590,Generation:0,CreationTimestamp:2019-07-15 22:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc0008cf007 0xc0008cf008}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008cf070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008cf090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.762: INFO: Pod "nginx-deployment-85db8c99c5-jpz2z" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-jpz2z,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-jpz2z,UID:36241544-a751-11e9-a496-5e4367ce3703,ResourceVersion:20440,Generation:0,CreationTimestamp:2019-07-15 22:38:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc0008cf107 0xc0008cf108}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.91,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008cf1a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008cf1c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:05 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.91,PodIP:172.30.43.228,StartTime:2019-07-15 22:38:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-15 22:38:06 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://71e7847e32815007dc3fde57a94fa61388029d53a472f7cc643b7d7bf7a7de14}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.763: INFO: Pod "nginx-deployment-85db8c99c5-kv27k" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-kv27k,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-kv27k,UID:36274c46-a751-11e9-a496-5e4367ce3703,ResourceVersion:20452,Generation:0,CreationTimestamp:2019-07-15 22:38:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc0008cf3c7 0xc0008cf3c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008cf450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008cf470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:05 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.93,PodIP:172.30.19.1,StartTime:2019-07-15 22:38:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-15 22:38:07 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://e80691e0af86c5f782e7d8ef7f2dfeea4454b5ea6c3c1d2c57f015833f19821f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.763: INFO: Pod "nginx-deployment-85db8c99c5-mphdb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-mphdb,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-mphdb,UID:3620ed85-a751-11e9-a496-5e4367ce3703,ResourceVersion:20424,Generation:0,CreationTimestamp:2019-07-15 22:38:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc0008cf550 0xc0008cf551}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008cf5c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008cf5e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:05 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.93,PodIP:172.30.19.61,StartTime:2019-07-15 22:38:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-15 22:38:06 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://4028d501c25294776db1a51f59c9da92250e5152dc4eb8d6b3543eb1fee721c1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.763: INFO: Pod "nginx-deployment-85db8c99c5-p5lf5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-p5lf5,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-p5lf5,UID:39e56f2c-a751-11e9-a496-5e4367ce3703,ResourceVersion:20596,Generation:0,CreationTimestamp:2019-07-15 22:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc0008cf6d7 0xc0008cf6d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008cf750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008cf770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.763: INFO: Pod "nginx-deployment-85db8c99c5-pjkb8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-pjkb8,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-pjkb8,UID:39e5b44a-a751-11e9-a496-5e4367ce3703,ResourceVersion:20597,Generation:0,CreationTimestamp:2019-07-15 22:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc0008cf7d7 0xc0008cf7d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008cf840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008cf870}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.763: INFO: Pod "nginx-deployment-85db8c99c5-qfkbf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-qfkbf,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-qfkbf,UID:39e2f762-a751-11e9-a496-5e4367ce3703,ResourceVersion:20582,Generation:0,CreationTimestamp:2019-07-15 22:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc0008cf8d7 0xc0008cf8d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008cfa20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008cfae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.763: INFO: Pod "nginx-deployment-85db8c99c5-qvffv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-qvffv,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-qvffv,UID:362a6100-a751-11e9-a496-5e4367ce3703,ResourceVersion:20460,Generation:0,CreationTimestamp:2019-07-15 22:38:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc0008cfb57 0xc0008cfb58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008cfc80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008cfca0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:05 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.93,PodIP:172.30.19.6,StartTime:2019-07-15 22:38:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-15 22:38:07 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://53c87b74d3662267fd2d4541d32ac67902707bae9098fc8c88d38b96d37a5a4b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.764: INFO: Pod "nginx-deployment-85db8c99c5-sftkf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-sftkf,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-sftkf,UID:362a5ad1-a751-11e9-a496-5e4367ce3703,ResourceVersion:20464,Generation:0,CreationTimestamp:2019-07-15 22:38:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc0008cfe40 0xc0008cfe41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008cfeb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008cfed0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:05 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.93,PodIP:172.30.19.63,StartTime:2019-07-15 22:38:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-15 22:38:07 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://cf4320f6afcc71f66607fe1cbd6a6371fded9e72ea04be99083b666614f8e78c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.764: INFO: Pod "nginx-deployment-85db8c99c5-tb5cg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-tb5cg,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-tb5cg,UID:39e5585d-a751-11e9-a496-5e4367ce3703,ResourceVersion:20592,Generation:0,CreationTimestamp:2019-07-15 22:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc000fdc077 0xc000fdc078}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fdc0e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fdc100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.764: INFO: Pod "nginx-deployment-85db8c99c5-vg2sj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-vg2sj,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-vg2sj,UID:36279f5c-a751-11e9-a496-5e4367ce3703,ResourceVersion:20443,Generation:0,CreationTimestamp:2019-07-15 22:38:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc000fdc167 0xc000fdc168}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.94,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fdc220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fdc240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:05 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.94,PodIP:172.30.176.147,StartTime:2019-07-15 22:38:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-15 22:38:06 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://fc52f31b2f099405d8f72540058b4b7d1462afd06f0df26cb0462abc0140c352}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.764: INFO: Pod "nginx-deployment-85db8c99c5-vj9mm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-vj9mm,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-85db8c99c5-vj9mm,UID:39e55b48-a751-11e9-a496-5e4367ce3703,ResourceVersion:20591,Generation:0,CreationTimestamp:2019-07-15 22:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 361e0d76-a751-11e9-a496-5e4367ce3703 0xc000fdc317 0xc000fdc318}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fdc380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fdc3a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.764: INFO: Pod "nginx-deployment-b79c9d74d-hf672" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-hf672,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-b79c9d74d-hf672,UID:38a48d25-a751-11e9-a496-5e4367ce3703,ResourceVersion:20565,Generation:0,CreationTimestamp:2019-07-15 22:38:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 3894efd0-a751-11e9-a496-5e4367ce3703 0xc000fdc407 0xc000fdc408}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fdc480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fdc4a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.93,PodIP:172.30.19.8,StartTime:2019-07-15 22:38:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.765: INFO: Pod "nginx-deployment-b79c9d74d-j28rd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-j28rd,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-b79c9d74d-j28rd,UID:39e52b57-a751-11e9-a496-5e4367ce3703,ResourceVersion:20593,Generation:0,CreationTimestamp:2019-07-15 22:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 3894efd0-a751-11e9-a496-5e4367ce3703 0xc000fdc590 0xc000fdc591}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fdc600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fdc620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.765: INFO: Pod "nginx-deployment-b79c9d74d-mps7w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-mps7w,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-b79c9d74d-mps7w,UID:3896c87e-a751-11e9-a496-5e4367ce3703,ResourceVersion:20567,Generation:0,CreationTimestamp:2019-07-15 22:38:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 3894efd0-a751-11e9-a496-5e4367ce3703 0xc000fdc687 0xc000fdc688}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fdc700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fdc720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.93,PodIP:172.30.19.7,StartTime:2019-07-15 22:38:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.765: INFO: Pod "nginx-deployment-b79c9d74d-mv4gf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-mv4gf,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-b79c9d74d-mv4gf,UID:389962e8-a751-11e9-a496-5e4367ce3703,ResourceVersion:20572,Generation:0,CreationTimestamp:2019-07-15 22:38:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 3894efd0-a751-11e9-a496-5e4367ce3703 0xc000fdc810 0xc000fdc811}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.91,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fdc890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fdc8b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.91,PodIP:172.30.43.230,StartTime:2019-07-15 22:38:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.766: INFO: Pod "nginx-deployment-b79c9d74d-nmpp9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-nmpp9,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-b79c9d74d-nmpp9,UID:38995d7c-a751-11e9-a496-5e4367ce3703,ResourceVersion:20498,Generation:0,CreationTimestamp:2019-07-15 22:38:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 3894efd0-a751-11e9-a496-5e4367ce3703 0xc000fdc9a0 0xc000fdc9a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.94,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fdca20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fdca40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.94,PodIP:,StartTime:2019-07-15 22:38:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.766: INFO: Pod "nginx-deployment-b79c9d74d-s2cs9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-s2cs9,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-b79c9d74d-s2cs9,UID:38a8a75d-a751-11e9-a496-5e4367ce3703,ResourceVersion:20564,Generation:0,CreationTimestamp:2019-07-15 22:38:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 3894efd0-a751-11e9-a496-5e4367ce3703 0xc000fdcb10 0xc000fdcb11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fdcb90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fdcbb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:38:09 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.93,PodIP:172.30.19.9,StartTime:2019-07-15 22:38:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.766: INFO: Pod "nginx-deployment-b79c9d74d-xnmm5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-xnmm5,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-b79c9d74d-xnmm5,UID:39e86c72-a751-11e9-a496-5e4367ce3703,ResourceVersion:20599,Generation:0,CreationTimestamp:2019-07-15 22:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 3894efd0-a751-11e9-a496-5e4367ce3703 0xc000fdccc0 0xc000fdccc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fdcd30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fdcd50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 22:38:11.766: INFO: Pod "nginx-deployment-b79c9d74d-zgrc2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-zgrc2,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9586,SelfLink:/api/v1/namespaces/deployment-9586/pods/nginx-deployment-b79c9d74d-zgrc2,UID:39e87fb0-a751-11e9-a496-5e4367ce3703,ResourceVersion:20601,Generation:0,CreationTimestamp:2019-07-15 22:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 3894efd0-a751-11e9-a496-5e4367ce3703 0xc000fdcdc7 0xc000fdcdc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bkch2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bkch2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bkch2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fdce30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fdce50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:38:11.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9586" for this suite.
Jul 15 22:38:19.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:38:20.241: INFO: namespace deployment-9586 deletion completed in 8.440412922s

• [SLOW TEST:15.122 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:38:20.242: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8747
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 22:38:20.529: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3f250a94-a751-11e9-983d-d6ce37abd03c" in namespace "projected-8747" to be "success or failure"
Jul 15 22:38:20.539: INFO: Pod "downwardapi-volume-3f250a94-a751-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.141741ms
Jul 15 22:38:22.561: INFO: Pod "downwardapi-volume-3f250a94-a751-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031851227s
STEP: Saw pod success
Jul 15 22:38:22.561: INFO: Pod "downwardapi-volume-3f250a94-a751-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:38:22.571: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-3f250a94-a751-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 22:38:22.647: INFO: Waiting for pod downwardapi-volume-3f250a94-a751-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:38:22.658: INFO: Pod downwardapi-volume-3f250a94-a751-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:38:22.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8747" for this suite.
Jul 15 22:38:28.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:38:29.065: INFO: namespace projected-8747 deletion completed in 6.392926541s

• [SLOW TEST:8.824 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:38:29.067: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-6572
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Jul 15 22:38:29.340: INFO: Waiting up to 5m0s for pod "var-expansion-44652bc0-a751-11e9-983d-d6ce37abd03c" in namespace "var-expansion-6572" to be "success or failure"
Jul 15 22:38:29.351: INFO: Pod "var-expansion-44652bc0-a751-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.315993ms
Jul 15 22:38:31.363: INFO: Pod "var-expansion-44652bc0-a751-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022790976s
STEP: Saw pod success
Jul 15 22:38:31.363: INFO: Pod "var-expansion-44652bc0-a751-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:38:31.374: INFO: Trying to get logs from node 10.190.211.93 pod var-expansion-44652bc0-a751-11e9-983d-d6ce37abd03c container dapi-container: <nil>
STEP: delete the pod
Jul 15 22:38:31.441: INFO: Waiting for pod var-expansion-44652bc0-a751-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:38:31.451: INFO: Pod var-expansion-44652bc0-a751-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:38:31.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6572" for this suite.
Jul 15 22:38:37.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:38:38.015: INFO: namespace var-expansion-6572 deletion completed in 6.371683371s

• [SLOW TEST:8.948 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:38:38.016: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7566
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jul 15 22:38:38.262: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7566,SelfLink:/api/v1/namespaces/watch-7566/configmaps/e2e-watch-test-watch-closed,UID:49b5d8e5-a751-11e9-a496-5e4367ce3703,ResourceVersion:21178,Generation:0,CreationTimestamp:2019-07-15 22:38:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 15 22:38:38.263: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7566,SelfLink:/api/v1/namespaces/watch-7566/configmaps/e2e-watch-test-watch-closed,UID:49b5d8e5-a751-11e9-a496-5e4367ce3703,ResourceVersion:21179,Generation:0,CreationTimestamp:2019-07-15 22:38:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jul 15 22:38:38.301: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7566,SelfLink:/api/v1/namespaces/watch-7566/configmaps/e2e-watch-test-watch-closed,UID:49b5d8e5-a751-11e9-a496-5e4367ce3703,ResourceVersion:21180,Generation:0,CreationTimestamp:2019-07-15 22:38:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 15 22:38:38.301: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7566,SelfLink:/api/v1/namespaces/watch-7566/configmaps/e2e-watch-test-watch-closed,UID:49b5d8e5-a751-11e9-a496-5e4367ce3703,ResourceVersion:21181,Generation:0,CreationTimestamp:2019-07-15 22:38:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:38:38.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7566" for this suite.
Jul 15 22:38:44.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:38:44.710: INFO: namespace watch-7566 deletion completed in 6.39785927s

• [SLOW TEST:6.695 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:38:44.712: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2653
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Jul 15 22:38:44.984: INFO: Waiting up to 5m0s for pod "client-containers-4db6ffcb-a751-11e9-983d-d6ce37abd03c" in namespace "containers-2653" to be "success or failure"
Jul 15 22:38:44.994: INFO: Pod "client-containers-4db6ffcb-a751-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.289979ms
Jul 15 22:38:47.006: INFO: Pod "client-containers-4db6ffcb-a751-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021903173s
STEP: Saw pod success
Jul 15 22:38:47.006: INFO: Pod "client-containers-4db6ffcb-a751-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:38:47.015: INFO: Trying to get logs from node 10.190.211.93 pod client-containers-4db6ffcb-a751-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 22:38:47.067: INFO: Waiting for pod client-containers-4db6ffcb-a751-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:38:47.076: INFO: Pod client-containers-4db6ffcb-a751-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:38:47.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2653" for this suite.
Jul 15 22:38:53.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:38:53.663: INFO: namespace containers-2653 deletion completed in 6.573666265s

• [SLOW TEST:8.951 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:38:53.663: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-375
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-5309bc8d-a751-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume configMaps
Jul 15 22:38:53.916: INFO: Waiting up to 5m0s for pod "pod-configmaps-530b33ad-a751-11e9-983d-d6ce37abd03c" in namespace "configmap-375" to be "success or failure"
Jul 15 22:38:53.933: INFO: Pod "pod-configmaps-530b33ad-a751-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.976916ms
Jul 15 22:38:55.944: INFO: Pod "pod-configmaps-530b33ad-a751-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027425755s
STEP: Saw pod success
Jul 15 22:38:55.944: INFO: Pod "pod-configmaps-530b33ad-a751-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:38:55.956: INFO: Trying to get logs from node 10.190.211.93 pod pod-configmaps-530b33ad-a751-11e9-983d-d6ce37abd03c container configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 22:38:56.015: INFO: Waiting for pod pod-configmaps-530b33ad-a751-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:38:56.025: INFO: Pod pod-configmaps-530b33ad-a751-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:38:56.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-375" for this suite.
Jul 15 22:39:02.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:39:02.425: INFO: namespace configmap-375 deletion completed in 6.380316813s

• [SLOW TEST:8.763 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:39:02.427: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1006
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Jul 15 22:39:02.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 create -f - --namespace=kubectl-1006'
Jul 15 22:39:03.050: INFO: stderr: ""
Jul 15 22:39:03.050: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 15 22:39:03.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1006'
Jul 15 22:39:03.171: INFO: stderr: ""
Jul 15 22:39:03.171: INFO: stdout: "update-demo-nautilus-gf7nz update-demo-nautilus-hw2bh "
Jul 15 22:39:03.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-gf7nz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1006'
Jul 15 22:39:03.284: INFO: stderr: ""
Jul 15 22:39:03.284: INFO: stdout: ""
Jul 15 22:39:03.284: INFO: update-demo-nautilus-gf7nz is created but not running
Jul 15 22:39:08.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1006'
Jul 15 22:39:08.416: INFO: stderr: ""
Jul 15 22:39:08.416: INFO: stdout: "update-demo-nautilus-gf7nz update-demo-nautilus-hw2bh "
Jul 15 22:39:08.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-gf7nz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1006'
Jul 15 22:39:08.524: INFO: stderr: ""
Jul 15 22:39:08.524: INFO: stdout: "true"
Jul 15 22:39:08.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-gf7nz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1006'
Jul 15 22:39:08.651: INFO: stderr: ""
Jul 15 22:39:08.651: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 22:39:08.651: INFO: validating pod update-demo-nautilus-gf7nz
Jul 15 22:39:08.674: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 22:39:08.674: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 22:39:08.674: INFO: update-demo-nautilus-gf7nz is verified up and running
Jul 15 22:39:08.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-hw2bh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1006'
Jul 15 22:39:08.794: INFO: stderr: ""
Jul 15 22:39:08.794: INFO: stdout: "true"
Jul 15 22:39:08.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-hw2bh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1006'
Jul 15 22:39:08.904: INFO: stderr: ""
Jul 15 22:39:08.904: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 22:39:08.904: INFO: validating pod update-demo-nautilus-hw2bh
Jul 15 22:39:08.922: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 22:39:08.922: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 22:39:08.922: INFO: update-demo-nautilus-hw2bh is verified up and running
STEP: scaling down the replication controller
Jul 15 22:39:08.924: INFO: scanned /root for discovery docs: <nil>
Jul 15 22:39:08.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1006'
Jul 15 22:39:10.129: INFO: stderr: ""
Jul 15 22:39:10.129: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 15 22:39:10.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1006'
Jul 15 22:39:10.241: INFO: stderr: ""
Jul 15 22:39:10.241: INFO: stdout: "update-demo-nautilus-gf7nz update-demo-nautilus-hw2bh "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jul 15 22:39:15.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1006'
Jul 15 22:39:15.368: INFO: stderr: ""
Jul 15 22:39:15.368: INFO: stdout: "update-demo-nautilus-gf7nz update-demo-nautilus-hw2bh "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jul 15 22:39:20.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1006'
Jul 15 22:39:20.482: INFO: stderr: ""
Jul 15 22:39:20.482: INFO: stdout: "update-demo-nautilus-gf7nz update-demo-nautilus-hw2bh "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jul 15 22:39:25.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1006'
Jul 15 22:39:25.601: INFO: stderr: ""
Jul 15 22:39:25.601: INFO: stdout: "update-demo-nautilus-gf7nz "
Jul 15 22:39:25.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-gf7nz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1006'
Jul 15 22:39:25.719: INFO: stderr: ""
Jul 15 22:39:25.719: INFO: stdout: "true"
Jul 15 22:39:25.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-gf7nz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1006'
Jul 15 22:39:25.845: INFO: stderr: ""
Jul 15 22:39:25.845: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 22:39:25.845: INFO: validating pod update-demo-nautilus-gf7nz
Jul 15 22:39:25.859: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 22:39:25.859: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 22:39:25.859: INFO: update-demo-nautilus-gf7nz is verified up and running
STEP: scaling up the replication controller
Jul 15 22:39:25.861: INFO: scanned /root for discovery docs: <nil>
Jul 15 22:39:25.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1006'
Jul 15 22:39:27.041: INFO: stderr: ""
Jul 15 22:39:27.041: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 15 22:39:27.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1006'
Jul 15 22:39:27.161: INFO: stderr: ""
Jul 15 22:39:27.161: INFO: stdout: "update-demo-nautilus-gf7nz update-demo-nautilus-x4jfp "
Jul 15 22:39:27.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-gf7nz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1006'
Jul 15 22:39:27.284: INFO: stderr: ""
Jul 15 22:39:27.284: INFO: stdout: "true"
Jul 15 22:39:27.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-gf7nz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1006'
Jul 15 22:39:27.405: INFO: stderr: ""
Jul 15 22:39:27.405: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 22:39:27.405: INFO: validating pod update-demo-nautilus-gf7nz
Jul 15 22:39:27.420: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 22:39:27.420: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 22:39:27.420: INFO: update-demo-nautilus-gf7nz is verified up and running
Jul 15 22:39:27.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-x4jfp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1006'
Jul 15 22:39:27.531: INFO: stderr: ""
Jul 15 22:39:27.531: INFO: stdout: ""
Jul 15 22:39:27.531: INFO: update-demo-nautilus-x4jfp is created but not running
Jul 15 22:39:32.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1006'
Jul 15 22:39:32.649: INFO: stderr: ""
Jul 15 22:39:32.649: INFO: stdout: "update-demo-nautilus-gf7nz update-demo-nautilus-x4jfp "
Jul 15 22:39:32.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-gf7nz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1006'
Jul 15 22:39:32.765: INFO: stderr: ""
Jul 15 22:39:32.765: INFO: stdout: "true"
Jul 15 22:39:32.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-gf7nz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1006'
Jul 15 22:39:32.896: INFO: stderr: ""
Jul 15 22:39:32.896: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 22:39:32.896: INFO: validating pod update-demo-nautilus-gf7nz
Jul 15 22:39:32.916: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 22:39:32.916: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 22:39:32.916: INFO: update-demo-nautilus-gf7nz is verified up and running
Jul 15 22:39:32.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-x4jfp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1006'
Jul 15 22:39:33.027: INFO: stderr: ""
Jul 15 22:39:33.027: INFO: stdout: "true"
Jul 15 22:39:33.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-x4jfp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1006'
Jul 15 22:39:33.137: INFO: stderr: ""
Jul 15 22:39:33.137: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 22:39:33.137: INFO: validating pod update-demo-nautilus-x4jfp
Jul 15 22:39:33.155: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 22:39:33.155: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 22:39:33.155: INFO: update-demo-nautilus-x4jfp is verified up and running
STEP: using delete to clean up resources
Jul 15 22:39:33.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 delete --grace-period=0 --force -f - --namespace=kubectl-1006'
Jul 15 22:39:33.296: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 22:39:33.296: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jul 15 22:39:33.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1006'
Jul 15 22:39:33.404: INFO: stderr: "No resources found.\n"
Jul 15 22:39:33.404: INFO: stdout: ""
Jul 15 22:39:33.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -l name=update-demo --namespace=kubectl-1006 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 15 22:39:33.525: INFO: stderr: ""
Jul 15 22:39:33.525: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:39:33.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1006" for this suite.
Jul 15 22:39:57.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:39:58.065: INFO: namespace kubectl-1006 deletion completed in 24.526085304s

• [SLOW TEST:55.639 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:39:58.066: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6950
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jul 15 22:40:02.964: INFO: Successfully updated pod "annotationupdate796e67ef-a751-11e9-983d-d6ce37abd03c"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:40:05.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6950" for this suite.
Jul 15 22:40:29.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:40:29.428: INFO: namespace projected-6950 deletion completed in 24.400207353s

• [SLOW TEST:31.363 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:40:29.428: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9659
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-8c204307-a751-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume configMaps
Jul 15 22:40:29.703: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8c21b56d-a751-11e9-983d-d6ce37abd03c" in namespace "projected-9659" to be "success or failure"
Jul 15 22:40:29.719: INFO: Pod "pod-projected-configmaps-8c21b56d-a751-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.054595ms
Jul 15 22:40:31.733: INFO: Pod "pod-projected-configmaps-8c21b56d-a751-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030333114s
STEP: Saw pod success
Jul 15 22:40:31.733: INFO: Pod "pod-projected-configmaps-8c21b56d-a751-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:40:31.748: INFO: Trying to get logs from node 10.190.211.93 pod pod-projected-configmaps-8c21b56d-a751-11e9-983d-d6ce37abd03c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 22:40:31.825: INFO: Waiting for pod pod-projected-configmaps-8c21b56d-a751-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:40:31.835: INFO: Pod pod-projected-configmaps-8c21b56d-a751-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:40:31.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9659" for this suite.
Jul 15 22:40:37.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:40:38.458: INFO: namespace projected-9659 deletion completed in 6.610233521s

• [SLOW TEST:9.030 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:40:38.458: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5343
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 22:40:38.679: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jul 15 22:40:38.707: INFO: Pod name sample-pod: Found 0 pods out of 1
Jul 15 22:40:43.720: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul 15 22:40:43.720: INFO: Creating deployment "test-rolling-update-deployment"
Jul 15 22:40:43.730: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jul 15 22:40:43.754: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jul 15 22:40:45.774: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jul 15 22:40:45.783: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 15 22:40:45.822: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-5343,SelfLink:/apis/apps/v1/namespaces/deployment-5343/deployments/test-rolling-update-deployment,UID:9480d7b8-a751-11e9-a496-5e4367ce3703,ResourceVersion:21719,Generation:1,CreationTimestamp:2019-07-15 22:40:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-07-15 22:40:43 +0000 UTC 2019-07-15 22:40:43 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-07-15 22:40:45 +0000 UTC 2019-07-15 22:40:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-57b6b5bb54" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jul 15 22:40:45.836: INFO: New ReplicaSet "test-rolling-update-deployment-57b6b5bb54" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54,GenerateName:,Namespace:deployment-5343,SelfLink:/apis/apps/v1/namespaces/deployment-5343/replicasets/test-rolling-update-deployment-57b6b5bb54,UID:9485cbf4-a751-11e9-a496-5e4367ce3703,ResourceVersion:21708,Generation:1,CreationTimestamp:2019-07-15 22:40:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 9480d7b8-a751-11e9-a496-5e4367ce3703 0xc002887487 0xc002887488}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul 15 22:40:45.836: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jul 15 22:40:45.836: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-5343,SelfLink:/apis/apps/v1/namespaces/deployment-5343/replicasets/test-rolling-update-controller,UID:917f9572-a751-11e9-a496-5e4367ce3703,ResourceVersion:21718,Generation:2,CreationTimestamp:2019-07-15 22:40:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 9480d7b8-a751-11e9-a496-5e4367ce3703 0xc0028873b7 0xc0028873b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 15 22:40:45.847: INFO: Pod "test-rolling-update-deployment-57b6b5bb54-6kkmf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54-6kkmf,GenerateName:test-rolling-update-deployment-57b6b5bb54-,Namespace:deployment-5343,SelfLink:/api/v1/namespaces/deployment-5343/pods/test-rolling-update-deployment-57b6b5bb54-6kkmf,UID:94882cb1-a751-11e9-a496-5e4367ce3703,ResourceVersion:21707,Generation:0,CreationTimestamp:2019-07-15 22:40:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-57b6b5bb54 9485cbf4-a751-11e9-a496-5e4367ce3703 0xc00283ed67 0xc00283ed68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-g7ccw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g7ccw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-g7ccw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00283edf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00283ee10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:40:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:40:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:40:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:40:43 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.93,PodIP:172.30.19.25,StartTime:2019-07-15 22:40:43 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-07-15 22:40:45 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://64ac9ae83e7f5cd58b5478332cfe34cb609dfcbb79da8542f569d0b35df12142}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:40:45.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5343" for this suite.
Jul 15 22:40:53.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:40:54.246: INFO: namespace deployment-5343 deletion completed in 8.386607964s

• [SLOW TEST:15.788 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:40:54.247: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9251
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jul 15 22:40:54.496: INFO: Waiting up to 5m0s for pod "pod-9aea8e35-a751-11e9-983d-d6ce37abd03c" in namespace "emptydir-9251" to be "success or failure"
Jul 15 22:40:54.511: INFO: Pod "pod-9aea8e35-a751-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.50655ms
Jul 15 22:40:56.523: INFO: Pod "pod-9aea8e35-a751-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026358262s
Jul 15 22:40:58.536: INFO: Pod "pod-9aea8e35-a751-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039836376s
STEP: Saw pod success
Jul 15 22:40:58.536: INFO: Pod "pod-9aea8e35-a751-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:40:58.546: INFO: Trying to get logs from node 10.190.211.93 pod pod-9aea8e35-a751-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 22:40:58.624: INFO: Waiting for pod pod-9aea8e35-a751-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:40:58.635: INFO: Pod pod-9aea8e35-a751-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:40:58.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9251" for this suite.
Jul 15 22:41:04.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:41:05.030: INFO: namespace emptydir-9251 deletion completed in 6.382899935s

• [SLOW TEST:10.784 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:41:05.031: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9685
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-a15834f9-a751-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume configMaps
Jul 15 22:41:05.300: INFO: Waiting up to 5m0s for pod "pod-configmaps-a159822d-a751-11e9-983d-d6ce37abd03c" in namespace "configmap-9685" to be "success or failure"
Jul 15 22:41:05.316: INFO: Pod "pod-configmaps-a159822d-a751-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.122426ms
Jul 15 22:41:07.328: INFO: Pod "pod-configmaps-a159822d-a751-11e9-983d-d6ce37abd03c": Phase="Running", Reason="", readiness=true. Elapsed: 2.028255237s
Jul 15 22:41:09.343: INFO: Pod "pod-configmaps-a159822d-a751-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043159561s
STEP: Saw pod success
Jul 15 22:41:09.343: INFO: Pod "pod-configmaps-a159822d-a751-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:41:09.355: INFO: Trying to get logs from node 10.190.211.93 pod pod-configmaps-a159822d-a751-11e9-983d-d6ce37abd03c container configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 22:41:09.427: INFO: Waiting for pod pod-configmaps-a159822d-a751-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:41:09.441: INFO: Pod pod-configmaps-a159822d-a751-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:41:09.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9685" for this suite.
Jul 15 22:41:15.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:41:15.898: INFO: namespace configmap-9685 deletion completed in 6.442526717s

• [SLOW TEST:10.867 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:41:15.898: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8076
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:41:19.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8076" for this suite.
Jul 15 22:41:43.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:41:43.643: INFO: namespace replication-controller-8076 deletion completed in 24.37256073s

• [SLOW TEST:27.744 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:41:43.643: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7263
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-b85a0c81-a751-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume secrets
Jul 15 22:41:43.895: INFO: Waiting up to 5m0s for pod "pod-secrets-b85c38c1-a751-11e9-983d-d6ce37abd03c" in namespace "secrets-7263" to be "success or failure"
Jul 15 22:41:43.910: INFO: Pod "pod-secrets-b85c38c1-a751-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.744642ms
Jul 15 22:41:45.922: INFO: Pod "pod-secrets-b85c38c1-a751-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02709669s
STEP: Saw pod success
Jul 15 22:41:45.922: INFO: Pod "pod-secrets-b85c38c1-a751-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:41:45.935: INFO: Trying to get logs from node 10.190.211.93 pod pod-secrets-b85c38c1-a751-11e9-983d-d6ce37abd03c container secret-volume-test: <nil>
STEP: delete the pod
Jul 15 22:41:45.997: INFO: Waiting for pod pod-secrets-b85c38c1-a751-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:41:46.008: INFO: Pod pod-secrets-b85c38c1-a751-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:41:46.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7263" for this suite.
Jul 15 22:41:52.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:41:52.386: INFO: namespace secrets-7263 deletion completed in 6.365795842s

• [SLOW TEST:8.743 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:41:52.387: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1813
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Jul 15 22:41:52.626: INFO: Waiting up to 5m0s for pod "pod-bd90488c-a751-11e9-983d-d6ce37abd03c" in namespace "emptydir-1813" to be "success or failure"
Jul 15 22:41:52.640: INFO: Pod "pod-bd90488c-a751-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.856067ms
Jul 15 22:41:54.651: INFO: Pod "pod-bd90488c-a751-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025685802s
Jul 15 22:41:56.661: INFO: Pod "pod-bd90488c-a751-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035707415s
STEP: Saw pod success
Jul 15 22:41:56.661: INFO: Pod "pod-bd90488c-a751-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:41:56.672: INFO: Trying to get logs from node 10.190.211.93 pod pod-bd90488c-a751-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 22:41:56.731: INFO: Waiting for pod pod-bd90488c-a751-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:41:56.743: INFO: Pod pod-bd90488c-a751-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:41:56.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1813" for this suite.
Jul 15 22:42:02.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:42:03.181: INFO: namespace emptydir-1813 deletion completed in 6.421873381s

• [SLOW TEST:10.795 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:42:03.182: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3095
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-x55x
STEP: Creating a pod to test atomic-volume-subpath
Jul 15 22:42:03.456: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-x55x" in namespace "subpath-3095" to be "success or failure"
Jul 15 22:42:03.470: INFO: Pod "pod-subpath-test-configmap-x55x": Phase="Pending", Reason="", readiness=false. Elapsed: 14.350609ms
Jul 15 22:42:05.481: INFO: Pod "pod-subpath-test-configmap-x55x": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025682442s
Jul 15 22:42:07.494: INFO: Pod "pod-subpath-test-configmap-x55x": Phase="Running", Reason="", readiness=true. Elapsed: 4.038276009s
Jul 15 22:42:09.508: INFO: Pod "pod-subpath-test-configmap-x55x": Phase="Running", Reason="", readiness=true. Elapsed: 6.052422607s
Jul 15 22:42:11.519: INFO: Pod "pod-subpath-test-configmap-x55x": Phase="Running", Reason="", readiness=true. Elapsed: 8.063078951s
Jul 15 22:42:13.530: INFO: Pod "pod-subpath-test-configmap-x55x": Phase="Running", Reason="", readiness=true. Elapsed: 10.074542976s
Jul 15 22:42:15.545: INFO: Pod "pod-subpath-test-configmap-x55x": Phase="Running", Reason="", readiness=true. Elapsed: 12.0892802s
Jul 15 22:42:17.557: INFO: Pod "pod-subpath-test-configmap-x55x": Phase="Running", Reason="", readiness=true. Elapsed: 14.101173233s
Jul 15 22:42:19.571: INFO: Pod "pod-subpath-test-configmap-x55x": Phase="Running", Reason="", readiness=true. Elapsed: 16.115702379s
Jul 15 22:42:21.582: INFO: Pod "pod-subpath-test-configmap-x55x": Phase="Running", Reason="", readiness=true. Elapsed: 18.126363674s
Jul 15 22:42:23.594: INFO: Pod "pod-subpath-test-configmap-x55x": Phase="Running", Reason="", readiness=true. Elapsed: 20.13825185s
Jul 15 22:42:25.604: INFO: Pod "pod-subpath-test-configmap-x55x": Phase="Running", Reason="", readiness=true. Elapsed: 22.148743605s
Jul 15 22:42:27.615: INFO: Pod "pod-subpath-test-configmap-x55x": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.159118076s
STEP: Saw pod success
Jul 15 22:42:27.615: INFO: Pod "pod-subpath-test-configmap-x55x" satisfied condition "success or failure"
Jul 15 22:42:27.626: INFO: Trying to get logs from node 10.190.211.93 pod pod-subpath-test-configmap-x55x container test-container-subpath-configmap-x55x: <nil>
STEP: delete the pod
Jul 15 22:42:27.690: INFO: Waiting for pod pod-subpath-test-configmap-x55x to disappear
Jul 15 22:42:27.699: INFO: Pod pod-subpath-test-configmap-x55x no longer exists
STEP: Deleting pod pod-subpath-test-configmap-x55x
Jul 15 22:42:27.699: INFO: Deleting pod "pod-subpath-test-configmap-x55x" in namespace "subpath-3095"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:42:27.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3095" for this suite.
Jul 15 22:42:33.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:42:34.473: INFO: namespace subpath-3095 deletion completed in 6.685582357s

• [SLOW TEST:31.292 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:42:34.474: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6827
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6827
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-6827
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6827
Jul 15 22:42:34.812: INFO: Found 0 stateful pods, waiting for 1
Jul 15 22:42:44.824: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jul 15 22:42:44.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 22:42:45.285: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 15 22:42:45.285: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 22:42:45.285: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 22:42:45.297: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jul 15 22:42:55.315: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 15 22:42:55.315: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 22:42:55.363: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jul 15 22:42:55.363: INFO: ss-0  10.190.211.93  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:34 +0000 UTC  }]
Jul 15 22:42:55.363: INFO: 
Jul 15 22:42:55.363: INFO: StatefulSet ss has not reached scale 3, at 1
Jul 15 22:42:56.377: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.989635998s
Jul 15 22:42:57.388: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.975472306s
Jul 15 22:42:58.583: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.964852668s
Jul 15 22:42:59.593: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.76953804s
Jul 15 22:43:00.606: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.759514586s
Jul 15 22:43:01.618: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.74681612s
Jul 15 22:43:02.631: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.734627119s
Jul 15 22:43:03.641: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.721124363s
Jul 15 22:43:04.655: INFO: Verifying statefulset ss doesn't scale past 3 for another 710.964336ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6827
Jul 15 22:43:05.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:43:06.123: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 15 22:43:06.123: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 22:43:06.123: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 15 22:43:06.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:43:06.571: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jul 15 22:43:06.571: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 22:43:06.571: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 15 22:43:06.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:43:07.172: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jul 15 22:43:07.172: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 22:43:07.172: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 15 22:43:07.186: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Jul 15 22:43:17.200: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 22:43:17.200: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 22:43:17.200: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jul 15 22:43:17.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 22:43:17.632: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 15 22:43:17.632: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 22:43:17.632: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 22:43:17.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 22:43:18.091: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 15 22:43:18.091: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 22:43:18.091: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 22:43:18.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 22:43:18.555: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 15 22:43:18.555: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 22:43:18.555: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 22:43:18.555: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 22:43:18.569: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jul 15 22:43:28.595: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 15 22:43:28.595: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul 15 22:43:28.595: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul 15 22:43:28.631: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jul 15 22:43:28.631: INFO: ss-0  10.190.211.93  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:34 +0000 UTC  }]
Jul 15 22:43:28.631: INFO: ss-1  10.190.211.94  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  }]
Jul 15 22:43:28.631: INFO: ss-2  10.190.211.91  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  }]
Jul 15 22:43:28.631: INFO: 
Jul 15 22:43:28.631: INFO: StatefulSet ss has not reached scale 0, at 3
Jul 15 22:43:29.642: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jul 15 22:43:29.642: INFO: ss-0  10.190.211.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:34 +0000 UTC  }]
Jul 15 22:43:29.642: INFO: ss-1  10.190.211.94  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  }]
Jul 15 22:43:29.643: INFO: ss-2  10.190.211.91  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  }]
Jul 15 22:43:29.643: INFO: 
Jul 15 22:43:29.643: INFO: StatefulSet ss has not reached scale 0, at 3
Jul 15 22:43:30.655: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jul 15 22:43:30.655: INFO: ss-0  10.190.211.93  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:34 +0000 UTC  }]
Jul 15 22:43:30.655: INFO: ss-1  10.190.211.94  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  }]
Jul 15 22:43:30.655: INFO: ss-2  10.190.211.91  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  }]
Jul 15 22:43:30.655: INFO: 
Jul 15 22:43:30.655: INFO: StatefulSet ss has not reached scale 0, at 3
Jul 15 22:43:31.665: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jul 15 22:43:31.665: INFO: ss-1  10.190.211.94  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  }]
Jul 15 22:43:31.665: INFO: 
Jul 15 22:43:31.665: INFO: StatefulSet ss has not reached scale 0, at 1
Jul 15 22:43:32.675: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jul 15 22:43:32.675: INFO: ss-1  10.190.211.94  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  }]
Jul 15 22:43:32.675: INFO: 
Jul 15 22:43:32.675: INFO: StatefulSet ss has not reached scale 0, at 1
Jul 15 22:43:33.685: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jul 15 22:43:33.685: INFO: ss-1  10.190.211.94  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  }]
Jul 15 22:43:33.686: INFO: 
Jul 15 22:43:33.686: INFO: StatefulSet ss has not reached scale 0, at 1
Jul 15 22:43:34.696: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jul 15 22:43:34.696: INFO: ss-1  10.190.211.94  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  }]
Jul 15 22:43:34.696: INFO: 
Jul 15 22:43:34.696: INFO: StatefulSet ss has not reached scale 0, at 1
Jul 15 22:43:35.711: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jul 15 22:43:35.711: INFO: ss-1  10.190.211.94  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  }]
Jul 15 22:43:35.711: INFO: 
Jul 15 22:43:35.711: INFO: StatefulSet ss has not reached scale 0, at 1
Jul 15 22:43:36.722: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jul 15 22:43:36.722: INFO: ss-1  10.190.211.94  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  }]
Jul 15 22:43:36.722: INFO: 
Jul 15 22:43:36.722: INFO: StatefulSet ss has not reached scale 0, at 1
Jul 15 22:43:37.738: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jul 15 22:43:37.738: INFO: ss-1  10.190.211.94  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:42:55 +0000 UTC  }]
Jul 15 22:43:37.738: INFO: 
Jul 15 22:43:37.738: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6827
Jul 15 22:43:38.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:43:38.999: INFO: rc: 1
Jul 15 22:43:39.000: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc00253fc20 exit status 1 <nil> <nil> true [0xc000937300 0xc000937530 0xc000937638] [0xc000937300 0xc000937530 0xc000937638] [0xc0009374e8 0xc000937618] [0x9c00a0 0x9c00a0] 0xc0030752c0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Jul 15 22:43:49.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:43:49.115: INFO: rc: 1
Jul 15 22:43:49.115: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00176e720 exit status 1 <nil> <nil> true [0xc002e724d8 0xc002e72518 0xc002e72530] [0xc002e724d8 0xc002e72518 0xc002e72530] [0xc002e72510 0xc002e72528] [0x9c00a0 0x9c00a0] 0xc0026f2540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:43:59.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:43:59.228: INFO: rc: 1
Jul 15 22:43:59.228: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00253ff50 exit status 1 <nil> <nil> true [0xc000937640 0xc0009376c8 0xc000937728] [0xc000937640 0xc0009376c8 0xc000937728] [0xc000937688 0xc000937710] [0x9c00a0 0x9c00a0] 0xc003075a40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:44:09.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:44:09.334: INFO: rc: 1
Jul 15 22:44:09.334: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00176ea80 exit status 1 <nil> <nil> true [0xc002e72538 0xc002e72580 0xc002e725c0] [0xc002e72538 0xc002e72580 0xc002e725c0] [0xc002e72568 0xc002e725b8] [0x9c00a0 0x9c00a0] 0xc0026f2ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:44:19.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:44:19.446: INFO: rc: 1
Jul 15 22:44:19.446: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0028d8570 exit status 1 <nil> <nil> true [0xc00248c910 0xc00248c940 0xc00248c990] [0xc00248c910 0xc00248c940 0xc00248c990] [0xc00248c930 0xc00248c968] [0x9c00a0 0x9c00a0] 0xc0017709c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:44:29.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:44:29.591: INFO: rc: 1
Jul 15 22:44:29.591: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0028d88d0 exit status 1 <nil> <nil> true [0xc00248c9a0 0xc00248c9d8 0xc00248ca10] [0xc00248c9a0 0xc00248c9d8 0xc00248ca10] [0xc00248c9c8 0xc00248ca00] [0x9c00a0 0x9c00a0] 0xc001770e40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:44:39.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:44:39.696: INFO: rc: 1
Jul 15 22:44:39.696: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002462420 exit status 1 <nil> <nil> true [0xc000937740 0xc0009377e0 0xc000937858] [0xc000937740 0xc0009377e0 0xc000937858] [0xc0009377b0 0xc000937838] [0x9c00a0 0x9c00a0] 0xc002a16000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:44:49.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:44:49.786: INFO: rc: 1
Jul 15 22:44:49.786: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0024628d0 exit status 1 <nil> <nil> true [0xc000937868 0xc000937898 0xc0009378e0] [0xc000937868 0xc000937898 0xc0009378e0] [0xc000937888 0xc0009378b0] [0x9c00a0 0x9c00a0] 0xc002a164e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:44:59.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:44:59.893: INFO: rc: 1
Jul 15 22:44:59.893: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00253e300 exit status 1 <nil> <nil> true [0xc000936200 0xc000936578 0xc0009365e8] [0xc000936200 0xc000936578 0xc0009365e8] [0xc000936398 0xc0009365a0] [0x9c00a0 0x9c00a0] 0xc003074660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:45:09.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:45:10.011: INFO: rc: 1
Jul 15 22:45:10.011: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003236300 exit status 1 <nil> <nil> true [0xc00248c010 0xc00248c0d0 0xc00248c150] [0xc00248c010 0xc00248c0d0 0xc00248c150] [0xc00248c070 0xc00248c138] [0x9c00a0 0x9c00a0] 0xc00282e720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:45:20.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:45:20.230: INFO: rc: 1
Jul 15 22:45:20.230: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00307a360 exit status 1 <nil> <nil> true [0xc001948078 0xc0019482c8 0xc001948660] [0xc001948078 0xc0019482c8 0xc001948660] [0xc0019481a8 0xc0019485a8] [0x9c00a0 0x9c00a0] 0xc002fd82a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:45:30.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:45:30.321: INFO: rc: 1
Jul 15 22:45:30.321: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00307a6f0 exit status 1 <nil> <nil> true [0xc0019486e0 0xc0019487c8 0xc0019489e8] [0xc0019486e0 0xc0019487c8 0xc0019489e8] [0xc0019487a8 0xc001948978] [0x9c00a0 0x9c00a0] 0xc002fd8600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:45:40.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:45:40.432: INFO: rc: 1
Jul 15 22:45:40.432: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00307aa20 exit status 1 <nil> <nil> true [0xc001948a20 0xc001948c48 0xc001948ea8] [0xc001948a20 0xc001948c48 0xc001948ea8] [0xc001948ac0 0xc001948de8] [0x9c00a0 0x9c00a0] 0xc002fd8960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:45:50.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:45:50.531: INFO: rc: 1
Jul 15 22:45:50.531: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003236660 exit status 1 <nil> <nil> true [0xc00248c190 0xc00248c260 0xc00248c2d8] [0xc00248c190 0xc00248c260 0xc00248c2d8] [0xc00248c220 0xc00248c2a8] [0x9c00a0 0x9c00a0] 0xc00282efc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:46:00.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:46:00.633: INFO: rc: 1
Jul 15 22:46:00.633: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003236990 exit status 1 <nil> <nil> true [0xc00248c300 0xc00248c360 0xc00248c3c0] [0xc00248c300 0xc00248c360 0xc00248c3c0] [0xc00248c328 0xc00248c3b0] [0x9c00a0 0x9c00a0] 0xc00282f3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:46:10.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:46:10.794: INFO: rc: 1
Jul 15 22:46:10.794: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003236ff0 exit status 1 <nil> <nil> true [0xc00248c3e0 0xc00248c418 0xc00248c458] [0xc00248c3e0 0xc00248c418 0xc00248c458] [0xc00248c408 0xc00248c440] [0x9c00a0 0x9c00a0] 0xc00282f740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:46:20.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:46:20.931: INFO: rc: 1
Jul 15 22:46:20.931: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00307ad80 exit status 1 <nil> <nil> true [0xc001948fa8 0xc001949228 0xc0019494c8] [0xc001948fa8 0xc001949228 0xc0019494c8] [0xc001949170 0xc001949470] [0x9c00a0 0x9c00a0] 0xc002fd8de0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:46:30.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:46:31.041: INFO: rc: 1
Jul 15 22:46:31.041: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003237350 exit status 1 <nil> <nil> true [0xc00248c468 0xc00248c4a0 0xc00248c4d0] [0xc00248c468 0xc00248c4a0 0xc00248c4d0] [0xc00248c490 0xc00248c4c0] [0x9c00a0 0x9c00a0] 0xc00282fb60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:46:41.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:46:41.136: INFO: rc: 1
Jul 15 22:46:41.137: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001a64330 exit status 1 <nil> <nil> true [0xc002e72000 0xc002e72020 0xc002e72078] [0xc002e72000 0xc002e72020 0xc002e72078] [0xc002e72010 0xc002e72058] [0x9c00a0 0x9c00a0] 0xc002a163c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:46:51.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:46:51.237: INFO: rc: 1
Jul 15 22:46:51.237: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00253e6c0 exit status 1 <nil> <nil> true [0xc000936738 0xc000936878 0xc000936a38] [0xc000936738 0xc000936878 0xc000936a38] [0xc0009367c0 0xc0009369e8] [0x9c00a0 0x9c00a0] 0xc003075140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:47:01.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:47:01.347: INFO: rc: 1
Jul 15 22:47:01.347: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001a64300 exit status 1 <nil> <nil> true [0xc002e72008 0xc002e72040 0xc002e72090] [0xc002e72008 0xc002e72040 0xc002e72090] [0xc002e72020 0xc002e72078] [0x9c00a0 0x9c00a0] 0xc002a163c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:47:11.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:47:11.458: INFO: rc: 1
Jul 15 22:47:11.458: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00253e360 exit status 1 <nil> <nil> true [0xc000936140 0xc000936398 0xc0009365a0] [0xc000936140 0xc000936398 0xc0009365a0] [0xc0009362c0 0xc000936588] [0x9c00a0 0x9c00a0] 0xc003074660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:47:21.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:47:21.555: INFO: rc: 1
Jul 15 22:47:21.555: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001a64690 exit status 1 <nil> <nil> true [0xc002e720b0 0xc002e72108 0xc002e72120] [0xc002e720b0 0xc002e72108 0xc002e72120] [0xc002e720f0 0xc002e72118] [0x9c00a0 0x9c00a0] 0xc002a167e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:47:31.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:47:31.670: INFO: rc: 1
Jul 15 22:47:31.670: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003236330 exit status 1 <nil> <nil> true [0xc00248c010 0xc00248c0d0 0xc00248c150] [0xc00248c010 0xc00248c0d0 0xc00248c150] [0xc00248c070 0xc00248c138] [0x9c00a0 0x9c00a0] 0xc00282e720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:47:41.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:47:41.787: INFO: rc: 1
Jul 15 22:47:41.787: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0032366c0 exit status 1 <nil> <nil> true [0xc00248c190 0xc00248c260 0xc00248c2d8] [0xc00248c190 0xc00248c260 0xc00248c2d8] [0xc00248c220 0xc00248c2a8] [0x9c00a0 0x9c00a0] 0xc00282efc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:47:51.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:47:52.033: INFO: rc: 1
Jul 15 22:47:52.033: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003236a50 exit status 1 <nil> <nil> true [0xc00248c300 0xc00248c360 0xc00248c3c0] [0xc00248c300 0xc00248c360 0xc00248c3c0] [0xc00248c328 0xc00248c3b0] [0x9c00a0 0x9c00a0] 0xc00282f3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:48:02.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:48:02.140: INFO: rc: 1
Jul 15 22:48:02.140: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0032370e0 exit status 1 <nil> <nil> true [0xc00248c3e0 0xc00248c418 0xc00248c458] [0xc00248c3e0 0xc00248c418 0xc00248c458] [0xc00248c408 0xc00248c440] [0x9c00a0 0x9c00a0] 0xc00282f740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:48:12.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:48:12.276: INFO: rc: 1
Jul 15 22:48:12.276: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00307a300 exit status 1 <nil> <nil> true [0xc001948078 0xc0019482c8 0xc001948660] [0xc001948078 0xc0019482c8 0xc001948660] [0xc0019481a8 0xc0019485a8] [0x9c00a0 0x9c00a0] 0xc002fd82a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:48:22.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:48:22.382: INFO: rc: 1
Jul 15 22:48:22.382: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00307a660 exit status 1 <nil> <nil> true [0xc0019486e0 0xc0019487c8 0xc0019489e8] [0xc0019486e0 0xc0019487c8 0xc0019489e8] [0xc0019487a8 0xc001948978] [0x9c00a0 0x9c00a0] 0xc002fd8600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:48:32.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:48:32.480: INFO: rc: 1
Jul 15 22:48:32.480: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00307a9f0 exit status 1 <nil> <nil> true [0xc001948a20 0xc001948c48 0xc001948ea8] [0xc001948a20 0xc001948c48 0xc001948ea8] [0xc001948ac0 0xc001948de8] [0x9c00a0 0x9c00a0] 0xc002fd8960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jul 15 22:48:42.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 exec --namespace=statefulset-6827 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 22:48:42.597: INFO: rc: 1
Jul 15 22:48:42.597: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Jul 15 22:48:42.597: INFO: Scaling statefulset ss to 0
Jul 15 22:48:42.636: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 15 22:48:42.646: INFO: Deleting all statefulset in ns statefulset-6827
Jul 15 22:48:42.656: INFO: Scaling statefulset ss to 0
Jul 15 22:48:42.693: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 22:48:42.704: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:48:42.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6827" for this suite.
Jul 15 22:48:50.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:48:51.150: INFO: namespace statefulset-6827 deletion completed in 8.387128745s

• [SLOW TEST:376.677 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:48:51.150: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4082
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jul 15 22:48:55.573: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 15 22:48:55.584: INFO: Pod pod-with-prestop-http-hook still exists
Jul 15 22:48:57.584: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 15 22:48:57.597: INFO: Pod pod-with-prestop-http-hook still exists
Jul 15 22:48:59.585: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 15 22:48:59.596: INFO: Pod pod-with-prestop-http-hook still exists
Jul 15 22:49:01.585: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 15 22:49:01.594: INFO: Pod pod-with-prestop-http-hook still exists
Jul 15 22:49:03.585: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 15 22:49:03.596: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:49:03.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4082" for this suite.
Jul 15 22:49:27.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:49:28.046: INFO: namespace container-lifecycle-hook-4082 deletion completed in 24.397364453s

• [SLOW TEST:36.896 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:49:28.047: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8913
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0715 22:49:58.905665      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 15 22:49:58.905: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:49:58.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8913" for this suite.
Jul 15 22:50:06.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:50:07.311: INFO: namespace gc-8913 deletion completed in 8.391771555s

• [SLOW TEST:39.264 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:50:07.312: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7509
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jul 15 22:50:07.553: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:50:10.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7509" for this suite.
Jul 15 22:50:16.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:50:16.983: INFO: namespace init-container-7509 deletion completed in 6.375142851s

• [SLOW TEST:9.671 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:50:16.983: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-981
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-981
Jul 15 22:50:19.251: INFO: Started pod liveness-exec in namespace container-probe-981
STEP: checking the pod's current state and verifying that restartCount is present
Jul 15 22:50:19.263: INFO: Initial restart count of pod liveness-exec is 0
Jul 15 22:51:07.691: INFO: Restart count of pod container-probe-981/liveness-exec is now 1 (48.427219613s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:51:07.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-981" for this suite.
Jul 15 22:51:13.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:51:14.130: INFO: namespace container-probe-981 deletion completed in 6.382807915s

• [SLOW TEST:57.147 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:51:14.131: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5698
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-0c662424-a753-11e9-983d-d6ce37abd03c
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:51:14.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5698" for this suite.
Jul 15 22:51:20.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:51:20.811: INFO: namespace configmap-5698 deletion completed in 6.429745774s

• [SLOW TEST:6.680 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:51:20.812: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9045
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1524
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 15 22:51:21.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-9045'
Jul 15 22:51:21.230: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 15 22:51:21.230: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1529
Jul 15 22:51:25.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 delete deployment e2e-test-nginx-deployment --namespace=kubectl-9045'
Jul 15 22:51:25.406: INFO: stderr: ""
Jul 15 22:51:25.406: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:51:25.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9045" for this suite.
Jul 15 22:51:49.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:51:50.002: INFO: namespace kubectl-9045 deletion completed in 24.394742292s

• [SLOW TEST:29.190 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:51:50.002: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5188
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Jul 15 22:51:50.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 --namespace=kubectl-5188 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jul 15 22:51:51.992: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jul 15 22:51:51.993: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:51:54.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5188" for this suite.
Jul 15 22:52:04.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:52:04.400: INFO: namespace kubectl-5188 deletion completed in 10.371543499s

• [SLOW TEST:14.399 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:52:04.401: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7885
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 22:52:04.618: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:52:08.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7885" for this suite.
Jul 15 22:52:54.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:52:55.132: INFO: namespace pods-7885 deletion completed in 46.384007461s

• [SLOW TEST:50.731 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:52:55.132: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7503
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1688
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 15 22:52:55.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-7503'
Jul 15 22:52:55.496: INFO: stderr: ""
Jul 15 22:52:55.496: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jul 15 22:53:00.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pod e2e-test-nginx-pod --namespace=kubectl-7503 -o json'
Jul 15 22:53:00.659: INFO: stderr: ""
Jul 15 22:53:00.659: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-07-15T22:52:55Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-7503\",\n        \"resourceVersion\": \"23769\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-7503/pods/e2e-test-nginx-pod\",\n        \"uid\": \"48a7d2de-a753-11e9-9310-f2885f9aaa1a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-hcqgs\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.190.211.93\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-hcqgs\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-hcqgs\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-15T22:52:55Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-15T22:52:56Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-15T22:52:56Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-15T22:52:55Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://baaa2fc34ea9ef6ceb164a6402df891b55682eedee4a08bce9456b34b70c850e\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-07-15T22:52:56Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.190.211.93\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.19.47\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-07-15T22:52:55Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jul 15 22:53:00.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 replace -f - --namespace=kubectl-7503'
Jul 15 22:53:00.966: INFO: stderr: ""
Jul 15 22:53:00.966: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1693
Jul 15 22:53:00.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 delete pods e2e-test-nginx-pod --namespace=kubectl-7503'
Jul 15 22:53:02.947: INFO: stderr: ""
Jul 15 22:53:02.947: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:53:02.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7503" for this suite.
Jul 15 22:53:09.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:53:09.338: INFO: namespace kubectl-7503 deletion completed in 6.374061605s

• [SLOW TEST:14.207 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:53:09.339: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1419
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-1419
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 15 22:53:09.561: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 15 22:53:31.856: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.43.240 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1419 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 22:53:31.856: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 22:53:33.134: INFO: Found all expected endpoints: [netserver-0]
Jul 15 22:53:33.154: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.176.158 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1419 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 22:53:33.155: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 22:53:34.418: INFO: Found all expected endpoints: [netserver-1]
Jul 15 22:53:34.430: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.19.45 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1419 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 22:53:34.430: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 22:53:35.716: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:53:35.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1419" for this suite.
Jul 15 22:53:59.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:54:00.092: INFO: namespace pod-network-test-1419 deletion completed in 24.361899798s

• [SLOW TEST:50.754 seconds]
[sig-network] Networking
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:54:00.093: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6873
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jul 15 22:54:00.339: INFO: Waiting up to 5m0s for pod "pod-6f504dae-a753-11e9-983d-d6ce37abd03c" in namespace "emptydir-6873" to be "success or failure"
Jul 15 22:54:00.352: INFO: Pod "pod-6f504dae-a753-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.41503ms
Jul 15 22:54:02.365: INFO: Pod "pod-6f504dae-a753-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02622538s
STEP: Saw pod success
Jul 15 22:54:02.365: INFO: Pod "pod-6f504dae-a753-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:54:02.375: INFO: Trying to get logs from node 10.190.211.93 pod pod-6f504dae-a753-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 22:54:02.446: INFO: Waiting for pod pod-6f504dae-a753-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:54:02.458: INFO: Pod pod-6f504dae-a753-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:54:02.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6873" for this suite.
Jul 15 22:54:08.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:54:08.863: INFO: namespace emptydir-6873 deletion completed in 6.391533185s

• [SLOW TEST:8.771 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:54:08.864: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9002
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jul 15 22:54:09.153: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-9002,SelfLink:/api/v1/namespaces/watch-9002/configmaps/e2e-watch-test-resource-version,UID:7489df7a-a753-11e9-a496-5e4367ce3703,ResourceVersion:24074,Generation:0,CreationTimestamp:2019-07-15 22:54:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 15 22:54:09.153: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-9002,SelfLink:/api/v1/namespaces/watch-9002/configmaps/e2e-watch-test-resource-version,UID:7489df7a-a753-11e9-a496-5e4367ce3703,ResourceVersion:24076,Generation:0,CreationTimestamp:2019-07-15 22:54:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:54:09.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9002" for this suite.
Jul 15 22:54:15.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:54:15.565: INFO: namespace watch-9002 deletion completed in 6.398756557s

• [SLOW TEST:6.701 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:54:15.565: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1185
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 22:54:15.812: INFO: Waiting up to 5m0s for pod "downwardapi-volume-788894c8-a753-11e9-983d-d6ce37abd03c" in namespace "projected-1185" to be "success or failure"
Jul 15 22:54:15.826: INFO: Pod "downwardapi-volume-788894c8-a753-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.058832ms
Jul 15 22:54:17.836: INFO: Pod "downwardapi-volume-788894c8-a753-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023491673s
Jul 15 22:54:19.847: INFO: Pod "downwardapi-volume-788894c8-a753-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034971626s
STEP: Saw pod success
Jul 15 22:54:19.848: INFO: Pod "downwardapi-volume-788894c8-a753-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:54:19.859: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-788894c8-a753-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 22:54:19.925: INFO: Waiting for pod downwardapi-volume-788894c8-a753-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:54:19.939: INFO: Pod downwardapi-volume-788894c8-a753-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:54:19.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1185" for this suite.
Jul 15 22:54:25.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:54:26.355: INFO: namespace projected-1185 deletion completed in 6.396765229s

• [SLOW TEST:10.790 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:54:26.355: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1296
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1579
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 15 22:54:26.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1296'
Jul 15 22:54:26.735: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 15 22:54:26.735: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1584
Jul 15 22:54:26.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 delete jobs e2e-test-nginx-job --namespace=kubectl-1296'
Jul 15 22:54:26.921: INFO: stderr: ""
Jul 15 22:54:26.921: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:54:26.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1296" for this suite.
Jul 15 22:54:32.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:54:33.311: INFO: namespace kubectl-1296 deletion completed in 6.377151673s

• [SLOW TEST:6.956 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:54:33.311: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-4366
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3148
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2548
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:54:40.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4366" for this suite.
Jul 15 22:54:46.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:54:46.520: INFO: namespace namespaces-4366 deletion completed in 6.371468004s
STEP: Destroying namespace "nsdeletetest-3148" for this suite.
Jul 15 22:54:46.531: INFO: Namespace nsdeletetest-3148 was already deleted
STEP: Destroying namespace "nsdeletetest-2548" for this suite.
Jul 15 22:54:52.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:54:52.898: INFO: namespace nsdeletetest-2548 deletion completed in 6.366975549s

• [SLOW TEST:19.587 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:54:52.899: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5575
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-8ec95e83-a753-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume configMaps
Jul 15 22:54:53.160: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8ecaaf4b-a753-11e9-983d-d6ce37abd03c" in namespace "projected-5575" to be "success or failure"
Jul 15 22:54:53.173: INFO: Pod "pod-projected-configmaps-8ecaaf4b-a753-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.422159ms
Jul 15 22:54:55.183: INFO: Pod "pod-projected-configmaps-8ecaaf4b-a753-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022429904s
STEP: Saw pod success
Jul 15 22:54:55.183: INFO: Pod "pod-projected-configmaps-8ecaaf4b-a753-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 22:54:55.194: INFO: Trying to get logs from node 10.190.211.93 pod pod-projected-configmaps-8ecaaf4b-a753-11e9-983d-d6ce37abd03c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 22:54:55.243: INFO: Waiting for pod pod-projected-configmaps-8ecaaf4b-a753-11e9-983d-d6ce37abd03c to disappear
Jul 15 22:54:55.252: INFO: Pod pod-projected-configmaps-8ecaaf4b-a753-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:54:55.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5575" for this suite.
Jul 15 22:55:01.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:55:01.866: INFO: namespace projected-5575 deletion completed in 6.59935673s

• [SLOW TEST:8.967 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:55:01.867: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7897
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Jul 15 22:55:02.101: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jul 15 22:55:02.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 create -f - --namespace=kubectl-7897'
Jul 15 22:55:02.343: INFO: stderr: ""
Jul 15 22:55:02.343: INFO: stdout: "service/redis-slave created\n"
Jul 15 22:55:02.344: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jul 15 22:55:02.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 create -f - --namespace=kubectl-7897'
Jul 15 22:55:02.701: INFO: stderr: ""
Jul 15 22:55:02.701: INFO: stdout: "service/redis-master created\n"
Jul 15 22:55:02.701: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jul 15 22:55:02.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 create -f - --namespace=kubectl-7897'
Jul 15 22:55:02.998: INFO: stderr: ""
Jul 15 22:55:02.998: INFO: stdout: "service/frontend created\n"
Jul 15 22:55:02.998: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jul 15 22:55:02.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 create -f - --namespace=kubectl-7897'
Jul 15 22:55:03.319: INFO: stderr: ""
Jul 15 22:55:03.319: INFO: stdout: "deployment.apps/frontend created\n"
Jul 15 22:55:03.320: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jul 15 22:55:03.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 create -f - --namespace=kubectl-7897'
Jul 15 22:55:03.524: INFO: stderr: ""
Jul 15 22:55:03.524: INFO: stdout: "deployment.apps/redis-master created\n"
Jul 15 22:55:03.524: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jul 15 22:55:03.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 create -f - --namespace=kubectl-7897'
Jul 15 22:55:03.742: INFO: stderr: ""
Jul 15 22:55:03.742: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Jul 15 22:55:03.742: INFO: Waiting for all frontend pods to be Running.
Jul 15 22:55:18.793: INFO: Waiting for frontend to serve content.
Jul 15 22:55:23.842: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Jul 15 22:55:28.875: INFO: Trying to add a new entry to the guestbook.
Jul 15 22:55:28.904: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jul 15 22:55:28.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 delete --grace-period=0 --force -f - --namespace=kubectl-7897'
Jul 15 22:55:29.106: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 22:55:29.106: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jul 15 22:55:29.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 delete --grace-period=0 --force -f - --namespace=kubectl-7897'
Jul 15 22:55:29.266: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 22:55:29.266: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jul 15 22:55:29.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 delete --grace-period=0 --force -f - --namespace=kubectl-7897'
Jul 15 22:55:29.451: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 22:55:29.451: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jul 15 22:55:29.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 delete --grace-period=0 --force -f - --namespace=kubectl-7897'
Jul 15 22:55:29.579: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 22:55:29.579: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jul 15 22:55:29.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 delete --grace-period=0 --force -f - --namespace=kubectl-7897'
Jul 15 22:55:29.711: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 22:55:29.711: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jul 15 22:55:29.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 delete --grace-period=0 --force -f - --namespace=kubectl-7897'
Jul 15 22:55:29.837: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 22:55:29.837: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:55:29.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7897" for this suite.
Jul 15 22:56:13.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:56:14.233: INFO: namespace kubectl-7897 deletion completed in 44.374071483s

• [SLOW TEST:72.366 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:56:14.233: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3451
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-3451
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 15 22:56:14.447: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 15 22:56:36.716: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.19.52:8080/dial?request=hostName&protocol=udp&host=172.30.43.243&port=8081&tries=1'] Namespace:pod-network-test-3451 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 22:56:36.716: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 22:56:37.015: INFO: Waiting for endpoints: map[]
Jul 15 22:56:37.025: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.19.52:8080/dial?request=hostName&protocol=udp&host=172.30.19.53&port=8081&tries=1'] Namespace:pod-network-test-3451 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 22:56:37.025: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 22:56:37.312: INFO: Waiting for endpoints: map[]
Jul 15 22:56:37.324: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.19.52:8080/dial?request=hostName&protocol=udp&host=172.30.176.160&port=8081&tries=1'] Namespace:pod-network-test-3451 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 22:56:37.324: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 22:56:37.594: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:56:37.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3451" for this suite.
Jul 15 22:57:01.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:57:02.014: INFO: namespace pod-network-test-3451 deletion completed in 24.407459408s

• [SLOW TEST:47.781 seconds]
[sig-network] Networking
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:57:02.015: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5128
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-5128
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 15 22:57:02.229: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 15 22:57:20.520: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.176.161:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5128 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 22:57:20.520: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 22:57:20.821: INFO: Found all expected endpoints: [netserver-0]
Jul 15 22:57:20.832: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.19.54:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5128 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 22:57:20.832: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 22:57:21.126: INFO: Found all expected endpoints: [netserver-1]
Jul 15 22:57:21.138: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.43.244:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5128 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 22:57:21.138: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 22:57:21.458: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:57:21.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5128" for this suite.
Jul 15 22:57:45.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:57:45.860: INFO: namespace pod-network-test-5128 deletion completed in 24.387266299s

• [SLOW TEST:43.846 seconds]
[sig-network] Networking
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:57:45.861: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7400
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jul 15 22:57:46.090: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7400,SelfLink:/api/v1/namespaces/watch-7400/configmaps/e2e-watch-test-configmap-a,UID:f5e0903d-a753-11e9-a496-5e4367ce3703,ResourceVersion:25089,Generation:0,CreationTimestamp:2019-07-15 22:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 15 22:57:46.090: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7400,SelfLink:/api/v1/namespaces/watch-7400/configmaps/e2e-watch-test-configmap-a,UID:f5e0903d-a753-11e9-a496-5e4367ce3703,ResourceVersion:25089,Generation:0,CreationTimestamp:2019-07-15 22:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jul 15 22:57:56.108: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7400,SelfLink:/api/v1/namespaces/watch-7400/configmaps/e2e-watch-test-configmap-a,UID:f5e0903d-a753-11e9-a496-5e4367ce3703,ResourceVersion:25106,Generation:0,CreationTimestamp:2019-07-15 22:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jul 15 22:57:56.108: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7400,SelfLink:/api/v1/namespaces/watch-7400/configmaps/e2e-watch-test-configmap-a,UID:f5e0903d-a753-11e9-a496-5e4367ce3703,ResourceVersion:25106,Generation:0,CreationTimestamp:2019-07-15 22:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jul 15 22:58:06.133: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7400,SelfLink:/api/v1/namespaces/watch-7400/configmaps/e2e-watch-test-configmap-a,UID:f5e0903d-a753-11e9-a496-5e4367ce3703,ResourceVersion:25123,Generation:0,CreationTimestamp:2019-07-15 22:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 15 22:58:06.133: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7400,SelfLink:/api/v1/namespaces/watch-7400/configmaps/e2e-watch-test-configmap-a,UID:f5e0903d-a753-11e9-a496-5e4367ce3703,ResourceVersion:25123,Generation:0,CreationTimestamp:2019-07-15 22:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jul 15 22:58:16.151: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7400,SelfLink:/api/v1/namespaces/watch-7400/configmaps/e2e-watch-test-configmap-a,UID:f5e0903d-a753-11e9-a496-5e4367ce3703,ResourceVersion:25139,Generation:0,CreationTimestamp:2019-07-15 22:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 15 22:58:16.151: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7400,SelfLink:/api/v1/namespaces/watch-7400/configmaps/e2e-watch-test-configmap-a,UID:f5e0903d-a753-11e9-a496-5e4367ce3703,ResourceVersion:25139,Generation:0,CreationTimestamp:2019-07-15 22:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jul 15 22:58:26.172: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7400,SelfLink:/api/v1/namespaces/watch-7400/configmaps/e2e-watch-test-configmap-b,UID:0dc30265-a754-11e9-a496-5e4367ce3703,ResourceVersion:25200,Generation:0,CreationTimestamp:2019-07-15 22:58:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 15 22:58:26.173: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7400,SelfLink:/api/v1/namespaces/watch-7400/configmaps/e2e-watch-test-configmap-b,UID:0dc30265-a754-11e9-a496-5e4367ce3703,ResourceVersion:25200,Generation:0,CreationTimestamp:2019-07-15 22:58:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jul 15 22:58:36.188: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7400,SelfLink:/api/v1/namespaces/watch-7400/configmaps/e2e-watch-test-configmap-b,UID:0dc30265-a754-11e9-a496-5e4367ce3703,ResourceVersion:25218,Generation:0,CreationTimestamp:2019-07-15 22:58:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 15 22:58:36.188: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7400,SelfLink:/api/v1/namespaces/watch-7400/configmaps/e2e-watch-test-configmap-b,UID:0dc30265-a754-11e9-a496-5e4367ce3703,ResourceVersion:25218,Generation:0,CreationTimestamp:2019-07-15 22:58:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:58:46.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7400" for this suite.
Jul 15 22:58:52.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:58:52.574: INFO: namespace watch-7400 deletion completed in 6.370376483s

• [SLOW TEST:66.713 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:58:52.575: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:58:54.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4252" for this suite.
Jul 15 22:59:46.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 22:59:47.315: INFO: namespace kubelet-test-4252 deletion completed in 52.396021568s

• [SLOW TEST:54.740 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 22:59:47.316: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-3296
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jul 15 22:59:51.616: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-3e462685-a754-11e9-983d-d6ce37abd03c,GenerateName:,Namespace:events-3296,SelfLink:/api/v1/namespaces/events-3296/pods/send-events-3e462685-a754-11e9-983d-d6ce37abd03c,UID:3e46dea6-a754-11e9-a496-5e4367ce3703,ResourceVersion:25405,Generation:0,CreationTimestamp:2019-07-15 22:59:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 538708912,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-cccgw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cccgw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-cccgw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d086d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d086f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:59:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:59:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:59:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 22:59:47 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.93,PodIP:172.30.19.57,StartTime:2019-07-15 22:59:47 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-07-15 22:59:48 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://a5c6e1c05446118c05cbd816eb79049b70754394fc241f98edbe602b72271d9c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jul 15 22:59:53.629: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jul 15 22:59:55.642: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 22:59:55.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3296" for this suite.
Jul 15 23:00:33.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:00:34.368: INFO: namespace events-3296 deletion completed in 38.693214048s

• [SLOW TEST:47.052 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:00:34.368: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1767
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-5a545428-a754-11e9-983d-d6ce37abd03c
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:00:38.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1767" for this suite.
Jul 15 23:01:02.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:01:03.117: INFO: namespace configmap-1767 deletion completed in 24.372644455s

• [SLOW TEST:28.749 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:01:03.120: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2295
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 23:01:03.374: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jul 15 23:01:08.385: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul 15 23:01:08.385: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 15 23:01:08.434: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-2295,SelfLink:/apis/apps/v1/namespaces/deployment-2295/deployments/test-cleanup-deployment,UID:6e77fc1f-a754-11e9-a496-5e4367ce3703,ResourceVersion:25626,Generation:1,CreationTimestamp:2019-07-15 23:01:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jul 15 23:01:08.446: INFO: New ReplicaSet "test-cleanup-deployment-6865c98b76" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76,GenerateName:,Namespace:deployment-2295,SelfLink:/apis/apps/v1/namespaces/deployment-2295/replicasets/test-cleanup-deployment-6865c98b76,UID:6e7c18b6-a754-11e9-a496-5e4367ce3703,ResourceVersion:25628,Generation:1,CreationTimestamp:2019-07-15 23:01:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 6e77fc1f-a754-11e9-a496-5e4367ce3703 0xc0032bc677 0xc0032bc678}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 15 23:01:08.446: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jul 15 23:01:08.446: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-2295,SelfLink:/apis/apps/v1/namespaces/deployment-2295/replicasets/test-cleanup-controller,UID:6b747430-a754-11e9-a496-5e4367ce3703,ResourceVersion:25627,Generation:1,CreationTimestamp:2019-07-15 23:01:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 6e77fc1f-a754-11e9-a496-5e4367ce3703 0xc0032bc5a7 0xc0032bc5a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul 15 23:01:08.491: INFO: Pod "test-cleanup-controller-p6l2z" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-p6l2z,GenerateName:test-cleanup-controller-,Namespace:deployment-2295,SelfLink:/api/v1/namespaces/deployment-2295/pods/test-cleanup-controller-p6l2z,UID:6b77af6c-a754-11e9-a496-5e4367ce3703,ResourceVersion:25616,Generation:0,CreationTimestamp:2019-07-15 23:01:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 6b747430-a754-11e9-a496-5e4367ce3703 0xc0032bd057 0xc0032bd058}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wc69d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wc69d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wc69d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032bd0d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032bd100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 23:01:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 23:01:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 23:01:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 23:01:03 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.93,PodIP:172.30.19.58,StartTime:2019-07-15 23:01:03 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-15 23:01:04 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://9b63d5ba4ba1187e394e56e3131864470ac615f4b0363d820a4f053b366e74f1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 23:01:08.491: INFO: Pod "test-cleanup-deployment-6865c98b76-tx99d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76-tx99d,GenerateName:test-cleanup-deployment-6865c98b76-,Namespace:deployment-2295,SelfLink:/api/v1/namespaces/deployment-2295/pods/test-cleanup-deployment-6865c98b76-tx99d,UID:6e7df024-a754-11e9-a496-5e4367ce3703,ResourceVersion:25633,Generation:0,CreationTimestamp:2019-07-15 23:01:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-6865c98b76 6e7c18b6-a754-11e9-a496-5e4367ce3703 0xc0032bd1e7 0xc0032bd1e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wc69d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wc69d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-wc69d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032bd260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032bd280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 23:01:08 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:01:08.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2295" for this suite.
Jul 15 23:01:14.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:01:14.908: INFO: namespace deployment-2295 deletion completed in 6.402960729s

• [SLOW TEST:11.789 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:01:14.908: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4734
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-727b4d9a-a754-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume configMaps
Jul 15 23:01:15.155: INFO: Waiting up to 5m0s for pod "pod-configmaps-727c874c-a754-11e9-983d-d6ce37abd03c" in namespace "configmap-4734" to be "success or failure"
Jul 15 23:01:15.169: INFO: Pod "pod-configmaps-727c874c-a754-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.071547ms
Jul 15 23:01:17.180: INFO: Pod "pod-configmaps-727c874c-a754-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024827997s
STEP: Saw pod success
Jul 15 23:01:17.180: INFO: Pod "pod-configmaps-727c874c-a754-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:01:17.194: INFO: Trying to get logs from node 10.190.211.93 pod pod-configmaps-727c874c-a754-11e9-983d-d6ce37abd03c container configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 23:01:17.249: INFO: Waiting for pod pod-configmaps-727c874c-a754-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:01:17.257: INFO: Pod pod-configmaps-727c874c-a754-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:01:17.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4734" for this suite.
Jul 15 23:01:23.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:01:23.685: INFO: namespace configmap-4734 deletion completed in 6.411318852s

• [SLOW TEST:8.776 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:01:23.685: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-115
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-115
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-115
STEP: Creating statefulset with conflicting port in namespace statefulset-115
STEP: Waiting until pod test-pod will start running in namespace statefulset-115
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-115
Jul 15 23:01:28.195: INFO: Observed stateful pod in namespace: statefulset-115, name: ss-0, uid: 78251b63-a754-11e9-a496-5e4367ce3703, status phase: Pending. Waiting for statefulset controller to delete.
Jul 15 23:01:28.687: INFO: Observed stateful pod in namespace: statefulset-115, name: ss-0, uid: 78251b63-a754-11e9-a496-5e4367ce3703, status phase: Failed. Waiting for statefulset controller to delete.
Jul 15 23:01:28.706: INFO: Observed stateful pod in namespace: statefulset-115, name: ss-0, uid: 78251b63-a754-11e9-a496-5e4367ce3703, status phase: Failed. Waiting for statefulset controller to delete.
Jul 15 23:01:28.720: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-115
STEP: Removing pod with conflicting port in namespace statefulset-115
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-115 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 15 23:01:40.839: INFO: Deleting all statefulset in ns statefulset-115
Jul 15 23:01:40.849: INFO: Scaling statefulset ss to 0
Jul 15 23:01:50.903: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 23:01:50.914: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:01:50.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-115" for this suite.
Jul 15 23:01:57.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:01:57.320: INFO: namespace statefulset-115 deletion completed in 6.345857826s

• [SLOW TEST:33.635 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:01:57.320: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3479
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Jul 15 23:01:57.534: INFO: namespace kubectl-3479
Jul 15 23:01:57.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 create -f - --namespace=kubectl-3479'
Jul 15 23:01:57.817: INFO: stderr: ""
Jul 15 23:01:57.817: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jul 15 23:01:58.826: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 23:01:58.826: INFO: Found 0 / 1
Jul 15 23:01:59.827: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 23:01:59.827: INFO: Found 0 / 1
Jul 15 23:02:00.827: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 23:02:00.827: INFO: Found 1 / 1
Jul 15 23:02:00.827: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul 15 23:02:00.839: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 23:02:00.840: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 15 23:02:00.840: INFO: wait on redis-master startup in kubectl-3479 
Jul 15 23:02:00.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 logs redis-master-fwzdr redis-master --namespace=kubectl-3479'
Jul 15 23:02:01.006: INFO: stderr: ""
Jul 15 23:02:01.006: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Jul 23:01:59.141 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Jul 23:01:59.141 # Server started, Redis version 3.2.12\n1:M 15 Jul 23:01:59.141 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Jul 23:01:59.141 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jul 15 23:02:01.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-3479'
Jul 15 23:02:01.439: INFO: stderr: ""
Jul 15 23:02:01.439: INFO: stdout: "service/rm2 exposed\n"
Jul 15 23:02:01.454: INFO: Service rm2 in namespace kubectl-3479 found.
STEP: exposing service
Jul 15 23:02:03.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-3479'
Jul 15 23:02:03.637: INFO: stderr: ""
Jul 15 23:02:03.637: INFO: stdout: "service/rm3 exposed\n"
Jul 15 23:02:03.644: INFO: Service rm3 in namespace kubectl-3479 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:02:05.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3479" for this suite.
Jul 15 23:02:29.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:02:30.039: INFO: namespace kubectl-3479 deletion completed in 24.363362403s

• [SLOW TEST:32.719 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:02:30.039: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7598
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Jul 15 23:02:30.289: INFO: Waiting up to 5m0s for pod "var-expansion-9f44d6b3-a754-11e9-983d-d6ce37abd03c" in namespace "var-expansion-7598" to be "success or failure"
Jul 15 23:02:30.315: INFO: Pod "var-expansion-9f44d6b3-a754-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 25.161202ms
Jul 15 23:02:32.330: INFO: Pod "var-expansion-9f44d6b3-a754-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.04063762s
STEP: Saw pod success
Jul 15 23:02:32.330: INFO: Pod "var-expansion-9f44d6b3-a754-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:02:32.340: INFO: Trying to get logs from node 10.190.211.93 pod var-expansion-9f44d6b3-a754-11e9-983d-d6ce37abd03c container dapi-container: <nil>
STEP: delete the pod
Jul 15 23:02:32.404: INFO: Waiting for pod var-expansion-9f44d6b3-a754-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:02:32.415: INFO: Pod var-expansion-9f44d6b3-a754-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:02:32.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7598" for this suite.
Jul 15 23:02:38.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:02:38.812: INFO: namespace var-expansion-7598 deletion completed in 6.382680826s

• [SLOW TEST:8.772 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:02:38.812: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-344
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jul 15 23:02:39.052: INFO: Waiting up to 5m0s for pod "pod-a47db32d-a754-11e9-983d-d6ce37abd03c" in namespace "emptydir-344" to be "success or failure"
Jul 15 23:02:39.066: INFO: Pod "pod-a47db32d-a754-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.842646ms
Jul 15 23:02:41.081: INFO: Pod "pod-a47db32d-a754-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028848774s
STEP: Saw pod success
Jul 15 23:02:41.081: INFO: Pod "pod-a47db32d-a754-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:02:41.093: INFO: Trying to get logs from node 10.190.211.93 pod pod-a47db32d-a754-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 23:02:41.154: INFO: Waiting for pod pod-a47db32d-a754-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:02:41.170: INFO: Pod pod-a47db32d-a754-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:02:41.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-344" for this suite.
Jul 15 23:02:47.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:02:47.595: INFO: namespace emptydir-344 deletion completed in 6.408154467s

• [SLOW TEST:8.783 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:02:47.595: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5649
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Jul 15 23:02:47.840: INFO: Waiting up to 5m0s for pod "client-containers-a9ba41dc-a754-11e9-983d-d6ce37abd03c" in namespace "containers-5649" to be "success or failure"
Jul 15 23:02:47.858: INFO: Pod "client-containers-a9ba41dc-a754-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.809476ms
Jul 15 23:02:49.873: INFO: Pod "client-containers-a9ba41dc-a754-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032451429s
Jul 15 23:02:51.884: INFO: Pod "client-containers-a9ba41dc-a754-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043869497s
STEP: Saw pod success
Jul 15 23:02:51.884: INFO: Pod "client-containers-a9ba41dc-a754-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:02:52.110: INFO: Trying to get logs from node 10.190.211.93 pod client-containers-a9ba41dc-a754-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 23:02:52.161: INFO: Waiting for pod client-containers-a9ba41dc-a754-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:02:52.170: INFO: Pod client-containers-a9ba41dc-a754-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:02:52.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5649" for this suite.
Jul 15 23:02:58.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:02:58.726: INFO: namespace containers-5649 deletion completed in 6.540270221s

• [SLOW TEST:11.130 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:02:58.726: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2271
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-2271
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2271 to expose endpoints map[]
Jul 15 23:02:58.998: INFO: Get endpoints failed (9.997699ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jul 15 23:03:00.015: INFO: successfully validated that service endpoint-test2 in namespace services-2271 exposes endpoints map[] (1.027238861s elapsed)
STEP: Creating pod pod1 in namespace services-2271
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2271 to expose endpoints map[pod1:[80]]
Jul 15 23:03:02.110: INFO: successfully validated that service endpoint-test2 in namespace services-2271 exposes endpoints map[pod1:[80]] (2.071223516s elapsed)
STEP: Creating pod pod2 in namespace services-2271
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2271 to expose endpoints map[pod1:[80] pod2:[80]]
Jul 15 23:03:05.268: INFO: successfully validated that service endpoint-test2 in namespace services-2271 exposes endpoints map[pod1:[80] pod2:[80]] (3.144568492s elapsed)
STEP: Deleting pod pod1 in namespace services-2271
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2271 to expose endpoints map[pod2:[80]]
Jul 15 23:03:05.320: INFO: successfully validated that service endpoint-test2 in namespace services-2271 exposes endpoints map[pod2:[80]] (31.687713ms elapsed)
STEP: Deleting pod pod2 in namespace services-2271
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2271 to expose endpoints map[]
Jul 15 23:03:05.350: INFO: successfully validated that service endpoint-test2 in namespace services-2271 exposes endpoints map[] (12.24708ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:03:05.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2271" for this suite.
Jul 15 23:03:29.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:03:29.816: INFO: namespace services-2271 deletion completed in 24.39381552s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:31.089 seconds]
[sig-network] Services
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:03:29.816: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7353
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:03:34.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7353" for this suite.
Jul 15 23:03:40.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:03:40.484: INFO: namespace kubelet-test-7353 deletion completed in 6.400857828s

• [SLOW TEST:10.668 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:03:40.485: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6710
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6710.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6710.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6710.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6710.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6710.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6710.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6710.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6710.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6710.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6710.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6710.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 99.19.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.19.99_udp@PTR;check="$$(dig +tcp +noall +answer +search 99.19.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.19.99_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6710.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6710.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6710.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6710.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6710.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6710.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6710.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6710.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6710.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6710.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6710.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 99.19.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.19.99_udp@PTR;check="$$(dig +tcp +noall +answer +search 99.19.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.19.99_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul 15 23:03:50.837: INFO: Unable to read wheezy_udp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:03:50.850: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:03:50.867: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:03:50.882: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:03:51.012: INFO: Unable to read jessie_udp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:03:51.033: INFO: Unable to read jessie_tcp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:03:51.049: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:03:51.064: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:03:51.165: INFO: Lookups using dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c failed for: [wheezy_udp@dns-test-service.dns-6710.svc.cluster.local wheezy_tcp@dns-test-service.dns-6710.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local jessie_udp@dns-test-service.dns-6710.svc.cluster.local jessie_tcp@dns-test-service.dns-6710.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local]

Jul 15 23:03:56.180: INFO: Unable to read wheezy_udp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:03:56.194: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:03:56.207: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:03:56.225: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:03:56.334: INFO: Unable to read jessie_udp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:03:56.348: INFO: Unable to read jessie_tcp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:03:56.366: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:03:56.380: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:03:56.467: INFO: Lookups using dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c failed for: [wheezy_udp@dns-test-service.dns-6710.svc.cluster.local wheezy_tcp@dns-test-service.dns-6710.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local jessie_udp@dns-test-service.dns-6710.svc.cluster.local jessie_tcp@dns-test-service.dns-6710.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local]

Jul 15 23:04:01.183: INFO: Unable to read wheezy_udp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:01.205: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:01.222: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:01.237: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:01.343: INFO: Unable to read jessie_udp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:01.359: INFO: Unable to read jessie_tcp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:01.375: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:01.392: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:01.493: INFO: Lookups using dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c failed for: [wheezy_udp@dns-test-service.dns-6710.svc.cluster.local wheezy_tcp@dns-test-service.dns-6710.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local jessie_udp@dns-test-service.dns-6710.svc.cluster.local jessie_tcp@dns-test-service.dns-6710.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local]

Jul 15 23:04:06.181: INFO: Unable to read wheezy_udp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:06.197: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:06.211: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:06.232: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:06.350: INFO: Unable to read jessie_udp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:06.368: INFO: Unable to read jessie_tcp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:06.383: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:06.400: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:06.498: INFO: Lookups using dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c failed for: [wheezy_udp@dns-test-service.dns-6710.svc.cluster.local wheezy_tcp@dns-test-service.dns-6710.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local jessie_udp@dns-test-service.dns-6710.svc.cluster.local jessie_tcp@dns-test-service.dns-6710.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local]

Jul 15 23:04:11.179: INFO: Unable to read wheezy_udp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:11.197: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:11.212: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:11.241: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:11.343: INFO: Unable to read jessie_udp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:11.357: INFO: Unable to read jessie_tcp@dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:11.375: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:11.389: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local from pod dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c: the server could not find the requested resource (get pods dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c)
Jul 15 23:04:11.505: INFO: Lookups using dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c failed for: [wheezy_udp@dns-test-service.dns-6710.svc.cluster.local wheezy_tcp@dns-test-service.dns-6710.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local jessie_udp@dns-test-service.dns-6710.svc.cluster.local jessie_tcp@dns-test-service.dns-6710.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6710.svc.cluster.local]

Jul 15 23:04:16.513: INFO: DNS probes using dns-6710/dns-test-c947ad0e-a754-11e9-983d-d6ce37abd03c succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:04:16.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6710" for this suite.
Jul 15 23:04:24.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:04:25.078: INFO: namespace dns-6710 deletion completed in 8.40688881s

• [SLOW TEST:44.594 seconds]
[sig-network] DNS
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:04:25.079: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8882
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:04:25.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8882" for this suite.
Jul 15 23:04:31.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:04:31.878: INFO: namespace services-8882 deletion completed in 6.560654405s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.800 seconds]
[sig-network] Services
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:04:31.879: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2423
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 23:04:32.129: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e7e44859-a754-11e9-983d-d6ce37abd03c" in namespace "downward-api-2423" to be "success or failure"
Jul 15 23:04:32.141: INFO: Pod "downwardapi-volume-e7e44859-a754-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.280292ms
Jul 15 23:04:34.292: INFO: Pod "downwardapi-volume-e7e44859-a754-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.162894629s
Jul 15 23:04:36.376: INFO: Pod "downwardapi-volume-e7e44859-a754-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.246826189s
STEP: Saw pod success
Jul 15 23:04:36.376: INFO: Pod "downwardapi-volume-e7e44859-a754-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:04:36.386: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-e7e44859-a754-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 23:04:36.440: INFO: Waiting for pod downwardapi-volume-e7e44859-a754-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:04:36.450: INFO: Pod downwardapi-volume-e7e44859-a754-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:04:36.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2423" for this suite.
Jul 15 23:04:42.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:04:42.858: INFO: namespace downward-api-2423 deletion completed in 6.389670838s

• [SLOW TEST:10.979 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:04:42.858: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2257
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-ee6ba6b1-a754-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume configMaps
Jul 15 23:04:43.092: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ee6d23a8-a754-11e9-983d-d6ce37abd03c" in namespace "projected-2257" to be "success or failure"
Jul 15 23:04:43.114: INFO: Pod "pod-projected-configmaps-ee6d23a8-a754-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 22.092301ms
Jul 15 23:04:45.126: INFO: Pod "pod-projected-configmaps-ee6d23a8-a754-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034023144s
Jul 15 23:04:47.137: INFO: Pod "pod-projected-configmaps-ee6d23a8-a754-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04529609s
STEP: Saw pod success
Jul 15 23:04:47.137: INFO: Pod "pod-projected-configmaps-ee6d23a8-a754-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:04:47.148: INFO: Trying to get logs from node 10.190.211.93 pod pod-projected-configmaps-ee6d23a8-a754-11e9-983d-d6ce37abd03c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 23:04:47.232: INFO: Waiting for pod pod-projected-configmaps-ee6d23a8-a754-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:04:47.279: INFO: Pod pod-projected-configmaps-ee6d23a8-a754-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:04:47.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2257" for this suite.
Jul 15 23:04:53.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:04:53.841: INFO: namespace projected-2257 deletion completed in 6.54311453s

• [SLOW TEST:10.983 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:04:53.842: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1863
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-f4fa64ab-a754-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume secrets
Jul 15 23:04:54.102: INFO: Waiting up to 5m0s for pod "pod-secrets-f4fcb3f4-a754-11e9-983d-d6ce37abd03c" in namespace "secrets-1863" to be "success or failure"
Jul 15 23:04:54.113: INFO: Pod "pod-secrets-f4fcb3f4-a754-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.982717ms
Jul 15 23:04:56.127: INFO: Pod "pod-secrets-f4fcb3f4-a754-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024963524s
Jul 15 23:04:58.139: INFO: Pod "pod-secrets-f4fcb3f4-a754-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037190079s
STEP: Saw pod success
Jul 15 23:04:58.139: INFO: Pod "pod-secrets-f4fcb3f4-a754-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:04:58.149: INFO: Trying to get logs from node 10.190.211.93 pod pod-secrets-f4fcb3f4-a754-11e9-983d-d6ce37abd03c container secret-volume-test: <nil>
STEP: delete the pod
Jul 15 23:04:58.205: INFO: Waiting for pod pod-secrets-f4fcb3f4-a754-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:04:58.215: INFO: Pod pod-secrets-f4fcb3f4-a754-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:04:58.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1863" for this suite.
Jul 15 23:05:04.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:05:04.638: INFO: namespace secrets-1863 deletion completed in 6.409505034s

• [SLOW TEST:10.796 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:05:04.639: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7235
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-fb6c8ead-a754-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume secrets
Jul 15 23:05:04.931: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fb6e620a-a754-11e9-983d-d6ce37abd03c" in namespace "projected-7235" to be "success or failure"
Jul 15 23:05:04.946: INFO: Pod "pod-projected-secrets-fb6e620a-a754-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.635499ms
Jul 15 23:05:06.956: INFO: Pod "pod-projected-secrets-fb6e620a-a754-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024983504s
Jul 15 23:05:08.966: INFO: Pod "pod-projected-secrets-fb6e620a-a754-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034636616s
STEP: Saw pod success
Jul 15 23:05:08.966: INFO: Pod "pod-projected-secrets-fb6e620a-a754-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:05:08.976: INFO: Trying to get logs from node 10.190.211.93 pod pod-projected-secrets-fb6e620a-a754-11e9-983d-d6ce37abd03c container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 15 23:05:09.036: INFO: Waiting for pod pod-projected-secrets-fb6e620a-a754-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:05:09.059: INFO: Pod pod-projected-secrets-fb6e620a-a754-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:05:09.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7235" for this suite.
Jul 15 23:05:15.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:05:15.843: INFO: namespace projected-7235 deletion completed in 6.771734469s

• [SLOW TEST:11.204 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:05:15.844: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5941
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Jul 15 23:05:16.083: INFO: Waiting up to 5m0s for pod "pod-02171b00-a755-11e9-983d-d6ce37abd03c" in namespace "emptydir-5941" to be "success or failure"
Jul 15 23:05:16.099: INFO: Pod "pod-02171b00-a755-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 15.428784ms
Jul 15 23:05:18.110: INFO: Pod "pod-02171b00-a755-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026788472s
Jul 15 23:05:20.137: INFO: Pod "pod-02171b00-a755-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053028644s
STEP: Saw pod success
Jul 15 23:05:20.137: INFO: Pod "pod-02171b00-a755-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:05:20.150: INFO: Trying to get logs from node 10.190.211.93 pod pod-02171b00-a755-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 23:05:20.225: INFO: Waiting for pod pod-02171b00-a755-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:05:20.241: INFO: Pod pod-02171b00-a755-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:05:20.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5941" for this suite.
Jul 15 23:05:26.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:05:26.646: INFO: namespace emptydir-5941 deletion completed in 6.392075968s

• [SLOW TEST:10.802 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:05:26.648: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8471
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 23:05:26.868: INFO: Creating deployment "test-recreate-deployment"
Jul 15 23:05:26.880: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jul 15 23:05:26.902: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Jul 15 23:05:28.922: INFO: Waiting deployment "test-recreate-deployment" to complete
Jul 15 23:05:28.929: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jul 15 23:05:28.947: INFO: Updating deployment test-recreate-deployment
Jul 15 23:05:28.947: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 15 23:05:29.159: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-8471,SelfLink:/apis/apps/v1/namespaces/deployment-8471/deployments/test-recreate-deployment,UID:088736b2-a755-11e9-a496-5e4367ce3703,ResourceVersion:26906,Generation:2,CreationTimestamp:2019-07-15 23:05:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-07-15 23:05:29 +0000 UTC 2019-07-15 23:05:29 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-07-15 23:05:29 +0000 UTC 2019-07-15 23:05:26 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-745fb9c84c" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jul 15 23:05:29.173: INFO: New ReplicaSet "test-recreate-deployment-745fb9c84c" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c,GenerateName:,Namespace:deployment-8471,SelfLink:/apis/apps/v1/namespaces/deployment-8471/replicasets/test-recreate-deployment-745fb9c84c,UID:09cfe3ac-a755-11e9-a496-5e4367ce3703,ResourceVersion:26904,Generation:1,CreationTimestamp:2019-07-15 23:05:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 088736b2-a755-11e9-a496-5e4367ce3703 0xc0017bb0e7 0xc0017bb0e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 15 23:05:29.173: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jul 15 23:05:29.173: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6566d46b4b,GenerateName:,Namespace:deployment-8471,SelfLink:/apis/apps/v1/namespaces/deployment-8471/replicasets/test-recreate-deployment-6566d46b4b,UID:0888f32b-a755-11e9-a496-5e4367ce3703,ResourceVersion:26894,Generation:2,CreationTimestamp:2019-07-15 23:05:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 088736b2-a755-11e9-a496-5e4367ce3703 0xc0017bab07 0xc0017bab08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 15 23:05:29.184: INFO: Pod "test-recreate-deployment-745fb9c84c-67x8d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c-67x8d,GenerateName:test-recreate-deployment-745fb9c84c-,Namespace:deployment-8471,SelfLink:/api/v1/namespaces/deployment-8471/pods/test-recreate-deployment-745fb9c84c-67x8d,UID:09d26efb-a755-11e9-a496-5e4367ce3703,ResourceVersion:26905,Generation:0,CreationTimestamp:2019-07-15 23:05:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-745fb9c84c 09cfe3ac-a755-11e9-a496-5e4367ce3703 0xc0004af397 0xc0004af398}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-hgxtq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hgxtq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hgxtq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.211.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0004af4b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0004af570}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 23:05:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 23:05:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 23:05:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 23:05:29 +0000 UTC  }],Message:,Reason:,HostIP:10.190.211.93,PodIP:,StartTime:2019-07-15 23:05:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:05:29.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8471" for this suite.
Jul 15 23:05:37.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:05:37.600: INFO: namespace deployment-8471 deletion completed in 8.400282115s

• [SLOW TEST:10.951 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:05:37.601: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2188
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul 15 23:05:37.864: INFO: Waiting up to 5m0s for pod "downward-api-0f122b49-a755-11e9-983d-d6ce37abd03c" in namespace "downward-api-2188" to be "success or failure"
Jul 15 23:05:37.873: INFO: Pod "downward-api-0f122b49-a755-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.440479ms
Jul 15 23:05:39.884: INFO: Pod "downward-api-0f122b49-a755-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020302419s
STEP: Saw pod success
Jul 15 23:05:39.884: INFO: Pod "downward-api-0f122b49-a755-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:05:39.894: INFO: Trying to get logs from node 10.190.211.93 pod downward-api-0f122b49-a755-11e9-983d-d6ce37abd03c container dapi-container: <nil>
STEP: delete the pod
Jul 15 23:05:39.951: INFO: Waiting for pod downward-api-0f122b49-a755-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:05:39.974: INFO: Pod downward-api-0f122b49-a755-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:05:39.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2188" for this suite.
Jul 15 23:05:46.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:05:46.372: INFO: namespace downward-api-2188 deletion completed in 6.381687478s

• [SLOW TEST:8.771 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:05:46.374: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7591
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-2zxf
STEP: Creating a pod to test atomic-volume-subpath
Jul 15 23:05:46.644: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-2zxf" in namespace "subpath-7591" to be "success or failure"
Jul 15 23:05:46.662: INFO: Pod "pod-subpath-test-downwardapi-2zxf": Phase="Pending", Reason="", readiness=false. Elapsed: 17.544219ms
Jul 15 23:05:48.671: INFO: Pod "pod-subpath-test-downwardapi-2zxf": Phase="Running", Reason="", readiness=true. Elapsed: 2.027195097s
Jul 15 23:05:50.682: INFO: Pod "pod-subpath-test-downwardapi-2zxf": Phase="Running", Reason="", readiness=true. Elapsed: 4.037849716s
Jul 15 23:05:52.698: INFO: Pod "pod-subpath-test-downwardapi-2zxf": Phase="Running", Reason="", readiness=true. Elapsed: 6.053948188s
Jul 15 23:05:54.708: INFO: Pod "pod-subpath-test-downwardapi-2zxf": Phase="Running", Reason="", readiness=true. Elapsed: 8.064239187s
Jul 15 23:05:56.719: INFO: Pod "pod-subpath-test-downwardapi-2zxf": Phase="Running", Reason="", readiness=true. Elapsed: 10.074916405s
Jul 15 23:05:58.730: INFO: Pod "pod-subpath-test-downwardapi-2zxf": Phase="Running", Reason="", readiness=true. Elapsed: 12.085711934s
Jul 15 23:06:00.741: INFO: Pod "pod-subpath-test-downwardapi-2zxf": Phase="Running", Reason="", readiness=true. Elapsed: 14.097224082s
Jul 15 23:06:02.753: INFO: Pod "pod-subpath-test-downwardapi-2zxf": Phase="Running", Reason="", readiness=true. Elapsed: 16.1088145s
Jul 15 23:06:04.763: INFO: Pod "pod-subpath-test-downwardapi-2zxf": Phase="Running", Reason="", readiness=true. Elapsed: 18.119276269s
Jul 15 23:06:06.774: INFO: Pod "pod-subpath-test-downwardapi-2zxf": Phase="Running", Reason="", readiness=true. Elapsed: 20.12970969s
Jul 15 23:06:08.784: INFO: Pod "pod-subpath-test-downwardapi-2zxf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.140221965s
STEP: Saw pod success
Jul 15 23:06:08.784: INFO: Pod "pod-subpath-test-downwardapi-2zxf" satisfied condition "success or failure"
Jul 15 23:06:08.793: INFO: Trying to get logs from node 10.190.211.93 pod pod-subpath-test-downwardapi-2zxf container test-container-subpath-downwardapi-2zxf: <nil>
STEP: delete the pod
Jul 15 23:06:08.877: INFO: Waiting for pod pod-subpath-test-downwardapi-2zxf to disappear
Jul 15 23:06:08.886: INFO: Pod pod-subpath-test-downwardapi-2zxf no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-2zxf
Jul 15 23:06:08.886: INFO: Deleting pod "pod-subpath-test-downwardapi-2zxf" in namespace "subpath-7591"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:06:08.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7591" for this suite.
Jul 15 23:06:14.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:06:15.293: INFO: namespace subpath-7591 deletion completed in 6.378694437s

• [SLOW TEST:28.919 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:06:15.294: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-995
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jul 15 23:06:19.627: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-995 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 23:06:19.627: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 23:06:19.942: INFO: Exec stderr: ""
Jul 15 23:06:19.943: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-995 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 23:06:19.943: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 23:06:20.271: INFO: Exec stderr: ""
Jul 15 23:06:20.271: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-995 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 23:06:20.271: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 23:06:20.544: INFO: Exec stderr: ""
Jul 15 23:06:20.544: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-995 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 23:06:20.544: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 23:06:20.863: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jul 15 23:06:20.863: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-995 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 23:06:20.863: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 23:06:21.153: INFO: Exec stderr: ""
Jul 15 23:06:21.153: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-995 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 23:06:21.153: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 23:06:21.473: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jul 15 23:06:21.473: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-995 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 23:06:21.473: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 23:06:21.727: INFO: Exec stderr: ""
Jul 15 23:06:21.727: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-995 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 23:06:21.727: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 23:06:22.015: INFO: Exec stderr: ""
Jul 15 23:06:22.015: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-995 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 23:06:22.015: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 23:06:22.290: INFO: Exec stderr: ""
Jul 15 23:06:22.290: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-995 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 23:06:22.290: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
Jul 15 23:06:22.595: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:06:22.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-995" for this suite.
Jul 15 23:07:04.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:07:04.998: INFO: namespace e2e-kubelet-etc-hosts-995 deletion completed in 42.387538401s

• [SLOW TEST:49.704 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:07:04.999: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4770
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1387
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 15 23:07:05.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4770'
Jul 15 23:07:05.385: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 15 23:07:05.385: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1393
Jul 15 23:07:07.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 delete deployment e2e-test-nginx-deployment --namespace=kubectl-4770'
Jul 15 23:07:07.548: INFO: stderr: ""
Jul 15 23:07:07.548: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:07:07.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4770" for this suite.
Jul 15 23:07:31.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:07:31.925: INFO: namespace kubectl-4770 deletion completed in 24.362515966s

• [SLOW TEST:26.926 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:07:31.925: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1734
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-1734
Jul 15 23:07:34.196: INFO: Started pod liveness-exec in namespace container-probe-1734
STEP: checking the pod's current state and verifying that restartCount is present
Jul 15 23:07:34.206: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:11:36.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1734" for this suite.
Jul 15 23:11:42.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:11:42.478: INFO: namespace container-probe-1734 deletion completed in 6.3818733s

• [SLOW TEST:250.553 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:11:42.478: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3090
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Jul 15 23:11:42.710: INFO: Waiting up to 5m0s for pod "pod-e88958ad-a755-11e9-983d-d6ce37abd03c" in namespace "emptydir-3090" to be "success or failure"
Jul 15 23:11:42.724: INFO: Pod "pod-e88958ad-a755-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.919857ms
Jul 15 23:11:44.735: INFO: Pod "pod-e88958ad-a755-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024214016s
Jul 15 23:11:46.744: INFO: Pod "pod-e88958ad-a755-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033990014s
STEP: Saw pod success
Jul 15 23:11:46.744: INFO: Pod "pod-e88958ad-a755-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:11:46.754: INFO: Trying to get logs from node 10.190.211.93 pod pod-e88958ad-a755-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 23:11:46.823: INFO: Waiting for pod pod-e88958ad-a755-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:11:46.832: INFO: Pod pod-e88958ad-a755-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:11:46.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3090" for this suite.
Jul 15 23:11:52.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:11:53.204: INFO: namespace emptydir-3090 deletion completed in 6.357467847s

• [SLOW TEST:10.725 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:11:53.204: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1716
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jul 15 23:11:53.406: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:11:57.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1716" for this suite.
Jul 15 23:12:03.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:12:03.416: INFO: namespace init-container-1716 deletion completed in 6.36746492s

• [SLOW TEST:10.213 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:12:03.418: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-853
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Jul 15 23:12:03.653: INFO: Waiting up to 5m0s for pod "pod-f5050d62-a755-11e9-983d-d6ce37abd03c" in namespace "emptydir-853" to be "success or failure"
Jul 15 23:12:03.672: INFO: Pod "pod-f5050d62-a755-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 18.575133ms
Jul 15 23:12:05.681: INFO: Pod "pod-f5050d62-a755-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02783931s
STEP: Saw pod success
Jul 15 23:12:05.681: INFO: Pod "pod-f5050d62-a755-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:12:05.692: INFO: Trying to get logs from node 10.190.211.93 pod pod-f5050d62-a755-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 23:12:05.744: INFO: Waiting for pod pod-f5050d62-a755-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:12:05.765: INFO: Pod pod-f5050d62-a755-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:12:05.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-853" for this suite.
Jul 15 23:12:11.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:12:12.263: INFO: namespace emptydir-853 deletion completed in 6.483757108s

• [SLOW TEST:8.846 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:12:12.267: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6355
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Jul 15 23:12:12.520: INFO: Waiting up to 5m0s for pod "pod-fa4d4dd6-a755-11e9-983d-d6ce37abd03c" in namespace "emptydir-6355" to be "success or failure"
Jul 15 23:12:12.530: INFO: Pod "pod-fa4d4dd6-a755-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.410048ms
Jul 15 23:12:14.542: INFO: Pod "pod-fa4d4dd6-a755-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021977888s
STEP: Saw pod success
Jul 15 23:12:14.542: INFO: Pod "pod-fa4d4dd6-a755-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:12:14.553: INFO: Trying to get logs from node 10.190.211.93 pod pod-fa4d4dd6-a755-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 23:12:14.605: INFO: Waiting for pod pod-fa4d4dd6-a755-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:12:14.621: INFO: Pod pod-fa4d4dd6-a755-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:12:14.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6355" for this suite.
Jul 15 23:12:20.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:12:21.014: INFO: namespace emptydir-6355 deletion completed in 6.377232613s

• [SLOW TEST:8.748 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:12:21.015: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6376
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 23:12:21.252: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ff82d695-a755-11e9-983d-d6ce37abd03c" in namespace "projected-6376" to be "success or failure"
Jul 15 23:12:21.265: INFO: Pod "downwardapi-volume-ff82d695-a755-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.658137ms
Jul 15 23:12:23.280: INFO: Pod "downwardapi-volume-ff82d695-a755-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027983947s
STEP: Saw pod success
Jul 15 23:12:23.280: INFO: Pod "downwardapi-volume-ff82d695-a755-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:12:23.295: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-ff82d695-a755-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 23:12:23.352: INFO: Waiting for pod downwardapi-volume-ff82d695-a755-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:12:23.371: INFO: Pod downwardapi-volume-ff82d695-a755-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:12:23.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6376" for this suite.
Jul 15 23:12:29.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:12:29.780: INFO: namespace projected-6376 deletion completed in 6.396976564s

• [SLOW TEST:8.765 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:12:29.780: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2316
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 23:12:30.031: INFO: Waiting up to 5m0s for pod "downwardapi-volume-04bdbdd4-a756-11e9-983d-d6ce37abd03c" in namespace "projected-2316" to be "success or failure"
Jul 15 23:12:30.045: INFO: Pod "downwardapi-volume-04bdbdd4-a756-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.88177ms
Jul 15 23:12:32.056: INFO: Pod "downwardapi-volume-04bdbdd4-a756-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025205093s
Jul 15 23:12:34.069: INFO: Pod "downwardapi-volume-04bdbdd4-a756-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03778039s
STEP: Saw pod success
Jul 15 23:12:34.069: INFO: Pod "downwardapi-volume-04bdbdd4-a756-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:12:34.080: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-04bdbdd4-a756-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 23:12:34.143: INFO: Waiting for pod downwardapi-volume-04bdbdd4-a756-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:12:34.165: INFO: Pod downwardapi-volume-04bdbdd4-a756-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:12:34.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2316" for this suite.
Jul 15 23:12:40.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:12:40.610: INFO: namespace projected-2316 deletion completed in 6.43021187s

• [SLOW TEST:10.830 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:12:40.612: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1369
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-0b4ed024-a756-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume secrets
Jul 15 23:12:41.056: INFO: Waiting up to 5m0s for pod "pod-secrets-0b50b02a-a756-11e9-983d-d6ce37abd03c" in namespace "secrets-1369" to be "success or failure"
Jul 15 23:12:41.076: INFO: Pod "pod-secrets-0b50b02a-a756-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 19.426056ms
Jul 15 23:12:43.099: INFO: Pod "pod-secrets-0b50b02a-a756-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042665148s
Jul 15 23:12:45.112: INFO: Pod "pod-secrets-0b50b02a-a756-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056300021s
STEP: Saw pod success
Jul 15 23:12:45.112: INFO: Pod "pod-secrets-0b50b02a-a756-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:12:45.123: INFO: Trying to get logs from node 10.190.211.93 pod pod-secrets-0b50b02a-a756-11e9-983d-d6ce37abd03c container secret-volume-test: <nil>
STEP: delete the pod
Jul 15 23:12:45.175: INFO: Waiting for pod pod-secrets-0b50b02a-a756-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:12:45.184: INFO: Pod pod-secrets-0b50b02a-a756-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:12:45.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1369" for this suite.
Jul 15 23:12:51.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:12:51.797: INFO: namespace secrets-1369 deletion completed in 6.600460793s

• [SLOW TEST:11.185 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:12:51.797: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5924
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:13:17.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5924" for this suite.
Jul 15 23:13:25.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:13:26.236: INFO: namespace container-runtime-5924 deletion completed in 8.370550021s

• [SLOW TEST:34.439 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:13:26.237: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7383
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-26634e20-a756-11e9-983d-d6ce37abd03c
STEP: Creating secret with name secret-projected-all-test-volume-26634dfb-a756-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test Check all projections for projected volume plugin
Jul 15 23:13:26.505: INFO: Waiting up to 5m0s for pod "projected-volume-26634dac-a756-11e9-983d-d6ce37abd03c" in namespace "projected-7383" to be "success or failure"
Jul 15 23:13:26.526: INFO: Pod "projected-volume-26634dac-a756-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 20.826042ms
Jul 15 23:13:28.536: INFO: Pod "projected-volume-26634dac-a756-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03124145s
STEP: Saw pod success
Jul 15 23:13:28.536: INFO: Pod "projected-volume-26634dac-a756-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:13:28.548: INFO: Trying to get logs from node 10.190.211.93 pod projected-volume-26634dac-a756-11e9-983d-d6ce37abd03c container projected-all-volume-test: <nil>
STEP: delete the pod
Jul 15 23:13:28.614: INFO: Waiting for pod projected-volume-26634dac-a756-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:13:28.626: INFO: Pod projected-volume-26634dac-a756-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:13:28.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7383" for this suite.
Jul 15 23:13:34.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:13:35.016: INFO: namespace projected-7383 deletion completed in 6.372140942s

• [SLOW TEST:8.779 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:13:35.016: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2176
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul 15 23:13:35.254: INFO: Waiting up to 5m0s for pod "downward-api-2b9e6c9e-a756-11e9-983d-d6ce37abd03c" in namespace "downward-api-2176" to be "success or failure"
Jul 15 23:13:35.267: INFO: Pod "downward-api-2b9e6c9e-a756-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.613376ms
Jul 15 23:13:37.279: INFO: Pod "downward-api-2b9e6c9e-a756-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024872879s
STEP: Saw pod success
Jul 15 23:13:37.279: INFO: Pod "downward-api-2b9e6c9e-a756-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:13:37.305: INFO: Trying to get logs from node 10.190.211.93 pod downward-api-2b9e6c9e-a756-11e9-983d-d6ce37abd03c container dapi-container: <nil>
STEP: delete the pod
Jul 15 23:13:37.366: INFO: Waiting for pod downward-api-2b9e6c9e-a756-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:13:37.378: INFO: Pod downward-api-2b9e6c9e-a756-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:13:37.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2176" for this suite.
Jul 15 23:13:43.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:13:43.781: INFO: namespace downward-api-2176 deletion completed in 6.389271071s

• [SLOW TEST:8.765 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:13:43.782: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7347
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-30d8ea04-a756-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume configMaps
Jul 15 23:13:44.041: INFO: Waiting up to 5m0s for pod "pod-configmaps-30db29bc-a756-11e9-983d-d6ce37abd03c" in namespace "configmap-7347" to be "success or failure"
Jul 15 23:13:44.065: INFO: Pod "pod-configmaps-30db29bc-a756-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 23.338957ms
Jul 15 23:13:46.075: INFO: Pod "pod-configmaps-30db29bc-a756-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033493762s
Jul 15 23:13:48.085: INFO: Pod "pod-configmaps-30db29bc-a756-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043539777s
STEP: Saw pod success
Jul 15 23:13:48.085: INFO: Pod "pod-configmaps-30db29bc-a756-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:13:48.097: INFO: Trying to get logs from node 10.190.211.93 pod pod-configmaps-30db29bc-a756-11e9-983d-d6ce37abd03c container configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 23:13:48.156: INFO: Waiting for pod pod-configmaps-30db29bc-a756-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:13:48.165: INFO: Pod pod-configmaps-30db29bc-a756-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:13:48.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7347" for this suite.
Jul 15 23:13:54.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:13:54.580: INFO: namespace configmap-7347 deletion completed in 6.401179563s

• [SLOW TEST:10.798 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:13:54.580: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6715
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul 15 23:13:54.809: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 15 23:13:54.839: INFO: Waiting for terminating namespaces to be deleted...
Jul 15 23:13:54.849: INFO: 
Logging pods the kubelet thinks is on node 10.190.211.91 before test
Jul 15 23:13:54.886: INFO: coredns-74d7dffd76-4skkd from kube-system started at 2019-07-15 20:52:46 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.886: INFO: 	Container coredns ready: true, restart count 0
Jul 15 23:13:54.886: INFO: ibm-master-proxy-static-10.190.211.91 from kube-system started at <nil> (0 container statuses recorded)
Jul 15 23:13:54.886: INFO: calico-node-296f7 from kube-system started at 2019-07-15 20:52:20 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.886: INFO: 	Container calico-node ready: true, restart count 0
Jul 15 23:13:54.886: INFO: metrics-server-6cdf95ffc5-rgpxg from kube-system started at 2019-07-15 20:52:51 +0000 UTC (2 container statuses recorded)
Jul 15 23:13:54.886: INFO: 	Container metrics-server ready: true, restart count 0
Jul 15 23:13:54.886: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Jul 15 23:13:54.886: INFO: sonobuoy-systemd-logs-daemon-set-e8a5b131278f47ce-msplm from heptio-sonobuoy started at 2019-07-15 21:58:11 +0000 UTC (2 container statuses recorded)
Jul 15 23:13:54.886: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jul 15 23:13:54.886: INFO: 	Container systemd-logs ready: true, restart count 1
Jul 15 23:13:54.886: INFO: ibm-file-plugin-76564988db-lwwst from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.886: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Jul 15 23:13:54.886: INFO: coredns-autoscaler-6d8b6f867-lm5sc from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.887: INFO: 	Container autoscaler ready: true, restart count 0
Jul 15 23:13:54.887: INFO: ibm-kube-fluentd-qq2vb from kube-system started at 2019-07-15 20:52:48 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.887: INFO: 	Container fluentd ready: true, restart count 0
Jul 15 23:13:54.887: INFO: ibm-cloud-provider-ip-169-62-60-229-5746bf8754-pvhns from ibm-system started at 2019-07-15 20:54:43 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.887: INFO: 	Container ibm-cloud-provider-ip-169-62-60-229 ready: true, restart count 0
Jul 15 23:13:54.887: INFO: public-crf7531fcdf3c4443f99d3792052463a22-alb1-5c8744f6fb-lq8qt from kube-system started at 2019-07-15 20:56:16 +0000 UTC (4 container statuses recorded)
Jul 15 23:13:54.887: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jul 15 23:13:54.887: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jul 15 23:13:54.887: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jul 15 23:13:54.887: INFO: 	Container nginx-ingress ready: true, restart count 0
Jul 15 23:13:54.887: INFO: ibm-keepalived-watcher-7hbvk from kube-system started at 2019-07-15 20:52:20 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.887: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jul 15 23:13:54.887: INFO: vpn-84dbfcd799-q9rz6 from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.887: INFO: 	Container vpn ready: true, restart count 0
Jul 15 23:13:54.887: INFO: calico-kube-controllers-658bc54b6f-dngkt from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.887: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jul 15 23:13:54.887: INFO: 
Logging pods the kubelet thinks is on node 10.190.211.93 before test
Jul 15 23:13:54.921: INFO: ibm-keepalived-watcher-svlzn from kube-system started at 2019-07-15 20:57:54 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.922: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jul 15 23:13:54.922: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-15 21:58:06 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.922: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 15 23:13:54.922: INFO: sonobuoy-e2e-job-d0083bb64b09449f from heptio-sonobuoy started at 2019-07-15 21:58:11 +0000 UTC (2 container statuses recorded)
Jul 15 23:13:54.922: INFO: 	Container e2e ready: true, restart count 0
Jul 15 23:13:54.922: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 15 23:13:54.922: INFO: sonobuoy-systemd-logs-daemon-set-e8a5b131278f47ce-tctpt from heptio-sonobuoy started at 2019-07-15 21:58:11 +0000 UTC (2 container statuses recorded)
Jul 15 23:13:54.922: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jul 15 23:13:54.922: INFO: 	Container systemd-logs ready: true, restart count 1
Jul 15 23:13:54.922: INFO: ibm-kube-fluentd-fw2dr from kube-system started at 2019-07-15 20:57:54 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.922: INFO: 	Container fluentd ready: true, restart count 0
Jul 15 23:13:54.922: INFO: calico-node-dd7kh from kube-system started at 2019-07-15 20:57:54 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.922: INFO: 	Container calico-node ready: true, restart count 0
Jul 15 23:13:54.922: INFO: ibm-master-proxy-static-10.190.211.93 from kube-system started at <nil> (0 container statuses recorded)
Jul 15 23:13:54.922: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-07-15 21:58:01 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.922: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Jul 15 23:13:54.923: INFO: 
Logging pods the kubelet thinks is on node 10.190.211.94 before test
Jul 15 23:13:54.957: INFO: ibm-keepalived-watcher-2wg6l from kube-system started at 2019-07-15 20:52:22 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.957: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jul 15 23:13:54.957: INFO: ibm-cloud-provider-ip-169-62-60-229-5746bf8754-p7mpv from ibm-system started at 2019-07-15 20:54:43 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.957: INFO: 	Container ibm-cloud-provider-ip-169-62-60-229 ready: true, restart count 0
Jul 15 23:13:54.957: INFO: kubernetes-dashboard-6c88b75685-qr28b from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.957: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jul 15 23:13:54.957: INFO: ibm-master-proxy-static-10.190.211.94 from kube-system started at <nil> (0 container statuses recorded)
Jul 15 23:13:54.957: INFO: ibm-storage-watcher-6979c6f4b8-hrmrc from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.957: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Jul 15 23:13:54.957: INFO: public-crf7531fcdf3c4443f99d3792052463a22-alb1-5c8744f6fb-4l5rc from kube-system started at 2019-07-15 20:56:16 +0000 UTC (4 container statuses recorded)
Jul 15 23:13:54.957: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jul 15 23:13:54.957: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jul 15 23:13:54.957: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jul 15 23:13:54.957: INFO: 	Container nginx-ingress ready: true, restart count 0
Jul 15 23:13:54.957: INFO: sonobuoy-systemd-logs-daemon-set-e8a5b131278f47ce-xndzt from heptio-sonobuoy started at 2019-07-15 21:58:11 +0000 UTC (2 container statuses recorded)
Jul 15 23:13:54.957: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jul 15 23:13:54.957: INFO: 	Container systemd-logs ready: true, restart count 1
Jul 15 23:13:54.957: INFO: calico-node-kmc66 from kube-system started at 2019-07-15 20:52:22 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.957: INFO: 	Container calico-node ready: true, restart count 0
Jul 15 23:13:54.957: INFO: coredns-74d7dffd76-lmpp5 from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.957: INFO: 	Container coredns ready: true, restart count 0
Jul 15 23:13:54.957: INFO: ibm-kube-fluentd-csglz from kube-system started at 2019-07-15 20:52:48 +0000 UTC (1 container statuses recorded)
Jul 15 23:13:54.957: INFO: 	Container fluentd ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node 10.190.211.91
STEP: verifying the node has the label node 10.190.211.93
STEP: verifying the node has the label node 10.190.211.94
Jul 15 23:13:55.093: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.190.211.93
Jul 15 23:13:55.093: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.190.211.93
Jul 15 23:13:55.093: INFO: Pod sonobuoy-e2e-job-d0083bb64b09449f requesting resource cpu=0m on Node 10.190.211.93
Jul 15 23:13:55.093: INFO: Pod sonobuoy-systemd-logs-daemon-set-e8a5b131278f47ce-msplm requesting resource cpu=0m on Node 10.190.211.91
Jul 15 23:13:55.093: INFO: Pod sonobuoy-systemd-logs-daemon-set-e8a5b131278f47ce-tctpt requesting resource cpu=0m on Node 10.190.211.93
Jul 15 23:13:55.093: INFO: Pod sonobuoy-systemd-logs-daemon-set-e8a5b131278f47ce-xndzt requesting resource cpu=0m on Node 10.190.211.94
Jul 15 23:13:55.093: INFO: Pod ibm-cloud-provider-ip-169-62-60-229-5746bf8754-p7mpv requesting resource cpu=5m on Node 10.190.211.94
Jul 15 23:13:55.093: INFO: Pod ibm-cloud-provider-ip-169-62-60-229-5746bf8754-pvhns requesting resource cpu=5m on Node 10.190.211.91
Jul 15 23:13:55.093: INFO: Pod calico-kube-controllers-658bc54b6f-dngkt requesting resource cpu=10m on Node 10.190.211.91
Jul 15 23:13:55.093: INFO: Pod calico-node-296f7 requesting resource cpu=250m on Node 10.190.211.91
Jul 15 23:13:55.093: INFO: Pod calico-node-dd7kh requesting resource cpu=250m on Node 10.190.211.93
Jul 15 23:13:55.093: INFO: Pod calico-node-kmc66 requesting resource cpu=250m on Node 10.190.211.94
Jul 15 23:13:55.094: INFO: Pod coredns-74d7dffd76-4skkd requesting resource cpu=100m on Node 10.190.211.91
Jul 15 23:13:55.094: INFO: Pod coredns-74d7dffd76-lmpp5 requesting resource cpu=100m on Node 10.190.211.94
Jul 15 23:13:55.094: INFO: Pod coredns-autoscaler-6d8b6f867-lm5sc requesting resource cpu=20m on Node 10.190.211.91
Jul 15 23:13:55.094: INFO: Pod ibm-file-plugin-76564988db-lwwst requesting resource cpu=50m on Node 10.190.211.91
Jul 15 23:13:55.094: INFO: Pod ibm-keepalived-watcher-2wg6l requesting resource cpu=5m on Node 10.190.211.94
Jul 15 23:13:55.094: INFO: Pod ibm-keepalived-watcher-7hbvk requesting resource cpu=5m on Node 10.190.211.91
Jul 15 23:13:55.094: INFO: Pod ibm-keepalived-watcher-svlzn requesting resource cpu=5m on Node 10.190.211.93
Jul 15 23:13:55.094: INFO: Pod ibm-kube-fluentd-csglz requesting resource cpu=25m on Node 10.190.211.94
Jul 15 23:13:55.094: INFO: Pod ibm-kube-fluentd-fw2dr requesting resource cpu=25m on Node 10.190.211.93
Jul 15 23:13:55.094: INFO: Pod ibm-kube-fluentd-qq2vb requesting resource cpu=25m on Node 10.190.211.91
Jul 15 23:13:55.094: INFO: Pod ibm-master-proxy-static-10.190.211.91 requesting resource cpu=25m on Node 10.190.211.91
Jul 15 23:13:55.094: INFO: Pod ibm-master-proxy-static-10.190.211.93 requesting resource cpu=25m on Node 10.190.211.93
Jul 15 23:13:55.094: INFO: Pod ibm-master-proxy-static-10.190.211.94 requesting resource cpu=25m on Node 10.190.211.94
Jul 15 23:13:55.095: INFO: Pod ibm-storage-watcher-6979c6f4b8-hrmrc requesting resource cpu=50m on Node 10.190.211.94
Jul 15 23:13:55.095: INFO: Pod kubernetes-dashboard-6c88b75685-qr28b requesting resource cpu=50m on Node 10.190.211.94
Jul 15 23:13:55.095: INFO: Pod metrics-server-6cdf95ffc5-rgpxg requesting resource cpu=53m on Node 10.190.211.91
Jul 15 23:13:55.095: INFO: Pod public-crf7531fcdf3c4443f99d3792052463a22-alb1-5c8744f6fb-4l5rc requesting resource cpu=896m on Node 10.190.211.94
Jul 15 23:13:55.095: INFO: Pod public-crf7531fcdf3c4443f99d3792052463a22-alb1-5c8744f6fb-lq8qt requesting resource cpu=896m on Node 10.190.211.91
Jul 15 23:13:55.095: INFO: Pod vpn-84dbfcd799-q9rz6 requesting resource cpu=5m on Node 10.190.211.91
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-377510fd-a756-11e9-983d-d6ce37abd03c.15b1b79e0ce002d6], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6715/filler-pod-377510fd-a756-11e9-983d-d6ce37abd03c to 10.190.211.93]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-377510fd-a756-11e9-983d-d6ce37abd03c.15b1b79e4d0d663b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-377510fd-a756-11e9-983d-d6ce37abd03c.15b1b79e5171f6e1], Reason = [Created], Message = [Created container filler-pod-377510fd-a756-11e9-983d-d6ce37abd03c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-377510fd-a756-11e9-983d-d6ce37abd03c.15b1b79e5d51b7de], Reason = [Started], Message = [Started container filler-pod-377510fd-a756-11e9-983d-d6ce37abd03c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-377906af-a756-11e9-983d-d6ce37abd03c.15b1b79e0e775056], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6715/filler-pod-377906af-a756-11e9-983d-d6ce37abd03c to 10.190.211.94]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-377906af-a756-11e9-983d-d6ce37abd03c.15b1b79e51ed717d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-377906af-a756-11e9-983d-d6ce37abd03c.15b1b79e5667df69], Reason = [Created], Message = [Created container filler-pod-377906af-a756-11e9-983d-d6ce37abd03c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-377906af-a756-11e9-983d-d6ce37abd03c.15b1b79e640895ee], Reason = [Started], Message = [Started container filler-pod-377906af-a756-11e9-983d-d6ce37abd03c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-377b5620-a756-11e9-983d-d6ce37abd03c.15b1b79e0f2a63da], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6715/filler-pod-377b5620-a756-11e9-983d-d6ce37abd03c to 10.190.211.91]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-377b5620-a756-11e9-983d-d6ce37abd03c.15b1b79e5155fc19], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-377b5620-a756-11e9-983d-d6ce37abd03c.15b1b79e553b4f59], Reason = [Created], Message = [Created container filler-pod-377b5620-a756-11e9-983d-d6ce37abd03c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-377b5620-a756-11e9-983d-d6ce37abd03c.15b1b79e603685cb], Reason = [Started], Message = [Started container filler-pod-377b5620-a756-11e9-983d-d6ce37abd03c]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15b1b79f030284f0], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.190.211.91
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.190.211.93
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.190.211.94
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:14:00.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6715" for this suite.
Jul 15 23:14:08.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:14:08.947: INFO: namespace sched-pred-6715 deletion completed in 8.512716167s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:14.367 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:14:08.947: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1510
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1510.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1510.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul 15 23:14:13.377: INFO: DNS probes using dns-1510/dns-test-3fd95bcc-a756-11e9-983d-d6ce37abd03c succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:14:13.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1510" for this suite.
Jul 15 23:14:19.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:14:19.841: INFO: namespace dns-1510 deletion completed in 6.410959193s

• [SLOW TEST:10.894 seconds]
[sig-network] DNS
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:14:19.842: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7316
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Jul 15 23:14:20.085: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-077690921 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:14:20.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7316" for this suite.
Jul 15 23:14:26.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:14:26.845: INFO: namespace kubectl-7316 deletion completed in 6.624507078s

• [SLOW TEST:7.004 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:14:26.845: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9013
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 23:14:27.089: INFO: Creating ReplicaSet my-hostname-basic-4a86fac4-a756-11e9-983d-d6ce37abd03c
Jul 15 23:14:27.110: INFO: Pod name my-hostname-basic-4a86fac4-a756-11e9-983d-d6ce37abd03c: Found 0 pods out of 1
Jul 15 23:14:32.120: INFO: Pod name my-hostname-basic-4a86fac4-a756-11e9-983d-d6ce37abd03c: Found 1 pods out of 1
Jul 15 23:14:32.121: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-4a86fac4-a756-11e9-983d-d6ce37abd03c" is running
Jul 15 23:14:32.134: INFO: Pod "my-hostname-basic-4a86fac4-a756-11e9-983d-d6ce37abd03c-q5b47" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-15 23:14:27 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-15 23:14:29 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-15 23:14:29 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-15 23:14:27 +0000 UTC Reason: Message:}])
Jul 15 23:14:32.134: INFO: Trying to dial the pod
Jul 15 23:14:37.178: INFO: Controller my-hostname-basic-4a86fac4-a756-11e9-983d-d6ce37abd03c: Got expected result from replica 1 [my-hostname-basic-4a86fac4-a756-11e9-983d-d6ce37abd03c-q5b47]: "my-hostname-basic-4a86fac4-a756-11e9-983d-d6ce37abd03c-q5b47", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:14:37.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9013" for this suite.
Jul 15 23:14:43.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:14:43.867: INFO: namespace replicaset-9013 deletion completed in 6.675186825s

• [SLOW TEST:17.021 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:14:43.867: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5536
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 23:14:44.170: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jul 15 23:14:44.193: INFO: Number of nodes with available pods: 0
Jul 15 23:14:44.193: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jul 15 23:14:44.238: INFO: Number of nodes with available pods: 0
Jul 15 23:14:44.238: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:14:45.250: INFO: Number of nodes with available pods: 0
Jul 15 23:14:45.250: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:14:46.249: INFO: Number of nodes with available pods: 1
Jul 15 23:14:46.249: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jul 15 23:14:46.301: INFO: Number of nodes with available pods: 1
Jul 15 23:14:46.301: INFO: Number of running nodes: 0, number of available pods: 1
Jul 15 23:14:47.311: INFO: Number of nodes with available pods: 0
Jul 15 23:14:47.311: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jul 15 23:14:47.334: INFO: Number of nodes with available pods: 0
Jul 15 23:14:47.334: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:14:48.348: INFO: Number of nodes with available pods: 0
Jul 15 23:14:48.349: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:14:49.345: INFO: Number of nodes with available pods: 0
Jul 15 23:14:49.345: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:14:50.344: INFO: Number of nodes with available pods: 0
Jul 15 23:14:50.344: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:14:51.345: INFO: Number of nodes with available pods: 0
Jul 15 23:14:51.345: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:14:52.347: INFO: Number of nodes with available pods: 0
Jul 15 23:14:52.347: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:14:53.345: INFO: Number of nodes with available pods: 0
Jul 15 23:14:53.345: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:14:54.350: INFO: Number of nodes with available pods: 0
Jul 15 23:14:54.350: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:14:55.357: INFO: Number of nodes with available pods: 0
Jul 15 23:14:55.357: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:14:56.345: INFO: Number of nodes with available pods: 0
Jul 15 23:14:56.345: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:14:57.347: INFO: Number of nodes with available pods: 0
Jul 15 23:14:57.347: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:14:58.345: INFO: Number of nodes with available pods: 0
Jul 15 23:14:58.346: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:14:59.344: INFO: Number of nodes with available pods: 0
Jul 15 23:14:59.344: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:15:00.345: INFO: Number of nodes with available pods: 0
Jul 15 23:15:00.345: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:15:01.365: INFO: Number of nodes with available pods: 1
Jul 15 23:15:01.365: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5536, will wait for the garbage collector to delete the pods
Jul 15 23:15:01.475: INFO: Deleting DaemonSet.extensions daemon-set took: 29.125407ms
Jul 15 23:15:01.675: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.346473ms
Jul 15 23:15:04.790: INFO: Number of nodes with available pods: 0
Jul 15 23:15:04.790: INFO: Number of running nodes: 0, number of available pods: 0
Jul 15 23:15:04.802: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5536/daemonsets","resourceVersion":"28881"},"items":null}

Jul 15 23:15:04.811: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5536/pods","resourceVersion":"28881"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:15:04.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5536" for this suite.
Jul 15 23:15:10.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:15:11.354: INFO: namespace daemonsets-5536 deletion completed in 6.437317672s

• [SLOW TEST:27.487 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:15:11.356: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9474
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-9474
Jul 15 23:15:13.633: INFO: Started pod liveness-http in namespace container-probe-9474
STEP: checking the pod's current state and verifying that restartCount is present
Jul 15 23:15:13.643: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:19:15.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9474" for this suite.
Jul 15 23:19:21.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:19:21.964: INFO: namespace container-probe-9474 deletion completed in 6.369167239s

• [SLOW TEST:250.608 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:19:21.965: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-9167
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Jul 15 23:19:24.905: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9167 pod-service-account-fad0f9d4-a756-11e9-983d-d6ce37abd03c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Jul 15 23:19:25.336: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9167 pod-service-account-fad0f9d4-a756-11e9-983d-d6ce37abd03c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Jul 15 23:19:25.760: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9167 pod-service-account-fad0f9d4-a756-11e9-983d-d6ce37abd03c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:19:26.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9167" for this suite.
Jul 15 23:19:32.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:19:32.538: INFO: namespace svcaccounts-9167 deletion completed in 6.375144514s

• [SLOW TEST:10.573 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:19:32.538: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9635
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-00b9a608-a757-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume secrets
Jul 15 23:19:32.806: INFO: Waiting up to 5m0s for pod "pod-secrets-00bba4c7-a757-11e9-983d-d6ce37abd03c" in namespace "secrets-9635" to be "success or failure"
Jul 15 23:19:32.818: INFO: Pod "pod-secrets-00bba4c7-a757-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.858306ms
Jul 15 23:19:34.828: INFO: Pod "pod-secrets-00bba4c7-a757-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022290699s
Jul 15 23:19:36.852: INFO: Pod "pod-secrets-00bba4c7-a757-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04575147s
STEP: Saw pod success
Jul 15 23:19:36.852: INFO: Pod "pod-secrets-00bba4c7-a757-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:19:36.864: INFO: Trying to get logs from node 10.190.211.93 pod pod-secrets-00bba4c7-a757-11e9-983d-d6ce37abd03c container secret-volume-test: <nil>
STEP: delete the pod
Jul 15 23:19:36.979: INFO: Waiting for pod pod-secrets-00bba4c7-a757-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:19:36.997: INFO: Pod pod-secrets-00bba4c7-a757-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:19:36.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9635" for this suite.
Jul 15 23:19:43.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:19:43.394: INFO: namespace secrets-9635 deletion completed in 6.36891349s

• [SLOW TEST:10.856 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:19:43.395: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6488
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Jul 15 23:19:43.629: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-077690921 proxy --unix-socket=/tmp/kubectl-proxy-unix592674280/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:19:43.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6488" for this suite.
Jul 15 23:19:49.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:19:50.122: INFO: namespace kubectl-6488 deletion completed in 6.423846784s

• [SLOW TEST:6.728 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:19:50.123: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6531
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-6531
Jul 15 23:19:54.377: INFO: Started pod liveness-http in namespace container-probe-6531
STEP: checking the pod's current state and verifying that restartCount is present
Jul 15 23:19:54.387: INFO: Initial restart count of pod liveness-http is 0
Jul 15 23:20:16.533: INFO: Restart count of pod container-probe-6531/liveness-http is now 1 (22.145863513s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:20:16.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6531" for this suite.
Jul 15 23:20:24.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:20:25.164: INFO: namespace container-probe-6531 deletion completed in 8.578593599s

• [SLOW TEST:35.041 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:20:25.165: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8785
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 23:20:25.388: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:20:26.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8785" for this suite.
Jul 15 23:20:32.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:20:32.971: INFO: namespace custom-resource-definition-8785 deletion completed in 6.424367852s

• [SLOW TEST:7.806 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:20:32.972: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1573
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul 15 23:20:33.205: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 15 23:20:33.402: INFO: Waiting for terminating namespaces to be deleted...
Jul 15 23:20:33.412: INFO: 
Logging pods the kubelet thinks is on node 10.190.211.91 before test
Jul 15 23:20:33.447: INFO: coredns-74d7dffd76-4skkd from kube-system started at 2019-07-15 20:52:46 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.447: INFO: 	Container coredns ready: true, restart count 0
Jul 15 23:20:33.447: INFO: ibm-master-proxy-static-10.190.211.91 from kube-system started at <nil> (0 container statuses recorded)
Jul 15 23:20:33.447: INFO: calico-node-296f7 from kube-system started at 2019-07-15 20:52:20 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.447: INFO: 	Container calico-node ready: true, restart count 0
Jul 15 23:20:33.447: INFO: metrics-server-6cdf95ffc5-rgpxg from kube-system started at 2019-07-15 20:52:51 +0000 UTC (2 container statuses recorded)
Jul 15 23:20:33.447: INFO: 	Container metrics-server ready: true, restart count 0
Jul 15 23:20:33.447: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Jul 15 23:20:33.447: INFO: sonobuoy-systemd-logs-daemon-set-e8a5b131278f47ce-msplm from heptio-sonobuoy started at 2019-07-15 21:58:11 +0000 UTC (2 container statuses recorded)
Jul 15 23:20:33.447: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jul 15 23:20:33.447: INFO: 	Container systemd-logs ready: true, restart count 1
Jul 15 23:20:33.447: INFO: ibm-file-plugin-76564988db-lwwst from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.447: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Jul 15 23:20:33.447: INFO: coredns-autoscaler-6d8b6f867-lm5sc from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.447: INFO: 	Container autoscaler ready: true, restart count 0
Jul 15 23:20:33.447: INFO: ibm-kube-fluentd-qq2vb from kube-system started at 2019-07-15 20:52:48 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.447: INFO: 	Container fluentd ready: true, restart count 0
Jul 15 23:20:33.447: INFO: ibm-cloud-provider-ip-169-62-60-229-5746bf8754-pvhns from ibm-system started at 2019-07-15 20:54:43 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.448: INFO: 	Container ibm-cloud-provider-ip-169-62-60-229 ready: true, restart count 0
Jul 15 23:20:33.448: INFO: public-crf7531fcdf3c4443f99d3792052463a22-alb1-5c8744f6fb-lq8qt from kube-system started at 2019-07-15 20:56:16 +0000 UTC (4 container statuses recorded)
Jul 15 23:20:33.448: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jul 15 23:20:33.448: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jul 15 23:20:33.448: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jul 15 23:20:33.448: INFO: 	Container nginx-ingress ready: true, restart count 0
Jul 15 23:20:33.448: INFO: ibm-keepalived-watcher-7hbvk from kube-system started at 2019-07-15 20:52:20 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.448: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jul 15 23:20:33.448: INFO: vpn-84dbfcd799-q9rz6 from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.448: INFO: 	Container vpn ready: true, restart count 0
Jul 15 23:20:33.448: INFO: calico-kube-controllers-658bc54b6f-dngkt from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.448: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jul 15 23:20:33.448: INFO: 
Logging pods the kubelet thinks is on node 10.190.211.93 before test
Jul 15 23:20:33.477: INFO: ibm-master-proxy-static-10.190.211.93 from kube-system started at <nil> (0 container statuses recorded)
Jul 15 23:20:33.477: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-07-15 21:58:01 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.477: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Jul 15 23:20:33.477: INFO: ibm-keepalived-watcher-svlzn from kube-system started at 2019-07-15 20:57:54 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.477: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jul 15 23:20:33.477: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-15 21:58:06 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.477: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 15 23:20:33.477: INFO: sonobuoy-e2e-job-d0083bb64b09449f from heptio-sonobuoy started at 2019-07-15 21:58:11 +0000 UTC (2 container statuses recorded)
Jul 15 23:20:33.477: INFO: 	Container e2e ready: true, restart count 0
Jul 15 23:20:33.477: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 15 23:20:33.477: INFO: sonobuoy-systemd-logs-daemon-set-e8a5b131278f47ce-tctpt from heptio-sonobuoy started at 2019-07-15 21:58:11 +0000 UTC (2 container statuses recorded)
Jul 15 23:20:33.477: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jul 15 23:20:33.477: INFO: 	Container systemd-logs ready: true, restart count 1
Jul 15 23:20:33.478: INFO: ibm-kube-fluentd-fw2dr from kube-system started at 2019-07-15 20:57:54 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.478: INFO: 	Container fluentd ready: true, restart count 0
Jul 15 23:20:33.478: INFO: calico-node-dd7kh from kube-system started at 2019-07-15 20:57:54 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.478: INFO: 	Container calico-node ready: true, restart count 0
Jul 15 23:20:33.478: INFO: 
Logging pods the kubelet thinks is on node 10.190.211.94 before test
Jul 15 23:20:33.529: INFO: ibm-keepalived-watcher-2wg6l from kube-system started at 2019-07-15 20:52:22 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.529: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jul 15 23:20:33.529: INFO: ibm-cloud-provider-ip-169-62-60-229-5746bf8754-p7mpv from ibm-system started at 2019-07-15 20:54:43 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.529: INFO: 	Container ibm-cloud-provider-ip-169-62-60-229 ready: true, restart count 0
Jul 15 23:20:33.529: INFO: kubernetes-dashboard-6c88b75685-qr28b from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.529: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jul 15 23:20:33.529: INFO: ibm-master-proxy-static-10.190.211.94 from kube-system started at <nil> (0 container statuses recorded)
Jul 15 23:20:33.529: INFO: ibm-storage-watcher-6979c6f4b8-hrmrc from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.529: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Jul 15 23:20:33.529: INFO: public-crf7531fcdf3c4443f99d3792052463a22-alb1-5c8744f6fb-4l5rc from kube-system started at 2019-07-15 20:56:16 +0000 UTC (4 container statuses recorded)
Jul 15 23:20:33.529: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jul 15 23:20:33.529: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jul 15 23:20:33.529: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jul 15 23:20:33.529: INFO: 	Container nginx-ingress ready: true, restart count 0
Jul 15 23:20:33.529: INFO: sonobuoy-systemd-logs-daemon-set-e8a5b131278f47ce-xndzt from heptio-sonobuoy started at 2019-07-15 21:58:11 +0000 UTC (2 container statuses recorded)
Jul 15 23:20:33.529: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jul 15 23:20:33.529: INFO: 	Container systemd-logs ready: true, restart count 1
Jul 15 23:20:33.529: INFO: calico-node-kmc66 from kube-system started at 2019-07-15 20:52:22 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.529: INFO: 	Container calico-node ready: true, restart count 0
Jul 15 23:20:33.529: INFO: coredns-74d7dffd76-lmpp5 from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.529: INFO: 	Container coredns ready: true, restart count 0
Jul 15 23:20:33.529: INFO: ibm-kube-fluentd-csglz from kube-system started at 2019-07-15 20:52:48 +0000 UTC (1 container statuses recorded)
Jul 15 23:20:33.529: INFO: 	Container fluentd ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-26518bf9-a757-11e9-983d-d6ce37abd03c 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-26518bf9-a757-11e9-983d-d6ce37abd03c off the node 10.190.211.93
STEP: verifying the node doesn't have the label kubernetes.io/e2e-26518bf9-a757-11e9-983d-d6ce37abd03c
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:20:39.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1573" for this suite.
Jul 15 23:20:48.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:20:48.451: INFO: namespace sched-pred-1573 deletion completed in 8.440388196s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:15.479 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:20:48.452: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2459
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-2459/configmap-test-2dfb19d2-a757-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume configMaps
Jul 15 23:20:48.734: INFO: Waiting up to 5m0s for pod "pod-configmaps-2dfc6b27-a757-11e9-983d-d6ce37abd03c" in namespace "configmap-2459" to be "success or failure"
Jul 15 23:20:48.751: INFO: Pod "pod-configmaps-2dfc6b27-a757-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.335572ms
Jul 15 23:20:50.814: INFO: Pod "pod-configmaps-2dfc6b27-a757-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080397214s
Jul 15 23:20:52.824: INFO: Pod "pod-configmaps-2dfc6b27-a757-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.090720758s
STEP: Saw pod success
Jul 15 23:20:52.825: INFO: Pod "pod-configmaps-2dfc6b27-a757-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:20:52.835: INFO: Trying to get logs from node 10.190.211.93 pod pod-configmaps-2dfc6b27-a757-11e9-983d-d6ce37abd03c container env-test: <nil>
STEP: delete the pod
Jul 15 23:20:52.903: INFO: Waiting for pod pod-configmaps-2dfc6b27-a757-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:20:52.916: INFO: Pod pod-configmaps-2dfc6b27-a757-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:20:52.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2459" for this suite.
Jul 15 23:20:58.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:20:59.380: INFO: namespace configmap-2459 deletion completed in 6.449414215s

• [SLOW TEST:10.928 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:20:59.382: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7765
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-7765
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Jul 15 23:20:59.644: INFO: Found 0 stateful pods, waiting for 3
Jul 15 23:21:09.655: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 23:21:09.655: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 23:21:09.655: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jul 15 23:21:09.738: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jul 15 23:21:19.833: INFO: Updating stateful set ss2
Jul 15 23:21:19.865: INFO: Waiting for Pod statefulset-7765/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Jul 15 23:21:29.971: INFO: Found 2 stateful pods, waiting for 3
Jul 15 23:21:39.982: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 23:21:39.982: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 23:21:39.982: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jul 15 23:21:40.041: INFO: Updating stateful set ss2
Jul 15 23:21:40.064: INFO: Waiting for Pod statefulset-7765/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jul 15 23:21:50.105: INFO: Waiting for Pod statefulset-7765/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jul 15 23:22:00.118: INFO: Updating stateful set ss2
Jul 15 23:22:00.138: INFO: Waiting for StatefulSet statefulset-7765/ss2 to complete update
Jul 15 23:22:00.138: INFO: Waiting for Pod statefulset-7765/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jul 15 23:22:10.160: INFO: Waiting for StatefulSet statefulset-7765/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 15 23:22:20.166: INFO: Deleting all statefulset in ns statefulset-7765
Jul 15 23:22:20.177: INFO: Scaling statefulset ss2 to 0
Jul 15 23:22:50.239: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 23:22:50.248: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:22:50.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7765" for this suite.
Jul 15 23:22:58.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:22:58.725: INFO: namespace statefulset-7765 deletion completed in 8.40586238s

• [SLOW TEST:119.343 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:22:58.726: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6912
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul 15 23:22:59.032: INFO: Number of nodes with available pods: 0
Jul 15 23:22:59.032: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:23:00.062: INFO: Number of nodes with available pods: 0
Jul 15 23:23:00.062: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:23:01.064: INFO: Number of nodes with available pods: 2
Jul 15 23:23:01.064: INFO: Node 10.190.211.93 is running more than one daemon pod
Jul 15 23:23:02.065: INFO: Number of nodes with available pods: 3
Jul 15 23:23:02.065: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jul 15 23:23:02.156: INFO: Number of nodes with available pods: 2
Jul 15 23:23:02.156: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:23:03.181: INFO: Number of nodes with available pods: 2
Jul 15 23:23:03.181: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:23:04.196: INFO: Number of nodes with available pods: 2
Jul 15 23:23:04.196: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:23:05.181: INFO: Number of nodes with available pods: 2
Jul 15 23:23:05.181: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:23:06.183: INFO: Number of nodes with available pods: 2
Jul 15 23:23:06.183: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:23:07.180: INFO: Number of nodes with available pods: 2
Jul 15 23:23:07.180: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:23:08.193: INFO: Number of nodes with available pods: 2
Jul 15 23:23:08.193: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:23:09.221: INFO: Number of nodes with available pods: 2
Jul 15 23:23:09.221: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:23:10.180: INFO: Number of nodes with available pods: 2
Jul 15 23:23:10.180: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:23:11.182: INFO: Number of nodes with available pods: 3
Jul 15 23:23:11.182: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6912, will wait for the garbage collector to delete the pods
Jul 15 23:23:11.282: INFO: Deleting DaemonSet.extensions daemon-set took: 25.860106ms
Jul 15 23:23:11.485: INFO: Terminating DaemonSet.extensions daemon-set pods took: 202.383103ms
Jul 15 23:23:22.500: INFO: Number of nodes with available pods: 0
Jul 15 23:23:22.500: INFO: Number of running nodes: 0, number of available pods: 0
Jul 15 23:23:22.510: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6912/daemonsets","resourceVersion":"30432"},"items":null}

Jul 15 23:23:22.519: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6912/pods","resourceVersion":"30432"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:23:22.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6912" for this suite.
Jul 15 23:23:30.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:23:31.014: INFO: namespace daemonsets-6912 deletion completed in 8.418821447s

• [SLOW TEST:32.289 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:23:31.015: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7916
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:23:35.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7916" for this suite.
Jul 15 23:24:15.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:24:15.743: INFO: namespace kubelet-test-7916 deletion completed in 40.399924076s

• [SLOW TEST:44.727 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:24:15.743: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8578
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 15 23:24:16.017: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jul 15 23:24:16.052: INFO: Number of nodes with available pods: 0
Jul 15 23:24:16.052: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:24:17.075: INFO: Number of nodes with available pods: 0
Jul 15 23:24:17.075: INFO: Node 10.190.211.91 is running more than one daemon pod
Jul 15 23:24:18.078: INFO: Number of nodes with available pods: 3
Jul 15 23:24:18.078: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jul 15 23:24:18.169: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:18.169: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:18.169: INFO: Wrong image for pod: daemon-set-vhxzt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:19.196: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:19.196: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:19.196: INFO: Wrong image for pod: daemon-set-vhxzt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:20.209: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:20.209: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:20.209: INFO: Wrong image for pod: daemon-set-vhxzt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:21.193: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:21.193: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:21.193: INFO: Wrong image for pod: daemon-set-vhxzt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:21.194: INFO: Pod daemon-set-vhxzt is not available
Jul 15 23:24:22.194: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:22.194: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:22.194: INFO: Wrong image for pod: daemon-set-vhxzt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:22.194: INFO: Pod daemon-set-vhxzt is not available
Jul 15 23:24:23.194: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:23.194: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:23.194: INFO: Wrong image for pod: daemon-set-vhxzt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:23.194: INFO: Pod daemon-set-vhxzt is not available
Jul 15 23:24:24.192: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:24.192: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:24.192: INFO: Wrong image for pod: daemon-set-vhxzt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:24.192: INFO: Pod daemon-set-vhxzt is not available
Jul 15 23:24:25.193: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:25.193: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:25.193: INFO: Wrong image for pod: daemon-set-vhxzt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:25.193: INFO: Pod daemon-set-vhxzt is not available
Jul 15 23:24:26.193: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:26.193: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:26.193: INFO: Wrong image for pod: daemon-set-vhxzt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:26.194: INFO: Pod daemon-set-vhxzt is not available
Jul 15 23:24:27.198: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:27.198: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:27.198: INFO: Wrong image for pod: daemon-set-vhxzt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:27.198: INFO: Pod daemon-set-vhxzt is not available
Jul 15 23:24:28.194: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:28.194: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:28.194: INFO: Wrong image for pod: daemon-set-vhxzt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:28.194: INFO: Pod daemon-set-vhxzt is not available
Jul 15 23:24:29.193: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:29.193: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:29.193: INFO: Wrong image for pod: daemon-set-vhxzt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:29.193: INFO: Pod daemon-set-vhxzt is not available
Jul 15 23:24:30.196: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:30.196: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:30.196: INFO: Wrong image for pod: daemon-set-vhxzt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:30.196: INFO: Pod daemon-set-vhxzt is not available
Jul 15 23:24:31.194: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:31.194: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:31.194: INFO: Wrong image for pod: daemon-set-vhxzt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:31.194: INFO: Pod daemon-set-vhxzt is not available
Jul 15 23:24:32.197: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:32.197: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:32.197: INFO: Wrong image for pod: daemon-set-vhxzt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:32.197: INFO: Pod daemon-set-vhxzt is not available
Jul 15 23:24:33.193: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:33.193: INFO: Pod daemon-set-fgnxm is not available
Jul 15 23:24:33.193: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:34.193: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:34.193: INFO: Pod daemon-set-fgnxm is not available
Jul 15 23:24:34.193: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:35.194: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:35.194: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:36.193: INFO: Wrong image for pod: daemon-set-97rp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:36.193: INFO: Pod daemon-set-97rp9 is not available
Jul 15 23:24:36.193: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:37.195: INFO: Pod daemon-set-2f2mm is not available
Jul 15 23:24:37.195: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:38.193: INFO: Pod daemon-set-2f2mm is not available
Jul 15 23:24:38.193: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:39.193: INFO: Pod daemon-set-2f2mm is not available
Jul 15 23:24:39.193: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:40.194: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:41.203: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:41.203: INFO: Pod daemon-set-mjw79 is not available
Jul 15 23:24:42.195: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:42.195: INFO: Pod daemon-set-mjw79 is not available
Jul 15 23:24:43.193: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:43.193: INFO: Pod daemon-set-mjw79 is not available
Jul 15 23:24:44.194: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:44.194: INFO: Pod daemon-set-mjw79 is not available
Jul 15 23:24:45.196: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:45.196: INFO: Pod daemon-set-mjw79 is not available
Jul 15 23:24:46.193: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:46.193: INFO: Pod daemon-set-mjw79 is not available
Jul 15 23:24:47.194: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:47.194: INFO: Pod daemon-set-mjw79 is not available
Jul 15 23:24:48.194: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:48.194: INFO: Pod daemon-set-mjw79 is not available
Jul 15 23:24:49.193: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:49.193: INFO: Pod daemon-set-mjw79 is not available
Jul 15 23:24:50.193: INFO: Wrong image for pod: daemon-set-mjw79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 15 23:24:50.193: INFO: Pod daemon-set-mjw79 is not available
Jul 15 23:24:51.195: INFO: Pod daemon-set-m5rbn is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Jul 15 23:24:51.230: INFO: Number of nodes with available pods: 2
Jul 15 23:24:51.230: INFO: Node 10.190.211.94 is running more than one daemon pod
Jul 15 23:24:52.256: INFO: Number of nodes with available pods: 2
Jul 15 23:24:52.256: INFO: Node 10.190.211.94 is running more than one daemon pod
Jul 15 23:24:53.254: INFO: Number of nodes with available pods: 2
Jul 15 23:24:53.254: INFO: Node 10.190.211.94 is running more than one daemon pod
Jul 15 23:24:54.253: INFO: Number of nodes with available pods: 3
Jul 15 23:24:54.253: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8578, will wait for the garbage collector to delete the pods
Jul 15 23:24:54.398: INFO: Deleting DaemonSet.extensions daemon-set took: 22.571022ms
Jul 15 23:24:54.598: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.203623ms
Jul 15 23:25:02.508: INFO: Number of nodes with available pods: 0
Jul 15 23:25:02.508: INFO: Number of running nodes: 0, number of available pods: 0
Jul 15 23:25:02.517: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8578/daemonsets","resourceVersion":"30823"},"items":null}

Jul 15 23:25:02.527: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8578/pods","resourceVersion":"30823"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:25:02.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8578" for this suite.
Jul 15 23:25:10.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:25:10.978: INFO: namespace daemonsets-8578 deletion completed in 8.37703542s

• [SLOW TEST:55.235 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:25:10.979: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5463
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:25:11.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5463" for this suite.
Jul 15 23:25:33.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:25:33.634: INFO: namespace kubelet-test-5463 deletion completed in 22.377366368s

• [SLOW TEST:22.655 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:25:33.635: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4721
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul 15 23:25:33.869: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 15 23:25:33.894: INFO: Waiting for terminating namespaces to be deleted...
Jul 15 23:25:33.903: INFO: 
Logging pods the kubelet thinks is on node 10.190.211.91 before test
Jul 15 23:25:33.940: INFO: calico-kube-controllers-658bc54b6f-dngkt from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:33.940: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jul 15 23:25:33.940: INFO: ibm-cloud-provider-ip-169-62-60-229-5746bf8754-pvhns from ibm-system started at 2019-07-15 20:54:43 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:33.940: INFO: 	Container ibm-cloud-provider-ip-169-62-60-229 ready: true, restart count 0
Jul 15 23:25:33.940: INFO: public-crf7531fcdf3c4443f99d3792052463a22-alb1-5c8744f6fb-lq8qt from kube-system started at 2019-07-15 20:56:16 +0000 UTC (4 container statuses recorded)
Jul 15 23:25:33.940: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jul 15 23:25:33.940: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jul 15 23:25:33.940: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jul 15 23:25:33.940: INFO: 	Container nginx-ingress ready: true, restart count 0
Jul 15 23:25:33.940: INFO: ibm-keepalived-watcher-7hbvk from kube-system started at 2019-07-15 20:52:20 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:33.940: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jul 15 23:25:33.940: INFO: vpn-84dbfcd799-q9rz6 from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:33.940: INFO: 	Container vpn ready: true, restart count 0
Jul 15 23:25:33.940: INFO: coredns-74d7dffd76-4skkd from kube-system started at 2019-07-15 20:52:46 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:33.940: INFO: 	Container coredns ready: true, restart count 0
Jul 15 23:25:33.940: INFO: ibm-master-proxy-static-10.190.211.91 from kube-system started at <nil> (0 container statuses recorded)
Jul 15 23:25:33.940: INFO: calico-node-296f7 from kube-system started at 2019-07-15 20:52:20 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:33.940: INFO: 	Container calico-node ready: true, restart count 0
Jul 15 23:25:33.940: INFO: ibm-kube-fluentd-qq2vb from kube-system started at 2019-07-15 20:52:48 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:33.940: INFO: 	Container fluentd ready: true, restart count 0
Jul 15 23:25:33.940: INFO: metrics-server-6cdf95ffc5-rgpxg from kube-system started at 2019-07-15 20:52:51 +0000 UTC (2 container statuses recorded)
Jul 15 23:25:33.940: INFO: 	Container metrics-server ready: true, restart count 0
Jul 15 23:25:33.940: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Jul 15 23:25:33.940: INFO: sonobuoy-systemd-logs-daemon-set-e8a5b131278f47ce-msplm from heptio-sonobuoy started at 2019-07-15 21:58:11 +0000 UTC (2 container statuses recorded)
Jul 15 23:25:33.940: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jul 15 23:25:33.940: INFO: 	Container systemd-logs ready: true, restart count 1
Jul 15 23:25:33.940: INFO: ibm-file-plugin-76564988db-lwwst from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:33.940: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Jul 15 23:25:33.940: INFO: coredns-autoscaler-6d8b6f867-lm5sc from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:33.940: INFO: 	Container autoscaler ready: true, restart count 0
Jul 15 23:25:33.940: INFO: 
Logging pods the kubelet thinks is on node 10.190.211.93 before test
Jul 15 23:25:33.970: INFO: calico-node-dd7kh from kube-system started at 2019-07-15 20:57:54 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:33.970: INFO: 	Container calico-node ready: true, restart count 0
Jul 15 23:25:33.970: INFO: ibm-kube-fluentd-fw2dr from kube-system started at 2019-07-15 20:57:54 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:33.970: INFO: 	Container fluentd ready: true, restart count 0
Jul 15 23:25:33.970: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-07-15 21:58:01 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:33.970: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Jul 15 23:25:33.970: INFO: ibm-master-proxy-static-10.190.211.93 from kube-system started at <nil> (0 container statuses recorded)
Jul 15 23:25:33.970: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-15 21:58:06 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:33.970: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 15 23:25:33.970: INFO: ibm-keepalived-watcher-svlzn from kube-system started at 2019-07-15 20:57:54 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:33.970: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jul 15 23:25:33.970: INFO: sonobuoy-systemd-logs-daemon-set-e8a5b131278f47ce-tctpt from heptio-sonobuoy started at 2019-07-15 21:58:11 +0000 UTC (2 container statuses recorded)
Jul 15 23:25:33.970: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jul 15 23:25:33.970: INFO: 	Container systemd-logs ready: true, restart count 1
Jul 15 23:25:33.970: INFO: sonobuoy-e2e-job-d0083bb64b09449f from heptio-sonobuoy started at 2019-07-15 21:58:11 +0000 UTC (2 container statuses recorded)
Jul 15 23:25:33.970: INFO: 	Container e2e ready: true, restart count 0
Jul 15 23:25:33.970: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 15 23:25:33.970: INFO: 
Logging pods the kubelet thinks is on node 10.190.211.94 before test
Jul 15 23:25:34.022: INFO: calico-node-kmc66 from kube-system started at 2019-07-15 20:52:22 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:34.022: INFO: 	Container calico-node ready: true, restart count 0
Jul 15 23:25:34.022: INFO: coredns-74d7dffd76-lmpp5 from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:34.022: INFO: 	Container coredns ready: true, restart count 0
Jul 15 23:25:34.022: INFO: ibm-kube-fluentd-csglz from kube-system started at 2019-07-15 20:52:48 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:34.022: INFO: 	Container fluentd ready: true, restart count 0
Jul 15 23:25:34.022: INFO: ibm-keepalived-watcher-2wg6l from kube-system started at 2019-07-15 20:52:22 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:34.022: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jul 15 23:25:34.022: INFO: ibm-cloud-provider-ip-169-62-60-229-5746bf8754-p7mpv from ibm-system started at 2019-07-15 20:54:43 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:34.022: INFO: 	Container ibm-cloud-provider-ip-169-62-60-229 ready: true, restart count 0
Jul 15 23:25:34.022: INFO: kubernetes-dashboard-6c88b75685-qr28b from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:34.022: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jul 15 23:25:34.022: INFO: ibm-master-proxy-static-10.190.211.94 from kube-system started at <nil> (0 container statuses recorded)
Jul 15 23:25:34.022: INFO: ibm-storage-watcher-6979c6f4b8-hrmrc from kube-system started at 2019-07-15 20:52:36 +0000 UTC (1 container statuses recorded)
Jul 15 23:25:34.022: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Jul 15 23:25:34.022: INFO: public-crf7531fcdf3c4443f99d3792052463a22-alb1-5c8744f6fb-4l5rc from kube-system started at 2019-07-15 20:56:16 +0000 UTC (4 container statuses recorded)
Jul 15 23:25:34.022: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jul 15 23:25:34.022: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jul 15 23:25:34.022: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jul 15 23:25:34.022: INFO: 	Container nginx-ingress ready: true, restart count 0
Jul 15 23:25:34.022: INFO: sonobuoy-systemd-logs-daemon-set-e8a5b131278f47ce-xndzt from heptio-sonobuoy started at 2019-07-15 21:58:11 +0000 UTC (2 container statuses recorded)
Jul 15 23:25:34.022: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jul 15 23:25:34.022: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15b1b840c94fad73], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:25:35.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4721" for this suite.
Jul 15 23:25:41.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:25:41.475: INFO: namespace sched-pred-4721 deletion completed in 6.371040156s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.840 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:25:41.475: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3205
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jul 15 23:25:41.726: INFO: Waiting up to 5m0s for pod "pod-dca1410e-a757-11e9-983d-d6ce37abd03c" in namespace "emptydir-3205" to be "success or failure"
Jul 15 23:25:41.739: INFO: Pod "pod-dca1410e-a757-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.562643ms
Jul 15 23:25:43.749: INFO: Pod "pod-dca1410e-a757-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022812148s
STEP: Saw pod success
Jul 15 23:25:43.749: INFO: Pod "pod-dca1410e-a757-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:25:43.759: INFO: Trying to get logs from node 10.190.211.93 pod pod-dca1410e-a757-11e9-983d-d6ce37abd03c container test-container: <nil>
STEP: delete the pod
Jul 15 23:25:43.811: INFO: Waiting for pod pod-dca1410e-a757-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:25:43.823: INFO: Pod pod-dca1410e-a757-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:25:43.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3205" for this suite.
Jul 15 23:25:49.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:25:50.254: INFO: namespace emptydir-3205 deletion completed in 6.417257621s

• [SLOW TEST:8.779 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:25:50.255: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4098
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-e1db36e0-a757-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume configMaps
Jul 15 23:25:50.510: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e1dcb419-a757-11e9-983d-d6ce37abd03c" in namespace "projected-4098" to be "success or failure"
Jul 15 23:25:50.521: INFO: Pod "pod-projected-configmaps-e1dcb419-a757-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.685983ms
Jul 15 23:25:52.531: INFO: Pod "pod-projected-configmaps-e1dcb419-a757-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020632366s
Jul 15 23:25:54.542: INFO: Pod "pod-projected-configmaps-e1dcb419-a757-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032041176s
STEP: Saw pod success
Jul 15 23:25:54.542: INFO: Pod "pod-projected-configmaps-e1dcb419-a757-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:25:54.554: INFO: Trying to get logs from node 10.190.211.93 pod pod-projected-configmaps-e1dcb419-a757-11e9-983d-d6ce37abd03c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 23:25:54.616: INFO: Waiting for pod pod-projected-configmaps-e1dcb419-a757-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:25:54.626: INFO: Pod pod-projected-configmaps-e1dcb419-a757-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:25:54.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4098" for this suite.
Jul 15 23:26:00.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:26:01.035: INFO: namespace projected-4098 deletion completed in 6.386588881s

• [SLOW TEST:10.780 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:26:01.036: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-1927
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Jul 15 23:26:01.282: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-1927" to be "success or failure"
Jul 15 23:26:01.300: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 17.975819ms
Jul 15 23:26:03.310: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028492948s
Jul 15 23:26:05.324: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041922611s
STEP: Saw pod success
Jul 15 23:26:05.324: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jul 15 23:26:05.334: INFO: Trying to get logs from node 10.190.211.93 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jul 15 23:26:05.395: INFO: Waiting for pod pod-host-path-test to disappear
Jul 15 23:26:05.405: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:26:05.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-1927" for this suite.
Jul 15 23:26:11.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:26:11.930: INFO: namespace hostpath-1927 deletion completed in 6.502693647s

• [SLOW TEST:10.894 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:26:11.930: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7320
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-eec9e3aa-a757-11e9-983d-d6ce37abd03c
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-eec9e3aa-a757-11e9-983d-d6ce37abd03c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:26:16.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7320" for this suite.
Jul 15 23:26:40.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:26:40.913: INFO: namespace projected-7320 deletion completed in 24.363871764s

• [SLOW TEST:28.984 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:26:40.914: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8644
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jul 15 23:26:45.274: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 23:26:45.286: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 23:26:47.286: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 23:26:47.302: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 23:26:49.286: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 23:26:49.299: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 23:26:51.286: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 23:26:51.305: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 23:26:53.286: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 23:26:53.300: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 23:26:55.286: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 23:26:55.297: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 23:26:57.286: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 23:26:57.298: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 23:26:59.286: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 23:26:59.296: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 23:27:01.286: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 23:27:01.297: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 23:27:03.286: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 23:27:03.298: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 23:27:05.286: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 23:27:05.300: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 23:27:07.286: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 23:27:07.296: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 23:27:09.286: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 23:27:09.297: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 23:27:11.286: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 23:27:11.296: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 23:27:13.286: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 23:27:13.296: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:27:13.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8644" for this suite.
Jul 15 23:27:37.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:27:37.755: INFO: namespace container-lifecycle-hook-8644 deletion completed in 24.412262904s

• [SLOW TEST:56.842 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:27:37.756: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7923
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Jul 15 23:27:37.995: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:27:52.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7923" for this suite.
Jul 15 23:27:58.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:27:58.872: INFO: namespace pods-7923 deletion completed in 6.386968096s

• [SLOW TEST:21.116 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:27:58.872: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4790
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Jul 15 23:27:59.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 api-versions'
Jul 15 23:27:59.197: INFO: stderr: ""
Jul 15 23:27:59.197: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:27:59.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4790" for this suite.
Jul 15 23:28:05.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:28:05.611: INFO: namespace kubectl-4790 deletion completed in 6.402142596s

• [SLOW TEST:6.739 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:28:05.611: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1678
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jul 15 23:28:08.558: INFO: Successfully updated pod "pod-update-activedeadlineseconds-3286ecb1-a758-11e9-983d-d6ce37abd03c"
Jul 15 23:28:08.558: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-3286ecb1-a758-11e9-983d-d6ce37abd03c" in namespace "pods-1678" to be "terminated due to deadline exceeded"
Jul 15 23:28:08.572: INFO: Pod "pod-update-activedeadlineseconds-3286ecb1-a758-11e9-983d-d6ce37abd03c": Phase="Running", Reason="", readiness=true. Elapsed: 13.626189ms
Jul 15 23:28:10.897: INFO: Pod "pod-update-activedeadlineseconds-3286ecb1-a758-11e9-983d-d6ce37abd03c": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.338849052s
Jul 15 23:28:10.897: INFO: Pod "pod-update-activedeadlineseconds-3286ecb1-a758-11e9-983d-d6ce37abd03c" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:28:10.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1678" for this suite.
Jul 15 23:28:16.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:28:17.328: INFO: namespace pods-1678 deletion completed in 6.417107374s

• [SLOW TEST:11.717 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:28:17.328: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9079
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:28:21.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9079" for this suite.
Jul 15 23:29:03.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:29:04.310: INFO: namespace kubelet-test-9079 deletion completed in 42.403065792s

• [SLOW TEST:46.982 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:29:04.311: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7023
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-5586ede3-a758-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume secrets
Jul 15 23:29:04.574: INFO: Waiting up to 5m0s for pod "pod-secrets-55892ec1-a758-11e9-983d-d6ce37abd03c" in namespace "secrets-7023" to be "success or failure"
Jul 15 23:29:04.592: INFO: Pod "pod-secrets-55892ec1-a758-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.716739ms
Jul 15 23:29:06.605: INFO: Pod "pod-secrets-55892ec1-a758-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030407551s
Jul 15 23:29:08.615: INFO: Pod "pod-secrets-55892ec1-a758-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040410768s
STEP: Saw pod success
Jul 15 23:29:08.615: INFO: Pod "pod-secrets-55892ec1-a758-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:29:08.626: INFO: Trying to get logs from node 10.190.211.93 pod pod-secrets-55892ec1-a758-11e9-983d-d6ce37abd03c container secret-env-test: <nil>
STEP: delete the pod
Jul 15 23:29:08.687: INFO: Waiting for pod pod-secrets-55892ec1-a758-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:29:08.699: INFO: Pod pod-secrets-55892ec1-a758-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:29:08.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7023" for this suite.
Jul 15 23:29:14.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:29:15.108: INFO: namespace secrets-7023 deletion completed in 6.394038319s

• [SLOW TEST:10.797 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:29:15.109: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-271
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Jul 15 23:29:15.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 create -f - --namespace=kubectl-271'
Jul 15 23:29:15.764: INFO: stderr: ""
Jul 15 23:29:15.764: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 15 23:29:15.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-271'
Jul 15 23:29:15.872: INFO: stderr: ""
Jul 15 23:29:15.872: INFO: stdout: "update-demo-nautilus-7hksh "
STEP: Replicas for name=update-demo: expected=2 actual=1
Jul 15 23:29:20.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-271'
Jul 15 23:29:20.988: INFO: stderr: ""
Jul 15 23:29:20.988: INFO: stdout: "update-demo-nautilus-7hksh update-demo-nautilus-fhmfl "
Jul 15 23:29:20.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-7hksh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-271'
Jul 15 23:29:21.090: INFO: stderr: ""
Jul 15 23:29:21.090: INFO: stdout: "true"
Jul 15 23:29:21.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-7hksh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-271'
Jul 15 23:29:21.198: INFO: stderr: ""
Jul 15 23:29:21.198: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 23:29:21.198: INFO: validating pod update-demo-nautilus-7hksh
Jul 15 23:29:21.216: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 23:29:21.216: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 23:29:21.216: INFO: update-demo-nautilus-7hksh is verified up and running
Jul 15 23:29:21.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-fhmfl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-271'
Jul 15 23:29:21.342: INFO: stderr: ""
Jul 15 23:29:21.342: INFO: stdout: "true"
Jul 15 23:29:21.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods update-demo-nautilus-fhmfl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-271'
Jul 15 23:29:21.441: INFO: stderr: ""
Jul 15 23:29:21.441: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 23:29:21.441: INFO: validating pod update-demo-nautilus-fhmfl
Jul 15 23:29:21.459: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 23:29:21.459: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 23:29:21.459: INFO: update-demo-nautilus-fhmfl is verified up and running
STEP: using delete to clean up resources
Jul 15 23:29:21.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 delete --grace-period=0 --force -f - --namespace=kubectl-271'
Jul 15 23:29:21.586: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 23:29:21.586: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jul 15 23:29:21.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-271'
Jul 15 23:29:21.744: INFO: stderr: "No resources found.\n"
Jul 15 23:29:21.744: INFO: stdout: ""
Jul 15 23:29:21.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-077690921 get pods -l name=update-demo --namespace=kubectl-271 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 15 23:29:21.866: INFO: stderr: ""
Jul 15 23:29:21.866: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:29:21.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-271" for this suite.
Jul 15 23:29:45.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:29:46.248: INFO: namespace kubectl-271 deletion completed in 24.368793243s

• [SLOW TEST:31.140 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:29:46.248: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6400
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6400.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6400.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6400.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6400.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6400.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6400.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul 15 23:29:50.678: INFO: DNS probes using dns-6400/dns-test-6e8479c3-a758-11e9-983d-d6ce37abd03c succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:29:50.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6400" for this suite.
Jul 15 23:29:56.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:29:57.358: INFO: namespace dns-6400 deletion completed in 6.611051626s

• [SLOW TEST:11.110 seconds]
[sig-network] DNS
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:29:57.359: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4057
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jul 15 23:30:06.005: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 15 23:30:06.026: INFO: Pod pod-with-poststart-http-hook still exists
Jul 15 23:30:08.033: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 15 23:30:08.044: INFO: Pod pod-with-poststart-http-hook still exists
Jul 15 23:30:10.027: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 15 23:30:10.041: INFO: Pod pod-with-poststart-http-hook still exists
Jul 15 23:30:12.026: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 15 23:30:12.045: INFO: Pod pod-with-poststart-http-hook still exists
Jul 15 23:30:14.026: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 15 23:30:14.037: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:30:14.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4057" for this suite.
Jul 15 23:30:34.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:30:34.443: INFO: namespace container-lifecycle-hook-4057 deletion completed in 20.392516704s

• [SLOW TEST:37.085 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:30:34.444: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1943
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-1943
Jul 15 23:30:36.711: INFO: Started pod liveness-http in namespace container-probe-1943
STEP: checking the pod's current state and verifying that restartCount is present
Jul 15 23:30:36.721: INFO: Initial restart count of pod liveness-http is 0
Jul 15 23:30:50.822: INFO: Restart count of pod container-probe-1943/liveness-http is now 1 (14.100612293s elapsed)
Jul 15 23:31:11.029: INFO: Restart count of pod container-probe-1943/liveness-http is now 2 (34.307859889s elapsed)
Jul 15 23:31:29.132: INFO: Restart count of pod container-probe-1943/liveness-http is now 3 (52.411376413s elapsed)
Jul 15 23:31:49.515: INFO: Restart count of pod container-probe-1943/liveness-http is now 4 (1m12.793534694s elapsed)
Jul 15 23:32:52.012: INFO: Restart count of pod container-probe-1943/liveness-http is now 5 (2m15.290899476s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:32:52.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1943" for this suite.
Jul 15 23:32:58.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:32:58.442: INFO: namespace container-probe-1943 deletion completed in 6.372677741s

• [SLOW TEST:143.999 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:32:58.443: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2537
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-4523
STEP: Creating secret with name secret-test-e1153864-a758-11e9-983d-d6ce37abd03c
STEP: Creating a pod to test consume secrets
Jul 15 23:32:58.927: INFO: Waiting up to 5m0s for pod "pod-secrets-e1388011-a758-11e9-983d-d6ce37abd03c" in namespace "secrets-2537" to be "success or failure"
Jul 15 23:32:58.953: INFO: Pod "pod-secrets-e1388011-a758-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 26.220862ms
Jul 15 23:33:00.964: INFO: Pod "pod-secrets-e1388011-a758-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036696099s
STEP: Saw pod success
Jul 15 23:33:00.964: INFO: Pod "pod-secrets-e1388011-a758-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:33:00.975: INFO: Trying to get logs from node 10.190.211.93 pod pod-secrets-e1388011-a758-11e9-983d-d6ce37abd03c container secret-volume-test: <nil>
STEP: delete the pod
Jul 15 23:33:01.043: INFO: Waiting for pod pod-secrets-e1388011-a758-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:33:01.062: INFO: Pod pod-secrets-e1388011-a758-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:33:01.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2537" for this suite.
Jul 15 23:33:07.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:33:07.459: INFO: namespace secrets-2537 deletion completed in 6.374000588s
STEP: Destroying namespace "secret-namespace-4523" for this suite.
Jul 15 23:33:13.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:33:13.828: INFO: namespace secret-namespace-4523 deletion completed in 6.368893051s

• [SLOW TEST:15.385 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:33:13.829: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-9505
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Jul 15 23:33:14.624: INFO: created pod pod-service-account-defaultsa
Jul 15 23:33:14.624: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jul 15 23:33:14.638: INFO: created pod pod-service-account-mountsa
Jul 15 23:33:14.638: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jul 15 23:33:14.653: INFO: created pod pod-service-account-nomountsa
Jul 15 23:33:14.653: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jul 15 23:33:14.669: INFO: created pod pod-service-account-defaultsa-mountspec
Jul 15 23:33:14.669: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jul 15 23:33:14.680: INFO: created pod pod-service-account-mountsa-mountspec
Jul 15 23:33:14.680: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jul 15 23:33:14.698: INFO: created pod pod-service-account-nomountsa-mountspec
Jul 15 23:33:14.699: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jul 15 23:33:14.711: INFO: created pod pod-service-account-defaultsa-nomountspec
Jul 15 23:33:14.711: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jul 15 23:33:14.731: INFO: created pod pod-service-account-mountsa-nomountspec
Jul 15 23:33:14.731: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jul 15 23:33:14.745: INFO: created pod pod-service-account-nomountsa-nomountspec
Jul 15 23:33:14.745: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:33:14.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9505" for this suite.
Jul 15 23:33:23.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:33:23.369: INFO: namespace svcaccounts-9505 deletion completed in 8.611012759s

• [SLOW TEST:9.540 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:33:23.369: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-7682
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:33:25.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7682" for this suite.
Jul 15 23:33:31.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:33:32.179: INFO: namespace emptydir-wrapper-7682 deletion completed in 6.396164094s

• [SLOW TEST:8.810 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:33:32.180: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-788
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-f53299b8-a758-11e9-983d-d6ce37abd03c
STEP: Creating configMap with name cm-test-opt-upd-f5329a12-a758-11e9-983d-d6ce37abd03c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-f53299b8-a758-11e9-983d-d6ce37abd03c
STEP: Updating configmap cm-test-opt-upd-f5329a12-a758-11e9-983d-d6ce37abd03c
STEP: Creating configMap with name cm-test-opt-create-f5329a43-a758-11e9-983d-d6ce37abd03c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:34:59.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-788" for this suite.
Jul 15 23:35:23.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:35:24.138: INFO: namespace projected-788 deletion completed in 24.394843652s

• [SLOW TEST:111.959 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:35:24.139: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2878
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 23:35:24.407: INFO: Waiting up to 5m0s for pod "downwardapi-volume-37ee2eed-a759-11e9-983d-d6ce37abd03c" in namespace "projected-2878" to be "success or failure"
Jul 15 23:35:24.418: INFO: Pod "downwardapi-volume-37ee2eed-a759-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.769176ms
Jul 15 23:35:26.430: INFO: Pod "downwardapi-volume-37ee2eed-a759-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023519897s
Jul 15 23:35:28.442: INFO: Pod "downwardapi-volume-37ee2eed-a759-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035590612s
STEP: Saw pod success
Jul 15 23:35:28.443: INFO: Pod "downwardapi-volume-37ee2eed-a759-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:35:28.455: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-37ee2eed-a759-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 23:35:28.517: INFO: Waiting for pod downwardapi-volume-37ee2eed-a759-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:35:28.526: INFO: Pod downwardapi-volume-37ee2eed-a759-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:35:28.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2878" for this suite.
Jul 15 23:35:34.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:35:34.925: INFO: namespace projected-2878 deletion completed in 6.379042415s

• [SLOW TEST:10.786 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:35:34.925: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6028
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul 15 23:35:35.157: INFO: Waiting up to 5m0s for pod "downward-api-3e573f08-a759-11e9-983d-d6ce37abd03c" in namespace "downward-api-6028" to be "success or failure"
Jul 15 23:35:35.167: INFO: Pod "downward-api-3e573f08-a759-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.678825ms
Jul 15 23:35:37.177: INFO: Pod "downward-api-3e573f08-a759-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019820178s
STEP: Saw pod success
Jul 15 23:35:37.177: INFO: Pod "downward-api-3e573f08-a759-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:35:37.187: INFO: Trying to get logs from node 10.190.211.93 pod downward-api-3e573f08-a759-11e9-983d-d6ce37abd03c container dapi-container: <nil>
STEP: delete the pod
Jul 15 23:35:37.444: INFO: Waiting for pod downward-api-3e573f08-a759-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:35:37.457: INFO: Pod downward-api-3e573f08-a759-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:35:37.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6028" for this suite.
Jul 15 23:35:43.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:35:44.129: INFO: namespace downward-api-6028 deletion completed in 6.624183283s

• [SLOW TEST:9.205 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 15 23:35:44.130: INFO: >>> kubeConfig: /tmp/kubeconfig-077690921
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8658
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 15 23:35:44.376: INFO: Waiting up to 5m0s for pod "downwardapi-volume-43d5529d-a759-11e9-983d-d6ce37abd03c" in namespace "projected-8658" to be "success or failure"
Jul 15 23:35:44.396: INFO: Pod "downwardapi-volume-43d5529d-a759-11e9-983d-d6ce37abd03c": Phase="Pending", Reason="", readiness=false. Elapsed: 19.187922ms
Jul 15 23:35:46.409: INFO: Pod "downwardapi-volume-43d5529d-a759-11e9-983d-d6ce37abd03c": Phase="Running", Reason="", readiness=true. Elapsed: 2.032115457s
Jul 15 23:35:48.419: INFO: Pod "downwardapi-volume-43d5529d-a759-11e9-983d-d6ce37abd03c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042850963s
STEP: Saw pod success
Jul 15 23:35:48.419: INFO: Pod "downwardapi-volume-43d5529d-a759-11e9-983d-d6ce37abd03c" satisfied condition "success or failure"
Jul 15 23:35:48.431: INFO: Trying to get logs from node 10.190.211.93 pod downwardapi-volume-43d5529d-a759-11e9-983d-d6ce37abd03c container client-container: <nil>
STEP: delete the pod
Jul 15 23:35:48.545: INFO: Waiting for pod downwardapi-volume-43d5529d-a759-11e9-983d-d6ce37abd03c to disappear
Jul 15 23:35:48.554: INFO: Pod downwardapi-volume-43d5529d-a759-11e9-983d-d6ce37abd03c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 15 23:35:48.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8658" for this suite.
Jul 15 23:35:56.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 23:35:56.937: INFO: namespace projected-8658 deletion completed in 8.365287937s

• [SLOW TEST:12.807 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSJul 15 23:35:56.937: INFO: Running AfterSuite actions on all nodes
Jul 15 23:35:56.937: INFO: Running AfterSuite actions on node 1
Jul 15 23:35:56.937: INFO: Skipping dumping logs from cluster

Ran 204 of 3586 Specs in 5843.001 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3382 Skipped PASS

Ginkgo ran 1 suite in 1h37m24.16985508s
Test Suite Passed
