I1021 15:48:28.959305      17 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-731484646
I1021 15:48:28.959466      17 e2e.go:242] Starting e2e run "3984d8a7-f41a-11e9-ae8d-bacadc8895d2" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1571672908 - Will randomize all specs
Will run 204 of 3586 specs

Oct 21 15:48:29.062: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 15:48:29.064: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Oct 21 15:48:29.128: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct 21 15:48:29.194: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct 21 15:48:29.194: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Oct 21 15:48:29.194: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct 21 15:48:29.211: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Oct 21 15:48:29.211: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Oct 21 15:48:29.211: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
Oct 21 15:48:29.211: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Oct 21 15:48:29.211: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Oct 21 15:48:29.211: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Oct 21 15:48:29.211: INFO: e2e test version: v1.14.8
Oct 21 15:48:29.214: INFO: kube-apiserver version: v1.14.8+IKS
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:48:29.215: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename emptydir
Oct 21 15:48:29.311: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Oct 21 15:48:29.352: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-676
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 21 15:48:29.514: INFO: Waiting up to 5m0s for pod "pod-3a3cbb99-f41a-11e9-ae8d-bacadc8895d2" in namespace "emptydir-676" to be "success or failure"
Oct 21 15:48:29.532: INFO: Pod "pod-3a3cbb99-f41a-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 17.23611ms
Oct 21 15:48:31.544: INFO: Pod "pod-3a3cbb99-f41a-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030099015s
Oct 21 15:48:33.562: INFO: Pod "pod-3a3cbb99-f41a-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047748641s
Oct 21 15:48:35.581: INFO: Pod "pod-3a3cbb99-f41a-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.066292078s
STEP: Saw pod success
Oct 21 15:48:35.581: INFO: Pod "pod-3a3cbb99-f41a-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 15:48:35.597: INFO: Trying to get logs from node 10.134.235.118 pod pod-3a3cbb99-f41a-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 15:48:35.657: INFO: Waiting for pod pod-3a3cbb99-f41a-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 15:48:35.665: INFO: Pod pod-3a3cbb99-f41a-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:48:35.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-676" for this suite.
Oct 21 15:48:41.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:48:42.072: INFO: namespace emptydir-676 deletion completed in 6.393515248s

• [SLOW TEST:12.857 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:48:42.072: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3552
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Oct 21 15:48:42.297: INFO: Waiting up to 5m0s for pod "client-containers-41dc8acb-f41a-11e9-ae8d-bacadc8895d2" in namespace "containers-3552" to be "success or failure"
Oct 21 15:48:42.311: INFO: Pod "client-containers-41dc8acb-f41a-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 14.555901ms
Oct 21 15:48:44.585: INFO: Pod "client-containers-41dc8acb-f41a-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.288301904s
Oct 21 15:48:46.597: INFO: Pod "client-containers-41dc8acb-f41a-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.300510921s
STEP: Saw pod success
Oct 21 15:48:46.597: INFO: Pod "client-containers-41dc8acb-f41a-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 15:48:46.607: INFO: Trying to get logs from node 10.134.235.67 pod client-containers-41dc8acb-f41a-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 15:48:46.663: INFO: Waiting for pod client-containers-41dc8acb-f41a-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 15:48:46.671: INFO: Pod client-containers-41dc8acb-f41a-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:48:46.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3552" for this suite.
Oct 21 15:48:52.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:48:53.072: INFO: namespace containers-3552 deletion completed in 6.374542903s

• [SLOW TEST:10.999 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:48:53.072: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-502
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-486d4075-f41a-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume secrets
Oct 21 15:48:53.326: INFO: Waiting up to 5m0s for pod "pod-secrets-486f56f5-f41a-11e9-ae8d-bacadc8895d2" in namespace "secrets-502" to be "success or failure"
Oct 21 15:48:53.336: INFO: Pod "pod-secrets-486f56f5-f41a-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.269983ms
Oct 21 15:48:55.349: INFO: Pod "pod-secrets-486f56f5-f41a-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02327061s
Oct 21 15:48:57.359: INFO: Pod "pod-secrets-486f56f5-f41a-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032790811s
STEP: Saw pod success
Oct 21 15:48:57.359: INFO: Pod "pod-secrets-486f56f5-f41a-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 15:48:57.368: INFO: Trying to get logs from node 10.134.235.118 pod pod-secrets-486f56f5-f41a-11e9-ae8d-bacadc8895d2 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 15:48:57.427: INFO: Waiting for pod pod-secrets-486f56f5-f41a-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 15:48:57.435: INFO: Pod pod-secrets-486f56f5-f41a-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:48:57.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-502" for this suite.
Oct 21 15:49:03.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:49:03.866: INFO: namespace secrets-502 deletion completed in 6.418399502s

• [SLOW TEST:10.794 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:49:03.866: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7821
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:49:08.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7821" for this suite.
Oct 21 15:49:14.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:49:14.542: INFO: namespace kubelet-test-7821 deletion completed in 6.405440991s

• [SLOW TEST:10.676 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:49:14.542: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-283
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 15:49:14.776: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5537c0f7-f41a-11e9-ae8d-bacadc8895d2" in namespace "projected-283" to be "success or failure"
Oct 21 15:49:14.791: INFO: Pod "downwardapi-volume-5537c0f7-f41a-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 14.227756ms
Oct 21 15:49:16.800: INFO: Pod "downwardapi-volume-5537c0f7-f41a-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023806193s
STEP: Saw pod success
Oct 21 15:49:16.800: INFO: Pod "downwardapi-volume-5537c0f7-f41a-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 15:49:16.809: INFO: Trying to get logs from node 10.134.235.118 pod downwardapi-volume-5537c0f7-f41a-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 15:49:16.866: INFO: Waiting for pod downwardapi-volume-5537c0f7-f41a-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 15:49:16.876: INFO: Pod downwardapi-volume-5537c0f7-f41a-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:49:16.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-283" for this suite.
Oct 21 15:49:22.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:49:23.500: INFO: namespace projected-283 deletion completed in 6.609189476s

• [SLOW TEST:8.958 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:49:23.500: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9087
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-5ae841bd-f41a-11e9-ae8d-bacadc8895d2
Oct 21 15:49:24.331: INFO: Pod name my-hostname-basic-5ae841bd-f41a-11e9-ae8d-bacadc8895d2: Found 0 pods out of 1
Oct 21 15:49:29.342: INFO: Pod name my-hostname-basic-5ae841bd-f41a-11e9-ae8d-bacadc8895d2: Found 1 pods out of 1
Oct 21 15:49:29.342: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-5ae841bd-f41a-11e9-ae8d-bacadc8895d2" are running
Oct 21 15:49:29.350: INFO: Pod "my-hostname-basic-5ae841bd-f41a-11e9-ae8d-bacadc8895d2-6gf94" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 15:49:24 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 15:49:28 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 15:49:28 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 15:49:24 +0000 UTC Reason: Message:}])
Oct 21 15:49:29.350: INFO: Trying to dial the pod
Oct 21 15:49:34.391: INFO: Controller my-hostname-basic-5ae841bd-f41a-11e9-ae8d-bacadc8895d2: Got expected result from replica 1 [my-hostname-basic-5ae841bd-f41a-11e9-ae8d-bacadc8895d2-6gf94]: "my-hostname-basic-5ae841bd-f41a-11e9-ae8d-bacadc8895d2-6gf94", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:49:34.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9087" for this suite.
Oct 21 15:49:42.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:49:42.828: INFO: namespace replication-controller-9087 deletion completed in 8.421356682s

• [SLOW TEST:19.328 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:49:42.829: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9446
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-9446
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 21 15:49:43.026: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 21 15:50:09.276: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.132.58:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9446 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 15:50:09.276: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 15:50:09.620: INFO: Found all expected endpoints: [netserver-0]
Oct 21 15:50:09.632: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.198.116:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9446 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 15:50:09.632: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 15:50:09.889: INFO: Found all expected endpoints: [netserver-1]
Oct 21 15:50:09.898: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.192.235:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9446 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 15:50:09.898: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 15:50:10.140: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:50:10.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9446" for this suite.
Oct 21 15:50:34.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:50:35.493: INFO: namespace pod-network-test-9446 deletion completed in 25.339119033s

• [SLOW TEST:52.664 seconds]
[sig-network] Networking
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:50:35.493: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2478
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct 21 15:50:35.710: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 21 15:50:35.731: INFO: Waiting for terminating namespaces to be deleted...
Oct 21 15:50:35.739: INFO: 
Logging pods the kubelet thinks is on node 10.134.235.118 before test
Oct 21 15:50:35.770: INFO: ibm-master-proxy-static-10.134.235.118 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 15:50:35.770: INFO: ibm-keepalived-watcher-s768g from kube-system started at 2019-10-21 14:16:32 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.770: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 15:50:35.770: INFO: coredns-9dd7747c7-cgj4m from kube-system started at 2019-10-21 14:35:59 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.770: INFO: 	Container coredns ready: true, restart count 0
Oct 21 15:50:35.770: INFO: sonobuoy from sonobuoy started at 2019-10-21 15:48:00 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.770: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 21 15:50:35.770: INFO: sonobuoy-systemd-logs-daemon-set-aae6d13d2b504a80-z8lvd from sonobuoy started at 2019-10-21 15:48:07 +0000 UTC (2 container statuses recorded)
Oct 21 15:50:35.770: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 15:50:35.770: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 21 15:50:35.770: INFO: ibm-cloud-provider-ip-169-50-36-162-5fffc56797-4s4bl from ibm-system started at 2019-10-21 14:27:14 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.770: INFO: 	Container ibm-cloud-provider-ip-169-50-36-162 ready: true, restart count 0
Oct 21 15:50:35.770: INFO: calico-node-xczq8 from kube-system started at 2019-10-21 14:16:32 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.770: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 15:50:35.770: INFO: ibm-kube-fluentd-5gkfc from kube-system started at 2019-10-21 14:16:32 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.770: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 15:50:35.770: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-10-21 14:18:34 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.770: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Oct 21 15:50:35.770: INFO: vpn-7754bb6d4-2n6w7 from kube-system started at 2019-10-21 14:35:37 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.770: INFO: 	Container vpn ready: true, restart count 0
Oct 21 15:50:35.770: INFO: 
Logging pods the kubelet thinks is on node 10.134.235.67 before test
Oct 21 15:50:35.823: INFO: sonobuoy-systemd-logs-daemon-set-aae6d13d2b504a80-8xb54 from sonobuoy started at 2019-10-21 15:48:07 +0000 UTC (2 container statuses recorded)
Oct 21 15:50:35.823: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 15:50:35.823: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 21 15:50:35.823: INFO: ibm-master-proxy-static-10.134.235.67 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 15:50:35.823: INFO: ibm-keepalived-watcher-p74j4 from kube-system started at 2019-10-21 14:17:00 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.823: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 15:50:35.823: INFO: public-crbmmrhnff04rpad188da0-alb1-5bd9899fdd-sq8jg from kube-system started at 2019-10-21 14:28:20 +0000 UTC (4 container statuses recorded)
Oct 21 15:50:35.823: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 15:50:35.823: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 15:50:35.824: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 15:50:35.824: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 21 15:50:35.824: INFO: ibm-cloud-provider-ip-169-50-36-162-5fffc56797-6gpb8 from ibm-system started at 2019-10-21 14:27:14 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.824: INFO: 	Container ibm-cloud-provider-ip-169-50-36-162 ready: true, restart count 0
Oct 21 15:50:35.824: INFO: calico-node-hvq6v from kube-system started at 2019-10-21 14:17:00 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.824: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 15:50:35.824: INFO: ibm-kube-fluentd-5ssfj from kube-system started at 2019-10-21 14:17:00 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.824: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 15:50:35.824: INFO: 
Logging pods the kubelet thinks is on node 10.134.235.77 before test
Oct 21 15:50:35.872: INFO: calico-kube-controllers-65f9c6c467-9xskh from kube-system started at 2019-10-21 14:14:25 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.872: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct 21 15:50:35.872: INFO: sonobuoy-systemd-logs-daemon-set-aae6d13d2b504a80-mzxfn from sonobuoy started at 2019-10-21 15:48:07 +0000 UTC (2 container statuses recorded)
Oct 21 15:50:35.872: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 15:50:35.872: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 21 15:50:35.872: INFO: sonobuoy-e2e-job-84d501f52fd84cd8 from sonobuoy started at 2019-10-21 15:48:07 +0000 UTC (2 container statuses recorded)
Oct 21 15:50:35.872: INFO: 	Container e2e ready: true, restart count 0
Oct 21 15:50:35.872: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 15:50:35.872: INFO: ibm-master-proxy-static-10.134.235.77 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 15:50:35.872: INFO: ibm-keepalived-watcher-vv9sg from kube-system started at 2019-10-21 14:14:07 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.872: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 15:50:35.872: INFO: public-crbmmrhnff04rpad188da0-alb1-5bd9899fdd-sk955 from kube-system started at 2019-10-21 14:28:20 +0000 UTC (4 container statuses recorded)
Oct 21 15:50:35.872: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 15:50:35.872: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 15:50:35.872: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 15:50:35.872: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 21 15:50:35.872: INFO: coredns-9dd7747c7-kp66g from kube-system started at 2019-10-21 14:35:59 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.872: INFO: 	Container coredns ready: true, restart count 0
Oct 21 15:50:35.872: INFO: coredns-autoscaler-5d4db8dd68-4rk7m from kube-system started at 2019-10-21 14:14:26 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.872: INFO: 	Container autoscaler ready: true, restart count 0
Oct 21 15:50:35.872: INFO: metrics-server-64cc5dbf7f-mqllr from kube-system started at 2019-10-21 14:14:41 +0000 UTC (2 container statuses recorded)
Oct 21 15:50:35.872: INFO: 	Container metrics-server ready: true, restart count 0
Oct 21 15:50:35.872: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct 21 15:50:35.872: INFO: calico-node-qbdl6 from kube-system started at 2019-10-21 14:14:07 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.872: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 15:50:35.872: INFO: ibm-file-plugin-9bf87c759-7h2dh from kube-system started at 2019-10-21 14:14:25 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.872: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct 21 15:50:35.872: INFO: ibm-storage-watcher-5f677d9c66-8mmsv from kube-system started at 2019-10-21 14:14:25 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.872: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct 21 15:50:35.872: INFO: kubernetes-dashboard-5c8c9b7546-56vkg from kube-system started at 2019-10-21 14:14:26 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.872: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct 21 15:50:35.872: INFO: ibm-kube-fluentd-zwqgb from kube-system started at 2019-10-21 14:14:36 +0000 UTC (1 container statuses recorded)
Oct 21 15:50:35.872: INFO: 	Container fluentd ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node 10.134.235.118
STEP: verifying the node has the label node 10.134.235.67
STEP: verifying the node has the label node 10.134.235.77
Oct 21 15:50:35.988: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.134.235.118
Oct 21 15:50:35.988: INFO: Pod ibm-cloud-provider-ip-169-50-36-162-5fffc56797-4s4bl requesting resource cpu=5m on Node 10.134.235.118
Oct 21 15:50:35.988: INFO: Pod ibm-cloud-provider-ip-169-50-36-162-5fffc56797-6gpb8 requesting resource cpu=5m on Node 10.134.235.67
Oct 21 15:50:35.988: INFO: Pod calico-kube-controllers-65f9c6c467-9xskh requesting resource cpu=10m on Node 10.134.235.77
Oct 21 15:50:35.988: INFO: Pod calico-node-hvq6v requesting resource cpu=250m on Node 10.134.235.67
Oct 21 15:50:35.988: INFO: Pod calico-node-qbdl6 requesting resource cpu=250m on Node 10.134.235.77
Oct 21 15:50:35.988: INFO: Pod calico-node-xczq8 requesting resource cpu=250m on Node 10.134.235.118
Oct 21 15:50:35.988: INFO: Pod coredns-9dd7747c7-cgj4m requesting resource cpu=100m on Node 10.134.235.118
Oct 21 15:50:35.988: INFO: Pod coredns-9dd7747c7-kp66g requesting resource cpu=100m on Node 10.134.235.77
Oct 21 15:50:35.988: INFO: Pod coredns-autoscaler-5d4db8dd68-4rk7m requesting resource cpu=20m on Node 10.134.235.77
Oct 21 15:50:35.988: INFO: Pod ibm-file-plugin-9bf87c759-7h2dh requesting resource cpu=50m on Node 10.134.235.77
Oct 21 15:50:35.988: INFO: Pod ibm-keepalived-watcher-p74j4 requesting resource cpu=5m on Node 10.134.235.67
Oct 21 15:50:35.988: INFO: Pod ibm-keepalived-watcher-s768g requesting resource cpu=5m on Node 10.134.235.118
Oct 21 15:50:35.988: INFO: Pod ibm-keepalived-watcher-vv9sg requesting resource cpu=5m on Node 10.134.235.77
Oct 21 15:50:35.988: INFO: Pod ibm-kube-fluentd-5gkfc requesting resource cpu=25m on Node 10.134.235.118
Oct 21 15:50:35.988: INFO: Pod ibm-kube-fluentd-5ssfj requesting resource cpu=25m on Node 10.134.235.67
Oct 21 15:50:35.988: INFO: Pod ibm-kube-fluentd-zwqgb requesting resource cpu=25m on Node 10.134.235.77
Oct 21 15:50:35.988: INFO: Pod ibm-master-proxy-static-10.134.235.118 requesting resource cpu=25m on Node 10.134.235.118
Oct 21 15:50:35.988: INFO: Pod ibm-master-proxy-static-10.134.235.67 requesting resource cpu=25m on Node 10.134.235.67
Oct 21 15:50:35.988: INFO: Pod ibm-master-proxy-static-10.134.235.77 requesting resource cpu=25m on Node 10.134.235.77
Oct 21 15:50:35.988: INFO: Pod ibm-storage-watcher-5f677d9c66-8mmsv requesting resource cpu=50m on Node 10.134.235.77
Oct 21 15:50:35.988: INFO: Pod kubernetes-dashboard-5c8c9b7546-56vkg requesting resource cpu=50m on Node 10.134.235.77
Oct 21 15:50:35.988: INFO: Pod metrics-server-64cc5dbf7f-mqllr requesting resource cpu=53m on Node 10.134.235.77
Oct 21 15:50:35.989: INFO: Pod public-crbmmrhnff04rpad188da0-alb1-5bd9899fdd-sk955 requesting resource cpu=0m on Node 10.134.235.77
Oct 21 15:50:35.989: INFO: Pod public-crbmmrhnff04rpad188da0-alb1-5bd9899fdd-sq8jg requesting resource cpu=0m on Node 10.134.235.67
Oct 21 15:50:35.989: INFO: Pod vpn-7754bb6d4-2n6w7 requesting resource cpu=5m on Node 10.134.235.118
Oct 21 15:50:35.989: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.134.235.118
Oct 21 15:50:35.989: INFO: Pod sonobuoy-e2e-job-84d501f52fd84cd8 requesting resource cpu=0m on Node 10.134.235.77
Oct 21 15:50:35.989: INFO: Pod sonobuoy-systemd-logs-daemon-set-aae6d13d2b504a80-8xb54 requesting resource cpu=0m on Node 10.134.235.67
Oct 21 15:50:35.989: INFO: Pod sonobuoy-systemd-logs-daemon-set-aae6d13d2b504a80-mzxfn requesting resource cpu=0m on Node 10.134.235.77
Oct 21 15:50:35.989: INFO: Pod sonobuoy-systemd-logs-daemon-set-aae6d13d2b504a80-z8lvd requesting resource cpu=0m on Node 10.134.235.118
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85a303b6-f41a-11e9-ae8d-bacadc8895d2.15cfb44c96b5967c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2478/filler-pod-85a303b6-f41a-11e9-ae8d-bacadc8895d2 to 10.134.235.118]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85a303b6-f41a-11e9-ae8d-bacadc8895d2.15cfb44cd2d846f2], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85a303b6-f41a-11e9-ae8d-bacadc8895d2.15cfb44cd6da3a8c], Reason = [Created], Message = [Created container filler-pod-85a303b6-f41a-11e9-ae8d-bacadc8895d2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85a303b6-f41a-11e9-ae8d-bacadc8895d2.15cfb44ce17a59ba], Reason = [Started], Message = [Started container filler-pod-85a303b6-f41a-11e9-ae8d-bacadc8895d2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85a5c614-f41a-11e9-ae8d-bacadc8895d2.15cfb44c97b7b162], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2478/filler-pod-85a5c614-f41a-11e9-ae8d-bacadc8895d2 to 10.134.235.67]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85a5c614-f41a-11e9-ae8d-bacadc8895d2.15cfb44cd005359d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85a5c614-f41a-11e9-ae8d-bacadc8895d2.15cfb44cd34fe6d4], Reason = [Created], Message = [Created container filler-pod-85a5c614-f41a-11e9-ae8d-bacadc8895d2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85a5c614-f41a-11e9-ae8d-bacadc8895d2.15cfb44cdc42d85f], Reason = [Started], Message = [Started container filler-pod-85a5c614-f41a-11e9-ae8d-bacadc8895d2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85a7d2fe-f41a-11e9-ae8d-bacadc8895d2.15cfb44c98f34143], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2478/filler-pod-85a7d2fe-f41a-11e9-ae8d-bacadc8895d2 to 10.134.235.77]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85a7d2fe-f41a-11e9-ae8d-bacadc8895d2.15cfb44cd284facd], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85a7d2fe-f41a-11e9-ae8d-bacadc8895d2.15cfb44cd75daea3], Reason = [Created], Message = [Created container filler-pod-85a7d2fe-f41a-11e9-ae8d-bacadc8895d2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85a7d2fe-f41a-11e9-ae8d-bacadc8895d2.15cfb44cdf485f82], Reason = [Started], Message = [Started container filler-pod-85a7d2fe-f41a-11e9-ae8d-bacadc8895d2]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15cfb44d13d3f037], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.134.235.77
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.134.235.118
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.134.235.67
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:50:39.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2478" for this suite.
Oct 21 15:50:45.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:50:46.865: INFO: namespace sched-pred-2478 deletion completed in 7.611227737s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.372 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:50:46.867: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8497
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-8497
Oct 21 15:50:53.115: INFO: Started pod liveness-http in namespace container-probe-8497
STEP: checking the pod's current state and verifying that restartCount is present
Oct 21 15:50:53.123: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:54:53.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8497" for this suite.
Oct 21 15:54:59.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:54:59.886: INFO: namespace container-probe-8497 deletion completed in 6.338395153s

• [SLOW TEST:253.020 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:54:59.887: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-925
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 15:55:00.119: INFO: Waiting up to 5m0s for pod "downwardapi-volume-230e853d-f41b-11e9-ae8d-bacadc8895d2" in namespace "projected-925" to be "success or failure"
Oct 21 15:55:00.127: INFO: Pod "downwardapi-volume-230e853d-f41b-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.137264ms
Oct 21 15:55:02.137: INFO: Pod "downwardapi-volume-230e853d-f41b-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018732337s
Oct 21 15:55:04.148: INFO: Pod "downwardapi-volume-230e853d-f41b-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029606558s
STEP: Saw pod success
Oct 21 15:55:04.148: INFO: Pod "downwardapi-volume-230e853d-f41b-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 15:55:04.157: INFO: Trying to get logs from node 10.134.235.67 pod downwardapi-volume-230e853d-f41b-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 15:55:04.216: INFO: Waiting for pod downwardapi-volume-230e853d-f41b-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 15:55:04.224: INFO: Pod downwardapi-volume-230e853d-f41b-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:55:04.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-925" for this suite.
Oct 21 15:55:10.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:55:10.652: INFO: namespace projected-925 deletion completed in 6.413691328s

• [SLOW TEST:10.766 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:55:10.654: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6040
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Oct 21 15:55:10.905: INFO: Waiting up to 5m0s for pod "client-containers-297ac315-f41b-11e9-ae8d-bacadc8895d2" in namespace "containers-6040" to be "success or failure"
Oct 21 15:55:10.916: INFO: Pod "client-containers-297ac315-f41b-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.088771ms
Oct 21 15:55:12.926: INFO: Pod "client-containers-297ac315-f41b-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020700994s
Oct 21 15:55:14.939: INFO: Pod "client-containers-297ac315-f41b-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033923848s
Oct 21 15:55:16.953: INFO: Pod "client-containers-297ac315-f41b-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.047981719s
STEP: Saw pod success
Oct 21 15:55:16.953: INFO: Pod "client-containers-297ac315-f41b-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 15:55:16.962: INFO: Trying to get logs from node 10.134.235.118 pod client-containers-297ac315-f41b-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 15:55:17.021: INFO: Waiting for pod client-containers-297ac315-f41b-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 15:55:17.029: INFO: Pod client-containers-297ac315-f41b-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:55:17.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6040" for this suite.
Oct 21 15:55:23.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:55:23.412: INFO: namespace containers-6040 deletion completed in 6.370037285s

• [SLOW TEST:12.759 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:55:23.412: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9247
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-9247/secret-test-31208ee7-f41b-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume secrets
Oct 21 15:55:23.736: INFO: Waiting up to 5m0s for pod "pod-configmaps-3122bc80-f41b-11e9-ae8d-bacadc8895d2" in namespace "secrets-9247" to be "success or failure"
Oct 21 15:55:23.747: INFO: Pod "pod-configmaps-3122bc80-f41b-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.612757ms
Oct 21 15:55:25.757: INFO: Pod "pod-configmaps-3122bc80-f41b-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021430781s
Oct 21 15:55:27.767: INFO: Pod "pod-configmaps-3122bc80-f41b-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031417122s
Oct 21 15:55:29.780: INFO: Pod "pod-configmaps-3122bc80-f41b-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043937336s
STEP: Saw pod success
Oct 21 15:55:29.780: INFO: Pod "pod-configmaps-3122bc80-f41b-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 15:55:29.788: INFO: Trying to get logs from node 10.134.235.118 pod pod-configmaps-3122bc80-f41b-11e9-ae8d-bacadc8895d2 container env-test: <nil>
STEP: delete the pod
Oct 21 15:55:29.869: INFO: Waiting for pod pod-configmaps-3122bc80-f41b-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 15:55:29.887: INFO: Pod pod-configmaps-3122bc80-f41b-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:55:29.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9247" for this suite.
Oct 21 15:55:35.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:55:36.268: INFO: namespace secrets-9247 deletion completed in 6.36861115s

• [SLOW TEST:12.856 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:55:36.269: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8693
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 15:55:36.478: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:55:37.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8693" for this suite.
Oct 21 15:55:43.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:55:43.984: INFO: namespace custom-resource-definition-8693 deletion completed in 6.361108459s

• [SLOW TEST:7.715 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:32
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:55:43.985: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2813
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-3d583b37-f41b-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume configMaps
Oct 21 15:55:44.239: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3d5aacfb-f41b-11e9-ae8d-bacadc8895d2" in namespace "projected-2813" to be "success or failure"
Oct 21 15:55:44.249: INFO: Pod "pod-projected-configmaps-3d5aacfb-f41b-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.618778ms
Oct 21 15:55:46.259: INFO: Pod "pod-projected-configmaps-3d5aacfb-f41b-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019942045s
STEP: Saw pod success
Oct 21 15:55:46.259: INFO: Pod "pod-projected-configmaps-3d5aacfb-f41b-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 15:55:46.269: INFO: Trying to get logs from node 10.134.235.118 pod pod-projected-configmaps-3d5aacfb-f41b-11e9-ae8d-bacadc8895d2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 15:55:46.326: INFO: Waiting for pod pod-projected-configmaps-3d5aacfb-f41b-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 15:55:46.334: INFO: Pod pod-projected-configmaps-3d5aacfb-f41b-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:55:46.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2813" for this suite.
Oct 21 15:55:52.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:55:52.710: INFO: namespace projected-2813 deletion completed in 6.362872425s

• [SLOW TEST:8.726 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:55:52.710: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7777
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1021 15:56:03.198656      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 21 15:56:03.198: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:56:03.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7777" for this suite.
Oct 21 15:56:09.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:56:09.667: INFO: namespace gc-7777 deletion completed in 6.444393768s

• [SLOW TEST:16.957 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:56:09.669: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7477
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 21 15:56:12.521: INFO: Successfully updated pod "pod-update-4cada623-f41b-11e9-ae8d-bacadc8895d2"
STEP: verifying the updated pod is in kubernetes
Oct 21 15:56:12.542: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:56:12.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7477" for this suite.
Oct 21 15:56:36.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:56:36.926: INFO: namespace pods-7477 deletion completed in 24.369183468s

• [SLOW TEST:27.257 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:56:36.926: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1673
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-5ce72f90-f41b-11e9-ae8d-bacadc8895d2
STEP: Creating configMap with name cm-test-opt-upd-5ce72fc7-f41b-11e9-ae8d-bacadc8895d2
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-5ce72f90-f41b-11e9-ae8d-bacadc8895d2
STEP: Updating configmap cm-test-opt-upd-5ce72fc7-f41b-11e9-ae8d-bacadc8895d2
STEP: Creating configMap with name cm-test-opt-create-5ce72fde-f41b-11e9-ae8d-bacadc8895d2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:58:12.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1673" for this suite.
Oct 21 15:58:37.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:58:37.430: INFO: namespace projected-1673 deletion completed in 24.458925556s

• [SLOW TEST:120.504 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:58:37.432: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8179
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 21 15:58:37.673: INFO: Waiting up to 5m0s for pod "pod-a4bb5d3d-f41b-11e9-ae8d-bacadc8895d2" in namespace "emptydir-8179" to be "success or failure"
Oct 21 15:58:37.683: INFO: Pod "pod-a4bb5d3d-f41b-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.993198ms
Oct 21 15:58:39.694: INFO: Pod "pod-a4bb5d3d-f41b-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02182769s
Oct 21 15:58:41.704: INFO: Pod "pod-a4bb5d3d-f41b-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031767234s
STEP: Saw pod success
Oct 21 15:58:41.704: INFO: Pod "pod-a4bb5d3d-f41b-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 15:58:41.712: INFO: Trying to get logs from node 10.134.235.67 pod pod-a4bb5d3d-f41b-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 15:58:41.765: INFO: Waiting for pod pod-a4bb5d3d-f41b-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 15:58:41.773: INFO: Pod pod-a4bb5d3d-f41b-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:58:41.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8179" for this suite.
Oct 21 15:58:47.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:58:48.148: INFO: namespace emptydir-8179 deletion completed in 6.357192443s

• [SLOW TEST:10.716 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:58:48.149: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4291
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 21 15:58:56.483: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 15:58:56.490: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 15:58:58.490: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 15:58:58.499: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 15:59:00.490: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 15:59:00.499: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 15:59:02.490: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 15:59:02.505: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 15:59:04.490: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 15:59:04.499: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 15:59:06.490: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 15:59:06.501: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 15:59:08.490: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 15:59:08.500: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 15:59:10.490: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 15:59:10.499: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 15:59:12.490: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 15:59:12.505: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 15:59:14.490: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 15:59:14.502: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 15:59:16.490: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 15:59:16.864: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 15:59:18.490: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 15:59:18.499: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:59:18.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4291" for this suite.
Oct 21 15:59:42.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:59:42.987: INFO: namespace container-lifecycle-hook-4291 deletion completed in 24.450317553s

• [SLOW TEST:54.839 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 15:59:42.987: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-5128
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Oct 21 15:59:49.305: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5128 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 15:59:49.305: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 15:59:49.580: INFO: Exec stderr: ""
Oct 21 15:59:49.580: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5128 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 15:59:49.580: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 15:59:49.830: INFO: Exec stderr: ""
Oct 21 15:59:49.830: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5128 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 15:59:49.830: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 15:59:50.068: INFO: Exec stderr: ""
Oct 21 15:59:50.068: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5128 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 15:59:50.068: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 15:59:50.646: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Oct 21 15:59:50.646: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5128 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 15:59:50.646: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 15:59:50.902: INFO: Exec stderr: ""
Oct 21 15:59:50.902: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5128 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 15:59:50.902: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 15:59:51.161: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Oct 21 15:59:51.161: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5128 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 15:59:51.161: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 15:59:51.401: INFO: Exec stderr: ""
Oct 21 15:59:51.401: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5128 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 15:59:51.401: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 15:59:51.680: INFO: Exec stderr: ""
Oct 21 15:59:51.680: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5128 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 15:59:51.680: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 15:59:51.915: INFO: Exec stderr: ""
Oct 21 15:59:51.915: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5128 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 15:59:51.915: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 15:59:52.173: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 15:59:52.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5128" for this suite.
Oct 21 16:00:32.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:00:32.537: INFO: namespace e2e-kubelet-etc-hosts-5128 deletion completed in 40.353594819s

• [SLOW TEST:49.550 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:00:32.538: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8702
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-8702
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-8702
STEP: Creating statefulset with conflicting port in namespace statefulset-8702
STEP: Waiting until pod test-pod will start running in namespace statefulset-8702
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-8702
Oct 21 16:00:34.830: INFO: Observed stateful pod in namespace: statefulset-8702, name: ss-0, uid: e99617a4-f41b-11e9-93ac-c26612c2e4bb, status phase: Pending. Waiting for statefulset controller to delete.
Oct 21 16:00:41.101: INFO: Observed stateful pod in namespace: statefulset-8702, name: ss-0, uid: e99617a4-f41b-11e9-93ac-c26612c2e4bb, status phase: Failed. Waiting for statefulset controller to delete.
Oct 21 16:00:41.118: INFO: Observed stateful pod in namespace: statefulset-8702, name: ss-0, uid: e99617a4-f41b-11e9-93ac-c26612c2e4bb, status phase: Failed. Waiting for statefulset controller to delete.
Oct 21 16:00:41.133: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-8702
STEP: Removing pod with conflicting port in namespace statefulset-8702
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-8702 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 21 16:00:45.218: INFO: Deleting all statefulset in ns statefulset-8702
Oct 21 16:00:45.225: INFO: Scaling statefulset ss to 0
Oct 21 16:00:55.270: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 16:00:55.279: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:00:55.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8702" for this suite.
Oct 21 16:01:01.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:01:01.758: INFO: namespace statefulset-8702 deletion completed in 6.42959764s

• [SLOW TEST:29.221 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:01:01.759: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6180
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-fac2b12a-f41b-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume configMaps
Oct 21 16:01:02.021: INFO: Waiting up to 5m0s for pod "pod-configmaps-fac48a82-f41b-11e9-ae8d-bacadc8895d2" in namespace "configmap-6180" to be "success or failure"
Oct 21 16:01:02.030: INFO: Pod "pod-configmaps-fac48a82-f41b-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.975468ms
Oct 21 16:01:04.042: INFO: Pod "pod-configmaps-fac48a82-f41b-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020709633s
STEP: Saw pod success
Oct 21 16:01:04.042: INFO: Pod "pod-configmaps-fac48a82-f41b-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:01:04.051: INFO: Trying to get logs from node 10.134.235.118 pod pod-configmaps-fac48a82-f41b-11e9-ae8d-bacadc8895d2 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:01:04.113: INFO: Waiting for pod pod-configmaps-fac48a82-f41b-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:01:04.122: INFO: Pod pod-configmaps-fac48a82-f41b-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:01:04.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6180" for this suite.
Oct 21 16:01:10.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:01:10.506: INFO: namespace configmap-6180 deletion completed in 6.366734885s

• [SLOW TEST:8.747 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:01:10.507: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3350
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 16:01:10.721: INFO: Creating deployment "test-recreate-deployment"
Oct 21 16:01:10.734: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct 21 16:01:10.752: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Oct 21 16:01:12.775: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct 21 16:01:12.785: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707270470, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707270470, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707270470, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707270470, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6566d46b4b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 16:01:14.802: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct 21 16:01:14.827: INFO: Updating deployment test-recreate-deployment
Oct 21 16:01:14.827: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 21 16:01:14.930: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-3350,SelfLink:/apis/apps/v1/namespaces/deployment-3350/deployments/test-recreate-deployment,UID:fff6c28f-f41b-11e9-a1ef-46591df82ad7,ResourceVersion:22513,Generation:2,CreationTimestamp:2019-10-21 16:01:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-10-21 16:01:14 +0000 UTC 2019-10-21 16:01:14 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-10-21 16:01:14 +0000 UTC 2019-10-21 16:01:10 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-745fb9c84c" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Oct 21 16:01:14.948: INFO: New ReplicaSet "test-recreate-deployment-745fb9c84c" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c,GenerateName:,Namespace:deployment-3350,SelfLink:/apis/apps/v1/namespaces/deployment-3350/replicasets/test-recreate-deployment-745fb9c84c,UID:02725012-f41c-11e9-93ac-c26612c2e4bb,ResourceVersion:22512,Generation:1,CreationTimestamp:2019-10-21 16:01:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment fff6c28f-f41b-11e9-a1ef-46591df82ad7 0xc0031f2117 0xc0031f2118}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 16:01:14.948: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct 21 16:01:14.948: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6566d46b4b,GenerateName:,Namespace:deployment-3350,SelfLink:/apis/apps/v1/namespaces/deployment-3350/replicasets/test-recreate-deployment-6566d46b4b,UID:fff9d84f-f41b-11e9-93ac-c26612c2e4bb,ResourceVersion:22503,Generation:2,CreationTimestamp:2019-10-21 16:01:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment fff6c28f-f41b-11e9-a1ef-46591df82ad7 0xc0031f2047 0xc0031f2048}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 16:01:14.958: INFO: Pod "test-recreate-deployment-745fb9c84c-r98vs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c-r98vs,GenerateName:test-recreate-deployment-745fb9c84c-,Namespace:deployment-3350,SelfLink:/api/v1/namespaces/deployment-3350/pods/test-recreate-deployment-745fb9c84c-r98vs,UID:0273877d-f41c-11e9-93ac-c26612c2e4bb,ResourceVersion:22515,Generation:0,CreationTimestamp:2019-10-21 16:01:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-745fb9c84c 02725012-f41c-11e9-93ac-c26612c2e4bb 0xc002026127 0xc002026128}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-n59bl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-n59bl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-n59bl true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.118,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020261a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020261c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:01:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:01:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:01:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:01:14 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.118,PodIP:,StartTime:2019-10-21 16:01:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:01:14.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3350" for this suite.
Oct 21 16:01:21.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:01:21.361: INFO: namespace deployment-3350 deletion completed in 6.389076173s

• [SLOW TEST:10.854 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:01:21.361: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3220
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-066f71a3-f41c-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume secrets
Oct 21 16:01:21.604: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-067175c0-f41c-11e9-ae8d-bacadc8895d2" in namespace "projected-3220" to be "success or failure"
Oct 21 16:01:21.616: INFO: Pod "pod-projected-secrets-067175c0-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.37698ms
Oct 21 16:01:23.626: INFO: Pod "pod-projected-secrets-067175c0-f41c-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021683617s
STEP: Saw pod success
Oct 21 16:01:23.626: INFO: Pod "pod-projected-secrets-067175c0-f41c-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:01:23.635: INFO: Trying to get logs from node 10.134.235.67 pod pod-projected-secrets-067175c0-f41c-11e9-ae8d-bacadc8895d2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 21 16:01:23.690: INFO: Waiting for pod pod-projected-secrets-067175c0-f41c-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:01:23.699: INFO: Pod pod-projected-secrets-067175c0-f41c-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:01:23.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3220" for this suite.
Oct 21 16:01:29.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:01:30.084: INFO: namespace projected-3220 deletion completed in 6.370725488s

• [SLOW TEST:8.723 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:01:30.084: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1901
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1384
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 16:01:30.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1901'
Oct 21 16:01:30.482: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 21 16:01:30.482: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1390
Oct 21 16:01:32.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 delete deployment e2e-test-nginx-deployment --namespace=kubectl-1901'
Oct 21 16:01:32.623: INFO: stderr: ""
Oct 21 16:01:32.623: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:01:32.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1901" for this suite.
Oct 21 16:01:56.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:01:56.983: INFO: namespace kubectl-1901 deletion completed in 24.345743348s

• [SLOW TEST:26.899 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:01:56.984: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4623
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Oct 21 16:01:57.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 cluster-info'
Oct 21 16:01:57.829: INFO: stderr: ""
Oct 21 16:01:57.829: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:01:57.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4623" for this suite.
Oct 21 16:02:03.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:02:04.231: INFO: namespace kubectl-4623 deletion completed in 6.388574144s

• [SLOW TEST:7.247 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:02:04.231: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3899
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:02:04.465: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1ffd1761-f41c-11e9-ae8d-bacadc8895d2" in namespace "downward-api-3899" to be "success or failure"
Oct 21 16:02:04.473: INFO: Pod "downwardapi-volume-1ffd1761-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.875278ms
Oct 21 16:02:06.485: INFO: Pod "downwardapi-volume-1ffd1761-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020215063s
Oct 21 16:02:08.495: INFO: Pod "downwardapi-volume-1ffd1761-f41c-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030572725s
STEP: Saw pod success
Oct 21 16:02:08.495: INFO: Pod "downwardapi-volume-1ffd1761-f41c-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:02:08.506: INFO: Trying to get logs from node 10.134.235.67 pod downwardapi-volume-1ffd1761-f41c-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 16:02:08.569: INFO: Waiting for pod downwardapi-volume-1ffd1761-f41c-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:02:09.251: INFO: Pod downwardapi-volume-1ffd1761-f41c-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:02:09.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3899" for this suite.
Oct 21 16:02:15.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:02:15.685: INFO: namespace downward-api-3899 deletion completed in 6.416142106s

• [SLOW TEST:11.454 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:02:15.686: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4137
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:02:15.930: INFO: Waiting up to 5m0s for pod "downwardapi-volume-26d1c384-f41c-11e9-ae8d-bacadc8895d2" in namespace "projected-4137" to be "success or failure"
Oct 21 16:02:15.942: INFO: Pod "downwardapi-volume-26d1c384-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.494448ms
Oct 21 16:02:17.958: INFO: Pod "downwardapi-volume-26d1c384-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027702273s
Oct 21 16:02:19.974: INFO: Pod "downwardapi-volume-26d1c384-f41c-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044270529s
STEP: Saw pod success
Oct 21 16:02:19.974: INFO: Pod "downwardapi-volume-26d1c384-f41c-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:02:19.984: INFO: Trying to get logs from node 10.134.235.118 pod downwardapi-volume-26d1c384-f41c-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 16:02:20.145: INFO: Waiting for pod downwardapi-volume-26d1c384-f41c-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:02:20.154: INFO: Pod downwardapi-volume-26d1c384-f41c-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:02:20.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4137" for this suite.
Oct 21 16:02:26.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:02:26.525: INFO: namespace projected-4137 deletion completed in 6.359408714s

• [SLOW TEST:10.839 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:02:26.525: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4037
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:02:26.754: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2d46ad58-f41c-11e9-ae8d-bacadc8895d2" in namespace "projected-4037" to be "success or failure"
Oct 21 16:02:26.763: INFO: Pod "downwardapi-volume-2d46ad58-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.558714ms
Oct 21 16:02:28.820: INFO: Pod "downwardapi-volume-2d46ad58-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065396138s
Oct 21 16:02:30.829: INFO: Pod "downwardapi-volume-2d46ad58-f41c-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.075010616s
STEP: Saw pod success
Oct 21 16:02:30.829: INFO: Pod "downwardapi-volume-2d46ad58-f41c-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:02:30.841: INFO: Trying to get logs from node 10.134.235.67 pod downwardapi-volume-2d46ad58-f41c-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 16:02:31.186: INFO: Waiting for pod downwardapi-volume-2d46ad58-f41c-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:02:31.195: INFO: Pod downwardapi-volume-2d46ad58-f41c-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:02:31.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4037" for this suite.
Oct 21 16:02:37.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:02:37.566: INFO: namespace projected-4037 deletion completed in 6.357209959s

• [SLOW TEST:11.041 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:02:37.566: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-924
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:02:37.789: INFO: Waiting up to 5m0s for pod "downwardapi-volume-33da29bf-f41c-11e9-ae8d-bacadc8895d2" in namespace "downward-api-924" to be "success or failure"
Oct 21 16:02:37.798: INFO: Pod "downwardapi-volume-33da29bf-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.18677ms
Oct 21 16:02:39.807: INFO: Pod "downwardapi-volume-33da29bf-f41c-11e9-ae8d-bacadc8895d2": Phase="Running", Reason="", readiness=true. Elapsed: 2.018322996s
Oct 21 16:02:41.818: INFO: Pod "downwardapi-volume-33da29bf-f41c-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029756405s
STEP: Saw pod success
Oct 21 16:02:41.818: INFO: Pod "downwardapi-volume-33da29bf-f41c-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:02:41.827: INFO: Trying to get logs from node 10.134.235.118 pod downwardapi-volume-33da29bf-f41c-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 16:02:41.881: INFO: Waiting for pod downwardapi-volume-33da29bf-f41c-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:02:41.889: INFO: Pod downwardapi-volume-33da29bf-f41c-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:02:41.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-924" for this suite.
Oct 21 16:02:47.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:02:48.255: INFO: namespace downward-api-924 deletion completed in 6.352835949s

• [SLOW TEST:10.688 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:02:48.256: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1083
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:02:48.551: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3a432cfa-f41c-11e9-ae8d-bacadc8895d2" in namespace "projected-1083" to be "success or failure"
Oct 21 16:02:48.560: INFO: Pod "downwardapi-volume-3a432cfa-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.626582ms
Oct 21 16:02:50.571: INFO: Pod "downwardapi-volume-3a432cfa-f41c-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02024288s
STEP: Saw pod success
Oct 21 16:02:50.571: INFO: Pod "downwardapi-volume-3a432cfa-f41c-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:02:50.866: INFO: Trying to get logs from node 10.134.235.118 pod downwardapi-volume-3a432cfa-f41c-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 16:02:50.913: INFO: Waiting for pod downwardapi-volume-3a432cfa-f41c-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:02:50.922: INFO: Pod downwardapi-volume-3a432cfa-f41c-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:02:50.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1083" for this suite.
Oct 21 16:02:56.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:02:57.296: INFO: namespace projected-1083 deletion completed in 6.363351226s

• [SLOW TEST:9.041 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:02:57.296: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1913
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-3fe6e725-f41c-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume configMaps
Oct 21 16:02:58.018: INFO: Waiting up to 5m0s for pod "pod-configmaps-3fe8c4a0-f41c-11e9-ae8d-bacadc8895d2" in namespace "configmap-1913" to be "success or failure"
Oct 21 16:02:58.036: INFO: Pod "pod-configmaps-3fe8c4a0-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 17.450535ms
Oct 21 16:03:00.048: INFO: Pod "pod-configmaps-3fe8c4a0-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029653645s
Oct 21 16:03:02.057: INFO: Pod "pod-configmaps-3fe8c4a0-f41c-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038175586s
STEP: Saw pod success
Oct 21 16:03:02.057: INFO: Pod "pod-configmaps-3fe8c4a0-f41c-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:03:02.069: INFO: Trying to get logs from node 10.134.235.118 pod pod-configmaps-3fe8c4a0-f41c-11e9-ae8d-bacadc8895d2 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:03:02.128: INFO: Waiting for pod pod-configmaps-3fe8c4a0-f41c-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:03:02.141: INFO: Pod pod-configmaps-3fe8c4a0-f41c-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:03:02.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1913" for this suite.
Oct 21 16:03:08.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:03:08.574: INFO: namespace configmap-1913 deletion completed in 6.418971758s

• [SLOW TEST:11.278 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:03:08.574: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6300
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Oct 21 16:03:08.808: INFO: Waiting up to 5m0s for pod "client-containers-465794e1-f41c-11e9-ae8d-bacadc8895d2" in namespace "containers-6300" to be "success or failure"
Oct 21 16:03:08.817: INFO: Pod "client-containers-465794e1-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.314904ms
Oct 21 16:03:10.827: INFO: Pod "client-containers-465794e1-f41c-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019005441s
STEP: Saw pod success
Oct 21 16:03:10.827: INFO: Pod "client-containers-465794e1-f41c-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:03:10.836: INFO: Trying to get logs from node 10.134.235.67 pod client-containers-465794e1-f41c-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 16:03:10.885: INFO: Waiting for pod client-containers-465794e1-f41c-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:03:10.907: INFO: Pod client-containers-465794e1-f41c-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:03:10.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6300" for this suite.
Oct 21 16:03:16.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:03:17.322: INFO: namespace containers-6300 deletion completed in 6.400079432s

• [SLOW TEST:8.748 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:03:17.323: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3251
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-4b8ecb44-f41c-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume secrets
Oct 21 16:03:17.570: INFO: Waiting up to 5m0s for pod "pod-secrets-4b9086e7-f41c-11e9-ae8d-bacadc8895d2" in namespace "secrets-3251" to be "success or failure"
Oct 21 16:03:17.582: INFO: Pod "pod-secrets-4b9086e7-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.834477ms
Oct 21 16:03:19.593: INFO: Pod "pod-secrets-4b9086e7-f41c-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023109368s
STEP: Saw pod success
Oct 21 16:03:19.593: INFO: Pod "pod-secrets-4b9086e7-f41c-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:03:19.608: INFO: Trying to get logs from node 10.134.235.118 pod pod-secrets-4b9086e7-f41c-11e9-ae8d-bacadc8895d2 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 16:03:19.666: INFO: Waiting for pod pod-secrets-4b9086e7-f41c-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:03:19.674: INFO: Pod pod-secrets-4b9086e7-f41c-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:03:19.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3251" for this suite.
Oct 21 16:03:25.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:03:26.209: INFO: namespace secrets-3251 deletion completed in 6.519408017s

• [SLOW TEST:8.887 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:03:26.210: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-5380
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Oct 21 16:03:27.014: INFO: created pod pod-service-account-defaultsa
Oct 21 16:03:27.014: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct 21 16:03:27.028: INFO: created pod pod-service-account-mountsa
Oct 21 16:03:27.028: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct 21 16:03:27.042: INFO: created pod pod-service-account-nomountsa
Oct 21 16:03:27.042: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct 21 16:03:27.053: INFO: created pod pod-service-account-defaultsa-mountspec
Oct 21 16:03:27.054: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct 21 16:03:27.070: INFO: created pod pod-service-account-mountsa-mountspec
Oct 21 16:03:27.070: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct 21 16:03:27.081: INFO: created pod pod-service-account-nomountsa-mountspec
Oct 21 16:03:27.082: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct 21 16:03:27.092: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct 21 16:03:27.092: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct 21 16:03:27.103: INFO: created pod pod-service-account-mountsa-nomountspec
Oct 21 16:03:27.103: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct 21 16:03:27.117: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct 21 16:03:27.117: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:03:27.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5380" for this suite.
Oct 21 16:03:33.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:03:33.546: INFO: namespace svcaccounts-5380 deletion completed in 6.414522449s

• [SLOW TEST:7.336 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:03:33.546: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-444
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-553c4e73-f41c-11e9-ae8d-bacadc8895d2
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-553c4e73-f41c-11e9-ae8d-bacadc8895d2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:03:37.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-444" for this suite.
Oct 21 16:04:01.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:04:02.362: INFO: namespace projected-444 deletion completed in 24.42788153s

• [SLOW TEST:28.816 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:04:02.363: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3399
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-3399
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3399 to expose endpoints map[]
Oct 21 16:04:02.668: INFO: successfully validated that service multi-endpoint-test in namespace services-3399 exposes endpoints map[] (14.463343ms elapsed)
STEP: Creating pod pod1 in namespace services-3399
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3399 to expose endpoints map[pod1:[100]]
Oct 21 16:04:04.751: INFO: successfully validated that service multi-endpoint-test in namespace services-3399 exposes endpoints map[pod1:[100]] (2.060652501s elapsed)
STEP: Creating pod pod2 in namespace services-3399
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3399 to expose endpoints map[pod1:[100] pod2:[101]]
Oct 21 16:04:06.850: INFO: successfully validated that service multi-endpoint-test in namespace services-3399 exposes endpoints map[pod1:[100] pod2:[101]] (2.085439977s elapsed)
STEP: Deleting pod pod1 in namespace services-3399
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3399 to expose endpoints map[pod2:[101]]
Oct 21 16:04:07.907: INFO: successfully validated that service multi-endpoint-test in namespace services-3399 exposes endpoints map[pod2:[101]] (1.038088224s elapsed)
STEP: Deleting pod pod2 in namespace services-3399
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3399 to expose endpoints map[]
Oct 21 16:04:07.931: INFO: successfully validated that service multi-endpoint-test in namespace services-3399 exposes endpoints map[] (7.133653ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:04:07.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3399" for this suite.
Oct 21 16:04:32.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:04:32.377: INFO: namespace services-3399 deletion completed in 24.36818936s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:30.014 seconds]
[sig-network] Services
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:04:32.377: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8024
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-7849d4c1-f41c-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume configMaps
Oct 21 16:04:32.621: INFO: Waiting up to 5m0s for pod "pod-configmaps-784bd9c0-f41c-11e9-ae8d-bacadc8895d2" in namespace "configmap-8024" to be "success or failure"
Oct 21 16:04:32.635: INFO: Pod "pod-configmaps-784bd9c0-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.580555ms
Oct 21 16:04:34.644: INFO: Pod "pod-configmaps-784bd9c0-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023071574s
Oct 21 16:04:36.654: INFO: Pod "pod-configmaps-784bd9c0-f41c-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033247938s
STEP: Saw pod success
Oct 21 16:04:36.655: INFO: Pod "pod-configmaps-784bd9c0-f41c-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:04:36.663: INFO: Trying to get logs from node 10.134.235.67 pod pod-configmaps-784bd9c0-f41c-11e9-ae8d-bacadc8895d2 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:04:36.713: INFO: Waiting for pod pod-configmaps-784bd9c0-f41c-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:04:36.722: INFO: Pod pod-configmaps-784bd9c0-f41c-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:04:36.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8024" for this suite.
Oct 21 16:04:42.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:04:43.141: INFO: namespace configmap-8024 deletion completed in 6.39949909s

• [SLOW TEST:10.764 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:04:43.142: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1060
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 16:04:43.358: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:04:47.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1060" for this suite.
Oct 21 16:05:27.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:05:28.056: INFO: namespace pods-1060 deletion completed in 40.389810539s

• [SLOW TEST:44.914 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:05:28.056: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5232
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-5232/configmap-test-997aa9ba-f41c-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume configMaps
Oct 21 16:05:28.305: INFO: Waiting up to 5m0s for pod "pod-configmaps-997ccc8e-f41c-11e9-ae8d-bacadc8895d2" in namespace "configmap-5232" to be "success or failure"
Oct 21 16:05:28.313: INFO: Pod "pod-configmaps-997ccc8e-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.681704ms
Oct 21 16:05:30.323: INFO: Pod "pod-configmaps-997ccc8e-f41c-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018612455s
STEP: Saw pod success
Oct 21 16:05:30.323: INFO: Pod "pod-configmaps-997ccc8e-f41c-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:05:30.331: INFO: Trying to get logs from node 10.134.235.67 pod pod-configmaps-997ccc8e-f41c-11e9-ae8d-bacadc8895d2 container env-test: <nil>
STEP: delete the pod
Oct 21 16:05:30.386: INFO: Waiting for pod pod-configmaps-997ccc8e-f41c-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:05:30.394: INFO: Pod pod-configmaps-997ccc8e-f41c-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:05:30.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5232" for this suite.
Oct 21 16:05:36.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:05:36.784: INFO: namespace configmap-5232 deletion completed in 6.37485008s

• [SLOW TEST:8.727 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:05:36.784: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3685
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 16:05:37.035: INFO: (0) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.879992ms)
Oct 21 16:05:37.058: INFO: (1) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.094296ms)
Oct 21 16:05:37.072: INFO: (2) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.276874ms)
Oct 21 16:05:37.089: INFO: (3) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.03375ms)
Oct 21 16:05:37.103: INFO: (4) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.731775ms)
Oct 21 16:05:37.119: INFO: (5) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.305367ms)
Oct 21 16:05:37.133: INFO: (6) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.647854ms)
Oct 21 16:05:37.148: INFO: (7) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.198906ms)
Oct 21 16:05:37.165: INFO: (8) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.129723ms)
Oct 21 16:05:37.181: INFO: (9) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.666888ms)
Oct 21 16:05:37.196: INFO: (10) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.729698ms)
Oct 21 16:05:37.213: INFO: (11) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.377494ms)
Oct 21 16:05:37.231: INFO: (12) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 18.298915ms)
Oct 21 16:05:37.251: INFO: (13) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 19.922263ms)
Oct 21 16:05:37.264: INFO: (14) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.989811ms)
Oct 21 16:05:37.277: INFO: (15) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.949578ms)
Oct 21 16:05:37.299: INFO: (16) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.076671ms)
Oct 21 16:05:37.313: INFO: (17) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.123954ms)
Oct 21 16:05:37.326: INFO: (18) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.954736ms)
Oct 21 16:05:37.341: INFO: (19) /api/v1/nodes/10.134.235.118:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.115352ms)
[AfterEach] version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:05:37.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3685" for this suite.
Oct 21 16:05:43.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:05:44.286: INFO: namespace proxy-3685 deletion completed in 6.931581733s

• [SLOW TEST:7.502 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:05:44.287: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1086
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:05:44.518: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a326dae8-f41c-11e9-ae8d-bacadc8895d2" in namespace "downward-api-1086" to be "success or failure"
Oct 21 16:05:44.533: INFO: Pod "downwardapi-volume-a326dae8-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 15.036738ms
Oct 21 16:05:46.547: INFO: Pod "downwardapi-volume-a326dae8-f41c-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02883702s
STEP: Saw pod success
Oct 21 16:05:46.547: INFO: Pod "downwardapi-volume-a326dae8-f41c-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:05:46.560: INFO: Trying to get logs from node 10.134.235.67 pod downwardapi-volume-a326dae8-f41c-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 16:05:46.619: INFO: Waiting for pod downwardapi-volume-a326dae8-f41c-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:05:46.629: INFO: Pod downwardapi-volume-a326dae8-f41c-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:05:46.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1086" for this suite.
Oct 21 16:05:52.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:05:53.010: INFO: namespace downward-api-1086 deletion completed in 6.364455197s

• [SLOW TEST:8.723 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:05:53.011: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2233
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 21 16:05:53.244: INFO: Waiting up to 5m0s for pod "pod-a85a8750-f41c-11e9-ae8d-bacadc8895d2" in namespace "emptydir-2233" to be "success or failure"
Oct 21 16:05:53.252: INFO: Pod "pod-a85a8750-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.608839ms
Oct 21 16:05:55.262: INFO: Pod "pod-a85a8750-f41c-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017993896s
STEP: Saw pod success
Oct 21 16:05:55.262: INFO: Pod "pod-a85a8750-f41c-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:05:55.289: INFO: Trying to get logs from node 10.134.235.67 pod pod-a85a8750-f41c-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 16:05:55.353: INFO: Waiting for pod pod-a85a8750-f41c-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:05:55.369: INFO: Pod pod-a85a8750-f41c-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:05:55.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2233" for this suite.
Oct 21 16:06:01.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:06:02.881: INFO: namespace emptydir-2233 deletion completed in 7.498910981s

• [SLOW TEST:9.870 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:06:02.883: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5296
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-ae4baad9-f41c-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume configMaps
Oct 21 16:06:03.239: INFO: Waiting up to 5m0s for pod "pod-configmaps-ae4d7f08-f41c-11e9-ae8d-bacadc8895d2" in namespace "configmap-5296" to be "success or failure"
Oct 21 16:06:03.256: INFO: Pod "pod-configmaps-ae4d7f08-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 16.892749ms
Oct 21 16:06:05.274: INFO: Pod "pod-configmaps-ae4d7f08-f41c-11e9-ae8d-bacadc8895d2": Phase="Running", Reason="", readiness=true. Elapsed: 2.035071018s
Oct 21 16:06:07.285: INFO: Pod "pod-configmaps-ae4d7f08-f41c-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045307703s
STEP: Saw pod success
Oct 21 16:06:07.285: INFO: Pod "pod-configmaps-ae4d7f08-f41c-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:06:07.296: INFO: Trying to get logs from node 10.134.235.118 pod pod-configmaps-ae4d7f08-f41c-11e9-ae8d-bacadc8895d2 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:06:07.353: INFO: Waiting for pod pod-configmaps-ae4d7f08-f41c-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:06:07.363: INFO: Pod pod-configmaps-ae4d7f08-f41c-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:06:07.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5296" for this suite.
Oct 21 16:06:13.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:06:13.830: INFO: namespace configmap-5296 deletion completed in 6.453956105s

• [SLOW TEST:10.947 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:06:13.831: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8744
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 21 16:06:18.179: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 21 16:06:18.195: INFO: Pod pod-with-prestop-http-hook still exists
Oct 21 16:06:20.195: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 21 16:06:20.206: INFO: Pod pod-with-prestop-http-hook still exists
Oct 21 16:06:22.195: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 21 16:06:22.204: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:06:22.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8744" for this suite.
Oct 21 16:06:46.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:06:46.587: INFO: namespace container-lifecycle-hook-8744 deletion completed in 24.346376242s

• [SLOW TEST:32.756 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:06:46.588: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2860
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 16:06:46.884: INFO: Create a RollingUpdate DaemonSet
Oct 21 16:06:46.897: INFO: Check that daemon pods launch on every node of the cluster
Oct 21 16:06:46.923: INFO: Number of nodes with available pods: 0
Oct 21 16:06:46.923: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 16:06:47.962: INFO: Number of nodes with available pods: 0
Oct 21 16:06:47.962: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 16:06:48.945: INFO: Number of nodes with available pods: 1
Oct 21 16:06:48.945: INFO: Node 10.134.235.67 is running more than one daemon pod
Oct 21 16:06:49.945: INFO: Number of nodes with available pods: 2
Oct 21 16:06:49.945: INFO: Node 10.134.235.77 is running more than one daemon pod
Oct 21 16:06:50.947: INFO: Number of nodes with available pods: 2
Oct 21 16:06:50.948: INFO: Node 10.134.235.77 is running more than one daemon pod
Oct 21 16:06:51.947: INFO: Number of nodes with available pods: 3
Oct 21 16:06:51.947: INFO: Number of running nodes: 3, number of available pods: 3
Oct 21 16:06:51.947: INFO: Update the DaemonSet to trigger a rollout
Oct 21 16:06:51.967: INFO: Updating DaemonSet daemon-set
Oct 21 16:06:59.184: INFO: Roll back the DaemonSet before rollout is complete
Oct 21 16:06:59.206: INFO: Updating DaemonSet daemon-set
Oct 21 16:06:59.206: INFO: Make sure DaemonSet rollback is complete
Oct 21 16:06:59.220: INFO: Wrong image for pod: daemon-set-2522c. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 21 16:06:59.220: INFO: Pod daemon-set-2522c is not available
Oct 21 16:07:00.246: INFO: Wrong image for pod: daemon-set-2522c. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 21 16:07:00.246: INFO: Pod daemon-set-2522c is not available
Oct 21 16:07:01.243: INFO: Pod daemon-set-gb8g9 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2860, will wait for the garbage collector to delete the pods
Oct 21 16:07:01.368: INFO: Deleting DaemonSet.extensions daemon-set took: 26.491196ms
Oct 21 16:07:01.468: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.263296ms
Oct 21 16:07:06.182: INFO: Number of nodes with available pods: 0
Oct 21 16:07:06.182: INFO: Number of running nodes: 0, number of available pods: 0
Oct 21 16:07:06.210: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2860/daemonsets","resourceVersion":"24227"},"items":null}

Oct 21 16:07:06.219: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2860/pods","resourceVersion":"24227"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:07:06.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2860" for this suite.
Oct 21 16:07:14.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:07:14.804: INFO: namespace daemonsets-2860 deletion completed in 8.413144508s

• [SLOW TEST:28.216 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:07:14.804: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6709
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-4823
STEP: Creating secret with name secret-test-d91c62e7-f41c-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume secrets
Oct 21 16:07:15.302: INFO: Waiting up to 5m0s for pod "pod-secrets-d941e910-f41c-11e9-ae8d-bacadc8895d2" in namespace "secrets-6709" to be "success or failure"
Oct 21 16:07:15.314: INFO: Pod "pod-secrets-d941e910-f41c-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.685681ms
Oct 21 16:07:17.323: INFO: Pod "pod-secrets-d941e910-f41c-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020654469s
STEP: Saw pod success
Oct 21 16:07:17.323: INFO: Pod "pod-secrets-d941e910-f41c-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:07:17.334: INFO: Trying to get logs from node 10.134.235.67 pod pod-secrets-d941e910-f41c-11e9-ae8d-bacadc8895d2 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 16:07:17.403: INFO: Waiting for pod pod-secrets-d941e910-f41c-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:07:17.414: INFO: Pod pod-secrets-d941e910-f41c-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:07:17.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6709" for this suite.
Oct 21 16:07:23.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:07:23.839: INFO: namespace secrets-6709 deletion completed in 6.409348234s
STEP: Destroying namespace "secret-namespace-4823" for this suite.
Oct 21 16:07:29.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:07:30.212: INFO: namespace secret-namespace-4823 deletion completed in 6.372857487s

• [SLOW TEST:15.408 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:07:30.213: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-395
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-395
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-395
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-395
Oct 21 16:07:30.452: INFO: Found 0 stateful pods, waiting for 1
Oct 21 16:07:40.463: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Oct 21 16:07:40.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-395 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 16:07:40.843: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 16:07:40.843: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 16:07:40.843: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 16:07:40.853: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 21 16:07:50.865: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 16:07:50.865: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 16:07:50.905: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998743s
Oct 21 16:07:51.915: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.989323164s
Oct 21 16:07:52.925: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.97953224s
Oct 21 16:07:53.934: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.969167892s
Oct 21 16:07:54.945: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.960410247s
Oct 21 16:07:55.958: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.949166096s
Oct 21 16:07:56.968: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.937006192s
Oct 21 16:07:57.977: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.926534752s
Oct 21 16:07:58.990: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.91747046s
Oct 21 16:07:59.999: INFO: Verifying statefulset ss doesn't scale past 1 for another 904.328648ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-395
Oct 21 16:08:01.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-395 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:08:02.172: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 21 16:08:02.172: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 16:08:02.172: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 16:08:02.183: INFO: Found 1 stateful pods, waiting for 3
Oct 21 16:08:12.197: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:08:12.197: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:08:12.197: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Oct 21 16:08:12.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-395 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 16:08:12.623: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 16:08:12.623: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 16:08:12.623: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 16:08:12.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-395 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 16:08:12.960: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 16:08:12.960: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 16:08:12.960: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 16:08:12.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-395 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 16:08:13.300: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 16:08:13.300: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 16:08:13.300: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 16:08:13.300: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 16:08:13.309: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct 21 16:08:23.687: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 16:08:23.687: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 16:08:23.687: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 16:08:23.727: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998709s
Oct 21 16:08:24.736: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.989622038s
Oct 21 16:08:25.748: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.980452271s
Oct 21 16:08:26.757: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.968585414s
Oct 21 16:08:27.767: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.95957238s
Oct 21 16:08:28.778: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.948670408s
Oct 21 16:08:30.101: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.938198898s
Oct 21 16:08:31.112: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.615151716s
Oct 21 16:08:32.121: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.604088632s
Oct 21 16:08:33.133: INFO: Verifying statefulset ss doesn't scale past 3 for another 595.134329ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-395
Oct 21 16:08:34.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-395 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:08:34.673: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 21 16:08:34.673: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 16:08:34.673: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 16:08:34.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-395 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:08:35.019: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 21 16:08:35.019: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 16:08:35.020: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 16:08:35.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-395 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:08:35.582: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 21 16:08:35.582: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 16:08:35.582: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 16:08:35.582: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 21 16:09:15.626: INFO: Deleting all statefulset in ns statefulset-395
Oct 21 16:09:15.636: INFO: Scaling statefulset ss to 0
Oct 21 16:09:15.668: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 16:09:15.677: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:09:15.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-395" for this suite.
Oct 21 16:09:23.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:09:24.166: INFO: namespace statefulset-395 deletion completed in 8.442107007s

• [SLOW TEST:113.952 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:09:24.167: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-52
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 16:09:24.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-52'
Oct 21 16:09:24.483: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 21 16:09:24.483: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Oct 21 16:09:24.499: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-h4tnj]
Oct 21 16:09:24.499: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-h4tnj" in namespace "kubectl-52" to be "running and ready"
Oct 21 16:09:24.509: INFO: Pod "e2e-test-nginx-rc-h4tnj": Phase="Pending", Reason="", readiness=false. Elapsed: 9.809173ms
Oct 21 16:09:26.518: INFO: Pod "e2e-test-nginx-rc-h4tnj": Phase="Running", Reason="", readiness=true. Elapsed: 2.018998664s
Oct 21 16:09:26.518: INFO: Pod "e2e-test-nginx-rc-h4tnj" satisfied condition "running and ready"
Oct 21 16:09:26.518: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-h4tnj]
Oct 21 16:09:26.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 logs rc/e2e-test-nginx-rc --namespace=kubectl-52'
Oct 21 16:09:26.993: INFO: stderr: ""
Oct 21 16:09:26.993: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1425
Oct 21 16:09:26.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 delete rc e2e-test-nginx-rc --namespace=kubectl-52'
Oct 21 16:09:27.105: INFO: stderr: ""
Oct 21 16:09:27.105: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:09:27.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-52" for this suite.
Oct 21 16:09:51.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:09:51.492: INFO: namespace kubectl-52 deletion completed in 24.374231668s

• [SLOW TEST:27.325 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:09:51.492: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6264
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Oct 21 16:09:51.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 create -f - --namespace=kubectl-6264'
Oct 21 16:09:51.937: INFO: stderr: ""
Oct 21 16:09:51.937: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 16:09:51.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6264'
Oct 21 16:09:52.042: INFO: stderr: ""
Oct 21 16:09:52.042: INFO: stdout: "update-demo-nautilus-9m5l6 update-demo-nautilus-vkn78 "
Oct 21 16:09:52.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-9m5l6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6264'
Oct 21 16:09:52.147: INFO: stderr: ""
Oct 21 16:09:52.147: INFO: stdout: ""
Oct 21 16:09:52.147: INFO: update-demo-nautilus-9m5l6 is created but not running
Oct 21 16:09:57.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6264'
Oct 21 16:09:57.241: INFO: stderr: ""
Oct 21 16:09:57.241: INFO: stdout: "update-demo-nautilus-9m5l6 update-demo-nautilus-vkn78 "
Oct 21 16:09:57.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-9m5l6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6264'
Oct 21 16:09:57.346: INFO: stderr: ""
Oct 21 16:09:57.346: INFO: stdout: "true"
Oct 21 16:09:57.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-9m5l6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6264'
Oct 21 16:09:57.457: INFO: stderr: ""
Oct 21 16:09:57.457: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:09:57.457: INFO: validating pod update-demo-nautilus-9m5l6
Oct 21 16:09:57.480: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:09:57.480: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:09:57.480: INFO: update-demo-nautilus-9m5l6 is verified up and running
Oct 21 16:09:57.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-vkn78 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6264'
Oct 21 16:09:57.568: INFO: stderr: ""
Oct 21 16:09:57.568: INFO: stdout: "true"
Oct 21 16:09:57.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-vkn78 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6264'
Oct 21 16:09:57.680: INFO: stderr: ""
Oct 21 16:09:57.680: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:09:57.680: INFO: validating pod update-demo-nautilus-vkn78
Oct 21 16:09:57.696: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:09:57.696: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:09:57.696: INFO: update-demo-nautilus-vkn78 is verified up and running
STEP: scaling down the replication controller
Oct 21 16:09:57.697: INFO: scanned /root for discovery docs: <nil>
Oct 21 16:09:57.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-6264'
Oct 21 16:09:58.871: INFO: stderr: ""
Oct 21 16:09:58.871: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 16:09:58.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6264'
Oct 21 16:09:58.971: INFO: stderr: ""
Oct 21 16:09:58.971: INFO: stdout: "update-demo-nautilus-9m5l6 update-demo-nautilus-vkn78 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 21 16:10:03.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6264'
Oct 21 16:10:04.074: INFO: stderr: ""
Oct 21 16:10:04.074: INFO: stdout: "update-demo-nautilus-9m5l6 update-demo-nautilus-vkn78 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 21 16:10:09.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6264'
Oct 21 16:10:09.166: INFO: stderr: ""
Oct 21 16:10:09.166: INFO: stdout: "update-demo-nautilus-9m5l6 update-demo-nautilus-vkn78 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 21 16:10:14.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6264'
Oct 21 16:10:14.278: INFO: stderr: ""
Oct 21 16:10:14.278: INFO: stdout: "update-demo-nautilus-9m5l6 "
Oct 21 16:10:14.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-9m5l6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6264'
Oct 21 16:10:14.390: INFO: stderr: ""
Oct 21 16:10:14.390: INFO: stdout: "true"
Oct 21 16:10:14.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-9m5l6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6264'
Oct 21 16:10:14.483: INFO: stderr: ""
Oct 21 16:10:14.483: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:10:14.483: INFO: validating pod update-demo-nautilus-9m5l6
Oct 21 16:10:14.504: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:10:14.504: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:10:14.504: INFO: update-demo-nautilus-9m5l6 is verified up and running
STEP: scaling up the replication controller
Oct 21 16:10:14.505: INFO: scanned /root for discovery docs: <nil>
Oct 21 16:10:14.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-6264'
Oct 21 16:10:15.658: INFO: stderr: ""
Oct 21 16:10:15.658: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 16:10:15.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6264'
Oct 21 16:10:15.765: INFO: stderr: ""
Oct 21 16:10:15.765: INFO: stdout: "update-demo-nautilus-9m5l6 update-demo-nautilus-9qz9k "
Oct 21 16:10:15.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-9m5l6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6264'
Oct 21 16:10:15.871: INFO: stderr: ""
Oct 21 16:10:15.871: INFO: stdout: "true"
Oct 21 16:10:15.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-9m5l6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6264'
Oct 21 16:10:15.956: INFO: stderr: ""
Oct 21 16:10:15.956: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:10:15.956: INFO: validating pod update-demo-nautilus-9m5l6
Oct 21 16:10:15.973: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:10:15.973: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:10:15.973: INFO: update-demo-nautilus-9m5l6 is verified up and running
Oct 21 16:10:15.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-9qz9k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6264'
Oct 21 16:10:16.066: INFO: stderr: ""
Oct 21 16:10:16.067: INFO: stdout: "true"
Oct 21 16:10:16.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-9qz9k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6264'
Oct 21 16:10:16.169: INFO: stderr: ""
Oct 21 16:10:16.169: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:10:16.169: INFO: validating pod update-demo-nautilus-9qz9k
Oct 21 16:10:16.203: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:10:16.203: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:10:16.203: INFO: update-demo-nautilus-9qz9k is verified up and running
STEP: using delete to clean up resources
Oct 21 16:10:16.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 delete --grace-period=0 --force -f - --namespace=kubectl-6264'
Oct 21 16:10:16.320: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 16:10:16.320: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 21 16:10:16.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6264'
Oct 21 16:10:16.422: INFO: stderr: "No resources found.\n"
Oct 21 16:10:16.422: INFO: stdout: ""
Oct 21 16:10:16.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -l name=update-demo --namespace=kubectl-6264 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 21 16:10:16.514: INFO: stderr: ""
Oct 21 16:10:16.514: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:10:16.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6264" for this suite.
Oct 21 16:10:40.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:10:40.924: INFO: namespace kubectl-6264 deletion completed in 24.396764562s

• [SLOW TEST:49.432 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:10:40.924: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8151
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 16:10:41.283: INFO: (0) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.001749ms)
Oct 21 16:10:41.301: INFO: (1) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 18.465161ms)
Oct 21 16:10:41.316: INFO: (2) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.459044ms)
Oct 21 16:10:41.341: INFO: (3) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 24.985158ms)
Oct 21 16:10:41.358: INFO: (4) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.008551ms)
Oct 21 16:10:41.374: INFO: (5) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.384832ms)
Oct 21 16:10:41.401: INFO: (6) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 27.235325ms)
Oct 21 16:10:41.418: INFO: (7) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.187805ms)
Oct 21 16:10:41.435: INFO: (8) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.715922ms)
Oct 21 16:10:41.448: INFO: (9) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.298764ms)
Oct 21 16:10:41.463: INFO: (10) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.02429ms)
Oct 21 16:10:41.478: INFO: (11) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.394692ms)
Oct 21 16:10:41.492: INFO: (12) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.090309ms)
Oct 21 16:10:41.514: INFO: (13) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.821244ms)
Oct 21 16:10:41.527: INFO: (14) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.484113ms)
Oct 21 16:10:41.542: INFO: (15) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.162365ms)
Oct 21 16:10:41.560: INFO: (16) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.339627ms)
Oct 21 16:10:41.579: INFO: (17) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 19.377314ms)
Oct 21 16:10:41.603: INFO: (18) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.947553ms)
Oct 21 16:10:41.620: INFO: (19) /api/v1/nodes/10.134.235.118/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.354631ms)
[AfterEach] version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:10:41.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8151" for this suite.
Oct 21 16:10:47.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:10:47.982: INFO: namespace proxy-8151 deletion completed in 6.350127325s

• [SLOW TEST:7.058 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:10:47.982: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4255
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct 21 16:10:48.196: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:10:52.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4255" for this suite.
Oct 21 16:10:58.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:10:58.752: INFO: namespace init-container-4255 deletion completed in 6.389560269s

• [SLOW TEST:10.770 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:10:58.752: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-7497
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9622
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9120
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:11:06.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7497" for this suite.
Oct 21 16:11:12.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:11:13.049: INFO: namespace namespaces-7497 deletion completed in 6.438144374s
STEP: Destroying namespace "nsdeletetest-9622" for this suite.
Oct 21 16:11:13.060: INFO: Namespace nsdeletetest-9622 was already deleted
STEP: Destroying namespace "nsdeletetest-9120" for this suite.
Oct 21 16:11:19.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:11:19.439: INFO: namespace nsdeletetest-9120 deletion completed in 6.378832218s

• [SLOW TEST:20.687 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:11:19.439: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7696
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct 21 16:11:19.670: INFO: Waiting up to 5m0s for pod "downward-api-6aeacbb1-f41d-11e9-ae8d-bacadc8895d2" in namespace "downward-api-7696" to be "success or failure"
Oct 21 16:11:19.679: INFO: Pod "downward-api-6aeacbb1-f41d-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.663759ms
Oct 21 16:11:21.687: INFO: Pod "downward-api-6aeacbb1-f41d-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017389504s
STEP: Saw pod success
Oct 21 16:11:21.687: INFO: Pod "downward-api-6aeacbb1-f41d-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:11:21.698: INFO: Trying to get logs from node 10.134.235.118 pod downward-api-6aeacbb1-f41d-11e9-ae8d-bacadc8895d2 container dapi-container: <nil>
STEP: delete the pod
Oct 21 16:11:21.767: INFO: Waiting for pod downward-api-6aeacbb1-f41d-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:11:21.779: INFO: Pod downward-api-6aeacbb1-f41d-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:11:21.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7696" for this suite.
Oct 21 16:11:27.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:11:28.216: INFO: namespace downward-api-7696 deletion completed in 6.423672014s

• [SLOW TEST:8.777 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:11:28.216: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4301
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 16:11:28.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-4301'
Oct 21 16:11:28.535: INFO: stderr: ""
Oct 21 16:11:28.535: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Oct 21 16:11:33.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pod e2e-test-nginx-pod --namespace=kubectl-4301 -o json'
Oct 21 16:11:33.760: INFO: stderr: ""
Oct 21 16:11:33.760: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-10-21T16:11:28Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-4301\",\n        \"resourceVersion\": \"25309\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-4301/pods/e2e-test-nginx-pod\",\n        \"uid\": \"7033dba4-f41d-11e9-93ac-c26612c2e4bb\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-2mj6b\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.134.235.67\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-2mj6b\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-2mj6b\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-21T16:11:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-21T16:11:30Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-21T16:11:30Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-21T16:11:28Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://6d3d3957e36b1b11f151e83b46ddf12c1e3bb7ec1f3c2bc4f9ae5d635fa09a02\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-10-21T16:11:29Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.134.235.67\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.198.84\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-10-21T16:11:28Z\"\n    }\n}\n"
STEP: replace the image in the pod
Oct 21 16:11:33.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 replace -f - --namespace=kubectl-4301'
Oct 21 16:11:34.065: INFO: stderr: ""
Oct 21 16:11:34.065: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Oct 21 16:11:34.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 delete pods e2e-test-nginx-pod --namespace=kubectl-4301'
Oct 21 16:11:36.454: INFO: stderr: ""
Oct 21 16:11:36.454: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:11:36.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4301" for this suite.
Oct 21 16:11:42.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:11:42.899: INFO: namespace kubectl-4301 deletion completed in 6.420095739s

• [SLOW TEST:14.683 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:11:42.899: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6832
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-78ecbdc1-f41d-11e9-ae8d-bacadc8895d2
STEP: Creating secret with name s-test-opt-upd-78ecbe1a-f41d-11e9-ae8d-bacadc8895d2
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-78ecbdc1-f41d-11e9-ae8d-bacadc8895d2
STEP: Updating secret s-test-opt-upd-78ecbe1a-f41d-11e9-ae8d-bacadc8895d2
STEP: Creating secret with name s-test-opt-create-78ecbe38-f41d-11e9-ae8d-bacadc8895d2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:13:16.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6832" for this suite.
Oct 21 16:13:40.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:13:41.245: INFO: namespace secrets-6832 deletion completed in 24.380112654s

• [SLOW TEST:118.346 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:13:41.246: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1090
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 16:13:41.469: INFO: Creating deployment "nginx-deployment"
Oct 21 16:13:41.485: INFO: Waiting for observed generation 1
Oct 21 16:13:43.510: INFO: Waiting for all required pods to come up
Oct 21 16:13:43.521: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Oct 21 16:13:45.560: INFO: Waiting for deployment "nginx-deployment" to complete
Oct 21 16:13:45.577: INFO: Updating deployment "nginx-deployment" with a non-existent image
Oct 21 16:13:45.627: INFO: Updating deployment nginx-deployment
Oct 21 16:13:45.627: INFO: Waiting for observed generation 2
Oct 21 16:13:47.647: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct 21 16:13:47.656: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct 21 16:13:47.663: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 21 16:13:47.689: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct 21 16:13:47.689: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct 21 16:13:47.696: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 21 16:13:47.714: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Oct 21 16:13:47.714: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Oct 21 16:13:47.744: INFO: Updating deployment nginx-deployment
Oct 21 16:13:47.744: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Oct 21 16:13:47.761: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct 21 16:13:49.778: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 21 16:13:49.797: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-1090,SelfLink:/apis/apps/v1/namespaces/deployment-1090/deployments/nginx-deployment,UID:bf71b409-f41d-11e9-a1ef-46591df82ad7,ResourceVersion:26064,Generation:3,CreationTimestamp:2019-10-21 16:13:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:10,UnavailableReplicas:23,Conditions:[{Available False 2019-10-21 16:13:47 +0000 UTC 2019-10-21 16:13:47 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-10-21 16:13:49 +0000 UTC 2019-10-21 16:13:41 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-b79c9d74d" is progressing.}],ReadyReplicas:10,CollisionCount:nil,},}

Oct 21 16:13:49.806: INFO: New ReplicaSet "nginx-deployment-b79c9d74d" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d,GenerateName:,Namespace:deployment-1090,SelfLink:/apis/apps/v1/namespaces/deployment-1090/replicasets/nginx-deployment-b79c9d74d,UID:c1ec3557-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25922,Generation:3,CreationTimestamp:2019-10-21 16:13:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bf71b409-f41d-11e9-a1ef-46591df82ad7 0xc00210d607 0xc00210d608}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 16:13:49.806: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Oct 21 16:13:49.806: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5,GenerateName:,Namespace:deployment-1090,SelfLink:/apis/apps/v1/namespaces/deployment-1090/replicasets/nginx-deployment-85db8c99c5,UID:bf754667-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:26063,Generation:3,CreationTimestamp:2019-10-21 16:13:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bf71b409-f41d-11e9-a1ef-46591df82ad7 0xc00210d537 0xc00210d538}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:10,AvailableReplicas:10,Conditions:[],},}
Oct 21 16:13:49.834: INFO: Pod "nginx-deployment-85db8c99c5-56hx9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-56hx9,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-56hx9,UID:c33656a8-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25951,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc00210dfc7 0xc00210dfc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.77,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a06040} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a06060}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.77,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.835: INFO: Pod "nginx-deployment-85db8c99c5-5w685" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-5w685,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-5w685,UID:c332ab25-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25921,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a06127 0xc002a06128}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.77,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a061a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a061c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.77,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.835: INFO: Pod "nginx-deployment-85db8c99c5-bcjm5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-bcjm5,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-bcjm5,UID:c334713b-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25937,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a06287 0xc002a06288}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.77,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a06300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a06320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.77,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.835: INFO: Pod "nginx-deployment-85db8c99c5-bthvb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-bthvb,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-bthvb,UID:c3312210-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:26023,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a063e7 0xc002a063e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.77,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a06460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a06480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.77,PodIP:172.30.132.7,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:13:48 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://e3e0cd4ba4722a9fdf1d0e547464dc33d9dba968f92da807570f36e246bb8d24}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.835: INFO: Pod "nginx-deployment-85db8c99c5-g4qwt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-g4qwt,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-g4qwt,UID:c332af40-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25920,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a06557 0xc002a06558}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.67,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a065d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a065f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.67,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.835: INFO: Pod "nginx-deployment-85db8c99c5-g7p98" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-g7p98,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-g7p98,UID:bfac1a09-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25743,Generation:0,CreationTimestamp:2019-10-21 16:13:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a066b7 0xc002a066b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.67,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a06730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a06750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:41 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.67,PodIP:172.30.198.87,StartTime:2019-10-21 16:13:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:13:43 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://c435036bd9fb24c7776e40d14b92a69dcbce4e4630fd377e91f89cdd4dd36499}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.835: INFO: Pod "nginx-deployment-85db8c99c5-hxs4b" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-hxs4b,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-hxs4b,UID:bfa6ea8d-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25705,Generation:0,CreationTimestamp:2019-10-21 16:13:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a06827 0xc002a06828}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.77,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a068a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a068c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:41 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.77,PodIP:172.30.132.62,StartTime:2019-10-21 16:13:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:13:42 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://0bdb7925423870ec9159c24f7a5a18981d8baea9d8ad8af7e32d142ae2271f4c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.835: INFO: Pod "nginx-deployment-85db8c99c5-mhb7v" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-mhb7v,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-mhb7v,UID:bfa967a8-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25763,Generation:0,CreationTimestamp:2019-10-21 16:13:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a06997 0xc002a06998}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.118,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a06a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a06a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:41 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.118,PodIP:172.30.192.215,StartTime:2019-10-21 16:13:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:13:43 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://cea5f3381512968d407c2bd5522b8961630c97aa196f25c8645acc549e604db7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.835: INFO: Pod "nginx-deployment-85db8c99c5-n7rfb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-n7rfb,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-n7rfb,UID:c3364bef-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25968,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a06b07 0xc002a06b08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.118,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a06b80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a06ba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.118,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.835: INFO: Pod "nginx-deployment-85db8c99c5-nsjng" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-nsjng,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-nsjng,UID:c3364ffd-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25959,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a06c67 0xc002a06c68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.67,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a06ce0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a06d00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.67,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.835: INFO: Pod "nginx-deployment-85db8c99c5-nvsmm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-nvsmm,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-nvsmm,UID:c3364606-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25950,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a06dc7 0xc002a06dc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.67,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a06e70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a06e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.67,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.835: INFO: Pod "nginx-deployment-85db8c99c5-phth5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-phth5,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-phth5,UID:bfa3bd9d-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25746,Generation:0,CreationTimestamp:2019-10-21 16:13:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a06f57 0xc002a06f58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.67,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a06fd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a06ff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:41 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.67,PodIP:172.30.198.86,StartTime:2019-10-21 16:13:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:13:43 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://0f03779d15f67c48e791ae143d60fdeef3de3951ed5fa1ec03c0976f9166b918}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.836: INFO: Pod "nginx-deployment-85db8c99c5-qmfrj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-qmfrj,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-qmfrj,UID:bfa96bf9-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25737,Generation:0,CreationTimestamp:2019-10-21 16:13:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a070c7 0xc002a070c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.67,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a07140} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a07160}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:41 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.67,PodIP:172.30.198.88,StartTime:2019-10-21 16:13:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:13:43 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://a2af28b117c5f897a44b07455c2afbbf9a1b20d1d2be63bffaee55392f790214}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.836: INFO: Pod "nginx-deployment-85db8c99c5-rtnzj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-rtnzj,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-rtnzj,UID:c3346134-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:26061,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a07247 0xc002a07248}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.118,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a072d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a072f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.118,PodIP:172.30.192.220,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:13:49 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://94a72cf265aed5c5b9ae1e629a6b06df28df180aea8cca40b2c957ffed29e716}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.836: INFO: Pod "nginx-deployment-85db8c99c5-tlcxh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-tlcxh,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-tlcxh,UID:c33461e9-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25936,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a073d7 0xc002a073d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.118,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a07450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a07470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.118,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.836: INFO: Pod "nginx-deployment-85db8c99c5-ts92q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-ts92q,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-ts92q,UID:c336990b-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25961,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a07547 0xc002a07548}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.118,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a075f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a07610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.118,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.836: INFO: Pod "nginx-deployment-85db8c99c5-tzdzb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-tzdzb,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-tzdzb,UID:bfa965a6-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25734,Generation:0,CreationTimestamp:2019-10-21 16:13:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a076d7 0xc002a076d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.67,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a07750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a07770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:41 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.67,PodIP:172.30.198.85,StartTime:2019-10-21 16:13:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:13:43 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://bc9198365121c96dab5f4c32c6349d14738b0b577c972bd59e4a662f11915238}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.836: INFO: Pod "nginx-deployment-85db8c99c5-v448g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-v448g,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-v448g,UID:c3346262-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25940,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a07847 0xc002a07848}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.67,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a078c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a078e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.67,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.836: INFO: Pod "nginx-deployment-85db8c99c5-vdhj2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-vdhj2,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-vdhj2,UID:bfa6d4d1-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25725,Generation:0,CreationTimestamp:2019-10-21 16:13:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a079a7 0xc002a079a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.118,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a07a20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a07a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:41 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.118,PodIP:172.30.192.208,StartTime:2019-10-21 16:13:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:13:43 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://fd275bb1ece48b140bed07bf97636139152c29d447b5d65c744a9df4c011f029}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.836: INFO: Pod "nginx-deployment-85db8c99c5-xncpn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-xncpn,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-85db8c99c5-xncpn,UID:bfa95ae4-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25757,Generation:0,CreationTimestamp:2019-10-21 16:13:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 bf754667-f41d-11e9-93ac-c26612c2e4bb 0xc002a07b17 0xc002a07b18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.118,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a07b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a07bc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:41 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.118,PodIP:172.30.192.216,StartTime:2019-10-21 16:13:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:13:43 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://edf447c4f4cda3c855f5cadbc0963d8673a8bb0c97bffa4d8553260748dfe088}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.836: INFO: Pod "nginx-deployment-b79c9d74d-6md6x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-6md6x,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-b79c9d74d-6md6x,UID:c3359186-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25955,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d c1ec3557-f41d-11e9-93ac-c26612c2e4bb 0xc002a07c97 0xc002a07c98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.118,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a07d10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a07d30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.118,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.836: INFO: Pod "nginx-deployment-b79c9d74d-8474g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-8474g,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-b79c9d74d-8474g,UID:c3379a8f-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25965,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d c1ec3557-f41d-11e9-93ac-c26612c2e4bb 0xc002a07e00 0xc002a07e01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.67,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a07e80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a07ea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.67,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.837: INFO: Pod "nginx-deployment-b79c9d74d-bwzlb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-bwzlb,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-b79c9d74d-bwzlb,UID:c3322f6e-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25909,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d c1ec3557-f41d-11e9-93ac-c26612c2e4bb 0xc002a07f70 0xc002a07f71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.118,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a07ff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002342010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.118,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.837: INFO: Pod "nginx-deployment-b79c9d74d-cfqws" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-cfqws,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-b79c9d74d-cfqws,UID:c3359a24-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25943,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d c1ec3557-f41d-11e9-93ac-c26612c2e4bb 0xc0023420e0 0xc0023420e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.118,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002342160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002342180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.118,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.837: INFO: Pod "nginx-deployment-b79c9d74d-dgc4c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-dgc4c,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-b79c9d74d-dgc4c,UID:c3357780-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25944,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d c1ec3557-f41d-11e9-93ac-c26612c2e4bb 0xc002342270 0xc002342271}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.77,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002342300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002342320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.77,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.837: INFO: Pod "nginx-deployment-b79c9d74d-dxwbg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-dxwbg,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-b79c9d74d-dxwbg,UID:c1ee1a3c-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25990,Generation:0,CreationTimestamp:2019-10-21 16:13:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d c1ec3557-f41d-11e9-93ac-c26612c2e4bb 0xc0023423f0 0xc0023423f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.118,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002342470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002342490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.118,PodIP:172.30.192.218,StartTime:2019-10-21 16:13:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.837: INFO: Pod "nginx-deployment-b79c9d74d-hmbqz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-hmbqz,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-b79c9d74d-hmbqz,UID:c33424b3-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25931,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d c1ec3557-f41d-11e9-93ac-c26612c2e4bb 0xc0023425c0 0xc0023425c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.77,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002342640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002342660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.77,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.837: INFO: Pod "nginx-deployment-b79c9d74d-qk98l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-qk98l,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-b79c9d74d-qk98l,UID:c3359faf-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25958,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d c1ec3557-f41d-11e9-93ac-c26612c2e4bb 0xc002342730 0xc002342731}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.77,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023427b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023427d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.77,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.837: INFO: Pod "nginx-deployment-b79c9d74d-rvt9w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-rvt9w,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-b79c9d74d-rvt9w,UID:c1faf5ad-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25994,Generation:0,CreationTimestamp:2019-10-21 16:13:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d c1ec3557-f41d-11e9-93ac-c26612c2e4bb 0xc0023428a0 0xc0023428a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.67,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002342930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002342950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.67,PodIP:172.30.198.90,StartTime:2019-10-21 16:13:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.838: INFO: Pod "nginx-deployment-b79c9d74d-tqmfw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-tqmfw,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-b79c9d74d-tqmfw,UID:c1f957bb-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25987,Generation:0,CreationTimestamp:2019-10-21 16:13:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d c1ec3557-f41d-11e9-93ac-c26612c2e4bb 0xc002342a40 0xc002342a41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.118,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002342ac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002342ae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.118,PodIP:172.30.192.213,StartTime:2019-10-21 16:13:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.838: INFO: Pod "nginx-deployment-b79c9d74d-vzkdl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-vzkdl,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-b79c9d74d-vzkdl,UID:c1efb93e-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25982,Generation:0,CreationTimestamp:2019-10-21 16:13:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d c1ec3557-f41d-11e9-93ac-c26612c2e4bb 0xc002342bd0 0xc002342bd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.77,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002342c50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002342c70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.77,PodIP:172.30.132.63,StartTime:2019-10-21 16:13:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.838: INFO: Pod "nginx-deployment-b79c9d74d-xnnp5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-xnnp5,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-b79c9d74d-xnnp5,UID:c1ef9dc1-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25858,Generation:0,CreationTimestamp:2019-10-21 16:13:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d c1ec3557-f41d-11e9-93ac-c26612c2e4bb 0xc002342d60 0xc002342d61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.67,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002342de0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002342e00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:45 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.67,PodIP:172.30.198.89,StartTime:2019-10-21 16:13:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:13:49.838: INFO: Pod "nginx-deployment-b79c9d74d-zwcs7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-zwcs7,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-1090,SelfLink:/api/v1/namespaces/deployment-1090/pods/nginx-deployment-b79c9d74d-zwcs7,UID:c334099a-f41d-11e9-93ac-c26612c2e4bb,ResourceVersion:25932,Generation:0,CreationTimestamp:2019-10-21 16:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d c1ec3557-f41d-11e9-93ac-c26612c2e4bb 0xc002342ef0 0xc002342ef1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mwhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mwhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8mwhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.67,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002342f70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002342f90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:13:47 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.67,PodIP:,StartTime:2019-10-21 16:13:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:13:49.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1090" for this suite.
Oct 21 16:14:00.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:14:00.552: INFO: namespace deployment-1090 deletion completed in 10.691025898s

• [SLOW TEST:19.306 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:14:00.552: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5814
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 21 16:14:00.877: INFO: Number of nodes with available pods: 0
Oct 21 16:14:00.877: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 16:14:01.902: INFO: Number of nodes with available pods: 0
Oct 21 16:14:01.902: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 16:14:02.900: INFO: Number of nodes with available pods: 3
Oct 21 16:14:02.900: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Oct 21 16:14:02.958: INFO: Number of nodes with available pods: 2
Oct 21 16:14:02.958: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 16:14:03.996: INFO: Number of nodes with available pods: 2
Oct 21 16:14:03.996: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 16:14:04.981: INFO: Number of nodes with available pods: 3
Oct 21 16:14:04.982: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5814, will wait for the garbage collector to delete the pods
Oct 21 16:14:05.091: INFO: Deleting DaemonSet.extensions daemon-set took: 27.37357ms
Oct 21 16:14:05.292: INFO: Terminating DaemonSet.extensions daemon-set pods took: 201.095774ms
Oct 21 16:14:18.405: INFO: Number of nodes with available pods: 0
Oct 21 16:14:18.405: INFO: Number of running nodes: 0, number of available pods: 0
Oct 21 16:14:18.412: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5814/daemonsets","resourceVersion":"26693"},"items":null}

Oct 21 16:14:18.423: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5814/pods","resourceVersion":"26693"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:14:18.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5814" for this suite.
Oct 21 16:14:26.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:14:26.880: INFO: namespace daemonsets-5814 deletion completed in 8.382856052s

• [SLOW TEST:26.329 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:14:26.881: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1862
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1862
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Oct 21 16:14:27.126: INFO: Found 0 stateful pods, waiting for 3
Oct 21 16:14:37.136: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:14:37.136: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:14:37.136: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 21 16:14:37.192: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Oct 21 16:14:47.279: INFO: Updating stateful set ss2
Oct 21 16:14:47.300: INFO: Waiting for Pod statefulset-1862/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Oct 21 16:14:57.742: INFO: Found 2 stateful pods, waiting for 3
Oct 21 16:15:07.753: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:15:07.753: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:15:07.753: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Oct 21 16:15:07.802: INFO: Updating stateful set ss2
Oct 21 16:15:07.823: INFO: Waiting for Pod statefulset-1862/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 21 16:15:17.850: INFO: Waiting for Pod statefulset-1862/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 21 16:15:27.872: INFO: Updating stateful set ss2
Oct 21 16:15:27.893: INFO: Waiting for StatefulSet statefulset-1862/ss2 to complete update
Oct 21 16:15:27.893: INFO: Waiting for Pod statefulset-1862/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 21 16:15:37.915: INFO: Deleting all statefulset in ns statefulset-1862
Oct 21 16:15:37.922: INFO: Scaling statefulset ss2 to 0
Oct 21 16:16:17.959: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 16:16:17.969: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:16:18.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1862" for this suite.
Oct 21 16:16:26.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:16:26.429: INFO: namespace statefulset-1862 deletion completed in 8.394138012s

• [SLOW TEST:119.548 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:16:26.430: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-4766
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Oct 21 16:16:27.511: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Oct 21 16:16:29.627: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271387, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271387, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271387, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271387, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 16:16:31.638: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271387, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271387, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271387, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271387, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 16:16:33.637: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271387, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271387, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271387, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271387, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 16:16:35.638: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271387, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271387, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271387, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271387, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 16:16:38.933: INFO: Waited 1.283150362s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:16:39.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4766" for this suite.
Oct 21 16:16:45.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:16:45.835: INFO: namespace aggregator-4766 deletion completed in 6.367650657s

• [SLOW TEST:19.405 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:16:45.836: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2399
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Oct 21 16:16:46.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 create -f - --namespace=kubectl-2399'
Oct 21 16:16:46.410: INFO: stderr: ""
Oct 21 16:16:46.410: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 16:16:46.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2399'
Oct 21 16:16:46.520: INFO: stderr: ""
Oct 21 16:16:46.520: INFO: stdout: "update-demo-nautilus-6bl2v update-demo-nautilus-bc4h8 "
Oct 21 16:16:46.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-6bl2v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2399'
Oct 21 16:16:46.636: INFO: stderr: ""
Oct 21 16:16:46.637: INFO: stdout: ""
Oct 21 16:16:46.637: INFO: update-demo-nautilus-6bl2v is created but not running
Oct 21 16:16:51.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2399'
Oct 21 16:16:51.743: INFO: stderr: ""
Oct 21 16:16:51.743: INFO: stdout: "update-demo-nautilus-6bl2v update-demo-nautilus-bc4h8 "
Oct 21 16:16:51.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-6bl2v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2399'
Oct 21 16:16:51.836: INFO: stderr: ""
Oct 21 16:16:51.836: INFO: stdout: "true"
Oct 21 16:16:51.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-6bl2v -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2399'
Oct 21 16:16:51.924: INFO: stderr: ""
Oct 21 16:16:51.924: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:16:51.924: INFO: validating pod update-demo-nautilus-6bl2v
Oct 21 16:16:51.945: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:16:51.945: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:16:51.945: INFO: update-demo-nautilus-6bl2v is verified up and running
Oct 21 16:16:51.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-bc4h8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2399'
Oct 21 16:16:52.040: INFO: stderr: ""
Oct 21 16:16:52.040: INFO: stdout: "true"
Oct 21 16:16:52.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-bc4h8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2399'
Oct 21 16:16:52.147: INFO: stderr: ""
Oct 21 16:16:52.147: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:16:52.147: INFO: validating pod update-demo-nautilus-bc4h8
Oct 21 16:16:52.164: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:16:52.164: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:16:52.164: INFO: update-demo-nautilus-bc4h8 is verified up and running
STEP: using delete to clean up resources
Oct 21 16:16:52.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 delete --grace-period=0 --force -f - --namespace=kubectl-2399'
Oct 21 16:16:52.282: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 16:16:52.282: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 21 16:16:52.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2399'
Oct 21 16:16:52.398: INFO: stderr: "No resources found.\n"
Oct 21 16:16:52.399: INFO: stdout: ""
Oct 21 16:16:52.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -l name=update-demo --namespace=kubectl-2399 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 21 16:16:52.521: INFO: stderr: ""
Oct 21 16:16:52.521: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:16:52.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2399" for this suite.
Oct 21 16:17:16.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:17:16.924: INFO: namespace kubectl-2399 deletion completed in 24.391854422s

• [SLOW TEST:31.088 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:17:16.925: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7171
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 21 16:17:23.300: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:17:23.311: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:17:25.311: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:17:25.321: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:17:27.311: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:17:27.320: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:17:29.311: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:17:29.323: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:17:31.311: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:17:31.321: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:17:33.311: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:17:33.321: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:17:35.311: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:17:35.320: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:17:37.311: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:17:37.327: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:17:39.311: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:17:39.323: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:17:41.311: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:17:41.327: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:17:43.311: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:17:43.324: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:17:45.311: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:17:45.323: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:17:47.311: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:17:47.320: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:17:49.311: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:17:49.321: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:17:51.311: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:17:51.319: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:17:51.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7171" for this suite.
Oct 21 16:18:15.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:18:15.723: INFO: namespace container-lifecycle-hook-7171 deletion completed in 24.392496802s

• [SLOW TEST:58.798 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:18:15.723: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6441
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-630a1cb4-f41e-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume configMaps
Oct 21 16:18:15.960: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-630bb8bc-f41e-11e9-ae8d-bacadc8895d2" in namespace "projected-6441" to be "success or failure"
Oct 21 16:18:15.970: INFO: Pod "pod-projected-configmaps-630bb8bc-f41e-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.569053ms
Oct 21 16:18:17.980: INFO: Pod "pod-projected-configmaps-630bb8bc-f41e-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020303505s
Oct 21 16:18:19.992: INFO: Pod "pod-projected-configmaps-630bb8bc-f41e-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03223832s
STEP: Saw pod success
Oct 21 16:18:19.992: INFO: Pod "pod-projected-configmaps-630bb8bc-f41e-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:18:20.001: INFO: Trying to get logs from node 10.134.235.67 pod pod-projected-configmaps-630bb8bc-f41e-11e9-ae8d-bacadc8895d2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:18:20.054: INFO: Waiting for pod pod-projected-configmaps-630bb8bc-f41e-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:18:20.068: INFO: Pod pod-projected-configmaps-630bb8bc-f41e-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:18:20.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6441" for this suite.
Oct 21 16:18:26.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:18:26.483: INFO: namespace projected-6441 deletion completed in 6.400541801s

• [SLOW TEST:10.760 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:18:26.485: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2491
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-2491
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 21 16:18:26.696: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 21 16:18:51.103: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.192.236:8080/dial?request=hostName&protocol=udp&host=172.30.198.104&port=8081&tries=1'] Namespace:pod-network-test-2491 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:18:51.103: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 16:18:51.318: INFO: Waiting for endpoints: map[]
Oct 21 16:18:51.328: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.192.236:8080/dial?request=hostName&protocol=udp&host=172.30.132.19&port=8081&tries=1'] Namespace:pod-network-test-2491 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:18:51.328: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 16:18:51.537: INFO: Waiting for endpoints: map[]
Oct 21 16:18:51.546: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.192.236:8080/dial?request=hostName&protocol=udp&host=172.30.192.235&port=8081&tries=1'] Namespace:pod-network-test-2491 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:18:51.546: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 16:18:51.782: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:18:51.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2491" for this suite.
Oct 21 16:19:05.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:19:06.229: INFO: namespace pod-network-test-2491 deletion completed in 14.434993194s

• [SLOW TEST:39.744 seconds]
[sig-network] Networking
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:19:06.229: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8719
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 16:19:06.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 create -f - --namespace=kubectl-8719'
Oct 21 16:19:06.642: INFO: stderr: ""
Oct 21 16:19:06.642: INFO: stdout: "replicationcontroller/redis-master created\n"
Oct 21 16:19:06.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 create -f - --namespace=kubectl-8719'
Oct 21 16:19:06.848: INFO: stderr: ""
Oct 21 16:19:06.848: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 21 16:19:07.857: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:19:07.857: INFO: Found 0 / 1
Oct 21 16:19:08.857: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:19:08.857: INFO: Found 0 / 1
Oct 21 16:19:09.858: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:19:09.858: INFO: Found 0 / 1
Oct 21 16:19:10.859: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:19:10.859: INFO: Found 1 / 1
Oct 21 16:19:10.859: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 21 16:19:10.867: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:19:10.867: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 21 16:19:10.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 describe pod redis-master-kj427 --namespace=kubectl-8719'
Oct 21 16:19:10.991: INFO: stderr: ""
Oct 21 16:19:10.991: INFO: stdout: "Name:               redis-master-kj427\nNamespace:          kubectl-8719\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.134.235.118/10.134.235.118\nStart Time:         Mon, 21 Oct 2019 16:19:06 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 172.30.192.237\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://a867a7622e660d6cf84f88fc44389583c39c8e60fdd08e0cd2d6c5ea2148a895\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 21 Oct 2019 16:19:09 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9kn98 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-9kn98:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-9kn98\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 600s\n                 node.kubernetes.io/unreachable:NoExecute for 600s\nEvents:\n  Type    Reason     Age   From                     Message\n  ----    ------     ----  ----                     -------\n  Normal  Scheduled  4s    default-scheduler        Successfully assigned kubectl-8719/redis-master-kj427 to 10.134.235.118\n  Normal  Pulling    3s    kubelet, 10.134.235.118  Pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     1s    kubelet, 10.134.235.118  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    1s    kubelet, 10.134.235.118  Created container redis-master\n  Normal  Started    1s    kubelet, 10.134.235.118  Started container redis-master\n"
Oct 21 16:19:10.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 describe rc redis-master --namespace=kubectl-8719'
Oct 21 16:19:11.147: INFO: stderr: ""
Oct 21 16:19:11.148: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-8719\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  5s    replication-controller  Created pod: redis-master-kj427\n"
Oct 21 16:19:11.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 describe service redis-master --namespace=kubectl-8719'
Oct 21 16:19:11.273: INFO: stderr: ""
Oct 21 16:19:11.273: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-8719\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.10.229\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.192.237:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct 21 16:19:11.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 describe node 10.134.235.118'
Oct 21 16:19:11.468: INFO: stderr: ""
Oct 21 16:19:11.468: INFO: stdout: "Name:               10.134.235.118\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-de\n                    failure-domain.beta.kubernetes.io/zone=fra02\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=169.50.53.168\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.134.235.118\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=eu-de\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-bmmrhnff04rpad188da0-kubee2epvgh-default-00000352\n                    ibm-cloud.kubernetes.io/worker-pool-id=bmmrhnff04rpad188da0-264d456\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.14.7_1535\n                    ibm-cloud.kubernetes.io/zone=fra02\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.134.235.118\n                    kubernetes.io/os=linux\n                    privateVLAN=1739935\n                    publicVLAN=1739933\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 21 Oct 2019 14:16:32 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 21 Oct 2019 16:18:32 +0000   Mon, 21 Oct 2019 14:16:32 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 21 Oct 2019 16:18:32 +0000   Mon, 21 Oct 2019 14:16:32 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 21 Oct 2019 16:18:32 +0000   Mon, 21 Oct 2019 14:16:32 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 21 Oct 2019 16:18:32 +0000   Mon, 21 Oct 2019 14:16:42 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.134.235.118\n  ExternalIP:  169.50.53.168\n  Hostname:    10.134.235.118\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419960Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627512Ki\n pods:               110\nSystem Info:\n Machine ID:                 4ea5befb26ae4c0f9d5917e3763724e5\n System UUID:                8174885F-2965-8D4D-2D77-DA380D764EFE\n Boot ID:                    af4a84be-3021-4858-8df4-29dede325986\n Kernel Version:             4.15.0-65-generic\n OS Image:                   Ubuntu 18.04.3 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.10\n Kubelet Version:            v1.14.7+IKS\n Kube-Proxy Version:         v1.14.7+IKS\nProviderID:                  ibm://cc7530878c499d74ad77f31c918c626e///bmmrhnff04rpad188da0/kube-bmmrhnff04rpad188da0-kubee2epvgh-default-00000352\nNon-terminated Pods:         (11 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  default                    test-k8s-e2e-pvg-master-verification                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         120m\n  ibm-system                 ibm-cloud-provider-ip-169-50-36-162-5fffc56797-4s4bl       5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         111m\n  kube-system                calico-node-xczq8                                          250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         122m\n  kube-system                coredns-9dd7747c7-cgj4m                                    100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     103m\n  kube-system                ibm-keepalived-watcher-s768g                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         122m\n  kube-system                ibm-kube-fluentd-5gkfc                                     25m (0%)      300m (7%)   150Mi (1%)       800M (5%)      122m\n  kube-system                ibm-master-proxy-static-10.134.235.118                     25m (0%)      300m (7%)   32M (0%)         512M (3%)      122m\n  kube-system                vpn-7754bb6d4-2n6w7                                        5m (0%)       0 (0%)      5Mi (0%)         0 (0%)         103m\n  kubectl-8719               redis-master-kj427                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         5s\n  sonobuoy                   sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         31m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-aae6d13d2b504a80-z8lvd    0 (0%)        0 (0%)      0 (0%)           0 (0%)         31m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                415m (10%)     600m (15%)\n  memory             364050Ki (2%)  1690850Ki (12%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
Oct 21 16:19:11.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 describe namespace kubectl-8719'
Oct 21 16:19:11.626: INFO: stderr: ""
Oct 21 16:19:11.626: INFO: stdout: "Name:         kubectl-8719\nLabels:       e2e-framework=kubectl\n              e2e-run=3984d8a7-f41a-11e9-ae8d-bacadc8895d2\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:19:11.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8719" for this suite.
Oct 21 16:19:35.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:19:35.988: INFO: namespace kubectl-8719 deletion completed in 24.345088862s

• [SLOW TEST:29.759 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:19:35.988: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2589
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 21 16:19:36.222: INFO: Waiting up to 5m0s for pod "pod-92e2e08b-f41e-11e9-ae8d-bacadc8895d2" in namespace "emptydir-2589" to be "success or failure"
Oct 21 16:19:36.238: INFO: Pod "pod-92e2e08b-f41e-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 16.441677ms
Oct 21 16:19:38.247: INFO: Pod "pod-92e2e08b-f41e-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025209663s
STEP: Saw pod success
Oct 21 16:19:38.247: INFO: Pod "pod-92e2e08b-f41e-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:19:38.258: INFO: Trying to get logs from node 10.134.235.67 pod pod-92e2e08b-f41e-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 16:19:38.392: INFO: Waiting for pod pod-92e2e08b-f41e-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:19:38.402: INFO: Pod pod-92e2e08b-f41e-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:19:38.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2589" for this suite.
Oct 21 16:19:44.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:19:44.759: INFO: namespace emptydir-2589 deletion completed in 6.344228543s

• [SLOW TEST:8.771 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:19:44.759: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3680
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-981d0166-f41e-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume secrets
Oct 21 16:19:45.002: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-981e917d-f41e-11e9-ae8d-bacadc8895d2" in namespace "projected-3680" to be "success or failure"
Oct 21 16:19:45.013: INFO: Pod "pod-projected-secrets-981e917d-f41e-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.552887ms
Oct 21 16:19:47.022: INFO: Pod "pod-projected-secrets-981e917d-f41e-11e9-ae8d-bacadc8895d2": Phase="Running", Reason="", readiness=true. Elapsed: 2.019868314s
Oct 21 16:19:49.032: INFO: Pod "pod-projected-secrets-981e917d-f41e-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029503095s
STEP: Saw pod success
Oct 21 16:19:49.032: INFO: Pod "pod-projected-secrets-981e917d-f41e-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:19:49.040: INFO: Trying to get logs from node 10.134.235.118 pod pod-projected-secrets-981e917d-f41e-11e9-ae8d-bacadc8895d2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 21 16:19:49.101: INFO: Waiting for pod pod-projected-secrets-981e917d-f41e-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:19:49.109: INFO: Pod pod-projected-secrets-981e917d-f41e-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:19:49.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3680" for this suite.
Oct 21 16:19:55.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:19:55.508: INFO: namespace projected-3680 deletion completed in 6.387636825s

• [SLOW TEST:10.748 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:19:55.508: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-909
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-9e84a0df-f41e-11e9-ae8d-bacadc8895d2
STEP: Creating secret with name s-test-opt-upd-9e84a127-f41e-11e9-ae8d-bacadc8895d2
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-9e84a0df-f41e-11e9-ae8d-bacadc8895d2
STEP: Updating secret s-test-opt-upd-9e84a127-f41e-11e9-ae8d-bacadc8895d2
STEP: Creating secret with name s-test-opt-create-9e84a14a-f41e-11e9-ae8d-bacadc8895d2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:21:22.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-909" for this suite.
Oct 21 16:21:46.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:21:46.575: INFO: namespace projected-909 deletion completed in 24.374224666s

• [SLOW TEST:111.067 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:21:46.576: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3709
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-e0b90782-f41e-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume secrets
Oct 21 16:21:46.833: INFO: Waiting up to 5m0s for pod "pod-secrets-e0bbbc23-f41e-11e9-ae8d-bacadc8895d2" in namespace "secrets-3709" to be "success or failure"
Oct 21 16:21:46.846: INFO: Pod "pod-secrets-e0bbbc23-f41e-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.991613ms
Oct 21 16:21:48.855: INFO: Pod "pod-secrets-e0bbbc23-f41e-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021374508s
STEP: Saw pod success
Oct 21 16:21:48.855: INFO: Pod "pod-secrets-e0bbbc23-f41e-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:21:48.863: INFO: Trying to get logs from node 10.134.235.118 pod pod-secrets-e0bbbc23-f41e-11e9-ae8d-bacadc8895d2 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 16:21:48.911: INFO: Waiting for pod pod-secrets-e0bbbc23-f41e-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:21:48.918: INFO: Pod pod-secrets-e0bbbc23-f41e-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:21:48.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3709" for this suite.
Oct 21 16:21:54.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:21:55.583: INFO: namespace secrets-3709 deletion completed in 6.653837758s

• [SLOW TEST:9.007 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:21:55.584: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7727
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Oct 21 16:21:55.823: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:22:08.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7727" for this suite.
Oct 21 16:22:14.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:22:14.944: INFO: namespace pods-7727 deletion completed in 6.531293908s

• [SLOW TEST:19.360 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:22:14.944: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7237
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Oct 21 16:22:17.735: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7237 pod-service-account-f1f2910b-f41e-11e9-ae8d-bacadc8895d2 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Oct 21 16:22:18.085: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7237 pod-service-account-f1f2910b-f41e-11e9-ae8d-bacadc8895d2 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Oct 21 16:22:18.427: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7237 pod-service-account-f1f2910b-f41e-11e9-ae8d-bacadc8895d2 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:22:18.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7237" for this suite.
Oct 21 16:22:24.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:22:25.324: INFO: namespace svcaccounts-7237 deletion completed in 6.513827051s

• [SLOW TEST:10.380 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:22:25.324: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3697
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-f7e3eb33-f41e-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume secrets
Oct 21 16:22:25.694: INFO: Waiting up to 5m0s for pod "pod-secrets-f7e5c4b0-f41e-11e9-ae8d-bacadc8895d2" in namespace "secrets-3697" to be "success or failure"
Oct 21 16:22:25.705: INFO: Pod "pod-secrets-f7e5c4b0-f41e-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.021128ms
Oct 21 16:22:27.714: INFO: Pod "pod-secrets-f7e5c4b0-f41e-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020446513s
STEP: Saw pod success
Oct 21 16:22:27.714: INFO: Pod "pod-secrets-f7e5c4b0-f41e-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:22:27.723: INFO: Trying to get logs from node 10.134.235.67 pod pod-secrets-f7e5c4b0-f41e-11e9-ae8d-bacadc8895d2 container secret-env-test: <nil>
STEP: delete the pod
Oct 21 16:22:27.785: INFO: Waiting for pod pod-secrets-f7e5c4b0-f41e-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:22:27.793: INFO: Pod pod-secrets-f7e5c4b0-f41e-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:22:27.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3697" for this suite.
Oct 21 16:22:33.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:22:34.469: INFO: namespace secrets-3697 deletion completed in 6.658518489s

• [SLOW TEST:9.145 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:22:34.470: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3906
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-fd44f94a-f41e-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume secrets
Oct 21 16:22:34.726: INFO: Waiting up to 5m0s for pod "pod-secrets-fd474ede-f41e-11e9-ae8d-bacadc8895d2" in namespace "secrets-3906" to be "success or failure"
Oct 21 16:22:34.740: INFO: Pod "pod-secrets-fd474ede-f41e-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 14.668538ms
Oct 21 16:22:36.751: INFO: Pod "pod-secrets-fd474ede-f41e-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025117745s
STEP: Saw pod success
Oct 21 16:22:36.751: INFO: Pod "pod-secrets-fd474ede-f41e-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:22:36.760: INFO: Trying to get logs from node 10.134.235.118 pod pod-secrets-fd474ede-f41e-11e9-ae8d-bacadc8895d2 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 16:22:36.812: INFO: Waiting for pod pod-secrets-fd474ede-f41e-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:22:36.821: INFO: Pod pod-secrets-fd474ede-f41e-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:22:36.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3906" for this suite.
Oct 21 16:22:42.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:22:43.227: INFO: namespace secrets-3906 deletion completed in 6.393324391s

• [SLOW TEST:8.757 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:22:43.227: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9354
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-9354/configmap-test-02e1594a-f41f-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume configMaps
Oct 21 16:22:44.137: INFO: Waiting up to 5m0s for pod "pod-configmaps-02e36feb-f41f-11e9-ae8d-bacadc8895d2" in namespace "configmap-9354" to be "success or failure"
Oct 21 16:22:44.149: INFO: Pod "pod-configmaps-02e36feb-f41f-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.21437ms
Oct 21 16:22:46.158: INFO: Pod "pod-configmaps-02e36feb-f41f-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021017968s
STEP: Saw pod success
Oct 21 16:22:46.158: INFO: Pod "pod-configmaps-02e36feb-f41f-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:22:46.168: INFO: Trying to get logs from node 10.134.235.67 pod pod-configmaps-02e36feb-f41f-11e9-ae8d-bacadc8895d2 container env-test: <nil>
STEP: delete the pod
Oct 21 16:22:46.231: INFO: Waiting for pod pod-configmaps-02e36feb-f41f-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:22:46.238: INFO: Pod pod-configmaps-02e36feb-f41f-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:22:46.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9354" for this suite.
Oct 21 16:22:52.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:22:52.681: INFO: namespace configmap-9354 deletion completed in 6.428063917s

• [SLOW TEST:9.454 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:22:52.682: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7139
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:22:52.922: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0820ad24-f41f-11e9-ae8d-bacadc8895d2" in namespace "projected-7139" to be "success or failure"
Oct 21 16:22:52.937: INFO: Pod "downwardapi-volume-0820ad24-f41f-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 15.275914ms
Oct 21 16:22:54.946: INFO: Pod "downwardapi-volume-0820ad24-f41f-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024393012s
STEP: Saw pod success
Oct 21 16:22:54.946: INFO: Pod "downwardapi-volume-0820ad24-f41f-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:22:54.955: INFO: Trying to get logs from node 10.134.235.118 pod downwardapi-volume-0820ad24-f41f-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 16:22:55.007: INFO: Waiting for pod downwardapi-volume-0820ad24-f41f-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:22:55.017: INFO: Pod downwardapi-volume-0820ad24-f41f-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:22:55.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7139" for this suite.
Oct 21 16:23:01.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:23:01.469: INFO: namespace projected-7139 deletion completed in 6.440963598s

• [SLOW TEST:8.787 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:23:01.469: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-0d5c5b57-f41f-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume secrets
Oct 21 16:23:01.714: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0d5e2ba8-f41f-11e9-ae8d-bacadc8895d2" in namespace "projected-1864" to be "success or failure"
Oct 21 16:23:01.725: INFO: Pod "pod-projected-secrets-0d5e2ba8-f41f-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.192028ms
Oct 21 16:23:03.738: INFO: Pod "pod-projected-secrets-0d5e2ba8-f41f-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024365965s
STEP: Saw pod success
Oct 21 16:23:03.738: INFO: Pod "pod-projected-secrets-0d5e2ba8-f41f-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:23:03.749: INFO: Trying to get logs from node 10.134.235.67 pod pod-projected-secrets-0d5e2ba8-f41f-11e9-ae8d-bacadc8895d2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 21 16:23:03.810: INFO: Waiting for pod pod-projected-secrets-0d5e2ba8-f41f-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:23:03.834: INFO: Pod pod-projected-secrets-0d5e2ba8-f41f-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:23:03.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1864" for this suite.
Oct 21 16:23:09.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:23:10.227: INFO: namespace projected-1864 deletion completed in 6.380097861s

• [SLOW TEST:8.758 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:23:10.227: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2264
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Oct 21 16:23:10.477: INFO: Waiting up to 5m0s for pod "var-expansion-1296f711-f41f-11e9-ae8d-bacadc8895d2" in namespace "var-expansion-2264" to be "success or failure"
Oct 21 16:23:10.487: INFO: Pod "var-expansion-1296f711-f41f-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.329439ms
Oct 21 16:23:12.496: INFO: Pod "var-expansion-1296f711-f41f-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01986091s
Oct 21 16:23:14.511: INFO: Pod "var-expansion-1296f711-f41f-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033894805s
STEP: Saw pod success
Oct 21 16:23:14.511: INFO: Pod "var-expansion-1296f711-f41f-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:23:14.522: INFO: Trying to get logs from node 10.134.235.118 pod var-expansion-1296f711-f41f-11e9-ae8d-bacadc8895d2 container dapi-container: <nil>
STEP: delete the pod
Oct 21 16:23:14.578: INFO: Waiting for pod var-expansion-1296f711-f41f-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:23:14.586: INFO: Pod var-expansion-1296f711-f41f-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:23:14.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2264" for this suite.
Oct 21 16:23:20.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:23:21.004: INFO: namespace var-expansion-2264 deletion completed in 6.406608888s

• [SLOW TEST:10.777 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:23:21.005: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9610
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-1900f8f7-f41f-11e9-ae8d-bacadc8895d2
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:23:25.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9610" for this suite.
Oct 21 16:23:49.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:23:49.760: INFO: namespace configmap-9610 deletion completed in 24.41388881s

• [SLOW TEST:28.755 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:23:49.760: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3983
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-2a252866-f41f-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume configMaps
Oct 21 16:23:50.003: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2a26c084-f41f-11e9-ae8d-bacadc8895d2" in namespace "projected-3983" to be "success or failure"
Oct 21 16:23:50.014: INFO: Pod "pod-projected-configmaps-2a26c084-f41f-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.495401ms
Oct 21 16:23:52.023: INFO: Pod "pod-projected-configmaps-2a26c084-f41f-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019728597s
STEP: Saw pod success
Oct 21 16:23:52.023: INFO: Pod "pod-projected-configmaps-2a26c084-f41f-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:23:52.033: INFO: Trying to get logs from node 10.134.235.118 pod pod-projected-configmaps-2a26c084-f41f-11e9-ae8d-bacadc8895d2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:23:52.082: INFO: Waiting for pod pod-projected-configmaps-2a26c084-f41f-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:23:52.090: INFO: Pod pod-projected-configmaps-2a26c084-f41f-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:23:52.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3983" for this suite.
Oct 21 16:23:58.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:23:58.459: INFO: namespace projected-3983 deletion completed in 6.354730175s

• [SLOW TEST:8.698 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:23:58.459: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2139
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-s556
STEP: Creating a pod to test atomic-volume-subpath
Oct 21 16:23:58.707: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-s556" in namespace "subpath-2139" to be "success or failure"
Oct 21 16:23:58.715: INFO: Pod "pod-subpath-test-configmap-s556": Phase="Pending", Reason="", readiness=false. Elapsed: 7.97887ms
Oct 21 16:24:00.726: INFO: Pod "pod-subpath-test-configmap-s556": Phase="Running", Reason="", readiness=true. Elapsed: 2.019137577s
Oct 21 16:24:02.738: INFO: Pod "pod-subpath-test-configmap-s556": Phase="Running", Reason="", readiness=true. Elapsed: 4.030945097s
Oct 21 16:24:05.438: INFO: Pod "pod-subpath-test-configmap-s556": Phase="Running", Reason="", readiness=true. Elapsed: 6.731577132s
Oct 21 16:24:07.450: INFO: Pod "pod-subpath-test-configmap-s556": Phase="Running", Reason="", readiness=true. Elapsed: 8.743453419s
Oct 21 16:24:09.461: INFO: Pod "pod-subpath-test-configmap-s556": Phase="Running", Reason="", readiness=true. Elapsed: 10.754171101s
Oct 21 16:24:11.470: INFO: Pod "pod-subpath-test-configmap-s556": Phase="Running", Reason="", readiness=true. Elapsed: 12.763276768s
Oct 21 16:24:13.482: INFO: Pod "pod-subpath-test-configmap-s556": Phase="Running", Reason="", readiness=true. Elapsed: 14.775219693s
Oct 21 16:24:15.494: INFO: Pod "pod-subpath-test-configmap-s556": Phase="Running", Reason="", readiness=true. Elapsed: 16.787175673s
Oct 21 16:24:17.505: INFO: Pod "pod-subpath-test-configmap-s556": Phase="Running", Reason="", readiness=true. Elapsed: 18.797858154s
Oct 21 16:24:19.515: INFO: Pod "pod-subpath-test-configmap-s556": Phase="Running", Reason="", readiness=true. Elapsed: 20.807877047s
Oct 21 16:24:21.525: INFO: Pod "pod-subpath-test-configmap-s556": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.817751137s
STEP: Saw pod success
Oct 21 16:24:21.525: INFO: Pod "pod-subpath-test-configmap-s556" satisfied condition "success or failure"
Oct 21 16:24:21.537: INFO: Trying to get logs from node 10.134.235.67 pod pod-subpath-test-configmap-s556 container test-container-subpath-configmap-s556: <nil>
STEP: delete the pod
Oct 21 16:24:21.615: INFO: Waiting for pod pod-subpath-test-configmap-s556 to disappear
Oct 21 16:24:21.625: INFO: Pod pod-subpath-test-configmap-s556 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-s556
Oct 21 16:24:21.625: INFO: Deleting pod "pod-subpath-test-configmap-s556" in namespace "subpath-2139"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:24:21.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2139" for this suite.
Oct 21 16:24:27.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:24:28.057: INFO: namespace subpath-2139 deletion completed in 6.40256475s

• [SLOW TEST:29.598 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:24:28.057: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4383
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-40f8c8bf-f41f-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume configMaps
Oct 21 16:24:28.300: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-40fa7a51-f41f-11e9-ae8d-bacadc8895d2" in namespace "projected-4383" to be "success or failure"
Oct 21 16:24:28.320: INFO: Pod "pod-projected-configmaps-40fa7a51-f41f-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 19.78638ms
Oct 21 16:24:30.330: INFO: Pod "pod-projected-configmaps-40fa7a51-f41f-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029273461s
STEP: Saw pod success
Oct 21 16:24:30.330: INFO: Pod "pod-projected-configmaps-40fa7a51-f41f-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:24:30.345: INFO: Trying to get logs from node 10.134.235.118 pod pod-projected-configmaps-40fa7a51-f41f-11e9-ae8d-bacadc8895d2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:24:30.405: INFO: Waiting for pod pod-projected-configmaps-40fa7a51-f41f-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:24:30.413: INFO: Pod pod-projected-configmaps-40fa7a51-f41f-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:24:30.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4383" for this suite.
Oct 21 16:24:36.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:24:36.809: INFO: namespace projected-4383 deletion completed in 6.381040558s

• [SLOW TEST:8.752 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:24:36.809: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5075
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 21 16:24:37.048: INFO: Waiting up to 5m0s for pod "pod-46311add-f41f-11e9-ae8d-bacadc8895d2" in namespace "emptydir-5075" to be "success or failure"
Oct 21 16:24:37.057: INFO: Pod "pod-46311add-f41f-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.457089ms
Oct 21 16:24:39.072: INFO: Pod "pod-46311add-f41f-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023491008s
STEP: Saw pod success
Oct 21 16:24:39.072: INFO: Pod "pod-46311add-f41f-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:24:39.080: INFO: Trying to get logs from node 10.134.235.67 pod pod-46311add-f41f-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 16:24:39.135: INFO: Waiting for pod pod-46311add-f41f-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:24:39.143: INFO: Pod pod-46311add-f41f-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:24:39.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5075" for this suite.
Oct 21 16:24:45.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:24:45.552: INFO: namespace emptydir-5075 deletion completed in 6.398171742s

• [SLOW TEST:8.743 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:24:45.552: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3713
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 21 16:24:50.022: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 21 16:24:50.036: INFO: Pod pod-with-poststart-http-hook still exists
Oct 21 16:24:52.037: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 21 16:24:52.082: INFO: Pod pod-with-poststart-http-hook still exists
Oct 21 16:24:54.037: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 21 16:24:54.046: INFO: Pod pod-with-poststart-http-hook still exists
Oct 21 16:24:56.037: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 21 16:24:56.049: INFO: Pod pod-with-poststart-http-hook still exists
Oct 21 16:24:58.037: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 21 16:24:58.047: INFO: Pod pod-with-poststart-http-hook still exists
Oct 21 16:25:00.037: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 21 16:25:00.049: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:25:00.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3713" for this suite.
Oct 21 16:25:24.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:25:24.438: INFO: namespace container-lifecycle-hook-3713 deletion completed in 24.377183496s

• [SLOW TEST:38.885 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:25:24.439: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3404
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-6295ab0a-f41f-11e9-ae8d-bacadc8895d2
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-6295ab0a-f41f-11e9-ae8d-bacadc8895d2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:26:43.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3404" for this suite.
Oct 21 16:27:07.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:27:07.738: INFO: namespace configmap-3404 deletion completed in 24.401506077s

• [SLOW TEST:103.299 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:27:07.738: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8468
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-8468
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8468 to expose endpoints map[]
Oct 21 16:27:08.037: INFO: successfully validated that service endpoint-test2 in namespace services-8468 exposes endpoints map[] (15.161883ms elapsed)
STEP: Creating pod pod1 in namespace services-8468
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8468 to expose endpoints map[pod1:[80]]
Oct 21 16:27:10.296: INFO: successfully validated that service endpoint-test2 in namespace services-8468 exposes endpoints map[pod1:[80]] (2.232886858s elapsed)
STEP: Creating pod pod2 in namespace services-8468
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8468 to expose endpoints map[pod1:[80] pod2:[80]]
Oct 21 16:27:12.387: INFO: successfully validated that service endpoint-test2 in namespace services-8468 exposes endpoints map[pod1:[80] pod2:[80]] (2.080429726s elapsed)
STEP: Deleting pod pod1 in namespace services-8468
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8468 to expose endpoints map[pod2:[80]]
Oct 21 16:27:12.423: INFO: successfully validated that service endpoint-test2 in namespace services-8468 exposes endpoints map[pod2:[80]] (18.150984ms elapsed)
STEP: Deleting pod pod2 in namespace services-8468
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8468 to expose endpoints map[]
Oct 21 16:27:12.448: INFO: successfully validated that service endpoint-test2 in namespace services-8468 exposes endpoints map[] (8.794792ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:27:12.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8468" for this suite.
Oct 21 16:27:36.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:27:36.910: INFO: namespace services-8468 deletion completed in 24.375583037s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:29.172 seconds]
[sig-network] Services
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:27:36.911: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6258
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Oct 21 16:27:37.146: INFO: Waiting up to 5m0s for pod "pod-b18a2a67-f41f-11e9-ae8d-bacadc8895d2" in namespace "emptydir-6258" to be "success or failure"
Oct 21 16:27:37.158: INFO: Pod "pod-b18a2a67-f41f-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.960864ms
Oct 21 16:27:39.183: INFO: Pod "pod-b18a2a67-f41f-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037251741s
STEP: Saw pod success
Oct 21 16:27:39.183: INFO: Pod "pod-b18a2a67-f41f-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:27:39.192: INFO: Trying to get logs from node 10.134.235.67 pod pod-b18a2a67-f41f-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 16:27:39.254: INFO: Waiting for pod pod-b18a2a67-f41f-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:27:39.261: INFO: Pod pod-b18a2a67-f41f-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:27:39.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6258" for this suite.
Oct 21 16:27:45.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:27:45.626: INFO: namespace emptydir-6258 deletion completed in 6.344954467s

• [SLOW TEST:8.716 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:27:45.626: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9316
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 21 16:27:48.429: INFO: Successfully updated pod "pod-update-activedeadlineseconds-b6bd5584-f41f-11e9-ae8d-bacadc8895d2"
Oct 21 16:27:48.429: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-b6bd5584-f41f-11e9-ae8d-bacadc8895d2" in namespace "pods-9316" to be "terminated due to deadline exceeded"
Oct 21 16:27:48.444: INFO: Pod "pod-update-activedeadlineseconds-b6bd5584-f41f-11e9-ae8d-bacadc8895d2": Phase="Running", Reason="", readiness=true. Elapsed: 14.675912ms
Oct 21 16:27:50.457: INFO: Pod "pod-update-activedeadlineseconds-b6bd5584-f41f-11e9-ae8d-bacadc8895d2": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.027691375s
Oct 21 16:27:50.457: INFO: Pod "pod-update-activedeadlineseconds-b6bd5584-f41f-11e9-ae8d-bacadc8895d2" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:27:50.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9316" for this suite.
Oct 21 16:27:58.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:27:58.857: INFO: namespace pods-9316 deletion completed in 8.383198751s

• [SLOW TEST:13.231 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:27:58.858: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9715
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Oct 21 16:27:59.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 api-versions'
Oct 21 16:27:59.169: INFO: stderr: ""
Oct 21 16:27:59.169: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:27:59.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9715" for this suite.
Oct 21 16:28:05.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:28:05.602: INFO: namespace kubectl-9715 deletion completed in 6.420692981s

• [SLOW TEST:6.744 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:28:05.602: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3475
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:28:05.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3475" for this suite.
Oct 21 16:28:29.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:28:30.261: INFO: namespace pods-3475 deletion completed in 24.385370805s

• [SLOW TEST:24.658 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:28:30.261: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7128
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Oct 21 16:28:30.489: INFO: Waiting up to 5m0s for pod "pod-d154f1c7-f41f-11e9-ae8d-bacadc8895d2" in namespace "emptydir-7128" to be "success or failure"
Oct 21 16:28:30.498: INFO: Pod "pod-d154f1c7-f41f-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.197024ms
Oct 21 16:28:32.508: INFO: Pod "pod-d154f1c7-f41f-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018950479s
STEP: Saw pod success
Oct 21 16:28:32.508: INFO: Pod "pod-d154f1c7-f41f-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:28:32.516: INFO: Trying to get logs from node 10.134.235.118 pod pod-d154f1c7-f41f-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 16:28:32.573: INFO: Waiting for pod pod-d154f1c7-f41f-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:28:32.581: INFO: Pod pod-d154f1c7-f41f-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:28:32.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7128" for this suite.
Oct 21 16:28:40.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:28:41.072: INFO: namespace emptydir-7128 deletion completed in 8.477608504s

• [SLOW TEST:10.811 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:28:41.075: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1937
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 16:28:41.328: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct 21 16:28:46.338: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 21 16:28:46.338: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct 21 16:28:48.351: INFO: Creating deployment "test-rollover-deployment"
Oct 21 16:28:48.395: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct 21 16:28:50.416: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct 21 16:28:50.438: INFO: Ensure that both replica sets have 1 created replica
Oct 21 16:28:50.458: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct 21 16:28:50.491: INFO: Updating deployment test-rollover-deployment
Oct 21 16:28:50.491: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct 21 16:28:52.587: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct 21 16:28:52.622: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct 21 16:28:52.640: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 16:28:52.640: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272128, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272128, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272132, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272128, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 16:28:54.658: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 16:28:54.658: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272128, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272128, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272132, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272128, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 16:28:56.663: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 16:28:56.663: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272128, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272128, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272132, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272128, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 16:28:58.661: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 16:28:58.662: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272128, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272128, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272132, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272128, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 16:29:00.661: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 16:29:00.661: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272128, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272128, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272132, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272128, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 16:29:02.711: INFO: 
Oct 21 16:29:02.711: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 21 16:29:02.752: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-1937,SelfLink:/apis/apps/v1/namespaces/deployment-1937/deployments/test-rollover-deployment,UID:dbff6ca0-f41f-11e9-a1ef-46591df82ad7,ResourceVersion:30039,Generation:2,CreationTimestamp:2019-10-21 16:28:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-21 16:28:48 +0000 UTC 2019-10-21 16:28:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-21 16:29:02 +0000 UTC 2019-10-21 16:28:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-659c699649" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 21 16:29:02.767: INFO: New ReplicaSet "test-rollover-deployment-659c699649" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649,GenerateName:,Namespace:deployment-1937,SelfLink:/apis/apps/v1/namespaces/deployment-1937/replicasets/test-rollover-deployment-659c699649,UID:dd4447eb-f41f-11e9-93ac-c26612c2e4bb,ResourceVersion:30028,Generation:2,CreationTimestamp:2019-10-21 16:28:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment dbff6ca0-f41f-11e9-a1ef-46591df82ad7 0xc00317b377 0xc00317b378}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 21 16:29:02.767: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct 21 16:29:02.767: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-1937,SelfLink:/apis/apps/v1/namespaces/deployment-1937/replicasets/test-rollover-controller,UID:d7c9e4dd-f41f-11e9-a1ef-46591df82ad7,ResourceVersion:30037,Generation:2,CreationTimestamp:2019-10-21 16:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment dbff6ca0-f41f-11e9-a1ef-46591df82ad7 0xc00317b2a7 0xc00317b2a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 16:29:02.767: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-7b45b6464,GenerateName:,Namespace:deployment-1937,SelfLink:/apis/apps/v1/namespaces/deployment-1937/replicasets/test-rollover-deployment-7b45b6464,UID:dc05ffa9-f41f-11e9-93ac-c26612c2e4bb,ResourceVersion:29995,Generation:2,CreationTimestamp:2019-10-21 16:28:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment dbff6ca0-f41f-11e9-a1ef-46591df82ad7 0xc00317b460 0xc00317b461}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 16:29:02.782: INFO: Pod "test-rollover-deployment-659c699649-djmpn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649-djmpn,GenerateName:test-rollover-deployment-659c699649-,Namespace:deployment-1937,SelfLink:/api/v1/namespaces/deployment-1937/pods/test-rollover-deployment-659c699649-djmpn,UID:dd4c2bba-f41f-11e9-93ac-c26612c2e4bb,ResourceVersion:30009,Generation:0,CreationTimestamp:2019-10-21 16:28:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-659c699649 dd4447eb-f41f-11e9-93ac-c26612c2e4bb 0xc002dd60f7 0xc002dd60f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2nwf7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2nwf7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-2nwf7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.67,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002dd6170} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002dd6190}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:28:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:28:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:28:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:28:50 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.67,PodIP:172.30.198.118,StartTime:2019-10-21 16:28:50 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-21 16:28:51 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://561e7bcc64008068a494c4fc365c99b770a82e63915e7b655710f65b06f0d5f5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:29:02.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1937" for this suite.
Oct 21 16:29:10.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:29:11.165: INFO: namespace deployment-1937 deletion completed in 8.363362155s

• [SLOW TEST:30.090 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:29:11.166: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1243
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1021 16:29:21.772636      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 21 16:29:21.772: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:29:21.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1243" for this suite.
Oct 21 16:29:29.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:29:30.671: INFO: namespace gc-1243 deletion completed in 8.881300747s

• [SLOW TEST:19.506 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:29:30.672: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-85
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1256
STEP: creating an rc
Oct 21 16:29:30.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 create -f - --namespace=kubectl-85'
Oct 21 16:29:31.228: INFO: stderr: ""
Oct 21 16:29:31.228: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Oct 21 16:29:32.240: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:29:32.240: INFO: Found 0 / 1
Oct 21 16:29:33.239: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:29:33.239: INFO: Found 0 / 1
Oct 21 16:29:34.237: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:29:34.237: INFO: Found 1 / 1
Oct 21 16:29:34.238: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 21 16:29:34.246: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:29:34.246: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Oct 21 16:29:34.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 logs redis-master-4qnk7 redis-master --namespace=kubectl-85'
Oct 21 16:29:34.380: INFO: stderr: ""
Oct 21 16:29:34.380: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Oct 16:29:32.494 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Oct 16:29:32.494 # Server started, Redis version 3.2.12\n1:M 21 Oct 16:29:32.494 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Oct 16:29:32.494 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Oct 21 16:29:34.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 log redis-master-4qnk7 redis-master --namespace=kubectl-85 --tail=1'
Oct 21 16:29:34.498: INFO: stderr: ""
Oct 21 16:29:34.498: INFO: stdout: "1:M 21 Oct 16:29:32.494 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Oct 21 16:29:34.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 log redis-master-4qnk7 redis-master --namespace=kubectl-85 --limit-bytes=1'
Oct 21 16:29:34.623: INFO: stderr: ""
Oct 21 16:29:34.623: INFO: stdout: " "
STEP: exposing timestamps
Oct 21 16:29:34.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 log redis-master-4qnk7 redis-master --namespace=kubectl-85 --tail=1 --timestamps'
Oct 21 16:29:34.741: INFO: stderr: ""
Oct 21 16:29:34.741: INFO: stdout: "2019-10-21T16:29:32.495149775Z 1:M 21 Oct 16:29:32.494 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Oct 21 16:29:37.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 log redis-master-4qnk7 redis-master --namespace=kubectl-85 --since=1s'
Oct 21 16:29:37.346: INFO: stderr: ""
Oct 21 16:29:37.346: INFO: stdout: ""
Oct 21 16:29:37.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 log redis-master-4qnk7 redis-master --namespace=kubectl-85 --since=24h'
Oct 21 16:29:37.480: INFO: stderr: ""
Oct 21 16:29:37.480: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Oct 16:29:32.494 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Oct 16:29:32.494 # Server started, Redis version 3.2.12\n1:M 21 Oct 16:29:32.494 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Oct 16:29:32.494 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
STEP: using delete to clean up resources
Oct 21 16:29:37.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 delete --grace-period=0 --force -f - --namespace=kubectl-85'
Oct 21 16:29:37.593: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 16:29:37.593: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Oct 21 16:29:37.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get rc,svc -l name=nginx --no-headers --namespace=kubectl-85'
Oct 21 16:29:37.702: INFO: stderr: "No resources found.\n"
Oct 21 16:29:37.702: INFO: stdout: ""
Oct 21 16:29:37.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -l name=nginx --namespace=kubectl-85 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 21 16:29:37.804: INFO: stderr: ""
Oct 21 16:29:37.804: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:29:37.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-85" for this suite.
Oct 21 16:29:45.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:29:46.155: INFO: namespace kubectl-85 deletion completed in 8.33920763s

• [SLOW TEST:15.483 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:29:46.156: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9167
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 16:29:46.376: INFO: Creating ReplicaSet my-hostname-basic-fe93af12-f41f-11e9-ae8d-bacadc8895d2
Oct 21 16:29:46.394: INFO: Pod name my-hostname-basic-fe93af12-f41f-11e9-ae8d-bacadc8895d2: Found 0 pods out of 1
Oct 21 16:29:51.405: INFO: Pod name my-hostname-basic-fe93af12-f41f-11e9-ae8d-bacadc8895d2: Found 1 pods out of 1
Oct 21 16:29:51.405: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-fe93af12-f41f-11e9-ae8d-bacadc8895d2" is running
Oct 21 16:29:51.413: INFO: Pod "my-hostname-basic-fe93af12-f41f-11e9-ae8d-bacadc8895d2-w965g" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 16:29:46 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 16:29:48 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 16:29:48 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 16:29:46 +0000 UTC Reason: Message:}])
Oct 21 16:29:51.414: INFO: Trying to dial the pod
Oct 21 16:29:56.449: INFO: Controller my-hostname-basic-fe93af12-f41f-11e9-ae8d-bacadc8895d2: Got expected result from replica 1 [my-hostname-basic-fe93af12-f41f-11e9-ae8d-bacadc8895d2-w965g]: "my-hostname-basic-fe93af12-f41f-11e9-ae8d-bacadc8895d2-w965g", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:29:56.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9167" for this suite.
Oct 21 16:30:02.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:30:02.883: INFO: namespace replicaset-9167 deletion completed in 6.420783575s

• [SLOW TEST:16.726 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:30:02.883: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3244
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Oct 21 16:30:03.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 create -f - --namespace=kubectl-3244'
Oct 21 16:30:03.484: INFO: stderr: ""
Oct 21 16:30:03.484: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 16:30:03.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3244'
Oct 21 16:30:03.605: INFO: stderr: ""
Oct 21 16:30:03.605: INFO: stdout: "update-demo-nautilus-8xxst update-demo-nautilus-p6ths "
Oct 21 16:30:03.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-8xxst -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3244'
Oct 21 16:30:03.707: INFO: stderr: ""
Oct 21 16:30:03.707: INFO: stdout: ""
Oct 21 16:30:03.707: INFO: update-demo-nautilus-8xxst is created but not running
Oct 21 16:30:08.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3244'
Oct 21 16:30:08.822: INFO: stderr: ""
Oct 21 16:30:08.822: INFO: stdout: "update-demo-nautilus-8xxst update-demo-nautilus-p6ths "
Oct 21 16:30:08.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-8xxst -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3244'
Oct 21 16:30:08.921: INFO: stderr: ""
Oct 21 16:30:08.921: INFO: stdout: "true"
Oct 21 16:30:08.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-8xxst -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3244'
Oct 21 16:30:09.017: INFO: stderr: ""
Oct 21 16:30:09.017: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:30:09.017: INFO: validating pod update-demo-nautilus-8xxst
Oct 21 16:30:09.045: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:30:09.045: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:30:09.045: INFO: update-demo-nautilus-8xxst is verified up and running
Oct 21 16:30:09.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-p6ths -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3244'
Oct 21 16:30:09.137: INFO: stderr: ""
Oct 21 16:30:09.137: INFO: stdout: "true"
Oct 21 16:30:09.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-nautilus-p6ths -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3244'
Oct 21 16:30:09.242: INFO: stderr: ""
Oct 21 16:30:09.242: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:30:09.242: INFO: validating pod update-demo-nautilus-p6ths
Oct 21 16:30:09.302: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:30:09.302: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:30:09.302: INFO: update-demo-nautilus-p6ths is verified up and running
STEP: rolling-update to new replication controller
Oct 21 16:30:09.303: INFO: scanned /root for discovery docs: <nil>
Oct 21 16:30:09.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-3244'
Oct 21 16:30:32.177: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 21 16:30:32.177: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 16:30:32.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3244'
Oct 21 16:30:32.277: INFO: stderr: ""
Oct 21 16:30:32.277: INFO: stdout: "update-demo-kitten-7fxjs update-demo-kitten-twmgn "
Oct 21 16:30:32.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-kitten-7fxjs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3244'
Oct 21 16:30:32.390: INFO: stderr: ""
Oct 21 16:30:32.390: INFO: stdout: "true"
Oct 21 16:30:32.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-kitten-7fxjs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3244'
Oct 21 16:30:32.494: INFO: stderr: ""
Oct 21 16:30:32.494: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 21 16:30:32.494: INFO: validating pod update-demo-kitten-7fxjs
Oct 21 16:30:33.216: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 21 16:30:33.216: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 21 16:30:33.216: INFO: update-demo-kitten-7fxjs is verified up and running
Oct 21 16:30:33.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-kitten-twmgn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3244'
Oct 21 16:30:33.319: INFO: stderr: ""
Oct 21 16:30:33.319: INFO: stdout: "true"
Oct 21 16:30:33.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods update-demo-kitten-twmgn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3244'
Oct 21 16:30:33.421: INFO: stderr: ""
Oct 21 16:30:33.421: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 21 16:30:33.421: INFO: validating pod update-demo-kitten-twmgn
Oct 21 16:30:33.445: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 21 16:30:33.445: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 21 16:30:33.445: INFO: update-demo-kitten-twmgn is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:30:33.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3244" for this suite.
Oct 21 16:30:57.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:30:57.842: INFO: namespace kubectl-3244 deletion completed in 24.381564159s

• [SLOW TEST:54.959 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:30:57.842: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3691
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7165
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3856
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:31:23.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3691" for this suite.
Oct 21 16:31:29.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:31:29.935: INFO: namespace namespaces-3691 deletion completed in 6.372871182s
STEP: Destroying namespace "nsdeletetest-7165" for this suite.
Oct 21 16:31:29.944: INFO: Namespace nsdeletetest-7165 was already deleted
STEP: Destroying namespace "nsdeletetest-3856" for this suite.
Oct 21 16:31:35.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:31:36.321: INFO: namespace nsdeletetest-3856 deletion completed in 6.376570625s

• [SLOW TEST:38.479 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:31:36.321: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6179
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-6179
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 21 16:31:36.532: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 21 16:31:58.744: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.198.126 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6179 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:31:58.744: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 16:32:00.003: INFO: Found all expected endpoints: [netserver-0]
Oct 21 16:32:00.013: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.192.195 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6179 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:32:00.013: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 16:32:01.270: INFO: Found all expected endpoints: [netserver-1]
Oct 21 16:32:01.280: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.132.22 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6179 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:32:01.280: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 16:32:02.541: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:32:02.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6179" for this suite.
Oct 21 16:32:26.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:32:26.909: INFO: namespace pod-network-test-6179 deletion completed in 24.351488024s

• [SLOW TEST:50.588 seconds]
[sig-network] Networking
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:32:26.909: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5108
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct 21 16:32:29.726: INFO: Successfully updated pod "labelsupdate5e639592-f420-11e9-ae8d-bacadc8895d2"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:32:33.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5108" for this suite.
Oct 21 16:32:57.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:32:58.163: INFO: namespace projected-5108 deletion completed in 24.358174921s

• [SLOW TEST:31.254 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:32:58.163: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9091
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-71039dd7-f420-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume configMaps
Oct 21 16:32:58.400: INFO: Waiting up to 5m0s for pod "pod-configmaps-7105479c-f420-11e9-ae8d-bacadc8895d2" in namespace "configmap-9091" to be "success or failure"
Oct 21 16:32:58.411: INFO: Pod "pod-configmaps-7105479c-f420-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.204448ms
Oct 21 16:33:00.434: INFO: Pod "pod-configmaps-7105479c-f420-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033647645s
Oct 21 16:33:02.443: INFO: Pod "pod-configmaps-7105479c-f420-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042638131s
STEP: Saw pod success
Oct 21 16:33:02.443: INFO: Pod "pod-configmaps-7105479c-f420-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:33:02.453: INFO: Trying to get logs from node 10.134.235.118 pod pod-configmaps-7105479c-f420-11e9-ae8d-bacadc8895d2 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:33:02.518: INFO: Waiting for pod pod-configmaps-7105479c-f420-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:33:02.526: INFO: Pod pod-configmaps-7105479c-f420-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:33:02.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9091" for this suite.
Oct 21 16:33:08.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:33:08.920: INFO: namespace configmap-9091 deletion completed in 6.382400891s

• [SLOW TEST:10.757 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:33:08.921: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5008
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:33:11.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5008" for this suite.
Oct 21 16:33:51.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:33:51.596: INFO: namespace kubelet-test-5008 deletion completed in 40.364995212s

• [SLOW TEST:42.675 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:33:51.597: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4085
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:33:55.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4085" for this suite.
Oct 21 16:34:44.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:34:45.058: INFO: namespace kubelet-test-4085 deletion completed in 49.115608663s

• [SLOW TEST:53.461 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:34:45.059: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8645
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Oct 21 16:34:45.291: INFO: Waiting up to 5m0s for pod "var-expansion-b0bb491f-f420-11e9-ae8d-bacadc8895d2" in namespace "var-expansion-8645" to be "success or failure"
Oct 21 16:34:45.306: INFO: Pod "var-expansion-b0bb491f-f420-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 15.220695ms
Oct 21 16:34:47.315: INFO: Pod "var-expansion-b0bb491f-f420-11e9-ae8d-bacadc8895d2": Phase="Running", Reason="", readiness=true. Elapsed: 2.024750287s
Oct 21 16:34:49.327: INFO: Pod "var-expansion-b0bb491f-f420-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036697002s
STEP: Saw pod success
Oct 21 16:34:49.327: INFO: Pod "var-expansion-b0bb491f-f420-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:34:49.336: INFO: Trying to get logs from node 10.134.235.67 pod var-expansion-b0bb491f-f420-11e9-ae8d-bacadc8895d2 container dapi-container: <nil>
STEP: delete the pod
Oct 21 16:34:49.388: INFO: Waiting for pod var-expansion-b0bb491f-f420-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:34:49.396: INFO: Pod var-expansion-b0bb491f-f420-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:34:49.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8645" for this suite.
Oct 21 16:34:55.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:34:55.836: INFO: namespace var-expansion-8645 deletion completed in 6.423399644s

• [SLOW TEST:10.777 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:34:55.836: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-8789
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-8789
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-8789
STEP: Deleting pre-stop pod
Oct 21 16:35:09.185: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:35:09.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-8789" for this suite.
Oct 21 16:35:49.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:35:49.631: INFO: namespace prestop-8789 deletion completed in 40.407529876s

• [SLOW TEST:53.795 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:35:49.633: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3188
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Oct 21 16:35:49.884: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3188,SelfLink:/api/v1/namespaces/watch-3188/configmaps/e2e-watch-test-watch-closed,UID:d7397f33-f420-11e9-a1ef-46591df82ad7,ResourceVersion:31742,Generation:0,CreationTimestamp:2019-10-21 16:35:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 21 16:35:49.885: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3188,SelfLink:/api/v1/namespaces/watch-3188/configmaps/e2e-watch-test-watch-closed,UID:d7397f33-f420-11e9-a1ef-46591df82ad7,ResourceVersion:31743,Generation:0,CreationTimestamp:2019-10-21 16:35:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Oct 21 16:35:49.931: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3188,SelfLink:/api/v1/namespaces/watch-3188/configmaps/e2e-watch-test-watch-closed,UID:d7397f33-f420-11e9-a1ef-46591df82ad7,ResourceVersion:31744,Generation:0,CreationTimestamp:2019-10-21 16:35:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 21 16:35:49.931: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3188,SelfLink:/api/v1/namespaces/watch-3188/configmaps/e2e-watch-test-watch-closed,UID:d7397f33-f420-11e9-a1ef-46591df82ad7,ResourceVersion:31745,Generation:0,CreationTimestamp:2019-10-21 16:35:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:35:49.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3188" for this suite.
Oct 21 16:35:55.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:35:56.304: INFO: namespace watch-3188 deletion completed in 6.35884419s

• [SLOW TEST:6.671 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:35:56.304: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3640
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:35:56.527: INFO: Waiting up to 5m0s for pod "downwardapi-volume-db317022-f420-11e9-ae8d-bacadc8895d2" in namespace "projected-3640" to be "success or failure"
Oct 21 16:35:56.538: INFO: Pod "downwardapi-volume-db317022-f420-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.187037ms
Oct 21 16:35:58.549: INFO: Pod "downwardapi-volume-db317022-f420-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022438871s
STEP: Saw pod success
Oct 21 16:35:58.549: INFO: Pod "downwardapi-volume-db317022-f420-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:35:58.558: INFO: Trying to get logs from node 10.134.235.118 pod downwardapi-volume-db317022-f420-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 16:35:58.607: INFO: Waiting for pod downwardapi-volume-db317022-f420-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:35:58.615: INFO: Pod downwardapi-volume-db317022-f420-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:35:58.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3640" for this suite.
Oct 21 16:36:04.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:36:05.069: INFO: namespace projected-3640 deletion completed in 6.440081891s

• [SLOW TEST:8.765 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:36:05.070: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8089
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct 21 16:36:05.296: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 21 16:36:05.326: INFO: Waiting for terminating namespaces to be deleted...
Oct 21 16:36:05.339: INFO: 
Logging pods the kubelet thinks is on node 10.134.235.118 before test
Oct 21 16:36:05.407: INFO: vpn-7754bb6d4-2n6w7 from kube-system started at 2019-10-21 14:35:37 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.407: INFO: 	Container vpn ready: true, restart count 0
Oct 21 16:36:05.407: INFO: ibm-master-proxy-static-10.134.235.118 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 16:36:05.407: INFO: ibm-keepalived-watcher-s768g from kube-system started at 2019-10-21 14:16:32 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.407: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 16:36:05.407: INFO: coredns-9dd7747c7-cgj4m from kube-system started at 2019-10-21 14:35:59 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.407: INFO: 	Container coredns ready: true, restart count 0
Oct 21 16:36:05.407: INFO: sonobuoy from sonobuoy started at 2019-10-21 15:48:00 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.407: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 21 16:36:05.407: INFO: sonobuoy-systemd-logs-daemon-set-aae6d13d2b504a80-z8lvd from sonobuoy started at 2019-10-21 15:48:07 +0000 UTC (2 container statuses recorded)
Oct 21 16:36:05.407: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 16:36:05.407: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 21 16:36:05.407: INFO: calico-node-xczq8 from kube-system started at 2019-10-21 14:16:32 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.407: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 16:36:05.407: INFO: ibm-kube-fluentd-5gkfc from kube-system started at 2019-10-21 14:16:32 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.407: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 16:36:05.407: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-10-21 14:18:34 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.407: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Oct 21 16:36:05.407: INFO: ibm-cloud-provider-ip-169-50-36-162-5fffc56797-4s4bl from ibm-system started at 2019-10-21 14:27:14 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.407: INFO: 	Container ibm-cloud-provider-ip-169-50-36-162 ready: true, restart count 0
Oct 21 16:36:05.407: INFO: 
Logging pods the kubelet thinks is on node 10.134.235.67 before test
Oct 21 16:36:05.457: INFO: ibm-kube-fluentd-5ssfj from kube-system started at 2019-10-21 14:17:00 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.457: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 16:36:05.457: INFO: public-crbmmrhnff04rpad188da0-alb1-5bd9899fdd-sq8jg from kube-system started at 2019-10-21 14:28:20 +0000 UTC (4 container statuses recorded)
Oct 21 16:36:05.457: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 16:36:05.457: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 16:36:05.457: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 16:36:05.457: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 21 16:36:05.457: INFO: sonobuoy-systemd-logs-daemon-set-aae6d13d2b504a80-8xb54 from sonobuoy started at 2019-10-21 15:48:07 +0000 UTC (2 container statuses recorded)
Oct 21 16:36:05.457: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 16:36:05.458: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 21 16:36:05.458: INFO: ibm-cloud-provider-ip-169-50-36-162-5fffc56797-6gpb8 from ibm-system started at 2019-10-21 14:27:14 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.458: INFO: 	Container ibm-cloud-provider-ip-169-50-36-162 ready: true, restart count 0
Oct 21 16:36:05.458: INFO: calico-node-hvq6v from kube-system started at 2019-10-21 14:17:00 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.458: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 16:36:05.458: INFO: ibm-master-proxy-static-10.134.235.67 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 16:36:05.458: INFO: ibm-keepalived-watcher-p74j4 from kube-system started at 2019-10-21 14:17:00 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.458: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 16:36:05.458: INFO: 
Logging pods the kubelet thinks is on node 10.134.235.77 before test
Oct 21 16:36:05.593: INFO: ibm-master-proxy-static-10.134.235.77 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 16:36:05.593: INFO: ibm-keepalived-watcher-vv9sg from kube-system started at 2019-10-21 14:14:07 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.593: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 16:36:05.593: INFO: public-crbmmrhnff04rpad188da0-alb1-5bd9899fdd-sk955 from kube-system started at 2019-10-21 14:28:20 +0000 UTC (4 container statuses recorded)
Oct 21 16:36:05.593: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 16:36:05.593: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 16:36:05.593: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 16:36:05.593: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 21 16:36:05.593: INFO: sonobuoy-e2e-job-84d501f52fd84cd8 from sonobuoy started at 2019-10-21 15:48:07 +0000 UTC (2 container statuses recorded)
Oct 21 16:36:05.593: INFO: 	Container e2e ready: true, restart count 0
Oct 21 16:36:05.593: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 16:36:05.593: INFO: coredns-autoscaler-5d4db8dd68-4rk7m from kube-system started at 2019-10-21 14:14:26 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.593: INFO: 	Container autoscaler ready: true, restart count 0
Oct 21 16:36:05.593: INFO: metrics-server-64cc5dbf7f-mqllr from kube-system started at 2019-10-21 14:14:41 +0000 UTC (2 container statuses recorded)
Oct 21 16:36:05.593: INFO: 	Container metrics-server ready: true, restart count 0
Oct 21 16:36:05.593: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct 21 16:36:05.593: INFO: calico-node-qbdl6 from kube-system started at 2019-10-21 14:14:07 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.593: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 16:36:05.593: INFO: ibm-file-plugin-9bf87c759-7h2dh from kube-system started at 2019-10-21 14:14:25 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.593: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct 21 16:36:05.593: INFO: ibm-storage-watcher-5f677d9c66-8mmsv from kube-system started at 2019-10-21 14:14:25 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.593: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct 21 16:36:05.593: INFO: coredns-9dd7747c7-kp66g from kube-system started at 2019-10-21 14:35:59 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.593: INFO: 	Container coredns ready: true, restart count 0
Oct 21 16:36:05.593: INFO: kubernetes-dashboard-5c8c9b7546-56vkg from kube-system started at 2019-10-21 14:14:26 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.593: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct 21 16:36:05.593: INFO: ibm-kube-fluentd-zwqgb from kube-system started at 2019-10-21 14:14:36 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.593: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 16:36:05.593: INFO: calico-kube-controllers-65f9c6c467-9xskh from kube-system started at 2019-10-21 14:14:25 +0000 UTC (1 container statuses recorded)
Oct 21 16:36:05.593: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct 21 16:36:05.593: INFO: sonobuoy-systemd-logs-daemon-set-aae6d13d2b504a80-mzxfn from sonobuoy started at 2019-10-21 15:48:07 +0000 UTC (2 container statuses recorded)
Oct 21 16:36:05.593: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 16:36:05.593: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15cfb6c821369d80], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:36:06.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8089" for this suite.
Oct 21 16:36:12.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:36:13.092: INFO: namespace sched-pred-8089 deletion completed in 6.416463562s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:8.023 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:36:13.094: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5908
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-e533ffe9-f420-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume configMaps
Oct 21 16:36:13.329: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e5358f5a-f420-11e9-ae8d-bacadc8895d2" in namespace "projected-5908" to be "success or failure"
Oct 21 16:36:13.343: INFO: Pod "pod-projected-configmaps-e5358f5a-f420-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 14.018972ms
Oct 21 16:36:15.353: INFO: Pod "pod-projected-configmaps-e5358f5a-f420-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024066669s
STEP: Saw pod success
Oct 21 16:36:15.353: INFO: Pod "pod-projected-configmaps-e5358f5a-f420-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:36:15.362: INFO: Trying to get logs from node 10.134.235.67 pod pod-projected-configmaps-e5358f5a-f420-11e9-ae8d-bacadc8895d2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:36:15.418: INFO: Waiting for pod pod-projected-configmaps-e5358f5a-f420-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:36:15.426: INFO: Pod pod-projected-configmaps-e5358f5a-f420-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:36:15.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5908" for this suite.
Oct 21 16:36:21.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:36:21.845: INFO: namespace projected-5908 deletion completed in 6.406766244s

• [SLOW TEST:8.751 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:36:21.845: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8880
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 16:36:22.135: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"ea7240a6-f420-11e9-a1ef-46591df82ad7", Controller:(*bool)(0xc002f4b876), BlockOwnerDeletion:(*bool)(0xc002f4b877)}}
Oct 21 16:36:22.155: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"ea6d7331-f420-11e9-a1ef-46591df82ad7", Controller:(*bool)(0xc00317a74a), BlockOwnerDeletion:(*bool)(0xc00317a74b)}}
Oct 21 16:36:22.175: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"ea6fee9d-f420-11e9-a1ef-46591df82ad7", Controller:(*bool)(0xc002f4ba86), BlockOwnerDeletion:(*bool)(0xc002f4ba87)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:36:27.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8880" for this suite.
Oct 21 16:36:33.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:36:33.702: INFO: namespace gc-8880 deletion completed in 6.486145808s

• [SLOW TEST:11.856 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:36:33.702: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9538
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-f17e19ee-f420-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume configMaps
Oct 21 16:36:33.948: INFO: Waiting up to 5m0s for pod "pod-configmaps-f17fa114-f420-11e9-ae8d-bacadc8895d2" in namespace "configmap-9538" to be "success or failure"
Oct 21 16:36:33.956: INFO: Pod "pod-configmaps-f17fa114-f420-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.667187ms
Oct 21 16:36:35.966: INFO: Pod "pod-configmaps-f17fa114-f420-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018376833s
STEP: Saw pod success
Oct 21 16:36:35.966: INFO: Pod "pod-configmaps-f17fa114-f420-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:36:35.979: INFO: Trying to get logs from node 10.134.235.67 pod pod-configmaps-f17fa114-f420-11e9-ae8d-bacadc8895d2 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:36:36.026: INFO: Waiting for pod pod-configmaps-f17fa114-f420-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:36:36.033: INFO: Pod pod-configmaps-f17fa114-f420-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:36:36.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9538" for this suite.
Oct 21 16:36:42.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:36:42.386: INFO: namespace configmap-9538 deletion completed in 6.339447197s

• [SLOW TEST:8.685 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:36:42.388: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6026
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:37:05.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6026" for this suite.
Oct 21 16:37:11.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:37:11.623: INFO: namespace container-runtime-6026 deletion completed in 6.390044303s

• [SLOW TEST:29.236 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:37:11.624: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6701
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:37:11.862: INFO: Waiting up to 5m0s for pod "downwardapi-volume-08179e5f-f421-11e9-ae8d-bacadc8895d2" in namespace "downward-api-6701" to be "success or failure"
Oct 21 16:37:11.872: INFO: Pod "downwardapi-volume-08179e5f-f421-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.466311ms
Oct 21 16:37:13.885: INFO: Pod "downwardapi-volume-08179e5f-f421-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022944312s
STEP: Saw pod success
Oct 21 16:37:13.885: INFO: Pod "downwardapi-volume-08179e5f-f421-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:37:13.895: INFO: Trying to get logs from node 10.134.235.67 pod downwardapi-volume-08179e5f-f421-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 16:37:13.964: INFO: Waiting for pod downwardapi-volume-08179e5f-f421-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:37:13.975: INFO: Pod downwardapi-volume-08179e5f-f421-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:37:13.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6701" for this suite.
Oct 21 16:37:20.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:37:20.390: INFO: namespace downward-api-6701 deletion completed in 6.390064771s

• [SLOW TEST:8.766 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:37:20.392: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2755
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:38:20.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2755" for this suite.
Oct 21 16:38:44.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:38:45.039: INFO: namespace container-probe-2755 deletion completed in 24.382747854s

• [SLOW TEST:84.647 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:38:45.039: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8495
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Oct 21 16:38:47.315: INFO: Pod pod-hostip-3fc5980f-f421-11e9-ae8d-bacadc8895d2 has hostIP: 10.134.235.67
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:38:47.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8495" for this suite.
Oct 21 16:39:07.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:39:07.839: INFO: namespace pods-8495 deletion completed in 20.511111277s

• [SLOW TEST:22.801 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:39:07.840: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7361
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:39:08.071: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4d5cd921-f421-11e9-ae8d-bacadc8895d2" in namespace "projected-7361" to be "success or failure"
Oct 21 16:39:08.085: INFO: Pod "downwardapi-volume-4d5cd921-f421-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.456512ms
Oct 21 16:39:10.095: INFO: Pod "downwardapi-volume-4d5cd921-f421-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023622731s
STEP: Saw pod success
Oct 21 16:39:10.095: INFO: Pod "downwardapi-volume-4d5cd921-f421-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:39:10.103: INFO: Trying to get logs from node 10.134.235.118 pod downwardapi-volume-4d5cd921-f421-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 16:39:10.156: INFO: Waiting for pod downwardapi-volume-4d5cd921-f421-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:39:10.163: INFO: Pod downwardapi-volume-4d5cd921-f421-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:39:10.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7361" for this suite.
Oct 21 16:39:16.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:39:16.530: INFO: namespace projected-7361 deletion completed in 6.349704719s

• [SLOW TEST:8.690 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:39:16.530: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9747
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1649
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 16:39:16.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-9747'
Oct 21 16:39:16.869: INFO: stderr: ""
Oct 21 16:39:16.869: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1654
Oct 21 16:39:16.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 delete pods e2e-test-nginx-pod --namespace=kubectl-9747'
Oct 21 16:39:28.357: INFO: stderr: ""
Oct 21 16:39:28.357: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:39:28.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9747" for this suite.
Oct 21 16:39:36.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:39:36.731: INFO: namespace kubectl-9747 deletion completed in 8.356623658s

• [SLOW TEST:20.200 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:39:36.731: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9884
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct 21 16:39:36.958: INFO: Waiting up to 5m0s for pod "downward-api-5e9464af-f421-11e9-ae8d-bacadc8895d2" in namespace "downward-api-9884" to be "success or failure"
Oct 21 16:39:36.970: INFO: Pod "downward-api-5e9464af-f421-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.617275ms
Oct 21 16:39:38.980: INFO: Pod "downward-api-5e9464af-f421-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022371925s
STEP: Saw pod success
Oct 21 16:39:38.980: INFO: Pod "downward-api-5e9464af-f421-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:39:38.990: INFO: Trying to get logs from node 10.134.235.118 pod downward-api-5e9464af-f421-11e9-ae8d-bacadc8895d2 container dapi-container: <nil>
STEP: delete the pod
Oct 21 16:39:39.051: INFO: Waiting for pod downward-api-5e9464af-f421-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:39:39.059: INFO: Pod downward-api-5e9464af-f421-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:39:39.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9884" for this suite.
Oct 21 16:39:45.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:39:45.695: INFO: namespace downward-api-9884 deletion completed in 6.622127611s

• [SLOW TEST:8.964 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:39:45.696: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7822
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct 21 16:39:45.935: INFO: Waiting up to 5m0s for pod "downward-api-63edd589-f421-11e9-ae8d-bacadc8895d2" in namespace "downward-api-7822" to be "success or failure"
Oct 21 16:39:45.951: INFO: Pod "downward-api-63edd589-f421-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 16.114881ms
Oct 21 16:39:47.961: INFO: Pod "downward-api-63edd589-f421-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02594348s
Oct 21 16:39:49.973: INFO: Pod "downward-api-63edd589-f421-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037810126s
STEP: Saw pod success
Oct 21 16:39:49.973: INFO: Pod "downward-api-63edd589-f421-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:39:49.983: INFO: Trying to get logs from node 10.134.235.67 pod downward-api-63edd589-f421-11e9-ae8d-bacadc8895d2 container dapi-container: <nil>
STEP: delete the pod
Oct 21 16:39:50.037: INFO: Waiting for pod downward-api-63edd589-f421-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:39:50.050: INFO: Pod downward-api-63edd589-f421-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:39:50.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7822" for this suite.
Oct 21 16:39:56.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:39:56.445: INFO: namespace downward-api-7822 deletion completed in 6.382974228s

• [SLOW TEST:10.749 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:39:56.445: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2743
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-6a546098-f421-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume secrets
Oct 21 16:39:56.681: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6a562bc5-f421-11e9-ae8d-bacadc8895d2" in namespace "projected-2743" to be "success or failure"
Oct 21 16:39:56.689: INFO: Pod "pod-projected-secrets-6a562bc5-f421-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.75026ms
Oct 21 16:39:58.741: INFO: Pod "pod-projected-secrets-6a562bc5-f421-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060101046s
Oct 21 16:40:00.753: INFO: Pod "pod-projected-secrets-6a562bc5-f421-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.071831058s
STEP: Saw pod success
Oct 21 16:40:00.753: INFO: Pod "pod-projected-secrets-6a562bc5-f421-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:40:00.762: INFO: Trying to get logs from node 10.134.235.118 pod pod-projected-secrets-6a562bc5-f421-11e9-ae8d-bacadc8895d2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 21 16:40:00.817: INFO: Waiting for pod pod-projected-secrets-6a562bc5-f421-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:40:00.826: INFO: Pod pod-projected-secrets-6a562bc5-f421-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:40:00.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2743" for this suite.
Oct 21 16:40:08.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:40:09.212: INFO: namespace projected-2743 deletion completed in 8.373768309s

• [SLOW TEST:12.767 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:40:09.212: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6629
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct 21 16:40:09.460: INFO: PodSpec: initContainers in spec.initContainers
Oct 21 16:40:51.147: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-71f6be18-f421-11e9-ae8d-bacadc8895d2", GenerateName:"", Namespace:"init-container-6629", SelfLink:"/api/v1/namespaces/init-container-6629/pods/pod-init-71f6be18-f421-11e9-ae8d-bacadc8895d2", UID:"71f764b8-f421-11e9-a1ef-46591df82ad7", ResourceVersion:"32867", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63707272809, loc:(*time.Location)(0x882f100)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"460486194"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-8xwnw", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002718000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8xwnw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8xwnw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8xwnw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000b19ee8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.134.235.67", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002e66e40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000b19f70)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000b19f90)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000b19f98), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000b19f9c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272809, loc:(*time.Location)(0x882f100)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272809, loc:(*time.Location)(0x882f100)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272809, loc:(*time.Location)(0x882f100)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707272809, loc:(*time.Location)(0x882f100)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.134.235.67", PodIP:"172.30.198.77", StartTime:(*v1.Time)(0xc001f74340), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00295dea0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00295df10)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://6a0ac848bd5977ba4b6654f03a9ce7c232410def15588e71f17d012b48da6147"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001f744c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001f74480), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:40:51.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6629" for this suite.
Oct 21 16:41:15.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:41:15.522: INFO: namespace init-container-6629 deletion completed in 24.358781201s

• [SLOW TEST:66.309 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:41:15.522: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2890
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct 21 16:41:15.756: INFO: Waiting up to 5m0s for pod "downward-api-99779b50-f421-11e9-ae8d-bacadc8895d2" in namespace "downward-api-2890" to be "success or failure"
Oct 21 16:41:15.766: INFO: Pod "downward-api-99779b50-f421-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.036697ms
Oct 21 16:41:17.775: INFO: Pod "downward-api-99779b50-f421-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019106822s
Oct 21 16:41:19.785: INFO: Pod "downward-api-99779b50-f421-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028800966s
STEP: Saw pod success
Oct 21 16:41:19.785: INFO: Pod "downward-api-99779b50-f421-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:41:19.795: INFO: Trying to get logs from node 10.134.235.118 pod downward-api-99779b50-f421-11e9-ae8d-bacadc8895d2 container dapi-container: <nil>
STEP: delete the pod
Oct 21 16:41:19.854: INFO: Waiting for pod downward-api-99779b50-f421-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:41:19.862: INFO: Pod downward-api-99779b50-f421-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:41:19.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2890" for this suite.
Oct 21 16:41:25.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:41:26.306: INFO: namespace downward-api-2890 deletion completed in 6.432694202s

• [SLOW TEST:10.784 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:41:26.307: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7598
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Oct 21 16:41:26.542: INFO: Waiting up to 5m0s for pod "client-containers-9fe45ea1-f421-11e9-ae8d-bacadc8895d2" in namespace "containers-7598" to be "success or failure"
Oct 21 16:41:26.550: INFO: Pod "client-containers-9fe45ea1-f421-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.989397ms
Oct 21 16:41:28.559: INFO: Pod "client-containers-9fe45ea1-f421-11e9-ae8d-bacadc8895d2": Phase="Running", Reason="", readiness=true. Elapsed: 2.0168707s
Oct 21 16:41:30.569: INFO: Pod "client-containers-9fe45ea1-f421-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026372276s
STEP: Saw pod success
Oct 21 16:41:30.569: INFO: Pod "client-containers-9fe45ea1-f421-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:41:30.580: INFO: Trying to get logs from node 10.134.235.118 pod client-containers-9fe45ea1-f421-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 16:41:30.628: INFO: Waiting for pod client-containers-9fe45ea1-f421-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:41:30.639: INFO: Pod client-containers-9fe45ea1-f421-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:41:30.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7598" for this suite.
Oct 21 16:41:36.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:41:37.044: INFO: namespace containers-7598 deletion completed in 6.389824746s

• [SLOW TEST:10.737 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:41:37.044: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7093
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 16:41:41.343: INFO: Waiting up to 5m0s for pod "client-envvars-a8b93d01-f421-11e9-ae8d-bacadc8895d2" in namespace "pods-7093" to be "success or failure"
Oct 21 16:41:41.352: INFO: Pod "client-envvars-a8b93d01-f421-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.405502ms
Oct 21 16:41:43.362: INFO: Pod "client-envvars-a8b93d01-f421-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018711386s
STEP: Saw pod success
Oct 21 16:41:43.362: INFO: Pod "client-envvars-a8b93d01-f421-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:41:43.374: INFO: Trying to get logs from node 10.134.235.67 pod client-envvars-a8b93d01-f421-11e9-ae8d-bacadc8895d2 container env3cont: <nil>
STEP: delete the pod
Oct 21 16:41:43.428: INFO: Waiting for pod client-envvars-a8b93d01-f421-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:41:43.438: INFO: Pod client-envvars-a8b93d01-f421-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:41:43.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7093" for this suite.
Oct 21 16:42:33.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:42:33.865: INFO: namespace pods-7093 deletion completed in 50.413688036s

• [SLOW TEST:56.821 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:42:33.866: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3737
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct 21 16:42:34.117: INFO: Waiting up to 5m0s for pod "downward-api-c82b7950-f421-11e9-ae8d-bacadc8895d2" in namespace "downward-api-3737" to be "success or failure"
Oct 21 16:42:34.128: INFO: Pod "downward-api-c82b7950-f421-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.927079ms
Oct 21 16:42:36.137: INFO: Pod "downward-api-c82b7950-f421-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020651457s
STEP: Saw pod success
Oct 21 16:42:36.138: INFO: Pod "downward-api-c82b7950-f421-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:42:36.146: INFO: Trying to get logs from node 10.134.235.118 pod downward-api-c82b7950-f421-11e9-ae8d-bacadc8895d2 container dapi-container: <nil>
STEP: delete the pod
Oct 21 16:42:36.205: INFO: Waiting for pod downward-api-c82b7950-f421-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:42:36.212: INFO: Pod downward-api-c82b7950-f421-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:42:36.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3737" for this suite.
Oct 21 16:42:42.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:42:42.593: INFO: namespace downward-api-3737 deletion completed in 6.366255678s

• [SLOW TEST:8.727 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:42:42.593: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-4787
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Oct 21 16:42:46.862: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-cd5cf69e-f421-11e9-ae8d-bacadc8895d2,GenerateName:,Namespace:events-4787,SelfLink:/api/v1/namespaces/events-4787/pods/send-events-cd5cf69e-f421-11e9-ae8d-bacadc8895d2,UID:cd5d4cb3-f421-11e9-a1ef-46591df82ad7,ResourceVersion:33267,Generation:0,CreationTimestamp:2019-10-21 16:42:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 803067533,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fx9mv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fx9mv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-fx9mv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.118,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a7bc90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a7bcb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:42:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:42:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:42:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:42:42 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.118,PodIP:172.30.192.224,StartTime:2019-10-21 16:42:42 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-10-21 16:42:44 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://b012670df1c8e38d5cfddde8ee5a363e9eea4df5aa1a95f13abb41a8674d4a58}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Oct 21 16:42:48.870: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Oct 21 16:42:50.879: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:42:50.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4787" for this suite.
Oct 21 16:43:32.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:43:33.345: INFO: namespace events-4787 deletion completed in 42.436592064s

• [SLOW TEST:50.752 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:43:33.346: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5778
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:43:33.588: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb9eee1e-f421-11e9-ae8d-bacadc8895d2" in namespace "projected-5778" to be "success or failure"
Oct 21 16:43:33.597: INFO: Pod "downwardapi-volume-eb9eee1e-f421-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.524242ms
Oct 21 16:43:35.607: INFO: Pod "downwardapi-volume-eb9eee1e-f421-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019305916s
STEP: Saw pod success
Oct 21 16:43:35.607: INFO: Pod "downwardapi-volume-eb9eee1e-f421-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:43:35.616: INFO: Trying to get logs from node 10.134.235.118 pod downwardapi-volume-eb9eee1e-f421-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 16:43:35.677: INFO: Waiting for pod downwardapi-volume-eb9eee1e-f421-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:43:35.688: INFO: Pod downwardapi-volume-eb9eee1e-f421-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:43:35.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5778" for this suite.
Oct 21 16:43:41.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:43:42.057: INFO: namespace projected-5778 deletion completed in 6.355570441s

• [SLOW TEST:8.712 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:43:42.058: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9212
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-9212
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 21 16:43:42.275: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 21 16:44:00.490: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.198.82:8080/dial?request=hostName&protocol=http&host=172.30.198.81&port=8080&tries=1'] Namespace:pod-network-test-9212 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:44:00.490: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 16:44:00.768: INFO: Waiting for endpoints: map[]
Oct 21 16:44:00.778: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.198.82:8080/dial?request=hostName&protocol=http&host=172.30.192.223&port=8080&tries=1'] Namespace:pod-network-test-9212 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:44:00.778: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 16:44:01.042: INFO: Waiting for endpoints: map[]
Oct 21 16:44:01.052: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.198.82:8080/dial?request=hostName&protocol=http&host=172.30.132.24&port=8080&tries=1'] Namespace:pod-network-test-9212 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:44:01.052: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
Oct 21 16:44:01.347: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:44:01.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9212" for this suite.
Oct 21 16:44:25.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:44:26.674: INFO: namespace pod-network-test-9212 deletion completed in 25.31050919s

• [SLOW TEST:44.616 seconds]
[sig-network] Networking
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:44:26.675: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2577
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Oct 21 16:44:27.585: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-2577,SelfLink:/api/v1/namespaces/watch-2577/configmaps/e2e-watch-test-resource-version,UID:0bc3a420-f422-11e9-a1ef-46591df82ad7,ResourceVersion:33618,Generation:0,CreationTimestamp:2019-10-21 16:44:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 21 16:44:27.586: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-2577,SelfLink:/api/v1/namespaces/watch-2577/configmaps/e2e-watch-test-resource-version,UID:0bc3a420-f422-11e9-a1ef-46591df82ad7,ResourceVersion:33619,Generation:0,CreationTimestamp:2019-10-21 16:44:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:44:27.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2577" for this suite.
Oct 21 16:44:33.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:44:33.986: INFO: namespace watch-2577 deletion completed in 6.384606057s

• [SLOW TEST:7.311 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:44:33.986: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6425
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 16:44:34.229: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct 21 16:44:39.243: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 21 16:44:39.243: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 21 16:44:43.316: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-6425,SelfLink:/apis/apps/v1/namespaces/deployment-6425/deployments/test-cleanup-deployment,UID:12c58ee1-f422-11e9-a1ef-46591df82ad7,ResourceVersion:33707,Generation:1,CreationTimestamp:2019-10-21 16:44:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-21 16:44:39 +0000 UTC 2019-10-21 16:44:39 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-21 16:44:41 +0000 UTC 2019-10-21 16:44:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-6865c98b76" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 21 16:44:43.324: INFO: New ReplicaSet "test-cleanup-deployment-6865c98b76" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76,GenerateName:,Namespace:deployment-6425,SelfLink:/apis/apps/v1/namespaces/deployment-6425/replicasets/test-cleanup-deployment-6865c98b76,UID:12ca0bfc-f422-11e9-93ac-c26612c2e4bb,ResourceVersion:33696,Generation:1,CreationTimestamp:2019-10-21 16:44:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 12c58ee1-f422-11e9-a1ef-46591df82ad7 0xc002eb09a7 0xc002eb09a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 21 16:44:43.335: INFO: Pod "test-cleanup-deployment-6865c98b76-sfqbt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76-sfqbt,GenerateName:test-cleanup-deployment-6865c98b76-,Namespace:deployment-6425,SelfLink:/api/v1/namespaces/deployment-6425/pods/test-cleanup-deployment-6865c98b76-sfqbt,UID:12cb11cf-f422-11e9-93ac-c26612c2e4bb,ResourceVersion:33695,Generation:0,CreationTimestamp:2019-10-21 16:44:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-6865c98b76 12ca0bfc-f422-11e9-93ac-c26612c2e4bb 0xc002eb1007 0xc002eb1008}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-k98z6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-k98z6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-k98z6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.118,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002eb1080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002eb10a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:44:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:44:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:44:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:44:39 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.118,PodIP:172.30.192.222,StartTime:2019-10-21 16:44:39 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-21 16:44:40 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://873250669e6a0195f8f9046cb23b943d5e60595b14494edfb2351bc3da56fe9d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:44:43.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6425" for this suite.
Oct 21 16:44:49.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:44:49.743: INFO: namespace deployment-6425 deletion completed in 6.387939346s

• [SLOW TEST:15.757 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:44:49.744: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1332
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-b9bn
STEP: Creating a pod to test atomic-volume-subpath
Oct 21 16:44:50.539: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-b9bn" in namespace "subpath-1332" to be "success or failure"
Oct 21 16:44:50.549: INFO: Pod "pod-subpath-test-secret-b9bn": Phase="Pending", Reason="", readiness=false. Elapsed: 10.064975ms
Oct 21 16:44:52.558: INFO: Pod "pod-subpath-test-secret-b9bn": Phase="Running", Reason="", readiness=true. Elapsed: 2.019117958s
Oct 21 16:44:54.569: INFO: Pod "pod-subpath-test-secret-b9bn": Phase="Running", Reason="", readiness=true. Elapsed: 4.029778837s
Oct 21 16:44:56.580: INFO: Pod "pod-subpath-test-secret-b9bn": Phase="Running", Reason="", readiness=true. Elapsed: 6.04032055s
Oct 21 16:44:58.590: INFO: Pod "pod-subpath-test-secret-b9bn": Phase="Running", Reason="", readiness=true. Elapsed: 8.050407527s
Oct 21 16:45:00.600: INFO: Pod "pod-subpath-test-secret-b9bn": Phase="Running", Reason="", readiness=true. Elapsed: 10.060773668s
Oct 21 16:45:02.610: INFO: Pod "pod-subpath-test-secret-b9bn": Phase="Running", Reason="", readiness=true. Elapsed: 12.070436726s
Oct 21 16:45:04.621: INFO: Pod "pod-subpath-test-secret-b9bn": Phase="Running", Reason="", readiness=true. Elapsed: 14.081314751s
Oct 21 16:45:06.630: INFO: Pod "pod-subpath-test-secret-b9bn": Phase="Running", Reason="", readiness=true. Elapsed: 16.090671971s
Oct 21 16:45:08.641: INFO: Pod "pod-subpath-test-secret-b9bn": Phase="Running", Reason="", readiness=true. Elapsed: 18.10146177s
Oct 21 16:45:10.652: INFO: Pod "pod-subpath-test-secret-b9bn": Phase="Running", Reason="", readiness=true. Elapsed: 20.112992938s
Oct 21 16:45:13.203: INFO: Pod "pod-subpath-test-secret-b9bn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.663865581s
STEP: Saw pod success
Oct 21 16:45:13.203: INFO: Pod "pod-subpath-test-secret-b9bn" satisfied condition "success or failure"
Oct 21 16:45:13.221: INFO: Trying to get logs from node 10.134.235.67 pod pod-subpath-test-secret-b9bn container test-container-subpath-secret-b9bn: <nil>
STEP: delete the pod
Oct 21 16:45:13.296: INFO: Waiting for pod pod-subpath-test-secret-b9bn to disappear
Oct 21 16:45:13.304: INFO: Pod pod-subpath-test-secret-b9bn no longer exists
STEP: Deleting pod pod-subpath-test-secret-b9bn
Oct 21 16:45:13.304: INFO: Deleting pod "pod-subpath-test-secret-b9bn" in namespace "subpath-1332"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:45:13.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1332" for this suite.
Oct 21 16:45:19.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:45:19.748: INFO: namespace subpath-1332 deletion completed in 6.422775887s

• [SLOW TEST:30.004 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:45:19.749: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9911
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:45:19.993: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2b0b41de-f422-11e9-ae8d-bacadc8895d2" in namespace "downward-api-9911" to be "success or failure"
Oct 21 16:45:20.005: INFO: Pod "downwardapi-volume-2b0b41de-f422-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.843805ms
Oct 21 16:45:22.016: INFO: Pod "downwardapi-volume-2b0b41de-f422-11e9-ae8d-bacadc8895d2": Phase="Running", Reason="", readiness=true. Elapsed: 2.022596093s
Oct 21 16:45:24.025: INFO: Pod "downwardapi-volume-2b0b41de-f422-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031421247s
STEP: Saw pod success
Oct 21 16:45:24.025: INFO: Pod "downwardapi-volume-2b0b41de-f422-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:45:24.035: INFO: Trying to get logs from node 10.134.235.118 pod downwardapi-volume-2b0b41de-f422-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 16:45:24.096: INFO: Waiting for pod downwardapi-volume-2b0b41de-f422-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:45:24.109: INFO: Pod downwardapi-volume-2b0b41de-f422-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:45:24.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9911" for this suite.
Oct 21 16:45:30.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:45:30.587: INFO: namespace downward-api-9911 deletion completed in 6.462627144s

• [SLOW TEST:10.838 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:45:30.587: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2815
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2815.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2815.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 21 16:45:44.995: INFO: DNS probes using dns-2815/dns-test-31819535-f422-11e9-ae8d-bacadc8895d2 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:45:45.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2815" for this suite.
Oct 21 16:45:51.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:45:51.885: INFO: namespace dns-2815 deletion completed in 6.852670794s

• [SLOW TEST:21.298 seconds]
[sig-network] DNS
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:45:51.885: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1583
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Oct 21 16:45:52.094: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Oct 21 16:45:52.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 create -f - --namespace=kubectl-1583'
Oct 21 16:45:52.485: INFO: stderr: ""
Oct 21 16:45:52.485: INFO: stdout: "service/redis-slave created\n"
Oct 21 16:45:52.485: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Oct 21 16:45:52.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 create -f - --namespace=kubectl-1583'
Oct 21 16:45:52.771: INFO: stderr: ""
Oct 21 16:45:52.771: INFO: stdout: "service/redis-master created\n"
Oct 21 16:45:52.771: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct 21 16:45:52.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 create -f - --namespace=kubectl-1583'
Oct 21 16:45:52.948: INFO: stderr: ""
Oct 21 16:45:52.948: INFO: stdout: "service/frontend created\n"
Oct 21 16:45:52.948: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Oct 21 16:45:52.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 create -f - --namespace=kubectl-1583'
Oct 21 16:45:53.274: INFO: stderr: ""
Oct 21 16:45:53.274: INFO: stdout: "deployment.apps/frontend created\n"
Oct 21 16:45:53.275: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct 21 16:45:53.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 create -f - --namespace=kubectl-1583'
Oct 21 16:45:53.550: INFO: stderr: ""
Oct 21 16:45:53.550: INFO: stdout: "deployment.apps/redis-master created\n"
Oct 21 16:45:53.551: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Oct 21 16:45:53.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 create -f - --namespace=kubectl-1583'
Oct 21 16:45:53.905: INFO: stderr: ""
Oct 21 16:45:53.905: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Oct 21 16:45:53.905: INFO: Waiting for all frontend pods to be Running.
Oct 21 16:46:13.956: INFO: Waiting for frontend to serve content.
Oct 21 16:46:14.000: INFO: Trying to add a new entry to the guestbook.
Oct 21 16:46:14.036: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Oct 21 16:46:14.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 delete --grace-period=0 --force -f - --namespace=kubectl-1583'
Oct 21 16:46:14.295: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 16:46:14.295: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Oct 21 16:46:14.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 delete --grace-period=0 --force -f - --namespace=kubectl-1583'
Oct 21 16:46:14.466: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 16:46:14.466: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 21 16:46:14.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 delete --grace-period=0 --force -f - --namespace=kubectl-1583'
Oct 21 16:46:14.615: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 16:46:14.615: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 21 16:46:14.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 delete --grace-period=0 --force -f - --namespace=kubectl-1583'
Oct 21 16:46:14.746: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 16:46:14.746: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 21 16:46:14.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 delete --grace-period=0 --force -f - --namespace=kubectl-1583'
Oct 21 16:46:14.887: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 16:46:14.887: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 21 16:46:14.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 delete --grace-period=0 --force -f - --namespace=kubectl-1583'
Oct 21 16:46:15.008: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 16:46:15.008: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:46:15.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1583" for this suite.
Oct 21 16:46:55.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:46:55.660: INFO: namespace kubectl-1583 deletion completed in 40.633656502s

• [SLOW TEST:63.775 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:46:55.661: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6722
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1576
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 16:46:55.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-6722'
Oct 21 16:46:55.996: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 21 16:46:55.996: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1581
Oct 21 16:46:56.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 delete jobs e2e-test-nginx-job --namespace=kubectl-6722'
Oct 21 16:46:56.127: INFO: stderr: ""
Oct 21 16:46:56.127: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:46:56.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6722" for this suite.
Oct 21 16:47:02.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:47:02.533: INFO: namespace kubectl-6722 deletion completed in 6.386251423s

• [SLOW TEST:6.872 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:47:02.533: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5871
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-5871
Oct 21 16:47:04.796: INFO: Started pod liveness-exec in namespace container-probe-5871
STEP: checking the pod's current state and verifying that restartCount is present
Oct 21 16:47:04.807: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:51:05.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5871" for this suite.
Oct 21 16:51:11.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:51:11.606: INFO: namespace container-probe-5871 deletion completed in 6.384774763s

• [SLOW TEST:249.073 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:51:11.607: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3339
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-3339
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Oct 21 16:51:11.844: INFO: Found 0 stateful pods, waiting for 3
Oct 21 16:51:21.854: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:51:21.854: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:51:21.854: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:51:21.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-3339 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 16:51:22.233: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 16:51:22.233: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 16:51:22.233: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 21 16:51:32.329: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Oct 21 16:51:42.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-3339 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:51:43.055: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 21 16:51:43.055: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 16:51:43.055: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 16:51:53.117: INFO: Waiting for StatefulSet statefulset-3339/ss2 to complete update
Oct 21 16:51:53.117: INFO: Waiting for Pod statefulset-3339/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 21 16:51:53.117: INFO: Waiting for Pod statefulset-3339/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 21 16:51:53.117: INFO: Waiting for Pod statefulset-3339/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 21 16:52:03.138: INFO: Waiting for StatefulSet statefulset-3339/ss2 to complete update
Oct 21 16:52:03.138: INFO: Waiting for Pod statefulset-3339/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 21 16:52:13.137: INFO: Waiting for StatefulSet statefulset-3339/ss2 to complete update
STEP: Rolling back to a previous revision
Oct 21 16:52:23.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-3339 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 16:52:23.480: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 16:52:23.480: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 16:52:23.480: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 16:52:33.556: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Oct 21 16:52:43.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-3339 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:52:43.916: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 21 16:52:43.916: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 16:52:43.916: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 16:53:03.978: INFO: Waiting for StatefulSet statefulset-3339/ss2 to complete update
Oct 21 16:53:03.978: INFO: Waiting for Pod statefulset-3339/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 21 16:53:13.998: INFO: Deleting all statefulset in ns statefulset-3339
Oct 21 16:53:14.006: INFO: Scaling statefulset ss2 to 0
Oct 21 16:53:34.046: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 16:53:34.055: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:53:34.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3339" for this suite.
Oct 21 16:53:42.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:53:42.447: INFO: namespace statefulset-3339 deletion completed in 8.341159886s

• [SLOW TEST:150.841 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:53:42.448: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3613
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1021 16:53:48.757243      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 21 16:53:48.757: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:53:48.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3613" for this suite.
Oct 21 16:53:56.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:53:57.208: INFO: namespace gc-3613 deletion completed in 8.438578509s

• [SLOW TEST:14.761 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:53:57.210: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1937
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 16:53:57.498: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Oct 21 16:53:57.534: INFO: Number of nodes with available pods: 0
Oct 21 16:53:57.534: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 16:53:58.601: INFO: Number of nodes with available pods: 0
Oct 21 16:53:58.601: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 16:53:59.555: INFO: Number of nodes with available pods: 3
Oct 21 16:53:59.555: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Oct 21 16:53:59.623: INFO: Wrong image for pod: daemon-set-5dmtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:53:59.623: INFO: Wrong image for pod: daemon-set-djmmq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:53:59.623: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:00.645: INFO: Wrong image for pod: daemon-set-5dmtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:00.645: INFO: Wrong image for pod: daemon-set-djmmq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:00.645: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:01.645: INFO: Wrong image for pod: daemon-set-5dmtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:01.646: INFO: Wrong image for pod: daemon-set-djmmq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:01.646: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:02.646: INFO: Wrong image for pod: daemon-set-5dmtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:02.646: INFO: Pod daemon-set-5dmtz is not available
Oct 21 16:54:02.646: INFO: Wrong image for pod: daemon-set-djmmq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:02.646: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:03.647: INFO: Wrong image for pod: daemon-set-5dmtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:03.647: INFO: Pod daemon-set-5dmtz is not available
Oct 21 16:54:03.647: INFO: Wrong image for pod: daemon-set-djmmq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:03.647: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:04.647: INFO: Wrong image for pod: daemon-set-5dmtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:04.647: INFO: Pod daemon-set-5dmtz is not available
Oct 21 16:54:04.647: INFO: Wrong image for pod: daemon-set-djmmq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:04.647: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:05.646: INFO: Wrong image for pod: daemon-set-5dmtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:05.646: INFO: Pod daemon-set-5dmtz is not available
Oct 21 16:54:05.646: INFO: Wrong image for pod: daemon-set-djmmq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:05.646: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:06.645: INFO: Wrong image for pod: daemon-set-5dmtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:06.645: INFO: Pod daemon-set-5dmtz is not available
Oct 21 16:54:06.645: INFO: Wrong image for pod: daemon-set-djmmq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:06.645: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:07.649: INFO: Wrong image for pod: daemon-set-5dmtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:07.649: INFO: Pod daemon-set-5dmtz is not available
Oct 21 16:54:07.649: INFO: Wrong image for pod: daemon-set-djmmq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:07.649: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:08.645: INFO: Wrong image for pod: daemon-set-djmmq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:08.645: INFO: Pod daemon-set-gclc4 is not available
Oct 21 16:54:08.645: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:09.646: INFO: Wrong image for pod: daemon-set-djmmq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:09.646: INFO: Pod daemon-set-gclc4 is not available
Oct 21 16:54:09.646: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:10.645: INFO: Wrong image for pod: daemon-set-djmmq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:10.645: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:11.667: INFO: Wrong image for pod: daemon-set-djmmq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:11.667: INFO: Pod daemon-set-djmmq is not available
Oct 21 16:54:11.667: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:12.646: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:12.646: INFO: Pod daemon-set-xj4dr is not available
Oct 21 16:54:13.647: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:13.647: INFO: Pod daemon-set-xj4dr is not available
Oct 21 16:54:14.646: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:14.646: INFO: Pod daemon-set-xj4dr is not available
Oct 21 16:54:15.943: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:15.943: INFO: Pod daemon-set-xj4dr is not available
Oct 21 16:54:16.645: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:17.644: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:17.644: INFO: Pod daemon-set-ggh59 is not available
Oct 21 16:54:18.643: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:18.643: INFO: Pod daemon-set-ggh59 is not available
Oct 21 16:54:20.065: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:20.065: INFO: Pod daemon-set-ggh59 is not available
Oct 21 16:54:20.646: INFO: Wrong image for pod: daemon-set-ggh59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 16:54:20.646: INFO: Pod daemon-set-ggh59 is not available
Oct 21 16:54:21.648: INFO: Pod daemon-set-b2pg4 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Oct 21 16:54:21.689: INFO: Number of nodes with available pods: 2
Oct 21 16:54:21.689: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 16:54:22.716: INFO: Number of nodes with available pods: 2
Oct 21 16:54:22.716: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 16:54:23.718: INFO: Number of nodes with available pods: 3
Oct 21 16:54:23.719: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1937, will wait for the garbage collector to delete the pods
Oct 21 16:54:23.871: INFO: Deleting DaemonSet.extensions daemon-set took: 23.094734ms
Oct 21 16:54:23.977: INFO: Terminating DaemonSet.extensions daemon-set pods took: 105.708836ms
Oct 21 16:54:36.185: INFO: Number of nodes with available pods: 0
Oct 21 16:54:36.185: INFO: Number of running nodes: 0, number of available pods: 0
Oct 21 16:54:36.197: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1937/daemonsets","resourceVersion":"36069"},"items":null}

Oct 21 16:54:36.205: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1937/pods","resourceVersion":"36069"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:54:36.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1937" for this suite.
Oct 21 16:54:44.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:54:44.609: INFO: namespace daemonsets-1937 deletion completed in 8.347250287s

• [SLOW TEST:47.399 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:54:44.609: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7304
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Oct 21 16:54:44.846: INFO: Waiting up to 5m0s for pod "var-expansion-7bb8888b-f423-11e9-ae8d-bacadc8895d2" in namespace "var-expansion-7304" to be "success or failure"
Oct 21 16:54:44.855: INFO: Pod "var-expansion-7bb8888b-f423-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.242699ms
Oct 21 16:54:46.865: INFO: Pod "var-expansion-7bb8888b-f423-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018768504s
STEP: Saw pod success
Oct 21 16:54:46.865: INFO: Pod "var-expansion-7bb8888b-f423-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:54:46.883: INFO: Trying to get logs from node 10.134.235.67 pod var-expansion-7bb8888b-f423-11e9-ae8d-bacadc8895d2 container dapi-container: <nil>
STEP: delete the pod
Oct 21 16:54:46.942: INFO: Waiting for pod var-expansion-7bb8888b-f423-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:54:46.958: INFO: Pod var-expansion-7bb8888b-f423-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:54:46.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7304" for this suite.
Oct 21 16:54:53.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:54:53.708: INFO: namespace var-expansion-7304 deletion completed in 6.736062216s

• [SLOW TEST:9.099 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:54:53.709: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-88
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 16:54:53.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-88'
Oct 21 16:54:54.064: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 21 16:54:54.064: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Oct 21 16:54:54.080: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Oct 21 16:54:54.082: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Oct 21 16:54:54.093: INFO: scanned /root for discovery docs: <nil>
Oct 21 16:54:54.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-88'
Oct 21 16:55:10.068: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 21 16:55:10.068: INFO: stdout: "Created e2e-test-nginx-rc-d6e3c041a480c5667db5f7cd03b8a606\nScaling up e2e-test-nginx-rc-d6e3c041a480c5667db5f7cd03b8a606 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d6e3c041a480c5667db5f7cd03b8a606 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d6e3c041a480c5667db5f7cd03b8a606 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Oct 21 16:55:10.068: INFO: stdout: "Created e2e-test-nginx-rc-d6e3c041a480c5667db5f7cd03b8a606\nScaling up e2e-test-nginx-rc-d6e3c041a480c5667db5f7cd03b8a606 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d6e3c041a480c5667db5f7cd03b8a606 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d6e3c041a480c5667db5f7cd03b8a606 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Oct 21 16:55:10.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-88'
Oct 21 16:55:10.169: INFO: stderr: ""
Oct 21 16:55:10.169: INFO: stdout: "e2e-test-nginx-rc-d6e3c041a480c5667db5f7cd03b8a606-xjc2b e2e-test-nginx-rc-s95n4 "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Oct 21 16:55:15.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-88'
Oct 21 16:55:15.261: INFO: stderr: ""
Oct 21 16:55:15.261: INFO: stdout: "e2e-test-nginx-rc-d6e3c041a480c5667db5f7cd03b8a606-xjc2b "
Oct 21 16:55:15.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods e2e-test-nginx-rc-d6e3c041a480c5667db5f7cd03b8a606-xjc2b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-88'
Oct 21 16:55:15.371: INFO: stderr: ""
Oct 21 16:55:15.371: INFO: stdout: "true"
Oct 21 16:55:15.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods e2e-test-nginx-rc-d6e3c041a480c5667db5f7cd03b8a606-xjc2b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-88'
Oct 21 16:55:15.474: INFO: stderr: ""
Oct 21 16:55:15.474: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Oct 21 16:55:15.474: INFO: e2e-test-nginx-rc-d6e3c041a480c5667db5f7cd03b8a606-xjc2b is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1486
Oct 21 16:55:15.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 delete rc e2e-test-nginx-rc --namespace=kubectl-88'
Oct 21 16:55:15.611: INFO: stderr: ""
Oct 21 16:55:15.611: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:55:15.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-88" for this suite.
Oct 21 16:55:39.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:55:40.332: INFO: namespace kubectl-88 deletion completed in 24.707265078s

• [SLOW TEST:46.623 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:55:40.332: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8405
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1174
STEP: creating the pod
Oct 21 16:55:40.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 create -f - --namespace=kubectl-8405'
Oct 21 16:55:40.764: INFO: stderr: ""
Oct 21 16:55:40.764: INFO: stdout: "pod/pause created\n"
Oct 21 16:55:40.764: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct 21 16:55:40.764: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8405" to be "running and ready"
Oct 21 16:55:40.777: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 12.969128ms
Oct 21 16:55:42.787: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.022649227s
Oct 21 16:55:42.787: INFO: Pod "pause" satisfied condition "running and ready"
Oct 21 16:55:42.787: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Oct 21 16:55:42.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 label pods pause testing-label=testing-label-value --namespace=kubectl-8405'
Oct 21 16:55:42.886: INFO: stderr: ""
Oct 21 16:55:42.886: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Oct 21 16:55:42.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pod pause -L testing-label --namespace=kubectl-8405'
Oct 21 16:55:42.991: INFO: stderr: ""
Oct 21 16:55:42.991: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Oct 21 16:55:42.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 label pods pause testing-label- --namespace=kubectl-8405'
Oct 21 16:55:43.104: INFO: stderr: ""
Oct 21 16:55:43.104: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Oct 21 16:55:43.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pod pause -L testing-label --namespace=kubectl-8405'
Oct 21 16:55:43.194: INFO: stderr: ""
Oct 21 16:55:43.194: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1181
STEP: using delete to clean up resources
Oct 21 16:55:43.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 delete --grace-period=0 --force -f - --namespace=kubectl-8405'
Oct 21 16:55:43.423: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 16:55:43.423: INFO: stdout: "pod \"pause\" force deleted\n"
Oct 21 16:55:43.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get rc,svc -l name=pause --no-headers --namespace=kubectl-8405'
Oct 21 16:55:43.605: INFO: stderr: "No resources found.\n"
Oct 21 16:55:43.605: INFO: stdout: ""
Oct 21 16:55:43.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 get pods -l name=pause --namespace=kubectl-8405 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 21 16:55:43.705: INFO: stderr: ""
Oct 21 16:55:43.705: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:55:43.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8405" for this suite.
Oct 21 16:55:49.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:55:50.042: INFO: namespace kubectl-8405 deletion completed in 6.322548324s

• [SLOW TEST:9.710 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:55:50.043: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2617
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Oct 21 16:55:50.253: INFO: namespace kubectl-2617
Oct 21 16:55:50.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 create -f - --namespace=kubectl-2617'
Oct 21 16:55:50.573: INFO: stderr: ""
Oct 21 16:55:50.573: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 21 16:55:51.582: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:55:51.582: INFO: Found 0 / 1
Oct 21 16:55:52.582: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:55:52.582: INFO: Found 1 / 1
Oct 21 16:55:52.582: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 21 16:55:52.593: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:55:52.593: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 21 16:55:52.593: INFO: wait on redis-master startup in kubectl-2617 
Oct 21 16:55:52.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 logs redis-master-g589b redis-master --namespace=kubectl-2617'
Oct 21 16:55:52.781: INFO: stderr: ""
Oct 21 16:55:52.781: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Oct 16:55:51.744 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Oct 16:55:51.744 # Server started, Redis version 3.2.12\n1:M 21 Oct 16:55:51.744 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Oct 16:55:51.744 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Oct 21 16:55:52.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-2617'
Oct 21 16:55:52.937: INFO: stderr: ""
Oct 21 16:55:52.937: INFO: stdout: "service/rm2 exposed\n"
Oct 21 16:55:52.946: INFO: Service rm2 in namespace kubectl-2617 found.
STEP: exposing service
Oct 21 16:55:54.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-2617'
Oct 21 16:55:55.084: INFO: stderr: ""
Oct 21 16:55:55.084: INFO: stdout: "service/rm3 exposed\n"
Oct 21 16:55:55.092: INFO: Service rm3 in namespace kubectl-2617 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:55:57.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2617" for this suite.
Oct 21 16:56:21.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:56:21.490: INFO: namespace kubectl-2617 deletion completed in 24.367988683s

• [SLOW TEST:31.447 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:56:21.493: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7977
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-b5788a1c-f423-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume secrets
Oct 21 16:56:21.741: INFO: Waiting up to 5m0s for pod "pod-secrets-b57a54a6-f423-11e9-ae8d-bacadc8895d2" in namespace "secrets-7977" to be "success or failure"
Oct 21 16:56:21.754: INFO: Pod "pod-secrets-b57a54a6-f423-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.876433ms
Oct 21 16:56:23.763: INFO: Pod "pod-secrets-b57a54a6-f423-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022625256s
STEP: Saw pod success
Oct 21 16:56:23.764: INFO: Pod "pod-secrets-b57a54a6-f423-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 16:56:23.774: INFO: Trying to get logs from node 10.134.235.118 pod pod-secrets-b57a54a6-f423-11e9-ae8d-bacadc8895d2 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 16:56:23.839: INFO: Waiting for pod pod-secrets-b57a54a6-f423-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 16:56:23.850: INFO: Pod pod-secrets-b57a54a6-f423-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:56:23.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7977" for this suite.
Oct 21 16:56:29.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:56:30.249: INFO: namespace secrets-7977 deletion completed in 6.385021781s

• [SLOW TEST:8.756 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:56:30.250: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-3749
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct 21 16:56:30.467: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:56:33.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3749" for this suite.
Oct 21 16:56:39.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:56:40.043: INFO: namespace init-container-3749 deletion completed in 6.417812749s

• [SLOW TEST:9.793 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:56:40.043: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1362
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 16:57:06.310: INFO: Container started at 2019-10-21 16:56:41 +0000 UTC, pod became ready at 2019-10-21 16:57:04 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:57:06.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1362" for this suite.
Oct 21 16:57:30.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:57:30.976: INFO: namespace container-probe-1362 deletion completed in 24.64987733s

• [SLOW TEST:50.934 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:57:30.977: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-119
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-zx56
STEP: Creating a pod to test atomic-volume-subpath
Oct 21 16:57:31.246: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-zx56" in namespace "subpath-119" to be "success or failure"
Oct 21 16:57:31.257: INFO: Pod "pod-subpath-test-configmap-zx56": Phase="Pending", Reason="", readiness=false. Elapsed: 10.443584ms
Oct 21 16:57:33.268: INFO: Pod "pod-subpath-test-configmap-zx56": Phase="Running", Reason="", readiness=true. Elapsed: 2.021319721s
Oct 21 16:57:35.277: INFO: Pod "pod-subpath-test-configmap-zx56": Phase="Running", Reason="", readiness=true. Elapsed: 4.0309176s
Oct 21 16:57:37.287: INFO: Pod "pod-subpath-test-configmap-zx56": Phase="Running", Reason="", readiness=true. Elapsed: 6.041074124s
Oct 21 16:57:39.298: INFO: Pod "pod-subpath-test-configmap-zx56": Phase="Running", Reason="", readiness=true. Elapsed: 8.051497881s
Oct 21 16:57:41.308: INFO: Pod "pod-subpath-test-configmap-zx56": Phase="Running", Reason="", readiness=true. Elapsed: 10.06156474s
Oct 21 16:57:43.317: INFO: Pod "pod-subpath-test-configmap-zx56": Phase="Running", Reason="", readiness=true. Elapsed: 12.070985178s
Oct 21 16:57:45.327: INFO: Pod "pod-subpath-test-configmap-zx56": Phase="Running", Reason="", readiness=true. Elapsed: 14.0809453s
Oct 21 16:57:47.337: INFO: Pod "pod-subpath-test-configmap-zx56": Phase="Running", Reason="", readiness=true. Elapsed: 16.090358627s
Oct 21 16:57:49.346: INFO: Pod "pod-subpath-test-configmap-zx56": Phase="Running", Reason="", readiness=true. Elapsed: 18.100293283s
Oct 21 16:57:51.356: INFO: Pod "pod-subpath-test-configmap-zx56": Phase="Running", Reason="", readiness=true. Elapsed: 20.110068795s
Oct 21 16:57:53.366: INFO: Pod "pod-subpath-test-configmap-zx56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.119841055s
STEP: Saw pod success
Oct 21 16:57:53.366: INFO: Pod "pod-subpath-test-configmap-zx56" satisfied condition "success or failure"
Oct 21 16:57:53.375: INFO: Trying to get logs from node 10.134.235.67 pod pod-subpath-test-configmap-zx56 container test-container-subpath-configmap-zx56: <nil>
STEP: delete the pod
Oct 21 16:57:53.423: INFO: Waiting for pod pod-subpath-test-configmap-zx56 to disappear
Oct 21 16:57:53.433: INFO: Pod pod-subpath-test-configmap-zx56 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-zx56
Oct 21 16:57:53.433: INFO: Deleting pod "pod-subpath-test-configmap-zx56" in namespace "subpath-119"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 16:57:53.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-119" for this suite.
Oct 21 16:57:59.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:58:00.113: INFO: namespace subpath-119 deletion completed in 6.655595733s

• [SLOW TEST:29.136 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 16:58:00.113: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5512
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-5512
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-5512
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5512
Oct 21 16:58:00.365: INFO: Found 0 stateful pods, waiting for 1
Oct 21 16:58:10.376: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Oct 21 16:58:10.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 16:58:10.783: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 16:58:10.783: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 16:58:10.783: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 16:58:10.793: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 21 16:58:20.814: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 16:58:20.814: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 16:58:20.855: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 21 16:58:20.855: INFO: ss-0  10.134.235.118  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  }]
Oct 21 16:58:20.855: INFO: ss-1                  Pending         []
Oct 21 16:58:20.855: INFO: 
Oct 21 16:58:20.855: INFO: StatefulSet ss has not reached scale 3, at 2
Oct 21 16:58:21.866: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988804042s
Oct 21 16:58:22.876: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.977947004s
Oct 21 16:58:23.886: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.967382864s
Oct 21 16:58:24.899: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.957545422s
Oct 21 16:58:25.913: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.944689953s
Oct 21 16:58:27.054: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.930785397s
Oct 21 16:58:28.071: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.79000659s
Oct 21 16:58:29.086: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.772602506s
Oct 21 16:58:30.096: INFO: Verifying statefulset ss doesn't scale past 3 for another 757.374088ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5512
Oct 21 16:58:31.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:58:31.474: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 21 16:58:31.474: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 16:58:31.474: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 16:58:31.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:58:31.790: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 21 16:58:31.790: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 16:58:31.790: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 16:58:31.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:58:32.189: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 21 16:58:32.189: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 16:58:32.189: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 16:58:32.198: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:58:32.198: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:58:32.198: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Oct 21 16:58:32.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 16:58:32.560: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 16:58:32.560: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 16:58:32.560: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 16:58:32.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 16:58:32.878: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 16:58:32.878: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 16:58:32.878: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 16:58:32.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 16:58:33.206: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 16:58:33.206: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 16:58:33.206: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 16:58:33.206: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 16:58:33.215: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Oct 21 16:58:43.235: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 16:58:43.235: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 16:58:43.235: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 16:58:43.267: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 21 16:58:43.267: INFO: ss-0  10.134.235.118  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  }]
Oct 21 16:58:43.267: INFO: ss-1  10.134.235.67   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  }]
Oct 21 16:58:43.267: INFO: ss-2  10.134.235.77   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  }]
Oct 21 16:58:43.267: INFO: 
Oct 21 16:58:43.267: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 21 16:58:44.276: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 21 16:58:44.276: INFO: ss-0  10.134.235.118  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  }]
Oct 21 16:58:44.276: INFO: ss-1  10.134.235.67   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  }]
Oct 21 16:58:44.276: INFO: ss-2  10.134.235.77   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  }]
Oct 21 16:58:44.276: INFO: 
Oct 21 16:58:44.276: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 21 16:58:45.286: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 21 16:58:45.286: INFO: ss-0  10.134.235.118  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  }]
Oct 21 16:58:45.286: INFO: ss-1  10.134.235.67   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  }]
Oct 21 16:58:45.286: INFO: ss-2  10.134.235.77   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  }]
Oct 21 16:58:45.286: INFO: 
Oct 21 16:58:45.286: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 21 16:58:46.295: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 21 16:58:46.295: INFO: ss-0  10.134.235.118  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  }]
Oct 21 16:58:46.295: INFO: ss-1  10.134.235.67   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  }]
Oct 21 16:58:46.295: INFO: ss-2  10.134.235.77   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  }]
Oct 21 16:58:46.295: INFO: 
Oct 21 16:58:46.295: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 21 16:58:47.306: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 21 16:58:47.306: INFO: ss-0  10.134.235.118  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  }]
Oct 21 16:58:47.306: INFO: ss-1  10.134.235.67   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  }]
Oct 21 16:58:47.306: INFO: ss-2  10.134.235.77   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  }]
Oct 21 16:58:47.306: INFO: 
Oct 21 16:58:47.306: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 21 16:58:48.314: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 21 16:58:48.315: INFO: ss-0  10.134.235.118  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  }]
Oct 21 16:58:48.315: INFO: ss-1  10.134.235.67   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  }]
Oct 21 16:58:48.315: INFO: ss-2  10.134.235.77   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  }]
Oct 21 16:58:48.315: INFO: 
Oct 21 16:58:48.315: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 21 16:58:49.325: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 21 16:58:49.325: INFO: ss-0  10.134.235.118  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  }]
Oct 21 16:58:49.325: INFO: ss-2  10.134.235.77   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  }]
Oct 21 16:58:49.325: INFO: 
Oct 21 16:58:49.325: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 21 16:58:50.336: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 21 16:58:50.336: INFO: ss-0  10.134.235.118  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:00 +0000 UTC  }]
Oct 21 16:58:50.336: INFO: ss-2  10.134.235.77   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  }]
Oct 21 16:58:50.336: INFO: 
Oct 21 16:58:50.336: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 21 16:58:51.345: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Oct 21 16:58:51.345: INFO: ss-2  10.134.235.77  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  }]
Oct 21 16:58:51.345: INFO: 
Oct 21 16:58:51.345: INFO: StatefulSet ss has not reached scale 0, at 1
Oct 21 16:58:52.355: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Oct 21 16:58:52.355: INFO: ss-2  10.134.235.77  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:58:20 +0000 UTC  }]
Oct 21 16:58:52.355: INFO: 
Oct 21 16:58:52.355: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5512
Oct 21 16:58:53.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:58:53.578: INFO: rc: 1
Oct 21 16:58:53.578: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc00158bb90 exit status 1 <nil> <nil> true [0xc003333078 0xc003333090 0xc0033330a8] [0xc003333078 0xc003333090 0xc0033330a8] [0xc003333088 0xc0033330a0] [0xb916c0 0xb916c0] 0xc0029f29c0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Oct 21 16:59:03.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:59:03.665: INFO: rc: 1
Oct 21 16:59:03.666: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0031a1f20 exit status 1 <nil> <nil> true [0xc00208c1f8 0xc00208c210 0xc00208c228] [0xc00208c1f8 0xc00208c210 0xc00208c228] [0xc00208c208 0xc00208c220] [0xb916c0 0xb916c0] 0xc001b8ea20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 16:59:13.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:59:13.760: INFO: rc: 1
Oct 21 16:59:13.760: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002a09b00 exit status 1 <nil> <nil> true [0xc002bc69a8 0xc002bc69d8 0xc002bc6a18] [0xc002bc69a8 0xc002bc69d8 0xc002bc6a18] [0xc002bc69c8 0xc002bc6a08] [0xb916c0 0xb916c0] 0xc002a23980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 16:59:23.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:59:23.870: INFO: rc: 1
Oct 21 16:59:23.871: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00158bf50 exit status 1 <nil> <nil> true [0xc0033330b0 0xc0033330c8 0xc0033330e0] [0xc0033330b0 0xc0033330c8 0xc0033330e0] [0xc0033330c0 0xc0033330d8] [0xb916c0 0xb916c0] 0xc0029f2ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 16:59:33.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:59:33.954: INFO: rc: 1
Oct 21 16:59:33.954: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001210330 exit status 1 <nil> <nil> true [0xc0009a6320 0xc0009a6850 0xc0009a7118] [0xc0009a6320 0xc0009a6850 0xc0009a7118] [0xc0009a65b0 0xc0009a6fd8] [0xb916c0 0xb916c0] 0xc0027d02a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 16:59:43.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:59:44.036: INFO: rc: 1
Oct 21 16:59:44.036: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028a0330 exit status 1 <nil> <nil> true [0xc00098a4b0 0xc00098a560 0xc00098a610] [0xc00098a4b0 0xc00098a560 0xc00098a610] [0xc00098a548 0xc00098a5b8] [0xb916c0 0xb916c0] 0xc00243a4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 16:59:54.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:59:54.460: INFO: rc: 1
Oct 21 16:59:54.461: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002bca330 exit status 1 <nil> <nil> true [0xc0009c0238 0xc0009c05a8 0xc0009c0688] [0xc0009c0238 0xc0009c05a8 0xc0009c0688] [0xc0009c04f8 0xc0009c05d0] [0xb916c0 0xb916c0] 0xc002960900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:00:04.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:00:04.555: INFO: rc: 1
Oct 21 17:00:04.555: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002bca6c0 exit status 1 <nil> <nil> true [0xc0009c0838 0xc0009c0ac0 0xc0009c0ba0] [0xc0009c0838 0xc0009c0ac0 0xc0009c0ba0] [0xc0009c09e0 0xc0009c0b58] [0xb916c0 0xb916c0] 0xc002961200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:00:14.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:00:14.675: INFO: rc: 1
Oct 21 17:00:14.675: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028a06c0 exit status 1 <nil> <nil> true [0xc00098a620 0xc00098a6d8 0xc00098a730] [0xc00098a620 0xc00098a6d8 0xc00098a730] [0xc00098a648 0xc00098a720] [0xb916c0 0xb916c0] 0xc00243bd40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:00:24.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:00:24.772: INFO: rc: 1
Oct 21 17:00:24.772: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028a0a50 exit status 1 <nil> <nil> true [0xc00098a740 0xc00098a760 0xc00098a798] [0xc00098a740 0xc00098a760 0xc00098a798] [0xc00098a758 0xc00098a788] [0xb916c0 0xb916c0] 0xc002888600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:00:34.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:00:34.871: INFO: rc: 1
Oct 21 17:00:34.871: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001210750 exit status 1 <nil> <nil> true [0xc0009a7490 0xc0009a76b8 0xc0009a7b90] [0xc0009a7490 0xc0009a76b8 0xc0009a7b90] [0xc0009a7620 0xc0009a7aa0] [0xb916c0 0xb916c0] 0xc0027d0660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:00:44.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:00:44.968: INFO: rc: 1
Oct 21 17:00:44.968: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002986390 exit status 1 <nil> <nil> true [0xc000010010 0xc000011b58 0xc000011c58] [0xc000010010 0xc000011b58 0xc000011c58] [0xc000011aa8 0xc000011c30] [0xb916c0 0xb916c0] 0xc0025d0480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:00:54.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:00:55.051: INFO: rc: 1
Oct 21 17:00:55.051: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001210d20 exit status 1 <nil> <nil> true [0xc0009a7ba8 0xc0009a7c58 0xc0009a7c90] [0xc0009a7ba8 0xc0009a7c58 0xc0009a7c90] [0xc0009a7c10 0xc0009a7c70] [0xb916c0 0xb916c0] 0xc0027d0a20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:01:05.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:01:05.148: INFO: rc: 1
Oct 21 17:01:05.148: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002bcaa80 exit status 1 <nil> <nil> true [0xc0009c0c30 0xc0009c0de0 0xc0009c12d8] [0xc0009c0c30 0xc0009c0de0 0xc0009c12d8] [0xc0009c0d58 0xc0009c10c8] [0xb916c0 0xb916c0] 0xc0029617a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:01:15.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:01:15.272: INFO: rc: 1
Oct 21 17:01:15.272: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0012110b0 exit status 1 <nil> <nil> true [0xc0009a7cd0 0xc0009a7d60 0xc0009a7f10] [0xc0009a7cd0 0xc0009a7d60 0xc0009a7f10] [0xc0009a7d50 0xc0009a7e88] [0xb916c0 0xb916c0] 0xc0027d0d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:01:25.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:01:25.368: INFO: rc: 1
Oct 21 17:01:25.368: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001211470 exit status 1 <nil> <nil> true [0xc0009a7f30 0xc0009a7fb8 0xc0000cc4c0] [0xc0009a7f30 0xc0009a7fb8 0xc0000cc4c0] [0xc0009a7fa8 0xc0000cc090] [0xb916c0 0xb916c0] 0xc0027d10e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:01:35.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:01:35.450: INFO: rc: 1
Oct 21 17:01:35.450: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002bca360 exit status 1 <nil> <nil> true [0xc0009a6320 0xc0009a6850 0xc0009a7118] [0xc0009a6320 0xc0009a6850 0xc0009a7118] [0xc0009a65b0 0xc0009a6fd8] [0xb916c0 0xb916c0] 0xc00243ab40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:01:45.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:01:45.538: INFO: rc: 1
Oct 21 17:01:45.538: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001210360 exit status 1 <nil> <nil> true [0xc0009c0238 0xc0009c05a8 0xc0009c0688] [0xc0009c0238 0xc0009c05a8 0xc0009c0688] [0xc0009c04f8 0xc0009c05d0] [0xb916c0 0xb916c0] 0xc002960600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:01:55.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:01:55.640: INFO: rc: 1
Oct 21 17:01:55.640: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0029863c0 exit status 1 <nil> <nil> true [0xc000010010 0xc000011b58 0xc000011c58] [0xc000010010 0xc000011b58 0xc000011c58] [0xc000011aa8 0xc000011c30] [0xb916c0 0xb916c0] 0xc0025d0480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:02:05.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:02:05.736: INFO: rc: 1
Oct 21 17:02:05.736: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028a0390 exit status 1 <nil> <nil> true [0xc0000cc090 0xc00098a4b0 0xc00098a560] [0xc0000cc090 0xc00098a4b0 0xc00098a560] [0xc0000ccad0 0xc00098a548] [0xb916c0 0xb916c0] 0xc0027d02a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:02:15.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:02:15.830: INFO: rc: 1
Oct 21 17:02:15.830: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002bca720 exit status 1 <nil> <nil> true [0xc0009a7490 0xc0009a76b8 0xc0009a7b90] [0xc0009a7490 0xc0009a76b8 0xc0009a7b90] [0xc0009a7620 0xc0009a7aa0] [0xb916c0 0xb916c0] 0xc002888240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:02:25.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:02:25.927: INFO: rc: 1
Oct 21 17:02:25.927: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002bcaae0 exit status 1 <nil> <nil> true [0xc0009a7ba8 0xc0009a7c58 0xc0009a7c90] [0xc0009a7ba8 0xc0009a7c58 0xc0009a7c90] [0xc0009a7c10 0xc0009a7c70] [0xb916c0 0xb916c0] 0xc002888960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:02:35.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:02:36.013: INFO: rc: 1
Oct 21 17:02:36.013: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002bcae40 exit status 1 <nil> <nil> true [0xc0009a7cd0 0xc0009a7d60 0xc0009a7f10] [0xc0009a7cd0 0xc0009a7d60 0xc0009a7f10] [0xc0009a7d50 0xc0009a7e88] [0xb916c0 0xb916c0] 0xc002889020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:02:46.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:02:46.120: INFO: rc: 1
Oct 21 17:02:46.120: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002bcb320 exit status 1 <nil> <nil> true [0xc0009a7f30 0xc0009a7fb8 0xc001cce038] [0xc0009a7f30 0xc0009a7fb8 0xc001cce038] [0xc0009a7fa8 0xc001cce020] [0xb916c0 0xb916c0] 0xc002889680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:02:56.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:02:56.221: INFO: rc: 1
Oct 21 17:02:56.221: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002986750 exit status 1 <nil> <nil> true [0xc000011c88 0xc000011d88 0xc000011da0] [0xc000011c88 0xc000011d88 0xc000011da0] [0xc000011d60 0xc000011d98] [0xb916c0 0xb916c0] 0xc0025d0840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:03:06.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:03:06.312: INFO: rc: 1
Oct 21 17:03:06.312: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0012107e0 exit status 1 <nil> <nil> true [0xc0009c0838 0xc0009c0ac0 0xc0009c0ba0] [0xc0009c0838 0xc0009c0ac0 0xc0009c0ba0] [0xc0009c09e0 0xc0009c0b58] [0xb916c0 0xb916c0] 0xc002960de0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:03:16.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:03:16.415: INFO: rc: 1
Oct 21 17:03:16.415: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001210de0 exit status 1 <nil> <nil> true [0xc0009c0c30 0xc0009c0de0 0xc0009c12d8] [0xc0009c0c30 0xc0009c0de0 0xc0009c12d8] [0xc0009c0d58 0xc0009c10c8] [0xb916c0 0xb916c0] 0xc002961620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:03:26.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:03:26.537: INFO: rc: 1
Oct 21 17:03:26.537: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002986ae0 exit status 1 <nil> <nil> true [0xc000011e00 0xc000011ea8 0xc000011ee8] [0xc000011e00 0xc000011ea8 0xc000011ee8] [0xc000011e88 0xc000011ed8] [0xb916c0 0xb916c0] 0xc0025d0d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:03:36.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:03:36.660: INFO: rc: 1
Oct 21 17:03:36.660: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028a0420 exit status 1 <nil> <nil> true [0xc001cce058 0xc001cce0a8 0xc001cce0d8] [0xc001cce058 0xc001cce0a8 0xc001cce0d8] [0xc001cce088 0xc001cce0d0] [0xb916c0 0xb916c0] 0xc0027d0360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:03:46.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:03:46.760: INFO: rc: 1
Oct 21 17:03:46.760: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028a0330 exit status 1 <nil> <nil> true [0xc0009a6068 0xc0009a65b0 0xc0009a6fd8] [0xc0009a6068 0xc0009a65b0 0xc0009a6fd8] [0xc0009a6498 0xc0009a6d50] [0xb916c0 0xb916c0] 0xc00243a4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 17:03:56.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 exec --namespace=statefulset-5512 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:03:56.851: INFO: rc: 1
Oct 21 17:03:56.851: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Oct 21 17:03:56.851: INFO: Scaling statefulset ss to 0
Oct 21 17:03:56.882: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 21 17:03:56.889: INFO: Deleting all statefulset in ns statefulset-5512
Oct 21 17:03:56.897: INFO: Scaling statefulset ss to 0
Oct 21 17:03:56.925: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 17:03:56.941: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:03:56.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5512" for this suite.
Oct 21 17:04:05.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:04:05.409: INFO: namespace statefulset-5512 deletion completed in 8.425339785s

• [SLOW TEST:365.295 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:04:05.409: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7380
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-c9fa9971-f424-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume configMaps
Oct 21 17:04:05.647: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c9fc434f-f424-11e9-ae8d-bacadc8895d2" in namespace "projected-7380" to be "success or failure"
Oct 21 17:04:05.657: INFO: Pod "pod-projected-configmaps-c9fc434f-f424-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.0401ms
Oct 21 17:04:07.670: INFO: Pod "pod-projected-configmaps-c9fc434f-f424-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022845774s
STEP: Saw pod success
Oct 21 17:04:07.670: INFO: Pod "pod-projected-configmaps-c9fc434f-f424-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:04:07.683: INFO: Trying to get logs from node 10.134.235.67 pod pod-projected-configmaps-c9fc434f-f424-11e9-ae8d-bacadc8895d2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 17:04:07.767: INFO: Waiting for pod pod-projected-configmaps-c9fc434f-f424-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:04:07.779: INFO: Pod pod-projected-configmaps-c9fc434f-f424-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:04:07.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7380" for this suite.
Oct 21 17:04:13.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:04:14.385: INFO: namespace projected-7380 deletion completed in 6.590334497s

• [SLOW TEST:8.976 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:04:14.385: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2194
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 21 17:04:14.618: INFO: Waiting up to 5m0s for pod "pod-cf558a72-f424-11e9-ae8d-bacadc8895d2" in namespace "emptydir-2194" to be "success or failure"
Oct 21 17:04:14.629: INFO: Pod "pod-cf558a72-f424-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.863682ms
Oct 21 17:04:16.638: INFO: Pod "pod-cf558a72-f424-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020466838s
STEP: Saw pod success
Oct 21 17:04:16.639: INFO: Pod "pod-cf558a72-f424-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:04:16.648: INFO: Trying to get logs from node 10.134.235.118 pod pod-cf558a72-f424-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 17:04:16.715: INFO: Waiting for pod pod-cf558a72-f424-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:04:16.722: INFO: Pod pod-cf558a72-f424-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:04:16.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2194" for this suite.
Oct 21 17:04:22.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:04:23.121: INFO: namespace emptydir-2194 deletion completed in 6.387444537s

• [SLOW TEST:8.737 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:04:23.122: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-9791
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Oct 21 17:04:23.352: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9791" to be "success or failure"
Oct 21 17:04:23.363: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 11.290882ms
Oct 21 17:04:25.374: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022737246s
STEP: Saw pod success
Oct 21 17:04:25.374: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Oct 21 17:04:25.383: INFO: Trying to get logs from node 10.134.235.67 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Oct 21 17:04:25.438: INFO: Waiting for pod pod-host-path-test to disappear
Oct 21 17:04:25.446: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:04:25.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-9791" for this suite.
Oct 21 17:04:31.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:04:31.868: INFO: namespace hostpath-9791 deletion completed in 6.402750864s

• [SLOW TEST:8.746 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:04:31.868: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6709
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct 21 17:04:32.079: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:04:36.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6709" for this suite.
Oct 21 17:05:00.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:05:01.026: INFO: namespace init-container-6709 deletion completed in 24.385144861s

• [SLOW TEST:29.158 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:05:01.026: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9568
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Oct 21 17:05:01.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 create -f - --namespace=kubectl-9568'
Oct 21 17:05:01.703: INFO: stderr: ""
Oct 21 17:05:01.703: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 21 17:05:02.715: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 17:05:02.715: INFO: Found 0 / 1
Oct 21 17:05:03.716: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 17:05:03.716: INFO: Found 1 / 1
Oct 21 17:05:03.716: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Oct 21 17:05:03.726: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 17:05:03.726: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 21 17:05:03.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 patch pod redis-master-8lg9n --namespace=kubectl-9568 -p {"metadata":{"annotations":{"x":"y"}}}'
Oct 21 17:05:03.836: INFO: stderr: ""
Oct 21 17:05:03.836: INFO: stdout: "pod/redis-master-8lg9n patched\n"
STEP: checking annotations
Oct 21 17:05:03.847: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 17:05:03.847: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:05:03.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9568" for this suite.
Oct 21 17:05:27.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:05:28.386: INFO: namespace kubectl-9568 deletion completed in 24.524945212s

• [SLOW TEST:27.360 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:05:28.388: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7324
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7324.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-7324.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7324.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7324.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-7324.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7324.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 21 17:05:32.789: INFO: DNS probes using dns-7324/dns-test-fb70a21f-f424-11e9-ae8d-bacadc8895d2 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:05:32.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7324" for this suite.
Oct 21 17:05:38.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:05:39.209: INFO: namespace dns-7324 deletion completed in 6.378752363s

• [SLOW TEST:10.822 seconds]
[sig-network] DNS
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:05:39.210: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2315
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Oct 21 17:05:40.062: INFO: Pod name wrapped-volume-race-023ef902-f425-11e9-ae8d-bacadc8895d2: Found 0 pods out of 5
Oct 21 17:05:45.079: INFO: Pod name wrapped-volume-race-023ef902-f425-11e9-ae8d-bacadc8895d2: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-023ef902-f425-11e9-ae8d-bacadc8895d2 in namespace emptydir-wrapper-2315, will wait for the garbage collector to delete the pods
Oct 21 17:05:45.221: INFO: Deleting ReplicationController wrapped-volume-race-023ef902-f425-11e9-ae8d-bacadc8895d2 took: 24.821875ms
Oct 21 17:05:45.422: INFO: Terminating ReplicationController wrapped-volume-race-023ef902-f425-11e9-ae8d-bacadc8895d2 pods took: 200.325854ms
STEP: Creating RC which spawns configmap-volume pods
Oct 21 17:06:21.476: INFO: Pod name wrapped-volume-race-1aed1c05-f425-11e9-ae8d-bacadc8895d2: Found 0 pods out of 5
Oct 21 17:06:26.492: INFO: Pod name wrapped-volume-race-1aed1c05-f425-11e9-ae8d-bacadc8895d2: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-1aed1c05-f425-11e9-ae8d-bacadc8895d2 in namespace emptydir-wrapper-2315, will wait for the garbage collector to delete the pods
Oct 21 17:06:26.627: INFO: Deleting ReplicationController wrapped-volume-race-1aed1c05-f425-11e9-ae8d-bacadc8895d2 took: 22.087459ms
Oct 21 17:06:26.728: INFO: Terminating ReplicationController wrapped-volume-race-1aed1c05-f425-11e9-ae8d-bacadc8895d2 pods took: 100.536357ms
STEP: Creating RC which spawns configmap-volume pods
Oct 21 17:07:11.277: INFO: Pod name wrapped-volume-race-389cf642-f425-11e9-ae8d-bacadc8895d2: Found 0 pods out of 5
Oct 21 17:07:16.292: INFO: Pod name wrapped-volume-race-389cf642-f425-11e9-ae8d-bacadc8895d2: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-389cf642-f425-11e9-ae8d-bacadc8895d2 in namespace emptydir-wrapper-2315, will wait for the garbage collector to delete the pods
Oct 21 17:07:16.438: INFO: Deleting ReplicationController wrapped-volume-race-389cf642-f425-11e9-ae8d-bacadc8895d2 took: 26.304422ms
Oct 21 17:07:16.639: INFO: Terminating ReplicationController wrapped-volume-race-389cf642-f425-11e9-ae8d-bacadc8895d2 pods took: 200.33596ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:07:52.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2315" for this suite.
Oct 21 17:08:00.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:08:01.119: INFO: namespace emptydir-wrapper-2315 deletion completed in 8.626060102s

• [SLOW TEST:141.909 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:08:01.120: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8565
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 17:08:01.352: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct 21 17:08:01.493: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 21 17:08:06.504: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 21 17:08:06.504: INFO: Creating deployment "test-rolling-update-deployment"
Oct 21 17:08:06.517: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct 21 17:08:06.542: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Oct 21 17:08:08.562: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct 21 17:08:08.574: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 21 17:08:08.606: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-8565,SelfLink:/apis/apps/v1/namespaces/deployment-8565/deployments/test-rolling-update-deployment,UID:598e90d1-f425-11e9-a1ef-46591df82ad7,ResourceVersion:38912,Generation:1,CreationTimestamp:2019-10-21 17:08:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-21 17:08:06 +0000 UTC 2019-10-21 17:08:06 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-21 17:08:08 +0000 UTC 2019-10-21 17:08:06 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-57b6b5bb54" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 21 17:08:08.620: INFO: New ReplicaSet "test-rolling-update-deployment-57b6b5bb54" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54,GenerateName:,Namespace:deployment-8565,SelfLink:/apis/apps/v1/namespaces/deployment-8565/replicasets/test-rolling-update-deployment-57b6b5bb54,UID:5993e123-f425-11e9-93ac-c26612c2e4bb,ResourceVersion:38902,Generation:1,CreationTimestamp:2019-10-21 17:08:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 598e90d1-f425-11e9-a1ef-46591df82ad7 0xc0033bdd47 0xc0033bdd48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 21 17:08:08.620: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct 21 17:08:08.620: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-8565,SelfLink:/apis/apps/v1/namespaces/deployment-8565/replicasets/test-rolling-update-controller,UID:567c6fa2-f425-11e9-a1ef-46591df82ad7,ResourceVersion:38911,Generation:2,CreationTimestamp:2019-10-21 17:08:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 598e90d1-f425-11e9-a1ef-46591df82ad7 0xc0033bdc77 0xc0033bdc78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 17:08:08.629: INFO: Pod "test-rolling-update-deployment-57b6b5bb54-ptzjt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54-ptzjt,GenerateName:test-rolling-update-deployment-57b6b5bb54-,Namespace:deployment-8565,SelfLink:/api/v1/namespaces/deployment-8565/pods/test-rolling-update-deployment-57b6b5bb54-ptzjt,UID:5994e61b-f425-11e9-93ac-c26612c2e4bb,ResourceVersion:38901,Generation:0,CreationTimestamp:2019-10-21 17:08:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-57b6b5bb54 5993e123-f425-11e9-93ac-c26612c2e4bb 0xc000a4cce7 0xc000a4cce8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q7q7q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7q7q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-q7q7q true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.235.118,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000a4cd70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000a4cd90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:08:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:08:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:08:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:08:06 +0000 UTC  }],Message:,Reason:,HostIP:10.134.235.118,PodIP:172.30.192.196,StartTime:2019-10-21 17:08:06 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-21 17:08:07 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://e641b3dae18846b2fae9822431ef4107bd4a220d63b5e409191f711966b271c1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:08:08.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8565" for this suite.
Oct 21 17:08:14.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:08:15.042: INFO: namespace deployment-8565 deletion completed in 6.396983777s

• [SLOW TEST:13.922 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:08:15.042: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4003
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 17:08:15.277: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5ec6f5be-f425-11e9-ae8d-bacadc8895d2" in namespace "downward-api-4003" to be "success or failure"
Oct 21 17:08:15.287: INFO: Pod "downwardapi-volume-5ec6f5be-f425-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.558363ms
Oct 21 17:08:17.298: INFO: Pod "downwardapi-volume-5ec6f5be-f425-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020401252s
STEP: Saw pod success
Oct 21 17:08:17.298: INFO: Pod "downwardapi-volume-5ec6f5be-f425-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:08:17.307: INFO: Trying to get logs from node 10.134.235.67 pod downwardapi-volume-5ec6f5be-f425-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 17:08:17.365: INFO: Waiting for pod downwardapi-volume-5ec6f5be-f425-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:08:17.374: INFO: Pod downwardapi-volume-5ec6f5be-f425-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:08:17.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4003" for this suite.
Oct 21 17:08:25.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:08:25.840: INFO: namespace downward-api-4003 deletion completed in 8.451161828s

• [SLOW TEST:10.798 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:08:25.840: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8348
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-6538c048-f425-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume secrets
Oct 21 17:08:26.126: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-653cb398-f425-11e9-ae8d-bacadc8895d2" in namespace "projected-8348" to be "success or failure"
Oct 21 17:08:26.135: INFO: Pod "pod-projected-secrets-653cb398-f425-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.939243ms
Oct 21 17:08:28.146: INFO: Pod "pod-projected-secrets-653cb398-f425-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020027625s
Oct 21 17:08:30.159: INFO: Pod "pod-projected-secrets-653cb398-f425-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032747214s
STEP: Saw pod success
Oct 21 17:08:30.159: INFO: Pod "pod-projected-secrets-653cb398-f425-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:08:30.167: INFO: Trying to get logs from node 10.134.235.118 pod pod-projected-secrets-653cb398-f425-11e9-ae8d-bacadc8895d2 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 17:08:30.211: INFO: Waiting for pod pod-projected-secrets-653cb398-f425-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:08:30.217: INFO: Pod pod-projected-secrets-653cb398-f425-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:08:30.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8348" for this suite.
Oct 21 17:08:36.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:08:36.609: INFO: namespace projected-8348 deletion completed in 6.376070363s

• [SLOW TEST:10.769 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:08:36.610: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7082
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 21 17:08:36.853: INFO: Waiting up to 5m0s for pod "pod-6ba3384d-f425-11e9-ae8d-bacadc8895d2" in namespace "emptydir-7082" to be "success or failure"
Oct 21 17:08:36.868: INFO: Pod "pod-6ba3384d-f425-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 15.513009ms
Oct 21 17:08:38.900: INFO: Pod "pod-6ba3384d-f425-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.04719183s
STEP: Saw pod success
Oct 21 17:08:38.900: INFO: Pod "pod-6ba3384d-f425-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:08:38.911: INFO: Trying to get logs from node 10.134.235.67 pod pod-6ba3384d-f425-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 17:08:38.959: INFO: Waiting for pod pod-6ba3384d-f425-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:08:38.966: INFO: Pod pod-6ba3384d-f425-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:08:38.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7082" for this suite.
Oct 21 17:08:47.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:08:47.395: INFO: namespace emptydir-7082 deletion completed in 8.414234781s

• [SLOW TEST:10.785 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:08:47.395: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2501
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 17:08:47.607: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:08:49.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2501" for this suite.
Oct 21 17:09:29.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:09:30.084: INFO: namespace pods-2501 deletion completed in 40.359086862s

• [SLOW TEST:42.689 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:09:30.085: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6383
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Oct 21 17:09:30.289: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-731484646 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:09:30.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6383" for this suite.
Oct 21 17:09:36.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:09:36.692: INFO: namespace kubectl-6383 deletion completed in 6.3109689s

• [SLOW TEST:6.607 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:09:36.692: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7153
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 21 17:09:36.919: INFO: Waiting up to 5m0s for pod "pod-8f70f180-f425-11e9-ae8d-bacadc8895d2" in namespace "emptydir-7153" to be "success or failure"
Oct 21 17:09:36.930: INFO: Pod "pod-8f70f180-f425-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.759881ms
Oct 21 17:09:38.939: INFO: Pod "pod-8f70f180-f425-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020245648s
STEP: Saw pod success
Oct 21 17:09:38.939: INFO: Pod "pod-8f70f180-f425-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:09:38.948: INFO: Trying to get logs from node 10.134.235.67 pod pod-8f70f180-f425-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 17:09:39.007: INFO: Waiting for pod pod-8f70f180-f425-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:09:39.018: INFO: Pod pod-8f70f180-f425-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:09:39.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7153" for this suite.
Oct 21 17:09:45.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:09:45.427: INFO: namespace emptydir-7153 deletion completed in 6.398132762s

• [SLOW TEST:8.735 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:09:45.428: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9649
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct 21 17:09:48.224: INFO: Successfully updated pod "labelsupdate94a50792-f425-11e9-ae8d-bacadc8895d2"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:09:52.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9649" for this suite.
Oct 21 17:10:16.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:10:16.721: INFO: namespace downward-api-9649 deletion completed in 24.42346163s

• [SLOW TEST:31.293 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:10:16.721: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1494
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 21 17:10:16.958: INFO: Waiting up to 5m0s for pod "pod-a74e14dd-f425-11e9-ae8d-bacadc8895d2" in namespace "emptydir-1494" to be "success or failure"
Oct 21 17:10:16.977: INFO: Pod "pod-a74e14dd-f425-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 19.371506ms
Oct 21 17:10:18.987: INFO: Pod "pod-a74e14dd-f425-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028556752s
STEP: Saw pod success
Oct 21 17:10:18.987: INFO: Pod "pod-a74e14dd-f425-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:10:18.996: INFO: Trying to get logs from node 10.134.235.67 pod pod-a74e14dd-f425-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 17:10:19.053: INFO: Waiting for pod pod-a74e14dd-f425-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:10:19.061: INFO: Pod pod-a74e14dd-f425-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:10:19.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1494" for this suite.
Oct 21 17:10:25.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:10:25.458: INFO: namespace emptydir-1494 deletion completed in 6.384594122s

• [SLOW TEST:8.736 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:10:25.458: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-166
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Oct 21 17:10:25.757: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-166,SelfLink:/api/v1/namespaces/watch-166/configmaps/e2e-watch-test-configmap-a,UID:ac8d2fcb-f425-11e9-a1ef-46591df82ad7,ResourceVersion:39452,Generation:0,CreationTimestamp:2019-10-21 17:10:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 21 17:10:25.758: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-166,SelfLink:/api/v1/namespaces/watch-166/configmaps/e2e-watch-test-configmap-a,UID:ac8d2fcb-f425-11e9-a1ef-46591df82ad7,ResourceVersion:39452,Generation:0,CreationTimestamp:2019-10-21 17:10:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Oct 21 17:10:35.778: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-166,SelfLink:/api/v1/namespaces/watch-166/configmaps/e2e-watch-test-configmap-a,UID:ac8d2fcb-f425-11e9-a1ef-46591df82ad7,ResourceVersion:39470,Generation:0,CreationTimestamp:2019-10-21 17:10:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 21 17:10:35.778: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-166,SelfLink:/api/v1/namespaces/watch-166/configmaps/e2e-watch-test-configmap-a,UID:ac8d2fcb-f425-11e9-a1ef-46591df82ad7,ResourceVersion:39470,Generation:0,CreationTimestamp:2019-10-21 17:10:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Oct 21 17:10:45.798: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-166,SelfLink:/api/v1/namespaces/watch-166/configmaps/e2e-watch-test-configmap-a,UID:ac8d2fcb-f425-11e9-a1ef-46591df82ad7,ResourceVersion:39488,Generation:0,CreationTimestamp:2019-10-21 17:10:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 21 17:10:45.798: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-166,SelfLink:/api/v1/namespaces/watch-166/configmaps/e2e-watch-test-configmap-a,UID:ac8d2fcb-f425-11e9-a1ef-46591df82ad7,ResourceVersion:39488,Generation:0,CreationTimestamp:2019-10-21 17:10:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Oct 21 17:10:55.821: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-166,SelfLink:/api/v1/namespaces/watch-166/configmaps/e2e-watch-test-configmap-a,UID:ac8d2fcb-f425-11e9-a1ef-46591df82ad7,ResourceVersion:39506,Generation:0,CreationTimestamp:2019-10-21 17:10:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 21 17:10:55.821: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-166,SelfLink:/api/v1/namespaces/watch-166/configmaps/e2e-watch-test-configmap-a,UID:ac8d2fcb-f425-11e9-a1ef-46591df82ad7,ResourceVersion:39506,Generation:0,CreationTimestamp:2019-10-21 17:10:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Oct 21 17:11:05.839: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-166,SelfLink:/api/v1/namespaces/watch-166/configmaps/e2e-watch-test-configmap-b,UID:c47043fa-f425-11e9-a1ef-46591df82ad7,ResourceVersion:39523,Generation:0,CreationTimestamp:2019-10-21 17:11:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 21 17:11:05.839: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-166,SelfLink:/api/v1/namespaces/watch-166/configmaps/e2e-watch-test-configmap-b,UID:c47043fa-f425-11e9-a1ef-46591df82ad7,ResourceVersion:39523,Generation:0,CreationTimestamp:2019-10-21 17:11:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Oct 21 17:11:15.860: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-166,SelfLink:/api/v1/namespaces/watch-166/configmaps/e2e-watch-test-configmap-b,UID:c47043fa-f425-11e9-a1ef-46591df82ad7,ResourceVersion:39539,Generation:0,CreationTimestamp:2019-10-21 17:11:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 21 17:11:15.860: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-166,SelfLink:/api/v1/namespaces/watch-166/configmaps/e2e-watch-test-configmap-b,UID:c47043fa-f425-11e9-a1ef-46591df82ad7,ResourceVersion:39539,Generation:0,CreationTimestamp:2019-10-21 17:11:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:11:25.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-166" for this suite.
Oct 21 17:11:34.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:11:35.167: INFO: namespace watch-166 deletion completed in 8.959956575s

• [SLOW TEST:69.709 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:11:35.168: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9122
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1521
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 17:11:35.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-9122'
Oct 21 17:11:35.567: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 21 17:11:35.567: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1526
Oct 21 17:11:37.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 delete deployment e2e-test-nginx-deployment --namespace=kubectl-9122'
Oct 21 17:11:37.715: INFO: stderr: ""
Oct 21 17:11:37.715: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:11:37.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9122" for this suite.
Oct 21 17:11:43.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:11:44.503: INFO: namespace kubectl-9122 deletion completed in 6.775735432s

• [SLOW TEST:9.335 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:11:44.503: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5462
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 21 17:11:44.803: INFO: Number of nodes with available pods: 0
Oct 21 17:11:44.803: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 17:11:45.827: INFO: Number of nodes with available pods: 0
Oct 21 17:11:45.827: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 17:11:46.831: INFO: Number of nodes with available pods: 2
Oct 21 17:11:46.831: INFO: Node 10.134.235.67 is running more than one daemon pod
Oct 21 17:11:47.826: INFO: Number of nodes with available pods: 3
Oct 21 17:11:47.826: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Oct 21 17:11:47.891: INFO: Number of nodes with available pods: 2
Oct 21 17:11:47.891: INFO: Node 10.134.235.77 is running more than one daemon pod
Oct 21 17:11:48.914: INFO: Number of nodes with available pods: 2
Oct 21 17:11:48.914: INFO: Node 10.134.235.77 is running more than one daemon pod
Oct 21 17:11:49.914: INFO: Number of nodes with available pods: 2
Oct 21 17:11:49.914: INFO: Node 10.134.235.77 is running more than one daemon pod
Oct 21 17:11:50.911: INFO: Number of nodes with available pods: 2
Oct 21 17:11:50.911: INFO: Node 10.134.235.77 is running more than one daemon pod
Oct 21 17:11:51.912: INFO: Number of nodes with available pods: 2
Oct 21 17:11:51.912: INFO: Node 10.134.235.77 is running more than one daemon pod
Oct 21 17:11:52.911: INFO: Number of nodes with available pods: 3
Oct 21 17:11:52.911: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5462, will wait for the garbage collector to delete the pods
Oct 21 17:11:52.999: INFO: Deleting DaemonSet.extensions daemon-set took: 20.249512ms
Oct 21 17:11:53.099: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.376406ms
Oct 21 17:12:01.212: INFO: Number of nodes with available pods: 0
Oct 21 17:12:01.212: INFO: Number of running nodes: 0, number of available pods: 0
Oct 21 17:12:01.221: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5462/daemonsets","resourceVersion":"39775"},"items":null}

Oct 21 17:12:01.231: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5462/pods","resourceVersion":"39775"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:12:01.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5462" for this suite.
Oct 21 17:12:09.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:12:09.983: INFO: namespace daemonsets-5462 deletion completed in 8.696902337s

• [SLOW TEST:25.480 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:12:09.983: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2967
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-pw62
STEP: Creating a pod to test atomic-volume-subpath
Oct 21 17:12:10.251: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-pw62" in namespace "subpath-2967" to be "success or failure"
Oct 21 17:12:10.261: INFO: Pod "pod-subpath-test-projected-pw62": Phase="Pending", Reason="", readiness=false. Elapsed: 10.375351ms
Oct 21 17:12:12.271: INFO: Pod "pod-subpath-test-projected-pw62": Phase="Running", Reason="", readiness=true. Elapsed: 2.020487485s
Oct 21 17:12:14.282: INFO: Pod "pod-subpath-test-projected-pw62": Phase="Running", Reason="", readiness=true. Elapsed: 4.031120357s
Oct 21 17:12:16.291: INFO: Pod "pod-subpath-test-projected-pw62": Phase="Running", Reason="", readiness=true. Elapsed: 6.04029618s
Oct 21 17:12:18.306: INFO: Pod "pod-subpath-test-projected-pw62": Phase="Running", Reason="", readiness=true. Elapsed: 8.054910136s
Oct 21 17:12:20.316: INFO: Pod "pod-subpath-test-projected-pw62": Phase="Running", Reason="", readiness=true. Elapsed: 10.064848452s
Oct 21 17:12:22.325: INFO: Pod "pod-subpath-test-projected-pw62": Phase="Running", Reason="", readiness=true. Elapsed: 12.073916435s
Oct 21 17:12:24.334: INFO: Pod "pod-subpath-test-projected-pw62": Phase="Running", Reason="", readiness=true. Elapsed: 14.082783664s
Oct 21 17:12:26.347: INFO: Pod "pod-subpath-test-projected-pw62": Phase="Running", Reason="", readiness=true. Elapsed: 16.095893724s
Oct 21 17:12:28.356: INFO: Pod "pod-subpath-test-projected-pw62": Phase="Running", Reason="", readiness=true. Elapsed: 18.105747615s
Oct 21 17:12:30.367: INFO: Pod "pod-subpath-test-projected-pw62": Phase="Running", Reason="", readiness=true. Elapsed: 20.116751561s
Oct 21 17:12:32.378: INFO: Pod "pod-subpath-test-projected-pw62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.127158492s
STEP: Saw pod success
Oct 21 17:12:32.378: INFO: Pod "pod-subpath-test-projected-pw62" satisfied condition "success or failure"
Oct 21 17:12:32.387: INFO: Trying to get logs from node 10.134.235.67 pod pod-subpath-test-projected-pw62 container test-container-subpath-projected-pw62: <nil>
STEP: delete the pod
Oct 21 17:12:32.446: INFO: Waiting for pod pod-subpath-test-projected-pw62 to disappear
Oct 21 17:12:32.454: INFO: Pod pod-subpath-test-projected-pw62 no longer exists
STEP: Deleting pod pod-subpath-test-projected-pw62
Oct 21 17:12:32.454: INFO: Deleting pod "pod-subpath-test-projected-pw62" in namespace "subpath-2967"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:12:32.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2967" for this suite.
Oct 21 17:12:38.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:12:39.135: INFO: namespace subpath-2967 deletion completed in 6.654933185s

• [SLOW TEST:29.152 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:12:39.136: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5943
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 17:12:39.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 version'
Oct 21 17:12:39.438: INFO: stderr: ""
Oct 21 17:12:39.438: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.8\", GitCommit:\"211047e9a1922595eaa3a1127ed365e9299a6c23\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T12:11:03Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.8+IKS\", GitCommit:\"e92d4d66e0fbcf26d180f9564d6d310341a98481\", GitTreeState:\"clean\", BuildDate:\"2019-10-17T11:20:25Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:12:39.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5943" for this suite.
Oct 21 17:12:45.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:12:45.833: INFO: namespace kubectl-5943 deletion completed in 6.382145046s

• [SLOW TEST:6.697 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:12:45.835: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8660
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Oct 21 17:12:46.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-731484646 --namespace=kubectl-8660 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Oct 21 17:12:47.960: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Oct 21 17:12:47.960: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:12:49.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8660" for this suite.
Oct 21 17:12:56.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:12:56.400: INFO: namespace kubectl-8660 deletion completed in 6.404321381s

• [SLOW TEST:10.565 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:12:56.400: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-227
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Oct 21 17:12:56.603: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-731484646 proxy --unix-socket=/tmp/kubectl-proxy-unix378422673/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:12:56.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-227" for this suite.
Oct 21 17:13:02.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:13:03.078: INFO: namespace kubectl-227 deletion completed in 6.416257962s

• [SLOW TEST:6.678 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:13:03.079: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8904
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-j4s8n in namespace proxy-8904
I1021 17:13:03.326131      17 runners.go:184] Created replication controller with name: proxy-service-j4s8n, namespace: proxy-8904, replica count: 1
I1021 17:13:04.376636      17 runners.go:184] proxy-service-j4s8n Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1021 17:13:05.376931      17 runners.go:184] proxy-service-j4s8n Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1021 17:13:06.377243      17 runners.go:184] proxy-service-j4s8n Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1021 17:13:07.377565      17 runners.go:184] proxy-service-j4s8n Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1021 17:13:08.377942      17 runners.go:184] proxy-service-j4s8n Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 21 17:13:08.387: INFO: setup took 5.09904578s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Oct 21 17:13:08.412: INFO: (0) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 24.946627ms)
Oct 21 17:13:08.419: INFO: (0) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 31.616089ms)
Oct 21 17:13:08.435: INFO: (0) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 47.790462ms)
Oct 21 17:13:08.444: INFO: (0) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 57.504734ms)
Oct 21 17:13:08.444: INFO: (0) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 57.626287ms)
Oct 21 17:13:08.445: INFO: (0) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 58.259226ms)
Oct 21 17:13:08.463: INFO: (0) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 76.494989ms)
Oct 21 17:13:08.465: INFO: (0) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 77.686919ms)
Oct 21 17:13:08.469: INFO: (0) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 82.439947ms)
Oct 21 17:13:08.470: INFO: (0) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 82.794838ms)
Oct 21 17:13:08.483: INFO: (0) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 96.103739ms)
Oct 21 17:13:08.625: INFO: (0) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 238.181655ms)
Oct 21 17:13:08.625: INFO: (0) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 238.56773ms)
Oct 21 17:13:08.631: INFO: (0) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 243.842332ms)
Oct 21 17:13:08.650: INFO: (0) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 263.159065ms)
Oct 21 17:13:08.665: INFO: (0) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 278.228578ms)
Oct 21 17:13:08.689: INFO: (1) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 23.68978ms)
Oct 21 17:13:08.698: INFO: (1) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 33.030767ms)
Oct 21 17:13:08.699: INFO: (1) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 33.512574ms)
Oct 21 17:13:08.699: INFO: (1) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 33.469691ms)
Oct 21 17:13:08.701: INFO: (1) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 35.900989ms)
Oct 21 17:13:08.703: INFO: (1) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 37.126597ms)
Oct 21 17:13:08.703: INFO: (1) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 37.911214ms)
Oct 21 17:13:08.704: INFO: (1) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 38.581107ms)
Oct 21 17:13:08.709: INFO: (1) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 43.841762ms)
Oct 21 17:13:08.709: INFO: (1) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 43.963546ms)
Oct 21 17:13:08.717: INFO: (1) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 51.602755ms)
Oct 21 17:13:08.718: INFO: (1) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 52.647168ms)
Oct 21 17:13:08.729: INFO: (1) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 64.279991ms)
Oct 21 17:13:08.730: INFO: (1) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 64.347106ms)
Oct 21 17:13:08.730: INFO: (1) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 64.528962ms)
Oct 21 17:13:08.730: INFO: (1) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 64.951828ms)
Oct 21 17:13:08.752: INFO: (2) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 21.583924ms)
Oct 21 17:13:08.752: INFO: (2) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 21.756663ms)
Oct 21 17:13:08.752: INFO: (2) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 21.9921ms)
Oct 21 17:13:08.753: INFO: (2) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 22.460304ms)
Oct 21 17:13:08.758: INFO: (2) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 27.885105ms)
Oct 21 17:13:08.758: INFO: (2) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 28.08023ms)
Oct 21 17:13:08.759: INFO: (2) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 28.223419ms)
Oct 21 17:13:08.759: INFO: (2) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 28.119965ms)
Oct 21 17:13:08.766: INFO: (2) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 35.24136ms)
Oct 21 17:13:08.766: INFO: (2) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 35.348335ms)
Oct 21 17:13:08.766: INFO: (2) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 35.332611ms)
Oct 21 17:13:08.766: INFO: (2) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 35.380861ms)
Oct 21 17:13:08.766: INFO: (2) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 35.342247ms)
Oct 21 17:13:08.766: INFO: (2) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 35.594232ms)
Oct 21 17:13:08.766: INFO: (2) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 35.486189ms)
Oct 21 17:13:08.776: INFO: (2) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 45.1368ms)
Oct 21 17:13:08.799: INFO: (3) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 23.217765ms)
Oct 21 17:13:08.808: INFO: (3) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 32.206862ms)
Oct 21 17:13:08.808: INFO: (3) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 32.601044ms)
Oct 21 17:13:08.808: INFO: (3) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 32.43273ms)
Oct 21 17:13:08.808: INFO: (3) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 32.511984ms)
Oct 21 17:13:08.812: INFO: (3) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 35.909875ms)
Oct 21 17:13:08.812: INFO: (3) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 36.697417ms)
Oct 21 17:13:08.813: INFO: (3) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 37.141998ms)
Oct 21 17:13:08.813: INFO: (3) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 37.370866ms)
Oct 21 17:13:08.813: INFO: (3) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 37.266441ms)
Oct 21 17:13:08.817: INFO: (3) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 41.093368ms)
Oct 21 17:13:08.817: INFO: (3) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 41.268203ms)
Oct 21 17:13:08.826: INFO: (3) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 50.234949ms)
Oct 21 17:13:08.826: INFO: (3) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 50.270937ms)
Oct 21 17:13:08.826: INFO: (3) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 50.135429ms)
Oct 21 17:13:08.826: INFO: (3) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 50.390043ms)
Oct 21 17:13:08.843: INFO: (4) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 16.404398ms)
Oct 21 17:13:08.850: INFO: (4) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 23.715739ms)
Oct 21 17:13:08.850: INFO: (4) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 24.031647ms)
Oct 21 17:13:08.850: INFO: (4) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 23.825008ms)
Oct 21 17:13:08.850: INFO: (4) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 24.148172ms)
Oct 21 17:13:08.850: INFO: (4) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 23.9381ms)
Oct 21 17:13:08.850: INFO: (4) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 23.90951ms)
Oct 21 17:13:08.850: INFO: (4) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 23.929754ms)
Oct 21 17:13:08.850: INFO: (4) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 23.861799ms)
Oct 21 17:13:08.859: INFO: (4) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 32.80383ms)
Oct 21 17:13:08.859: INFO: (4) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 32.61671ms)
Oct 21 17:13:08.859: INFO: (4) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 32.856195ms)
Oct 21 17:13:08.859: INFO: (4) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 32.779834ms)
Oct 21 17:13:08.859: INFO: (4) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 32.725812ms)
Oct 21 17:13:08.859: INFO: (4) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 32.810541ms)
Oct 21 17:13:08.861: INFO: (4) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 34.298133ms)
Oct 21 17:13:08.882: INFO: (5) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 20.910673ms)
Oct 21 17:13:08.891: INFO: (5) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 29.739525ms)
Oct 21 17:13:08.891: INFO: (5) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 29.804135ms)
Oct 21 17:13:08.893: INFO: (5) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 31.720314ms)
Oct 21 17:13:08.893: INFO: (5) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 31.968386ms)
Oct 21 17:13:08.896: INFO: (5) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 34.877123ms)
Oct 21 17:13:08.896: INFO: (5) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 35.192362ms)
Oct 21 17:13:08.896: INFO: (5) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 35.347814ms)
Oct 21 17:13:08.896: INFO: (5) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 35.316369ms)
Oct 21 17:13:08.896: INFO: (5) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 35.129798ms)
Oct 21 17:13:08.896: INFO: (5) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 35.507045ms)
Oct 21 17:13:08.897: INFO: (5) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 35.465254ms)
Oct 21 17:13:08.897: INFO: (5) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 36.001278ms)
Oct 21 17:13:08.906: INFO: (5) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 45.21648ms)
Oct 21 17:13:08.906: INFO: (5) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 45.455997ms)
Oct 21 17:13:08.907: INFO: (5) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 45.578617ms)
Oct 21 17:13:08.922: INFO: (6) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 15.087289ms)
Oct 21 17:13:08.931: INFO: (6) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 24.47743ms)
Oct 21 17:13:08.932: INFO: (6) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 25.639393ms)
Oct 21 17:13:08.933: INFO: (6) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 25.852929ms)
Oct 21 17:13:08.933: INFO: (6) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 26.096903ms)
Oct 21 17:13:08.933: INFO: (6) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 26.08329ms)
Oct 21 17:13:08.933: INFO: (6) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 26.008796ms)
Oct 21 17:13:08.936: INFO: (6) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 28.854773ms)
Oct 21 17:13:08.936: INFO: (6) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 28.805642ms)
Oct 21 17:13:08.947: INFO: (6) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 39.969249ms)
Oct 21 17:13:08.948: INFO: (6) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 41.086205ms)
Oct 21 17:13:08.949: INFO: (6) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 41.842552ms)
Oct 21 17:13:08.955: INFO: (6) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 48.00691ms)
Oct 21 17:13:08.955: INFO: (6) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 48.088238ms)
Oct 21 17:13:08.955: INFO: (6) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 48.269869ms)
Oct 21 17:13:08.961: INFO: (6) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 53.674181ms)
Oct 21 17:13:08.978: INFO: (7) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 17.208756ms)
Oct 21 17:13:08.988: INFO: (7) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 26.524663ms)
Oct 21 17:13:08.991: INFO: (7) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 30.270837ms)
Oct 21 17:13:08.991: INFO: (7) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 30.534331ms)
Oct 21 17:13:08.994: INFO: (7) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 32.988153ms)
Oct 21 17:13:08.994: INFO: (7) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 32.914224ms)
Oct 21 17:13:08.995: INFO: (7) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 33.783883ms)
Oct 21 17:13:08.995: INFO: (7) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 33.902875ms)
Oct 21 17:13:08.995: INFO: (7) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 34.062723ms)
Oct 21 17:13:08.997: INFO: (7) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 36.403167ms)
Oct 21 17:13:08.997: INFO: (7) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 36.521206ms)
Oct 21 17:13:08.997: INFO: (7) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 36.409951ms)
Oct 21 17:13:08.997: INFO: (7) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 36.390964ms)
Oct 21 17:13:09.002: INFO: (7) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 41.140402ms)
Oct 21 17:13:09.003: INFO: (7) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 42.034906ms)
Oct 21 17:13:09.003: INFO: (7) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 42.262647ms)
Oct 21 17:13:09.027: INFO: (8) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 23.742136ms)
Oct 21 17:13:09.036: INFO: (8) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 33.248154ms)
Oct 21 17:13:09.036: INFO: (8) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 33.31453ms)
Oct 21 17:13:09.036: INFO: (8) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 33.111033ms)
Oct 21 17:13:09.036: INFO: (8) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 33.266327ms)
Oct 21 17:13:09.037: INFO: (8) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 33.247165ms)
Oct 21 17:13:09.037: INFO: (8) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 33.266728ms)
Oct 21 17:13:09.037: INFO: (8) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 33.176538ms)
Oct 21 17:13:09.037: INFO: (8) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 33.23409ms)
Oct 21 17:13:09.039: INFO: (8) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 35.613209ms)
Oct 21 17:13:09.039: INFO: (8) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 35.852229ms)
Oct 21 17:13:09.039: INFO: (8) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 35.743383ms)
Oct 21 17:13:09.039: INFO: (8) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 35.788337ms)
Oct 21 17:13:09.040: INFO: (8) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 36.910312ms)
Oct 21 17:13:09.041: INFO: (8) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 37.134868ms)
Oct 21 17:13:09.041: INFO: (8) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 37.221664ms)
Oct 21 17:13:09.059: INFO: (9) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 18.360789ms)
Oct 21 17:13:09.064: INFO: (9) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 22.671541ms)
Oct 21 17:13:09.064: INFO: (9) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 23.069085ms)
Oct 21 17:13:09.064: INFO: (9) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 22.949775ms)
Oct 21 17:13:09.064: INFO: (9) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 22.796159ms)
Oct 21 17:13:09.064: INFO: (9) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 22.960747ms)
Oct 21 17:13:09.068: INFO: (9) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 26.892728ms)
Oct 21 17:13:09.068: INFO: (9) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 26.750222ms)
Oct 21 17:13:09.068: INFO: (9) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 26.672997ms)
Oct 21 17:13:09.068: INFO: (9) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 27.205876ms)
Oct 21 17:13:09.077: INFO: (9) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 36.291426ms)
Oct 21 17:13:09.077: INFO: (9) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 36.250853ms)
Oct 21 17:13:09.077: INFO: (9) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 36.187532ms)
Oct 21 17:13:09.083: INFO: (9) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 42.132448ms)
Oct 21 17:13:09.083: INFO: (9) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 41.883292ms)
Oct 21 17:13:09.083: INFO: (9) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 42.398528ms)
Oct 21 17:13:09.106: INFO: (10) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 22.95112ms)
Oct 21 17:13:09.107: INFO: (10) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 23.193958ms)
Oct 21 17:13:09.107: INFO: (10) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 23.092835ms)
Oct 21 17:13:09.107: INFO: (10) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 23.264601ms)
Oct 21 17:13:09.107: INFO: (10) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 23.536892ms)
Oct 21 17:13:09.107: INFO: (10) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 23.471535ms)
Oct 21 17:13:09.110: INFO: (10) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 26.584468ms)
Oct 21 17:13:09.110: INFO: (10) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 26.767762ms)
Oct 21 17:13:09.110: INFO: (10) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 26.91549ms)
Oct 21 17:13:09.111: INFO: (10) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 27.99735ms)
Oct 21 17:13:09.118: INFO: (10) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 34.262117ms)
Oct 21 17:13:09.118: INFO: (10) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 34.165059ms)
Oct 21 17:13:09.118: INFO: (10) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 34.480851ms)
Oct 21 17:13:09.118: INFO: (10) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 34.279278ms)
Oct 21 17:13:09.118: INFO: (10) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 34.228849ms)
Oct 21 17:13:09.118: INFO: (10) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 34.292425ms)
Oct 21 17:13:09.136: INFO: (11) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 18.294785ms)
Oct 21 17:13:09.146: INFO: (11) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 28.119569ms)
Oct 21 17:13:09.147: INFO: (11) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 28.831516ms)
Oct 21 17:13:09.147: INFO: (11) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 28.745037ms)
Oct 21 17:13:09.147: INFO: (11) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 29.193229ms)
Oct 21 17:13:09.147: INFO: (11) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 29.412732ms)
Oct 21 17:13:09.148: INFO: (11) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 30.032829ms)
Oct 21 17:13:09.148: INFO: (11) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 29.714597ms)
Oct 21 17:13:09.154: INFO: (11) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 35.542858ms)
Oct 21 17:13:09.154: INFO: (11) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 35.647947ms)
Oct 21 17:13:09.154: INFO: (11) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 36.101524ms)
Oct 21 17:13:09.161: INFO: (11) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 42.511942ms)
Oct 21 17:13:09.161: INFO: (11) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 42.436508ms)
Oct 21 17:13:09.161: INFO: (11) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 42.281536ms)
Oct 21 17:13:09.161: INFO: (11) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 42.446405ms)
Oct 21 17:13:09.161: INFO: (11) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 42.770471ms)
Oct 21 17:13:09.183: INFO: (12) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 22.306141ms)
Oct 21 17:13:09.184: INFO: (12) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 22.858384ms)
Oct 21 17:13:09.187: INFO: (12) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 26.142833ms)
Oct 21 17:13:09.188: INFO: (12) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 26.655489ms)
Oct 21 17:13:09.188: INFO: (12) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 27.04464ms)
Oct 21 17:13:09.188: INFO: (12) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 26.792943ms)
Oct 21 17:13:09.188: INFO: (12) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 27.046438ms)
Oct 21 17:13:09.193: INFO: (12) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 32.545751ms)
Oct 21 17:13:09.198: INFO: (12) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 36.807928ms)
Oct 21 17:13:09.198: INFO: (12) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 37.290197ms)
Oct 21 17:13:09.198: INFO: (12) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 37.100767ms)
Oct 21 17:13:09.203: INFO: (12) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 42.180914ms)
Oct 21 17:13:09.203: INFO: (12) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 42.381709ms)
Oct 21 17:13:09.205: INFO: (12) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 43.896629ms)
Oct 21 17:13:09.210: INFO: (12) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 49.072556ms)
Oct 21 17:13:09.210: INFO: (12) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 48.95758ms)
Oct 21 17:13:09.240: INFO: (13) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 29.428066ms)
Oct 21 17:13:09.240: INFO: (13) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 29.874694ms)
Oct 21 17:13:09.240: INFO: (13) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 29.787861ms)
Oct 21 17:13:09.240: INFO: (13) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 29.768369ms)
Oct 21 17:13:09.240: INFO: (13) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 29.709702ms)
Oct 21 17:13:09.240: INFO: (13) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 29.643137ms)
Oct 21 17:13:09.240: INFO: (13) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 29.744164ms)
Oct 21 17:13:09.240: INFO: (13) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 29.703837ms)
Oct 21 17:13:09.240: INFO: (13) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 29.545173ms)
Oct 21 17:13:09.255: INFO: (13) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 44.781339ms)
Oct 21 17:13:09.256: INFO: (13) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 45.199226ms)
Oct 21 17:13:09.257: INFO: (13) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 46.580238ms)
Oct 21 17:13:09.262: INFO: (13) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 51.679097ms)
Oct 21 17:13:09.263: INFO: (13) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 52.061823ms)
Oct 21 17:13:09.263: INFO: (13) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 52.547825ms)
Oct 21 17:13:09.265: INFO: (13) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 54.609077ms)
Oct 21 17:13:09.283: INFO: (14) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 18.087303ms)
Oct 21 17:13:09.284: INFO: (14) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 18.467174ms)
Oct 21 17:13:09.287: INFO: (14) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 21.472713ms)
Oct 21 17:13:09.289: INFO: (14) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 23.133046ms)
Oct 21 17:13:09.289: INFO: (14) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 23.663109ms)
Oct 21 17:13:09.289: INFO: (14) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 23.656334ms)
Oct 21 17:13:09.289: INFO: (14) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 23.830598ms)
Oct 21 17:13:09.289: INFO: (14) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 23.919292ms)
Oct 21 17:13:09.289: INFO: (14) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 23.963131ms)
Oct 21 17:13:09.290: INFO: (14) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 24.707495ms)
Oct 21 17:13:09.290: INFO: (14) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 24.864596ms)
Oct 21 17:13:09.302: INFO: (14) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 36.896529ms)
Oct 21 17:13:09.302: INFO: (14) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 36.646472ms)
Oct 21 17:13:09.313: INFO: (14) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 48.109486ms)
Oct 21 17:13:09.315: INFO: (14) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 49.431029ms)
Oct 21 17:13:09.315: INFO: (14) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 49.514637ms)
Oct 21 17:13:09.346: INFO: (15) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 30.530678ms)
Oct 21 17:13:09.346: INFO: (15) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 30.237992ms)
Oct 21 17:13:09.346: INFO: (15) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 30.168996ms)
Oct 21 17:13:09.362: INFO: (15) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 46.320737ms)
Oct 21 17:13:09.365: INFO: (15) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 48.952076ms)
Oct 21 17:13:09.369: INFO: (15) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 53.592714ms)
Oct 21 17:13:09.369: INFO: (15) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 53.537754ms)
Oct 21 17:13:09.372: INFO: (15) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 56.487143ms)
Oct 21 17:13:09.372: INFO: (15) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 56.185833ms)
Oct 21 17:13:09.372: INFO: (15) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 56.448474ms)
Oct 21 17:13:09.372: INFO: (15) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 56.546957ms)
Oct 21 17:13:09.383: INFO: (15) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 67.37328ms)
Oct 21 17:13:09.387: INFO: (15) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 71.951452ms)
Oct 21 17:13:09.389: INFO: (15) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 73.475294ms)
Oct 21 17:13:09.559: INFO: (15) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 243.508328ms)
Oct 21 17:13:09.560: INFO: (15) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 244.54282ms)
Oct 21 17:13:09.577: INFO: (16) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 16.384566ms)
Oct 21 17:13:09.579: INFO: (16) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 18.52072ms)
Oct 21 17:13:09.579: INFO: (16) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 18.463675ms)
Oct 21 17:13:09.581: INFO: (16) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 20.958566ms)
Oct 21 17:13:09.582: INFO: (16) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 21.161131ms)
Oct 21 17:13:09.582: INFO: (16) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 21.110769ms)
Oct 21 17:13:09.586: INFO: (16) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 25.565354ms)
Oct 21 17:13:09.586: INFO: (16) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 25.462642ms)
Oct 21 17:13:09.586: INFO: (16) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 25.738751ms)
Oct 21 17:13:09.586: INFO: (16) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 25.719532ms)
Oct 21 17:13:09.588: INFO: (16) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 27.616271ms)
Oct 21 17:13:09.588: INFO: (16) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 27.789855ms)
Oct 21 17:13:09.593: INFO: (16) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 32.100835ms)
Oct 21 17:13:09.593: INFO: (16) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 32.1961ms)
Oct 21 17:13:09.593: INFO: (16) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 32.507373ms)
Oct 21 17:13:09.595: INFO: (16) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 34.659647ms)
Oct 21 17:13:09.612: INFO: (17) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 16.577902ms)
Oct 21 17:13:09.612: INFO: (17) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 16.903745ms)
Oct 21 17:13:09.619: INFO: (17) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 23.517407ms)
Oct 21 17:13:09.619: INFO: (17) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 23.824167ms)
Oct 21 17:13:09.620: INFO: (17) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 23.701111ms)
Oct 21 17:13:09.620: INFO: (17) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 23.701679ms)
Oct 21 17:13:09.620: INFO: (17) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 23.800091ms)
Oct 21 17:13:09.621: INFO: (17) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 24.910889ms)
Oct 21 17:13:09.621: INFO: (17) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 25.11213ms)
Oct 21 17:13:09.621: INFO: (17) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 25.183553ms)
Oct 21 17:13:09.621: INFO: (17) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 25.607667ms)
Oct 21 17:13:09.627: INFO: (17) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 31.501239ms)
Oct 21 17:13:09.631: INFO: (17) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 35.713993ms)
Oct 21 17:13:09.633: INFO: (17) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 36.906101ms)
Oct 21 17:13:09.633: INFO: (17) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 37.166624ms)
Oct 21 17:13:09.637: INFO: (17) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 41.39784ms)
Oct 21 17:13:09.663: INFO: (18) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 25.929361ms)
Oct 21 17:13:09.670: INFO: (18) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 32.458525ms)
Oct 21 17:13:09.670: INFO: (18) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 32.704569ms)
Oct 21 17:13:09.670: INFO: (18) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 32.182273ms)
Oct 21 17:13:09.670: INFO: (18) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 32.578402ms)
Oct 21 17:13:09.670: INFO: (18) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 32.440764ms)
Oct 21 17:13:09.670: INFO: (18) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 32.558876ms)
Oct 21 17:13:09.670: INFO: (18) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 32.409294ms)
Oct 21 17:13:09.670: INFO: (18) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 32.957079ms)
Oct 21 17:13:09.671: INFO: (18) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 33.68892ms)
Oct 21 17:13:09.672: INFO: (18) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 34.693416ms)
Oct 21 17:13:09.672: INFO: (18) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 34.766155ms)
Oct 21 17:13:09.679: INFO: (18) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 41.287263ms)
Oct 21 17:13:09.679: INFO: (18) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 41.930435ms)
Oct 21 17:13:09.680: INFO: (18) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 42.143904ms)
Oct 21 17:13:09.680: INFO: (18) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 42.064566ms)
Oct 21 17:13:09.696: INFO: (19) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 15.993022ms)
Oct 21 17:13:09.706: INFO: (19) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 25.578253ms)
Oct 21 17:13:09.706: INFO: (19) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">... (200; 25.781084ms)
Oct 21 17:13:09.708: INFO: (19) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:443/proxy/tlsrewritem... (200; 27.784215ms)
Oct 21 17:13:09.708: INFO: (19) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:460/proxy/: tls baz (200; 28.004993ms)
Oct 21 17:13:09.708: INFO: (19) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:162/proxy/: bar (200; 28.076919ms)
Oct 21 17:13:09.708: INFO: (19) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s:1080/proxy/rewriteme">test<... (200; 27.584633ms)
Oct 21 17:13:09.708: INFO: (19) /api/v1/namespaces/proxy-8904/pods/http:proxy-service-j4s8n-rff9s:160/proxy/: foo (200; 27.742075ms)
Oct 21 17:13:09.708: INFO: (19) /api/v1/namespaces/proxy-8904/pods/https:proxy-service-j4s8n-rff9s:462/proxy/: tls qux (200; 28.157069ms)
Oct 21 17:13:09.709: INFO: (19) /api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/: <a href="/api/v1/namespaces/proxy-8904/pods/proxy-service-j4s8n-rff9s/proxy/rewriteme">test</a> (200; 28.262254ms)
Oct 21 17:13:09.709: INFO: (19) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname1/proxy/: tls baz (200; 28.866423ms)
Oct 21 17:13:09.710: INFO: (19) /api/v1/namespaces/proxy-8904/services/https:proxy-service-j4s8n:tlsportname2/proxy/: tls qux (200; 29.454548ms)
Oct 21 17:13:09.710: INFO: (19) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname2/proxy/: bar (200; 30.045982ms)
Oct 21 17:13:09.716: INFO: (19) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname1/proxy/: foo (200; 35.466854ms)
Oct 21 17:13:09.716: INFO: (19) /api/v1/namespaces/proxy-8904/services/http:proxy-service-j4s8n:portname1/proxy/: foo (200; 36.222655ms)
Oct 21 17:13:09.716: INFO: (19) /api/v1/namespaces/proxy-8904/services/proxy-service-j4s8n:portname2/proxy/: bar (200; 36.174601ms)
STEP: deleting ReplicationController proxy-service-j4s8n in namespace proxy-8904, will wait for the garbage collector to delete the pods
Oct 21 17:13:09.795: INFO: Deleting ReplicationController proxy-service-j4s8n took: 18.955262ms
Oct 21 17:13:09.895: INFO: Terminating ReplicationController proxy-service-j4s8n pods took: 100.150389ms
[AfterEach] version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:13:18.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8904" for this suite.
Oct 21 17:13:24.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:13:24.818: INFO: namespace proxy-8904 deletion completed in 6.409719914s

• [SLOW TEST:21.739 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:13:24.818: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8308
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1021 17:13:55.129093      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 21 17:13:55.129: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:13:55.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8308" for this suite.
Oct 21 17:14:01.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:14:01.629: INFO: namespace gc-8308 deletion completed in 6.488045967s

• [SLOW TEST:36.810 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:14:01.629: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4551
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Oct 21 17:14:01.879: INFO: Pod name pod-release: Found 0 pods out of 1
Oct 21 17:14:07.165: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:14:07.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4551" for this suite.
Oct 21 17:14:13.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:14:13.625: INFO: namespace replication-controller-4551 deletion completed in 6.387014827s

• [SLOW TEST:11.996 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:14:13.626: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6300
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 17:14:13.860: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3482277b-f426-11e9-ae8d-bacadc8895d2" in namespace "downward-api-6300" to be "success or failure"
Oct 21 17:14:13.873: INFO: Pod "downwardapi-volume-3482277b-f426-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.182975ms
Oct 21 17:14:15.881: INFO: Pod "downwardapi-volume-3482277b-f426-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020879096s
Oct 21 17:14:17.896: INFO: Pod "downwardapi-volume-3482277b-f426-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035194947s
STEP: Saw pod success
Oct 21 17:14:17.896: INFO: Pod "downwardapi-volume-3482277b-f426-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:14:17.904: INFO: Trying to get logs from node 10.134.235.118 pod downwardapi-volume-3482277b-f426-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 17:14:17.958: INFO: Waiting for pod downwardapi-volume-3482277b-f426-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:14:17.970: INFO: Pod downwardapi-volume-3482277b-f426-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:14:17.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6300" for this suite.
Oct 21 17:14:24.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:14:24.443: INFO: namespace downward-api-6300 deletion completed in 6.456380317s

• [SLOW TEST:10.818 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:14:24.445: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7901
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-3af524ca-f426-11e9-ae8d-bacadc8895d2
STEP: Creating secret with name secret-projected-all-test-volume-3af524ae-f426-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test Check all projections for projected volume plugin
Oct 21 17:14:24.708: INFO: Waiting up to 5m0s for pod "projected-volume-3af52477-f426-11e9-ae8d-bacadc8895d2" in namespace "projected-7901" to be "success or failure"
Oct 21 17:14:24.721: INFO: Pod "projected-volume-3af52477-f426-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.956474ms
Oct 21 17:14:26.731: INFO: Pod "projected-volume-3af52477-f426-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022779421s
STEP: Saw pod success
Oct 21 17:14:26.731: INFO: Pod "projected-volume-3af52477-f426-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:14:26.743: INFO: Trying to get logs from node 10.134.235.67 pod projected-volume-3af52477-f426-11e9-ae8d-bacadc8895d2 container projected-all-volume-test: <nil>
STEP: delete the pod
Oct 21 17:14:26.799: INFO: Waiting for pod projected-volume-3af52477-f426-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:14:26.808: INFO: Pod projected-volume-3af52477-f426-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:14:26.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7901" for this suite.
Oct 21 17:14:32.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:14:33.177: INFO: namespace projected-7901 deletion completed in 6.355474427s

• [SLOW TEST:8.732 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:14:33.177: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3284
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-402b2d7b-f426-11e9-ae8d-bacadc8895d2
STEP: Creating configMap with name cm-test-opt-upd-402b2dc4-f426-11e9-ae8d-bacadc8895d2
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-402b2d7b-f426-11e9-ae8d-bacadc8895d2
STEP: Updating configmap cm-test-opt-upd-402b2dc4-f426-11e9-ae8d-bacadc8895d2
STEP: Creating configMap with name cm-test-opt-create-402b2dde-f426-11e9-ae8d-bacadc8895d2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:16:07.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3284" for this suite.
Oct 21 17:16:31.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:16:31.861: INFO: namespace configmap-3284 deletion completed in 24.595747645s

• [SLOW TEST:118.685 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:16:31.863: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1761
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-86e6e07d-f426-11e9-ae8d-bacadc8895d2
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:16:32.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1761" for this suite.
Oct 21 17:16:38.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:16:38.791: INFO: namespace configmap-1761 deletion completed in 6.69212959s

• [SLOW TEST:6.928 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:16:38.791: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4949
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 21 17:16:39.029: INFO: Waiting up to 5m0s for pod "pod-8b09cc95-f426-11e9-ae8d-bacadc8895d2" in namespace "emptydir-4949" to be "success or failure"
Oct 21 17:16:39.042: INFO: Pod "pod-8b09cc95-f426-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.462679ms
Oct 21 17:16:41.051: INFO: Pod "pod-8b09cc95-f426-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021934122s
STEP: Saw pod success
Oct 21 17:16:41.051: INFO: Pod "pod-8b09cc95-f426-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:16:41.064: INFO: Trying to get logs from node 10.134.235.67 pod pod-8b09cc95-f426-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 17:16:41.125: INFO: Waiting for pod pod-8b09cc95-f426-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:16:41.136: INFO: Pod pod-8b09cc95-f426-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:16:41.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4949" for this suite.
Oct 21 17:16:47.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:16:47.516: INFO: namespace emptydir-4949 deletion completed in 6.367860121s

• [SLOW TEST:8.725 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:16:47.516: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8497
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-8497
Oct 21 17:16:51.761: INFO: Started pod liveness-http in namespace container-probe-8497
STEP: checking the pod's current state and verifying that restartCount is present
Oct 21 17:16:51.771: INFO: Initial restart count of pod liveness-http is 0
Oct 21 17:17:07.974: INFO: Restart count of pod container-probe-8497/liveness-http is now 1 (16.203203939s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:17:08.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8497" for this suite.
Oct 21 17:17:14.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:17:14.406: INFO: namespace container-probe-8497 deletion completed in 6.385741772s

• [SLOW TEST:26.890 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:17:14.406: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2886
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1021 17:17:15.397816      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 21 17:17:15.397: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:17:15.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2886" for this suite.
Oct 21 17:17:21.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:17:21.784: INFO: namespace gc-2886 deletion completed in 6.372245638s

• [SLOW TEST:7.378 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:17:21.785: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-6628
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6628
I1021 17:17:22.002006      17 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6628, replica count: 1
I1021 17:17:23.052593      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1021 17:17:24.052894      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 21 17:17:24.276: INFO: Created: latency-svc-6k6qj
Oct 21 17:17:24.276: INFO: Got endpoints: latency-svc-6k6qj [123.840489ms]
Oct 21 17:17:24.317: INFO: Created: latency-svc-rvmtm
Oct 21 17:17:24.323: INFO: Got endpoints: latency-svc-rvmtm [46.701804ms]
Oct 21 17:17:24.339: INFO: Created: latency-svc-7gdml
Oct 21 17:17:24.347: INFO: Got endpoints: latency-svc-7gdml [70.225677ms]
Oct 21 17:17:24.363: INFO: Created: latency-svc-xvbhm
Oct 21 17:17:24.372: INFO: Got endpoints: latency-svc-xvbhm [94.958036ms]
Oct 21 17:17:24.378: INFO: Created: latency-svc-klb6n
Oct 21 17:17:24.386: INFO: Got endpoints: latency-svc-klb6n [108.931284ms]
Oct 21 17:17:24.393: INFO: Created: latency-svc-jjh8x
Oct 21 17:17:24.399: INFO: Got endpoints: latency-svc-jjh8x [122.323965ms]
Oct 21 17:17:24.411: INFO: Created: latency-svc-wwk8t
Oct 21 17:17:24.417: INFO: Got endpoints: latency-svc-wwk8t [140.536912ms]
Oct 21 17:17:24.428: INFO: Created: latency-svc-sjmfm
Oct 21 17:17:24.447: INFO: Got endpoints: latency-svc-sjmfm [169.837805ms]
Oct 21 17:17:24.453: INFO: Created: latency-svc-nmt7h
Oct 21 17:17:24.458: INFO: Got endpoints: latency-svc-nmt7h [181.269067ms]
Oct 21 17:17:24.477: INFO: Created: latency-svc-qpnqh
Oct 21 17:17:24.483: INFO: Got endpoints: latency-svc-qpnqh [206.243932ms]
Oct 21 17:17:24.497: INFO: Created: latency-svc-gk728
Oct 21 17:17:24.504: INFO: Got endpoints: latency-svc-gk728 [227.619448ms]
Oct 21 17:17:24.522: INFO: Created: latency-svc-dnm7x
Oct 21 17:17:24.531: INFO: Got endpoints: latency-svc-dnm7x [253.63073ms]
Oct 21 17:17:24.542: INFO: Created: latency-svc-x9d9f
Oct 21 17:17:24.550: INFO: Got endpoints: latency-svc-x9d9f [273.297317ms]
Oct 21 17:17:24.557: INFO: Created: latency-svc-p5p9t
Oct 21 17:17:24.565: INFO: Got endpoints: latency-svc-p5p9t [287.985359ms]
Oct 21 17:17:24.572: INFO: Created: latency-svc-fqpnk
Oct 21 17:17:24.587: INFO: Got endpoints: latency-svc-fqpnk [310.043407ms]
Oct 21 17:17:24.591: INFO: Created: latency-svc-ch86l
Oct 21 17:17:24.597: INFO: Got endpoints: latency-svc-ch86l [319.775348ms]
Oct 21 17:17:24.612: INFO: Created: latency-svc-hbs2s
Oct 21 17:17:24.619: INFO: Got endpoints: latency-svc-hbs2s [295.870474ms]
Oct 21 17:17:24.632: INFO: Created: latency-svc-bwvc8
Oct 21 17:17:24.637: INFO: Got endpoints: latency-svc-bwvc8 [290.408063ms]
Oct 21 17:17:25.255: INFO: Created: latency-svc-gn8bs
Oct 21 17:17:25.255: INFO: Got endpoints: latency-svc-gn8bs [855.724819ms]
Oct 21 17:17:25.255: INFO: Created: latency-svc-42ndt
Oct 21 17:17:25.255: INFO: Got endpoints: latency-svc-42ndt [869.417377ms]
Oct 21 17:17:25.255: INFO: Created: latency-svc-662kc
Oct 21 17:17:25.255: INFO: Got endpoints: latency-svc-662kc [883.578012ms]
Oct 21 17:17:25.271: INFO: Created: latency-svc-fl9vt
Oct 21 17:17:25.271: INFO: Created: latency-svc-k8vhd
Oct 21 17:17:25.271: INFO: Got endpoints: latency-svc-k8vhd [766.750117ms]
Oct 21 17:17:25.271: INFO: Got endpoints: latency-svc-fl9vt [854.202433ms]
Oct 21 17:17:25.290: INFO: Created: latency-svc-pgfkv
Oct 21 17:17:25.290: INFO: Got endpoints: latency-svc-pgfkv [806.645739ms]
Oct 21 17:17:25.290: INFO: Created: latency-svc-4mrrp
Oct 21 17:17:25.290: INFO: Got endpoints: latency-svc-4mrrp [843.700795ms]
Oct 21 17:17:25.291: INFO: Created: latency-svc-dj8wc
Oct 21 17:17:25.291: INFO: Created: latency-svc-n6888
Oct 21 17:17:25.291: INFO: Got endpoints: latency-svc-dj8wc [740.273571ms]
Oct 21 17:17:25.291: INFO: Created: latency-svc-2wg6b
Oct 21 17:17:25.291: INFO: Got endpoints: latency-svc-2wg6b [703.85617ms]
Oct 21 17:17:25.291: INFO: Created: latency-svc-m78h7
Oct 21 17:17:25.291: INFO: Got endpoints: latency-svc-m78h7 [671.741852ms]
Oct 21 17:17:25.291: INFO: Created: latency-svc-vczbs
Oct 21 17:17:25.291: INFO: Got endpoints: latency-svc-vczbs [726.217907ms]
Oct 21 17:17:25.291: INFO: Got endpoints: latency-svc-n6888 [653.417118ms]
Oct 21 17:17:25.291: INFO: Created: latency-svc-l6xnd
Oct 21 17:17:25.291: INFO: Got endpoints: latency-svc-l6xnd [694.683572ms]
Oct 21 17:17:25.291: INFO: Created: latency-svc-smg55
Oct 21 17:17:25.291: INFO: Got endpoints: latency-svc-smg55 [760.714278ms]
Oct 21 17:17:25.292: INFO: Created: latency-svc-kncfp
Oct 21 17:17:25.292: INFO: Got endpoints: latency-svc-kncfp [834.020862ms]
Oct 21 17:17:25.301: INFO: Created: latency-svc-m9vms
Oct 21 17:17:25.305: INFO: Got endpoints: latency-svc-m9vms [50.318621ms]
Oct 21 17:17:25.321: INFO: Created: latency-svc-n9dq8
Oct 21 17:17:25.329: INFO: Got endpoints: latency-svc-n9dq8 [73.636396ms]
Oct 21 17:17:25.342: INFO: Created: latency-svc-bx7pz
Oct 21 17:17:25.354: INFO: Got endpoints: latency-svc-bx7pz [98.152504ms]
Oct 21 17:17:25.361: INFO: Created: latency-svc-6gnfj
Oct 21 17:17:25.370: INFO: Got endpoints: latency-svc-6gnfj [98.789244ms]
Oct 21 17:17:25.382: INFO: Created: latency-svc-tcjwc
Oct 21 17:17:25.392: INFO: Got endpoints: latency-svc-tcjwc [120.420324ms]
Oct 21 17:17:25.403: INFO: Created: latency-svc-ws4kj
Oct 21 17:17:25.413: INFO: Got endpoints: latency-svc-ws4kj [123.025835ms]
Oct 21 17:17:25.430: INFO: Created: latency-svc-hbzhs
Oct 21 17:17:25.435: INFO: Got endpoints: latency-svc-hbzhs [43.124801ms]
Oct 21 17:17:25.459: INFO: Created: latency-svc-sfd9k
Oct 21 17:17:25.465: INFO: Got endpoints: latency-svc-sfd9k [174.639201ms]
Oct 21 17:17:25.478: INFO: Created: latency-svc-rj8w8
Oct 21 17:17:25.480: INFO: Got endpoints: latency-svc-rj8w8 [189.051781ms]
Oct 21 17:17:25.500: INFO: Created: latency-svc-sn8c4
Oct 21 17:17:25.513: INFO: Got endpoints: latency-svc-sn8c4 [222.787305ms]
Oct 21 17:17:25.538: INFO: Created: latency-svc-h99bn
Oct 21 17:17:25.541: INFO: Got endpoints: latency-svc-h99bn [250.816882ms]
Oct 21 17:17:25.556: INFO: Created: latency-svc-dp8mw
Oct 21 17:17:25.564: INFO: Got endpoints: latency-svc-dp8mw [272.801209ms]
Oct 21 17:17:25.579: INFO: Created: latency-svc-dwfl9
Oct 21 17:17:25.586: INFO: Got endpoints: latency-svc-dwfl9 [295.157033ms]
Oct 21 17:17:25.600: INFO: Created: latency-svc-97ql6
Oct 21 17:17:25.607: INFO: Got endpoints: latency-svc-97ql6 [316.062201ms]
Oct 21 17:17:25.619: INFO: Created: latency-svc-7dvxs
Oct 21 17:17:25.626: INFO: Got endpoints: latency-svc-7dvxs [333.855713ms]
Oct 21 17:17:25.639: INFO: Created: latency-svc-n4qql
Oct 21 17:17:25.648: INFO: Got endpoints: latency-svc-n4qql [356.949228ms]
Oct 21 17:17:25.654: INFO: Created: latency-svc-7d6t6
Oct 21 17:17:25.661: INFO: Got endpoints: latency-svc-7d6t6 [355.940341ms]
Oct 21 17:17:25.675: INFO: Created: latency-svc-gxjcs
Oct 21 17:17:25.690: INFO: Got endpoints: latency-svc-gxjcs [361.348892ms]
Oct 21 17:17:25.700: INFO: Created: latency-svc-4z9db
Oct 21 17:17:25.702: INFO: Got endpoints: latency-svc-4z9db [348.186259ms]
Oct 21 17:17:25.719: INFO: Created: latency-svc-lrl74
Oct 21 17:17:25.727: INFO: Got endpoints: latency-svc-lrl74 [356.73667ms]
Oct 21 17:17:25.738: INFO: Created: latency-svc-xkdd2
Oct 21 17:17:25.745: INFO: Got endpoints: latency-svc-xkdd2 [331.797942ms]
Oct 21 17:17:25.755: INFO: Created: latency-svc-rtnj5
Oct 21 17:17:25.765: INFO: Got endpoints: latency-svc-rtnj5 [329.81368ms]
Oct 21 17:17:25.780: INFO: Created: latency-svc-cwhzx
Oct 21 17:17:25.783: INFO: Got endpoints: latency-svc-cwhzx [318.04684ms]
Oct 21 17:17:25.795: INFO: Created: latency-svc-r57k5
Oct 21 17:17:25.807: INFO: Got endpoints: latency-svc-r57k5 [327.158481ms]
Oct 21 17:17:25.821: INFO: Created: latency-svc-sdvzz
Oct 21 17:17:25.826: INFO: Got endpoints: latency-svc-sdvzz [312.196102ms]
Oct 21 17:17:25.841: INFO: Created: latency-svc-58vvr
Oct 21 17:17:25.849: INFO: Got endpoints: latency-svc-58vvr [308.093958ms]
Oct 21 17:17:25.862: INFO: Created: latency-svc-shbqr
Oct 21 17:17:25.870: INFO: Got endpoints: latency-svc-shbqr [305.170514ms]
Oct 21 17:17:25.890: INFO: Created: latency-svc-tgvpt
Oct 21 17:17:25.898: INFO: Got endpoints: latency-svc-tgvpt [311.742058ms]
Oct 21 17:17:25.905: INFO: Created: latency-svc-mghnf
Oct 21 17:17:25.912: INFO: Got endpoints: latency-svc-mghnf [304.561553ms]
Oct 21 17:17:25.924: INFO: Created: latency-svc-pxd5f
Oct 21 17:17:25.931: INFO: Got endpoints: latency-svc-pxd5f [305.105752ms]
Oct 21 17:17:25.941: INFO: Created: latency-svc-zr9mr
Oct 21 17:17:25.949: INFO: Got endpoints: latency-svc-zr9mr [301.069822ms]
Oct 21 17:17:25.963: INFO: Created: latency-svc-9bzzv
Oct 21 17:17:25.969: INFO: Got endpoints: latency-svc-9bzzv [307.241096ms]
Oct 21 17:17:25.982: INFO: Created: latency-svc-r4l65
Oct 21 17:17:25.988: INFO: Got endpoints: latency-svc-r4l65 [297.451049ms]
Oct 21 17:17:26.002: INFO: Created: latency-svc-72hgp
Oct 21 17:17:26.009: INFO: Got endpoints: latency-svc-72hgp [307.319693ms]
Oct 21 17:17:26.027: INFO: Created: latency-svc-qsk9j
Oct 21 17:17:26.035: INFO: Got endpoints: latency-svc-qsk9j [307.830136ms]
Oct 21 17:17:26.051: INFO: Created: latency-svc-hkn4w
Oct 21 17:17:26.055: INFO: Got endpoints: latency-svc-hkn4w [310.385756ms]
Oct 21 17:17:26.072: INFO: Created: latency-svc-q6ljs
Oct 21 17:17:26.079: INFO: Got endpoints: latency-svc-q6ljs [314.552216ms]
Oct 21 17:17:26.092: INFO: Created: latency-svc-5dlwm
Oct 21 17:17:26.098: INFO: Got endpoints: latency-svc-5dlwm [315.050675ms]
Oct 21 17:17:26.117: INFO: Created: latency-svc-h57wn
Oct 21 17:17:26.127: INFO: Got endpoints: latency-svc-h57wn [319.130736ms]
Oct 21 17:17:26.139: INFO: Created: latency-svc-dc2mv
Oct 21 17:17:26.143: INFO: Got endpoints: latency-svc-dc2mv [317.486821ms]
Oct 21 17:17:26.153: INFO: Created: latency-svc-p5cg2
Oct 21 17:17:26.162: INFO: Got endpoints: latency-svc-p5cg2 [312.79251ms]
Oct 21 17:17:26.174: INFO: Created: latency-svc-28mvb
Oct 21 17:17:26.183: INFO: Got endpoints: latency-svc-28mvb [313.46545ms]
Oct 21 17:17:26.194: INFO: Created: latency-svc-mv5kk
Oct 21 17:17:26.204: INFO: Got endpoints: latency-svc-mv5kk [305.405749ms]
Oct 21 17:17:26.211: INFO: Created: latency-svc-2m6wf
Oct 21 17:17:26.217: INFO: Got endpoints: latency-svc-2m6wf [305.309881ms]
Oct 21 17:17:26.228: INFO: Created: latency-svc-7hvjl
Oct 21 17:17:26.235: INFO: Got endpoints: latency-svc-7hvjl [304.297908ms]
Oct 21 17:17:26.247: INFO: Created: latency-svc-cbzd4
Oct 21 17:17:26.256: INFO: Got endpoints: latency-svc-cbzd4 [306.600427ms]
Oct 21 17:17:26.270: INFO: Created: latency-svc-swsf6
Oct 21 17:17:26.276: INFO: Got endpoints: latency-svc-swsf6 [307.622735ms]
Oct 21 17:17:26.291: INFO: Created: latency-svc-9x6h6
Oct 21 17:17:26.299: INFO: Got endpoints: latency-svc-9x6h6 [310.865279ms]
Oct 21 17:17:26.314: INFO: Created: latency-svc-wdlm2
Oct 21 17:17:26.325: INFO: Got endpoints: latency-svc-wdlm2 [315.489403ms]
Oct 21 17:17:26.333: INFO: Created: latency-svc-9c5rb
Oct 21 17:17:26.343: INFO: Got endpoints: latency-svc-9c5rb [307.627044ms]
Oct 21 17:17:26.355: INFO: Created: latency-svc-gq6j5
Oct 21 17:17:26.375: INFO: Got endpoints: latency-svc-gq6j5 [319.448179ms]
Oct 21 17:17:26.386: INFO: Created: latency-svc-8thw2
Oct 21 17:17:26.400: INFO: Got endpoints: latency-svc-8thw2 [320.848851ms]
Oct 21 17:17:26.407: INFO: Created: latency-svc-ljcts
Oct 21 17:17:26.417: INFO: Got endpoints: latency-svc-ljcts [317.98311ms]
Oct 21 17:17:26.431: INFO: Created: latency-svc-bv5pj
Oct 21 17:17:26.439: INFO: Got endpoints: latency-svc-bv5pj [312.50323ms]
Oct 21 17:17:26.451: INFO: Created: latency-svc-8c7qh
Oct 21 17:17:26.462: INFO: Got endpoints: latency-svc-8c7qh [318.530421ms]
Oct 21 17:17:26.469: INFO: Created: latency-svc-dcsgk
Oct 21 17:17:26.476: INFO: Got endpoints: latency-svc-dcsgk [314.128889ms]
Oct 21 17:17:26.490: INFO: Created: latency-svc-w9cwd
Oct 21 17:17:26.499: INFO: Got endpoints: latency-svc-w9cwd [315.547223ms]
Oct 21 17:17:26.513: INFO: Created: latency-svc-wxcsh
Oct 21 17:17:26.523: INFO: Got endpoints: latency-svc-wxcsh [319.829224ms]
Oct 21 17:17:26.535: INFO: Created: latency-svc-zh4v5
Oct 21 17:17:26.542: INFO: Got endpoints: latency-svc-zh4v5 [324.924193ms]
Oct 21 17:17:26.554: INFO: Created: latency-svc-fnz5z
Oct 21 17:17:26.558: INFO: Got endpoints: latency-svc-fnz5z [322.932003ms]
Oct 21 17:17:26.577: INFO: Created: latency-svc-rqm9z
Oct 21 17:17:26.582: INFO: Got endpoints: latency-svc-rqm9z [326.435331ms]
Oct 21 17:17:26.603: INFO: Created: latency-svc-cshwf
Oct 21 17:17:26.609: INFO: Got endpoints: latency-svc-cshwf [332.864604ms]
Oct 21 17:17:26.626: INFO: Created: latency-svc-wmbss
Oct 21 17:17:26.631: INFO: Got endpoints: latency-svc-wmbss [331.825807ms]
Oct 21 17:17:26.649: INFO: Created: latency-svc-9pjnn
Oct 21 17:17:26.656: INFO: Got endpoints: latency-svc-9pjnn [330.824266ms]
Oct 21 17:17:26.671: INFO: Created: latency-svc-w59nj
Oct 21 17:17:26.681: INFO: Got endpoints: latency-svc-w59nj [337.913838ms]
Oct 21 17:17:27.108: INFO: Created: latency-svc-pljcj
Oct 21 17:17:27.115: INFO: Got endpoints: latency-svc-pljcj [740.648623ms]
Oct 21 17:17:27.134: INFO: Created: latency-svc-sfzpv
Oct 21 17:17:27.140: INFO: Got endpoints: latency-svc-sfzpv [739.493538ms]
Oct 21 17:17:27.157: INFO: Created: latency-svc-vl2k9
Oct 21 17:17:27.167: INFO: Got endpoints: latency-svc-vl2k9 [750.366234ms]
Oct 21 17:17:27.179: INFO: Created: latency-svc-hlpv9
Oct 21 17:17:27.187: INFO: Got endpoints: latency-svc-hlpv9 [747.251071ms]
Oct 21 17:17:27.205: INFO: Created: latency-svc-8dfm6
Oct 21 17:17:27.217: INFO: Got endpoints: latency-svc-8dfm6 [754.676115ms]
Oct 21 17:17:27.225: INFO: Created: latency-svc-llrdb
Oct 21 17:17:27.232: INFO: Got endpoints: latency-svc-llrdb [755.683946ms]
Oct 21 17:17:27.251: INFO: Created: latency-svc-xnxxc
Oct 21 17:17:27.260: INFO: Got endpoints: latency-svc-xnxxc [761.014711ms]
Oct 21 17:17:27.286: INFO: Created: latency-svc-fg7zh
Oct 21 17:17:27.293: INFO: Got endpoints: latency-svc-fg7zh [769.4437ms]
Oct 21 17:17:27.317: INFO: Created: latency-svc-zdt74
Oct 21 17:17:27.324: INFO: Got endpoints: latency-svc-zdt74 [781.553721ms]
Oct 21 17:17:27.349: INFO: Created: latency-svc-vwg8k
Oct 21 17:17:27.353: INFO: Got endpoints: latency-svc-vwg8k [794.968074ms]
Oct 21 17:17:27.367: INFO: Created: latency-svc-872l9
Oct 21 17:17:27.384: INFO: Got endpoints: latency-svc-872l9 [801.47736ms]
Oct 21 17:17:27.392: INFO: Created: latency-svc-859zb
Oct 21 17:17:27.400: INFO: Got endpoints: latency-svc-859zb [791.093303ms]
Oct 21 17:17:27.405: INFO: Created: latency-svc-nn7hz
Oct 21 17:17:27.410: INFO: Got endpoints: latency-svc-nn7hz [779.470205ms]
Oct 21 17:17:27.436: INFO: Created: latency-svc-z5lmz
Oct 21 17:17:27.445: INFO: Got endpoints: latency-svc-z5lmz [789.660614ms]
Oct 21 17:17:27.462: INFO: Created: latency-svc-nrrqs
Oct 21 17:17:27.466: INFO: Got endpoints: latency-svc-nrrqs [785.425089ms]
Oct 21 17:17:27.486: INFO: Created: latency-svc-9jkdd
Oct 21 17:17:27.496: INFO: Got endpoints: latency-svc-9jkdd [380.252063ms]
Oct 21 17:17:27.506: INFO: Created: latency-svc-mcddk
Oct 21 17:17:27.513: INFO: Got endpoints: latency-svc-mcddk [373.238483ms]
Oct 21 17:17:27.527: INFO: Created: latency-svc-slsjn
Oct 21 17:17:27.539: INFO: Got endpoints: latency-svc-slsjn [372.260822ms]
Oct 21 17:17:27.546: INFO: Created: latency-svc-gmkqp
Oct 21 17:17:27.554: INFO: Got endpoints: latency-svc-gmkqp [367.486242ms]
Oct 21 17:17:27.567: INFO: Created: latency-svc-5ll4h
Oct 21 17:17:27.600: INFO: Got endpoints: latency-svc-5ll4h [383.828674ms]
Oct 21 17:17:27.609: INFO: Created: latency-svc-dlcc6
Oct 21 17:17:27.616: INFO: Got endpoints: latency-svc-dlcc6 [383.614794ms]
Oct 21 17:17:27.632: INFO: Created: latency-svc-zk5zd
Oct 21 17:17:27.637: INFO: Got endpoints: latency-svc-zk5zd [377.323166ms]
Oct 21 17:17:27.659: INFO: Created: latency-svc-2x8w5
Oct 21 17:17:27.669: INFO: Got endpoints: latency-svc-2x8w5 [376.018426ms]
Oct 21 17:17:27.680: INFO: Created: latency-svc-5vbv6
Oct 21 17:17:27.687: INFO: Got endpoints: latency-svc-5vbv6 [362.829423ms]
Oct 21 17:17:27.696: INFO: Created: latency-svc-ggsxs
Oct 21 17:17:27.705: INFO: Got endpoints: latency-svc-ggsxs [351.404099ms]
Oct 21 17:17:27.714: INFO: Created: latency-svc-frt9b
Oct 21 17:17:27.724: INFO: Got endpoints: latency-svc-frt9b [340.53971ms]
Oct 21 17:17:27.732: INFO: Created: latency-svc-s277k
Oct 21 17:17:27.735: INFO: Got endpoints: latency-svc-s277k [334.632378ms]
Oct 21 17:17:27.743: INFO: Created: latency-svc-56h9z
Oct 21 17:17:27.759: INFO: Got endpoints: latency-svc-56h9z [348.877914ms]
Oct 21 17:17:27.767: INFO: Created: latency-svc-mx8fd
Oct 21 17:17:27.775: INFO: Got endpoints: latency-svc-mx8fd [329.497407ms]
Oct 21 17:17:27.789: INFO: Created: latency-svc-6dj9n
Oct 21 17:17:27.799: INFO: Got endpoints: latency-svc-6dj9n [332.141913ms]
Oct 21 17:17:27.819: INFO: Created: latency-svc-8d46p
Oct 21 17:17:27.820: INFO: Got endpoints: latency-svc-8d46p [324.710936ms]
Oct 21 17:17:27.835: INFO: Created: latency-svc-gkrtv
Oct 21 17:17:27.843: INFO: Got endpoints: latency-svc-gkrtv [329.616902ms]
Oct 21 17:17:27.856: INFO: Created: latency-svc-wwpm7
Oct 21 17:17:27.862: INFO: Got endpoints: latency-svc-wwpm7 [322.89854ms]
Oct 21 17:17:27.869: INFO: Created: latency-svc-lqpkm
Oct 21 17:17:27.881: INFO: Got endpoints: latency-svc-lqpkm [326.5387ms]
Oct 21 17:17:27.892: INFO: Created: latency-svc-qkvvs
Oct 21 17:17:27.907: INFO: Got endpoints: latency-svc-qkvvs [306.192129ms]
Oct 21 17:17:27.910: INFO: Created: latency-svc-494gd
Oct 21 17:17:27.919: INFO: Got endpoints: latency-svc-494gd [303.023989ms]
Oct 21 17:17:27.936: INFO: Created: latency-svc-jz8fc
Oct 21 17:17:27.943: INFO: Got endpoints: latency-svc-jz8fc [305.759558ms]
Oct 21 17:17:27.961: INFO: Created: latency-svc-6g44m
Oct 21 17:17:27.967: INFO: Got endpoints: latency-svc-6g44m [297.755347ms]
Oct 21 17:17:27.982: INFO: Created: latency-svc-cv2zh
Oct 21 17:17:27.992: INFO: Got endpoints: latency-svc-cv2zh [305.025403ms]
Oct 21 17:17:27.998: INFO: Created: latency-svc-2bjtv
Oct 21 17:17:28.003: INFO: Got endpoints: latency-svc-2bjtv [298.34904ms]
Oct 21 17:17:28.012: INFO: Created: latency-svc-phqjj
Oct 21 17:17:28.018: INFO: Got endpoints: latency-svc-phqjj [294.039798ms]
Oct 21 17:17:28.028: INFO: Created: latency-svc-ff9hx
Oct 21 17:17:28.037: INFO: Got endpoints: latency-svc-ff9hx [301.824469ms]
Oct 21 17:17:28.047: INFO: Created: latency-svc-plsbk
Oct 21 17:17:28.055: INFO: Got endpoints: latency-svc-plsbk [295.740627ms]
Oct 21 17:17:28.071: INFO: Created: latency-svc-6tpr7
Oct 21 17:17:28.076: INFO: Got endpoints: latency-svc-6tpr7 [300.853246ms]
Oct 21 17:17:28.100: INFO: Created: latency-svc-xc9nv
Oct 21 17:17:28.110: INFO: Got endpoints: latency-svc-xc9nv [311.181333ms]
Oct 21 17:17:28.121: INFO: Created: latency-svc-jllsb
Oct 21 17:17:28.128: INFO: Got endpoints: latency-svc-jllsb [308.026423ms]
Oct 21 17:17:28.147: INFO: Created: latency-svc-qn4kn
Oct 21 17:17:28.157: INFO: Got endpoints: latency-svc-qn4kn [313.645427ms]
Oct 21 17:17:28.169: INFO: Created: latency-svc-qjvvz
Oct 21 17:17:28.176: INFO: Got endpoints: latency-svc-qjvvz [313.672986ms]
Oct 21 17:17:28.190: INFO: Created: latency-svc-hb7l9
Oct 21 17:17:28.197: INFO: Got endpoints: latency-svc-hb7l9 [316.47761ms]
Oct 21 17:17:28.212: INFO: Created: latency-svc-9pdzf
Oct 21 17:17:28.222: INFO: Got endpoints: latency-svc-9pdzf [315.373936ms]
Oct 21 17:17:28.234: INFO: Created: latency-svc-p95qh
Oct 21 17:17:28.243: INFO: Got endpoints: latency-svc-p95qh [323.675643ms]
Oct 21 17:17:28.255: INFO: Created: latency-svc-chq74
Oct 21 17:17:28.264: INFO: Got endpoints: latency-svc-chq74 [320.892748ms]
Oct 21 17:17:28.277: INFO: Created: latency-svc-bsblx
Oct 21 17:17:28.289: INFO: Got endpoints: latency-svc-bsblx [321.623174ms]
Oct 21 17:17:28.298: INFO: Created: latency-svc-t6q5t
Oct 21 17:17:28.308: INFO: Got endpoints: latency-svc-t6q5t [315.736686ms]
Oct 21 17:17:28.320: INFO: Created: latency-svc-wqxrf
Oct 21 17:17:28.327: INFO: Got endpoints: latency-svc-wqxrf [323.738118ms]
Oct 21 17:17:28.344: INFO: Created: latency-svc-j78mj
Oct 21 17:17:28.357: INFO: Got endpoints: latency-svc-j78mj [338.160293ms]
Oct 21 17:17:28.368: INFO: Created: latency-svc-s6vqh
Oct 21 17:17:28.375: INFO: Got endpoints: latency-svc-s6vqh [338.024019ms]
Oct 21 17:17:28.400: INFO: Created: latency-svc-n96lv
Oct 21 17:17:28.408: INFO: Got endpoints: latency-svc-n96lv [352.609505ms]
Oct 21 17:17:28.426: INFO: Created: latency-svc-9qjhb
Oct 21 17:17:28.442: INFO: Got endpoints: latency-svc-9qjhb [365.599564ms]
Oct 21 17:17:28.449: INFO: Created: latency-svc-mr92w
Oct 21 17:17:28.457: INFO: Got endpoints: latency-svc-mr92w [347.439791ms]
Oct 21 17:17:28.470: INFO: Created: latency-svc-f9mx2
Oct 21 17:17:28.483: INFO: Got endpoints: latency-svc-f9mx2 [354.14434ms]
Oct 21 17:17:28.489: INFO: Created: latency-svc-m2fpj
Oct 21 17:17:28.498: INFO: Got endpoints: latency-svc-m2fpj [341.296041ms]
Oct 21 17:17:28.509: INFO: Created: latency-svc-lj9w5
Oct 21 17:17:28.516: INFO: Got endpoints: latency-svc-lj9w5 [339.940471ms]
Oct 21 17:17:28.541: INFO: Created: latency-svc-tcc5t
Oct 21 17:17:28.548: INFO: Got endpoints: latency-svc-tcc5t [350.449966ms]
Oct 21 17:17:28.565: INFO: Created: latency-svc-wchkc
Oct 21 17:17:28.574: INFO: Got endpoints: latency-svc-wchkc [352.070166ms]
Oct 21 17:17:28.587: INFO: Created: latency-svc-v4r8g
Oct 21 17:17:28.595: INFO: Got endpoints: latency-svc-v4r8g [352.207824ms]
Oct 21 17:17:28.611: INFO: Created: latency-svc-rh2vn
Oct 21 17:17:28.621: INFO: Got endpoints: latency-svc-rh2vn [357.312428ms]
Oct 21 17:17:28.643: INFO: Created: latency-svc-9nxb9
Oct 21 17:17:28.652: INFO: Got endpoints: latency-svc-9nxb9 [362.812867ms]
Oct 21 17:17:28.663: INFO: Created: latency-svc-v5cr8
Oct 21 17:17:28.670: INFO: Got endpoints: latency-svc-v5cr8 [362.072973ms]
Oct 21 17:17:28.681: INFO: Created: latency-svc-g9dpg
Oct 21 17:17:28.690: INFO: Got endpoints: latency-svc-g9dpg [363.119659ms]
Oct 21 17:17:28.698: INFO: Created: latency-svc-mpz5s
Oct 21 17:17:28.713: INFO: Got endpoints: latency-svc-mpz5s [356.279802ms]
Oct 21 17:17:28.720: INFO: Created: latency-svc-6c2lr
Oct 21 17:17:28.727: INFO: Got endpoints: latency-svc-6c2lr [351.543038ms]
Oct 21 17:17:28.739: INFO: Created: latency-svc-mkd5c
Oct 21 17:17:28.747: INFO: Got endpoints: latency-svc-mkd5c [338.656225ms]
Oct 21 17:17:28.777: INFO: Created: latency-svc-tjhmn
Oct 21 17:17:28.789: INFO: Got endpoints: latency-svc-tjhmn [347.853334ms]
Oct 21 17:17:28.798: INFO: Created: latency-svc-4b47p
Oct 21 17:17:28.805: INFO: Got endpoints: latency-svc-4b47p [347.799802ms]
Oct 21 17:17:28.814: INFO: Created: latency-svc-b4sdm
Oct 21 17:17:28.819: INFO: Got endpoints: latency-svc-b4sdm [336.380108ms]
Oct 21 17:17:28.829: INFO: Created: latency-svc-l969n
Oct 21 17:17:28.837: INFO: Got endpoints: latency-svc-l969n [338.88153ms]
Oct 21 17:17:28.848: INFO: Created: latency-svc-dxgr4
Oct 21 17:17:28.855: INFO: Got endpoints: latency-svc-dxgr4 [338.581232ms]
Oct 21 17:17:28.865: INFO: Created: latency-svc-r58hm
Oct 21 17:17:28.892: INFO: Created: latency-svc-l9j7v
Oct 21 17:17:28.892: INFO: Got endpoints: latency-svc-r58hm [344.172427ms]
Oct 21 17:17:28.894: INFO: Got endpoints: latency-svc-l9j7v [320.117611ms]
Oct 21 17:17:28.907: INFO: Created: latency-svc-m4ftx
Oct 21 17:17:28.917: INFO: Got endpoints: latency-svc-m4ftx [321.840931ms]
Oct 21 17:17:28.926: INFO: Created: latency-svc-xnbqr
Oct 21 17:17:28.940: INFO: Got endpoints: latency-svc-xnbqr [318.501909ms]
Oct 21 17:17:28.941: INFO: Created: latency-svc-xshkg
Oct 21 17:17:28.947: INFO: Got endpoints: latency-svc-xshkg [294.909972ms]
Oct 21 17:17:28.974: INFO: Created: latency-svc-pxvsz
Oct 21 17:17:28.981: INFO: Got endpoints: latency-svc-pxvsz [310.716704ms]
Oct 21 17:17:28.998: INFO: Created: latency-svc-s4cjw
Oct 21 17:17:29.002: INFO: Got endpoints: latency-svc-s4cjw [312.058422ms]
Oct 21 17:17:29.019: INFO: Created: latency-svc-jgbz2
Oct 21 17:17:29.028: INFO: Got endpoints: latency-svc-jgbz2 [315.022349ms]
Oct 21 17:17:29.049: INFO: Created: latency-svc-mspjt
Oct 21 17:17:29.055: INFO: Got endpoints: latency-svc-mspjt [328.541177ms]
Oct 21 17:17:29.073: INFO: Created: latency-svc-b77tg
Oct 21 17:17:29.080: INFO: Got endpoints: latency-svc-b77tg [333.175605ms]
Oct 21 17:17:29.099: INFO: Created: latency-svc-pz885
Oct 21 17:17:29.106: INFO: Got endpoints: latency-svc-pz885 [317.023768ms]
Oct 21 17:17:29.127: INFO: Created: latency-svc-hg6qz
Oct 21 17:17:29.139: INFO: Got endpoints: latency-svc-hg6qz [333.612928ms]
Oct 21 17:17:29.146: INFO: Created: latency-svc-78zks
Oct 21 17:17:29.156: INFO: Got endpoints: latency-svc-78zks [336.958041ms]
Oct 21 17:17:29.165: INFO: Created: latency-svc-xq56x
Oct 21 17:17:29.173: INFO: Got endpoints: latency-svc-xq56x [335.942443ms]
Oct 21 17:17:29.190: INFO: Created: latency-svc-lgjh8
Oct 21 17:17:29.195: INFO: Got endpoints: latency-svc-lgjh8 [340.21511ms]
Oct 21 17:17:29.209: INFO: Created: latency-svc-qkvhp
Oct 21 17:17:29.218: INFO: Got endpoints: latency-svc-qkvhp [325.774872ms]
Oct 21 17:17:29.230: INFO: Created: latency-svc-47htx
Oct 21 17:17:29.239: INFO: Got endpoints: latency-svc-47htx [344.913589ms]
Oct 21 17:17:29.246: INFO: Created: latency-svc-s4jps
Oct 21 17:17:29.255: INFO: Got endpoints: latency-svc-s4jps [338.298335ms]
Oct 21 17:17:29.262: INFO: Created: latency-svc-wsd5h
Oct 21 17:17:29.273: INFO: Got endpoints: latency-svc-wsd5h [333.138439ms]
Oct 21 17:17:29.282: INFO: Created: latency-svc-z7skn
Oct 21 17:17:29.289: INFO: Got endpoints: latency-svc-z7skn [342.814461ms]
Oct 21 17:17:29.300: INFO: Created: latency-svc-f67zv
Oct 21 17:17:29.307: INFO: Got endpoints: latency-svc-f67zv [326.08624ms]
Oct 21 17:17:29.332: INFO: Created: latency-svc-5lgxm
Oct 21 17:17:29.342: INFO: Got endpoints: latency-svc-5lgxm [339.109174ms]
Oct 21 17:17:29.355: INFO: Created: latency-svc-prn8l
Oct 21 17:17:29.359: INFO: Got endpoints: latency-svc-prn8l [331.368803ms]
Oct 21 17:17:29.380: INFO: Created: latency-svc-9rqg8
Oct 21 17:17:29.385: INFO: Got endpoints: latency-svc-9rqg8 [330.338681ms]
Oct 21 17:17:29.395: INFO: Created: latency-svc-6fxvx
Oct 21 17:17:29.401: INFO: Got endpoints: latency-svc-6fxvx [321.534272ms]
Oct 21 17:17:29.402: INFO: Latencies: [43.124801ms 46.701804ms 50.318621ms 70.225677ms 73.636396ms 94.958036ms 98.152504ms 98.789244ms 108.931284ms 120.420324ms 122.323965ms 123.025835ms 140.536912ms 169.837805ms 174.639201ms 181.269067ms 189.051781ms 206.243932ms 222.787305ms 227.619448ms 250.816882ms 253.63073ms 272.801209ms 273.297317ms 287.985359ms 290.408063ms 294.039798ms 294.909972ms 295.157033ms 295.740627ms 295.870474ms 297.451049ms 297.755347ms 298.34904ms 300.853246ms 301.069822ms 301.824469ms 303.023989ms 304.297908ms 304.561553ms 305.025403ms 305.105752ms 305.170514ms 305.309881ms 305.405749ms 305.759558ms 306.192129ms 306.600427ms 307.241096ms 307.319693ms 307.622735ms 307.627044ms 307.830136ms 308.026423ms 308.093958ms 310.043407ms 310.385756ms 310.716704ms 310.865279ms 311.181333ms 311.742058ms 312.058422ms 312.196102ms 312.50323ms 312.79251ms 313.46545ms 313.645427ms 313.672986ms 314.128889ms 314.552216ms 315.022349ms 315.050675ms 315.373936ms 315.489403ms 315.547223ms 315.736686ms 316.062201ms 316.47761ms 317.023768ms 317.486821ms 317.98311ms 318.04684ms 318.501909ms 318.530421ms 319.130736ms 319.448179ms 319.775348ms 319.829224ms 320.117611ms 320.848851ms 320.892748ms 321.534272ms 321.623174ms 321.840931ms 322.89854ms 322.932003ms 323.675643ms 323.738118ms 324.710936ms 324.924193ms 325.774872ms 326.08624ms 326.435331ms 326.5387ms 327.158481ms 328.541177ms 329.497407ms 329.616902ms 329.81368ms 330.338681ms 330.824266ms 331.368803ms 331.797942ms 331.825807ms 332.141913ms 332.864604ms 333.138439ms 333.175605ms 333.612928ms 333.855713ms 334.632378ms 335.942443ms 336.380108ms 336.958041ms 337.913838ms 338.024019ms 338.160293ms 338.298335ms 338.581232ms 338.656225ms 338.88153ms 339.109174ms 339.940471ms 340.21511ms 340.53971ms 341.296041ms 342.814461ms 344.172427ms 344.913589ms 347.439791ms 347.799802ms 347.853334ms 348.186259ms 348.877914ms 350.449966ms 351.404099ms 351.543038ms 352.070166ms 352.207824ms 352.609505ms 354.14434ms 355.940341ms 356.279802ms 356.73667ms 356.949228ms 357.312428ms 361.348892ms 362.072973ms 362.812867ms 362.829423ms 363.119659ms 365.599564ms 367.486242ms 372.260822ms 373.238483ms 376.018426ms 377.323166ms 380.252063ms 383.614794ms 383.828674ms 653.417118ms 671.741852ms 694.683572ms 703.85617ms 726.217907ms 739.493538ms 740.273571ms 740.648623ms 747.251071ms 750.366234ms 754.676115ms 755.683946ms 760.714278ms 761.014711ms 766.750117ms 769.4437ms 779.470205ms 781.553721ms 785.425089ms 789.660614ms 791.093303ms 794.968074ms 801.47736ms 806.645739ms 834.020862ms 843.700795ms 854.202433ms 855.724819ms 869.417377ms 883.578012ms]
Oct 21 17:17:29.402: INFO: 50 %ile: 325.774872ms
Oct 21 17:17:29.402: INFO: 90 %ile: 754.676115ms
Oct 21 17:17:29.402: INFO: 99 %ile: 869.417377ms
Oct 21 17:17:29.402: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:17:29.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6628" for this suite.
Oct 21 17:17:47.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:17:47.805: INFO: namespace svc-latency-6628 deletion completed in 18.384958941s

• [SLOW TEST:26.021 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:17:47.806: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3734
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 21 17:17:48.080: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Oct 21 17:17:48.102: INFO: Number of nodes with available pods: 0
Oct 21 17:17:48.102: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Oct 21 17:17:48.151: INFO: Number of nodes with available pods: 0
Oct 21 17:17:48.151: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 17:17:49.160: INFO: Number of nodes with available pods: 0
Oct 21 17:17:49.160: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 17:17:50.162: INFO: Number of nodes with available pods: 0
Oct 21 17:17:50.162: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 17:17:51.159: INFO: Number of nodes with available pods: 1
Oct 21 17:17:51.159: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Oct 21 17:17:51.199: INFO: Number of nodes with available pods: 1
Oct 21 17:17:51.199: INFO: Number of running nodes: 0, number of available pods: 1
Oct 21 17:17:52.209: INFO: Number of nodes with available pods: 0
Oct 21 17:17:52.209: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Oct 21 17:17:52.229: INFO: Number of nodes with available pods: 0
Oct 21 17:17:52.229: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 17:17:53.238: INFO: Number of nodes with available pods: 0
Oct 21 17:17:53.238: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 17:17:54.239: INFO: Number of nodes with available pods: 0
Oct 21 17:17:54.239: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 17:17:55.242: INFO: Number of nodes with available pods: 0
Oct 21 17:17:55.242: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 17:17:56.248: INFO: Number of nodes with available pods: 0
Oct 21 17:17:56.248: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 17:17:57.239: INFO: Number of nodes with available pods: 0
Oct 21 17:17:57.239: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 17:17:58.237: INFO: Number of nodes with available pods: 0
Oct 21 17:17:58.237: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 17:17:59.238: INFO: Number of nodes with available pods: 0
Oct 21 17:17:59.238: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 17:18:00.249: INFO: Number of nodes with available pods: 0
Oct 21 17:18:00.249: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 17:18:01.242: INFO: Number of nodes with available pods: 0
Oct 21 17:18:01.242: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 17:18:02.239: INFO: Number of nodes with available pods: 0
Oct 21 17:18:02.239: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 17:18:03.239: INFO: Number of nodes with available pods: 0
Oct 21 17:18:03.239: INFO: Node 10.134.235.118 is running more than one daemon pod
Oct 21 17:18:04.241: INFO: Number of nodes with available pods: 1
Oct 21 17:18:04.241: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3734, will wait for the garbage collector to delete the pods
Oct 21 17:18:04.361: INFO: Deleting DaemonSet.extensions daemon-set took: 40.394964ms
Oct 21 17:18:04.461: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.169993ms
Oct 21 17:18:07.475: INFO: Number of nodes with available pods: 0
Oct 21 17:18:07.475: INFO: Number of running nodes: 0, number of available pods: 0
Oct 21 17:18:07.486: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3734/daemonsets","resourceVersion":"42854"},"items":null}

Oct 21 17:18:07.494: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3734/pods","resourceVersion":"42854"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:18:07.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3734" for this suite.
Oct 21 17:18:13.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:18:14.049: INFO: namespace daemonsets-3734 deletion completed in 6.471939926s

• [SLOW TEST:26.243 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:18:14.049: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4767
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct 21 17:18:14.286: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 21 17:18:14.311: INFO: Waiting for terminating namespaces to be deleted...
Oct 21 17:18:14.320: INFO: 
Logging pods the kubelet thinks is on node 10.134.235.118 before test
Oct 21 17:18:14.356: INFO: vpn-7754bb6d4-2n6w7 from kube-system started at 2019-10-21 14:35:37 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.356: INFO: 	Container vpn ready: true, restart count 0
Oct 21 17:18:14.356: INFO: ibm-master-proxy-static-10.134.235.118 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 17:18:14.356: INFO: ibm-keepalived-watcher-s768g from kube-system started at 2019-10-21 14:16:32 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.356: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 17:18:14.356: INFO: coredns-9dd7747c7-cgj4m from kube-system started at 2019-10-21 14:35:59 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.356: INFO: 	Container coredns ready: true, restart count 0
Oct 21 17:18:14.356: INFO: sonobuoy from sonobuoy started at 2019-10-21 15:48:00 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.356: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 21 17:18:14.356: INFO: sonobuoy-systemd-logs-daemon-set-aae6d13d2b504a80-z8lvd from sonobuoy started at 2019-10-21 15:48:07 +0000 UTC (2 container statuses recorded)
Oct 21 17:18:14.356: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 21 17:18:14.356: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 21 17:18:14.356: INFO: calico-node-xczq8 from kube-system started at 2019-10-21 14:16:32 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.356: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 17:18:14.356: INFO: ibm-kube-fluentd-5gkfc from kube-system started at 2019-10-21 14:16:32 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.356: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 17:18:14.356: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-10-21 14:18:34 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.356: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Oct 21 17:18:14.356: INFO: ibm-cloud-provider-ip-169-50-36-162-5fffc56797-4s4bl from ibm-system started at 2019-10-21 14:27:14 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.356: INFO: 	Container ibm-cloud-provider-ip-169-50-36-162 ready: true, restart count 0
Oct 21 17:18:14.356: INFO: 
Logging pods the kubelet thinks is on node 10.134.235.67 before test
Oct 21 17:18:14.391: INFO: ibm-master-proxy-static-10.134.235.67 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 17:18:14.391: INFO: ibm-keepalived-watcher-p74j4 from kube-system started at 2019-10-21 14:17:00 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.391: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 17:18:14.391: INFO: ibm-kube-fluentd-5ssfj from kube-system started at 2019-10-21 14:17:00 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.391: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 17:18:14.392: INFO: public-crbmmrhnff04rpad188da0-alb1-5bd9899fdd-sq8jg from kube-system started at 2019-10-21 14:28:20 +0000 UTC (4 container statuses recorded)
Oct 21 17:18:14.392: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 17:18:14.392: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 17:18:14.392: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 17:18:14.392: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 21 17:18:14.392: INFO: sonobuoy-systemd-logs-daemon-set-aae6d13d2b504a80-8xb54 from sonobuoy started at 2019-10-21 15:48:07 +0000 UTC (2 container statuses recorded)
Oct 21 17:18:14.392: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 21 17:18:14.392: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 21 17:18:14.392: INFO: ibm-cloud-provider-ip-169-50-36-162-5fffc56797-6gpb8 from ibm-system started at 2019-10-21 14:27:14 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.392: INFO: 	Container ibm-cloud-provider-ip-169-50-36-162 ready: true, restart count 0
Oct 21 17:18:14.392: INFO: calico-node-hvq6v from kube-system started at 2019-10-21 14:17:00 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.392: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 17:18:14.392: INFO: 
Logging pods the kubelet thinks is on node 10.134.235.77 before test
Oct 21 17:18:14.438: INFO: kubernetes-dashboard-5c8c9b7546-56vkg from kube-system started at 2019-10-21 14:14:26 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.438: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct 21 17:18:14.438: INFO: ibm-kube-fluentd-zwqgb from kube-system started at 2019-10-21 14:14:36 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.438: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 17:18:14.438: INFO: calico-kube-controllers-65f9c6c467-9xskh from kube-system started at 2019-10-21 14:14:25 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.438: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct 21 17:18:14.438: INFO: sonobuoy-systemd-logs-daemon-set-aae6d13d2b504a80-mzxfn from sonobuoy started at 2019-10-21 15:48:07 +0000 UTC (2 container statuses recorded)
Oct 21 17:18:14.438: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 21 17:18:14.438: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 21 17:18:14.438: INFO: ibm-master-proxy-static-10.134.235.77 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 17:18:14.438: INFO: ibm-keepalived-watcher-vv9sg from kube-system started at 2019-10-21 14:14:07 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.438: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 17:18:14.438: INFO: public-crbmmrhnff04rpad188da0-alb1-5bd9899fdd-sk955 from kube-system started at 2019-10-21 14:28:20 +0000 UTC (4 container statuses recorded)
Oct 21 17:18:14.438: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 17:18:14.438: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 17:18:14.438: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 17:18:14.438: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 21 17:18:14.438: INFO: sonobuoy-e2e-job-84d501f52fd84cd8 from sonobuoy started at 2019-10-21 15:48:07 +0000 UTC (2 container statuses recorded)
Oct 21 17:18:14.438: INFO: 	Container e2e ready: true, restart count 0
Oct 21 17:18:14.438: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 17:18:14.438: INFO: calico-node-qbdl6 from kube-system started at 2019-10-21 14:14:07 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.438: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 17:18:14.438: INFO: ibm-file-plugin-9bf87c759-7h2dh from kube-system started at 2019-10-21 14:14:25 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.438: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct 21 17:18:14.438: INFO: ibm-storage-watcher-5f677d9c66-8mmsv from kube-system started at 2019-10-21 14:14:25 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.438: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct 21 17:18:14.438: INFO: coredns-9dd7747c7-kp66g from kube-system started at 2019-10-21 14:35:59 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.438: INFO: 	Container coredns ready: true, restart count 0
Oct 21 17:18:14.438: INFO: coredns-autoscaler-5d4db8dd68-4rk7m from kube-system started at 2019-10-21 14:14:26 +0000 UTC (1 container statuses recorded)
Oct 21 17:18:14.438: INFO: 	Container autoscaler ready: true, restart count 0
Oct 21 17:18:14.438: INFO: metrics-server-64cc5dbf7f-mqllr from kube-system started at 2019-10-21 14:14:41 +0000 UTC (2 container statuses recorded)
Oct 21 17:18:14.438: INFO: 	Container metrics-server ready: true, restart count 0
Oct 21 17:18:14.438: INFO: 	Container metrics-server-nanny ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-c52a4dcb-f426-11e9-ae8d-bacadc8895d2 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-c52a4dcb-f426-11e9-ae8d-bacadc8895d2 off the node 10.134.235.118
STEP: verifying the node doesn't have the label kubernetes.io/e2e-c52a4dcb-f426-11e9-ae8d-bacadc8895d2
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:18:18.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4767" for this suite.
Oct 21 17:18:32.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:18:33.070: INFO: namespace sched-pred-4767 deletion completed in 14.395883704s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:19.021 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:18:33.071: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6466
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 17:18:33.321: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cf283741-f426-11e9-ae8d-bacadc8895d2" in namespace "downward-api-6466" to be "success or failure"
Oct 21 17:18:33.335: INFO: Pod "downwardapi-volume-cf283741-f426-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.45308ms
Oct 21 17:18:35.345: INFO: Pod "downwardapi-volume-cf283741-f426-11e9-ae8d-bacadc8895d2": Phase="Running", Reason="", readiness=true. Elapsed: 2.023630464s
Oct 21 17:18:37.356: INFO: Pod "downwardapi-volume-cf283741-f426-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034780302s
STEP: Saw pod success
Oct 21 17:18:37.356: INFO: Pod "downwardapi-volume-cf283741-f426-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:18:37.366: INFO: Trying to get logs from node 10.134.235.67 pod downwardapi-volume-cf283741-f426-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 17:18:37.416: INFO: Waiting for pod downwardapi-volume-cf283741-f426-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:18:37.432: INFO: Pod downwardapi-volume-cf283741-f426-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:18:37.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6466" for this suite.
Oct 21 17:18:43.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:18:44.126: INFO: namespace downward-api-6466 deletion completed in 6.681878352s

• [SLOW TEST:11.055 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:18:44.126: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4319
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:18:48.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4319" for this suite.
Oct 21 17:19:32.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:19:32.832: INFO: namespace kubelet-test-4319 deletion completed in 44.418095758s

• [SLOW TEST:48.706 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:19:32.832: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4443
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-4443
Oct 21 17:19:37.089: INFO: Started pod liveness-http in namespace container-probe-4443
STEP: checking the pod's current state and verifying that restartCount is present
Oct 21 17:19:37.097: INFO: Initial restart count of pod liveness-http is 0
Oct 21 17:19:58.113: INFO: Restart count of pod container-probe-4443/liveness-http is now 1 (21.015738573s elapsed)
Oct 21 17:20:16.224: INFO: Restart count of pod container-probe-4443/liveness-http is now 2 (39.126557597s elapsed)
Oct 21 17:20:36.537: INFO: Restart count of pod container-probe-4443/liveness-http is now 3 (59.439892512s elapsed)
Oct 21 17:20:56.642: INFO: Restart count of pod container-probe-4443/liveness-http is now 4 (1m19.544469858s elapsed)
Oct 21 17:22:05.081: INFO: Restart count of pod container-probe-4443/liveness-http is now 5 (2m27.984205018s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:22:05.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4443" for this suite.
Oct 21 17:22:11.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:22:11.552: INFO: namespace container-probe-4443 deletion completed in 6.421126591s

• [SLOW TEST:158.720 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:22:11.552: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8577
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-51630c0d-f427-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume secrets
Oct 21 17:22:11.821: INFO: Waiting up to 5m0s for pod "pod-secrets-5164e27a-f427-11e9-ae8d-bacadc8895d2" in namespace "secrets-8577" to be "success or failure"
Oct 21 17:22:11.834: INFO: Pod "pod-secrets-5164e27a-f427-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.853738ms
Oct 21 17:22:13.844: INFO: Pod "pod-secrets-5164e27a-f427-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022999574s
Oct 21 17:22:15.854: INFO: Pod "pod-secrets-5164e27a-f427-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032958244s
STEP: Saw pod success
Oct 21 17:22:15.854: INFO: Pod "pod-secrets-5164e27a-f427-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:22:15.865: INFO: Trying to get logs from node 10.134.235.118 pod pod-secrets-5164e27a-f427-11e9-ae8d-bacadc8895d2 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 17:22:15.922: INFO: Waiting for pod pod-secrets-5164e27a-f427-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:22:15.930: INFO: Pod pod-secrets-5164e27a-f427-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:22:15.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8577" for this suite.
Oct 21 17:22:21.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:22:22.302: INFO: namespace secrets-8577 deletion completed in 6.357685167s

• [SLOW TEST:10.750 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:22:22.303: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3792
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Oct 21 17:22:22.571: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3792,SelfLink:/api/v1/namespaces/watch-3792/configmaps/e2e-watch-test-label-changed,UID:57c84baf-f427-11e9-a1ef-46591df82ad7,ResourceVersion:43549,Generation:0,CreationTimestamp:2019-10-21 17:22:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 21 17:22:22.572: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3792,SelfLink:/api/v1/namespaces/watch-3792/configmaps/e2e-watch-test-label-changed,UID:57c84baf-f427-11e9-a1ef-46591df82ad7,ResourceVersion:43550,Generation:0,CreationTimestamp:2019-10-21 17:22:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 21 17:22:22.572: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3792,SelfLink:/api/v1/namespaces/watch-3792/configmaps/e2e-watch-test-label-changed,UID:57c84baf-f427-11e9-a1ef-46591df82ad7,ResourceVersion:43551,Generation:0,CreationTimestamp:2019-10-21 17:22:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Oct 21 17:22:32.655: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3792,SelfLink:/api/v1/namespaces/watch-3792/configmaps/e2e-watch-test-label-changed,UID:57c84baf-f427-11e9-a1ef-46591df82ad7,ResourceVersion:43569,Generation:0,CreationTimestamp:2019-10-21 17:22:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 21 17:22:32.656: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3792,SelfLink:/api/v1/namespaces/watch-3792/configmaps/e2e-watch-test-label-changed,UID:57c84baf-f427-11e9-a1ef-46591df82ad7,ResourceVersion:43570,Generation:0,CreationTimestamp:2019-10-21 17:22:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Oct 21 17:22:32.656: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3792,SelfLink:/api/v1/namespaces/watch-3792/configmaps/e2e-watch-test-label-changed,UID:57c84baf-f427-11e9-a1ef-46591df82ad7,ResourceVersion:43571,Generation:0,CreationTimestamp:2019-10-21 17:22:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:22:32.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3792" for this suite.
Oct 21 17:22:38.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:22:39.043: INFO: namespace watch-3792 deletion completed in 6.373570212s

• [SLOW TEST:16.741 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:22:39.044: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7058
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7058.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7058.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7058.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7058.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7058.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7058.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7058.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7058.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7058.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7058.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7058.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 253.92.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.92.253_udp@PTR;check="$$(dig +tcp +noall +answer +search 253.92.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.92.253_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7058.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7058.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7058.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7058.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7058.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7058.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7058.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7058.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7058.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7058.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7058.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 253.92.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.92.253_udp@PTR;check="$$(dig +tcp +noall +answer +search 253.92.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.92.253_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 21 17:22:51.360: INFO: Unable to read wheezy_udp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:22:51.378: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:22:51.395: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:22:51.411: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:22:51.542: INFO: Unable to read jessie_udp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:22:51.557: INFO: Unable to read jessie_tcp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:22:51.573: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:22:51.590: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:22:51.696: INFO: Lookups using dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2 failed for: [wheezy_udp@dns-test-service.dns-7058.svc.cluster.local wheezy_tcp@dns-test-service.dns-7058.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local jessie_udp@dns-test-service.dns-7058.svc.cluster.local jessie_tcp@dns-test-service.dns-7058.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local]

Oct 21 17:22:56.715: INFO: Unable to read wheezy_udp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:22:56.729: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:22:56.744: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:22:56.759: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:22:56.868: INFO: Unable to read jessie_udp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:22:56.884: INFO: Unable to read jessie_tcp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:22:56.897: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:22:56.913: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:22:57.003: INFO: Lookups using dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2 failed for: [wheezy_udp@dns-test-service.dns-7058.svc.cluster.local wheezy_tcp@dns-test-service.dns-7058.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local jessie_udp@dns-test-service.dns-7058.svc.cluster.local jessie_tcp@dns-test-service.dns-7058.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local]

Oct 21 17:23:01.714: INFO: Unable to read wheezy_udp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:01.730: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:01.750: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:01.784: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:01.923: INFO: Unable to read jessie_udp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:01.942: INFO: Unable to read jessie_tcp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:01.960: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:01.979: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:02.090: INFO: Lookups using dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2 failed for: [wheezy_udp@dns-test-service.dns-7058.svc.cluster.local wheezy_tcp@dns-test-service.dns-7058.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local jessie_udp@dns-test-service.dns-7058.svc.cluster.local jessie_tcp@dns-test-service.dns-7058.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local]

Oct 21 17:23:07.511: INFO: Unable to read wheezy_udp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:07.547: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:07.565: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:07.582: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:07.708: INFO: Unable to read jessie_udp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:07.726: INFO: Unable to read jessie_tcp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:07.745: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:07.765: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:08.162: INFO: Lookups using dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2 failed for: [wheezy_udp@dns-test-service.dns-7058.svc.cluster.local wheezy_tcp@dns-test-service.dns-7058.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local jessie_udp@dns-test-service.dns-7058.svc.cluster.local jessie_tcp@dns-test-service.dns-7058.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local]

Oct 21 17:23:11.712: INFO: Unable to read wheezy_udp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:11.729: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:11.742: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:11.759: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:11.870: INFO: Unable to read jessie_udp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:11.887: INFO: Unable to read jessie_tcp@dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:11.907: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:11.921: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local from pod dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2: the server could not find the requested resource (get pods dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2)
Oct 21 17:23:12.022: INFO: Lookups using dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2 failed for: [wheezy_udp@dns-test-service.dns-7058.svc.cluster.local wheezy_tcp@dns-test-service.dns-7058.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local jessie_udp@dns-test-service.dns-7058.svc.cluster.local jessie_tcp@dns-test-service.dns-7058.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7058.svc.cluster.local]

Oct 21 17:23:17.023: INFO: DNS probes using dns-7058/dns-test-61c741ed-f427-11e9-ae8d-bacadc8895d2 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:23:17.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7058" for this suite.
Oct 21 17:23:23.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:23:24.325: INFO: namespace dns-7058 deletion completed in 7.167115504s

• [SLOW TEST:45.281 seconds]
[sig-network] DNS
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:23:24.325: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7029
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-7d231ade-f427-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume configMaps
Oct 21 17:23:25.220: INFO: Waiting up to 5m0s for pod "pod-configmaps-7d24ba01-f427-11e9-ae8d-bacadc8895d2" in namespace "configmap-7029" to be "success or failure"
Oct 21 17:23:25.233: INFO: Pod "pod-configmaps-7d24ba01-f427-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.633267ms
Oct 21 17:23:27.242: INFO: Pod "pod-configmaps-7d24ba01-f427-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022126769s
STEP: Saw pod success
Oct 21 17:23:27.242: INFO: Pod "pod-configmaps-7d24ba01-f427-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:23:27.255: INFO: Trying to get logs from node 10.134.235.118 pod pod-configmaps-7d24ba01-f427-11e9-ae8d-bacadc8895d2 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 17:23:27.313: INFO: Waiting for pod pod-configmaps-7d24ba01-f427-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:23:27.323: INFO: Pod pod-configmaps-7d24ba01-f427-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:23:27.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7029" for this suite.
Oct 21 17:23:33.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:23:33.741: INFO: namespace configmap-7029 deletion completed in 6.40399798s

• [SLOW TEST:9.416 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:23:33.743: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2695
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:23:38.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2695" for this suite.
Oct 21 17:23:44.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:23:44.517: INFO: namespace emptydir-wrapper-2695 deletion completed in 6.369369974s

• [SLOW TEST:10.774 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:23:44.517: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-2279
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Oct 21 17:23:47.810: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:23:48.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2279" for this suite.
Oct 21 17:24:06.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:24:07.294: INFO: namespace replicaset-2279 deletion completed in 18.425758036s

• [SLOW TEST:22.777 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:24:07.295: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6939
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1021 17:24:47.598392      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 21 17:24:47.598: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:24:47.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6939" for this suite.
Oct 21 17:24:55.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:24:56.024: INFO: namespace gc-6939 deletion completed in 8.412384221s

• [SLOW TEST:48.729 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:24:56.027: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5695
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 21 17:24:56.263: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b368e145-f427-11e9-ae8d-bacadc8895d2" in namespace "downward-api-5695" to be "success or failure"
Oct 21 17:24:56.273: INFO: Pod "downwardapi-volume-b368e145-f427-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.775979ms
Oct 21 17:24:58.283: INFO: Pod "downwardapi-volume-b368e145-f427-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020032201s
STEP: Saw pod success
Oct 21 17:24:58.283: INFO: Pod "downwardapi-volume-b368e145-f427-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:24:58.290: INFO: Trying to get logs from node 10.134.235.118 pod downwardapi-volume-b368e145-f427-11e9-ae8d-bacadc8895d2 container client-container: <nil>
STEP: delete the pod
Oct 21 17:24:58.352: INFO: Waiting for pod downwardapi-volume-b368e145-f427-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:24:58.368: INFO: Pod downwardapi-volume-b368e145-f427-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:24:58.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5695" for this suite.
Oct 21 17:25:04.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:25:04.798: INFO: namespace downward-api-5695 deletion completed in 6.416253816s

• [SLOW TEST:8.771 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:25:04.798: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4063
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 21 17:25:05.026: INFO: Waiting up to 5m0s for pod "pod-b8a271fb-f427-11e9-ae8d-bacadc8895d2" in namespace "emptydir-4063" to be "success or failure"
Oct 21 17:25:05.039: INFO: Pod "pod-b8a271fb-f427-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.9186ms
Oct 21 17:25:07.057: INFO: Pod "pod-b8a271fb-f427-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031246857s
STEP: Saw pod success
Oct 21 17:25:07.057: INFO: Pod "pod-b8a271fb-f427-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:25:07.068: INFO: Trying to get logs from node 10.134.235.67 pod pod-b8a271fb-f427-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 17:25:07.130: INFO: Waiting for pod pod-b8a271fb-f427-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:25:07.138: INFO: Pod pod-b8a271fb-f427-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:25:07.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4063" for this suite.
Oct 21 17:25:13.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:25:13.585: INFO: namespace emptydir-4063 deletion completed in 6.433067007s

• [SLOW TEST:8.787 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:25:13.586: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9633
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-sw2b
STEP: Creating a pod to test atomic-volume-subpath
Oct 21 17:25:13.852: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-sw2b" in namespace "subpath-9633" to be "success or failure"
Oct 21 17:25:13.861: INFO: Pod "pod-subpath-test-downwardapi-sw2b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.661048ms
Oct 21 17:25:15.871: INFO: Pod "pod-subpath-test-downwardapi-sw2b": Phase="Running", Reason="", readiness=true. Elapsed: 2.019238686s
Oct 21 17:25:17.881: INFO: Pod "pod-subpath-test-downwardapi-sw2b": Phase="Running", Reason="", readiness=true. Elapsed: 4.029388536s
Oct 21 17:25:19.891: INFO: Pod "pod-subpath-test-downwardapi-sw2b": Phase="Running", Reason="", readiness=true. Elapsed: 6.038951955s
Oct 21 17:25:21.900: INFO: Pod "pod-subpath-test-downwardapi-sw2b": Phase="Running", Reason="", readiness=true. Elapsed: 8.048180309s
Oct 21 17:25:23.909: INFO: Pod "pod-subpath-test-downwardapi-sw2b": Phase="Running", Reason="", readiness=true. Elapsed: 10.056904398s
Oct 21 17:25:25.918: INFO: Pod "pod-subpath-test-downwardapi-sw2b": Phase="Running", Reason="", readiness=true. Elapsed: 12.066418428s
Oct 21 17:25:27.928: INFO: Pod "pod-subpath-test-downwardapi-sw2b": Phase="Running", Reason="", readiness=true. Elapsed: 14.076085318s
Oct 21 17:25:29.942: INFO: Pod "pod-subpath-test-downwardapi-sw2b": Phase="Running", Reason="", readiness=true. Elapsed: 16.090670157s
Oct 21 17:25:31.951: INFO: Pod "pod-subpath-test-downwardapi-sw2b": Phase="Running", Reason="", readiness=true. Elapsed: 18.099349879s
Oct 21 17:25:33.966: INFO: Pod "pod-subpath-test-downwardapi-sw2b": Phase="Running", Reason="", readiness=true. Elapsed: 20.114797308s
Oct 21 17:25:35.978: INFO: Pod "pod-subpath-test-downwardapi-sw2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.126206071s
STEP: Saw pod success
Oct 21 17:25:35.978: INFO: Pod "pod-subpath-test-downwardapi-sw2b" satisfied condition "success or failure"
Oct 21 17:25:35.987: INFO: Trying to get logs from node 10.134.235.118 pod pod-subpath-test-downwardapi-sw2b container test-container-subpath-downwardapi-sw2b: <nil>
STEP: delete the pod
Oct 21 17:25:36.050: INFO: Waiting for pod pod-subpath-test-downwardapi-sw2b to disappear
Oct 21 17:25:36.065: INFO: Pod pod-subpath-test-downwardapi-sw2b no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-sw2b
Oct 21 17:25:36.065: INFO: Deleting pod "pod-subpath-test-downwardapi-sw2b" in namespace "subpath-9633"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:25:36.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9633" for this suite.
Oct 21 17:25:42.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:25:42.490: INFO: namespace subpath-9633 deletion completed in 6.396294524s

• [SLOW TEST:28.905 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:25:42.491: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5107
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 21 17:25:42.732: INFO: Waiting up to 5m0s for pod "pod-cf1ba982-f427-11e9-ae8d-bacadc8895d2" in namespace "emptydir-5107" to be "success or failure"
Oct 21 17:25:42.740: INFO: Pod "pod-cf1ba982-f427-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.493079ms
Oct 21 17:25:44.750: INFO: Pod "pod-cf1ba982-f427-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017999169s
STEP: Saw pod success
Oct 21 17:25:44.750: INFO: Pod "pod-cf1ba982-f427-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:25:44.760: INFO: Trying to get logs from node 10.134.235.67 pod pod-cf1ba982-f427-11e9-ae8d-bacadc8895d2 container test-container: <nil>
STEP: delete the pod
Oct 21 17:25:44.827: INFO: Waiting for pod pod-cf1ba982-f427-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:25:44.836: INFO: Pod pod-cf1ba982-f427-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:25:44.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5107" for this suite.
Oct 21 17:25:50.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:25:51.198: INFO: namespace emptydir-5107 deletion completed in 6.345914476s

• [SLOW TEST:8.707 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:25:51.199: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3613
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-d44a2e65-f427-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume secrets
Oct 21 17:25:51.439: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d44c3fca-f427-11e9-ae8d-bacadc8895d2" in namespace "projected-3613" to be "success or failure"
Oct 21 17:25:51.452: INFO: Pod "pod-projected-secrets-d44c3fca-f427-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.612426ms
Oct 21 17:25:53.462: INFO: Pod "pod-projected-secrets-d44c3fca-f427-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022638846s
STEP: Saw pod success
Oct 21 17:25:53.462: INFO: Pod "pod-projected-secrets-d44c3fca-f427-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:25:53.478: INFO: Trying to get logs from node 10.134.235.118 pod pod-projected-secrets-d44c3fca-f427-11e9-ae8d-bacadc8895d2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 21 17:25:53.531: INFO: Waiting for pod pod-projected-secrets-d44c3fca-f427-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:25:53.539: INFO: Pod pod-projected-secrets-d44c3fca-f427-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:25:53.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3613" for this suite.
Oct 21 17:25:59.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:25:59.899: INFO: namespace projected-3613 deletion completed in 6.346065091s

• [SLOW TEST:8.700 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:25:59.899: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6598
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-d97e452e-f427-11e9-ae8d-bacadc8895d2
STEP: Creating a pod to test consume configMaps
Oct 21 17:26:00.164: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d97fe344-f427-11e9-ae8d-bacadc8895d2" in namespace "projected-6598" to be "success or failure"
Oct 21 17:26:00.177: INFO: Pod "pod-projected-configmaps-d97fe344-f427-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.580274ms
Oct 21 17:26:02.187: INFO: Pod "pod-projected-configmaps-d97fe344-f427-11e9-ae8d-bacadc8895d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022940042s
Oct 21 17:26:04.198: INFO: Pod "pod-projected-configmaps-d97fe344-f427-11e9-ae8d-bacadc8895d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033398005s
STEP: Saw pod success
Oct 21 17:26:04.198: INFO: Pod "pod-projected-configmaps-d97fe344-f427-11e9-ae8d-bacadc8895d2" satisfied condition "success or failure"
Oct 21 17:26:04.209: INFO: Trying to get logs from node 10.134.235.67 pod pod-projected-configmaps-d97fe344-f427-11e9-ae8d-bacadc8895d2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 17:26:04.268: INFO: Waiting for pod pod-projected-configmaps-d97fe344-f427-11e9-ae8d-bacadc8895d2 to disappear
Oct 21 17:26:04.276: INFO: Pod pod-projected-configmaps-d97fe344-f427-11e9-ae8d-bacadc8895d2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:26:04.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6598" for this suite.
Oct 21 17:26:10.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:26:11.132: INFO: namespace projected-6598 deletion completed in 6.840469085s

• [SLOW TEST:11.234 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:26:11.134: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3902
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct 21 17:26:13.987: INFO: Successfully updated pod "annotationupdatee0317fbb-f427-11e9-ae8d-bacadc8895d2"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:26:16.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3902" for this suite.
Oct 21 17:26:40.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:26:40.486: INFO: namespace downward-api-3902 deletion completed in 24.43059039s

• [SLOW TEST:29.352 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:26:40.486: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5900
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct 21 17:26:43.438: INFO: Successfully updated pod "annotationupdatef1abe910-f427-11e9-ae8d-bacadc8895d2"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:26:47.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5900" for this suite.
Oct 21 17:27:11.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:27:11.901: INFO: namespace projected-5900 deletion completed in 24.355432651s

• [SLOW TEST:31.415 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:27:11.901: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9392
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:27:12.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9392" for this suite.
Oct 21 17:27:18.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:27:18.513: INFO: namespace services-9392 deletion completed in 6.368737172s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.613 seconds]
[sig-network] Services
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:27:18.514: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3475
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:27:18.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3475" for this suite.
Oct 21 17:27:24.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:27:25.160: INFO: namespace kubelet-test-3475 deletion completed in 6.373939148s

• [SLOW TEST:6.647 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:27:25.160: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5482
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:27:30.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5482" for this suite.
Oct 21 17:27:54.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:27:55.313: INFO: namespace replication-controller-5482 deletion completed in 24.382708466s

• [SLOW TEST:30.153 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 21 17:27:55.313: INFO: >>> kubeConfig: /tmp/kubeconfig-731484646
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5665
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-5665
Oct 21 17:27:57.568: INFO: Started pod liveness-exec in namespace container-probe-5665
STEP: checking the pod's current state and verifying that restartCount is present
Oct 21 17:27:57.580: INFO: Initial restart count of pod liveness-exec is 0
Oct 21 17:28:46.192: INFO: Restart count of pod container-probe-5665/liveness-exec is now 1 (48.612416204s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 21 17:28:46.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5665" for this suite.
Oct 21 17:28:52.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:28:52.635: INFO: namespace container-probe-5665 deletion completed in 6.393777515s

• [SLOW TEST:57.322 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSOct 21 17:28:52.636: INFO: Running AfterSuite actions on all nodes
Oct 21 17:28:52.636: INFO: Running AfterSuite actions on node 1
Oct 21 17:28:52.636: INFO: Skipping dumping logs from cluster

Ran 204 of 3586 Specs in 6023.574 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3382 Skipped PASS

Ginkgo ran 1 suite in 1h40m24.421499379s
Test Suite Passed
