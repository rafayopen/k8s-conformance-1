I1001 16:28:41.035063      17 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-589150881
I1001 16:28:41.035202      17 e2e.go:240] Starting e2e run "86cf0a07-e468-11e9-afc1-6aca03636ae4" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1569947320 - Will randomize all specs
Will run 204 of 3586 specs

Oct  1 16:28:41.177: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 16:28:41.179: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Oct  1 16:28:41.224: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct  1 16:28:41.290: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct  1 16:28:41.290: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Oct  1 16:28:41.291: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct  1 16:28:41.315: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Oct  1 16:28:41.315: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Oct  1 16:28:41.315: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
Oct  1 16:28:41.315: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Oct  1 16:28:41.315: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Oct  1 16:28:41.315: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Oct  1 16:28:41.315: INFO: e2e test version: v1.14.7
Oct  1 16:28:41.318: INFO: kube-apiserver version: v1.14.7+IKS
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:28:41.318: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename sched-pred
Oct  1 16:28:41.424: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Oct  1 16:28:41.457: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4285
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct  1 16:28:41.594: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  1 16:28:41.616: INFO: Waiting for terminating namespaces to be deleted...
Oct  1 16:28:41.624: INFO: 
Logging pods the kubelet thinks is on node 10.75.67.233 before test
Oct  1 16:28:41.654: INFO: calico-node-7zx9m from kube-system started at 2019-10-01 15:16:10 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.654: INFO: 	Container calico-node ready: true, restart count 0
Oct  1 16:28:41.654: INFO: sonobuoy from sonobuoy started at 2019-10-01 16:28:06 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.655: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  1 16:28:41.655: INFO: sonobuoy-systemd-logs-daemon-set-4416e0333c0e4618-j5sjs from sonobuoy started at 2019-10-01 16:28:13 +0000 UTC (2 container statuses recorded)
Oct  1 16:28:41.655: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  1 16:28:41.655: INFO: 	Container systemd-logs ready: true, restart count 0
Oct  1 16:28:41.655: INFO: ibm-kube-fluentd-b2lqr from kube-system started at 2019-10-01 15:16:10 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.655: INFO: 	Container fluentd ready: true, restart count 0
Oct  1 16:28:41.655: INFO: coredns-9dd7747c7-gkhfw from kube-system started at 2019-10-01 15:26:45 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.655: INFO: 	Container coredns ready: true, restart count 0
Oct  1 16:28:41.655: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-10-01 15:17:25 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.655: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Oct  1 16:28:41.655: INFO: vpn-7754bb6d4-wzqkn from kube-system started at 2019-10-01 15:26:22 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.655: INFO: 	Container vpn ready: true, restart count 0
Oct  1 16:28:41.656: INFO: ibm-master-proxy-static-10.75.67.233 from kube-system started at <nil> (0 container statuses recorded)
Oct  1 16:28:41.656: INFO: ibm-keepalived-watcher-xrgfc from kube-system started at 2019-10-01 15:16:10 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.656: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  1 16:28:41.656: INFO: 
Logging pods the kubelet thinks is on node 10.75.67.237 before test
Oct  1 16:28:41.727: INFO: coredns-9dd7747c7-psmnx from kube-system started at 2019-10-01 15:26:45 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.727: INFO: 	Container coredns ready: true, restart count 0
Oct  1 16:28:41.727: INFO: ibm-keepalived-watcher-ngkdv from kube-system started at 2019-10-01 15:02:53 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.727: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  1 16:28:41.727: INFO: metrics-server-6758dc85bb-gjn98 from kube-system started at 2019-10-01 15:03:37 +0000 UTC (2 container statuses recorded)
Oct  1 16:28:41.727: INFO: 	Container metrics-server ready: true, restart count 0
Oct  1 16:28:41.727: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct  1 16:28:41.727: INFO: ibm-cloud-provider-ip-161-156-139-203-7c5c6496c4-rdbdn from ibm-system started at 2019-10-01 15:05:51 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.727: INFO: 	Container ibm-cloud-provider-ip-161-156-139-203 ready: true, restart count 0
Oct  1 16:28:41.728: INFO: sonobuoy-e2e-job-12cb5697b8cf4781 from sonobuoy started at 2019-10-01 16:28:13 +0000 UTC (2 container statuses recorded)
Oct  1 16:28:41.728: INFO: 	Container e2e ready: false, restart count 0
Oct  1 16:28:41.728: INFO: 	Container sonobuoy-worker ready: false, restart count 0
Oct  1 16:28:41.728: INFO: sonobuoy-systemd-logs-daemon-set-4416e0333c0e4618-8x5jn from sonobuoy started at 2019-10-01 16:28:13 +0000 UTC (2 container statuses recorded)
Oct  1 16:28:41.728: INFO: 	Container sonobuoy-worker ready: false, restart count 0
Oct  1 16:28:41.728: INFO: 	Container systemd-logs ready: false, restart count 0
Oct  1 16:28:41.728: INFO: calico-node-d22c5 from kube-system started at 2019-10-01 15:02:53 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.728: INFO: 	Container calico-node ready: true, restart count 0
Oct  1 16:28:41.728: INFO: kubernetes-dashboard-5c8c9b7546-7f6fb from kube-system started at 2019-10-01 15:03:07 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.728: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct  1 16:28:41.728: INFO: coredns-autoscaler-5d4db8dd68-kkf9n from kube-system started at 2019-10-01 15:03:07 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.728: INFO: 	Container autoscaler ready: true, restart count 0
Oct  1 16:28:41.728: INFO: ibm-file-plugin-6b897f87c5-mqm42 from kube-system started at 2019-10-01 15:03:07 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.728: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct  1 16:28:41.728: INFO: ibm-kube-fluentd-dqt6z from kube-system started at 2019-10-01 15:03:20 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.728: INFO: 	Container fluentd ready: true, restart count 0
Oct  1 16:28:41.728: INFO: calico-kube-controllers-65f9c6c467-crfkj from kube-system started at 2019-10-01 15:03:07 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.728: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct  1 16:28:41.728: INFO: ibm-master-proxy-static-10.75.67.237 from kube-system started at <nil> (0 container statuses recorded)
Oct  1 16:28:41.728: INFO: ibm-storage-watcher-7457b8d444-gqm86 from kube-system started at 2019-10-01 15:03:07 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.728: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct  1 16:28:41.728: INFO: public-crbm9mdfvf0mdrp87rqprg-alb1-7bb44dd846-7zr89 from kube-system started at 2019-10-01 15:06:59 +0000 UTC (4 container statuses recorded)
Oct  1 16:28:41.728: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct  1 16:28:41.728: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct  1 16:28:41.728: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct  1 16:28:41.728: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct  1 16:28:41.728: INFO: 
Logging pods the kubelet thinks is on node 10.75.67.242 before test
Oct  1 16:28:41.782: INFO: ibm-cloud-provider-ip-161-156-139-203-7c5c6496c4-tzjcr from ibm-system started at 2019-10-01 15:05:51 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.782: INFO: 	Container ibm-cloud-provider-ip-161-156-139-203 ready: true, restart count 0
Oct  1 16:28:41.782: INFO: ibm-kube-fluentd-7q4bx from kube-system started at 2019-10-01 15:03:51 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.782: INFO: 	Container fluentd ready: true, restart count 0
Oct  1 16:28:41.782: INFO: public-crbm9mdfvf0mdrp87rqprg-alb1-7bb44dd846-cgfj7 from kube-system started at 2019-10-01 15:06:59 +0000 UTC (4 container statuses recorded)
Oct  1 16:28:41.782: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct  1 16:28:41.782: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct  1 16:28:41.782: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct  1 16:28:41.783: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct  1 16:28:41.783: INFO: ibm-master-proxy-static-10.75.67.242 from kube-system started at <nil> (0 container statuses recorded)
Oct  1 16:28:41.783: INFO: calico-node-hb58q from kube-system started at 2019-10-01 15:03:51 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.783: INFO: 	Container calico-node ready: true, restart count 0
Oct  1 16:28:41.783: INFO: ibm-keepalived-watcher-5g457 from kube-system started at 2019-10-01 15:03:51 +0000 UTC (1 container statuses recorded)
Oct  1 16:28:41.783: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  1 16:28:41.783: INFO: sonobuoy-systemd-logs-daemon-set-4416e0333c0e4618-9jgt9 from sonobuoy started at 2019-10-01 16:28:13 +0000 UTC (2 container statuses recorded)
Oct  1 16:28:41.783: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  1 16:28:41.783: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c992c571ea9b47], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:28:42.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4285" for this suite.
Oct  1 16:28:48.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:28:49.276: INFO: namespace sched-pred-4285 deletion completed in 6.414163441s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.958 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:28:49.277: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1969
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-8c6799f3-e468-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume secrets
Oct  1 16:28:49.520: INFO: Waiting up to 5m0s for pod "pod-secrets-8c6a2b75-e468-11e9-afc1-6aca03636ae4" in namespace "secrets-1969" to be "success or failure"
Oct  1 16:28:49.533: INFO: Pod "pod-secrets-8c6a2b75-e468-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.03025ms
Oct  1 16:28:51.560: INFO: Pod "pod-secrets-8c6a2b75-e468-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0400895s
Oct  1 16:28:53.572: INFO: Pod "pod-secrets-8c6a2b75-e468-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052431029s
STEP: Saw pod success
Oct  1 16:28:53.572: INFO: Pod "pod-secrets-8c6a2b75-e468-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:28:53.584: INFO: Trying to get logs from node 10.75.67.242 pod pod-secrets-8c6a2b75-e468-11e9-afc1-6aca03636ae4 container secret-volume-test: <nil>
STEP: delete the pod
Oct  1 16:28:53.641: INFO: Waiting for pod pod-secrets-8c6a2b75-e468-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:28:53.650: INFO: Pod pod-secrets-8c6a2b75-e468-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:28:53.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1969" for this suite.
Oct  1 16:28:59.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:29:00.014: INFO: namespace secrets-1969 deletion completed in 6.349687518s

• [SLOW TEST:10.738 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:29:00.015: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-697
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-697
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-697 to expose endpoints map[]
Oct  1 16:29:00.307: INFO: successfully validated that service multi-endpoint-test in namespace services-697 exposes endpoints map[] (13.423509ms elapsed)
STEP: Creating pod pod1 in namespace services-697
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-697 to expose endpoints map[pod1:[100]]
Oct  1 16:29:02.413: INFO: successfully validated that service multi-endpoint-test in namespace services-697 exposes endpoints map[pod1:[100]] (2.076984151s elapsed)
STEP: Creating pod pod2 in namespace services-697
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-697 to expose endpoints map[pod1:[100] pod2:[101]]
Oct  1 16:29:04.859: INFO: successfully validated that service multi-endpoint-test in namespace services-697 exposes endpoints map[pod1:[100] pod2:[101]] (2.433095825s elapsed)
STEP: Deleting pod pod1 in namespace services-697
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-697 to expose endpoints map[pod2:[101]]
Oct  1 16:29:04.910: INFO: successfully validated that service multi-endpoint-test in namespace services-697 exposes endpoints map[pod2:[101]] (31.803921ms elapsed)
STEP: Deleting pod pod2 in namespace services-697
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-697 to expose endpoints map[]
Oct  1 16:29:04.946: INFO: successfully validated that service multi-endpoint-test in namespace services-697 exposes endpoints map[] (14.687548ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:29:05.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-697" for this suite.
Oct  1 16:29:11.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:29:11.469: INFO: namespace services-697 deletion completed in 6.451903452s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:11.454 seconds]
[sig-network] Services
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:29:11.469: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5703
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5703.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5703.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  1 16:29:25.911: INFO: DNS probes using dns-5703/dns-test-99a638c5-e468-11e9-afc1-6aca03636ae4 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:29:25.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5703" for this suite.
Oct  1 16:29:34.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:29:34.313: INFO: namespace dns-5703 deletion completed in 8.352119378s

• [SLOW TEST:22.843 seconds]
[sig-network] DNS
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:29:34.313: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-301
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct  1 16:29:34.524: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  1 16:29:34.546: INFO: Waiting for terminating namespaces to be deleted...
Oct  1 16:29:34.555: INFO: 
Logging pods the kubelet thinks is on node 10.75.67.233 before test
Oct  1 16:29:34.583: INFO: calico-node-7zx9m from kube-system started at 2019-10-01 15:16:10 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.583: INFO: 	Container calico-node ready: true, restart count 0
Oct  1 16:29:34.583: INFO: sonobuoy from sonobuoy started at 2019-10-01 16:28:06 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.583: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  1 16:29:34.583: INFO: ibm-kube-fluentd-b2lqr from kube-system started at 2019-10-01 15:16:10 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.583: INFO: 	Container fluentd ready: true, restart count 0
Oct  1 16:29:34.583: INFO: coredns-9dd7747c7-gkhfw from kube-system started at 2019-10-01 15:26:45 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.583: INFO: 	Container coredns ready: true, restart count 0
Oct  1 16:29:34.583: INFO: sonobuoy-systemd-logs-daemon-set-4416e0333c0e4618-j5sjs from sonobuoy started at 2019-10-01 16:28:13 +0000 UTC (2 container statuses recorded)
Oct  1 16:29:34.583: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  1 16:29:34.583: INFO: 	Container systemd-logs ready: true, restart count 0
Oct  1 16:29:34.583: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-10-01 15:17:25 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.583: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Oct  1 16:29:34.583: INFO: ibm-master-proxy-static-10.75.67.233 from kube-system started at <nil> (0 container statuses recorded)
Oct  1 16:29:34.583: INFO: ibm-keepalived-watcher-xrgfc from kube-system started at 2019-10-01 15:16:10 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.583: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  1 16:29:34.583: INFO: vpn-7754bb6d4-wzqkn from kube-system started at 2019-10-01 15:26:22 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.583: INFO: 	Container vpn ready: true, restart count 0
Oct  1 16:29:34.583: INFO: 
Logging pods the kubelet thinks is on node 10.75.67.237 before test
Oct  1 16:29:34.621: INFO: ibm-cloud-provider-ip-161-156-139-203-7c5c6496c4-rdbdn from ibm-system started at 2019-10-01 15:05:51 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.621: INFO: 	Container ibm-cloud-provider-ip-161-156-139-203 ready: true, restart count 0
Oct  1 16:29:34.621: INFO: sonobuoy-e2e-job-12cb5697b8cf4781 from sonobuoy started at 2019-10-01 16:28:13 +0000 UTC (2 container statuses recorded)
Oct  1 16:29:34.621: INFO: 	Container e2e ready: true, restart count 0
Oct  1 16:29:34.621: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  1 16:29:34.621: INFO: sonobuoy-systemd-logs-daemon-set-4416e0333c0e4618-8x5jn from sonobuoy started at 2019-10-01 16:28:13 +0000 UTC (2 container statuses recorded)
Oct  1 16:29:34.621: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  1 16:29:34.621: INFO: 	Container systemd-logs ready: true, restart count 0
Oct  1 16:29:34.621: INFO: coredns-9dd7747c7-psmnx from kube-system started at 2019-10-01 15:26:45 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.621: INFO: 	Container coredns ready: true, restart count 0
Oct  1 16:29:34.621: INFO: ibm-keepalived-watcher-ngkdv from kube-system started at 2019-10-01 15:02:53 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.621: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  1 16:29:34.621: INFO: metrics-server-6758dc85bb-gjn98 from kube-system started at 2019-10-01 15:03:37 +0000 UTC (2 container statuses recorded)
Oct  1 16:29:34.621: INFO: 	Container metrics-server ready: true, restart count 0
Oct  1 16:29:34.621: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct  1 16:29:34.621: INFO: coredns-autoscaler-5d4db8dd68-kkf9n from kube-system started at 2019-10-01 15:03:07 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.621: INFO: 	Container autoscaler ready: true, restart count 0
Oct  1 16:29:34.621: INFO: ibm-file-plugin-6b897f87c5-mqm42 from kube-system started at 2019-10-01 15:03:07 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.621: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct  1 16:29:34.621: INFO: ibm-kube-fluentd-dqt6z from kube-system started at 2019-10-01 15:03:20 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.621: INFO: 	Container fluentd ready: true, restart count 0
Oct  1 16:29:34.621: INFO: calico-node-d22c5 from kube-system started at 2019-10-01 15:02:53 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.621: INFO: 	Container calico-node ready: true, restart count 0
Oct  1 16:29:34.621: INFO: kubernetes-dashboard-5c8c9b7546-7f6fb from kube-system started at 2019-10-01 15:03:07 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.621: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct  1 16:29:34.621: INFO: calico-kube-controllers-65f9c6c467-crfkj from kube-system started at 2019-10-01 15:03:07 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.621: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct  1 16:29:34.621: INFO: public-crbm9mdfvf0mdrp87rqprg-alb1-7bb44dd846-7zr89 from kube-system started at 2019-10-01 15:06:59 +0000 UTC (4 container statuses recorded)
Oct  1 16:29:34.621: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct  1 16:29:34.621: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct  1 16:29:34.621: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct  1 16:29:34.621: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct  1 16:29:34.621: INFO: ibm-master-proxy-static-10.75.67.237 from kube-system started at <nil> (0 container statuses recorded)
Oct  1 16:29:34.621: INFO: ibm-storage-watcher-7457b8d444-gqm86 from kube-system started at 2019-10-01 15:03:07 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.621: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct  1 16:29:34.621: INFO: 
Logging pods the kubelet thinks is on node 10.75.67.242 before test
Oct  1 16:29:34.656: INFO: ibm-cloud-provider-ip-161-156-139-203-7c5c6496c4-tzjcr from ibm-system started at 2019-10-01 15:05:51 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.657: INFO: 	Container ibm-cloud-provider-ip-161-156-139-203 ready: true, restart count 0
Oct  1 16:29:34.657: INFO: ibm-kube-fluentd-7q4bx from kube-system started at 2019-10-01 15:03:51 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.657: INFO: 	Container fluentd ready: true, restart count 0
Oct  1 16:29:34.657: INFO: public-crbm9mdfvf0mdrp87rqprg-alb1-7bb44dd846-cgfj7 from kube-system started at 2019-10-01 15:06:59 +0000 UTC (4 container statuses recorded)
Oct  1 16:29:34.657: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct  1 16:29:34.657: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct  1 16:29:34.657: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct  1 16:29:34.657: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct  1 16:29:34.657: INFO: ibm-master-proxy-static-10.75.67.242 from kube-system started at <nil> (0 container statuses recorded)
Oct  1 16:29:34.657: INFO: calico-node-hb58q from kube-system started at 2019-10-01 15:03:51 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.657: INFO: 	Container calico-node ready: true, restart count 0
Oct  1 16:29:34.657: INFO: ibm-keepalived-watcher-5g457 from kube-system started at 2019-10-01 15:03:51 +0000 UTC (1 container statuses recorded)
Oct  1 16:29:34.657: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  1 16:29:34.657: INFO: sonobuoy-systemd-logs-daemon-set-4416e0333c0e4618-9jgt9 from sonobuoy started at 2019-10-01 16:28:13 +0000 UTC (2 container statuses recorded)
Oct  1 16:29:34.657: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  1 16:29:34.657: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node 10.75.67.233
STEP: verifying the node has the label node 10.75.67.237
STEP: verifying the node has the label node 10.75.67.242
Oct  1 16:29:34.838: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.75.67.233
Oct  1 16:29:34.838: INFO: Pod ibm-cloud-provider-ip-161-156-139-203-7c5c6496c4-rdbdn requesting resource cpu=5m on Node 10.75.67.237
Oct  1 16:29:34.838: INFO: Pod ibm-cloud-provider-ip-161-156-139-203-7c5c6496c4-tzjcr requesting resource cpu=5m on Node 10.75.67.242
Oct  1 16:29:34.838: INFO: Pod calico-kube-controllers-65f9c6c467-crfkj requesting resource cpu=10m on Node 10.75.67.237
Oct  1 16:29:34.838: INFO: Pod calico-node-7zx9m requesting resource cpu=250m on Node 10.75.67.233
Oct  1 16:29:34.838: INFO: Pod calico-node-d22c5 requesting resource cpu=250m on Node 10.75.67.237
Oct  1 16:29:34.838: INFO: Pod calico-node-hb58q requesting resource cpu=250m on Node 10.75.67.242
Oct  1 16:29:34.838: INFO: Pod coredns-9dd7747c7-gkhfw requesting resource cpu=100m on Node 10.75.67.233
Oct  1 16:29:34.838: INFO: Pod coredns-9dd7747c7-psmnx requesting resource cpu=100m on Node 10.75.67.237
Oct  1 16:29:34.838: INFO: Pod coredns-autoscaler-5d4db8dd68-kkf9n requesting resource cpu=20m on Node 10.75.67.237
Oct  1 16:29:34.838: INFO: Pod ibm-file-plugin-6b897f87c5-mqm42 requesting resource cpu=50m on Node 10.75.67.237
Oct  1 16:29:34.838: INFO: Pod ibm-keepalived-watcher-5g457 requesting resource cpu=5m on Node 10.75.67.242
Oct  1 16:29:34.838: INFO: Pod ibm-keepalived-watcher-ngkdv requesting resource cpu=5m on Node 10.75.67.237
Oct  1 16:29:34.838: INFO: Pod ibm-keepalived-watcher-xrgfc requesting resource cpu=5m on Node 10.75.67.233
Oct  1 16:29:34.838: INFO: Pod ibm-kube-fluentd-7q4bx requesting resource cpu=25m on Node 10.75.67.242
Oct  1 16:29:34.838: INFO: Pod ibm-kube-fluentd-b2lqr requesting resource cpu=25m on Node 10.75.67.233
Oct  1 16:29:34.838: INFO: Pod ibm-kube-fluentd-dqt6z requesting resource cpu=25m on Node 10.75.67.237
Oct  1 16:29:34.838: INFO: Pod ibm-master-proxy-static-10.75.67.233 requesting resource cpu=25m on Node 10.75.67.233
Oct  1 16:29:34.838: INFO: Pod ibm-master-proxy-static-10.75.67.237 requesting resource cpu=25m on Node 10.75.67.237
Oct  1 16:29:34.838: INFO: Pod ibm-master-proxy-static-10.75.67.242 requesting resource cpu=25m on Node 10.75.67.242
Oct  1 16:29:34.839: INFO: Pod ibm-storage-watcher-7457b8d444-gqm86 requesting resource cpu=50m on Node 10.75.67.237
Oct  1 16:29:34.839: INFO: Pod kubernetes-dashboard-5c8c9b7546-7f6fb requesting resource cpu=50m on Node 10.75.67.237
Oct  1 16:29:34.839: INFO: Pod metrics-server-6758dc85bb-gjn98 requesting resource cpu=53m on Node 10.75.67.237
Oct  1 16:29:34.839: INFO: Pod public-crbm9mdfvf0mdrp87rqprg-alb1-7bb44dd846-7zr89 requesting resource cpu=0m on Node 10.75.67.237
Oct  1 16:29:34.839: INFO: Pod public-crbm9mdfvf0mdrp87rqprg-alb1-7bb44dd846-cgfj7 requesting resource cpu=0m on Node 10.75.67.242
Oct  1 16:29:34.839: INFO: Pod vpn-7754bb6d4-wzqkn requesting resource cpu=5m on Node 10.75.67.233
Oct  1 16:29:34.839: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.75.67.233
Oct  1 16:29:34.839: INFO: Pod sonobuoy-e2e-job-12cb5697b8cf4781 requesting resource cpu=0m on Node 10.75.67.237
Oct  1 16:29:34.839: INFO: Pod sonobuoy-systemd-logs-daemon-set-4416e0333c0e4618-8x5jn requesting resource cpu=0m on Node 10.75.67.237
Oct  1 16:29:34.839: INFO: Pod sonobuoy-systemd-logs-daemon-set-4416e0333c0e4618-9jgt9 requesting resource cpu=0m on Node 10.75.67.242
Oct  1 16:29:34.839: INFO: Pod sonobuoy-systemd-logs-daemon-set-4416e0333c0e4618-j5sjs requesting resource cpu=0m on Node 10.75.67.233
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a77038ff-e468-11e9-afc1-6aca03636ae4.15c992d1cb064059], Reason = [Scheduled], Message = [Successfully assigned sched-pred-301/filler-pod-a77038ff-e468-11e9-afc1-6aca03636ae4 to 10.75.67.233]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a77038ff-e468-11e9-afc1-6aca03636ae4.15c992d2067f4cf0], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a77038ff-e468-11e9-afc1-6aca03636ae4.15c992d20aac9791], Reason = [Created], Message = [Created container filler-pod-a77038ff-e468-11e9-afc1-6aca03636ae4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a77038ff-e468-11e9-afc1-6aca03636ae4.15c992d21529771c], Reason = [Started], Message = [Started container filler-pod-a77038ff-e468-11e9-afc1-6aca03636ae4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a773ae0e-e468-11e9-afc1-6aca03636ae4.15c992d1cbb9eac7], Reason = [Scheduled], Message = [Successfully assigned sched-pred-301/filler-pod-a773ae0e-e468-11e9-afc1-6aca03636ae4 to 10.75.67.237]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a773ae0e-e468-11e9-afc1-6aca03636ae4.15c992d206a67b8d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a773ae0e-e468-11e9-afc1-6aca03636ae4.15c992d20acb12ad], Reason = [Created], Message = [Created container filler-pod-a773ae0e-e468-11e9-afc1-6aca03636ae4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a773ae0e-e468-11e9-afc1-6aca03636ae4.15c992d2152203ae], Reason = [Started], Message = [Started container filler-pod-a773ae0e-e468-11e9-afc1-6aca03636ae4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a7759aa7-e468-11e9-afc1-6aca03636ae4.15c992d1cc9ce4d3], Reason = [Scheduled], Message = [Successfully assigned sched-pred-301/filler-pod-a7759aa7-e468-11e9-afc1-6aca03636ae4 to 10.75.67.242]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a7759aa7-e468-11e9-afc1-6aca03636ae4.15c992d208f977dd], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a7759aa7-e468-11e9-afc1-6aca03636ae4.15c992d20d4eca86], Reason = [Created], Message = [Created container filler-pod-a7759aa7-e468-11e9-afc1-6aca03636ae4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a7759aa7-e468-11e9-afc1-6aca03636ae4.15c992d2162ec6a7], Reason = [Started], Message = [Started container filler-pod-a7759aa7-e468-11e9-afc1-6aca03636ae4]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c992d247c2b2bd], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.75.67.233
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.75.67.237
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.75.67.242
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:29:38.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-301" for this suite.
Oct  1 16:29:46.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:29:46.405: INFO: namespace sched-pred-301 deletion completed in 8.316055637s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:12.092 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:29:46.406: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9403
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 16:29:46.697: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Oct  1 16:29:46.735: INFO: Number of nodes with available pods: 0
Oct  1 16:29:46.735: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 16:29:47.766: INFO: Number of nodes with available pods: 0
Oct  1 16:29:47.766: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 16:29:48.764: INFO: Number of nodes with available pods: 0
Oct  1 16:29:48.764: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 16:29:49.759: INFO: Number of nodes with available pods: 0
Oct  1 16:29:49.760: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 16:29:50.765: INFO: Number of nodes with available pods: 0
Oct  1 16:29:50.765: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 16:29:51.762: INFO: Number of nodes with available pods: 2
Oct  1 16:29:51.762: INFO: Node 10.75.67.237 is running more than one daemon pod
Oct  1 16:29:52.778: INFO: Number of nodes with available pods: 3
Oct  1 16:29:52.778: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Oct  1 16:29:52.864: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:52.864: INFO: Wrong image for pod: daemon-set-b6qlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:52.864: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:53.898: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:53.898: INFO: Wrong image for pod: daemon-set-b6qlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:53.898: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:54.902: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:54.902: INFO: Wrong image for pod: daemon-set-b6qlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:54.902: INFO: Pod daemon-set-b6qlq is not available
Oct  1 16:29:54.902: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:55.898: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:55.898: INFO: Wrong image for pod: daemon-set-b6qlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:55.898: INFO: Pod daemon-set-b6qlq is not available
Oct  1 16:29:55.898: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:56.895: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:56.895: INFO: Wrong image for pod: daemon-set-b6qlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:56.895: INFO: Pod daemon-set-b6qlq is not available
Oct  1 16:29:56.895: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:57.901: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:57.901: INFO: Wrong image for pod: daemon-set-b6qlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:57.901: INFO: Pod daemon-set-b6qlq is not available
Oct  1 16:29:57.901: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:58.896: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:58.896: INFO: Wrong image for pod: daemon-set-b6qlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:58.896: INFO: Pod daemon-set-b6qlq is not available
Oct  1 16:29:58.896: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:59.897: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:59.897: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:29:59.897: INFO: Pod daemon-set-zzx9r is not available
Oct  1 16:30:00.898: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:00.898: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:00.898: INFO: Pod daemon-set-zzx9r is not available
Oct  1 16:30:01.905: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:01.905: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:01.905: INFO: Pod daemon-set-zzx9r is not available
Oct  1 16:30:02.901: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:02.901: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:02.901: INFO: Pod daemon-set-zzx9r is not available
Oct  1 16:30:03.899: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:03.899: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:04.897: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:04.897: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:04.897: INFO: Pod daemon-set-btfzs is not available
Oct  1 16:30:05.899: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:05.899: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:05.899: INFO: Pod daemon-set-btfzs is not available
Oct  1 16:30:06.912: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:06.912: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:06.912: INFO: Pod daemon-set-btfzs is not available
Oct  1 16:30:07.900: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:07.900: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:07.900: INFO: Pod daemon-set-btfzs is not available
Oct  1 16:30:08.908: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:08.908: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:08.908: INFO: Pod daemon-set-btfzs is not available
Oct  1 16:30:09.900: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:09.900: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:09.900: INFO: Pod daemon-set-btfzs is not available
Oct  1 16:30:10.903: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:10.903: INFO: Wrong image for pod: daemon-set-btfzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:10.903: INFO: Pod daemon-set-btfzs is not available
Oct  1 16:30:11.903: INFO: Pod daemon-set-5clpf is not available
Oct  1 16:30:11.903: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:12.899: INFO: Pod daemon-set-5clpf is not available
Oct  1 16:30:12.899: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:13.904: INFO: Pod daemon-set-5clpf is not available
Oct  1 16:30:13.904: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:14.899: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:15.898: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:16.901: INFO: Wrong image for pod: daemon-set-5g7zx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct  1 16:30:16.901: INFO: Pod daemon-set-5g7zx is not available
Oct  1 16:30:17.896: INFO: Pod daemon-set-mcp8f is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Oct  1 16:30:17.936: INFO: Number of nodes with available pods: 2
Oct  1 16:30:17.936: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 16:30:18.964: INFO: Number of nodes with available pods: 2
Oct  1 16:30:18.964: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 16:30:19.959: INFO: Number of nodes with available pods: 2
Oct  1 16:30:19.959: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 16:30:20.958: INFO: Number of nodes with available pods: 3
Oct  1 16:30:20.958: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9403, will wait for the garbage collector to delete the pods
Oct  1 16:30:21.101: INFO: Deleting DaemonSet.extensions daemon-set took: 43.202977ms
Oct  1 16:30:21.201: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.225027ms
Oct  1 16:30:29.815: INFO: Number of nodes with available pods: 0
Oct  1 16:30:29.815: INFO: Number of running nodes: 0, number of available pods: 0
Oct  1 16:30:29.823: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9403/daemonsets","resourceVersion":"19450"},"items":null}

Oct  1 16:30:29.839: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9403/pods","resourceVersion":"19450"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:30:29.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9403" for this suite.
Oct  1 16:30:37.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:30:38.324: INFO: namespace daemonsets-9403 deletion completed in 8.421454426s

• [SLOW TEST:51.919 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:30:38.326: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7460
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-cd6df32e-e468-11e9-afc1-6aca03636ae4
STEP: Creating secret with name s-test-opt-upd-cd6df382-e468-11e9-afc1-6aca03636ae4
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-cd6df32e-e468-11e9-afc1-6aca03636ae4
STEP: Updating secret s-test-opt-upd-cd6df382-e468-11e9-afc1-6aca03636ae4
STEP: Creating secret with name s-test-opt-create-cd6df3a3-e468-11e9-afc1-6aca03636ae4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:30:42.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7460" for this suite.
Oct  1 16:31:06.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:31:07.714: INFO: namespace projected-7460 deletion completed in 24.778253888s

• [SLOW TEST:29.388 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:31:07.714: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5030
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 16:31:07.960: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct  1 16:31:07.984: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct  1 16:31:12.995: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct  1 16:31:12.995: INFO: Creating deployment "test-rolling-update-deployment"
Oct  1 16:31:13.014: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct  1 16:31:13.035: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Oct  1 16:31:15.056: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct  1 16:31:15.065: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct  1 16:31:15.095: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-5030,SelfLink:/apis/apps/v1/namespaces/deployment-5030/deployments/test-rolling-update-deployment,UID:e1f316e4-e468-11e9-bf88-8e83bb394576,ResourceVersion:19692,Generation:1,CreationTimestamp:2019-10-01 16:31:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-01 16:31:13 +0000 UTC 2019-10-01 16:31:13 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-01 16:31:14 +0000 UTC 2019-10-01 16:31:13 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-57b6b5bb54" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct  1 16:31:15.105: INFO: New ReplicaSet "test-rolling-update-deployment-57b6b5bb54" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54,GenerateName:,Namespace:deployment-5030,SelfLink:/apis/apps/v1/namespaces/deployment-5030/replicasets/test-rolling-update-deployment-57b6b5bb54,UID:e1f7c99e-e468-11e9-865f-ced8df5791d3,ResourceVersion:19681,Generation:1,CreationTimestamp:2019-10-01 16:31:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment e1f316e4-e468-11e9-bf88-8e83bb394576 0xc002ea77b7 0xc002ea77b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct  1 16:31:15.105: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct  1 16:31:15.105: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-5030,SelfLink:/apis/apps/v1/namespaces/deployment-5030/replicasets/test-rolling-update-controller,UID:def24b15-e468-11e9-bf88-8e83bb394576,ResourceVersion:19690,Generation:2,CreationTimestamp:2019-10-01 16:31:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment e1f316e4-e468-11e9-bf88-8e83bb394576 0xc002ea76e7 0xc002ea76e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct  1 16:31:15.115: INFO: Pod "test-rolling-update-deployment-57b6b5bb54-vm9nz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54-vm9nz,GenerateName:test-rolling-update-deployment-57b6b5bb54-,Namespace:deployment-5030,SelfLink:/api/v1/namespaces/deployment-5030/pods/test-rolling-update-deployment-57b6b5bb54-vm9nz,UID:e1f94312-e468-11e9-865f-ced8df5791d3,ResourceVersion:19680,Generation:0,CreationTimestamp:2019-10-01 16:31:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-57b6b5bb54 e1f7c99e-e468-11e9-865f-ced8df5791d3 0xc002e1e087 0xc002e1e088}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2p2hd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2p2hd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-2p2hd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e1e100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e1e120}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:31:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:31:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:31:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:31:13 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.242,PodIP:172.30.248.57,StartTime:2019-10-01 16:31:13 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-01 16:31:14 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://163a0f9a6c2c9f2498796bbfb38b0ca1a4625a3577f06a47690db409a69286b1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:31:15.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5030" for this suite.
Oct  1 16:31:23.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:31:23.505: INFO: namespace deployment-5030 deletion completed in 8.37472796s

• [SLOW TEST:15.791 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:31:23.505: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-79
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct  1 16:31:23.763: INFO: Waiting up to 5m0s for pod "pod-e859e365-e468-11e9-afc1-6aca03636ae4" in namespace "emptydir-79" to be "success or failure"
Oct  1 16:31:23.792: INFO: Pod "pod-e859e365-e468-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 28.850443ms
Oct  1 16:31:25.809: INFO: Pod "pod-e859e365-e468-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045923853s
Oct  1 16:31:27.818: INFO: Pod "pod-e859e365-e468-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055343019s
STEP: Saw pod success
Oct  1 16:31:27.818: INFO: Pod "pod-e859e365-e468-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:31:27.830: INFO: Trying to get logs from node 10.75.67.233 pod pod-e859e365-e468-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 16:31:27.884: INFO: Waiting for pod pod-e859e365-e468-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:31:27.894: INFO: Pod pod-e859e365-e468-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:31:27.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-79" for this suite.
Oct  1 16:31:33.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:31:34.307: INFO: namespace emptydir-79 deletion completed in 6.397142731s

• [SLOW TEST:10.802 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:31:34.308: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3328
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct  1 16:31:34.627: INFO: Number of nodes with available pods: 0
Oct  1 16:31:34.627: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 16:31:35.653: INFO: Number of nodes with available pods: 0
Oct  1 16:31:35.653: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 16:31:36.655: INFO: Number of nodes with available pods: 2
Oct  1 16:31:36.655: INFO: Node 10.75.67.237 is running more than one daemon pod
Oct  1 16:31:37.651: INFO: Number of nodes with available pods: 3
Oct  1 16:31:37.651: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Oct  1 16:31:37.713: INFO: Number of nodes with available pods: 2
Oct  1 16:31:37.713: INFO: Node 10.75.67.242 is running more than one daemon pod
Oct  1 16:31:38.735: INFO: Number of nodes with available pods: 2
Oct  1 16:31:38.735: INFO: Node 10.75.67.242 is running more than one daemon pod
Oct  1 16:31:39.736: INFO: Number of nodes with available pods: 3
Oct  1 16:31:39.736: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3328, will wait for the garbage collector to delete the pods
Oct  1 16:31:39.829: INFO: Deleting DaemonSet.extensions daemon-set took: 14.623885ms
Oct  1 16:31:39.929: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.332646ms
Oct  1 16:31:49.842: INFO: Number of nodes with available pods: 0
Oct  1 16:31:49.842: INFO: Number of running nodes: 0, number of available pods: 0
Oct  1 16:31:49.848: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3328/daemonsets","resourceVersion":"19921"},"items":null}

Oct  1 16:31:49.861: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3328/pods","resourceVersion":"19921"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:31:49.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3328" for this suite.
Oct  1 16:31:57.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:31:58.291: INFO: namespace daemonsets-3328 deletion completed in 8.366288349s

• [SLOW TEST:23.983 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:31:58.294: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-983
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-lntg
STEP: Creating a pod to test atomic-volume-subpath
Oct  1 16:31:58.554: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-lntg" in namespace "subpath-983" to be "success or failure"
Oct  1 16:31:58.568: INFO: Pod "pod-subpath-test-projected-lntg": Phase="Pending", Reason="", readiness=false. Elapsed: 14.129363ms
Oct  1 16:32:00.584: INFO: Pod "pod-subpath-test-projected-lntg": Phase="Running", Reason="", readiness=true. Elapsed: 2.030585082s
Oct  1 16:32:02.607: INFO: Pod "pod-subpath-test-projected-lntg": Phase="Running", Reason="", readiness=true. Elapsed: 4.052682329s
Oct  1 16:32:04.619: INFO: Pod "pod-subpath-test-projected-lntg": Phase="Running", Reason="", readiness=true. Elapsed: 6.065547495s
Oct  1 16:32:06.631: INFO: Pod "pod-subpath-test-projected-lntg": Phase="Running", Reason="", readiness=true. Elapsed: 8.077275957s
Oct  1 16:32:08.643: INFO: Pod "pod-subpath-test-projected-lntg": Phase="Running", Reason="", readiness=true. Elapsed: 10.089109957s
Oct  1 16:32:10.659: INFO: Pod "pod-subpath-test-projected-lntg": Phase="Running", Reason="", readiness=true. Elapsed: 12.104982835s
Oct  1 16:32:12.670: INFO: Pod "pod-subpath-test-projected-lntg": Phase="Running", Reason="", readiness=true. Elapsed: 14.11614181s
Oct  1 16:32:14.684: INFO: Pod "pod-subpath-test-projected-lntg": Phase="Running", Reason="", readiness=true. Elapsed: 16.129653538s
Oct  1 16:32:16.695: INFO: Pod "pod-subpath-test-projected-lntg": Phase="Running", Reason="", readiness=true. Elapsed: 18.140830996s
Oct  1 16:32:18.707: INFO: Pod "pod-subpath-test-projected-lntg": Phase="Running", Reason="", readiness=true. Elapsed: 20.153425452s
Oct  1 16:32:20.718: INFO: Pod "pod-subpath-test-projected-lntg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.163605791s
STEP: Saw pod success
Oct  1 16:32:20.718: INFO: Pod "pod-subpath-test-projected-lntg" satisfied condition "success or failure"
Oct  1 16:32:20.735: INFO: Trying to get logs from node 10.75.67.242 pod pod-subpath-test-projected-lntg container test-container-subpath-projected-lntg: <nil>
STEP: delete the pod
Oct  1 16:32:20.802: INFO: Waiting for pod pod-subpath-test-projected-lntg to disappear
Oct  1 16:32:20.816: INFO: Pod pod-subpath-test-projected-lntg no longer exists
STEP: Deleting pod pod-subpath-test-projected-lntg
Oct  1 16:32:20.816: INFO: Deleting pod "pod-subpath-test-projected-lntg" in namespace "subpath-983"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:32:20.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-983" for this suite.
Oct  1 16:32:26.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:32:27.210: INFO: namespace subpath-983 deletion completed in 6.366387656s

• [SLOW TEST:28.916 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:32:27.210: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5526
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 16:32:31.537: INFO: Waiting up to 5m0s for pod "client-envvars-10c089fe-e469-11e9-afc1-6aca03636ae4" in namespace "pods-5526" to be "success or failure"
Oct  1 16:32:31.548: INFO: Pod "client-envvars-10c089fe-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.83709ms
Oct  1 16:32:33.559: INFO: Pod "client-envvars-10c089fe-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021948727s
Oct  1 16:32:35.569: INFO: Pod "client-envvars-10c089fe-e469-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031562285s
STEP: Saw pod success
Oct  1 16:32:35.569: INFO: Pod "client-envvars-10c089fe-e469-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:32:35.578: INFO: Trying to get logs from node 10.75.67.242 pod client-envvars-10c089fe-e469-11e9-afc1-6aca03636ae4 container env3cont: <nil>
STEP: delete the pod
Oct  1 16:32:35.661: INFO: Waiting for pod client-envvars-10c089fe-e469-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:32:35.679: INFO: Pod client-envvars-10c089fe-e469-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:32:35.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5526" for this suite.
Oct  1 16:33:19.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:33:20.056: INFO: namespace pods-5526 deletion completed in 44.363560894s

• [SLOW TEST:52.846 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:33:20.057: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2018
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 16:33:20.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 version'
Oct  1 16:33:20.362: INFO: stderr: ""
Oct  1 16:33:20.362: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.7\", GitCommit:\"8fca2ec50a6133511b771a11559e24191b1aa2b4\", GitTreeState:\"clean\", BuildDate:\"2019-09-18T14:47:22Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.7+IKS\", GitCommit:\"44d102fa84ebb514e817942f5b1090cf54844445\", GitTreeState:\"clean\", BuildDate:\"2019-09-24T06:08:41Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:33:20.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2018" for this suite.
Oct  1 16:33:26.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:33:26.701: INFO: namespace kubectl-2018 deletion completed in 6.327608303s

• [SLOW TEST:6.645 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:33:26.702: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1369
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 16:33:26.966: INFO: Waiting up to 5m0s for pod "downwardapi-volume-31c93361-e469-11e9-afc1-6aca03636ae4" in namespace "downward-api-1369" to be "success or failure"
Oct  1 16:33:26.980: INFO: Pod "downwardapi-volume-31c93361-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.132202ms
Oct  1 16:33:28.995: INFO: Pod "downwardapi-volume-31c93361-e469-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028470502s
STEP: Saw pod success
Oct  1 16:33:28.996: INFO: Pod "downwardapi-volume-31c93361-e469-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:33:29.007: INFO: Trying to get logs from node 10.75.67.233 pod downwardapi-volume-31c93361-e469-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 16:33:29.057: INFO: Waiting for pod downwardapi-volume-31c93361-e469-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:33:29.066: INFO: Pod downwardapi-volume-31c93361-e469-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:33:29.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1369" for this suite.
Oct  1 16:33:35.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:33:35.456: INFO: namespace downward-api-1369 deletion completed in 6.377248508s

• [SLOW TEST:8.754 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:33:35.457: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4329
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-4329/configmap-test-36ff7697-e469-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume configMaps
Oct  1 16:33:35.723: INFO: Waiting up to 5m0s for pod "pod-configmaps-370137b9-e469-11e9-afc1-6aca03636ae4" in namespace "configmap-4329" to be "success or failure"
Oct  1 16:33:35.736: INFO: Pod "pod-configmaps-370137b9-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.332914ms
Oct  1 16:33:37.746: INFO: Pod "pod-configmaps-370137b9-e469-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02340942s
STEP: Saw pod success
Oct  1 16:33:37.746: INFO: Pod "pod-configmaps-370137b9-e469-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:33:37.760: INFO: Trying to get logs from node 10.75.67.242 pod pod-configmaps-370137b9-e469-11e9-afc1-6aca03636ae4 container env-test: <nil>
STEP: delete the pod
Oct  1 16:33:37.821: INFO: Waiting for pod pod-configmaps-370137b9-e469-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:33:37.831: INFO: Pod pod-configmaps-370137b9-e469-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:33:37.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4329" for this suite.
Oct  1 16:33:43.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:33:44.217: INFO: namespace configmap-4329 deletion completed in 6.356559667s

• [SLOW TEST:8.760 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:33:44.218: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3742
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-3c3547a3-e469-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume secrets
Oct  1 16:33:44.469: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3c36e21c-e469-11e9-afc1-6aca03636ae4" in namespace "projected-3742" to be "success or failure"
Oct  1 16:33:44.479: INFO: Pod "pod-projected-secrets-3c36e21c-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.561449ms
Oct  1 16:33:46.488: INFO: Pod "pod-projected-secrets-3c36e21c-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018637932s
Oct  1 16:33:48.500: INFO: Pod "pod-projected-secrets-3c36e21c-e469-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030400252s
STEP: Saw pod success
Oct  1 16:33:48.500: INFO: Pod "pod-projected-secrets-3c36e21c-e469-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:33:48.510: INFO: Trying to get logs from node 10.75.67.233 pod pod-projected-secrets-3c36e21c-e469-11e9-afc1-6aca03636ae4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  1 16:33:48.571: INFO: Waiting for pod pod-projected-secrets-3c36e21c-e469-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:33:48.579: INFO: Pod pod-projected-secrets-3c36e21c-e469-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:33:48.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3742" for this suite.
Oct  1 16:33:54.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:33:54.967: INFO: namespace projected-3742 deletion completed in 6.374408369s

• [SLOW TEST:10.749 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:33:54.967: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2143
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 16:33:55.192: INFO: Waiting up to 5m0s for pod "downwardapi-volume-429c05f0-e469-11e9-afc1-6aca03636ae4" in namespace "downward-api-2143" to be "success or failure"
Oct  1 16:33:55.209: INFO: Pod "downwardapi-volume-429c05f0-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 17.19934ms
Oct  1 16:33:57.251: INFO: Pod "downwardapi-volume-429c05f0-e469-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.059811367s
STEP: Saw pod success
Oct  1 16:33:57.251: INFO: Pod "downwardapi-volume-429c05f0-e469-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:33:57.261: INFO: Trying to get logs from node 10.75.67.242 pod downwardapi-volume-429c05f0-e469-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 16:33:57.342: INFO: Waiting for pod downwardapi-volume-429c05f0-e469-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:33:57.352: INFO: Pod downwardapi-volume-429c05f0-e469-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:33:57.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2143" for this suite.
Oct  1 16:34:03.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:34:03.773: INFO: namespace downward-api-2143 deletion completed in 6.39985842s

• [SLOW TEST:8.806 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:34:03.773: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-654
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 16:34:03.983: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:34:08.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-654" for this suite.
Oct  1 16:34:50.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:34:50.679: INFO: namespace pods-654 deletion completed in 42.428511343s

• [SLOW TEST:46.907 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:34:50.680: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4862
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-63d1bfdf-e469-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume secrets
Oct  1 16:34:50.922: INFO: Waiting up to 5m0s for pod "pod-secrets-63d3f4a2-e469-11e9-afc1-6aca03636ae4" in namespace "secrets-4862" to be "success or failure"
Oct  1 16:34:50.938: INFO: Pod "pod-secrets-63d3f4a2-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.445568ms
Oct  1 16:34:52.947: INFO: Pod "pod-secrets-63d3f4a2-e469-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024578463s
STEP: Saw pod success
Oct  1 16:34:52.947: INFO: Pod "pod-secrets-63d3f4a2-e469-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:34:52.956: INFO: Trying to get logs from node 10.75.67.242 pod pod-secrets-63d3f4a2-e469-11e9-afc1-6aca03636ae4 container secret-volume-test: <nil>
STEP: delete the pod
Oct  1 16:34:53.028: INFO: Waiting for pod pod-secrets-63d3f4a2-e469-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:34:53.040: INFO: Pod pod-secrets-63d3f4a2-e469-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:34:53.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4862" for this suite.
Oct  1 16:34:59.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:34:59.402: INFO: namespace secrets-4862 deletion completed in 6.347120198s

• [SLOW TEST:8.722 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:34:59.402: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8048
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:34:59.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8048" for this suite.
Oct  1 16:35:23.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:35:24.015: INFO: namespace kubelet-test-8048 deletion completed in 24.350494854s

• [SLOW TEST:24.614 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:35:24.016: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2976
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-77cb64d7-e469-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume configMaps
Oct  1 16:35:24.434: INFO: Waiting up to 5m0s for pod "pod-configmaps-77cd14b0-e469-11e9-afc1-6aca03636ae4" in namespace "configmap-2976" to be "success or failure"
Oct  1 16:35:24.446: INFO: Pod "pod-configmaps-77cd14b0-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.030248ms
Oct  1 16:35:26.461: INFO: Pod "pod-configmaps-77cd14b0-e469-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026697795s
STEP: Saw pod success
Oct  1 16:35:26.461: INFO: Pod "pod-configmaps-77cd14b0-e469-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:35:26.469: INFO: Trying to get logs from node 10.75.67.242 pod pod-configmaps-77cd14b0-e469-11e9-afc1-6aca03636ae4 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 16:35:26.533: INFO: Waiting for pod pod-configmaps-77cd14b0-e469-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:35:26.542: INFO: Pod pod-configmaps-77cd14b0-e469-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:35:26.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2976" for this suite.
Oct  1 16:35:32.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:35:32.901: INFO: namespace configmap-2976 deletion completed in 6.344884183s

• [SLOW TEST:8.885 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:35:32.901: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5366
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct  1 16:35:33.138: INFO: Waiting up to 5m0s for pod "pod-7cfccec5-e469-11e9-afc1-6aca03636ae4" in namespace "emptydir-5366" to be "success or failure"
Oct  1 16:35:33.154: INFO: Pod "pod-7cfccec5-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.25604ms
Oct  1 16:35:35.164: INFO: Pod "pod-7cfccec5-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02609544s
Oct  1 16:35:37.173: INFO: Pod "pod-7cfccec5-e469-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035483023s
STEP: Saw pod success
Oct  1 16:35:37.173: INFO: Pod "pod-7cfccec5-e469-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:35:37.183: INFO: Trying to get logs from node 10.75.67.233 pod pod-7cfccec5-e469-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 16:35:37.245: INFO: Waiting for pod pod-7cfccec5-e469-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:35:37.257: INFO: Pod pod-7cfccec5-e469-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:35:37.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5366" for this suite.
Oct  1 16:35:43.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:35:43.843: INFO: namespace emptydir-5366 deletion completed in 6.569844388s

• [SLOW TEST:10.941 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:35:43.843: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5766
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct  1 16:35:44.073: INFO: Waiting up to 5m0s for pod "pod-8381a4ff-e469-11e9-afc1-6aca03636ae4" in namespace "emptydir-5766" to be "success or failure"
Oct  1 16:35:44.082: INFO: Pod "pod-8381a4ff-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.535185ms
Oct  1 16:35:46.096: INFO: Pod "pod-8381a4ff-e469-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022708324s
STEP: Saw pod success
Oct  1 16:35:46.096: INFO: Pod "pod-8381a4ff-e469-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:35:46.104: INFO: Trying to get logs from node 10.75.67.242 pod pod-8381a4ff-e469-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 16:35:46.173: INFO: Waiting for pod pod-8381a4ff-e469-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:35:46.202: INFO: Pod pod-8381a4ff-e469-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:35:46.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5766" for this suite.
Oct  1 16:35:52.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:35:52.842: INFO: namespace emptydir-5766 deletion completed in 6.623699978s

• [SLOW TEST:8.999 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:35:52.842: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8219
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-88dea74d-e469-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume secrets
Oct  1 16:35:53.078: INFO: Waiting up to 5m0s for pod "pod-secrets-88e050c9-e469-11e9-afc1-6aca03636ae4" in namespace "secrets-8219" to be "success or failure"
Oct  1 16:35:53.091: INFO: Pod "pod-secrets-88e050c9-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.880359ms
Oct  1 16:35:55.101: INFO: Pod "pod-secrets-88e050c9-e469-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022511175s
STEP: Saw pod success
Oct  1 16:35:55.101: INFO: Pod "pod-secrets-88e050c9-e469-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:35:55.111: INFO: Trying to get logs from node 10.75.67.233 pod pod-secrets-88e050c9-e469-11e9-afc1-6aca03636ae4 container secret-env-test: <nil>
STEP: delete the pod
Oct  1 16:35:55.169: INFO: Waiting for pod pod-secrets-88e050c9-e469-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:35:55.179: INFO: Pod pod-secrets-88e050c9-e469-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:35:55.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8219" for this suite.
Oct  1 16:36:01.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:36:01.623: INFO: namespace secrets-8219 deletion completed in 6.425594816s

• [SLOW TEST:8.781 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:36:01.624: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4171
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-8e1dc745-e469-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume configMaps
Oct  1 16:36:01.897: INFO: Waiting up to 5m0s for pod "pod-configmaps-8e1ff730-e469-11e9-afc1-6aca03636ae4" in namespace "configmap-4171" to be "success or failure"
Oct  1 16:36:01.912: INFO: Pod "pod-configmaps-8e1ff730-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.494019ms
Oct  1 16:36:03.923: INFO: Pod "pod-configmaps-8e1ff730-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026255561s
Oct  1 16:36:05.934: INFO: Pod "pod-configmaps-8e1ff730-e469-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037766912s
STEP: Saw pod success
Oct  1 16:36:05.934: INFO: Pod "pod-configmaps-8e1ff730-e469-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:36:05.952: INFO: Trying to get logs from node 10.75.67.242 pod pod-configmaps-8e1ff730-e469-11e9-afc1-6aca03636ae4 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 16:36:06.019: INFO: Waiting for pod pod-configmaps-8e1ff730-e469-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:36:06.033: INFO: Pod pod-configmaps-8e1ff730-e469-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:36:06.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4171" for this suite.
Oct  1 16:36:12.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:36:12.509: INFO: namespace configmap-4171 deletion completed in 6.44617985s

• [SLOW TEST:10.885 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:36:12.509: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6855
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-949a60ea-e469-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume secrets
Oct  1 16:36:12.777: INFO: Waiting up to 5m0s for pod "pod-secrets-949cd08f-e469-11e9-afc1-6aca03636ae4" in namespace "secrets-6855" to be "success or failure"
Oct  1 16:36:12.787: INFO: Pod "pod-secrets-949cd08f-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.397317ms
Oct  1 16:36:14.798: INFO: Pod "pod-secrets-949cd08f-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020917305s
Oct  1 16:36:16.807: INFO: Pod "pod-secrets-949cd08f-e469-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030160898s
STEP: Saw pod success
Oct  1 16:36:16.808: INFO: Pod "pod-secrets-949cd08f-e469-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:36:16.817: INFO: Trying to get logs from node 10.75.67.233 pod pod-secrets-949cd08f-e469-11e9-afc1-6aca03636ae4 container secret-volume-test: <nil>
STEP: delete the pod
Oct  1 16:36:16.874: INFO: Waiting for pod pod-secrets-949cd08f-e469-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:36:16.882: INFO: Pod pod-secrets-949cd08f-e469-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:36:16.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6855" for this suite.
Oct  1 16:36:22.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:36:23.307: INFO: namespace secrets-6855 deletion completed in 6.406742368s

• [SLOW TEST:10.798 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:36:23.307: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9670
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct  1 16:36:23.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-9670'
Oct  1 16:36:23.770: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  1 16:36:23.770: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Oct  1 16:36:23.783: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Oct  1 16:36:23.786: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Oct  1 16:36:23.795: INFO: scanned /root for discovery docs: <nil>
Oct  1 16:36:23.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9670'
Oct  1 16:36:39.746: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct  1 16:36:39.746: INFO: stdout: "Created e2e-test-nginx-rc-3d03d0ab369580bd7b60b622ca542a10\nScaling up e2e-test-nginx-rc-3d03d0ab369580bd7b60b622ca542a10 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-3d03d0ab369580bd7b60b622ca542a10 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-3d03d0ab369580bd7b60b622ca542a10 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Oct  1 16:36:39.746: INFO: stdout: "Created e2e-test-nginx-rc-3d03d0ab369580bd7b60b622ca542a10\nScaling up e2e-test-nginx-rc-3d03d0ab369580bd7b60b622ca542a10 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-3d03d0ab369580bd7b60b622ca542a10 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-3d03d0ab369580bd7b60b622ca542a10 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Oct  1 16:36:39.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-9670'
Oct  1 16:36:39.859: INFO: stderr: ""
Oct  1 16:36:39.859: INFO: stdout: "e2e-test-nginx-rc-3d03d0ab369580bd7b60b622ca542a10-bv8sk "
Oct  1 16:36:39.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods e2e-test-nginx-rc-3d03d0ab369580bd7b60b622ca542a10-bv8sk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9670'
Oct  1 16:36:39.968: INFO: stderr: ""
Oct  1 16:36:39.968: INFO: stdout: "true"
Oct  1 16:36:39.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods e2e-test-nginx-rc-3d03d0ab369580bd7b60b622ca542a10-bv8sk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9670'
Oct  1 16:36:40.078: INFO: stderr: ""
Oct  1 16:36:40.078: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Oct  1 16:36:40.078: INFO: e2e-test-nginx-rc-3d03d0ab369580bd7b60b622ca542a10-bv8sk is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1486
Oct  1 16:36:40.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 delete rc e2e-test-nginx-rc --namespace=kubectl-9670'
Oct  1 16:36:40.208: INFO: stderr: ""
Oct  1 16:36:40.208: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:36:40.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9670" for this suite.
Oct  1 16:37:04.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:37:04.837: INFO: namespace kubectl-9670 deletion completed in 24.615311059s

• [SLOW TEST:41.530 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:37:04.837: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2881
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-b3ccd9e7-e469-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume secrets
Oct  1 16:37:05.112: INFO: Waiting up to 5m0s for pod "pod-secrets-b3cee49c-e469-11e9-afc1-6aca03636ae4" in namespace "secrets-2881" to be "success or failure"
Oct  1 16:37:05.127: INFO: Pod "pod-secrets-b3cee49c-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.455542ms
Oct  1 16:37:07.166: INFO: Pod "pod-secrets-b3cee49c-e469-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.054017002s
STEP: Saw pod success
Oct  1 16:37:07.166: INFO: Pod "pod-secrets-b3cee49c-e469-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:37:07.176: INFO: Trying to get logs from node 10.75.67.242 pod pod-secrets-b3cee49c-e469-11e9-afc1-6aca03636ae4 container secret-volume-test: <nil>
STEP: delete the pod
Oct  1 16:37:07.242: INFO: Waiting for pod pod-secrets-b3cee49c-e469-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:37:07.261: INFO: Pod pod-secrets-b3cee49c-e469-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:37:07.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2881" for this suite.
Oct  1 16:37:13.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:37:13.673: INFO: namespace secrets-2881 deletion completed in 6.395554867s

• [SLOW TEST:8.836 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:37:13.674: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5786
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-b912b24f-e469-11e9-afc1-6aca03636ae4
STEP: Creating secret with name secret-projected-all-test-volume-b912b227-e469-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test Check all projections for projected volume plugin
Oct  1 16:37:13.962: INFO: Waiting up to 5m0s for pod "projected-volume-b912b1e3-e469-11e9-afc1-6aca03636ae4" in namespace "projected-5786" to be "success or failure"
Oct  1 16:37:13.973: INFO: Pod "projected-volume-b912b1e3-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.02005ms
Oct  1 16:37:15.994: INFO: Pod "projected-volume-b912b1e3-e469-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031488525s
STEP: Saw pod success
Oct  1 16:37:15.994: INFO: Pod "projected-volume-b912b1e3-e469-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:37:16.004: INFO: Trying to get logs from node 10.75.67.233 pod projected-volume-b912b1e3-e469-11e9-afc1-6aca03636ae4 container projected-all-volume-test: <nil>
STEP: delete the pod
Oct  1 16:37:16.058: INFO: Waiting for pod projected-volume-b912b1e3-e469-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:37:16.069: INFO: Pod projected-volume-b912b1e3-e469-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:37:16.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5786" for this suite.
Oct  1 16:37:22.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:37:22.443: INFO: namespace projected-5786 deletion completed in 6.348558818s

• [SLOW TEST:8.769 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:37:22.444: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-517
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Oct  1 16:37:22.687: INFO: Waiting up to 5m0s for pod "client-containers-be48fc80-e469-11e9-afc1-6aca03636ae4" in namespace "containers-517" to be "success or failure"
Oct  1 16:37:22.703: INFO: Pod "client-containers-be48fc80-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.918332ms
Oct  1 16:37:24.712: INFO: Pod "client-containers-be48fc80-e469-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025546794s
Oct  1 16:37:26.726: INFO: Pod "client-containers-be48fc80-e469-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038823447s
STEP: Saw pod success
Oct  1 16:37:26.726: INFO: Pod "client-containers-be48fc80-e469-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:37:26.735: INFO: Trying to get logs from node 10.75.67.242 pod client-containers-be48fc80-e469-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 16:37:26.803: INFO: Waiting for pod client-containers-be48fc80-e469-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:37:26.814: INFO: Pod client-containers-be48fc80-e469-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:37:26.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-517" for this suite.
Oct  1 16:37:32.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:37:33.243: INFO: namespace containers-517 deletion completed in 6.416609305s

• [SLOW TEST:10.799 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:37:33.243: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3152
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-9fw7
STEP: Creating a pod to test atomic-volume-subpath
Oct  1 16:37:33.496: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-9fw7" in namespace "subpath-3152" to be "success or failure"
Oct  1 16:37:33.507: INFO: Pod "pod-subpath-test-downwardapi-9fw7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.91772ms
Oct  1 16:37:35.517: INFO: Pod "pod-subpath-test-downwardapi-9fw7": Phase="Running", Reason="", readiness=true. Elapsed: 2.021227752s
Oct  1 16:37:37.534: INFO: Pod "pod-subpath-test-downwardapi-9fw7": Phase="Running", Reason="", readiness=true. Elapsed: 4.038010914s
Oct  1 16:37:39.553: INFO: Pod "pod-subpath-test-downwardapi-9fw7": Phase="Running", Reason="", readiness=true. Elapsed: 6.057374471s
Oct  1 16:37:41.565: INFO: Pod "pod-subpath-test-downwardapi-9fw7": Phase="Running", Reason="", readiness=true. Elapsed: 8.068579508s
Oct  1 16:37:43.574: INFO: Pod "pod-subpath-test-downwardapi-9fw7": Phase="Running", Reason="", readiness=true. Elapsed: 10.078198309s
Oct  1 16:37:45.587: INFO: Pod "pod-subpath-test-downwardapi-9fw7": Phase="Running", Reason="", readiness=true. Elapsed: 12.09071186s
Oct  1 16:37:47.603: INFO: Pod "pod-subpath-test-downwardapi-9fw7": Phase="Running", Reason="", readiness=true. Elapsed: 14.106546029s
Oct  1 16:37:49.612: INFO: Pod "pod-subpath-test-downwardapi-9fw7": Phase="Running", Reason="", readiness=true. Elapsed: 16.115874955s
Oct  1 16:37:51.623: INFO: Pod "pod-subpath-test-downwardapi-9fw7": Phase="Running", Reason="", readiness=true. Elapsed: 18.12693432s
Oct  1 16:37:53.635: INFO: Pod "pod-subpath-test-downwardapi-9fw7": Phase="Running", Reason="", readiness=true. Elapsed: 20.139353458s
Oct  1 16:37:55.647: INFO: Pod "pod-subpath-test-downwardapi-9fw7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.151103004s
STEP: Saw pod success
Oct  1 16:37:55.647: INFO: Pod "pod-subpath-test-downwardapi-9fw7" satisfied condition "success or failure"
Oct  1 16:37:55.657: INFO: Trying to get logs from node 10.75.67.242 pod pod-subpath-test-downwardapi-9fw7 container test-container-subpath-downwardapi-9fw7: <nil>
STEP: delete the pod
Oct  1 16:37:55.724: INFO: Waiting for pod pod-subpath-test-downwardapi-9fw7 to disappear
Oct  1 16:37:55.742: INFO: Pod pod-subpath-test-downwardapi-9fw7 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-9fw7
Oct  1 16:37:55.742: INFO: Deleting pod "pod-subpath-test-downwardapi-9fw7" in namespace "subpath-3152"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:37:55.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3152" for this suite.
Oct  1 16:38:01.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:38:02.201: INFO: namespace subpath-3152 deletion completed in 6.420594822s

• [SLOW TEST:28.958 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:38:02.201: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4911
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:38:04.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4911" for this suite.
Oct  1 16:38:44.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:38:44.962: INFO: namespace kubelet-test-4911 deletion completed in 40.38307836s

• [SLOW TEST:42.761 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:38:44.962: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6509
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Oct  1 16:38:45.245: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6509,SelfLink:/api/v1/namespaces/watch-6509/configmaps/e2e-watch-test-label-changed,UID:ef79e241-e469-11e9-bf88-8e83bb394576,ResourceVersion:21538,Generation:0,CreationTimestamp:2019-10-01 16:38:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  1 16:38:45.245: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6509,SelfLink:/api/v1/namespaces/watch-6509/configmaps/e2e-watch-test-label-changed,UID:ef79e241-e469-11e9-bf88-8e83bb394576,ResourceVersion:21540,Generation:0,CreationTimestamp:2019-10-01 16:38:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct  1 16:38:45.245: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6509,SelfLink:/api/v1/namespaces/watch-6509/configmaps/e2e-watch-test-label-changed,UID:ef79e241-e469-11e9-bf88-8e83bb394576,ResourceVersion:21541,Generation:0,CreationTimestamp:2019-10-01 16:38:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Oct  1 16:38:55.339: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6509,SelfLink:/api/v1/namespaces/watch-6509/configmaps/e2e-watch-test-label-changed,UID:ef79e241-e469-11e9-bf88-8e83bb394576,ResourceVersion:21560,Generation:0,CreationTimestamp:2019-10-01 16:38:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  1 16:38:55.339: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6509,SelfLink:/api/v1/namespaces/watch-6509/configmaps/e2e-watch-test-label-changed,UID:ef79e241-e469-11e9-bf88-8e83bb394576,ResourceVersion:21561,Generation:0,CreationTimestamp:2019-10-01 16:38:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Oct  1 16:38:55.339: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6509,SelfLink:/api/v1/namespaces/watch-6509/configmaps/e2e-watch-test-label-changed,UID:ef79e241-e469-11e9-bf88-8e83bb394576,ResourceVersion:21562,Generation:0,CreationTimestamp:2019-10-01 16:38:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:38:55.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6509" for this suite.
Oct  1 16:39:01.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:39:01.775: INFO: namespace watch-6509 deletion completed in 6.422250608s

• [SLOW TEST:16.812 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:39:01.776: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7696
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-f9822e96-e469-11e9-afc1-6aca03636ae4
STEP: Creating configMap with name cm-test-opt-upd-f9822efb-e469-11e9-afc1-6aca03636ae4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-f9822e96-e469-11e9-afc1-6aca03636ae4
STEP: Updating configmap cm-test-opt-upd-f9822efb-e469-11e9-afc1-6aca03636ae4
STEP: Creating configMap with name cm-test-opt-create-f9822f26-e469-11e9-afc1-6aca03636ae4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:40:25.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7696" for this suite.
Oct  1 16:40:49.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:40:50.009: INFO: namespace configmap-7696 deletion completed in 24.431162084s

• [SLOW TEST:108.233 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:40:50.010: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4616
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-3a00e740-e46a-11e9-afc1-6aca03636ae4
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:40:50.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4616" for this suite.
Oct  1 16:40:56.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:40:56.750: INFO: namespace configmap-4616 deletion completed in 6.504027633s

• [SLOW TEST:6.740 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:40:56.752: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5370
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 16:40:57.011: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3e07a24b-e46a-11e9-afc1-6aca03636ae4" in namespace "projected-5370" to be "success or failure"
Oct  1 16:40:57.023: INFO: Pod "downwardapi-volume-3e07a24b-e46a-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.443691ms
Oct  1 16:40:59.032: INFO: Pod "downwardapi-volume-3e07a24b-e46a-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02109089s
STEP: Saw pod success
Oct  1 16:40:59.033: INFO: Pod "downwardapi-volume-3e07a24b-e46a-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:40:59.041: INFO: Trying to get logs from node 10.75.67.242 pod downwardapi-volume-3e07a24b-e46a-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 16:40:59.098: INFO: Waiting for pod downwardapi-volume-3e07a24b-e46a-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:40:59.111: INFO: Pod downwardapi-volume-3e07a24b-e46a-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:40:59.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5370" for this suite.
Oct  1 16:41:05.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:41:05.636: INFO: namespace projected-5370 deletion completed in 6.512793714s

• [SLOW TEST:8.884 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:41:05.636: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-931
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-931
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Oct  1 16:41:05.890: INFO: Found 0 stateful pods, waiting for 3
Oct  1 16:41:15.972: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 16:41:15.973: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 16:41:15.973: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 16:41:16.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-931 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  1 16:41:16.387: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  1 16:41:16.387: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  1 16:41:16.387: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct  1 16:41:26.469: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Oct  1 16:41:36.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-931 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  1 16:41:36.990: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct  1 16:41:36.990: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct  1 16:41:36.990: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct  1 16:41:57.060: INFO: Waiting for StatefulSet statefulset-931/ss2 to complete update
Oct  1 16:41:57.061: INFO: Waiting for Pod statefulset-931/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Oct  1 16:42:07.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-931 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  1 16:42:07.451: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  1 16:42:07.451: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  1 16:42:07.451: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  1 16:42:17.769: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Oct  1 16:42:28.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-931 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  1 16:42:28.446: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct  1 16:42:28.446: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct  1 16:42:28.446: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct  1 16:42:38.523: INFO: Waiting for StatefulSet statefulset-931/ss2 to complete update
Oct  1 16:42:38.523: INFO: Waiting for Pod statefulset-931/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct  1 16:42:38.523: INFO: Waiting for Pod statefulset-931/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct  1 16:42:38.523: INFO: Waiting for Pod statefulset-931/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct  1 16:42:48.542: INFO: Waiting for StatefulSet statefulset-931/ss2 to complete update
Oct  1 16:42:48.542: INFO: Waiting for Pod statefulset-931/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct  1 16:42:48.542: INFO: Waiting for Pod statefulset-931/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct  1 16:42:58.546: INFO: Waiting for StatefulSet statefulset-931/ss2 to complete update
Oct  1 16:42:58.546: INFO: Waiting for Pod statefulset-931/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct  1 16:43:08.545: INFO: Deleting all statefulset in ns statefulset-931
Oct  1 16:43:08.554: INFO: Scaling statefulset ss2 to 0
Oct  1 16:43:38.606: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 16:43:38.616: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:43:38.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-931" for this suite.
Oct  1 16:43:46.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:43:47.037: INFO: namespace statefulset-931 deletion completed in 8.370991412s

• [SLOW TEST:161.401 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:43:47.040: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-332
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 16:43:47.267: INFO: Creating deployment "nginx-deployment"
Oct  1 16:43:47.278: INFO: Waiting for observed generation 1
Oct  1 16:43:49.297: INFO: Waiting for all required pods to come up
Oct  1 16:43:49.308: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Oct  1 16:43:51.351: INFO: Waiting for deployment "nginx-deployment" to complete
Oct  1 16:43:51.369: INFO: Updating deployment "nginx-deployment" with a non-existent image
Oct  1 16:43:51.389: INFO: Updating deployment nginx-deployment
Oct  1 16:43:51.389: INFO: Waiting for observed generation 2
Oct  1 16:43:53.412: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct  1 16:43:53.421: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct  1 16:43:53.430: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct  1 16:43:53.456: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct  1 16:43:53.456: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct  1 16:43:53.465: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct  1 16:43:53.485: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Oct  1 16:43:53.485: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Oct  1 16:43:53.506: INFO: Updating deployment nginx-deployment
Oct  1 16:43:53.506: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Oct  1 16:43:53.522: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct  1 16:43:53.532: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct  1 16:43:53.552: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-332,SelfLink:/apis/apps/v1/namespaces/deployment-332/deployments/nginx-deployment,UID:a3874368-e46a-11e9-bf88-8e83bb394576,ResourceVersion:22834,Generation:3,CreationTimestamp:2019-10-01 16:43:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-10-01 16:43:51 +0000 UTC 2019-10-01 16:43:47 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-b79c9d74d" is progressing.} {Available False 2019-10-01 16:43:53 +0000 UTC 2019-10-01 16:43:53 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Oct  1 16:43:53.565: INFO: New ReplicaSet "nginx-deployment-b79c9d74d" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d,GenerateName:,Namespace:deployment-332,SelfLink:/apis/apps/v1/namespaces/deployment-332/replicasets/nginx-deployment-b79c9d74d,UID:a5fbc01a-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22830,Generation:3,CreationTimestamp:2019-10-01 16:43:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment a3874368-e46a-11e9-bf88-8e83bb394576 0xc0032c4cc7 0xc0032c4cc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct  1 16:43:53.565: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Oct  1 16:43:53.566: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5,GenerateName:,Namespace:deployment-332,SelfLink:/apis/apps/v1/namespaces/deployment-332/replicasets/nginx-deployment-85db8c99c5,UID:a388947e-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22829,Generation:3,CreationTimestamp:2019-10-01 16:43:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment a3874368-e46a-11e9-bf88-8e83bb394576 0xc0032c4bf7 0xc0032c4bf8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Oct  1 16:43:53.584: INFO: Pod "nginx-deployment-85db8c99c5-6m8bj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-6m8bj,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-6m8bj,UID:a73fe30b-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22852,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc0032079b7 0xc0032079b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003207a30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003207a50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.242,PodIP:,StartTime:2019-10-01 16:43:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.585: INFO: Pod "nginx-deployment-85db8c99c5-79klv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-79klv,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-79klv,UID:a38d662f-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22710,Generation:0,CreationTimestamp:2019-10-01 16:43:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc003207b17 0xc003207b18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.237,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003207b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003207bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:47 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.237,PodIP:172.30.58.125,StartTime:2019-10-01 16:43:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-01 16:43:48 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://7e43a0916ea85e4b32f54b78044ad543ed0262d3ba8fbd6ac16aeda2b375f8b8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.585: INFO: Pod "nginx-deployment-85db8c99c5-8d7bh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-8d7bh,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-8d7bh,UID:a746c586-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22868,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc003207c87 0xc003207c88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003207cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003207d10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.586: INFO: Pod "nginx-deployment-85db8c99c5-9l449" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-9l449,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-9l449,UID:a7469caf-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22867,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc003207d77 0xc003207d78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003207de0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003207e00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.589: INFO: Pod "nginx-deployment-85db8c99c5-b9nhc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-b9nhc,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-b9nhc,UID:a741da6e-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22862,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc003207e67 0xc003207e68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003207ee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003207f00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.242,PodIP:,StartTime:2019-10-01 16:43:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.589: INFO: Pod "nginx-deployment-85db8c99c5-fs92q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-fs92q,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-fs92q,UID:a743ec1c-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22855,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc003207fc7 0xc003207fc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003294050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003294070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.589: INFO: Pod "nginx-deployment-85db8c99c5-gbvbk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-gbvbk,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-gbvbk,UID:a390de3f-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22731,Generation:0,CreationTimestamp:2019-10-01 16:43:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc0032940f0 0xc0032940f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003294160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032941b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:47 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.233,PodIP:172.30.31.60,StartTime:2019-10-01 16:43:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-01 16:43:48 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://a30b4c0591465a6e8ba15f7b91eac8413dd075a8a653a7e998598b0a9586c010}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.589: INFO: Pod "nginx-deployment-85db8c99c5-gw6xf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-gw6xf,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-gw6xf,UID:a394319d-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22718,Generation:0,CreationTimestamp:2019-10-01 16:43:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc003294357 0xc003294358}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032945b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032945d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:47 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.233,PodIP:172.30.31.62,StartTime:2019-10-01 16:43:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-01 16:43:49 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://fabdd1425853587cb433eefe705c241db2fe4d1bc49737829eba53ac35583c64}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.589: INFO: Pod "nginx-deployment-85db8c99c5-kzqlt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-kzqlt,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-kzqlt,UID:a39123af-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22726,Generation:0,CreationTimestamp:2019-10-01 16:43:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc003294887 0xc003294888}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003294910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003294930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:47 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.242,PodIP:172.30.248.14,StartTime:2019-10-01 16:43:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-01 16:43:49 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://97bc424082175111bca3a83a57e17cdc7b48ce03b5bbe99f5be0aeda2e95b8ae}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.590: INFO: Pod "nginx-deployment-85db8c99c5-ls78v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-ls78v,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-ls78v,UID:a746b6e9-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22869,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc003294a07 0xc003294a08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003294b60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003294b80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.590: INFO: Pod "nginx-deployment-85db8c99c5-msg85" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-msg85,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-msg85,UID:a394298a-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22713,Generation:0,CreationTimestamp:2019-10-01 16:43:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc003294be7 0xc003294be8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.237,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003294c60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003294c90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:47 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.237,PodIP:172.30.58.126,StartTime:2019-10-01 16:43:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-01 16:43:48 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://cdc3decad51ca7af5b0f2d4465d31c3c8708755bb4b3f676f5f59256cbab4d2c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.590: INFO: Pod "nginx-deployment-85db8c99c5-rlbnm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-rlbnm,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-rlbnm,UID:a743d3db-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22853,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc003294ee7 0xc003294ee8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003294f70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003294f90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.590: INFO: Pod "nginx-deployment-85db8c99c5-rw2rp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-rw2rp,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-rw2rp,UID:a3941ee4-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22721,Generation:0,CreationTimestamp:2019-10-01 16:43:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc0032951a0 0xc0032951a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003295310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003295330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:47 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.233,PodIP:172.30.31.61,StartTime:2019-10-01 16:43:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-01 16:43:49 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://afbc96d900352a72cdfaeb92881bd22113f479f403f88728d220166c20945c3a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.590: INFO: Pod "nginx-deployment-85db8c99c5-wxhxs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-wxhxs,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-wxhxs,UID:a7440adc-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22861,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc0032954b7 0xc0032954b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003295590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032955b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.590: INFO: Pod "nginx-deployment-85db8c99c5-x4t7p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-x4t7p,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-x4t7p,UID:a741dfcf-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22873,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc003295630 0xc003295631}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.237,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032956a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032956c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.237,PodIP:,StartTime:2019-10-01 16:43:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.590: INFO: Pod "nginx-deployment-85db8c99c5-x6wbq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-x6wbq,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-x6wbq,UID:a746a347-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22866,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc003295797 0xc003295798}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003295800} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003295820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.590: INFO: Pod "nginx-deployment-85db8c99c5-x992f" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-x992f,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-x992f,UID:a38b1299-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22734,Generation:0,CreationTimestamp:2019-10-01 16:43:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc003295887 0xc003295888}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003295900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003295920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:47 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.242,PodIP:172.30.248.18,StartTime:2019-10-01 16:43:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-01 16:43:48 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://6af20a0de1ee7edb43e4ec94c115aaa2c599dd29056867e15a5b706fe0521457}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.590: INFO: Pod "nginx-deployment-85db8c99c5-xwh4k" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-xwh4k,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-xwh4k,UID:a38d376d-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22682,Generation:0,CreationTimestamp:2019-10-01 16:43:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc0032959f7 0xc0032959f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003295a70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003295a90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:47 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.233,PodIP:172.30.31.58,StartTime:2019-10-01 16:43:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-01 16:43:48 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://279c62198145afc7eae0e7bee3ac414fa54f1ee758afe81757239d19714af22d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.591: INFO: Pod "nginx-deployment-85db8c99c5-z2gd8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-z2gd8,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-z2gd8,UID:a746bdc2-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22870,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc003295b67 0xc003295b68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003295bd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003295bf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.591: INFO: Pod "nginx-deployment-85db8c99c5-z9xjn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-z9xjn,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-85db8c99c5-z9xjn,UID:a743f099-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22857,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 a388947e-e46a-11e9-865f-ced8df5791d3 0xc003295c57 0xc003295c58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.237,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003295cd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003295cf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.591: INFO: Pod "nginx-deployment-b79c9d74d-6cg9k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-6cg9k,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-b79c9d74d-6cg9k,UID:a60748fd-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22788,Generation:0,CreationTimestamp:2019-10-01 16:43:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d a5fbc01a-e46a-11e9-865f-ced8df5791d3 0xc003295d70 0xc003295d71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003295df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003295e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.233,PodIP:,StartTime:2019-10-01 16:43:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.591: INFO: Pod "nginx-deployment-b79c9d74d-ctdpg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-ctdpg,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-b79c9d74d-ctdpg,UID:a5ff62d3-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22767,Generation:0,CreationTimestamp:2019-10-01 16:43:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d a5fbc01a-e46a-11e9-865f-ced8df5791d3 0xc003295ef0 0xc003295ef1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003295f80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003295fa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.233,PodIP:,StartTime:2019-10-01 16:43:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.591: INFO: Pod "nginx-deployment-b79c9d74d-gcc8m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-gcc8m,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-b79c9d74d-gcc8m,UID:a74686c7-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22865,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d a5fbc01a-e46a-11e9-865f-ced8df5791d3 0xc002490080 0xc002490081}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024900f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002490110}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.591: INFO: Pod "nginx-deployment-b79c9d74d-k4sgf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-k4sgf,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-b79c9d74d-k4sgf,UID:a743ff20-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22859,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d a5fbc01a-e46a-11e9-865f-ced8df5791d3 0xc002490177 0xc002490178}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.237,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024901f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002490210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.592: INFO: Pod "nginx-deployment-b79c9d74d-m552r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-m552r,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-b79c9d74d-m552r,UID:a741dd0b-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22842,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d a5fbc01a-e46a-11e9-865f-ced8df5791d3 0xc002490290 0xc002490291}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002490310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002490330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.592: INFO: Pod "nginx-deployment-b79c9d74d-pdz52" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-pdz52,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-b79c9d74d-pdz52,UID:a5ff66f2-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22770,Generation:0,CreationTimestamp:2019-10-01 16:43:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d a5fbc01a-e46a-11e9-865f-ced8df5791d3 0xc0024903b0 0xc0024903b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.237,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002490430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002490450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.237,PodIP:,StartTime:2019-10-01 16:43:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.592: INFO: Pod "nginx-deployment-b79c9d74d-s7qc4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-s7qc4,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-b79c9d74d-s7qc4,UID:a743da10-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22854,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d a5fbc01a-e46a-11e9-865f-ced8df5791d3 0xc002490520 0xc002490521}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.233,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024905a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024905c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.592: INFO: Pod "nginx-deployment-b79c9d74d-t6jn2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-t6jn2,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-b79c9d74d-t6jn2,UID:a5fd7c12-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22755,Generation:0,CreationTimestamp:2019-10-01 16:43:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d a5fbc01a-e46a-11e9-865f-ced8df5791d3 0xc002490640 0xc002490641}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024906c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024906e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.242,PodIP:,StartTime:2019-10-01 16:43:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.593: INFO: Pod "nginx-deployment-b79c9d74d-tsf5d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-tsf5d,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-b79c9d74d-tsf5d,UID:a746a0a1-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22863,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d a5fbc01a-e46a-11e9-865f-ced8df5791d3 0xc0024907b0 0xc0024907b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002490830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002490860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.593: INFO: Pod "nginx-deployment-b79c9d74d-vgc65" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-vgc65,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-b79c9d74d-vgc65,UID:a7464b2e-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22871,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d a5fbc01a-e46a-11e9-865f-ced8df5791d3 0xc0024908c7 0xc0024908c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.237,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002490940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002490960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.593: INFO: Pod "nginx-deployment-b79c9d74d-wqwhv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-wqwhv,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-b79c9d74d-wqwhv,UID:a609fcd0-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22791,Generation:0,CreationTimestamp:2019-10-01 16:43:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d a5fbc01a-e46a-11e9-865f-ced8df5791d3 0xc0024909e0 0xc0024909e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002490a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002490a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:43:51 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.242,PodIP:,StartTime:2019-10-01 16:43:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct  1 16:43:53.593: INFO: Pod "nginx-deployment-b79c9d74d-xx7d9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-xx7d9,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-332,SelfLink:/api/v1/namespaces/deployment-332/pods/nginx-deployment-b79c9d74d-xx7d9,UID:a74690d8-e46a-11e9-865f-ced8df5791d3,ResourceVersion:22864,Generation:0,CreationTimestamp:2019-10-01 16:43:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d a5fbc01a-e46a-11e9-865f-ced8df5791d3 0xc002490b50 0xc002490b51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kllvt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kllvt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kllvt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002490bc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002490be0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:43:53.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-332" for this suite.
Oct  1 16:44:03.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:44:04.038: INFO: namespace deployment-332 deletion completed in 10.42422095s

• [SLOW TEST:16.998 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:44:04.039: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8112
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 16:44:04.295: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct  1 16:44:08.323: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct  1 16:44:10.400: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-8112,SelfLink:/apis/apps/v1/namespaces/deployment-8112/deployments/test-cleanup-deployment,UID:b0170025-e46a-11e9-bf88-8e83bb394576,ResourceVersion:23395,Generation:1,CreationTimestamp:2019-10-01 16:44:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-01 16:44:08 +0000 UTC 2019-10-01 16:44:08 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-01 16:44:09 +0000 UTC 2019-10-01 16:44:08 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-6865c98b76" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct  1 16:44:10.408: INFO: New ReplicaSet "test-cleanup-deployment-6865c98b76" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76,GenerateName:,Namespace:deployment-8112,SelfLink:/apis/apps/v1/namespaces/deployment-8112/replicasets/test-cleanup-deployment-6865c98b76,UID:b01ae03a-e46a-11e9-865f-ced8df5791d3,ResourceVersion:23386,Generation:1,CreationTimestamp:2019-10-01 16:44:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment b0170025-e46a-11e9-bf88-8e83bb394576 0xc001793c27 0xc001793c28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct  1 16:44:10.419: INFO: Pod "test-cleanup-deployment-6865c98b76-4pxk8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76-4pxk8,GenerateName:test-cleanup-deployment-6865c98b76-,Namespace:deployment-8112,SelfLink:/api/v1/namespaces/deployment-8112/pods/test-cleanup-deployment-6865c98b76-4pxk8,UID:b01d96fd-e46a-11e9-865f-ced8df5791d3,ResourceVersion:23385,Generation:0,CreationTimestamp:2019-10-01 16:44:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-6865c98b76 b01ae03a-e46a-11e9-865f-ced8df5791d3 0xc002a08247 0xc002a08248}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pjxqh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pjxqh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-pjxqh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a082c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a082e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:08 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.242,PodIP:172.30.248.29,StartTime:2019-10-01 16:44:08 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-01 16:44:09 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://94e072f5f860dd6f6cd46e4c1bb58d2e578ead721979baa980df37aede9db21c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:44:10.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8112" for this suite.
Oct  1 16:44:18.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:44:18.953: INFO: namespace deployment-8112 deletion completed in 8.513531759s

• [SLOW TEST:14.914 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:44:18.953: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7883
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-7883
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-7883
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7883
Oct  1 16:44:19.228: INFO: Found 0 stateful pods, waiting for 1
Oct  1 16:44:29.243: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Oct  1 16:44:29.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-7883 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  1 16:44:29.602: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  1 16:44:29.602: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  1 16:44:29.602: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  1 16:44:29.613: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct  1 16:44:39.626: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  1 16:44:39.626: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 16:44:39.672: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Oct  1 16:44:39.672: INFO: ss-0  10.75.67.233  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:19 +0000 UTC  }]
Oct  1 16:44:39.672: INFO: ss-1                Pending         []
Oct  1 16:44:39.672: INFO: 
Oct  1 16:44:39.672: INFO: StatefulSet ss has not reached scale 3, at 2
Oct  1 16:44:40.687: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.986927064s
Oct  1 16:44:41.696: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.97281644s
Oct  1 16:44:42.708: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.963276467s
Oct  1 16:44:43.772: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.951550325s
Oct  1 16:44:44.783: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.887139954s
Oct  1 16:44:45.792: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.876751084s
Oct  1 16:44:46.803: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.866763409s
Oct  1 16:44:47.812: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.856458835s
Oct  1 16:44:48.826: INFO: Verifying statefulset ss doesn't scale past 3 for another 847.236932ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7883
Oct  1 16:44:49.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-7883 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  1 16:44:50.164: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct  1 16:44:50.164: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct  1 16:44:50.164: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct  1 16:44:50.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-7883 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  1 16:44:50.489: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct  1 16:44:50.489: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct  1 16:44:50.489: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct  1 16:44:50.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-7883 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  1 16:44:50.811: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct  1 16:44:50.811: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct  1 16:44:50.811: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct  1 16:44:50.822: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 16:44:50.822: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 16:44:50.822: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Oct  1 16:44:50.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-7883 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  1 16:44:51.150: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  1 16:44:51.150: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  1 16:44:51.150: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  1 16:44:51.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-7883 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  1 16:44:51.474: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  1 16:44:51.474: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  1 16:44:51.474: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  1 16:44:51.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-7883 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  1 16:44:51.887: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  1 16:44:51.887: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  1 16:44:51.887: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  1 16:44:51.887: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 16:44:51.895: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct  1 16:45:02.004: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  1 16:45:02.004: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct  1 16:45:02.004: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct  1 16:45:02.045: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Oct  1 16:45:02.045: INFO: ss-0  10.75.67.233  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:19 +0000 UTC  }]
Oct  1 16:45:02.045: INFO: ss-1  10.75.67.242  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  }]
Oct  1 16:45:02.045: INFO: ss-2  10.75.67.237  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  }]
Oct  1 16:45:02.045: INFO: 
Oct  1 16:45:02.045: INFO: StatefulSet ss has not reached scale 0, at 3
Oct  1 16:45:03.058: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Oct  1 16:45:03.058: INFO: ss-0  10.75.67.233  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:19 +0000 UTC  }]
Oct  1 16:45:03.058: INFO: ss-1  10.75.67.242  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  }]
Oct  1 16:45:03.058: INFO: ss-2  10.75.67.237  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  }]
Oct  1 16:45:03.058: INFO: 
Oct  1 16:45:03.058: INFO: StatefulSet ss has not reached scale 0, at 3
Oct  1 16:45:04.069: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Oct  1 16:45:04.069: INFO: ss-0  10.75.67.233  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:19 +0000 UTC  }]
Oct  1 16:45:04.069: INFO: ss-2  10.75.67.237  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  }]
Oct  1 16:45:04.069: INFO: 
Oct  1 16:45:04.069: INFO: StatefulSet ss has not reached scale 0, at 2
Oct  1 16:45:05.080: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Oct  1 16:45:05.080: INFO: ss-0  10.75.67.233  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:19 +0000 UTC  }]
Oct  1 16:45:05.080: INFO: ss-2  10.75.67.237  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  }]
Oct  1 16:45:05.080: INFO: 
Oct  1 16:45:05.080: INFO: StatefulSet ss has not reached scale 0, at 2
Oct  1 16:45:06.091: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Oct  1 16:45:06.091: INFO: ss-0  10.75.67.233  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:19 +0000 UTC  }]
Oct  1 16:45:06.091: INFO: ss-2  10.75.67.237  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  }]
Oct  1 16:45:06.091: INFO: 
Oct  1 16:45:06.091: INFO: StatefulSet ss has not reached scale 0, at 2
Oct  1 16:45:07.105: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Oct  1 16:45:07.105: INFO: ss-0  10.75.67.233  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:19 +0000 UTC  }]
Oct  1 16:45:07.105: INFO: ss-2  10.75.67.237  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  }]
Oct  1 16:45:07.106: INFO: 
Oct  1 16:45:07.106: INFO: StatefulSet ss has not reached scale 0, at 2
Oct  1 16:45:08.118: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Oct  1 16:45:08.118: INFO: ss-0  10.75.67.233  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:19 +0000 UTC  }]
Oct  1 16:45:08.118: INFO: ss-2  10.75.67.237  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  }]
Oct  1 16:45:08.118: INFO: 
Oct  1 16:45:08.118: INFO: StatefulSet ss has not reached scale 0, at 2
Oct  1 16:45:09.133: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Oct  1 16:45:09.133: INFO: ss-2  10.75.67.237  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  }]
Oct  1 16:45:09.133: INFO: 
Oct  1 16:45:09.133: INFO: StatefulSet ss has not reached scale 0, at 1
Oct  1 16:45:10.146: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Oct  1 16:45:10.146: INFO: ss-2  10.75.67.237  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  }]
Oct  1 16:45:10.146: INFO: 
Oct  1 16:45:10.146: INFO: StatefulSet ss has not reached scale 0, at 1
Oct  1 16:45:11.164: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Oct  1 16:45:11.164: INFO: ss-2  10.75.67.237  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 16:44:39 +0000 UTC  }]
Oct  1 16:45:11.164: INFO: 
Oct  1 16:45:11.164: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7883
Oct  1 16:45:12.178: INFO: Scaling statefulset ss to 0
Oct  1 16:45:12.220: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct  1 16:45:12.246: INFO: Deleting all statefulset in ns statefulset-7883
Oct  1 16:45:12.257: INFO: Scaling statefulset ss to 0
Oct  1 16:45:12.291: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 16:45:12.299: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:45:12.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7883" for this suite.
Oct  1 16:45:20.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:45:20.764: INFO: namespace statefulset-7883 deletion completed in 8.403681561s

• [SLOW TEST:61.811 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:45:20.764: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2227
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 16:45:49.024: INFO: Container started at 2019-10-01 16:45:26 +0000 UTC, pod became ready at 2019-10-01 16:45:47 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:45:49.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2227" for this suite.
Oct  1 16:46:13.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:46:13.445: INFO: namespace container-probe-2227 deletion completed in 24.408018819s

• [SLOW TEST:52.681 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:46:13.445: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5694
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Oct  1 16:46:13.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 create -f - --namespace=kubectl-5694'
Oct  1 16:46:13.955: INFO: stderr: ""
Oct  1 16:46:13.955: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  1 16:46:13.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5694'
Oct  1 16:46:14.062: INFO: stderr: ""
Oct  1 16:46:14.062: INFO: stdout: "update-demo-nautilus-8brr5 update-demo-nautilus-kq9xl "
Oct  1 16:46:14.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-8brr5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5694'
Oct  1 16:46:14.161: INFO: stderr: ""
Oct  1 16:46:14.161: INFO: stdout: ""
Oct  1 16:46:14.161: INFO: update-demo-nautilus-8brr5 is created but not running
Oct  1 16:46:19.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5694'
Oct  1 16:46:19.288: INFO: stderr: ""
Oct  1 16:46:19.288: INFO: stdout: "update-demo-nautilus-8brr5 update-demo-nautilus-kq9xl "
Oct  1 16:46:19.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-8brr5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5694'
Oct  1 16:46:19.395: INFO: stderr: ""
Oct  1 16:46:19.395: INFO: stdout: "true"
Oct  1 16:46:19.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-8brr5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5694'
Oct  1 16:46:19.499: INFO: stderr: ""
Oct  1 16:46:19.500: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 16:46:19.500: INFO: validating pod update-demo-nautilus-8brr5
Oct  1 16:46:19.524: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 16:46:19.524: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 16:46:19.524: INFO: update-demo-nautilus-8brr5 is verified up and running
Oct  1 16:46:19.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-kq9xl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5694'
Oct  1 16:46:19.646: INFO: stderr: ""
Oct  1 16:46:19.646: INFO: stdout: "true"
Oct  1 16:46:19.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-kq9xl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5694'
Oct  1 16:46:19.758: INFO: stderr: ""
Oct  1 16:46:19.758: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 16:46:19.758: INFO: validating pod update-demo-nautilus-kq9xl
Oct  1 16:46:19.780: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 16:46:19.780: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 16:46:19.780: INFO: update-demo-nautilus-kq9xl is verified up and running
STEP: rolling-update to new replication controller
Oct  1 16:46:19.782: INFO: scanned /root for discovery docs: <nil>
Oct  1 16:46:19.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-5694'
Oct  1 16:46:41.846: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct  1 16:46:41.846: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  1 16:46:41.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5694'
Oct  1 16:46:41.960: INFO: stderr: ""
Oct  1 16:46:41.960: INFO: stdout: "update-demo-kitten-6q9q2 update-demo-kitten-rxpmp "
Oct  1 16:46:41.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-kitten-6q9q2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5694'
Oct  1 16:46:42.074: INFO: stderr: ""
Oct  1 16:46:42.074: INFO: stdout: "true"
Oct  1 16:46:42.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-kitten-6q9q2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5694'
Oct  1 16:46:42.182: INFO: stderr: ""
Oct  1 16:46:42.182: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct  1 16:46:42.182: INFO: validating pod update-demo-kitten-6q9q2
Oct  1 16:46:42.199: INFO: got data: {
  "image": "kitten.jpg"
}

Oct  1 16:46:42.199: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct  1 16:46:42.199: INFO: update-demo-kitten-6q9q2 is verified up and running
Oct  1 16:46:42.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-kitten-rxpmp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5694'
Oct  1 16:46:42.323: INFO: stderr: ""
Oct  1 16:46:42.323: INFO: stdout: "true"
Oct  1 16:46:42.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-kitten-rxpmp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5694'
Oct  1 16:46:42.422: INFO: stderr: ""
Oct  1 16:46:42.422: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct  1 16:46:42.422: INFO: validating pod update-demo-kitten-rxpmp
Oct  1 16:46:42.442: INFO: got data: {
  "image": "kitten.jpg"
}

Oct  1 16:46:42.442: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct  1 16:46:42.442: INFO: update-demo-kitten-rxpmp is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:46:42.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5694" for this suite.
Oct  1 16:47:06.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:47:06.808: INFO: namespace kubectl-5694 deletion completed in 24.352861998s

• [SLOW TEST:53.363 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:47:06.808: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4494
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1001 16:47:17.543777      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct  1 16:47:17.543: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:47:17.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4494" for this suite.
Oct  1 16:47:25.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:47:25.935: INFO: namespace gc-4494 deletion completed in 8.379452441s

• [SLOW TEST:19.127 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:47:25.935: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4068
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Oct  1 16:47:26.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 --namespace=kubectl-4068 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Oct  1 16:47:28.311: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Oct  1 16:47:28.311: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:47:30.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4068" for this suite.
Oct  1 16:47:40.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:47:40.716: INFO: namespace kubectl-4068 deletion completed in 10.377798883s

• [SLOW TEST:14.780 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:47:40.717: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2422
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct  1 16:47:40.955: INFO: Waiting up to 5m0s for pod "pod-2ecd9249-e46b-11e9-afc1-6aca03636ae4" in namespace "emptydir-2422" to be "success or failure"
Oct  1 16:47:40.970: INFO: Pod "pod-2ecd9249-e46b-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.379767ms
Oct  1 16:47:43.181: INFO: Pod "pod-2ecd9249-e46b-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.226053288s
Oct  1 16:47:45.191: INFO: Pod "pod-2ecd9249-e46b-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.236171898s
STEP: Saw pod success
Oct  1 16:47:45.191: INFO: Pod "pod-2ecd9249-e46b-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:47:45.204: INFO: Trying to get logs from node 10.75.67.242 pod pod-2ecd9249-e46b-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 16:47:45.265: INFO: Waiting for pod pod-2ecd9249-e46b-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:47:45.303: INFO: Pod pod-2ecd9249-e46b-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:47:45.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2422" for this suite.
Oct  1 16:47:51.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:47:51.721: INFO: namespace emptydir-2422 deletion completed in 6.405976239s

• [SLOW TEST:11.004 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:47:51.722: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1102
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Oct  1 16:47:51.957: INFO: Waiting up to 5m0s for pod "client-containers-355c46fe-e46b-11e9-afc1-6aca03636ae4" in namespace "containers-1102" to be "success or failure"
Oct  1 16:47:51.966: INFO: Pod "client-containers-355c46fe-e46b-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.79633ms
Oct  1 16:47:54.033: INFO: Pod "client-containers-355c46fe-e46b-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075951586s
Oct  1 16:47:56.044: INFO: Pod "client-containers-355c46fe-e46b-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.086376712s
STEP: Saw pod success
Oct  1 16:47:56.044: INFO: Pod "client-containers-355c46fe-e46b-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:47:56.053: INFO: Trying to get logs from node 10.75.67.233 pod client-containers-355c46fe-e46b-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 16:47:56.116: INFO: Waiting for pod client-containers-355c46fe-e46b-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:47:56.126: INFO: Pod client-containers-355c46fe-e46b-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:47:56.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1102" for this suite.
Oct  1 16:48:02.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:48:03.056: INFO: namespace containers-1102 deletion completed in 6.913210757s

• [SLOW TEST:11.334 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:48:03.056: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8471
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 16:48:03.414: INFO: Create a RollingUpdate DaemonSet
Oct  1 16:48:03.423: INFO: Check that daemon pods launch on every node of the cluster
Oct  1 16:48:03.450: INFO: Number of nodes with available pods: 0
Oct  1 16:48:03.450: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 16:48:04.479: INFO: Number of nodes with available pods: 0
Oct  1 16:48:04.479: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 16:48:05.481: INFO: Number of nodes with available pods: 2
Oct  1 16:48:05.481: INFO: Node 10.75.67.237 is running more than one daemon pod
Oct  1 16:48:06.478: INFO: Number of nodes with available pods: 3
Oct  1 16:48:06.478: INFO: Number of running nodes: 3, number of available pods: 3
Oct  1 16:48:06.479: INFO: Update the DaemonSet to trigger a rollout
Oct  1 16:48:06.497: INFO: Updating DaemonSet daemon-set
Oct  1 16:48:10.545: INFO: Roll back the DaemonSet before rollout is complete
Oct  1 16:48:10.560: INFO: Updating DaemonSet daemon-set
Oct  1 16:48:10.560: INFO: Make sure DaemonSet rollback is complete
Oct  1 16:48:10.574: INFO: Wrong image for pod: daemon-set-kqtvg. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct  1 16:48:10.574: INFO: Pod daemon-set-kqtvg is not available
Oct  1 16:48:11.600: INFO: Wrong image for pod: daemon-set-kqtvg. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct  1 16:48:11.600: INFO: Pod daemon-set-kqtvg is not available
Oct  1 16:48:12.599: INFO: Wrong image for pod: daemon-set-kqtvg. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct  1 16:48:12.599: INFO: Pod daemon-set-kqtvg is not available
Oct  1 16:48:13.600: INFO: Wrong image for pod: daemon-set-kqtvg. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct  1 16:48:13.601: INFO: Pod daemon-set-kqtvg is not available
Oct  1 16:48:14.598: INFO: Wrong image for pod: daemon-set-kqtvg. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct  1 16:48:14.599: INFO: Pod daemon-set-kqtvg is not available
Oct  1 16:48:15.597: INFO: Wrong image for pod: daemon-set-kqtvg. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct  1 16:48:15.597: INFO: Pod daemon-set-kqtvg is not available
Oct  1 16:48:16.598: INFO: Wrong image for pod: daemon-set-kqtvg. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct  1 16:48:16.598: INFO: Pod daemon-set-kqtvg is not available
Oct  1 16:48:17.600: INFO: Wrong image for pod: daemon-set-kqtvg. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct  1 16:48:17.601: INFO: Pod daemon-set-kqtvg is not available
Oct  1 16:48:18.601: INFO: Wrong image for pod: daemon-set-kqtvg. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct  1 16:48:18.601: INFO: Pod daemon-set-kqtvg is not available
Oct  1 16:48:19.599: INFO: Wrong image for pod: daemon-set-kqtvg. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct  1 16:48:19.599: INFO: Pod daemon-set-kqtvg is not available
Oct  1 16:48:20.599: INFO: Pod daemon-set-5lc6t is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8471, will wait for the garbage collector to delete the pods
Oct  1 16:48:20.703: INFO: Deleting DaemonSet.extensions daemon-set took: 18.127511ms
Oct  1 16:48:20.903: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.222418ms
Oct  1 16:48:31.516: INFO: Number of nodes with available pods: 0
Oct  1 16:48:31.516: INFO: Number of running nodes: 0, number of available pods: 0
Oct  1 16:48:31.522: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8471/daemonsets","resourceVersion":"24782"},"items":null}

Oct  1 16:48:31.530: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8471/pods","resourceVersion":"24782"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:48:31.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8471" for this suite.
Oct  1 16:48:39.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:48:39.977: INFO: namespace daemonsets-8471 deletion completed in 8.370642051s

• [SLOW TEST:36.921 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:48:39.977: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3330
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-521eb360-e46b-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume configMaps
Oct  1 16:48:40.217: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-52204f84-e46b-11e9-afc1-6aca03636ae4" in namespace "projected-3330" to be "success or failure"
Oct  1 16:48:40.231: INFO: Pod "pod-projected-configmaps-52204f84-e46b-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.903636ms
Oct  1 16:48:42.245: INFO: Pod "pod-projected-configmaps-52204f84-e46b-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027159041s
STEP: Saw pod success
Oct  1 16:48:42.245: INFO: Pod "pod-projected-configmaps-52204f84-e46b-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:48:42.288: INFO: Trying to get logs from node 10.75.67.233 pod pod-projected-configmaps-52204f84-e46b-11e9-afc1-6aca03636ae4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 16:48:42.349: INFO: Waiting for pod pod-projected-configmaps-52204f84-e46b-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:48:42.357: INFO: Pod pod-projected-configmaps-52204f84-e46b-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:48:42.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3330" for this suite.
Oct  1 16:48:48.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:48:48.894: INFO: namespace projected-3330 deletion completed in 6.523417509s

• [SLOW TEST:8.917 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:48:48.894: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9670
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct  1 16:48:55.244: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct  1 16:48:55.257: INFO: Pod pod-with-poststart-http-hook still exists
Oct  1 16:48:57.257: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct  1 16:48:57.269: INFO: Pod pod-with-poststart-http-hook still exists
Oct  1 16:48:59.257: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct  1 16:48:59.267: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:48:59.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9670" for this suite.
Oct  1 16:49:23.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:49:23.859: INFO: namespace container-lifecycle-hook-9670 deletion completed in 24.419451605s

• [SLOW TEST:34.965 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:49:23.859: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3839
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 16:49:24.090: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6c46bb4b-e46b-11e9-afc1-6aca03636ae4" in namespace "downward-api-3839" to be "success or failure"
Oct  1 16:49:24.099: INFO: Pod "downwardapi-volume-6c46bb4b-e46b-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.80851ms
Oct  1 16:49:26.114: INFO: Pod "downwardapi-volume-6c46bb4b-e46b-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023944097s
Oct  1 16:49:28.127: INFO: Pod "downwardapi-volume-6c46bb4b-e46b-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036551413s
STEP: Saw pod success
Oct  1 16:49:28.127: INFO: Pod "downwardapi-volume-6c46bb4b-e46b-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:49:28.140: INFO: Trying to get logs from node 10.75.67.233 pod downwardapi-volume-6c46bb4b-e46b-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 16:49:28.203: INFO: Waiting for pod downwardapi-volume-6c46bb4b-e46b-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:49:28.216: INFO: Pod downwardapi-volume-6c46bb4b-e46b-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:49:28.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3839" for this suite.
Oct  1 16:49:34.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:49:34.597: INFO: namespace downward-api-3839 deletion completed in 6.366275319s

• [SLOW TEST:10.738 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:49:34.597: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1001 16:49:44.955433      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct  1 16:49:44.955: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:49:44.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6" for this suite.
Oct  1 16:49:51.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:49:51.350: INFO: namespace gc-6 deletion completed in 6.383040555s

• [SLOW TEST:16.753 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:49:51.352: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8283
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-tgb74 in namespace proxy-8283
I1001 16:49:51.615764      17 runners.go:184] Created replication controller with name: proxy-service-tgb74, namespace: proxy-8283, replica count: 1
I1001 16:49:52.666778      17 runners.go:184] proxy-service-tgb74 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1001 16:49:53.667043      17 runners.go:184] proxy-service-tgb74 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1001 16:49:54.667317      17 runners.go:184] proxy-service-tgb74 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1001 16:49:55.667557      17 runners.go:184] proxy-service-tgb74 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1001 16:49:56.667691      17 runners.go:184] proxy-service-tgb74 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1001 16:49:57.667952      17 runners.go:184] proxy-service-tgb74 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1001 16:49:58.668190      17 runners.go:184] proxy-service-tgb74 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1001 16:49:59.668476      17 runners.go:184] proxy-service-tgb74 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  1 16:49:59.677: INFO: setup took 8.098245233s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Oct  1 16:49:59.697: INFO: (0) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 19.472573ms)
Oct  1 16:49:59.700: INFO: (0) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 22.789475ms)
Oct  1 16:49:59.704: INFO: (0) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 26.546578ms)
Oct  1 16:49:59.705: INFO: (0) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 27.13273ms)
Oct  1 16:49:59.705: INFO: (0) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 27.128562ms)
Oct  1 16:49:59.705: INFO: (0) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 27.443706ms)
Oct  1 16:49:59.708: INFO: (0) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 30.408544ms)
Oct  1 16:49:59.708: INFO: (0) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 30.811137ms)
Oct  1 16:49:59.714: INFO: (0) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 36.234037ms)
Oct  1 16:49:59.714: INFO: (0) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 36.761079ms)
Oct  1 16:49:59.715: INFO: (0) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 37.173966ms)
Oct  1 16:49:59.717: INFO: (0) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 39.076443ms)
Oct  1 16:49:59.717: INFO: (0) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 39.348085ms)
Oct  1 16:49:59.726: INFO: (0) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 48.285813ms)
Oct  1 16:49:59.736: INFO: (0) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 58.693728ms)
Oct  1 16:49:59.750: INFO: (0) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 72.341525ms)
Oct  1 16:49:59.762: INFO: (1) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 11.919239ms)
Oct  1 16:49:59.769: INFO: (1) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 19.125556ms)
Oct  1 16:49:59.770: INFO: (1) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 19.146322ms)
Oct  1 16:49:59.770: INFO: (1) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 19.353596ms)
Oct  1 16:49:59.770: INFO: (1) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 19.093403ms)
Oct  1 16:49:59.770: INFO: (1) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 18.979266ms)
Oct  1 16:49:59.770: INFO: (1) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 19.123225ms)
Oct  1 16:49:59.770: INFO: (1) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 19.526616ms)
Oct  1 16:49:59.770: INFO: (1) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 19.615162ms)
Oct  1 16:49:59.770: INFO: (1) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 19.572341ms)
Oct  1 16:49:59.774: INFO: (1) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 24.018096ms)
Oct  1 16:49:59.786: INFO: (1) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 35.306212ms)
Oct  1 16:49:59.786: INFO: (1) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 35.715865ms)
Oct  1 16:49:59.786: INFO: (1) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 35.368675ms)
Oct  1 16:49:59.786: INFO: (1) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 35.61026ms)
Oct  1 16:49:59.786: INFO: (1) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 35.847558ms)
Oct  1 16:49:59.806: INFO: (2) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 20.201246ms)
Oct  1 16:49:59.809: INFO: (2) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 22.609029ms)
Oct  1 16:49:59.809: INFO: (2) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 22.782333ms)
Oct  1 16:49:59.809: INFO: (2) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 22.722997ms)
Oct  1 16:49:59.810: INFO: (2) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 23.39082ms)
Oct  1 16:49:59.810: INFO: (2) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 23.729086ms)
Oct  1 16:49:59.810: INFO: (2) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 23.55165ms)
Oct  1 16:49:59.810: INFO: (2) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 23.473417ms)
Oct  1 16:49:59.810: INFO: (2) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 23.597372ms)
Oct  1 16:49:59.810: INFO: (2) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 23.948976ms)
Oct  1 16:49:59.814: INFO: (2) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 27.251408ms)
Oct  1 16:49:59.815: INFO: (2) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 28.997157ms)
Oct  1 16:49:59.816: INFO: (2) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 29.322105ms)
Oct  1 16:49:59.816: INFO: (2) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 29.236112ms)
Oct  1 16:49:59.816: INFO: (2) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 30.042063ms)
Oct  1 16:49:59.816: INFO: (2) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 29.937835ms)
Oct  1 16:49:59.837: INFO: (3) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 19.023506ms)
Oct  1 16:49:59.837: INFO: (3) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 20.398461ms)
Oct  1 16:49:59.837: INFO: (3) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 19.650566ms)
Oct  1 16:49:59.837: INFO: (3) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 19.991169ms)
Oct  1 16:49:59.837: INFO: (3) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 19.977426ms)
Oct  1 16:49:59.837: INFO: (3) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 20.363369ms)
Oct  1 16:49:59.837: INFO: (3) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 19.749219ms)
Oct  1 16:49:59.837: INFO: (3) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 19.854356ms)
Oct  1 16:49:59.837: INFO: (3) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 20.427273ms)
Oct  1 16:49:59.838: INFO: (3) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 20.264011ms)
Oct  1 16:49:59.839: INFO: (3) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 22.438616ms)
Oct  1 16:49:59.846: INFO: (3) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 29.353194ms)
Oct  1 16:49:59.847: INFO: (3) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 29.326163ms)
Oct  1 16:49:59.847: INFO: (3) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 29.867803ms)
Oct  1 16:49:59.847: INFO: (3) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 29.804461ms)
Oct  1 16:49:59.847: INFO: (3) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 30.439399ms)
Oct  1 16:49:59.865: INFO: (4) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 17.335172ms)
Oct  1 16:49:59.865: INFO: (4) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 17.131061ms)
Oct  1 16:49:59.865: INFO: (4) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 17.478119ms)
Oct  1 16:49:59.865: INFO: (4) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 16.993628ms)
Oct  1 16:49:59.865: INFO: (4) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 17.284466ms)
Oct  1 16:49:59.865: INFO: (4) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 17.447ms)
Oct  1 16:49:59.865: INFO: (4) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 17.343675ms)
Oct  1 16:49:59.865: INFO: (4) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 17.23944ms)
Oct  1 16:49:59.865: INFO: (4) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 17.239426ms)
Oct  1 16:49:59.865: INFO: (4) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 17.668727ms)
Oct  1 16:49:59.874: INFO: (4) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 26.422912ms)
Oct  1 16:49:59.883: INFO: (4) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 34.683647ms)
Oct  1 16:49:59.885: INFO: (4) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 37.722139ms)
Oct  1 16:49:59.885: INFO: (4) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 37.879966ms)
Oct  1 16:49:59.886: INFO: (4) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 37.770368ms)
Oct  1 16:49:59.886: INFO: (4) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 38.234542ms)
Oct  1 16:49:59.903: INFO: (5) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 16.614588ms)
Oct  1 16:49:59.903: INFO: (5) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 16.803053ms)
Oct  1 16:49:59.904: INFO: (5) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 17.11582ms)
Oct  1 16:49:59.904: INFO: (5) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 16.968365ms)
Oct  1 16:49:59.904: INFO: (5) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 17.050773ms)
Oct  1 16:49:59.904: INFO: (5) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 17.498817ms)
Oct  1 16:49:59.904: INFO: (5) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 17.5334ms)
Oct  1 16:49:59.904: INFO: (5) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 17.755951ms)
Oct  1 16:49:59.904: INFO: (5) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 18.001137ms)
Oct  1 16:49:59.905: INFO: (5) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 17.92264ms)
Oct  1 16:49:59.910: INFO: (5) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 23.997639ms)
Oct  1 16:49:59.914: INFO: (5) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 27.601467ms)
Oct  1 16:49:59.914: INFO: (5) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 27.738383ms)
Oct  1 16:49:59.914: INFO: (5) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 27.521876ms)
Oct  1 16:49:59.914: INFO: (5) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 27.477156ms)
Oct  1 16:49:59.914: INFO: (5) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 27.861132ms)
Oct  1 16:49:59.933: INFO: (6) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 18.748105ms)
Oct  1 16:49:59.935: INFO: (6) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 20.008042ms)
Oct  1 16:49:59.935: INFO: (6) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 20.328782ms)
Oct  1 16:49:59.935: INFO: (6) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 20.554954ms)
Oct  1 16:49:59.935: INFO: (6) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 20.614924ms)
Oct  1 16:49:59.935: INFO: (6) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 20.711618ms)
Oct  1 16:49:59.935: INFO: (6) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 20.511287ms)
Oct  1 16:49:59.935: INFO: (6) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 20.77508ms)
Oct  1 16:49:59.935: INFO: (6) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 20.887113ms)
Oct  1 16:49:59.936: INFO: (6) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 21.305502ms)
Oct  1 16:49:59.939: INFO: (6) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 25.070819ms)
Oct  1 16:49:59.947: INFO: (6) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 32.165893ms)
Oct  1 16:49:59.947: INFO: (6) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 32.293209ms)
Oct  1 16:49:59.947: INFO: (6) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 32.704232ms)
Oct  1 16:49:59.947: INFO: (6) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 32.627983ms)
Oct  1 16:49:59.947: INFO: (6) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 32.596933ms)
Oct  1 16:49:59.964: INFO: (7) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 16.253187ms)
Oct  1 16:49:59.968: INFO: (7) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 20.153696ms)
Oct  1 16:49:59.968: INFO: (7) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 20.78409ms)
Oct  1 16:49:59.973: INFO: (7) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 25.569307ms)
Oct  1 16:49:59.973: INFO: (7) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 25.759423ms)
Oct  1 16:49:59.973: INFO: (7) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 25.809908ms)
Oct  1 16:49:59.973: INFO: (7) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 25.808584ms)
Oct  1 16:49:59.973: INFO: (7) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 26.054522ms)
Oct  1 16:49:59.973: INFO: (7) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 25.805502ms)
Oct  1 16:49:59.973: INFO: (7) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 26.151979ms)
Oct  1 16:49:59.977: INFO: (7) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 29.551604ms)
Oct  1 16:49:59.982: INFO: (7) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 35.107715ms)
Oct  1 16:49:59.984: INFO: (7) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 36.751916ms)
Oct  1 16:49:59.984: INFO: (7) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 36.87291ms)
Oct  1 16:49:59.984: INFO: (7) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 36.899007ms)
Oct  1 16:49:59.985: INFO: (7) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 37.229678ms)
Oct  1 16:50:00.003: INFO: (8) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 18.104201ms)
Oct  1 16:50:00.003: INFO: (8) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 18.716996ms)
Oct  1 16:50:00.004: INFO: (8) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 18.678959ms)
Oct  1 16:50:00.004: INFO: (8) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 18.833641ms)
Oct  1 16:50:00.003: INFO: (8) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 18.694787ms)
Oct  1 16:50:00.004: INFO: (8) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 18.87601ms)
Oct  1 16:50:00.004: INFO: (8) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 19.064778ms)
Oct  1 16:50:00.004: INFO: (8) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 18.707642ms)
Oct  1 16:50:00.004: INFO: (8) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 18.993531ms)
Oct  1 16:50:00.004: INFO: (8) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 19.049634ms)
Oct  1 16:50:00.019: INFO: (8) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 34.047839ms)
Oct  1 16:50:00.019: INFO: (8) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 34.060711ms)
Oct  1 16:50:00.019: INFO: (8) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 34.363202ms)
Oct  1 16:50:00.019: INFO: (8) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 34.071524ms)
Oct  1 16:50:00.019: INFO: (8) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 34.168692ms)
Oct  1 16:50:00.020: INFO: (8) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 35.33559ms)
Oct  1 16:50:00.046: INFO: (9) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 26.240974ms)
Oct  1 16:50:00.046: INFO: (9) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 25.850736ms)
Oct  1 16:50:00.046: INFO: (9) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 25.979422ms)
Oct  1 16:50:00.046: INFO: (9) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 26.239675ms)
Oct  1 16:50:00.046: INFO: (9) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 25.855996ms)
Oct  1 16:50:00.047: INFO: (9) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 25.984871ms)
Oct  1 16:50:00.047: INFO: (9) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 26.337972ms)
Oct  1 16:50:00.047: INFO: (9) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 26.345801ms)
Oct  1 16:50:00.047: INFO: (9) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 26.999948ms)
Oct  1 16:50:00.051: INFO: (9) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 30.704936ms)
Oct  1 16:50:00.056: INFO: (9) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 35.46956ms)
Oct  1 16:50:00.064: INFO: (9) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 43.686192ms)
Oct  1 16:50:00.065: INFO: (9) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 44.077656ms)
Oct  1 16:50:00.065: INFO: (9) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 44.205004ms)
Oct  1 16:50:00.065: INFO: (9) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 44.156841ms)
Oct  1 16:50:00.065: INFO: (9) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 44.213023ms)
Oct  1 16:50:00.086: INFO: (10) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 20.609178ms)
Oct  1 16:50:00.086: INFO: (10) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 20.503779ms)
Oct  1 16:50:00.086: INFO: (10) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 20.623751ms)
Oct  1 16:50:00.086: INFO: (10) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 20.790777ms)
Oct  1 16:50:00.086: INFO: (10) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 20.810227ms)
Oct  1 16:50:00.086: INFO: (10) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 21.025125ms)
Oct  1 16:50:00.086: INFO: (10) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 21.439855ms)
Oct  1 16:50:00.087: INFO: (10) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 21.673655ms)
Oct  1 16:50:00.087: INFO: (10) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 21.566212ms)
Oct  1 16:50:00.087: INFO: (10) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 21.188067ms)
Oct  1 16:50:00.090: INFO: (10) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 25.220022ms)
Oct  1 16:50:00.095: INFO: (10) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 29.650672ms)
Oct  1 16:50:00.095: INFO: (10) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 29.948808ms)
Oct  1 16:50:00.095: INFO: (10) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 29.78451ms)
Oct  1 16:50:00.095: INFO: (10) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 29.888148ms)
Oct  1 16:50:00.095: INFO: (10) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 30.285253ms)
Oct  1 16:50:00.111: INFO: (11) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 15.796265ms)
Oct  1 16:50:00.119: INFO: (11) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 23.728254ms)
Oct  1 16:50:00.120: INFO: (11) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 24.337952ms)
Oct  1 16:50:00.120: INFO: (11) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 24.489469ms)
Oct  1 16:50:00.120: INFO: (11) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 24.810457ms)
Oct  1 16:50:00.120: INFO: (11) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 24.831974ms)
Oct  1 16:50:00.121: INFO: (11) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 25.105256ms)
Oct  1 16:50:00.121: INFO: (11) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 25.285489ms)
Oct  1 16:50:00.122: INFO: (11) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 26.93798ms)
Oct  1 16:50:00.123: INFO: (11) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 27.405773ms)
Oct  1 16:50:00.129: INFO: (11) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 33.506014ms)
Oct  1 16:50:00.133: INFO: (11) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 37.040969ms)
Oct  1 16:50:00.133: INFO: (11) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 37.141378ms)
Oct  1 16:50:00.143: INFO: (11) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 46.956235ms)
Oct  1 16:50:00.143: INFO: (11) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 47.03842ms)
Oct  1 16:50:00.143: INFO: (11) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 47.157646ms)
Oct  1 16:50:00.158: INFO: (12) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 15.393801ms)
Oct  1 16:50:00.170: INFO: (12) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 26.945976ms)
Oct  1 16:50:00.172: INFO: (12) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 28.467159ms)
Oct  1 16:50:00.175: INFO: (12) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 31.292728ms)
Oct  1 16:50:00.175: INFO: (12) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 31.275335ms)
Oct  1 16:50:00.175: INFO: (12) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 31.324334ms)
Oct  1 16:50:00.175: INFO: (12) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 31.700797ms)
Oct  1 16:50:00.175: INFO: (12) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 31.80956ms)
Oct  1 16:50:00.175: INFO: (12) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 31.394275ms)
Oct  1 16:50:00.175: INFO: (12) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 31.776276ms)
Oct  1 16:50:00.175: INFO: (12) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 32.031071ms)
Oct  1 16:50:00.177: INFO: (12) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 33.464819ms)
Oct  1 16:50:00.186: INFO: (12) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 42.165257ms)
Oct  1 16:50:00.186: INFO: (12) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 42.24632ms)
Oct  1 16:50:00.186: INFO: (12) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 42.892401ms)
Oct  1 16:50:00.186: INFO: (12) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 42.827829ms)
Oct  1 16:50:00.210: INFO: (13) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 23.066629ms)
Oct  1 16:50:00.210: INFO: (13) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 23.380183ms)
Oct  1 16:50:00.210: INFO: (13) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 23.473659ms)
Oct  1 16:50:00.210: INFO: (13) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 23.885025ms)
Oct  1 16:50:00.210: INFO: (13) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 24.049955ms)
Oct  1 16:50:00.210: INFO: (13) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 23.935302ms)
Oct  1 16:50:00.210: INFO: (13) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 24.073709ms)
Oct  1 16:50:00.210: INFO: (13) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 23.726604ms)
Oct  1 16:50:00.210: INFO: (13) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 23.826602ms)
Oct  1 16:50:00.210: INFO: (13) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 24.152987ms)
Oct  1 16:50:00.217: INFO: (13) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 30.265565ms)
Oct  1 16:50:00.226: INFO: (13) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 39.685898ms)
Oct  1 16:50:00.226: INFO: (13) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 39.919835ms)
Oct  1 16:50:00.226: INFO: (13) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 39.880352ms)
Oct  1 16:50:00.226: INFO: (13) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 40.106578ms)
Oct  1 16:50:00.228: INFO: (13) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 41.698696ms)
Oct  1 16:50:00.256: INFO: (14) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 27.2794ms)
Oct  1 16:50:00.256: INFO: (14) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 27.162016ms)
Oct  1 16:50:00.256: INFO: (14) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 27.570801ms)
Oct  1 16:50:00.256: INFO: (14) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 27.550357ms)
Oct  1 16:50:00.256: INFO: (14) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 27.422095ms)
Oct  1 16:50:00.256: INFO: (14) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 27.579789ms)
Oct  1 16:50:00.256: INFO: (14) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 27.558885ms)
Oct  1 16:50:00.260: INFO: (14) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 31.437873ms)
Oct  1 16:50:00.264: INFO: (14) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 35.296509ms)
Oct  1 16:50:00.264: INFO: (14) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 35.432721ms)
Oct  1 16:50:00.264: INFO: (14) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 35.973389ms)
Oct  1 16:50:00.265: INFO: (14) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 36.961009ms)
Oct  1 16:50:00.265: INFO: (14) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 36.925908ms)
Oct  1 16:50:00.266: INFO: (14) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 37.260035ms)
Oct  1 16:50:00.266: INFO: (14) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 37.505269ms)
Oct  1 16:50:00.266: INFO: (14) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 37.261082ms)
Oct  1 16:50:00.290: INFO: (15) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 24.015674ms)
Oct  1 16:50:00.291: INFO: (15) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 24.864898ms)
Oct  1 16:50:00.291: INFO: (15) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 24.570817ms)
Oct  1 16:50:00.291: INFO: (15) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 24.620813ms)
Oct  1 16:50:00.291: INFO: (15) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 24.570918ms)
Oct  1 16:50:00.291: INFO: (15) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 24.55674ms)
Oct  1 16:50:00.291: INFO: (15) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 24.818029ms)
Oct  1 16:50:00.291: INFO: (15) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 24.681414ms)
Oct  1 16:50:00.291: INFO: (15) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 24.964296ms)
Oct  1 16:50:00.292: INFO: (15) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 25.27011ms)
Oct  1 16:50:00.297: INFO: (15) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 30.159325ms)
Oct  1 16:50:00.297: INFO: (15) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 30.150677ms)
Oct  1 16:50:00.297: INFO: (15) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 30.007294ms)
Oct  1 16:50:00.297: INFO: (15) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 30.022336ms)
Oct  1 16:50:00.297: INFO: (15) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 30.131205ms)
Oct  1 16:50:00.297: INFO: (15) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 30.249101ms)
Oct  1 16:50:00.318: INFO: (16) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 21.648084ms)
Oct  1 16:50:00.318: INFO: (16) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 21.367323ms)
Oct  1 16:50:00.322: INFO: (16) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 24.965398ms)
Oct  1 16:50:00.322: INFO: (16) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 25.011965ms)
Oct  1 16:50:00.322: INFO: (16) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 25.385946ms)
Oct  1 16:50:00.322: INFO: (16) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 25.22632ms)
Oct  1 16:50:00.322: INFO: (16) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 25.621619ms)
Oct  1 16:50:00.323: INFO: (16) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 25.395237ms)
Oct  1 16:50:00.322: INFO: (16) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 25.385718ms)
Oct  1 16:50:00.326: INFO: (16) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 29.140979ms)
Oct  1 16:50:00.326: INFO: (16) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 29.338513ms)
Oct  1 16:50:00.326: INFO: (16) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 29.410034ms)
Oct  1 16:50:00.327: INFO: (16) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 29.335674ms)
Oct  1 16:50:00.327: INFO: (16) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 29.333805ms)
Oct  1 16:50:00.327: INFO: (16) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 29.435624ms)
Oct  1 16:50:00.333: INFO: (16) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 35.375536ms)
Oct  1 16:50:00.349: INFO: (17) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 15.798116ms)
Oct  1 16:50:00.358: INFO: (17) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 25.157036ms)
Oct  1 16:50:00.358: INFO: (17) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 24.809452ms)
Oct  1 16:50:00.358: INFO: (17) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 24.999917ms)
Oct  1 16:50:00.358: INFO: (17) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 25.51951ms)
Oct  1 16:50:00.360: INFO: (17) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 27.206357ms)
Oct  1 16:50:00.360: INFO: (17) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 27.220578ms)
Oct  1 16:50:00.360: INFO: (17) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 27.457371ms)
Oct  1 16:50:00.361: INFO: (17) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 27.887403ms)
Oct  1 16:50:00.361: INFO: (17) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 27.873938ms)
Oct  1 16:50:00.366: INFO: (17) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 33.119004ms)
Oct  1 16:50:00.370: INFO: (17) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 36.876727ms)
Oct  1 16:50:00.370: INFO: (17) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 37.243759ms)
Oct  1 16:50:00.371: INFO: (17) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 37.524751ms)
Oct  1 16:50:00.371: INFO: (17) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 37.623327ms)
Oct  1 16:50:00.371: INFO: (17) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 37.821819ms)
Oct  1 16:50:00.390: INFO: (18) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 19.119329ms)
Oct  1 16:50:00.390: INFO: (18) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 18.939396ms)
Oct  1 16:50:00.390: INFO: (18) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 19.010379ms)
Oct  1 16:50:00.390: INFO: (18) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 19.004139ms)
Oct  1 16:50:00.390: INFO: (18) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 19.137593ms)
Oct  1 16:50:00.390: INFO: (18) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 19.299595ms)
Oct  1 16:50:00.390: INFO: (18) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 19.227966ms)
Oct  1 16:50:00.408: INFO: (18) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 36.52656ms)
Oct  1 16:50:00.408: INFO: (18) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 36.526617ms)
Oct  1 16:50:00.408: INFO: (18) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 36.831983ms)
Oct  1 16:50:00.408: INFO: (18) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 36.756981ms)
Oct  1 16:50:00.411: INFO: (18) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 40.201914ms)
Oct  1 16:50:00.417: INFO: (18) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 45.959987ms)
Oct  1 16:50:00.417: INFO: (18) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 46.492782ms)
Oct  1 16:50:00.418: INFO: (18) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 46.376578ms)
Oct  1 16:50:00.417: INFO: (18) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 46.257908ms)
Oct  1 16:50:00.431: INFO: (19) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 12.925839ms)
Oct  1 16:50:00.439: INFO: (19) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">test<... (200; 21.056991ms)
Oct  1 16:50:00.439: INFO: (19) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:462/proxy/: tls qux (200; 21.091239ms)
Oct  1 16:50:00.439: INFO: (19) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl/proxy/rewriteme">test</a> (200; 21.318287ms)
Oct  1 16:50:00.440: INFO: (19) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:160/proxy/: foo (200; 21.435749ms)
Oct  1 16:50:00.440: INFO: (19) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:443/proxy/tlsrewritem... (200; 21.644306ms)
Oct  1 16:50:00.440: INFO: (19) /api/v1/namespaces/proxy-8283/pods/proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 21.635326ms)
Oct  1 16:50:00.440: INFO: (19) /api/v1/namespaces/proxy-8283/pods/https:proxy-service-tgb74-vc7nl:460/proxy/: tls baz (200; 22.238061ms)
Oct  1 16:50:00.440: INFO: (19) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:162/proxy/: bar (200; 21.981634ms)
Oct  1 16:50:00.440: INFO: (19) /api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8283/pods/http:proxy-service-tgb74-vc7nl:1080/proxy/rewriteme">... (200; 22.102952ms)
Oct  1 16:50:00.446: INFO: (19) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname1/proxy/: foo (200; 28.223697ms)
Oct  1 16:50:00.450: INFO: (19) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname2/proxy/: tls qux (200; 31.747025ms)
Oct  1 16:50:00.450: INFO: (19) /api/v1/namespaces/proxy-8283/services/https:proxy-service-tgb74:tlsportname1/proxy/: tls baz (200; 32.12957ms)
Oct  1 16:50:00.451: INFO: (19) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname2/proxy/: bar (200; 32.513825ms)
Oct  1 16:50:00.451: INFO: (19) /api/v1/namespaces/proxy-8283/services/proxy-service-tgb74:portname2/proxy/: bar (200; 32.505071ms)
Oct  1 16:50:00.451: INFO: (19) /api/v1/namespaces/proxy-8283/services/http:proxy-service-tgb74:portname1/proxy/: foo (200; 32.788224ms)
STEP: deleting ReplicationController proxy-service-tgb74 in namespace proxy-8283, will wait for the garbage collector to delete the pods
Oct  1 16:50:00.537: INFO: Deleting ReplicationController proxy-service-tgb74 took: 26.22878ms
Oct  1 16:50:00.737: INFO: Terminating ReplicationController proxy-service-tgb74 pods took: 200.284372ms
[AfterEach] version v1
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:50:02.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8283" for this suite.
Oct  1 16:50:08.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:50:09.045: INFO: namespace proxy-8283 deletion completed in 6.388656544s

• [SLOW TEST:17.693 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:50:09.045: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-152
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Oct  1 16:50:09.281: INFO: Waiting up to 5m0s for pod "client-containers-87360113-e46b-11e9-afc1-6aca03636ae4" in namespace "containers-152" to be "success or failure"
Oct  1 16:50:09.293: INFO: Pod "client-containers-87360113-e46b-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.240123ms
Oct  1 16:50:11.306: INFO: Pod "client-containers-87360113-e46b-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024059394s
Oct  1 16:50:13.322: INFO: Pod "client-containers-87360113-e46b-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040047426s
STEP: Saw pod success
Oct  1 16:50:13.322: INFO: Pod "client-containers-87360113-e46b-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:50:13.331: INFO: Trying to get logs from node 10.75.67.233 pod client-containers-87360113-e46b-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 16:50:13.414: INFO: Waiting for pod client-containers-87360113-e46b-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:50:13.424: INFO: Pod client-containers-87360113-e46b-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:50:13.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-152" for this suite.
Oct  1 16:50:19.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:50:19.796: INFO: namespace containers-152 deletion completed in 6.352245016s

• [SLOW TEST:10.750 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:50:19.796: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4407
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct  1 16:50:20.035: INFO: Waiting up to 5m0s for pod "pod-8d9ee240-e46b-11e9-afc1-6aca03636ae4" in namespace "emptydir-4407" to be "success or failure"
Oct  1 16:50:20.051: INFO: Pod "pod-8d9ee240-e46b-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.912834ms
Oct  1 16:50:22.061: INFO: Pod "pod-8d9ee240-e46b-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02598046s
Oct  1 16:50:24.073: INFO: Pod "pod-8d9ee240-e46b-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038398458s
STEP: Saw pod success
Oct  1 16:50:24.073: INFO: Pod "pod-8d9ee240-e46b-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:50:24.083: INFO: Trying to get logs from node 10.75.67.242 pod pod-8d9ee240-e46b-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 16:50:24.151: INFO: Waiting for pod pod-8d9ee240-e46b-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:50:24.164: INFO: Pod pod-8d9ee240-e46b-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:50:24.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4407" for this suite.
Oct  1 16:50:30.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:50:30.533: INFO: namespace emptydir-4407 deletion completed in 6.352030366s

• [SLOW TEST:10.737 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:50:30.533: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3533
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4190
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9612
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:50:37.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3533" for this suite.
Oct  1 16:50:43.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:50:43.591: INFO: namespace namespaces-3533 deletion completed in 6.338216448s
STEP: Destroying namespace "nsdeletetest-4190" for this suite.
Oct  1 16:50:43.608: INFO: Namespace nsdeletetest-4190 was already deleted
STEP: Destroying namespace "nsdeletetest-9612" for this suite.
Oct  1 16:50:49.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:50:49.962: INFO: namespace nsdeletetest-9612 deletion completed in 6.354153574s

• [SLOW TEST:19.428 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:50:49.962: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8674
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-9f988c17-e46b-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume secrets
Oct  1 16:50:50.206: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9f9ac61d-e46b-11e9-afc1-6aca03636ae4" in namespace "projected-8674" to be "success or failure"
Oct  1 16:50:50.218: INFO: Pod "pod-projected-secrets-9f9ac61d-e46b-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.387947ms
Oct  1 16:50:52.230: INFO: Pod "pod-projected-secrets-9f9ac61d-e46b-11e9-afc1-6aca03636ae4": Phase="Running", Reason="", readiness=true. Elapsed: 2.023348448s
Oct  1 16:50:54.240: INFO: Pod "pod-projected-secrets-9f9ac61d-e46b-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033904233s
STEP: Saw pod success
Oct  1 16:50:54.240: INFO: Pod "pod-projected-secrets-9f9ac61d-e46b-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:50:54.250: INFO: Trying to get logs from node 10.75.67.233 pod pod-projected-secrets-9f9ac61d-e46b-11e9-afc1-6aca03636ae4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  1 16:50:54.302: INFO: Waiting for pod pod-projected-secrets-9f9ac61d-e46b-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:50:54.311: INFO: Pod pod-projected-secrets-9f9ac61d-e46b-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:50:54.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8674" for this suite.
Oct  1 16:51:00.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:51:00.726: INFO: namespace projected-8674 deletion completed in 6.399617434s

• [SLOW TEST:10.764 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:51:00.727: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3480
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct  1 16:51:00.980: INFO: Waiting up to 5m0s for pod "pod-a605c7f1-e46b-11e9-afc1-6aca03636ae4" in namespace "emptydir-3480" to be "success or failure"
Oct  1 16:51:01.002: INFO: Pod "pod-a605c7f1-e46b-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 21.951908ms
Oct  1 16:51:03.016: INFO: Pod "pod-a605c7f1-e46b-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035686286s
STEP: Saw pod success
Oct  1 16:51:03.016: INFO: Pod "pod-a605c7f1-e46b-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:51:03.030: INFO: Trying to get logs from node 10.75.67.242 pod pod-a605c7f1-e46b-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 16:51:03.101: INFO: Waiting for pod pod-a605c7f1-e46b-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:51:03.110: INFO: Pod pod-a605c7f1-e46b-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:51:03.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3480" for this suite.
Oct  1 16:51:09.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:51:09.573: INFO: namespace emptydir-3480 deletion completed in 6.436691821s

• [SLOW TEST:8.847 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:51:09.576: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-7461
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Oct  1 16:51:12.941: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:51:12.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7461" for this suite.
Oct  1 16:51:37.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:51:37.381: INFO: namespace replicaset-7461 deletion completed in 24.384394173s

• [SLOW TEST:27.805 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:51:37.383: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3672
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6399
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4332
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:52:03.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3672" for this suite.
Oct  1 16:52:09.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:52:09.624: INFO: namespace namespaces-3672 deletion completed in 6.437175701s
STEP: Destroying namespace "nsdeletetest-6399" for this suite.
Oct  1 16:52:09.634: INFO: Namespace nsdeletetest-6399 was already deleted
STEP: Destroying namespace "nsdeletetest-4332" for this suite.
Oct  1 16:52:15.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:52:16.016: INFO: namespace nsdeletetest-4332 deletion completed in 6.38192655s

• [SLOW TEST:38.634 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:52:16.017: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-489
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct  1 16:52:16.287: INFO: Waiting up to 5m0s for pod "pod-d2e96dad-e46b-11e9-afc1-6aca03636ae4" in namespace "emptydir-489" to be "success or failure"
Oct  1 16:52:16.301: INFO: Pod "pod-d2e96dad-e46b-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.782854ms
Oct  1 16:52:18.320: INFO: Pod "pod-d2e96dad-e46b-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032937761s
STEP: Saw pod success
Oct  1 16:52:18.320: INFO: Pod "pod-d2e96dad-e46b-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:52:18.329: INFO: Trying to get logs from node 10.75.67.242 pod pod-d2e96dad-e46b-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 16:52:18.382: INFO: Waiting for pod pod-d2e96dad-e46b-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:52:18.390: INFO: Pod pod-d2e96dad-e46b-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:52:18.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-489" for this suite.
Oct  1 16:52:24.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:52:24.759: INFO: namespace emptydir-489 deletion completed in 6.356754687s

• [SLOW TEST:8.742 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:52:24.760: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9150
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9150
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Oct  1 16:52:25.015: INFO: Found 0 stateful pods, waiting for 3
Oct  1 16:52:35.028: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 16:52:35.028: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 16:52:35.028: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct  1 16:52:35.091: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Oct  1 16:52:45.163: INFO: Updating stateful set ss2
Oct  1 16:52:45.185: INFO: Waiting for Pod statefulset-9150/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Oct  1 16:52:55.297: INFO: Found 2 stateful pods, waiting for 3
Oct  1 16:53:05.309: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 16:53:05.309: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 16:53:05.309: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Oct  1 16:53:05.364: INFO: Updating stateful set ss2
Oct  1 16:53:05.415: INFO: Waiting for Pod statefulset-9150/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct  1 16:53:15.471: INFO: Updating stateful set ss2
Oct  1 16:53:15.499: INFO: Waiting for StatefulSet statefulset-9150/ss2 to complete update
Oct  1 16:53:15.499: INFO: Waiting for Pod statefulset-9150/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct  1 16:53:25.520: INFO: Waiting for StatefulSet statefulset-9150/ss2 to complete update
Oct  1 16:53:25.520: INFO: Waiting for Pod statefulset-9150/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct  1 16:53:35.519: INFO: Deleting all statefulset in ns statefulset-9150
Oct  1 16:53:35.530: INFO: Scaling statefulset ss2 to 0
Oct  1 16:53:55.581: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 16:53:55.590: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:53:55.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9150" for this suite.
Oct  1 16:54:03.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:54:04.102: INFO: namespace statefulset-9150 deletion completed in 8.456869802s

• [SLOW TEST:99.343 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:54:04.105: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-9370
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Oct  1 16:54:04.989: INFO: Pod name wrapped-volume-race-13b09c68-e46c-11e9-afc1-6aca03636ae4: Found 0 pods out of 5
Oct  1 16:54:10.006: INFO: Pod name wrapped-volume-race-13b09c68-e46c-11e9-afc1-6aca03636ae4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-13b09c68-e46c-11e9-afc1-6aca03636ae4 in namespace emptydir-wrapper-9370, will wait for the garbage collector to delete the pods
Oct  1 16:54:10.210: INFO: Deleting ReplicationController wrapped-volume-race-13b09c68-e46c-11e9-afc1-6aca03636ae4 took: 40.105402ms
Oct  1 16:54:10.311: INFO: Terminating ReplicationController wrapped-volume-race-13b09c68-e46c-11e9-afc1-6aca03636ae4 pods took: 100.378711ms
STEP: Creating RC which spawns configmap-volume pods
Oct  1 16:54:49.254: INFO: Pod name wrapped-volume-race-2e131b84-e46c-11e9-afc1-6aca03636ae4: Found 0 pods out of 5
Oct  1 16:54:54.270: INFO: Pod name wrapped-volume-race-2e131b84-e46c-11e9-afc1-6aca03636ae4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2e131b84-e46c-11e9-afc1-6aca03636ae4 in namespace emptydir-wrapper-9370, will wait for the garbage collector to delete the pods
Oct  1 16:54:54.413: INFO: Deleting ReplicationController wrapped-volume-race-2e131b84-e46c-11e9-afc1-6aca03636ae4 took: 26.251008ms
Oct  1 16:54:54.614: INFO: Terminating ReplicationController wrapped-volume-race-2e131b84-e46c-11e9-afc1-6aca03636ae4 pods took: 200.437458ms
STEP: Creating RC which spawns configmap-volume pods
Oct  1 16:55:29.235: INFO: Pod name wrapped-volume-race-45dbd30b-e46c-11e9-afc1-6aca03636ae4: Found 0 pods out of 5
Oct  1 16:55:34.251: INFO: Pod name wrapped-volume-race-45dbd30b-e46c-11e9-afc1-6aca03636ae4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-45dbd30b-e46c-11e9-afc1-6aca03636ae4 in namespace emptydir-wrapper-9370, will wait for the garbage collector to delete the pods
Oct  1 16:55:34.402: INFO: Deleting ReplicationController wrapped-volume-race-45dbd30b-e46c-11e9-afc1-6aca03636ae4 took: 27.407687ms
Oct  1 16:55:34.602: INFO: Terminating ReplicationController wrapped-volume-race-45dbd30b-e46c-11e9-afc1-6aca03636ae4 pods took: 200.25427ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:56:20.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9370" for this suite.
Oct  1 16:56:28.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:56:28.651: INFO: namespace emptydir-wrapper-9370 deletion completed in 8.340093984s

• [SLOW TEST:144.546 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:56:28.652: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9102
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-69797a3d-e46c-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume secrets
Oct  1 16:56:28.897: INFO: Waiting up to 5m0s for pod "pod-secrets-697b010e-e46c-11e9-afc1-6aca03636ae4" in namespace "secrets-9102" to be "success or failure"
Oct  1 16:56:28.911: INFO: Pod "pod-secrets-697b010e-e46c-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.849011ms
Oct  1 16:56:30.924: INFO: Pod "pod-secrets-697b010e-e46c-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027024232s
STEP: Saw pod success
Oct  1 16:56:30.924: INFO: Pod "pod-secrets-697b010e-e46c-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:56:30.934: INFO: Trying to get logs from node 10.75.67.233 pod pod-secrets-697b010e-e46c-11e9-afc1-6aca03636ae4 container secret-volume-test: <nil>
STEP: delete the pod
Oct  1 16:56:31.000: INFO: Waiting for pod pod-secrets-697b010e-e46c-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:56:31.010: INFO: Pod pod-secrets-697b010e-e46c-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:56:31.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9102" for this suite.
Oct  1 16:56:37.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:56:37.383: INFO: namespace secrets-9102 deletion completed in 6.353846929s

• [SLOW TEST:8.732 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:56:37.384: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5773
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct  1 16:56:37.628: INFO: Waiting up to 5m0s for pod "downward-api-6eaef011-e46c-11e9-afc1-6aca03636ae4" in namespace "downward-api-5773" to be "success or failure"
Oct  1 16:56:37.643: INFO: Pod "downward-api-6eaef011-e46c-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.413815ms
Oct  1 16:56:39.653: INFO: Pod "downward-api-6eaef011-e46c-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02520524s
STEP: Saw pod success
Oct  1 16:56:39.653: INFO: Pod "downward-api-6eaef011-e46c-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:56:39.664: INFO: Trying to get logs from node 10.75.67.242 pod downward-api-6eaef011-e46c-11e9-afc1-6aca03636ae4 container dapi-container: <nil>
STEP: delete the pod
Oct  1 16:56:39.732: INFO: Waiting for pod downward-api-6eaef011-e46c-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:56:39.740: INFO: Pod downward-api-6eaef011-e46c-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:56:39.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5773" for this suite.
Oct  1 16:56:45.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:56:46.117: INFO: namespace downward-api-5773 deletion completed in 6.363512047s

• [SLOW TEST:8.733 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:56:46.118: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8500
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-8500/secret-test-73e434e2-e46c-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume secrets
Oct  1 16:56:46.376: INFO: Waiting up to 5m0s for pod "pod-configmaps-73e5f2ef-e46c-11e9-afc1-6aca03636ae4" in namespace "secrets-8500" to be "success or failure"
Oct  1 16:56:46.384: INFO: Pod "pod-configmaps-73e5f2ef-e46c-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.633037ms
Oct  1 16:56:48.397: INFO: Pod "pod-configmaps-73e5f2ef-e46c-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021637841s
STEP: Saw pod success
Oct  1 16:56:48.398: INFO: Pod "pod-configmaps-73e5f2ef-e46c-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:56:48.410: INFO: Trying to get logs from node 10.75.67.233 pod pod-configmaps-73e5f2ef-e46c-11e9-afc1-6aca03636ae4 container env-test: <nil>
STEP: delete the pod
Oct  1 16:56:48.470: INFO: Waiting for pod pod-configmaps-73e5f2ef-e46c-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:56:48.486: INFO: Pod pod-configmaps-73e5f2ef-e46c-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:56:48.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8500" for this suite.
Oct  1 16:56:54.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:56:54.836: INFO: namespace secrets-8500 deletion completed in 6.337180666s

• [SLOW TEST:8.718 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:56:54.836: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3567
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 16:56:55.351: INFO: Waiting up to 5m0s for pod "downwardapi-volume-793f7f5c-e46c-11e9-afc1-6aca03636ae4" in namespace "downward-api-3567" to be "success or failure"
Oct  1 16:56:55.363: INFO: Pod "downwardapi-volume-793f7f5c-e46c-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.757382ms
Oct  1 16:56:57.375: INFO: Pod "downwardapi-volume-793f7f5c-e46c-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023454104s
STEP: Saw pod success
Oct  1 16:56:57.375: INFO: Pod "downwardapi-volume-793f7f5c-e46c-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:56:57.388: INFO: Trying to get logs from node 10.75.67.242 pod downwardapi-volume-793f7f5c-e46c-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 16:56:57.455: INFO: Waiting for pod downwardapi-volume-793f7f5c-e46c-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:56:57.468: INFO: Pod downwardapi-volume-793f7f5c-e46c-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:56:57.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3567" for this suite.
Oct  1 16:57:03.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:57:03.920: INFO: namespace downward-api-3567 deletion completed in 6.439342708s

• [SLOW TEST:9.084 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:57:03.920: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7397
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Oct  1 16:57:04.217: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7397,SelfLink:/api/v1/namespaces/watch-7397/configmaps/e2e-watch-test-configmap-a,UID:7e8a9d25-e46c-11e9-bf88-8e83bb394576,ResourceVersion:27329,Generation:0,CreationTimestamp:2019-10-01 16:57:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  1 16:57:04.217: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7397,SelfLink:/api/v1/namespaces/watch-7397/configmaps/e2e-watch-test-configmap-a,UID:7e8a9d25-e46c-11e9-bf88-8e83bb394576,ResourceVersion:27329,Generation:0,CreationTimestamp:2019-10-01 16:57:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Oct  1 16:57:14.245: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7397,SelfLink:/api/v1/namespaces/watch-7397/configmaps/e2e-watch-test-configmap-a,UID:7e8a9d25-e46c-11e9-bf88-8e83bb394576,ResourceVersion:27346,Generation:0,CreationTimestamp:2019-10-01 16:57:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct  1 16:57:14.245: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7397,SelfLink:/api/v1/namespaces/watch-7397/configmaps/e2e-watch-test-configmap-a,UID:7e8a9d25-e46c-11e9-bf88-8e83bb394576,ResourceVersion:27346,Generation:0,CreationTimestamp:2019-10-01 16:57:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Oct  1 16:57:24.269: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7397,SelfLink:/api/v1/namespaces/watch-7397/configmaps/e2e-watch-test-configmap-a,UID:7e8a9d25-e46c-11e9-bf88-8e83bb394576,ResourceVersion:27364,Generation:0,CreationTimestamp:2019-10-01 16:57:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  1 16:57:24.269: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7397,SelfLink:/api/v1/namespaces/watch-7397/configmaps/e2e-watch-test-configmap-a,UID:7e8a9d25-e46c-11e9-bf88-8e83bb394576,ResourceVersion:27364,Generation:0,CreationTimestamp:2019-10-01 16:57:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Oct  1 16:57:34.294: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7397,SelfLink:/api/v1/namespaces/watch-7397/configmaps/e2e-watch-test-configmap-a,UID:7e8a9d25-e46c-11e9-bf88-8e83bb394576,ResourceVersion:27383,Generation:0,CreationTimestamp:2019-10-01 16:57:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  1 16:57:34.294: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7397,SelfLink:/api/v1/namespaces/watch-7397/configmaps/e2e-watch-test-configmap-a,UID:7e8a9d25-e46c-11e9-bf88-8e83bb394576,ResourceVersion:27383,Generation:0,CreationTimestamp:2019-10-01 16:57:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Oct  1 16:57:44.312: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7397,SelfLink:/api/v1/namespaces/watch-7397/configmaps/e2e-watch-test-configmap-b,UID:966f896d-e46c-11e9-bf88-8e83bb394576,ResourceVersion:27400,Generation:0,CreationTimestamp:2019-10-01 16:57:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  1 16:57:44.312: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7397,SelfLink:/api/v1/namespaces/watch-7397/configmaps/e2e-watch-test-configmap-b,UID:966f896d-e46c-11e9-bf88-8e83bb394576,ResourceVersion:27400,Generation:0,CreationTimestamp:2019-10-01 16:57:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Oct  1 16:57:54.333: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7397,SelfLink:/api/v1/namespaces/watch-7397/configmaps/e2e-watch-test-configmap-b,UID:966f896d-e46c-11e9-bf88-8e83bb394576,ResourceVersion:27417,Generation:0,CreationTimestamp:2019-10-01 16:57:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  1 16:57:54.334: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7397,SelfLink:/api/v1/namespaces/watch-7397/configmaps/e2e-watch-test-configmap-b,UID:966f896d-e46c-11e9-bf88-8e83bb394576,ResourceVersion:27417,Generation:0,CreationTimestamp:2019-10-01 16:57:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:58:04.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7397" for this suite.
Oct  1 16:58:10.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:58:10.799: INFO: namespace watch-7397 deletion completed in 6.451435346s

• [SLOW TEST:66.879 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:58:10.801: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4013
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct  1 16:58:11.051: INFO: Waiting up to 5m0s for pod "downward-api-a65db19a-e46c-11e9-afc1-6aca03636ae4" in namespace "downward-api-4013" to be "success or failure"
Oct  1 16:58:11.065: INFO: Pod "downward-api-a65db19a-e46c-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.08375ms
Oct  1 16:58:13.080: INFO: Pod "downward-api-a65db19a-e46c-11e9-afc1-6aca03636ae4": Phase="Running", Reason="", readiness=true. Elapsed: 2.02889202s
Oct  1 16:58:15.091: INFO: Pod "downward-api-a65db19a-e46c-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039829835s
STEP: Saw pod success
Oct  1 16:58:15.091: INFO: Pod "downward-api-a65db19a-e46c-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:58:15.101: INFO: Trying to get logs from node 10.75.67.233 pod downward-api-a65db19a-e46c-11e9-afc1-6aca03636ae4 container dapi-container: <nil>
STEP: delete the pod
Oct  1 16:58:15.159: INFO: Waiting for pod downward-api-a65db19a-e46c-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:58:15.170: INFO: Pod downward-api-a65db19a-e46c-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:58:15.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4013" for this suite.
Oct  1 16:58:21.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:58:21.608: INFO: namespace downward-api-4013 deletion completed in 6.418086966s

• [SLOW TEST:10.808 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:58:21.609: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4101
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Oct  1 16:58:24.413: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4101 pod-service-account-ad1f0f1a-e46c-11e9-afc1-6aca03636ae4 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Oct  1 16:58:24.735: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4101 pod-service-account-ad1f0f1a-e46c-11e9-afc1-6aca03636ae4 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Oct  1 16:58:25.066: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4101 pod-service-account-ad1f0f1a-e46c-11e9-afc1-6aca03636ae4 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:58:25.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4101" for this suite.
Oct  1 16:58:31.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:58:31.747: INFO: namespace svcaccounts-4101 deletion completed in 6.356379225s

• [SLOW TEST:10.139 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:58:31.748: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2487
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 16:58:31.978: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b2d7d798-e46c-11e9-afc1-6aca03636ae4" in namespace "projected-2487" to be "success or failure"
Oct  1 16:58:31.988: INFO: Pod "downwardapi-volume-b2d7d798-e46c-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.584436ms
Oct  1 16:58:34.010: INFO: Pod "downwardapi-volume-b2d7d798-e46c-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031779291s
STEP: Saw pod success
Oct  1 16:58:34.010: INFO: Pod "downwardapi-volume-b2d7d798-e46c-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 16:58:34.020: INFO: Trying to get logs from node 10.75.67.233 pod downwardapi-volume-b2d7d798-e46c-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 16:58:34.073: INFO: Waiting for pod downwardapi-volume-b2d7d798-e46c-11e9-afc1-6aca03636ae4 to disappear
Oct  1 16:58:34.083: INFO: Pod downwardapi-volume-b2d7d798-e46c-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 16:58:34.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2487" for this suite.
Oct  1 16:58:40.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 16:58:40.435: INFO: namespace projected-2487 deletion completed in 6.334723902s

• [SLOW TEST:8.687 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 16:58:40.436: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-203
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-203
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-203
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-203
Oct  1 16:58:40.775: INFO: Found 0 stateful pods, waiting for 1
Oct  1 16:58:50.786: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Oct  1 16:58:50.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-203 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  1 16:58:51.117: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  1 16:58:51.117: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  1 16:58:51.117: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  1 16:58:51.126: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct  1 16:59:01.137: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  1 16:59:01.137: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 16:59:01.190: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998512s
Oct  1 16:59:02.202: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.987229372s
Oct  1 16:59:03.214: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.975500644s
Oct  1 16:59:04.226: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.963346551s
Oct  1 16:59:05.237: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.951641483s
Oct  1 16:59:06.434: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.940708532s
Oct  1 16:59:07.537: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.743544094s
Oct  1 16:59:08.564: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.64063978s
Oct  1 16:59:09.583: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.613176544s
Oct  1 16:59:10.595: INFO: Verifying statefulset ss doesn't scale past 1 for another 594.915721ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-203
Oct  1 16:59:11.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-203 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  1 16:59:11.936: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct  1 16:59:11.936: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct  1 16:59:11.936: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct  1 16:59:11.959: INFO: Found 1 stateful pods, waiting for 3
Oct  1 16:59:21.971: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 16:59:21.971: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 16:59:21.971: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Oct  1 16:59:21.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-203 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  1 16:59:22.301: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  1 16:59:22.301: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  1 16:59:22.301: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  1 16:59:22.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-203 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  1 16:59:22.635: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  1 16:59:22.635: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  1 16:59:22.635: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  1 16:59:22.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-203 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct  1 16:59:22.979: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct  1 16:59:22.979: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct  1 16:59:22.979: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct  1 16:59:22.979: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 16:59:22.988: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Oct  1 16:59:33.010: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  1 16:59:33.010: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct  1 16:59:33.010: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct  1 16:59:33.043: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998541s
Oct  1 16:59:34.054: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.986067685s
Oct  1 16:59:35.064: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.975006992s
Oct  1 16:59:36.093: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.965238463s
Oct  1 16:59:37.103: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.936211299s
Oct  1 16:59:38.112: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.926839742s
Oct  1 16:59:39.125: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.916985988s
Oct  1 16:59:40.139: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.90410219s
Oct  1 16:59:41.149: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.890562852s
Oct  1 16:59:42.175: INFO: Verifying statefulset ss doesn't scale past 3 for another 880.370609ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-203
Oct  1 16:59:43.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-203 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  1 16:59:43.553: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct  1 16:59:43.554: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct  1 16:59:43.554: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct  1 16:59:43.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-203 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  1 16:59:43.872: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct  1 16:59:43.872: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct  1 16:59:43.872: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct  1 16:59:43.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 exec --namespace=statefulset-203 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct  1 16:59:44.217: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct  1 16:59:44.217: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct  1 16:59:44.217: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct  1 16:59:44.217: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct  1 17:00:04.267: INFO: Deleting all statefulset in ns statefulset-203
Oct  1 17:00:04.282: INFO: Scaling statefulset ss to 0
Oct  1 17:00:04.319: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 17:00:04.330: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:00:04.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-203" for this suite.
Oct  1 17:00:12.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:00:12.811: INFO: namespace statefulset-203 deletion completed in 8.416790293s

• [SLOW TEST:92.375 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:00:12.811: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5388
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct  1 17:00:15.658: INFO: Successfully updated pod "annotationupdateef16561d-e46c-11e9-afc1-6aca03636ae4"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:00:19.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5388" for this suite.
Oct  1 17:00:43.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:00:44.123: INFO: namespace projected-5388 deletion completed in 24.368750618s

• [SLOW TEST:31.312 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:00:44.123: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4776
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-01bd091f-e46d-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume secrets
Oct  1 17:00:44.357: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-01bf5063-e46d-11e9-afc1-6aca03636ae4" in namespace "projected-4776" to be "success or failure"
Oct  1 17:00:44.367: INFO: Pod "pod-projected-secrets-01bf5063-e46d-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.423289ms
Oct  1 17:00:46.379: INFO: Pod "pod-projected-secrets-01bf5063-e46d-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021644814s
Oct  1 17:00:48.392: INFO: Pod "pod-projected-secrets-01bf5063-e46d-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035240062s
STEP: Saw pod success
Oct  1 17:00:48.393: INFO: Pod "pod-projected-secrets-01bf5063-e46d-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:00:48.406: INFO: Trying to get logs from node 10.75.67.242 pod pod-projected-secrets-01bf5063-e46d-11e9-afc1-6aca03636ae4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  1 17:00:48.465: INFO: Waiting for pod pod-projected-secrets-01bf5063-e46d-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:00:48.477: INFO: Pod pod-projected-secrets-01bf5063-e46d-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:00:48.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4776" for this suite.
Oct  1 17:00:54.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:00:54.840: INFO: namespace projected-4776 deletion completed in 6.346168949s

• [SLOW TEST:10.717 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:00:54.840: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1205
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-1205
Oct  1 17:00:57.101: INFO: Started pod liveness-exec in namespace container-probe-1205
STEP: checking the pod's current state and verifying that restartCount is present
Oct  1 17:00:57.113: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:04:58.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1205" for this suite.
Oct  1 17:05:04.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:05:04.736: INFO: namespace container-probe-1205 deletion completed in 6.62612216s

• [SLOW TEST:249.896 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:05:04.737: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4623
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-9d1a03ea-e46d-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume configMaps
Oct  1 17:05:05.013: INFO: Waiting up to 5m0s for pod "pod-configmaps-9d1bb1a0-e46d-11e9-afc1-6aca03636ae4" in namespace "configmap-4623" to be "success or failure"
Oct  1 17:05:05.029: INFO: Pod "pod-configmaps-9d1bb1a0-e46d-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.43696ms
Oct  1 17:05:07.039: INFO: Pod "pod-configmaps-9d1bb1a0-e46d-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025273966s
Oct  1 17:05:09.051: INFO: Pod "pod-configmaps-9d1bb1a0-e46d-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03743322s
STEP: Saw pod success
Oct  1 17:05:09.051: INFO: Pod "pod-configmaps-9d1bb1a0-e46d-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:05:09.060: INFO: Trying to get logs from node 10.75.67.242 pod pod-configmaps-9d1bb1a0-e46d-11e9-afc1-6aca03636ae4 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 17:05:09.122: INFO: Waiting for pod pod-configmaps-9d1bb1a0-e46d-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:05:09.133: INFO: Pod pod-configmaps-9d1bb1a0-e46d-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:05:09.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4623" for this suite.
Oct  1 17:05:15.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:05:15.538: INFO: namespace configmap-4623 deletion completed in 6.389669414s

• [SLOW TEST:10.801 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:05:15.539: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1151
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct  1 17:05:21.919: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  1 17:05:21.929: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  1 17:05:23.929: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  1 17:05:23.941: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  1 17:05:25.929: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  1 17:05:25.940: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  1 17:05:27.929: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  1 17:05:27.940: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  1 17:05:29.929: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  1 17:05:29.941: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  1 17:05:31.929: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  1 17:05:31.945: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  1 17:05:33.929: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  1 17:05:33.939: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  1 17:05:35.929: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  1 17:05:35.949: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  1 17:05:37.929: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  1 17:05:37.942: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  1 17:05:39.929: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  1 17:05:39.977: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  1 17:05:41.929: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  1 17:05:41.938: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:05:41.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1151" for this suite.
Oct  1 17:06:05.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:06:06.676: INFO: namespace container-lifecycle-hook-1151 deletion completed in 24.724052609s

• [SLOW TEST:51.138 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:06:06.677: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9367
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Oct  1 17:06:06.915: INFO: Waiting up to 5m0s for pod "client-containers-c20166c8-e46d-11e9-afc1-6aca03636ae4" in namespace "containers-9367" to be "success or failure"
Oct  1 17:06:06.931: INFO: Pod "client-containers-c20166c8-e46d-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.140391ms
Oct  1 17:06:08.941: INFO: Pod "client-containers-c20166c8-e46d-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026551663s
Oct  1 17:06:10.952: INFO: Pod "client-containers-c20166c8-e46d-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037220048s
STEP: Saw pod success
Oct  1 17:06:10.952: INFO: Pod "client-containers-c20166c8-e46d-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:06:10.966: INFO: Trying to get logs from node 10.75.67.233 pod client-containers-c20166c8-e46d-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 17:06:11.104: INFO: Waiting for pod client-containers-c20166c8-e46d-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:06:11.116: INFO: Pod client-containers-c20166c8-e46d-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:06:11.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9367" for this suite.
Oct  1 17:06:17.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:06:17.770: INFO: namespace containers-9367 deletion completed in 6.636199475s

• [SLOW TEST:11.093 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:06:17.770: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7547
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-c8a16301-e46d-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume configMaps
Oct  1 17:06:18.041: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c8a33e69-e46d-11e9-afc1-6aca03636ae4" in namespace "projected-7547" to be "success or failure"
Oct  1 17:06:18.066: INFO: Pod "pod-projected-configmaps-c8a33e69-e46d-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 24.646137ms
Oct  1 17:06:20.079: INFO: Pod "pod-projected-configmaps-c8a33e69-e46d-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037812904s
Oct  1 17:06:22.089: INFO: Pod "pod-projected-configmaps-c8a33e69-e46d-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047801485s
STEP: Saw pod success
Oct  1 17:06:22.089: INFO: Pod "pod-projected-configmaps-c8a33e69-e46d-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:06:22.103: INFO: Trying to get logs from node 10.75.67.242 pod pod-projected-configmaps-c8a33e69-e46d-11e9-afc1-6aca03636ae4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 17:06:22.174: INFO: Waiting for pod pod-projected-configmaps-c8a33e69-e46d-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:06:22.184: INFO: Pod pod-projected-configmaps-c8a33e69-e46d-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:06:22.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7547" for this suite.
Oct  1 17:06:28.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:06:28.611: INFO: namespace projected-7547 deletion completed in 6.414491215s

• [SLOW TEST:10.841 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:06:28.611: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7243
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct  1 17:06:28.934: INFO: Number of nodes with available pods: 0
Oct  1 17:06:28.934: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 17:06:29.966: INFO: Number of nodes with available pods: 0
Oct  1 17:06:29.966: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 17:06:30.971: INFO: Number of nodes with available pods: 2
Oct  1 17:06:30.971: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 17:06:31.961: INFO: Number of nodes with available pods: 3
Oct  1 17:06:31.961: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Oct  1 17:06:32.023: INFO: Number of nodes with available pods: 2
Oct  1 17:06:32.023: INFO: Node 10.75.67.242 is running more than one daemon pod
Oct  1 17:06:33.048: INFO: Number of nodes with available pods: 2
Oct  1 17:06:33.048: INFO: Node 10.75.67.242 is running more than one daemon pod
Oct  1 17:06:34.048: INFO: Number of nodes with available pods: 2
Oct  1 17:06:34.048: INFO: Node 10.75.67.242 is running more than one daemon pod
Oct  1 17:06:35.055: INFO: Number of nodes with available pods: 2
Oct  1 17:06:35.055: INFO: Node 10.75.67.242 is running more than one daemon pod
Oct  1 17:06:36.048: INFO: Number of nodes with available pods: 2
Oct  1 17:06:36.048: INFO: Node 10.75.67.242 is running more than one daemon pod
Oct  1 17:06:37.055: INFO: Number of nodes with available pods: 3
Oct  1 17:06:37.055: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7243, will wait for the garbage collector to delete the pods
Oct  1 17:06:37.141: INFO: Deleting DaemonSet.extensions daemon-set took: 15.249837ms
Oct  1 17:06:37.341: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.287882ms
Oct  1 17:06:41.459: INFO: Number of nodes with available pods: 0
Oct  1 17:06:41.459: INFO: Number of running nodes: 0, number of available pods: 0
Oct  1 17:06:41.465: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7243/daemonsets","resourceVersion":"29032"},"items":null}

Oct  1 17:06:41.475: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7243/pods","resourceVersion":"29032"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:06:41.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7243" for this suite.
Oct  1 17:06:49.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:06:49.933: INFO: namespace daemonsets-7243 deletion completed in 8.336507068s

• [SLOW TEST:21.322 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:06:49.933: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7282
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Oct  1 17:06:50.483: INFO: Waiting up to 5m0s for pod "var-expansion-dbf99ad4-e46d-11e9-afc1-6aca03636ae4" in namespace "var-expansion-7282" to be "success or failure"
Oct  1 17:06:50.492: INFO: Pod "var-expansion-dbf99ad4-e46d-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.971254ms
Oct  1 17:06:52.502: INFO: Pod "var-expansion-dbf99ad4-e46d-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018862948s
STEP: Saw pod success
Oct  1 17:06:52.502: INFO: Pod "var-expansion-dbf99ad4-e46d-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:06:52.516: INFO: Trying to get logs from node 10.75.67.233 pod var-expansion-dbf99ad4-e46d-11e9-afc1-6aca03636ae4 container dapi-container: <nil>
STEP: delete the pod
Oct  1 17:06:52.574: INFO: Waiting for pod var-expansion-dbf99ad4-e46d-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:06:52.583: INFO: Pod var-expansion-dbf99ad4-e46d-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:06:52.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7282" for this suite.
Oct  1 17:06:58.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:06:58.953: INFO: namespace var-expansion-7282 deletion completed in 6.358870937s

• [SLOW TEST:9.020 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:06:58.954: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9129
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1001 17:07:05.531809      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct  1 17:07:05.531: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:07:05.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9129" for this suite.
Oct  1 17:07:13.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:07:14.007: INFO: namespace gc-9129 deletion completed in 8.462970709s

• [SLOW TEST:15.054 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:07:14.008: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9097
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1001 17:07:44.391977      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct  1 17:07:44.392: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:07:44.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9097" for this suite.
Oct  1 17:07:50.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:07:50.787: INFO: namespace gc-9097 deletion completed in 6.381479146s

• [SLOW TEST:36.779 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:07:50.787: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-1582
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-1582
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-1582
STEP: Deleting pre-stop pod
Oct  1 17:08:04.158: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:08:04.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-1582" for this suite.
Oct  1 17:08:44.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:08:44.588: INFO: namespace prestop-1582 deletion completed in 40.376271652s

• [SLOW TEST:53.801 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:08:44.588: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1362
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-2023990c-e46e-11e9-afc1-6aca03636ae4
STEP: Creating secret with name s-test-opt-upd-2023995a-e46e-11e9-afc1-6aca03636ae4
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2023990c-e46e-11e9-afc1-6aca03636ae4
STEP: Updating secret s-test-opt-upd-2023995a-e46e-11e9-afc1-6aca03636ae4
STEP: Creating secret with name s-test-opt-create-2023997e-e46e-11e9-afc1-6aca03636ae4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:10:14.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1362" for this suite.
Oct  1 17:10:38.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:10:38.845: INFO: namespace secrets-1362 deletion completed in 24.383253966s

• [SLOW TEST:114.257 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:10:38.845: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3238
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-6439ef30-e46e-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume configMaps
Oct  1 17:10:39.095: INFO: Waiting up to 5m0s for pod "pod-configmaps-643c2cae-e46e-11e9-afc1-6aca03636ae4" in namespace "configmap-3238" to be "success or failure"
Oct  1 17:10:39.110: INFO: Pod "pod-configmaps-643c2cae-e46e-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.956207ms
Oct  1 17:10:41.126: INFO: Pod "pod-configmaps-643c2cae-e46e-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030563221s
STEP: Saw pod success
Oct  1 17:10:41.126: INFO: Pod "pod-configmaps-643c2cae-e46e-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:10:41.136: INFO: Trying to get logs from node 10.75.67.233 pod pod-configmaps-643c2cae-e46e-11e9-afc1-6aca03636ae4 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 17:10:41.254: INFO: Waiting for pod pod-configmaps-643c2cae-e46e-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:10:41.270: INFO: Pod pod-configmaps-643c2cae-e46e-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:10:41.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3238" for this suite.
Oct  1 17:10:47.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:10:47.684: INFO: namespace configmap-3238 deletion completed in 6.400202103s

• [SLOW TEST:8.839 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:10:47.687: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1210
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct  1 17:10:47.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-1210'
Oct  1 17:10:48.131: INFO: stderr: ""
Oct  1 17:10:48.131: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Oct  1 17:10:53.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pod e2e-test-nginx-pod --namespace=kubectl-1210 -o json'
Oct  1 17:10:53.276: INFO: stderr: ""
Oct  1 17:10:53.276: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-10-01T17:10:48Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-1210\",\n        \"resourceVersion\": \"30049\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-1210/pods/e2e-test-nginx-pod\",\n        \"uid\": \"699df936-e46e-11e9-a0d0-8688e3f86694\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-r6rbh\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.75.67.242\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-r6rbh\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-r6rbh\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-01T17:10:48Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-01T17:10:49Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-01T17:10:49Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-01T17:10:48Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://4e6a957bcceba17605b9f17b6c19605cc86a9046bb9dcf8ffef4842cf9926729\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-10-01T17:10:49Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.75.67.242\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.248.6\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-10-01T17:10:48Z\"\n    }\n}\n"
STEP: replace the image in the pod
Oct  1 17:10:53.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 replace -f - --namespace=kubectl-1210'
Oct  1 17:10:53.576: INFO: stderr: ""
Oct  1 17:10:53.576: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Oct  1 17:10:53.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 delete pods e2e-test-nginx-pod --namespace=kubectl-1210'
Oct  1 17:10:59.802: INFO: stderr: ""
Oct  1 17:10:59.802: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:10:59.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1210" for this suite.
Oct  1 17:11:05.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:11:06.262: INFO: namespace kubectl-1210 deletion completed in 6.44475329s

• [SLOW TEST:18.576 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:11:06.263: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4298
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-8431
STEP: Creating secret with name secret-test-74938bf9-e46e-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume secrets
Oct  1 17:11:06.774: INFO: Waiting up to 5m0s for pod "pod-secrets-74bb64c8-e46e-11e9-afc1-6aca03636ae4" in namespace "secrets-4298" to be "success or failure"
Oct  1 17:11:06.794: INFO: Pod "pod-secrets-74bb64c8-e46e-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 19.698429ms
Oct  1 17:11:08.901: INFO: Pod "pod-secrets-74bb64c8-e46e-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.126906809s
Oct  1 17:11:10.920: INFO: Pod "pod-secrets-74bb64c8-e46e-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.145627001s
STEP: Saw pod success
Oct  1 17:11:10.920: INFO: Pod "pod-secrets-74bb64c8-e46e-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:11:10.931: INFO: Trying to get logs from node 10.75.67.233 pod pod-secrets-74bb64c8-e46e-11e9-afc1-6aca03636ae4 container secret-volume-test: <nil>
STEP: delete the pod
Oct  1 17:11:10.999: INFO: Waiting for pod pod-secrets-74bb64c8-e46e-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:11:11.009: INFO: Pod pod-secrets-74bb64c8-e46e-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:11:11.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4298" for this suite.
Oct  1 17:11:17.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:11:17.418: INFO: namespace secrets-4298 deletion completed in 6.395038715s
STEP: Destroying namespace "secret-namespace-8431" for this suite.
Oct  1 17:11:23.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:11:23.799: INFO: namespace secret-namespace-8431 deletion completed in 6.381320796s

• [SLOW TEST:17.536 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:11:23.799: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-970
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 17:11:24.042: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7f075aa4-e46e-11e9-afc1-6aca03636ae4" in namespace "projected-970" to be "success or failure"
Oct  1 17:11:24.051: INFO: Pod "downwardapi-volume-7f075aa4-e46e-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.65389ms
Oct  1 17:11:26.061: INFO: Pod "downwardapi-volume-7f075aa4-e46e-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018930804s
STEP: Saw pod success
Oct  1 17:11:26.061: INFO: Pod "downwardapi-volume-7f075aa4-e46e-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:11:26.071: INFO: Trying to get logs from node 10.75.67.242 pod downwardapi-volume-7f075aa4-e46e-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 17:11:26.149: INFO: Waiting for pod downwardapi-volume-7f075aa4-e46e-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:11:26.158: INFO: Pod downwardapi-volume-7f075aa4-e46e-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:11:26.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-970" for this suite.
Oct  1 17:11:32.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:11:32.559: INFO: namespace projected-970 deletion completed in 6.381051204s

• [SLOW TEST:8.760 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:11:32.561: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5093
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-844720ab-e46e-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume secrets
Oct  1 17:11:32.859: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8448c517-e46e-11e9-afc1-6aca03636ae4" in namespace "projected-5093" to be "success or failure"
Oct  1 17:11:32.873: INFO: Pod "pod-projected-secrets-8448c517-e46e-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.112662ms
Oct  1 17:11:34.888: INFO: Pod "pod-projected-secrets-8448c517-e46e-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02862614s
STEP: Saw pod success
Oct  1 17:11:34.888: INFO: Pod "pod-projected-secrets-8448c517-e46e-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:11:34.903: INFO: Trying to get logs from node 10.75.67.233 pod pod-projected-secrets-8448c517-e46e-11e9-afc1-6aca03636ae4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  1 17:11:34.956: INFO: Waiting for pod pod-projected-secrets-8448c517-e46e-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:11:34.971: INFO: Pod pod-projected-secrets-8448c517-e46e-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:11:34.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5093" for this suite.
Oct  1 17:11:41.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:11:41.657: INFO: namespace projected-5093 deletion completed in 6.667188334s

• [SLOW TEST:9.096 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:11:41.657: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4672
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 17:11:41.964: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"89b17fa4-e46e-11e9-bf88-8e83bb394576", Controller:(*bool)(0xc001792aea), BlockOwnerDeletion:(*bool)(0xc001792aeb)}}
Oct  1 17:11:41.979: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"89ac9032-e46e-11e9-bf88-8e83bb394576", Controller:(*bool)(0xc0010b0406), BlockOwnerDeletion:(*bool)(0xc0010b0407)}}
Oct  1 17:11:41.999: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"89aed855-e46e-11e9-bf88-8e83bb394576", Controller:(*bool)(0xc001320826), BlockOwnerDeletion:(*bool)(0xc001320827)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:11:47.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4672" for this suite.
Oct  1 17:11:55.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:11:55.422: INFO: namespace gc-4672 deletion completed in 8.367937637s

• [SLOW TEST:13.764 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:11:55.422: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5865
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1576
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct  1 17:11:55.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-5865'
Oct  1 17:11:55.752: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  1 17:11:55.752: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1581
Oct  1 17:11:55.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 delete jobs e2e-test-nginx-job --namespace=kubectl-5865'
Oct  1 17:11:55.890: INFO: stderr: ""
Oct  1 17:11:55.890: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:11:55.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5865" for this suite.
Oct  1 17:12:01.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:12:02.417: INFO: namespace kubectl-5865 deletion completed in 6.513946221s

• [SLOW TEST:6.995 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:12:02.418: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3243
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1256
STEP: creating an rc
Oct  1 17:12:02.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 create -f - --namespace=kubectl-3243'
Oct  1 17:12:02.975: INFO: stderr: ""
Oct  1 17:12:02.975: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Oct  1 17:12:03.990: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 17:12:03.990: INFO: Found 0 / 1
Oct  1 17:12:04.990: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 17:12:04.990: INFO: Found 1 / 1
Oct  1 17:12:04.990: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct  1 17:12:05.004: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 17:12:05.004: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Oct  1 17:12:05.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 logs redis-master-xbvf6 redis-master --namespace=kubectl-3243'
Oct  1 17:12:05.182: INFO: stderr: ""
Oct  1 17:12:05.182: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Oct 17:12:04.188 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Oct 17:12:04.188 # Server started, Redis version 3.2.12\n1:M 01 Oct 17:12:04.188 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Oct 17:12:04.188 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Oct  1 17:12:05.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 log redis-master-xbvf6 redis-master --namespace=kubectl-3243 --tail=1'
Oct  1 17:12:05.371: INFO: stderr: ""
Oct  1 17:12:05.371: INFO: stdout: "1:M 01 Oct 17:12:04.188 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Oct  1 17:12:05.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 log redis-master-xbvf6 redis-master --namespace=kubectl-3243 --limit-bytes=1'
Oct  1 17:12:05.509: INFO: stderr: ""
Oct  1 17:12:05.509: INFO: stdout: " "
STEP: exposing timestamps
Oct  1 17:12:05.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 log redis-master-xbvf6 redis-master --namespace=kubectl-3243 --tail=1 --timestamps'
Oct  1 17:12:05.645: INFO: stderr: ""
Oct  1 17:12:05.645: INFO: stdout: "2019-10-01T17:12:04.188591317Z 1:M 01 Oct 17:12:04.188 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Oct  1 17:12:08.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 log redis-master-xbvf6 redis-master --namespace=kubectl-3243 --since=1s'
Oct  1 17:12:08.347: INFO: stderr: ""
Oct  1 17:12:08.348: INFO: stdout: ""
Oct  1 17:12:08.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 log redis-master-xbvf6 redis-master --namespace=kubectl-3243 --since=24h'
Oct  1 17:12:08.502: INFO: stderr: ""
Oct  1 17:12:08.502: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Oct 17:12:04.188 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Oct 17:12:04.188 # Server started, Redis version 3.2.12\n1:M 01 Oct 17:12:04.188 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Oct 17:12:04.188 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
STEP: using delete to clean up resources
Oct  1 17:12:08.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 delete --grace-period=0 --force -f - --namespace=kubectl-3243'
Oct  1 17:12:08.637: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 17:12:08.637: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Oct  1 17:12:08.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get rc,svc -l name=nginx --no-headers --namespace=kubectl-3243'
Oct  1 17:12:08.764: INFO: stderr: "No resources found.\n"
Oct  1 17:12:08.764: INFO: stdout: ""
Oct  1 17:12:08.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -l name=nginx --namespace=kubectl-3243 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  1 17:12:08.878: INFO: stderr: ""
Oct  1 17:12:08.878: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:12:08.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3243" for this suite.
Oct  1 17:12:32.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:12:33.242: INFO: namespace kubectl-3243 deletion completed in 24.350994672s

• [SLOW TEST:30.824 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:12:33.243: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4112
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct  1 17:12:36.074: INFO: Successfully updated pod "annotationupdatea86a96f4-e46e-11e9-afc1-6aca03636ae4"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:12:40.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4112" for this suite.
Oct  1 17:13:04.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:13:04.560: INFO: namespace downward-api-4112 deletion completed in 24.386215979s

• [SLOW TEST:31.317 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:13:04.560: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7435
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-bb160251-e46e-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume configMaps
Oct  1 17:13:04.835: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bb1898d3-e46e-11e9-afc1-6aca03636ae4" in namespace "projected-7435" to be "success or failure"
Oct  1 17:13:04.857: INFO: Pod "pod-projected-configmaps-bb1898d3-e46e-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 21.18731ms
Oct  1 17:13:06.873: INFO: Pod "pod-projected-configmaps-bb1898d3-e46e-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037490061s
STEP: Saw pod success
Oct  1 17:13:06.873: INFO: Pod "pod-projected-configmaps-bb1898d3-e46e-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:13:06.883: INFO: Trying to get logs from node 10.75.67.233 pod pod-projected-configmaps-bb1898d3-e46e-11e9-afc1-6aca03636ae4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 17:13:06.956: INFO: Waiting for pod pod-projected-configmaps-bb1898d3-e46e-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:13:06.973: INFO: Pod pod-projected-configmaps-bb1898d3-e46e-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:13:06.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7435" for this suite.
Oct  1 17:13:13.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:13:13.367: INFO: namespace projected-7435 deletion completed in 6.379186936s

• [SLOW TEST:8.807 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:13:13.368: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6308
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct  1 17:13:13.604: INFO: Waiting up to 5m0s for pod "pod-c0542223-e46e-11e9-afc1-6aca03636ae4" in namespace "emptydir-6308" to be "success or failure"
Oct  1 17:13:13.619: INFO: Pod "pod-c0542223-e46e-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.309075ms
Oct  1 17:13:15.630: INFO: Pod "pod-c0542223-e46e-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026008638s
Oct  1 17:13:17.641: INFO: Pod "pod-c0542223-e46e-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036233339s
STEP: Saw pod success
Oct  1 17:13:17.641: INFO: Pod "pod-c0542223-e46e-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:13:17.681: INFO: Trying to get logs from node 10.75.67.233 pod pod-c0542223-e46e-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 17:13:17.748: INFO: Waiting for pod pod-c0542223-e46e-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:13:17.762: INFO: Pod pod-c0542223-e46e-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:13:17.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6308" for this suite.
Oct  1 17:13:23.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:13:24.203: INFO: namespace emptydir-6308 deletion completed in 6.418012412s

• [SLOW TEST:10.834 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:13:24.203: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-6659
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 17:13:24.417: INFO: Creating ReplicaSet my-hostname-basic-c6ca13c7-e46e-11e9-afc1-6aca03636ae4
Oct  1 17:13:24.439: INFO: Pod name my-hostname-basic-c6ca13c7-e46e-11e9-afc1-6aca03636ae4: Found 0 pods out of 1
Oct  1 17:13:29.455: INFO: Pod name my-hostname-basic-c6ca13c7-e46e-11e9-afc1-6aca03636ae4: Found 1 pods out of 1
Oct  1 17:13:29.455: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-c6ca13c7-e46e-11e9-afc1-6aca03636ae4" is running
Oct  1 17:13:29.464: INFO: Pod "my-hostname-basic-c6ca13c7-e46e-11e9-afc1-6aca03636ae4-sm6zq" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-01 17:13:24 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-01 17:13:28 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-01 17:13:28 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-01 17:13:24 +0000 UTC Reason: Message:}])
Oct  1 17:13:29.464: INFO: Trying to dial the pod
Oct  1 17:13:34.511: INFO: Controller my-hostname-basic-c6ca13c7-e46e-11e9-afc1-6aca03636ae4: Got expected result from replica 1 [my-hostname-basic-c6ca13c7-e46e-11e9-afc1-6aca03636ae4-sm6zq]: "my-hostname-basic-c6ca13c7-e46e-11e9-afc1-6aca03636ae4-sm6zq", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:13:34.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6659" for this suite.
Oct  1 17:13:40.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:13:40.917: INFO: namespace replicaset-6659 deletion completed in 6.392872642s

• [SLOW TEST:16.714 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:13:40.917: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2382
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 17:13:41.148: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d0bfd173-e46e-11e9-afc1-6aca03636ae4" in namespace "downward-api-2382" to be "success or failure"
Oct  1 17:13:41.166: INFO: Pod "downwardapi-volume-d0bfd173-e46e-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.816846ms
Oct  1 17:13:43.177: INFO: Pod "downwardapi-volume-d0bfd173-e46e-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02899265s
STEP: Saw pod success
Oct  1 17:13:43.177: INFO: Pod "downwardapi-volume-d0bfd173-e46e-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:13:43.186: INFO: Trying to get logs from node 10.75.67.233 pod downwardapi-volume-d0bfd173-e46e-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 17:13:43.238: INFO: Waiting for pod downwardapi-volume-d0bfd173-e46e-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:13:43.253: INFO: Pod downwardapi-volume-d0bfd173-e46e-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:13:43.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2382" for this suite.
Oct  1 17:13:49.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:13:49.612: INFO: namespace downward-api-2382 deletion completed in 6.344695907s

• [SLOW TEST:8.695 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:13:49.612: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3927
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1649
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct  1 17:13:49.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3927'
Oct  1 17:13:49.939: INFO: stderr: ""
Oct  1 17:13:49.939: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1654
Oct  1 17:13:49.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 delete pods e2e-test-nginx-pod --namespace=kubectl-3927'
Oct  1 17:13:59.797: INFO: stderr: ""
Oct  1 17:13:59.797: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:13:59.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3927" for this suite.
Oct  1 17:14:05.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:14:06.248: INFO: namespace kubectl-3927 deletion completed in 6.438045043s

• [SLOW TEST:16.636 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:14:06.249: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7829
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Oct  1 17:14:06.494: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Oct  1 17:14:06.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 create -f - --namespace=kubectl-7829'
Oct  1 17:14:06.721: INFO: stderr: ""
Oct  1 17:14:06.721: INFO: stdout: "service/redis-slave created\n"
Oct  1 17:14:06.721: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Oct  1 17:14:06.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 create -f - --namespace=kubectl-7829'
Oct  1 17:14:07.030: INFO: stderr: ""
Oct  1 17:14:07.030: INFO: stdout: "service/redis-master created\n"
Oct  1 17:14:07.030: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct  1 17:14:07.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 create -f - --namespace=kubectl-7829'
Oct  1 17:14:07.237: INFO: stderr: ""
Oct  1 17:14:07.237: INFO: stdout: "service/frontend created\n"
Oct  1 17:14:07.237: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Oct  1 17:14:07.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 create -f - --namespace=kubectl-7829'
Oct  1 17:14:07.430: INFO: stderr: ""
Oct  1 17:14:07.430: INFO: stdout: "deployment.apps/frontend created\n"
Oct  1 17:14:07.430: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct  1 17:14:07.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 create -f - --namespace=kubectl-7829'
Oct  1 17:14:07.730: INFO: stderr: ""
Oct  1 17:14:07.730: INFO: stdout: "deployment.apps/redis-master created\n"
Oct  1 17:14:07.730: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Oct  1 17:14:07.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 create -f - --namespace=kubectl-7829'
Oct  1 17:14:08.018: INFO: stderr: ""
Oct  1 17:14:08.018: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Oct  1 17:14:08.018: INFO: Waiting for all frontend pods to be Running.
Oct  1 17:14:23.069: INFO: Waiting for frontend to serve content.
Oct  1 17:14:28.105: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Oct  1 17:14:33.142: INFO: Trying to add a new entry to the guestbook.
Oct  1 17:14:33.179: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Oct  1 17:14:33.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 delete --grace-period=0 --force -f - --namespace=kubectl-7829'
Oct  1 17:14:33.373: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 17:14:33.373: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Oct  1 17:14:33.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 delete --grace-period=0 --force -f - --namespace=kubectl-7829'
Oct  1 17:14:33.539: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 17:14:33.539: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct  1 17:14:33.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 delete --grace-period=0 --force -f - --namespace=kubectl-7829'
Oct  1 17:14:33.691: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 17:14:33.691: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct  1 17:14:33.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 delete --grace-period=0 --force -f - --namespace=kubectl-7829'
Oct  1 17:14:33.832: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 17:14:33.832: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct  1 17:14:33.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 delete --grace-period=0 --force -f - --namespace=kubectl-7829'
Oct  1 17:14:33.981: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 17:14:33.981: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct  1 17:14:33.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 delete --grace-period=0 --force -f - --namespace=kubectl-7829'
Oct  1 17:14:34.166: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 17:14:34.166: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:14:34.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7829" for this suite.
Oct  1 17:15:14.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:15:14.601: INFO: namespace kubectl-7829 deletion completed in 40.422044044s

• [SLOW TEST:68.352 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:15:14.603: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1728
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Oct  1 17:15:14.817: INFO: namespace kubectl-1728
Oct  1 17:15:14.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 create -f - --namespace=kubectl-1728'
Oct  1 17:15:15.042: INFO: stderr: ""
Oct  1 17:15:15.042: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct  1 17:15:16.051: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 17:15:16.051: INFO: Found 0 / 1
Oct  1 17:15:17.051: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 17:15:17.051: INFO: Found 0 / 1
Oct  1 17:15:18.051: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 17:15:18.051: INFO: Found 1 / 1
Oct  1 17:15:18.051: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct  1 17:15:18.062: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 17:15:18.063: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct  1 17:15:18.063: INFO: wait on redis-master startup in kubectl-1728 
Oct  1 17:15:18.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 logs redis-master-6wvdv redis-master --namespace=kubectl-1728'
Oct  1 17:15:18.201: INFO: stderr: ""
Oct  1 17:15:18.201: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Oct 17:15:16.333 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Oct 17:15:16.333 # Server started, Redis version 3.2.12\n1:M 01 Oct 17:15:16.333 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Oct 17:15:16.333 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Oct  1 17:15:18.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-1728'
Oct  1 17:15:18.368: INFO: stderr: ""
Oct  1 17:15:18.368: INFO: stdout: "service/rm2 exposed\n"
Oct  1 17:15:18.383: INFO: Service rm2 in namespace kubectl-1728 found.
STEP: exposing service
Oct  1 17:15:20.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-1728'
Oct  1 17:15:20.543: INFO: stderr: ""
Oct  1 17:15:20.543: INFO: stdout: "service/rm3 exposed\n"
Oct  1 17:15:20.550: INFO: Service rm3 in namespace kubectl-1728 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:15:22.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1728" for this suite.
Oct  1 17:15:46.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:15:46.913: INFO: namespace kubectl-1728 deletion completed in 24.330733987s

• [SLOW TEST:32.310 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:15:46.913: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9880
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9880
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-9880
STEP: Creating statefulset with conflicting port in namespace statefulset-9880
STEP: Waiting until pod test-pod will start running in namespace statefulset-9880
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9880
Oct  1 17:15:49.216: INFO: Observed stateful pod in namespace: statefulset-9880, name: ss-0, uid: 1ce99b46-e46f-11e9-865f-ced8df5791d3, status phase: Pending. Waiting for statefulset controller to delete.
Oct  1 17:15:58.798: INFO: Observed stateful pod in namespace: statefulset-9880, name: ss-0, uid: 1ce99b46-e46f-11e9-865f-ced8df5791d3, status phase: Failed. Waiting for statefulset controller to delete.
Oct  1 17:15:58.818: INFO: Observed stateful pod in namespace: statefulset-9880, name: ss-0, uid: 1ce99b46-e46f-11e9-865f-ced8df5791d3, status phase: Failed. Waiting for statefulset controller to delete.
Oct  1 17:15:58.831: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9880
STEP: Removing pod with conflicting port in namespace statefulset-9880
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9880 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct  1 17:16:02.912: INFO: Deleting all statefulset in ns statefulset-9880
Oct  1 17:16:02.922: INFO: Scaling statefulset ss to 0
Oct  1 17:16:13.273: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 17:16:13.288: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:16:13.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9880" for this suite.
Oct  1 17:16:21.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:16:21.803: INFO: namespace statefulset-9880 deletion completed in 8.454067621s

• [SLOW TEST:34.891 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:16:21.805: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7846
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-7846/configmap-test-30a695da-e46f-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume configMaps
Oct  1 17:16:22.055: INFO: Waiting up to 5m0s for pod "pod-configmaps-30a842a7-e46f-11e9-afc1-6aca03636ae4" in namespace "configmap-7846" to be "success or failure"
Oct  1 17:16:22.071: INFO: Pod "pod-configmaps-30a842a7-e46f-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.437563ms
Oct  1 17:16:24.082: INFO: Pod "pod-configmaps-30a842a7-e46f-11e9-afc1-6aca03636ae4": Phase="Running", Reason="", readiness=true. Elapsed: 2.027865142s
Oct  1 17:16:26.095: INFO: Pod "pod-configmaps-30a842a7-e46f-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040563283s
STEP: Saw pod success
Oct  1 17:16:26.095: INFO: Pod "pod-configmaps-30a842a7-e46f-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:16:26.106: INFO: Trying to get logs from node 10.75.67.242 pod pod-configmaps-30a842a7-e46f-11e9-afc1-6aca03636ae4 container env-test: <nil>
STEP: delete the pod
Oct  1 17:16:26.175: INFO: Waiting for pod pod-configmaps-30a842a7-e46f-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:16:26.183: INFO: Pod pod-configmaps-30a842a7-e46f-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:16:26.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7846" for this suite.
Oct  1 17:16:32.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:16:32.599: INFO: namespace configmap-7846 deletion completed in 6.3992575s

• [SLOW TEST:10.794 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:16:32.599: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4824
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 17:16:32.885: INFO: Waiting up to 5m0s for pod "downwardapi-volume-371c65f6-e46f-11e9-afc1-6aca03636ae4" in namespace "projected-4824" to be "success or failure"
Oct  1 17:16:32.900: INFO: Pod "downwardapi-volume-371c65f6-e46f-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.967971ms
Oct  1 17:16:34.913: INFO: Pod "downwardapi-volume-371c65f6-e46f-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028185796s
STEP: Saw pod success
Oct  1 17:16:34.913: INFO: Pod "downwardapi-volume-371c65f6-e46f-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:16:34.927: INFO: Trying to get logs from node 10.75.67.233 pod downwardapi-volume-371c65f6-e46f-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 17:16:35.078: INFO: Waiting for pod downwardapi-volume-371c65f6-e46f-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:16:35.091: INFO: Pod downwardapi-volume-371c65f6-e46f-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:16:35.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4824" for this suite.
Oct  1 17:16:41.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:16:41.436: INFO: namespace projected-4824 deletion completed in 6.333176915s

• [SLOW TEST:8.838 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:16:41.437: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9957
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-9957
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct  1 17:16:41.651: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct  1 17:17:09.964: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.31.16 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9957 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:17:09.964: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:17:11.176: INFO: Found all expected endpoints: [netserver-0]
Oct  1 17:17:11.187: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.248.13 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9957 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:17:11.187: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:17:12.414: INFO: Found all expected endpoints: [netserver-1]
Oct  1 17:17:12.429: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.58.88 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9957 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:17:12.429: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:17:13.643: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:17:13.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9957" for this suite.
Oct  1 17:17:37.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:17:38.033: INFO: namespace pod-network-test-9957 deletion completed in 24.377650805s

• [SLOW TEST:56.596 seconds]
[sig-network] Networking
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:17:38.033: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5858
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:18:38.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5858" for this suite.
Oct  1 17:19:06.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:19:07.075: INFO: namespace container-probe-5858 deletion completed in 28.780067165s

• [SLOW TEST:89.041 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:19:07.076: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1775
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct  1 17:19:11.897: INFO: Successfully updated pod "labelsupdate932885ac-e46f-11e9-afc1-6aca03636ae4"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:19:13.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1775" for this suite.
Oct  1 17:19:38.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:19:38.439: INFO: namespace projected-1775 deletion completed in 24.419781646s

• [SLOW TEST:31.364 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:19:38.440: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9613
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 17:19:38.975: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a6079e41-e46f-11e9-afc1-6aca03636ae4" in namespace "projected-9613" to be "success or failure"
Oct  1 17:19:38.991: INFO: Pod "downwardapi-volume-a6079e41-e46f-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.989175ms
Oct  1 17:19:41.002: INFO: Pod "downwardapi-volume-a6079e41-e46f-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027186652s
STEP: Saw pod success
Oct  1 17:19:41.002: INFO: Pod "downwardapi-volume-a6079e41-e46f-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:19:41.036: INFO: Trying to get logs from node 10.75.67.242 pod downwardapi-volume-a6079e41-e46f-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 17:19:41.102: INFO: Waiting for pod downwardapi-volume-a6079e41-e46f-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:19:41.111: INFO: Pod downwardapi-volume-a6079e41-e46f-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:19:41.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9613" for this suite.
Oct  1 17:19:47.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:19:47.470: INFO: namespace projected-9613 deletion completed in 6.347692595s

• [SLOW TEST:9.031 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:19:47.471: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4577
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Oct  1 17:19:47.716: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-4577,SelfLink:/api/v1/namespaces/watch-4577/configmaps/e2e-watch-test-watch-closed,UID:ab3c487e-e46f-11e9-bf88-8e83bb394576,ResourceVersion:32245,Generation:0,CreationTimestamp:2019-10-01 17:19:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  1 17:19:47.716: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-4577,SelfLink:/api/v1/namespaces/watch-4577/configmaps/e2e-watch-test-watch-closed,UID:ab3c487e-e46f-11e9-bf88-8e83bb394576,ResourceVersion:32246,Generation:0,CreationTimestamp:2019-10-01 17:19:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Oct  1 17:19:47.763: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-4577,SelfLink:/api/v1/namespaces/watch-4577/configmaps/e2e-watch-test-watch-closed,UID:ab3c487e-e46f-11e9-bf88-8e83bb394576,ResourceVersion:32247,Generation:0,CreationTimestamp:2019-10-01 17:19:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  1 17:19:47.763: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-4577,SelfLink:/api/v1/namespaces/watch-4577/configmaps/e2e-watch-test-watch-closed,UID:ab3c487e-e46f-11e9-bf88-8e83bb394576,ResourceVersion:32248,Generation:0,CreationTimestamp:2019-10-01 17:19:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:19:47.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4577" for this suite.
Oct  1 17:19:53.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:19:54.183: INFO: namespace watch-4577 deletion completed in 6.403690315s

• [SLOW TEST:6.713 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:19:54.185: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5650
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-77sf
STEP: Creating a pod to test atomic-volume-subpath
Oct  1 17:19:54.438: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-77sf" in namespace "subpath-5650" to be "success or failure"
Oct  1 17:19:54.451: INFO: Pod "pod-subpath-test-configmap-77sf": Phase="Pending", Reason="", readiness=false. Elapsed: 12.931035ms
Oct  1 17:19:56.466: INFO: Pod "pod-subpath-test-configmap-77sf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027530875s
Oct  1 17:19:58.477: INFO: Pod "pod-subpath-test-configmap-77sf": Phase="Running", Reason="", readiness=true. Elapsed: 4.038855109s
Oct  1 17:20:00.489: INFO: Pod "pod-subpath-test-configmap-77sf": Phase="Running", Reason="", readiness=true. Elapsed: 6.050495578s
Oct  1 17:20:02.500: INFO: Pod "pod-subpath-test-configmap-77sf": Phase="Running", Reason="", readiness=true. Elapsed: 8.061435089s
Oct  1 17:20:04.509: INFO: Pod "pod-subpath-test-configmap-77sf": Phase="Running", Reason="", readiness=true. Elapsed: 10.071253263s
Oct  1 17:20:06.521: INFO: Pod "pod-subpath-test-configmap-77sf": Phase="Running", Reason="", readiness=true. Elapsed: 12.082901929s
Oct  1 17:20:08.532: INFO: Pod "pod-subpath-test-configmap-77sf": Phase="Running", Reason="", readiness=true. Elapsed: 14.094069039s
Oct  1 17:20:10.550: INFO: Pod "pod-subpath-test-configmap-77sf": Phase="Running", Reason="", readiness=true. Elapsed: 16.111593731s
Oct  1 17:20:12.568: INFO: Pod "pod-subpath-test-configmap-77sf": Phase="Running", Reason="", readiness=true. Elapsed: 18.129634042s
Oct  1 17:20:14.582: INFO: Pod "pod-subpath-test-configmap-77sf": Phase="Running", Reason="", readiness=true. Elapsed: 20.143854253s
Oct  1 17:20:16.594: INFO: Pod "pod-subpath-test-configmap-77sf": Phase="Running", Reason="", readiness=true. Elapsed: 22.155448157s
Oct  1 17:20:18.604: INFO: Pod "pod-subpath-test-configmap-77sf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.165575451s
STEP: Saw pod success
Oct  1 17:20:18.604: INFO: Pod "pod-subpath-test-configmap-77sf" satisfied condition "success or failure"
Oct  1 17:20:18.614: INFO: Trying to get logs from node 10.75.67.233 pod pod-subpath-test-configmap-77sf container test-container-subpath-configmap-77sf: <nil>
STEP: delete the pod
Oct  1 17:20:18.677: INFO: Waiting for pod pod-subpath-test-configmap-77sf to disappear
Oct  1 17:20:18.687: INFO: Pod pod-subpath-test-configmap-77sf no longer exists
STEP: Deleting pod pod-subpath-test-configmap-77sf
Oct  1 17:20:18.687: INFO: Deleting pod "pod-subpath-test-configmap-77sf" in namespace "subpath-5650"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:20:18.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5650" for this suite.
Oct  1 17:20:24.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:20:25.105: INFO: namespace subpath-5650 deletion completed in 6.393310801s

• [SLOW TEST:30.921 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:20:25.108: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5866
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-c1ad2bff-e46f-11e9-afc1-6aca03636ae4
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-c1ad2bff-e46f-11e9-afc1-6aca03636ae4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:21:44.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5866" for this suite.
Oct  1 17:22:08.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:22:09.017: INFO: namespace configmap-5866 deletion completed in 24.482497838s

• [SLOW TEST:103.909 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:22:09.018: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4573
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:22:11.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4573" for this suite.
Oct  1 17:22:51.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:22:51.749: INFO: namespace kubelet-test-4573 deletion completed in 40.395516705s

• [SLOW TEST:42.732 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:22:51.750: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-9874
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-9874
I1001 17:22:51.979204      17 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-9874, replica count: 1
I1001 17:22:53.029788      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1001 17:22:54.030006      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  1 17:22:54.159: INFO: Created: latency-svc-bqzkp
Oct  1 17:22:54.167: INFO: Got endpoints: latency-svc-bqzkp [36.890756ms]
Oct  1 17:22:54.194: INFO: Created: latency-svc-jd7t2
Oct  1 17:22:54.205: INFO: Got endpoints: latency-svc-jd7t2 [37.914238ms]
Oct  1 17:22:54.209: INFO: Created: latency-svc-jmw6w
Oct  1 17:22:54.222: INFO: Got endpoints: latency-svc-jmw6w [55.398ms]
Oct  1 17:22:54.227: INFO: Created: latency-svc-gbz29
Oct  1 17:22:54.237: INFO: Got endpoints: latency-svc-gbz29 [69.992176ms]
Oct  1 17:22:54.248: INFO: Created: latency-svc-pcvhm
Oct  1 17:22:54.257: INFO: Got endpoints: latency-svc-pcvhm [89.855738ms]
Oct  1 17:22:54.262: INFO: Created: latency-svc-rmqxb
Oct  1 17:22:54.272: INFO: Got endpoints: latency-svc-rmqxb [104.738205ms]
Oct  1 17:22:54.276: INFO: Created: latency-svc-mlpgc
Oct  1 17:22:54.285: INFO: Got endpoints: latency-svc-mlpgc [118.392177ms]
Oct  1 17:22:54.294: INFO: Created: latency-svc-r2qpz
Oct  1 17:22:54.306: INFO: Got endpoints: latency-svc-r2qpz [138.681141ms]
Oct  1 17:22:54.308: INFO: Created: latency-svc-xm4sb
Oct  1 17:22:54.320: INFO: Got endpoints: latency-svc-xm4sb [152.864474ms]
Oct  1 17:22:54.331: INFO: Created: latency-svc-fzkkc
Oct  1 17:22:54.338: INFO: Got endpoints: latency-svc-fzkkc [170.918242ms]
Oct  1 17:22:54.342: INFO: Created: latency-svc-qkkld
Oct  1 17:22:54.354: INFO: Got endpoints: latency-svc-qkkld [186.79716ms]
Oct  1 17:22:54.356: INFO: Created: latency-svc-646s2
Oct  1 17:22:54.366: INFO: Got endpoints: latency-svc-646s2 [198.891907ms]
Oct  1 17:22:54.379: INFO: Created: latency-svc-xzxnl
Oct  1 17:22:54.387: INFO: Got endpoints: latency-svc-xzxnl [220.515443ms]
Oct  1 17:22:54.390: INFO: Created: latency-svc-k4m4s
Oct  1 17:22:54.400: INFO: Got endpoints: latency-svc-k4m4s [233.136377ms]
Oct  1 17:22:54.407: INFO: Created: latency-svc-xs26d
Oct  1 17:22:54.416: INFO: Got endpoints: latency-svc-xs26d [248.71093ms]
Oct  1 17:22:54.419: INFO: Created: latency-svc-tb7hw
Oct  1 17:22:54.433: INFO: Got endpoints: latency-svc-tb7hw [265.792886ms]
Oct  1 17:22:54.434: INFO: Created: latency-svc-4vqbb
Oct  1 17:22:54.443: INFO: Got endpoints: latency-svc-4vqbb [238.832871ms]
Oct  1 17:22:54.447: INFO: Created: latency-svc-mmqfn
Oct  1 17:22:54.457: INFO: Got endpoints: latency-svc-mmqfn [234.45864ms]
Oct  1 17:22:54.468: INFO: Created: latency-svc-d8frl
Oct  1 17:22:54.490: INFO: Created: latency-svc-ftpjh
Oct  1 17:22:54.490: INFO: Got endpoints: latency-svc-d8frl [253.24072ms]
Oct  1 17:22:54.504: INFO: Got endpoints: latency-svc-ftpjh [246.792624ms]
Oct  1 17:22:54.505: INFO: Created: latency-svc-mvt7r
Oct  1 17:22:54.522: INFO: Got endpoints: latency-svc-mvt7r [250.284206ms]
Oct  1 17:22:54.526: INFO: Created: latency-svc-thwpg
Oct  1 17:22:54.536: INFO: Got endpoints: latency-svc-thwpg [250.925672ms]
Oct  1 17:22:54.544: INFO: Created: latency-svc-xldgw
Oct  1 17:22:54.558: INFO: Got endpoints: latency-svc-xldgw [251.752687ms]
Oct  1 17:22:54.563: INFO: Created: latency-svc-tsd9h
Oct  1 17:22:54.580: INFO: Got endpoints: latency-svc-tsd9h [260.000408ms]
Oct  1 17:22:54.585: INFO: Created: latency-svc-79r2m
Oct  1 17:22:54.595: INFO: Got endpoints: latency-svc-79r2m [257.169303ms]
Oct  1 17:22:54.605: INFO: Created: latency-svc-6bmfz
Oct  1 17:22:54.616: INFO: Got endpoints: latency-svc-6bmfz [262.343273ms]
Oct  1 17:22:54.628: INFO: Created: latency-svc-h868n
Oct  1 17:22:54.636: INFO: Got endpoints: latency-svc-h868n [269.475841ms]
Oct  1 17:22:54.647: INFO: Created: latency-svc-5mqht
Oct  1 17:22:54.658: INFO: Got endpoints: latency-svc-5mqht [270.830258ms]
Oct  1 17:22:54.661: INFO: Created: latency-svc-ftzt9
Oct  1 17:22:54.670: INFO: Got endpoints: latency-svc-ftzt9 [269.629786ms]
Oct  1 17:22:54.681: INFO: Created: latency-svc-8k22f
Oct  1 17:22:54.692: INFO: Got endpoints: latency-svc-8k22f [276.066015ms]
Oct  1 17:22:54.698: INFO: Created: latency-svc-sc7sp
Oct  1 17:22:54.706: INFO: Got endpoints: latency-svc-sc7sp [272.989399ms]
Oct  1 17:22:54.712: INFO: Created: latency-svc-hdpmb
Oct  1 17:22:54.721: INFO: Got endpoints: latency-svc-hdpmb [277.619899ms]
Oct  1 17:22:54.730: INFO: Created: latency-svc-q659n
Oct  1 17:22:54.740: INFO: Got endpoints: latency-svc-q659n [282.720461ms]
Oct  1 17:22:54.743: INFO: Created: latency-svc-rxpxz
Oct  1 17:22:54.753: INFO: Got endpoints: latency-svc-rxpxz [262.553582ms]
Oct  1 17:22:54.771: INFO: Created: latency-svc-qsshv
Oct  1 17:22:54.780: INFO: Got endpoints: latency-svc-qsshv [276.307664ms]
Oct  1 17:22:54.793: INFO: Created: latency-svc-fh899
Oct  1 17:22:54.803: INFO: Got endpoints: latency-svc-fh899 [281.13689ms]
Oct  1 17:22:54.822: INFO: Created: latency-svc-7pq5g
Oct  1 17:22:54.849: INFO: Got endpoints: latency-svc-7pq5g [312.558106ms]
Oct  1 17:22:55.133: INFO: Created: latency-svc-l4rmb
Oct  1 17:22:55.148: INFO: Got endpoints: latency-svc-l4rmb [590.747062ms]
Oct  1 17:22:55.150: INFO: Created: latency-svc-q7tt2
Oct  1 17:22:55.155: INFO: Got endpoints: latency-svc-q7tt2 [575.236492ms]
Oct  1 17:22:55.175: INFO: Created: latency-svc-fdgbf
Oct  1 17:22:55.190: INFO: Got endpoints: latency-svc-fdgbf [595.21684ms]
Oct  1 17:22:55.211: INFO: Created: latency-svc-84f4r
Oct  1 17:22:55.226: INFO: Got endpoints: latency-svc-84f4r [609.43969ms]
Oct  1 17:22:55.236: INFO: Created: latency-svc-8b8df
Oct  1 17:22:55.252: INFO: Got endpoints: latency-svc-8b8df [616.527004ms]
Oct  1 17:22:55.256: INFO: Created: latency-svc-w4bgp
Oct  1 17:22:55.264: INFO: Got endpoints: latency-svc-w4bgp [605.553777ms]
Oct  1 17:22:55.269: INFO: Created: latency-svc-sg4jr
Oct  1 17:22:55.287: INFO: Got endpoints: latency-svc-sg4jr [616.61187ms]
Oct  1 17:22:55.291: INFO: Created: latency-svc-t6pxv
Oct  1 17:22:55.304: INFO: Got endpoints: latency-svc-t6pxv [611.444123ms]
Oct  1 17:22:55.309: INFO: Created: latency-svc-mnrfq
Oct  1 17:22:55.319: INFO: Got endpoints: latency-svc-mnrfq [612.958322ms]
Oct  1 17:22:55.327: INFO: Created: latency-svc-w96mz
Oct  1 17:22:55.332: INFO: Got endpoints: latency-svc-w96mz [610.949342ms]
Oct  1 17:22:55.339: INFO: Created: latency-svc-7lc2d
Oct  1 17:22:55.348: INFO: Got endpoints: latency-svc-7lc2d [608.793576ms]
Oct  1 17:22:55.353: INFO: Created: latency-svc-vmk7q
Oct  1 17:22:55.374: INFO: Got endpoints: latency-svc-vmk7q [621.072187ms]
Oct  1 17:22:55.393: INFO: Created: latency-svc-jjnnc
Oct  1 17:22:55.403: INFO: Got endpoints: latency-svc-jjnnc [623.221772ms]
Oct  1 17:22:55.408: INFO: Created: latency-svc-49lzv
Oct  1 17:22:55.418: INFO: Got endpoints: latency-svc-49lzv [614.191291ms]
Oct  1 17:22:55.424: INFO: Created: latency-svc-skrdz
Oct  1 17:22:55.432: INFO: Got endpoints: latency-svc-skrdz [582.676246ms]
Oct  1 17:22:55.440: INFO: Created: latency-svc-49rwt
Oct  1 17:22:55.451: INFO: Got endpoints: latency-svc-49rwt [302.953155ms]
Oct  1 17:22:55.457: INFO: Created: latency-svc-s7nft
Oct  1 17:22:55.466: INFO: Got endpoints: latency-svc-s7nft [311.363138ms]
Oct  1 17:22:55.484: INFO: Created: latency-svc-vhqvr
Oct  1 17:22:55.499: INFO: Got endpoints: latency-svc-vhqvr [308.91627ms]
Oct  1 17:22:55.508: INFO: Created: latency-svc-hwr9k
Oct  1 17:22:55.521: INFO: Got endpoints: latency-svc-hwr9k [294.826611ms]
Oct  1 17:22:55.530: INFO: Created: latency-svc-m2rwn
Oct  1 17:22:55.536: INFO: Got endpoints: latency-svc-m2rwn [283.873026ms]
Oct  1 17:22:55.548: INFO: Created: latency-svc-fq75p
Oct  1 17:22:55.565: INFO: Got endpoints: latency-svc-fq75p [300.938697ms]
Oct  1 17:22:55.573: INFO: Created: latency-svc-j9ncx
Oct  1 17:22:55.587: INFO: Got endpoints: latency-svc-j9ncx [300.22316ms]
Oct  1 17:22:55.594: INFO: Created: latency-svc-nnn5f
Oct  1 17:22:55.604: INFO: Got endpoints: latency-svc-nnn5f [300.316024ms]
Oct  1 17:22:55.607: INFO: Created: latency-svc-4w5gv
Oct  1 17:22:55.621: INFO: Got endpoints: latency-svc-4w5gv [302.06757ms]
Oct  1 17:22:55.626: INFO: Created: latency-svc-fnwb9
Oct  1 17:22:55.640: INFO: Got endpoints: latency-svc-fnwb9 [307.777932ms]
Oct  1 17:22:55.644: INFO: Created: latency-svc-tm7h7
Oct  1 17:22:55.656: INFO: Got endpoints: latency-svc-tm7h7 [307.106022ms]
Oct  1 17:22:55.661: INFO: Created: latency-svc-mtb62
Oct  1 17:22:55.672: INFO: Got endpoints: latency-svc-mtb62 [297.692175ms]
Oct  1 17:22:55.681: INFO: Created: latency-svc-lp575
Oct  1 17:22:55.686: INFO: Got endpoints: latency-svc-lp575 [282.851077ms]
Oct  1 17:22:55.695: INFO: Created: latency-svc-xtdwg
Oct  1 17:22:55.704: INFO: Got endpoints: latency-svc-xtdwg [286.339408ms]
Oct  1 17:22:55.708: INFO: Created: latency-svc-lcspz
Oct  1 17:22:55.717: INFO: Got endpoints: latency-svc-lcspz [285.061498ms]
Oct  1 17:22:55.725: INFO: Created: latency-svc-zqmcp
Oct  1 17:22:55.732: INFO: Got endpoints: latency-svc-zqmcp [280.984141ms]
Oct  1 17:22:55.737: INFO: Created: latency-svc-gnz4m
Oct  1 17:22:55.748: INFO: Got endpoints: latency-svc-gnz4m [281.851159ms]
Oct  1 17:22:55.763: INFO: Created: latency-svc-m5w5q
Oct  1 17:22:55.777: INFO: Got endpoints: latency-svc-m5w5q [277.027441ms]
Oct  1 17:22:55.784: INFO: Created: latency-svc-pln4n
Oct  1 17:22:55.794: INFO: Got endpoints: latency-svc-pln4n [273.685322ms]
Oct  1 17:22:55.802: INFO: Created: latency-svc-8k6bh
Oct  1 17:22:55.813: INFO: Got endpoints: latency-svc-8k6bh [276.558984ms]
Oct  1 17:22:55.817: INFO: Created: latency-svc-2rd92
Oct  1 17:22:55.832: INFO: Got endpoints: latency-svc-2rd92 [267.007072ms]
Oct  1 17:22:55.840: INFO: Created: latency-svc-gvw6z
Oct  1 17:22:55.850: INFO: Got endpoints: latency-svc-gvw6z [262.473417ms]
Oct  1 17:22:55.861: INFO: Created: latency-svc-x2wzl
Oct  1 17:22:55.866: INFO: Got endpoints: latency-svc-x2wzl [262.383714ms]
Oct  1 17:22:55.871: INFO: Created: latency-svc-psfqw
Oct  1 17:22:55.880: INFO: Got endpoints: latency-svc-psfqw [258.914942ms]
Oct  1 17:22:55.885: INFO: Created: latency-svc-gh8kq
Oct  1 17:22:55.896: INFO: Got endpoints: latency-svc-gh8kq [256.007939ms]
Oct  1 17:22:55.901: INFO: Created: latency-svc-cdqcd
Oct  1 17:22:55.911: INFO: Got endpoints: latency-svc-cdqcd [255.602385ms]
Oct  1 17:22:55.916: INFO: Created: latency-svc-qwf8h
Oct  1 17:22:55.930: INFO: Got endpoints: latency-svc-qwf8h [258.333311ms]
Oct  1 17:22:55.936: INFO: Created: latency-svc-dm2h9
Oct  1 17:22:55.945: INFO: Got endpoints: latency-svc-dm2h9 [257.968545ms]
Oct  1 17:22:55.954: INFO: Created: latency-svc-bm4fx
Oct  1 17:22:55.975: INFO: Got endpoints: latency-svc-bm4fx [270.87545ms]
Oct  1 17:22:55.981: INFO: Created: latency-svc-jjtt6
Oct  1 17:22:55.998: INFO: Got endpoints: latency-svc-jjtt6 [281.054326ms]
Oct  1 17:22:56.005: INFO: Created: latency-svc-pf2sz
Oct  1 17:22:56.012: INFO: Got endpoints: latency-svc-pf2sz [279.55165ms]
Oct  1 17:22:56.022: INFO: Created: latency-svc-tl4q8
Oct  1 17:22:56.034: INFO: Got endpoints: latency-svc-tl4q8 [286.170783ms]
Oct  1 17:22:56.039: INFO: Created: latency-svc-rzpl6
Oct  1 17:22:56.059: INFO: Created: latency-svc-h44rb
Oct  1 17:22:56.059: INFO: Got endpoints: latency-svc-rzpl6 [282.257489ms]
Oct  1 17:22:56.065: INFO: Got endpoints: latency-svc-h44rb [270.195296ms]
Oct  1 17:22:56.073: INFO: Created: latency-svc-pblfd
Oct  1 17:22:56.080: INFO: Got endpoints: latency-svc-pblfd [267.202757ms]
Oct  1 17:22:56.084: INFO: Created: latency-svc-hm6b7
Oct  1 17:22:56.095: INFO: Got endpoints: latency-svc-hm6b7 [262.459105ms]
Oct  1 17:22:56.101: INFO: Created: latency-svc-f5mb8
Oct  1 17:22:56.109: INFO: Got endpoints: latency-svc-f5mb8 [259.526939ms]
Oct  1 17:22:56.113: INFO: Created: latency-svc-vdjcr
Oct  1 17:22:56.124: INFO: Got endpoints: latency-svc-vdjcr [257.819259ms]
Oct  1 17:22:56.131: INFO: Created: latency-svc-tfkm5
Oct  1 17:22:56.144: INFO: Got endpoints: latency-svc-tfkm5 [263.331711ms]
Oct  1 17:22:56.153: INFO: Created: latency-svc-2rlwr
Oct  1 17:22:56.160: INFO: Got endpoints: latency-svc-2rlwr [263.590305ms]
Oct  1 17:22:56.167: INFO: Created: latency-svc-ll2kf
Oct  1 17:22:56.177: INFO: Got endpoints: latency-svc-ll2kf [265.698698ms]
Oct  1 17:22:56.188: INFO: Created: latency-svc-gfxs8
Oct  1 17:22:56.195: INFO: Got endpoints: latency-svc-gfxs8 [264.565454ms]
Oct  1 17:22:56.200: INFO: Created: latency-svc-9b4p7
Oct  1 17:22:56.209: INFO: Got endpoints: latency-svc-9b4p7 [264.705953ms]
Oct  1 17:22:56.214: INFO: Created: latency-svc-rfnck
Oct  1 17:22:56.225: INFO: Got endpoints: latency-svc-rfnck [249.739892ms]
Oct  1 17:22:56.229: INFO: Created: latency-svc-lp847
Oct  1 17:22:56.254: INFO: Created: latency-svc-csmj9
Oct  1 17:22:56.255: INFO: Got endpoints: latency-svc-lp847 [256.595575ms]
Oct  1 17:22:56.257: INFO: Got endpoints: latency-svc-csmj9 [245.131129ms]
Oct  1 17:22:56.263: INFO: Created: latency-svc-t5v8p
Oct  1 17:22:56.276: INFO: Got endpoints: latency-svc-t5v8p [241.368245ms]
Oct  1 17:22:56.285: INFO: Created: latency-svc-mqrtf
Oct  1 17:22:56.298: INFO: Got endpoints: latency-svc-mqrtf [43.485158ms]
Oct  1 17:22:56.314: INFO: Created: latency-svc-dq8p7
Oct  1 17:22:56.321: INFO: Got endpoints: latency-svc-dq8p7 [261.421159ms]
Oct  1 17:22:56.326: INFO: Created: latency-svc-922cf
Oct  1 17:22:56.337: INFO: Got endpoints: latency-svc-922cf [272.55919ms]
Oct  1 17:22:56.342: INFO: Created: latency-svc-zj8nb
Oct  1 17:22:56.353: INFO: Got endpoints: latency-svc-zj8nb [272.848706ms]
Oct  1 17:22:56.358: INFO: Created: latency-svc-wl6lx
Oct  1 17:22:56.370: INFO: Got endpoints: latency-svc-wl6lx [275.468487ms]
Oct  1 17:22:56.378: INFO: Created: latency-svc-6vnr8
Oct  1 17:22:56.387: INFO: Got endpoints: latency-svc-6vnr8 [278.130747ms]
Oct  1 17:22:56.395: INFO: Created: latency-svc-bh2jk
Oct  1 17:22:56.409: INFO: Created: latency-svc-4hf29
Oct  1 17:22:56.409: INFO: Got endpoints: latency-svc-bh2jk [284.987783ms]
Oct  1 17:22:56.417: INFO: Got endpoints: latency-svc-4hf29 [257.552637ms]
Oct  1 17:22:56.434: INFO: Created: latency-svc-ts6gk
Oct  1 17:22:56.435: INFO: Got endpoints: latency-svc-ts6gk [290.97174ms]
Oct  1 17:22:56.441: INFO: Created: latency-svc-9jts9
Oct  1 17:22:56.451: INFO: Got endpoints: latency-svc-9jts9 [273.315429ms]
Oct  1 17:22:56.458: INFO: Created: latency-svc-nkp88
Oct  1 17:22:56.468: INFO: Got endpoints: latency-svc-nkp88 [273.06829ms]
Oct  1 17:22:56.474: INFO: Created: latency-svc-pzfqk
Oct  1 17:22:56.487: INFO: Got endpoints: latency-svc-pzfqk [277.987782ms]
Oct  1 17:22:56.489: INFO: Created: latency-svc-fvdq7
Oct  1 17:22:56.498: INFO: Got endpoints: latency-svc-fvdq7 [273.568863ms]
Oct  1 17:22:56.502: INFO: Created: latency-svc-jtvlf
Oct  1 17:22:56.511: INFO: Got endpoints: latency-svc-jtvlf [253.157456ms]
Oct  1 17:22:56.520: INFO: Created: latency-svc-rdz4l
Oct  1 17:22:56.533: INFO: Got endpoints: latency-svc-rdz4l [256.709188ms]
Oct  1 17:22:56.536: INFO: Created: latency-svc-4jzcm
Oct  1 17:22:56.546: INFO: Got endpoints: latency-svc-4jzcm [248.114047ms]
Oct  1 17:22:56.552: INFO: Created: latency-svc-7nwgj
Oct  1 17:22:56.560: INFO: Got endpoints: latency-svc-7nwgj [239.029936ms]
Oct  1 17:22:56.564: INFO: Created: latency-svc-p52jm
Oct  1 17:22:56.569: INFO: Got endpoints: latency-svc-p52jm [232.019537ms]
Oct  1 17:22:56.575: INFO: Created: latency-svc-lns26
Oct  1 17:22:56.588: INFO: Got endpoints: latency-svc-lns26 [235.064696ms]
Oct  1 17:22:56.592: INFO: Created: latency-svc-x4qjg
Oct  1 17:22:56.603: INFO: Got endpoints: latency-svc-x4qjg [232.564294ms]
Oct  1 17:22:56.610: INFO: Created: latency-svc-8p2jd
Oct  1 17:22:56.621: INFO: Got endpoints: latency-svc-8p2jd [233.537641ms]
Oct  1 17:22:56.628: INFO: Created: latency-svc-l5m77
Oct  1 17:22:56.633: INFO: Got endpoints: latency-svc-l5m77 [223.834489ms]
Oct  1 17:22:56.640: INFO: Created: latency-svc-b4568
Oct  1 17:22:56.649: INFO: Got endpoints: latency-svc-b4568 [231.813845ms]
Oct  1 17:22:56.655: INFO: Created: latency-svc-mhwb9
Oct  1 17:22:56.663: INFO: Got endpoints: latency-svc-mhwb9 [228.128645ms]
Oct  1 17:22:56.669: INFO: Created: latency-svc-xh2cj
Oct  1 17:22:56.678: INFO: Got endpoints: latency-svc-xh2cj [227.75472ms]
Oct  1 17:22:56.689: INFO: Created: latency-svc-8mwtz
Oct  1 17:22:56.697: INFO: Got endpoints: latency-svc-8mwtz [229.242809ms]
Oct  1 17:22:56.702: INFO: Created: latency-svc-vszxn
Oct  1 17:22:56.710: INFO: Got endpoints: latency-svc-vszxn [222.862393ms]
Oct  1 17:22:56.714: INFO: Created: latency-svc-xht6x
Oct  1 17:22:56.725: INFO: Got endpoints: latency-svc-xht6x [226.696107ms]
Oct  1 17:22:56.729: INFO: Created: latency-svc-x4vr2
Oct  1 17:22:56.737: INFO: Got endpoints: latency-svc-x4vr2 [226.251015ms]
Oct  1 17:22:56.741: INFO: Created: latency-svc-5dhfl
Oct  1 17:22:56.750: INFO: Got endpoints: latency-svc-5dhfl [217.679194ms]
Oct  1 17:22:56.761: INFO: Created: latency-svc-xhk8z
Oct  1 17:22:56.767: INFO: Got endpoints: latency-svc-xhk8z [220.549317ms]
Oct  1 17:22:56.773: INFO: Created: latency-svc-p62p7
Oct  1 17:22:56.790: INFO: Got endpoints: latency-svc-p62p7 [230.398905ms]
Oct  1 17:22:56.806: INFO: Created: latency-svc-t4bmp
Oct  1 17:22:56.819: INFO: Got endpoints: latency-svc-t4bmp [249.478042ms]
Oct  1 17:22:57.215: INFO: Created: latency-svc-mgvqx
Oct  1 17:22:57.215: INFO: Created: latency-svc-l5hlf
Oct  1 17:22:57.216: INFO: Created: latency-svc-gbnwr
Oct  1 17:22:57.216: INFO: Created: latency-svc-dmjv2
Oct  1 17:22:57.224: INFO: Got endpoints: latency-svc-gbnwr [621.054404ms]
Oct  1 17:22:57.224: INFO: Got endpoints: latency-svc-l5hlf [591.005721ms]
Oct  1 17:22:57.224: INFO: Got endpoints: latency-svc-dmjv2 [603.190085ms]
Oct  1 17:22:57.224: INFO: Got endpoints: latency-svc-mgvqx [635.886331ms]
Oct  1 17:22:57.380: INFO: Created: latency-svc-6xqt7
Oct  1 17:22:57.391: INFO: Got endpoints: latency-svc-6xqt7 [741.683876ms]
Oct  1 17:22:57.402: INFO: Created: latency-svc-glv96
Oct  1 17:22:57.420: INFO: Got endpoints: latency-svc-glv96 [757.257795ms]
Oct  1 17:22:57.427: INFO: Created: latency-svc-w4ft4
Oct  1 17:22:57.436: INFO: Got endpoints: latency-svc-w4ft4 [757.228458ms]
Oct  1 17:22:57.441: INFO: Created: latency-svc-pn6pt
Oct  1 17:22:57.450: INFO: Got endpoints: latency-svc-pn6pt [752.676639ms]
Oct  1 17:22:57.459: INFO: Created: latency-svc-md86x
Oct  1 17:22:57.466: INFO: Got endpoints: latency-svc-md86x [755.839638ms]
Oct  1 17:22:57.473: INFO: Created: latency-svc-6kgbc
Oct  1 17:22:57.485: INFO: Got endpoints: latency-svc-6kgbc [759.54843ms]
Oct  1 17:22:57.490: INFO: Created: latency-svc-qxhgq
Oct  1 17:22:57.502: INFO: Got endpoints: latency-svc-qxhgq [764.557379ms]
Oct  1 17:22:57.508: INFO: Created: latency-svc-hrq7p
Oct  1 17:22:57.516: INFO: Got endpoints: latency-svc-hrq7p [765.625387ms]
Oct  1 17:22:57.521: INFO: Created: latency-svc-mjw9x
Oct  1 17:22:57.530: INFO: Got endpoints: latency-svc-mjw9x [763.30365ms]
Oct  1 17:22:57.535: INFO: Created: latency-svc-8l6d4
Oct  1 17:22:57.548: INFO: Got endpoints: latency-svc-8l6d4 [757.636587ms]
Oct  1 17:22:57.552: INFO: Created: latency-svc-6cwfs
Oct  1 17:22:57.562: INFO: Got endpoints: latency-svc-6cwfs [742.990033ms]
Oct  1 17:22:57.568: INFO: Created: latency-svc-p5ddb
Oct  1 17:22:57.577: INFO: Got endpoints: latency-svc-p5ddb [352.735417ms]
Oct  1 17:22:57.583: INFO: Created: latency-svc-2fcl9
Oct  1 17:22:57.593: INFO: Got endpoints: latency-svc-2fcl9 [368.805505ms]
Oct  1 17:22:57.598: INFO: Created: latency-svc-9hnbx
Oct  1 17:22:57.612: INFO: Got endpoints: latency-svc-9hnbx [387.759722ms]
Oct  1 17:22:57.623: INFO: Created: latency-svc-wmqjv
Oct  1 17:22:57.630: INFO: Created: latency-svc-pwrln
Oct  1 17:22:57.640: INFO: Got endpoints: latency-svc-wmqjv [416.147335ms]
Oct  1 17:22:57.648: INFO: Got endpoints: latency-svc-pwrln [257.416146ms]
Oct  1 17:22:57.662: INFO: Created: latency-svc-sd6g9
Oct  1 17:22:57.673: INFO: Got endpoints: latency-svc-sd6g9 [252.418046ms]
Oct  1 17:22:57.681: INFO: Created: latency-svc-86m8k
Oct  1 17:22:57.692: INFO: Got endpoints: latency-svc-86m8k [256.285288ms]
Oct  1 17:22:57.699: INFO: Created: latency-svc-qdw2k
Oct  1 17:22:57.710: INFO: Got endpoints: latency-svc-qdw2k [259.793703ms]
Oct  1 17:22:57.714: INFO: Created: latency-svc-nj7xm
Oct  1 17:22:57.727: INFO: Got endpoints: latency-svc-nj7xm [260.827055ms]
Oct  1 17:22:57.735: INFO: Created: latency-svc-9lp9z
Oct  1 17:22:57.743: INFO: Got endpoints: latency-svc-9lp9z [257.987245ms]
Oct  1 17:22:57.748: INFO: Created: latency-svc-ln82g
Oct  1 17:22:57.758: INFO: Got endpoints: latency-svc-ln82g [256.555538ms]
Oct  1 17:22:57.764: INFO: Created: latency-svc-qg68n
Oct  1 17:22:57.777: INFO: Got endpoints: latency-svc-qg68n [260.931328ms]
Oct  1 17:22:57.792: INFO: Created: latency-svc-sjp2d
Oct  1 17:22:57.800: INFO: Got endpoints: latency-svc-sjp2d [269.851992ms]
Oct  1 17:22:57.805: INFO: Created: latency-svc-bxlct
Oct  1 17:22:57.815: INFO: Got endpoints: latency-svc-bxlct [267.11595ms]
Oct  1 17:22:57.820: INFO: Created: latency-svc-8d5qx
Oct  1 17:22:57.829: INFO: Got endpoints: latency-svc-8d5qx [267.114582ms]
Oct  1 17:22:57.837: INFO: Created: latency-svc-c62c2
Oct  1 17:22:57.843: INFO: Got endpoints: latency-svc-c62c2 [266.218917ms]
Oct  1 17:22:57.848: INFO: Created: latency-svc-6wklf
Oct  1 17:22:57.856: INFO: Got endpoints: latency-svc-6wklf [262.495666ms]
Oct  1 17:22:57.862: INFO: Created: latency-svc-m42xc
Oct  1 17:22:57.872: INFO: Got endpoints: latency-svc-m42xc [259.934283ms]
Oct  1 17:22:57.889: INFO: Created: latency-svc-6gzt9
Oct  1 17:22:57.898: INFO: Got endpoints: latency-svc-6gzt9 [258.085422ms]
Oct  1 17:22:57.904: INFO: Created: latency-svc-nhsfv
Oct  1 17:22:57.914: INFO: Got endpoints: latency-svc-nhsfv [265.698535ms]
Oct  1 17:22:57.919: INFO: Created: latency-svc-hzbk6
Oct  1 17:22:57.933: INFO: Got endpoints: latency-svc-hzbk6 [259.472201ms]
Oct  1 17:22:57.937: INFO: Created: latency-svc-d9z2v
Oct  1 17:22:57.948: INFO: Got endpoints: latency-svc-d9z2v [256.127609ms]
Oct  1 17:22:57.951: INFO: Created: latency-svc-dhdx6
Oct  1 17:22:57.963: INFO: Got endpoints: latency-svc-dhdx6 [253.506345ms]
Oct  1 17:22:57.972: INFO: Created: latency-svc-sbb6x
Oct  1 17:22:57.980: INFO: Got endpoints: latency-svc-sbb6x [252.88599ms]
Oct  1 17:22:57.985: INFO: Created: latency-svc-x4xvk
Oct  1 17:22:57.994: INFO: Got endpoints: latency-svc-x4xvk [251.323528ms]
Oct  1 17:22:57.997: INFO: Created: latency-svc-dz77c
Oct  1 17:22:58.008: INFO: Got endpoints: latency-svc-dz77c [249.752765ms]
Oct  1 17:22:58.014: INFO: Created: latency-svc-7r56r
Oct  1 17:22:58.022: INFO: Got endpoints: latency-svc-7r56r [244.679666ms]
Oct  1 17:22:58.029: INFO: Created: latency-svc-zmb94
Oct  1 17:22:58.043: INFO: Got endpoints: latency-svc-zmb94 [242.567252ms]
Oct  1 17:22:58.049: INFO: Created: latency-svc-7cj7g
Oct  1 17:22:58.058: INFO: Got endpoints: latency-svc-7cj7g [242.59763ms]
Oct  1 17:22:58.062: INFO: Created: latency-svc-qp59c
Oct  1 17:22:58.077: INFO: Got endpoints: latency-svc-qp59c [248.085279ms]
Oct  1 17:22:58.080: INFO: Created: latency-svc-zlrr8
Oct  1 17:22:58.089: INFO: Got endpoints: latency-svc-zlrr8 [245.357754ms]
Oct  1 17:22:58.099: INFO: Created: latency-svc-n2vck
Oct  1 17:22:58.108: INFO: Got endpoints: latency-svc-n2vck [252.366697ms]
Oct  1 17:22:58.114: INFO: Created: latency-svc-t56rd
Oct  1 17:22:58.123: INFO: Got endpoints: latency-svc-t56rd [250.700598ms]
Oct  1 17:22:58.131: INFO: Created: latency-svc-pjc4v
Oct  1 17:22:58.136: INFO: Got endpoints: latency-svc-pjc4v [237.729106ms]
Oct  1 17:22:58.142: INFO: Created: latency-svc-58t79
Oct  1 17:22:58.152: INFO: Got endpoints: latency-svc-58t79 [238.028044ms]
Oct  1 17:22:58.157: INFO: Created: latency-svc-6dt22
Oct  1 17:22:58.167: INFO: Got endpoints: latency-svc-6dt22 [234.476963ms]
Oct  1 17:22:58.177: INFO: Created: latency-svc-tz789
Oct  1 17:22:58.188: INFO: Got endpoints: latency-svc-tz789 [240.322534ms]
Oct  1 17:22:58.194: INFO: Created: latency-svc-rsfvl
Oct  1 17:22:58.200: INFO: Got endpoints: latency-svc-rsfvl [236.85289ms]
Oct  1 17:22:58.212: INFO: Created: latency-svc-gjwlr
Oct  1 17:22:58.228: INFO: Got endpoints: latency-svc-gjwlr [247.290474ms]
Oct  1 17:22:58.231: INFO: Created: latency-svc-nnssg
Oct  1 17:22:58.244: INFO: Got endpoints: latency-svc-nnssg [250.29306ms]
Oct  1 17:22:58.250: INFO: Created: latency-svc-49vbx
Oct  1 17:22:58.258: INFO: Got endpoints: latency-svc-49vbx [250.061373ms]
Oct  1 17:22:58.265: INFO: Created: latency-svc-gzgk4
Oct  1 17:22:58.272: INFO: Got endpoints: latency-svc-gzgk4 [249.940334ms]
Oct  1 17:22:58.284: INFO: Created: latency-svc-74v2s
Oct  1 17:22:58.293: INFO: Got endpoints: latency-svc-74v2s [250.302226ms]
Oct  1 17:22:58.297: INFO: Created: latency-svc-7hf69
Oct  1 17:22:58.307: INFO: Got endpoints: latency-svc-7hf69 [248.952553ms]
Oct  1 17:22:58.311: INFO: Created: latency-svc-rsd92
Oct  1 17:22:58.321: INFO: Got endpoints: latency-svc-rsd92 [243.463335ms]
Oct  1 17:22:58.326: INFO: Created: latency-svc-6rhns
Oct  1 17:22:58.335: INFO: Got endpoints: latency-svc-6rhns [246.654249ms]
Oct  1 17:22:58.341: INFO: Created: latency-svc-rxcr9
Oct  1 17:22:58.349: INFO: Got endpoints: latency-svc-rxcr9 [240.987536ms]
Oct  1 17:22:58.357: INFO: Created: latency-svc-pxfv2
Oct  1 17:22:58.376: INFO: Got endpoints: latency-svc-pxfv2 [253.389451ms]
Oct  1 17:22:58.377: INFO: Created: latency-svc-q7rhc
Oct  1 17:22:58.394: INFO: Got endpoints: latency-svc-q7rhc [257.035412ms]
Oct  1 17:22:58.397: INFO: Created: latency-svc-5xkq5
Oct  1 17:22:58.407: INFO: Got endpoints: latency-svc-5xkq5 [254.745262ms]
Oct  1 17:22:58.412: INFO: Created: latency-svc-l77b9
Oct  1 17:22:58.424: INFO: Got endpoints: latency-svc-l77b9 [256.961278ms]
Oct  1 17:22:58.450: INFO: Created: latency-svc-s4bwc
Oct  1 17:22:58.460: INFO: Created: latency-svc-2mmsk
Oct  1 17:22:58.460: INFO: Got endpoints: latency-svc-s4bwc [271.952547ms]
Oct  1 17:22:58.469: INFO: Got endpoints: latency-svc-2mmsk [268.249668ms]
Oct  1 17:22:58.493: INFO: Created: latency-svc-nt2pl
Oct  1 17:22:58.493: INFO: Got endpoints: latency-svc-nt2pl [265.694558ms]
Oct  1 17:22:58.493: INFO: Latencies: [37.914238ms 43.485158ms 55.398ms 69.992176ms 89.855738ms 104.738205ms 118.392177ms 138.681141ms 152.864474ms 170.918242ms 186.79716ms 198.891907ms 217.679194ms 220.515443ms 220.549317ms 222.862393ms 223.834489ms 226.251015ms 226.696107ms 227.75472ms 228.128645ms 229.242809ms 230.398905ms 231.813845ms 232.019537ms 232.564294ms 233.136377ms 233.537641ms 234.45864ms 234.476963ms 235.064696ms 236.85289ms 237.729106ms 238.028044ms 238.832871ms 239.029936ms 240.322534ms 240.987536ms 241.368245ms 242.567252ms 242.59763ms 243.463335ms 244.679666ms 245.131129ms 245.357754ms 246.654249ms 246.792624ms 247.290474ms 248.085279ms 248.114047ms 248.71093ms 248.952553ms 249.478042ms 249.739892ms 249.752765ms 249.940334ms 250.061373ms 250.284206ms 250.29306ms 250.302226ms 250.700598ms 250.925672ms 251.323528ms 251.752687ms 252.366697ms 252.418046ms 252.88599ms 253.157456ms 253.24072ms 253.389451ms 253.506345ms 254.745262ms 255.602385ms 256.007939ms 256.127609ms 256.285288ms 256.555538ms 256.595575ms 256.709188ms 256.961278ms 257.035412ms 257.169303ms 257.416146ms 257.552637ms 257.819259ms 257.968545ms 257.987245ms 258.085422ms 258.333311ms 258.914942ms 259.472201ms 259.526939ms 259.793703ms 259.934283ms 260.000408ms 260.827055ms 260.931328ms 261.421159ms 262.343273ms 262.383714ms 262.459105ms 262.473417ms 262.495666ms 262.553582ms 263.331711ms 263.590305ms 264.565454ms 264.705953ms 265.694558ms 265.698535ms 265.698698ms 265.792886ms 266.218917ms 267.007072ms 267.114582ms 267.11595ms 267.202757ms 268.249668ms 269.475841ms 269.629786ms 269.851992ms 270.195296ms 270.830258ms 270.87545ms 271.952547ms 272.55919ms 272.848706ms 272.989399ms 273.06829ms 273.315429ms 273.568863ms 273.685322ms 275.468487ms 276.066015ms 276.307664ms 276.558984ms 277.027441ms 277.619899ms 277.987782ms 278.130747ms 279.55165ms 280.984141ms 281.054326ms 281.13689ms 281.851159ms 282.257489ms 282.720461ms 282.851077ms 283.873026ms 284.987783ms 285.061498ms 286.170783ms 286.339408ms 290.97174ms 294.826611ms 297.692175ms 300.22316ms 300.316024ms 300.938697ms 302.06757ms 302.953155ms 307.106022ms 307.777932ms 308.91627ms 311.363138ms 312.558106ms 352.735417ms 368.805505ms 387.759722ms 416.147335ms 575.236492ms 582.676246ms 590.747062ms 591.005721ms 595.21684ms 603.190085ms 605.553777ms 608.793576ms 609.43969ms 610.949342ms 611.444123ms 612.958322ms 614.191291ms 616.527004ms 616.61187ms 621.054404ms 621.072187ms 623.221772ms 635.886331ms 741.683876ms 742.990033ms 752.676639ms 755.839638ms 757.228458ms 757.257795ms 757.636587ms 759.54843ms 763.30365ms 764.557379ms 765.625387ms]
Oct  1 17:22:58.494: INFO: 50 %ile: 262.459105ms
Oct  1 17:22:58.494: INFO: 90 %ile: 611.444123ms
Oct  1 17:22:58.494: INFO: 99 %ile: 764.557379ms
Oct  1 17:22:58.494: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:22:58.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-9874" for this suite.
Oct  1 17:23:22.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:23:23.069: INFO: namespace svc-latency-9874 deletion completed in 24.555967381s

• [SLOW TEST:31.319 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:23:23.069: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8410
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Oct  1 17:23:23.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 cluster-info'
Oct  1 17:23:23.493: INFO: stderr: ""
Oct  1 17:23:23.493: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:23:23.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8410" for this suite.
Oct  1 17:23:29.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:23:29.861: INFO: namespace kubectl-8410 deletion completed in 6.348956708s

• [SLOW TEST:6.792 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:23:29.862: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6150
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 17:23:30.097: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2fca5894-e470-11e9-afc1-6aca03636ae4" in namespace "projected-6150" to be "success or failure"
Oct  1 17:23:30.106: INFO: Pod "downwardapi-volume-2fca5894-e470-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.05431ms
Oct  1 17:23:32.118: INFO: Pod "downwardapi-volume-2fca5894-e470-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020195418s
STEP: Saw pod success
Oct  1 17:23:32.118: INFO: Pod "downwardapi-volume-2fca5894-e470-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:23:32.128: INFO: Trying to get logs from node 10.75.67.233 pod downwardapi-volume-2fca5894-e470-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 17:23:32.177: INFO: Waiting for pod downwardapi-volume-2fca5894-e470-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:23:32.189: INFO: Pod downwardapi-volume-2fca5894-e470-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:23:32.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6150" for this suite.
Oct  1 17:23:38.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:23:38.813: INFO: namespace projected-6150 deletion completed in 6.612404703s

• [SLOW TEST:8.951 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:23:38.814: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-1642
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Oct  1 17:23:40.468: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Oct  1 17:23:42.572: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705547420, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705547420, loc:(*time.Location)(0x8830120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705547420, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705547420, loc:(*time.Location)(0x8830120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 17:23:44.581: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705547420, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705547420, loc:(*time.Location)(0x8830120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705547420, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705547420, loc:(*time.Location)(0x8830120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 17:23:46.582: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705547420, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705547420, loc:(*time.Location)(0x8830120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705547420, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705547420, loc:(*time.Location)(0x8830120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 17:23:48.582: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705547420, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705547420, loc:(*time.Location)(0x8830120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705547420, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705547420, loc:(*time.Location)(0x8830120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 17:23:51.749: INFO: Waited 1.159196462s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:23:52.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1642" for this suite.
Oct  1 17:23:58.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:23:58.638: INFO: namespace aggregator-1642 deletion completed in 6.34096937s

• [SLOW TEST:19.824 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:23:58.638: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7363
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct  1 17:23:58.882: INFO: Waiting up to 5m0s for pod "pod-40f2980e-e470-11e9-afc1-6aca03636ae4" in namespace "emptydir-7363" to be "success or failure"
Oct  1 17:23:58.900: INFO: Pod "pod-40f2980e-e470-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.323044ms
Oct  1 17:24:00.915: INFO: Pod "pod-40f2980e-e470-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032487065s
Oct  1 17:24:02.926: INFO: Pod "pod-40f2980e-e470-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044100832s
STEP: Saw pod success
Oct  1 17:24:02.926: INFO: Pod "pod-40f2980e-e470-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:24:02.943: INFO: Trying to get logs from node 10.75.67.233 pod pod-40f2980e-e470-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 17:24:03.009: INFO: Waiting for pod pod-40f2980e-e470-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:24:03.019: INFO: Pod pod-40f2980e-e470-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:24:03.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7363" for this suite.
Oct  1 17:24:09.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:24:09.389: INFO: namespace emptydir-7363 deletion completed in 6.357010067s

• [SLOW TEST:10.751 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:24:09.390: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2535
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2535.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2535.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2535.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2535.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2535.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2535.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  1 17:24:22.096: INFO: DNS probes using dns-2535/dns-test-4766005f-e470-11e9-afc1-6aca03636ae4 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:24:22.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2535" for this suite.
Oct  1 17:24:28.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:24:28.499: INFO: namespace dns-2535 deletion completed in 6.356222345s

• [SLOW TEST:19.109 seconds]
[sig-network] DNS
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:24:28.502: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2704
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-52bef879-e470-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume configMaps
Oct  1 17:24:28.752: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-52c09778-e470-11e9-afc1-6aca03636ae4" in namespace "projected-2704" to be "success or failure"
Oct  1 17:24:28.771: INFO: Pod "pod-projected-configmaps-52c09778-e470-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 19.772878ms
Oct  1 17:24:30.784: INFO: Pod "pod-projected-configmaps-52c09778-e470-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032718757s
Oct  1 17:24:32.950: INFO: Pod "pod-projected-configmaps-52c09778-e470-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.198101178s
STEP: Saw pod success
Oct  1 17:24:32.950: INFO: Pod "pod-projected-configmaps-52c09778-e470-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:24:32.974: INFO: Trying to get logs from node 10.75.67.233 pod pod-projected-configmaps-52c09778-e470-11e9-afc1-6aca03636ae4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 17:24:33.083: INFO: Waiting for pod pod-projected-configmaps-52c09778-e470-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:24:33.094: INFO: Pod pod-projected-configmaps-52c09778-e470-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:24:33.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2704" for this suite.
Oct  1 17:24:39.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:24:39.446: INFO: namespace projected-2704 deletion completed in 6.337335501s

• [SLOW TEST:10.944 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:24:39.446: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7153
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 17:24:39.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 create -f - --namespace=kubectl-7153'
Oct  1 17:24:39.916: INFO: stderr: ""
Oct  1 17:24:39.916: INFO: stdout: "replicationcontroller/redis-master created\n"
Oct  1 17:24:39.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 create -f - --namespace=kubectl-7153'
Oct  1 17:24:40.230: INFO: stderr: ""
Oct  1 17:24:40.230: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct  1 17:24:41.241: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 17:24:41.241: INFO: Found 0 / 1
Oct  1 17:24:42.243: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 17:24:42.243: INFO: Found 1 / 1
Oct  1 17:24:42.243: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct  1 17:24:42.254: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 17:24:42.254: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct  1 17:24:42.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 describe pod redis-master-vbwc2 --namespace=kubectl-7153'
Oct  1 17:24:42.392: INFO: stderr: ""
Oct  1 17:24:42.392: INFO: stdout: "Name:               redis-master-vbwc2\nNamespace:          kubectl-7153\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.75.67.242/10.75.67.242\nStart Time:         Tue, 01 Oct 2019 17:24:39 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 172.30.248.14\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://7965368a215ddbf59497a2175052fd3b93bcc99c183174b00dd0ab20b724ce09\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 01 Oct 2019 17:24:41 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-x5p7t (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-x5p7t:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-x5p7t\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 600s\n                 node.kubernetes.io/unreachable:NoExecute for 600s\nEvents:\n  Type    Reason     Age   From                   Message\n  ----    ------     ----  ----                   -------\n  Normal  Scheduled  3s    default-scheduler      Successfully assigned kubectl-7153/redis-master-vbwc2 to 10.75.67.242\n  Normal  Pulled     2s    kubelet, 10.75.67.242  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, 10.75.67.242  Created container redis-master\n  Normal  Started    1s    kubelet, 10.75.67.242  Started container redis-master\n"
Oct  1 17:24:42.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 describe rc redis-master --namespace=kubectl-7153'
Oct  1 17:24:42.546: INFO: stderr: ""
Oct  1 17:24:42.546: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-7153\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-vbwc2\n"
Oct  1 17:24:42.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 describe service redis-master --namespace=kubectl-7153'
Oct  1 17:24:42.697: INFO: stderr: ""
Oct  1 17:24:42.697: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-7153\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.16.81\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.248.14:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct  1 17:24:42.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 describe node 10.75.67.233'
Oct  1 17:24:42.896: INFO: stderr: ""
Oct  1 17:24:42.896: INFO: stdout: "Name:               10.75.67.233\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-de\n                    failure-domain.beta.kubernetes.io/zone=fra04\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=161.156.91.87\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.75.67.233\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=eu-de\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-bm9mdfvf0mdrp87rqprg-kubee2epvg9-default-00000215\n                    ibm-cloud.kubernetes.io/worker-pool-id=bm9mdfvf0mdrp87rqprg-8d2aaf9\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.14.6_1533\n                    ibm-cloud.kubernetes.io/zone=fra04\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.75.67.233\n                    kubernetes.io/os=linux\n                    privateVLAN=2409965\n                    publicVLAN=2409963\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 01 Oct 2019 15:16:10 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 01 Oct 2019 17:24:10 +0000   Tue, 01 Oct 2019 15:16:10 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 01 Oct 2019 17:24:10 +0000   Tue, 01 Oct 2019 15:16:10 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 01 Oct 2019 17:24:10 +0000   Tue, 01 Oct 2019 15:16:10 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 01 Oct 2019 17:24:10 +0000   Tue, 01 Oct 2019 15:16:20 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.75.67.233\n  ExternalIP:  161.156.91.87\n  Hostname:    10.75.67.233\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16420048Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627600Ki\n pods:               110\nSystem Info:\n Machine ID:                 87a05f06d56d4a24a16a3bd295557203\n System UUID:                4DB0C909-9CBE-278E-1709-70F137A5FC22\n Boot ID:                    43c0882d-bf99-48a5-96b5-db5cae14c46f\n Kernel Version:             4.15.0-62-generic\n OS Image:                   Ubuntu 18.04.3 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.9\n Kubelet Version:            v1.14.6+IKS\n Kube-Proxy Version:         v1.14.6+IKS\nProviderID:                  ibm://cc7530878c499d74ad77f31c918c626e///bm9mdfvf0mdrp87rqprg/kube-bm9mdfvf0mdrp87rqprg-kubee2epvg9-default-00000215\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  default                    test-k8s-e2e-pvg-master-verification                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         127m\n  kube-system                calico-node-7zx9m                                          250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         128m\n  kube-system                coredns-9dd7747c7-gkhfw                                    100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     117m\n  kube-system                ibm-keepalived-watcher-xrgfc                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         128m\n  kube-system                ibm-kube-fluentd-b2lqr                                     25m (0%)      300m (7%)   150Mi (1%)       800M (5%)      128m\n  kube-system                ibm-master-proxy-static-10.75.67.233                       25m (0%)      300m (7%)   32M (0%)         512M (3%)      128m\n  kube-system                vpn-7754bb6d4-wzqkn                                        5m (0%)       0 (0%)      5Mi (0%)         0 (0%)         118m\n  sonobuoy                   sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         56m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-4416e0333c0e4618-j5sjs    0 (0%)        0 (0%)      0 (0%)           0 (0%)         56m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                410m (10%)     600m (15%)\n  memory             353810Ki (2%)  1690850Ki (12%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
Oct  1 17:24:42.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 describe namespace kubectl-7153'
Oct  1 17:24:43.048: INFO: stderr: ""
Oct  1 17:24:43.048: INFO: stdout: "Name:         kubectl-7153\nLabels:       e2e-framework=kubectl\n              e2e-run=86cf0a07-e468-11e9-afc1-6aca03636ae4\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:24:43.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7153" for this suite.
Oct  1 17:25:07.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:25:07.521: INFO: namespace kubectl-7153 deletion completed in 24.458540271s

• [SLOW TEST:28.075 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:25:07.522: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3066
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct  1 17:25:07.777: INFO: Waiting up to 5m0s for pod "downward-api-6a033331-e470-11e9-afc1-6aca03636ae4" in namespace "downward-api-3066" to be "success or failure"
Oct  1 17:25:07.800: INFO: Pod "downward-api-6a033331-e470-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 22.958579ms
Oct  1 17:25:09.810: INFO: Pod "downward-api-6a033331-e470-11e9-afc1-6aca03636ae4": Phase="Running", Reason="", readiness=true. Elapsed: 2.03273587s
Oct  1 17:25:11.824: INFO: Pod "downward-api-6a033331-e470-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046932616s
STEP: Saw pod success
Oct  1 17:25:11.825: INFO: Pod "downward-api-6a033331-e470-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:25:11.834: INFO: Trying to get logs from node 10.75.67.233 pod downward-api-6a033331-e470-11e9-afc1-6aca03636ae4 container dapi-container: <nil>
STEP: delete the pod
Oct  1 17:25:11.909: INFO: Waiting for pod downward-api-6a033331-e470-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:25:11.923: INFO: Pod downward-api-6a033331-e470-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:25:11.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3066" for this suite.
Oct  1 17:25:17.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:25:18.308: INFO: namespace downward-api-3066 deletion completed in 6.372089882s

• [SLOW TEST:10.786 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:25:18.311: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8640
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct  1 17:25:22.637: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  1 17:25:22.655: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  1 17:25:24.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  1 17:25:24.666: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  1 17:25:26.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  1 17:25:26.665: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  1 17:25:28.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  1 17:25:28.667: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  1 17:25:30.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  1 17:25:30.666: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  1 17:25:32.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  1 17:25:32.668: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  1 17:25:34.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  1 17:25:34.665: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  1 17:25:36.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  1 17:25:36.665: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  1 17:25:38.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  1 17:25:38.665: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  1 17:25:40.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  1 17:25:40.669: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  1 17:25:42.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  1 17:25:42.677: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:25:42.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8640" for this suite.
Oct  1 17:26:06.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:26:07.114: INFO: namespace container-lifecycle-hook-8640 deletion completed in 24.393086908s

• [SLOW TEST:48.804 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:26:07.114: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3439
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct  1 17:26:09.987: INFO: Successfully updated pod "pod-update-activedeadlineseconds-8d860feb-e470-11e9-afc1-6aca03636ae4"
Oct  1 17:26:09.987: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-8d860feb-e470-11e9-afc1-6aca03636ae4" in namespace "pods-3439" to be "terminated due to deadline exceeded"
Oct  1 17:26:10.009: INFO: Pod "pod-update-activedeadlineseconds-8d860feb-e470-11e9-afc1-6aca03636ae4": Phase="Running", Reason="", readiness=true. Elapsed: 22.338853ms
Oct  1 17:26:12.020: INFO: Pod "pod-update-activedeadlineseconds-8d860feb-e470-11e9-afc1-6aca03636ae4": Phase="Running", Reason="", readiness=true. Elapsed: 2.032456582s
Oct  1 17:26:14.030: INFO: Pod "pod-update-activedeadlineseconds-8d860feb-e470-11e9-afc1-6aca03636ae4": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.042745694s
Oct  1 17:26:14.030: INFO: Pod "pod-update-activedeadlineseconds-8d860feb-e470-11e9-afc1-6aca03636ae4" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:26:14.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3439" for this suite.
Oct  1 17:26:22.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:26:22.420: INFO: namespace pods-3439 deletion completed in 8.373716581s

• [SLOW TEST:15.306 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:26:22.420: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7586
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-96a4ab6a-e470-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume configMaps
Oct  1 17:26:22.672: INFO: Waiting up to 5m0s for pod "pod-configmaps-96a69a58-e470-11e9-afc1-6aca03636ae4" in namespace "configmap-7586" to be "success or failure"
Oct  1 17:26:22.692: INFO: Pod "pod-configmaps-96a69a58-e470-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 20.21113ms
Oct  1 17:26:24.703: INFO: Pod "pod-configmaps-96a69a58-e470-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030689963s
STEP: Saw pod success
Oct  1 17:26:24.703: INFO: Pod "pod-configmaps-96a69a58-e470-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:26:24.712: INFO: Trying to get logs from node 10.75.67.233 pod pod-configmaps-96a69a58-e470-11e9-afc1-6aca03636ae4 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 17:26:24.774: INFO: Waiting for pod pod-configmaps-96a69a58-e470-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:26:24.784: INFO: Pod pod-configmaps-96a69a58-e470-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:26:24.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7586" for this suite.
Oct  1 17:26:30.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:26:31.177: INFO: namespace configmap-7586 deletion completed in 6.37488791s

• [SLOW TEST:8.757 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:26:31.178: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8771
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-8771
Oct  1 17:26:33.449: INFO: Started pod liveness-exec in namespace container-probe-8771
STEP: checking the pod's current state and verifying that restartCount is present
Oct  1 17:26:33.461: INFO: Initial restart count of pod liveness-exec is 0
Oct  1 17:27:25.847: INFO: Restart count of pod container-probe-8771/liveness-exec is now 1 (52.385355242s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:27:25.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8771" for this suite.
Oct  1 17:27:31.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:27:32.253: INFO: namespace container-probe-8771 deletion completed in 6.354095752s

• [SLOW TEST:61.075 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:27:32.254: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1772
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-1772
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct  1 17:27:32.461: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct  1 17:27:50.737: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.31.33:8080/dial?request=hostName&protocol=udp&host=172.30.31.35&port=8081&tries=1'] Namespace:pod-network-test-1772 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:27:50.737: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:27:50.954: INFO: Waiting for endpoints: map[]
Oct  1 17:27:50.967: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.31.33:8080/dial?request=hostName&protocol=udp&host=172.30.248.23&port=8081&tries=1'] Namespace:pod-network-test-1772 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:27:50.967: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:27:51.164: INFO: Waiting for endpoints: map[]
Oct  1 17:27:51.183: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.31.33:8080/dial?request=hostName&protocol=udp&host=172.30.58.90&port=8081&tries=1'] Namespace:pod-network-test-1772 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:27:51.183: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:27:51.632: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:27:51.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1772" for this suite.
Oct  1 17:28:15.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:28:16.024: INFO: namespace pod-network-test-1772 deletion completed in 24.377185583s

• [SLOW TEST:43.770 seconds]
[sig-network] Networking
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:28:16.025: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5186
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-da5f6bcd-e470-11e9-afc1-6aca03636ae4
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-da5f6bcd-e470-11e9-afc1-6aca03636ae4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:29:41.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5186" for this suite.
Oct  1 17:30:05.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:30:06.348: INFO: namespace projected-5186 deletion completed in 24.442142438s

• [SLOW TEST:110.323 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:30:06.349: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3178
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1384
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct  1 17:30:06.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3178'
Oct  1 17:30:06.694: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  1 17:30:06.694: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1390
Oct  1 17:30:08.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 delete deployment e2e-test-nginx-deployment --namespace=kubectl-3178'
Oct  1 17:30:08.853: INFO: stderr: ""
Oct  1 17:30:08.853: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:30:08.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3178" for this suite.
Oct  1 17:30:32.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:30:33.249: INFO: namespace kubectl-3178 deletion completed in 24.376751462s

• [SLOW TEST:26.900 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:30:33.250: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8464
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 17:30:33.466: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:30:37.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8464" for this suite.
Oct  1 17:31:19.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:31:19.970: INFO: namespace pods-8464 deletion completed in 42.387153396s

• [SLOW TEST:46.720 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:31:19.971: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1630
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-47fef30a-e471-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume secrets
Oct  1 17:31:20.223: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4801051a-e471-11e9-afc1-6aca03636ae4" in namespace "projected-1630" to be "success or failure"
Oct  1 17:31:20.240: INFO: Pod "pod-projected-secrets-4801051a-e471-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.437534ms
Oct  1 17:31:22.252: INFO: Pod "pod-projected-secrets-4801051a-e471-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028622419s
STEP: Saw pod success
Oct  1 17:31:22.252: INFO: Pod "pod-projected-secrets-4801051a-e471-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:31:22.264: INFO: Trying to get logs from node 10.75.67.242 pod pod-projected-secrets-4801051a-e471-11e9-afc1-6aca03636ae4 container secret-volume-test: <nil>
STEP: delete the pod
Oct  1 17:31:22.326: INFO: Waiting for pod pod-projected-secrets-4801051a-e471-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:31:22.336: INFO: Pod pod-projected-secrets-4801051a-e471-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:31:22.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1630" for this suite.
Oct  1 17:31:28.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:31:28.855: INFO: namespace projected-1630 deletion completed in 6.501661227s

• [SLOW TEST:8.884 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:31:28.855: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7377
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Oct  1 17:31:29.088: INFO: Waiting up to 5m0s for pod "var-expansion-4d4ab977-e471-11e9-afc1-6aca03636ae4" in namespace "var-expansion-7377" to be "success or failure"
Oct  1 17:31:29.099: INFO: Pod "var-expansion-4d4ab977-e471-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.814665ms
Oct  1 17:31:31.111: INFO: Pod "var-expansion-4d4ab977-e471-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023458906s
STEP: Saw pod success
Oct  1 17:31:31.112: INFO: Pod "var-expansion-4d4ab977-e471-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:31:31.123: INFO: Trying to get logs from node 10.75.67.233 pod var-expansion-4d4ab977-e471-11e9-afc1-6aca03636ae4 container dapi-container: <nil>
STEP: delete the pod
Oct  1 17:31:31.290: INFO: Waiting for pod var-expansion-4d4ab977-e471-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:31:31.314: INFO: Pod var-expansion-4d4ab977-e471-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:31:31.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7377" for this suite.
Oct  1 17:31:37.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:31:37.741: INFO: namespace var-expansion-7377 deletion completed in 6.412059445s

• [SLOW TEST:8.885 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:31:37.741: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8287
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 17:31:37.981: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5297d8d6-e471-11e9-afc1-6aca03636ae4" in namespace "projected-8287" to be "success or failure"
Oct  1 17:31:37.989: INFO: Pod "downwardapi-volume-5297d8d6-e471-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.361451ms
Oct  1 17:31:40.020: INFO: Pod "downwardapi-volume-5297d8d6-e471-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039201304s
STEP: Saw pod success
Oct  1 17:31:40.020: INFO: Pod "downwardapi-volume-5297d8d6-e471-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:31:40.029: INFO: Trying to get logs from node 10.75.67.242 pod downwardapi-volume-5297d8d6-e471-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 17:31:40.083: INFO: Waiting for pod downwardapi-volume-5297d8d6-e471-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:31:40.096: INFO: Pod downwardapi-volume-5297d8d6-e471-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:31:40.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8287" for this suite.
Oct  1 17:31:46.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:31:46.452: INFO: namespace projected-8287 deletion completed in 6.339416045s

• [SLOW TEST:8.711 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:31:46.452: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7782
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct  1 17:31:46.685: INFO: Waiting up to 5m0s for pod "pod-57c7cae0-e471-11e9-afc1-6aca03636ae4" in namespace "emptydir-7782" to be "success or failure"
Oct  1 17:31:46.695: INFO: Pod "pod-57c7cae0-e471-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.4356ms
Oct  1 17:31:48.704: INFO: Pod "pod-57c7cae0-e471-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018963584s
Oct  1 17:31:50.716: INFO: Pod "pod-57c7cae0-e471-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03109182s
STEP: Saw pod success
Oct  1 17:31:50.716: INFO: Pod "pod-57c7cae0-e471-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:31:50.727: INFO: Trying to get logs from node 10.75.67.233 pod pod-57c7cae0-e471-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 17:31:50.780: INFO: Waiting for pod pod-57c7cae0-e471-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:31:50.790: INFO: Pod pod-57c7cae0-e471-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:31:50.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7782" for this suite.
Oct  1 17:31:56.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:31:57.230: INFO: namespace emptydir-7782 deletion completed in 6.423666513s

• [SLOW TEST:10.778 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:31:57.231: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2370
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Oct  1 17:31:57.467: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-589150881 proxy --unix-socket=/tmp/kubectl-proxy-unix311270272/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:31:57.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2370" for this suite.
Oct  1 17:32:03.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:32:04.031: INFO: namespace kubectl-2370 deletion completed in 6.492138986s

• [SLOW TEST:6.801 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:32:04.031: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7012
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-hbmp
STEP: Creating a pod to test atomic-volume-subpath
Oct  1 17:32:04.350: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-hbmp" in namespace "subpath-7012" to be "success or failure"
Oct  1 17:32:04.360: INFO: Pod "pod-subpath-test-configmap-hbmp": Phase="Pending", Reason="", readiness=false. Elapsed: 10.332033ms
Oct  1 17:32:06.378: INFO: Pod "pod-subpath-test-configmap-hbmp": Phase="Running", Reason="", readiness=true. Elapsed: 2.027871028s
Oct  1 17:32:08.391: INFO: Pod "pod-subpath-test-configmap-hbmp": Phase="Running", Reason="", readiness=true. Elapsed: 4.041016914s
Oct  1 17:32:10.434: INFO: Pod "pod-subpath-test-configmap-hbmp": Phase="Running", Reason="", readiness=true. Elapsed: 6.083700841s
Oct  1 17:32:12.445: INFO: Pod "pod-subpath-test-configmap-hbmp": Phase="Running", Reason="", readiness=true. Elapsed: 8.095367873s
Oct  1 17:32:14.458: INFO: Pod "pod-subpath-test-configmap-hbmp": Phase="Running", Reason="", readiness=true. Elapsed: 10.108629768s
Oct  1 17:32:16.469: INFO: Pod "pod-subpath-test-configmap-hbmp": Phase="Running", Reason="", readiness=true. Elapsed: 12.119298594s
Oct  1 17:32:18.478: INFO: Pod "pod-subpath-test-configmap-hbmp": Phase="Running", Reason="", readiness=true. Elapsed: 14.128437927s
Oct  1 17:32:20.493: INFO: Pod "pod-subpath-test-configmap-hbmp": Phase="Running", Reason="", readiness=true. Elapsed: 16.143202607s
Oct  1 17:32:22.505: INFO: Pod "pod-subpath-test-configmap-hbmp": Phase="Running", Reason="", readiness=true. Elapsed: 18.155122419s
Oct  1 17:32:24.516: INFO: Pod "pod-subpath-test-configmap-hbmp": Phase="Running", Reason="", readiness=true. Elapsed: 20.166509146s
Oct  1 17:32:26.527: INFO: Pod "pod-subpath-test-configmap-hbmp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.177099213s
STEP: Saw pod success
Oct  1 17:32:26.527: INFO: Pod "pod-subpath-test-configmap-hbmp" satisfied condition "success or failure"
Oct  1 17:32:26.536: INFO: Trying to get logs from node 10.75.67.242 pod pod-subpath-test-configmap-hbmp container test-container-subpath-configmap-hbmp: <nil>
STEP: delete the pod
Oct  1 17:32:26.593: INFO: Waiting for pod pod-subpath-test-configmap-hbmp to disappear
Oct  1 17:32:26.611: INFO: Pod pod-subpath-test-configmap-hbmp no longer exists
STEP: Deleting pod pod-subpath-test-configmap-hbmp
Oct  1 17:32:26.612: INFO: Deleting pod "pod-subpath-test-configmap-hbmp" in namespace "subpath-7012"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:32:26.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7012" for this suite.
Oct  1 17:32:32.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:32:33.016: INFO: namespace subpath-7012 deletion completed in 6.380113649s

• [SLOW TEST:28.985 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:32:33.018: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4087
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-4087
Oct  1 17:32:37.284: INFO: Started pod liveness-http in namespace container-probe-4087
STEP: checking the pod's current state and verifying that restartCount is present
Oct  1 17:32:37.296: INFO: Initial restart count of pod liveness-http is 0
Oct  1 17:32:55.409: INFO: Restart count of pod container-probe-4087/liveness-http is now 1 (18.113105122s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:32:55.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4087" for this suite.
Oct  1 17:33:03.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:33:03.918: INFO: namespace container-probe-4087 deletion completed in 8.421454117s

• [SLOW TEST:30.900 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:33:03.918: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9997
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-9997
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct  1 17:33:04.142: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct  1 17:33:26.383: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.248.31:8080/dial?request=hostName&protocol=http&host=172.30.248.30&port=8080&tries=1'] Namespace:pod-network-test-9997 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:33:26.383: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:33:26.580: INFO: Waiting for endpoints: map[]
Oct  1 17:33:26.606: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.248.31:8080/dial?request=hostName&protocol=http&host=172.30.31.41&port=8080&tries=1'] Namespace:pod-network-test-9997 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:33:26.606: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:33:26.851: INFO: Waiting for endpoints: map[]
Oct  1 17:33:26.860: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.248.31:8080/dial?request=hostName&protocol=http&host=172.30.58.91&port=8080&tries=1'] Namespace:pod-network-test-9997 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:33:26.860: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:33:27.053: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:33:27.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9997" for this suite.
Oct  1 17:33:51.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:33:51.530: INFO: namespace pod-network-test-9997 deletion completed in 24.463916951s

• [SLOW TEST:47.613 seconds]
[sig-network] Networking
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:33:51.531: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8028
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Oct  1 17:33:51.764: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:33:59.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8028" for this suite.
Oct  1 17:34:05.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:34:06.245: INFO: namespace pods-8028 deletion completed in 6.416263461s

• [SLOW TEST:14.714 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:34:06.246: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6954
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-ab1bcb4c-e471-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume configMaps
Oct  1 17:34:06.512: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ab1dacbc-e471-11e9-afc1-6aca03636ae4" in namespace "projected-6954" to be "success or failure"
Oct  1 17:34:06.521: INFO: Pod "pod-projected-configmaps-ab1dacbc-e471-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.080017ms
Oct  1 17:34:08.531: INFO: Pod "pod-projected-configmaps-ab1dacbc-e471-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019257835s
STEP: Saw pod success
Oct  1 17:34:08.531: INFO: Pod "pod-projected-configmaps-ab1dacbc-e471-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:34:08.541: INFO: Trying to get logs from node 10.75.67.233 pod pod-projected-configmaps-ab1dacbc-e471-11e9-afc1-6aca03636ae4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 17:34:08.625: INFO: Waiting for pod pod-projected-configmaps-ab1dacbc-e471-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:34:08.642: INFO: Pod pod-projected-configmaps-ab1dacbc-e471-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:34:08.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6954" for this suite.
Oct  1 17:34:14.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:34:15.426: INFO: namespace projected-6954 deletion completed in 6.758724367s

• [SLOW TEST:9.180 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:34:15.427: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6934
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Oct  1 17:34:15.671: INFO: Pod name pod-release: Found 0 pods out of 1
Oct  1 17:34:20.682: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:34:20.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6934" for this suite.
Oct  1 17:34:26.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:34:27.179: INFO: namespace replication-controller-6934 deletion completed in 6.442968322s

• [SLOW TEST:11.752 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:34:27.179: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4635
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Oct  1 17:34:27.487: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-4635,SelfLink:/api/v1/namespaces/watch-4635/configmaps/e2e-watch-test-resource-version,UID:b797bffb-e471-11e9-bf88-8e83bb394576,ResourceVersion:36850,Generation:0,CreationTimestamp:2019-10-01 17:34:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  1 17:34:27.487: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-4635,SelfLink:/api/v1/namespaces/watch-4635/configmaps/e2e-watch-test-resource-version,UID:b797bffb-e471-11e9-bf88-8e83bb394576,ResourceVersion:36851,Generation:0,CreationTimestamp:2019-10-01 17:34:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:34:27.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4635" for this suite.
Oct  1 17:34:33.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:34:33.900: INFO: namespace watch-4635 deletion completed in 6.399493957s

• [SLOW TEST:6.721 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:34:33.900: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4937
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct  1 17:34:36.713: INFO: Successfully updated pod "pod-update-bb954d1b-e471-11e9-afc1-6aca03636ae4"
STEP: verifying the updated pod is in kubernetes
Oct  1 17:34:36.738: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:34:36.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4937" for this suite.
Oct  1 17:35:00.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:35:01.148: INFO: namespace pods-4937 deletion completed in 24.395291866s

• [SLOW TEST:27.247 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:35:01.148: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4113
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 17:35:01.390: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cbd4b26d-e471-11e9-afc1-6aca03636ae4" in namespace "downward-api-4113" to be "success or failure"
Oct  1 17:35:01.407: INFO: Pod "downwardapi-volume-cbd4b26d-e471-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 17.317314ms
Oct  1 17:35:03.421: INFO: Pod "downwardapi-volume-cbd4b26d-e471-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030682929s
STEP: Saw pod success
Oct  1 17:35:03.421: INFO: Pod "downwardapi-volume-cbd4b26d-e471-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:35:03.433: INFO: Trying to get logs from node 10.75.67.233 pod downwardapi-volume-cbd4b26d-e471-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 17:35:03.560: INFO: Waiting for pod downwardapi-volume-cbd4b26d-e471-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:35:03.578: INFO: Pod downwardapi-volume-cbd4b26d-e471-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:35:03.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4113" for this suite.
Oct  1 17:35:11.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:35:11.995: INFO: namespace downward-api-4113 deletion completed in 8.401039819s

• [SLOW TEST:10.847 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:35:11.995: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6951
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 17:35:12.241: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct  1 17:35:17.266: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct  1 17:35:17.266: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct  1 17:35:19.277: INFO: Creating deployment "test-rollover-deployment"
Oct  1 17:35:19.298: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct  1 17:35:21.319: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct  1 17:35:21.341: INFO: Ensure that both replica sets have 1 created replica
Oct  1 17:35:21.359: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct  1 17:35:21.381: INFO: Updating deployment test-rollover-deployment
Oct  1 17:35:21.382: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct  1 17:35:23.400: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct  1 17:35:23.421: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct  1 17:35:23.444: INFO: all replica sets need to contain the pod-template-hash label
Oct  1 17:35:23.444: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548119, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548119, loc:(*time.Location)(0x8830120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548123, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548119, loc:(*time.Location)(0x8830120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 17:35:25.466: INFO: all replica sets need to contain the pod-template-hash label
Oct  1 17:35:25.466: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548119, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548119, loc:(*time.Location)(0x8830120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548123, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548119, loc:(*time.Location)(0x8830120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 17:35:27.462: INFO: all replica sets need to contain the pod-template-hash label
Oct  1 17:35:27.462: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548119, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548119, loc:(*time.Location)(0x8830120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548123, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548119, loc:(*time.Location)(0x8830120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 17:35:29.465: INFO: all replica sets need to contain the pod-template-hash label
Oct  1 17:35:29.465: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548119, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548119, loc:(*time.Location)(0x8830120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548123, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548119, loc:(*time.Location)(0x8830120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 17:35:31.464: INFO: all replica sets need to contain the pod-template-hash label
Oct  1 17:35:31.464: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548119, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548119, loc:(*time.Location)(0x8830120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548123, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705548119, loc:(*time.Location)(0x8830120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 17:35:33.463: INFO: 
Oct  1 17:35:33.463: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct  1 17:35:33.502: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-6951,SelfLink:/apis/apps/v1/namespaces/deployment-6951/deployments/test-rollover-deployment,UID:d6828f10-e471-11e9-bf88-8e83bb394576,ResourceVersion:37133,Generation:2,CreationTimestamp:2019-10-01 17:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-01 17:35:19 +0000 UTC 2019-10-01 17:35:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-01 17:35:33 +0000 UTC 2019-10-01 17:35:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-659c699649" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct  1 17:35:33.512: INFO: New ReplicaSet "test-rollover-deployment-659c699649" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649,GenerateName:,Namespace:deployment-6951,SelfLink:/apis/apps/v1/namespaces/deployment-6951/replicasets/test-rollover-deployment-659c699649,UID:d7c326fe-e471-11e9-865f-ced8df5791d3,ResourceVersion:37122,Generation:2,CreationTimestamp:2019-10-01 17:35:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment d6828f10-e471-11e9-bf88-8e83bb394576 0xc00186e527 0xc00186e528}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct  1 17:35:33.512: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct  1 17:35:33.512: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-6951,SelfLink:/apis/apps/v1/namespaces/deployment-6951/replicasets/test-rollover-controller,UID:d24d2a70-e471-11e9-bf88-8e83bb394576,ResourceVersion:37131,Generation:2,CreationTimestamp:2019-10-01 17:35:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment d6828f10-e471-11e9-bf88-8e83bb394576 0xc00186e457 0xc00186e458}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct  1 17:35:33.512: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-7b45b6464,GenerateName:,Namespace:deployment-6951,SelfLink:/apis/apps/v1/namespaces/deployment-6951/replicasets/test-rollover-deployment-7b45b6464,UID:d686bd83-e471-11e9-865f-ced8df5791d3,ResourceVersion:37086,Generation:2,CreationTimestamp:2019-10-01 17:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment d6828f10-e471-11e9-bf88-8e83bb394576 0xc00186e5f0 0xc00186e5f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct  1 17:35:33.523: INFO: Pod "test-rollover-deployment-659c699649-2ts49" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649-2ts49,GenerateName:test-rollover-deployment-659c699649-,Namespace:deployment-6951,SelfLink:/api/v1/namespaces/deployment-6951/pods/test-rollover-deployment-659c699649-2ts49,UID:d7caa3e6-e471-11e9-865f-ced8df5791d3,ResourceVersion:37104,Generation:0,CreationTimestamp:2019-10-01 17:35:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-659c699649 d7c326fe-e471-11e9-865f-ced8df5791d3 0xc00186f1e7 0xc00186f1e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fhkzw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fhkzw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-fhkzw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00186f280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00186f2a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 17:35:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 17:35:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 17:35:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 17:35:21 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.242,PodIP:172.30.248.36,StartTime:2019-10-01 17:35:21 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-01 17:35:22 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://27b531c9bed057fadcb61a0d2944518d191f0337369ea9fbddcf88750485ccc2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:35:33.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6951" for this suite.
Oct  1 17:35:41.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:35:41.896: INFO: namespace deployment-6951 deletion completed in 8.360227748s

• [SLOW TEST:29.901 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:35:41.897: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5855
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-e41e57bc-e471-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume secrets
Oct  1 17:35:42.173: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e41ffeb2-e471-11e9-afc1-6aca03636ae4" in namespace "projected-5855" to be "success or failure"
Oct  1 17:35:42.187: INFO: Pod "pod-projected-secrets-e41ffeb2-e471-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.351508ms
Oct  1 17:35:44.197: INFO: Pod "pod-projected-secrets-e41ffeb2-e471-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023917464s
STEP: Saw pod success
Oct  1 17:35:44.197: INFO: Pod "pod-projected-secrets-e41ffeb2-e471-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:35:44.209: INFO: Trying to get logs from node 10.75.67.233 pod pod-projected-secrets-e41ffeb2-e471-11e9-afc1-6aca03636ae4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  1 17:35:44.280: INFO: Waiting for pod pod-projected-secrets-e41ffeb2-e471-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:35:44.292: INFO: Pod pod-projected-secrets-e41ffeb2-e471-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:35:44.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5855" for this suite.
Oct  1 17:35:50.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:35:50.668: INFO: namespace projected-5855 deletion completed in 6.36164892s

• [SLOW TEST:8.771 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:35:50.668: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7685
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct  1 17:35:50.871: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:35:55.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7685" for this suite.
Oct  1 17:36:19.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:36:19.742: INFO: namespace init-container-7685 deletion completed in 24.421676694s

• [SLOW TEST:29.074 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:36:19.745: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7589
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Oct  1 17:36:19.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 create -f - --namespace=kubectl-7589'
Oct  1 17:36:20.244: INFO: stderr: ""
Oct  1 17:36:20.244: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  1 17:36:20.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7589'
Oct  1 17:36:20.377: INFO: stderr: ""
Oct  1 17:36:20.377: INFO: stdout: "update-demo-nautilus-fx6dj update-demo-nautilus-qpv2h "
Oct  1 17:36:20.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-fx6dj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7589'
Oct  1 17:36:20.488: INFO: stderr: ""
Oct  1 17:36:20.488: INFO: stdout: ""
Oct  1 17:36:20.488: INFO: update-demo-nautilus-fx6dj is created but not running
Oct  1 17:36:25.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7589'
Oct  1 17:36:25.584: INFO: stderr: ""
Oct  1 17:36:25.584: INFO: stdout: "update-demo-nautilus-fx6dj update-demo-nautilus-qpv2h "
Oct  1 17:36:25.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-fx6dj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7589'
Oct  1 17:36:25.689: INFO: stderr: ""
Oct  1 17:36:25.689: INFO: stdout: "true"
Oct  1 17:36:25.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-fx6dj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7589'
Oct  1 17:36:25.809: INFO: stderr: ""
Oct  1 17:36:25.809: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 17:36:25.809: INFO: validating pod update-demo-nautilus-fx6dj
Oct  1 17:36:25.828: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 17:36:25.828: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 17:36:25.828: INFO: update-demo-nautilus-fx6dj is verified up and running
Oct  1 17:36:25.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-qpv2h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7589'
Oct  1 17:36:25.952: INFO: stderr: ""
Oct  1 17:36:25.952: INFO: stdout: "true"
Oct  1 17:36:25.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-qpv2h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7589'
Oct  1 17:36:26.067: INFO: stderr: ""
Oct  1 17:36:26.067: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 17:36:26.067: INFO: validating pod update-demo-nautilus-qpv2h
Oct  1 17:36:26.084: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 17:36:26.084: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 17:36:26.084: INFO: update-demo-nautilus-qpv2h is verified up and running
STEP: scaling down the replication controller
Oct  1 17:36:26.085: INFO: scanned /root for discovery docs: <nil>
Oct  1 17:36:26.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-7589'
Oct  1 17:36:27.258: INFO: stderr: ""
Oct  1 17:36:27.258: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  1 17:36:27.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7589'
Oct  1 17:36:27.377: INFO: stderr: ""
Oct  1 17:36:27.377: INFO: stdout: "update-demo-nautilus-fx6dj update-demo-nautilus-qpv2h "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct  1 17:36:32.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7589'
Oct  1 17:36:32.533: INFO: stderr: ""
Oct  1 17:36:32.533: INFO: stdout: "update-demo-nautilus-fx6dj update-demo-nautilus-qpv2h "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct  1 17:36:37.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7589'
Oct  1 17:36:37.640: INFO: stderr: ""
Oct  1 17:36:37.640: INFO: stdout: "update-demo-nautilus-fx6dj update-demo-nautilus-qpv2h "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct  1 17:36:42.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7589'
Oct  1 17:36:42.745: INFO: stderr: ""
Oct  1 17:36:42.745: INFO: stdout: "update-demo-nautilus-fx6dj "
Oct  1 17:36:42.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-fx6dj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7589'
Oct  1 17:36:42.854: INFO: stderr: ""
Oct  1 17:36:42.854: INFO: stdout: "true"
Oct  1 17:36:42.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-fx6dj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7589'
Oct  1 17:36:42.958: INFO: stderr: ""
Oct  1 17:36:42.958: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 17:36:42.958: INFO: validating pod update-demo-nautilus-fx6dj
Oct  1 17:36:42.974: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 17:36:42.974: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 17:36:42.974: INFO: update-demo-nautilus-fx6dj is verified up and running
STEP: scaling up the replication controller
Oct  1 17:36:42.975: INFO: scanned /root for discovery docs: <nil>
Oct  1 17:36:42.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-7589'
Oct  1 17:36:44.129: INFO: stderr: ""
Oct  1 17:36:44.129: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  1 17:36:44.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7589'
Oct  1 17:36:44.250: INFO: stderr: ""
Oct  1 17:36:44.250: INFO: stdout: "update-demo-nautilus-ckthd update-demo-nautilus-fx6dj "
Oct  1 17:36:44.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-ckthd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7589'
Oct  1 17:36:44.349: INFO: stderr: ""
Oct  1 17:36:44.349: INFO: stdout: ""
Oct  1 17:36:44.349: INFO: update-demo-nautilus-ckthd is created but not running
Oct  1 17:36:49.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7589'
Oct  1 17:36:49.451: INFO: stderr: ""
Oct  1 17:36:49.451: INFO: stdout: "update-demo-nautilus-ckthd update-demo-nautilus-fx6dj "
Oct  1 17:36:49.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-ckthd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7589'
Oct  1 17:36:49.555: INFO: stderr: ""
Oct  1 17:36:49.555: INFO: stdout: "true"
Oct  1 17:36:49.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-ckthd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7589'
Oct  1 17:36:49.664: INFO: stderr: ""
Oct  1 17:36:49.664: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 17:36:49.664: INFO: validating pod update-demo-nautilus-ckthd
Oct  1 17:36:49.683: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 17:36:49.683: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 17:36:49.683: INFO: update-demo-nautilus-ckthd is verified up and running
Oct  1 17:36:49.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-fx6dj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7589'
Oct  1 17:36:49.779: INFO: stderr: ""
Oct  1 17:36:49.779: INFO: stdout: "true"
Oct  1 17:36:49.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-fx6dj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7589'
Oct  1 17:36:49.898: INFO: stderr: ""
Oct  1 17:36:49.898: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 17:36:49.898: INFO: validating pod update-demo-nautilus-fx6dj
Oct  1 17:36:49.915: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 17:36:49.915: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 17:36:49.915: INFO: update-demo-nautilus-fx6dj is verified up and running
STEP: using delete to clean up resources
Oct  1 17:36:49.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 delete --grace-period=0 --force -f - --namespace=kubectl-7589'
Oct  1 17:36:50.049: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 17:36:50.049: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct  1 17:36:50.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7589'
Oct  1 17:36:50.190: INFO: stderr: "No resources found.\n"
Oct  1 17:36:50.190: INFO: stdout: ""
Oct  1 17:36:50.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -l name=update-demo --namespace=kubectl-7589 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  1 17:36:50.309: INFO: stderr: ""
Oct  1 17:36:50.309: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:36:50.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7589" for this suite.
Oct  1 17:37:14.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:37:14.725: INFO: namespace kubectl-7589 deletion completed in 24.398083114s

• [SLOW TEST:54.979 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:37:14.725: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-7845
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 17:37:14.946: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:37:16.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7845" for this suite.
Oct  1 17:37:22.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:37:22.568: INFO: namespace custom-resource-definition-7845 deletion completed in 6.45429027s

• [SLOW TEST:7.844 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:32
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:37:22.574: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6103
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Oct  1 17:37:24.863: INFO: Pod pod-hostip-20203d53-e472-11e9-afc1-6aca03636ae4 has hostIP: 10.75.67.242
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:37:24.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6103" for this suite.
Oct  1 17:37:48.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:37:49.256: INFO: namespace pods-6103 deletion completed in 24.376515418s

• [SLOW TEST:26.683 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:37:49.258: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6940
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 17:37:49.490: INFO: Waiting up to 5m0s for pod "downwardapi-volume-300750da-e472-11e9-afc1-6aca03636ae4" in namespace "downward-api-6940" to be "success or failure"
Oct  1 17:37:49.510: INFO: Pod "downwardapi-volume-300750da-e472-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 20.35845ms
Oct  1 17:37:51.529: INFO: Pod "downwardapi-volume-300750da-e472-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039373705s
STEP: Saw pod success
Oct  1 17:37:51.529: INFO: Pod "downwardapi-volume-300750da-e472-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:37:51.538: INFO: Trying to get logs from node 10.75.67.233 pod downwardapi-volume-300750da-e472-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 17:37:51.601: INFO: Waiting for pod downwardapi-volume-300750da-e472-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:37:51.610: INFO: Pod downwardapi-volume-300750da-e472-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:37:51.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6940" for this suite.
Oct  1 17:37:57.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:37:57.995: INFO: namespace downward-api-6940 deletion completed in 6.365420087s

• [SLOW TEST:8.737 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:37:57.995: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9729
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Oct  1 17:37:58.223: INFO: Waiting up to 5m0s for pod "pod-353bb271-e472-11e9-afc1-6aca03636ae4" in namespace "emptydir-9729" to be "success or failure"
Oct  1 17:37:58.236: INFO: Pod "pod-353bb271-e472-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.467677ms
Oct  1 17:38:00.246: INFO: Pod "pod-353bb271-e472-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023110974s
STEP: Saw pod success
Oct  1 17:38:00.246: INFO: Pod "pod-353bb271-e472-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:38:00.257: INFO: Trying to get logs from node 10.75.67.242 pod pod-353bb271-e472-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 17:38:00.320: INFO: Waiting for pod pod-353bb271-e472-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:38:00.330: INFO: Pod pod-353bb271-e472-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:38:00.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9729" for this suite.
Oct  1 17:38:06.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:38:07.043: INFO: namespace emptydir-9729 deletion completed in 6.700428046s

• [SLOW TEST:9.048 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:38:07.043: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6387
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct  1 17:38:07.637: INFO: Waiting up to 5m0s for pod "pod-3ad75c80-e472-11e9-afc1-6aca03636ae4" in namespace "emptydir-6387" to be "success or failure"
Oct  1 17:38:07.659: INFO: Pod "pod-3ad75c80-e472-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 21.726486ms
Oct  1 17:38:09.672: INFO: Pod "pod-3ad75c80-e472-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035459958s
STEP: Saw pod success
Oct  1 17:38:09.672: INFO: Pod "pod-3ad75c80-e472-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:38:09.683: INFO: Trying to get logs from node 10.75.67.233 pod pod-3ad75c80-e472-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 17:38:09.744: INFO: Waiting for pod pod-3ad75c80-e472-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:38:09.755: INFO: Pod pod-3ad75c80-e472-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:38:09.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6387" for this suite.
Oct  1 17:38:15.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:38:16.144: INFO: namespace emptydir-6387 deletion completed in 6.372440523s

• [SLOW TEST:9.100 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:38:16.144: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-450
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct  1 17:38:16.353: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:38:20.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-450" for this suite.
Oct  1 17:38:26.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:38:26.971: INFO: namespace init-container-450 deletion completed in 6.399307725s

• [SLOW TEST:10.827 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:38:26.971: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4332
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-46824c6a-e472-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume configMaps
Oct  1 17:38:27.227: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4685692e-e472-11e9-afc1-6aca03636ae4" in namespace "projected-4332" to be "success or failure"
Oct  1 17:38:27.237: INFO: Pod "pod-projected-configmaps-4685692e-e472-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.247858ms
Oct  1 17:38:29.250: INFO: Pod "pod-projected-configmaps-4685692e-e472-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022521265s
Oct  1 17:38:31.263: INFO: Pod "pod-projected-configmaps-4685692e-e472-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035611433s
STEP: Saw pod success
Oct  1 17:38:31.263: INFO: Pod "pod-projected-configmaps-4685692e-e472-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:38:31.272: INFO: Trying to get logs from node 10.75.67.233 pod pod-projected-configmaps-4685692e-e472-11e9-afc1-6aca03636ae4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 17:38:31.327: INFO: Waiting for pod pod-projected-configmaps-4685692e-e472-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:38:31.338: INFO: Pod pod-projected-configmaps-4685692e-e472-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:38:31.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4332" for this suite.
Oct  1 17:38:37.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:38:37.719: INFO: namespace projected-4332 deletion completed in 6.365288077s

• [SLOW TEST:10.748 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:38:37.719: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9402
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct  1 17:38:40.555: INFO: Successfully updated pod "labelsupdate4ceb27ac-e472-11e9-afc1-6aca03636ae4"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:38:42.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9402" for this suite.
Oct  1 17:39:06.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:39:07.003: INFO: namespace downward-api-9402 deletion completed in 24.385479544s

• [SLOW TEST:29.284 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:39:07.006: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2910
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Oct  1 17:39:07.235: INFO: Waiting up to 5m0s for pod "pod-5e5e7ead-e472-11e9-afc1-6aca03636ae4" in namespace "emptydir-2910" to be "success or failure"
Oct  1 17:39:07.256: INFO: Pod "pod-5e5e7ead-e472-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 20.941693ms
Oct  1 17:39:09.269: INFO: Pod "pod-5e5e7ead-e472-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034120105s
Oct  1 17:39:11.290: INFO: Pod "pod-5e5e7ead-e472-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055284677s
STEP: Saw pod success
Oct  1 17:39:11.290: INFO: Pod "pod-5e5e7ead-e472-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:39:11.304: INFO: Trying to get logs from node 10.75.67.233 pod pod-5e5e7ead-e472-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 17:39:11.374: INFO: Waiting for pod pod-5e5e7ead-e472-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:39:11.393: INFO: Pod pod-5e5e7ead-e472-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:39:11.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2910" for this suite.
Oct  1 17:39:17.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:39:17.805: INFO: namespace emptydir-2910 deletion completed in 6.396390969s

• [SLOW TEST:10.798 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:39:17.805: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3948
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 17:39:18.064: INFO: Waiting up to 5m0s for pod "downwardapi-volume-64d1f665-e472-11e9-afc1-6aca03636ae4" in namespace "projected-3948" to be "success or failure"
Oct  1 17:39:18.078: INFO: Pod "downwardapi-volume-64d1f665-e472-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.101885ms
Oct  1 17:39:20.088: INFO: Pod "downwardapi-volume-64d1f665-e472-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023581501s
STEP: Saw pod success
Oct  1 17:39:20.088: INFO: Pod "downwardapi-volume-64d1f665-e472-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:39:20.112: INFO: Trying to get logs from node 10.75.67.242 pod downwardapi-volume-64d1f665-e472-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 17:39:20.175: INFO: Waiting for pod downwardapi-volume-64d1f665-e472-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:39:20.187: INFO: Pod downwardapi-volume-64d1f665-e472-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:39:20.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3948" for this suite.
Oct  1 17:39:26.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:39:26.619: INFO: namespace projected-3948 deletion completed in 6.411866168s

• [SLOW TEST:8.814 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:39:26.620: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-375
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct  1 17:39:26.862: INFO: Waiting up to 5m0s for pod "downward-api-6a113952-e472-11e9-afc1-6aca03636ae4" in namespace "downward-api-375" to be "success or failure"
Oct  1 17:39:26.882: INFO: Pod "downward-api-6a113952-e472-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.910547ms
Oct  1 17:39:28.894: INFO: Pod "downward-api-6a113952-e472-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031486483s
STEP: Saw pod success
Oct  1 17:39:28.894: INFO: Pod "downward-api-6a113952-e472-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:39:28.903: INFO: Trying to get logs from node 10.75.67.233 pod downward-api-6a113952-e472-11e9-afc1-6aca03636ae4 container dapi-container: <nil>
STEP: delete the pod
Oct  1 17:39:29.197: INFO: Waiting for pod downward-api-6a113952-e472-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:39:29.208: INFO: Pod downward-api-6a113952-e472-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:39:29.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-375" for this suite.
Oct  1 17:39:35.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:39:35.655: INFO: namespace downward-api-375 deletion completed in 6.432022114s

• [SLOW TEST:9.035 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:39:35.655: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9356
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:39:39.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9356" for this suite.
Oct  1 17:39:45.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:39:46.450: INFO: namespace kubelet-test-9356 deletion completed in 6.489236969s

• [SLOW TEST:10.795 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:39:46.450: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-9469
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Oct  1 17:39:46.713: INFO: Waiting up to 5m0s for pod "var-expansion-75e68065-e472-11e9-afc1-6aca03636ae4" in namespace "var-expansion-9469" to be "success or failure"
Oct  1 17:39:46.729: INFO: Pod "var-expansion-75e68065-e472-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.706426ms
Oct  1 17:39:48.739: INFO: Pod "var-expansion-75e68065-e472-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02650377s
STEP: Saw pod success
Oct  1 17:39:48.739: INFO: Pod "var-expansion-75e68065-e472-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:39:48.750: INFO: Trying to get logs from node 10.75.67.233 pod var-expansion-75e68065-e472-11e9-afc1-6aca03636ae4 container dapi-container: <nil>
STEP: delete the pod
Oct  1 17:39:48.816: INFO: Waiting for pod var-expansion-75e68065-e472-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:39:48.829: INFO: Pod var-expansion-75e68065-e472-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:39:48.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9469" for this suite.
Oct  1 17:39:54.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:39:55.176: INFO: namespace var-expansion-9469 deletion completed in 6.33435133s

• [SLOW TEST:8.726 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:39:55.177: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7378
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Oct  1 17:39:55.382: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-589150881 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:39:55.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7378" for this suite.
Oct  1 17:40:01.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:40:01.896: INFO: namespace kubectl-7378 deletion completed in 6.413227548s

• [SLOW TEST:6.719 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:40:01.896: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4709
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct  1 17:40:02.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4709'
Oct  1 17:40:02.563: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  1 17:40:02.563: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Oct  1 17:40:02.607: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-465zx]
Oct  1 17:40:02.607: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-465zx" in namespace "kubectl-4709" to be "running and ready"
Oct  1 17:40:02.627: INFO: Pod "e2e-test-nginx-rc-465zx": Phase="Pending", Reason="", readiness=false. Elapsed: 19.148964ms
Oct  1 17:40:04.637: INFO: Pod "e2e-test-nginx-rc-465zx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029127335s
Oct  1 17:40:06.663: INFO: Pod "e2e-test-nginx-rc-465zx": Phase="Running", Reason="", readiness=true. Elapsed: 4.055926409s
Oct  1 17:40:06.663: INFO: Pod "e2e-test-nginx-rc-465zx" satisfied condition "running and ready"
Oct  1 17:40:06.663: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-465zx]
Oct  1 17:40:06.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 logs rc/e2e-test-nginx-rc --namespace=kubectl-4709'
Oct  1 17:40:06.819: INFO: stderr: ""
Oct  1 17:40:06.819: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1425
Oct  1 17:40:06.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 delete rc e2e-test-nginx-rc --namespace=kubectl-4709'
Oct  1 17:40:06.972: INFO: stderr: ""
Oct  1 17:40:06.972: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:40:06.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4709" for this suite.
Oct  1 17:40:31.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:40:31.345: INFO: namespace kubectl-4709 deletion completed in 24.351987624s

• [SLOW TEST:29.450 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:40:31.346: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-720
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-90a40568-e472-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume configMaps
Oct  1 17:40:31.590: INFO: Waiting up to 5m0s for pod "pod-configmaps-90a59cd9-e472-11e9-afc1-6aca03636ae4" in namespace "configmap-720" to be "success or failure"
Oct  1 17:40:31.606: INFO: Pod "pod-configmaps-90a59cd9-e472-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.530799ms
Oct  1 17:40:33.617: INFO: Pod "pod-configmaps-90a59cd9-e472-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027119121s
Oct  1 17:40:35.630: INFO: Pod "pod-configmaps-90a59cd9-e472-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039598236s
STEP: Saw pod success
Oct  1 17:40:35.630: INFO: Pod "pod-configmaps-90a59cd9-e472-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:40:35.645: INFO: Trying to get logs from node 10.75.67.233 pod pod-configmaps-90a59cd9-e472-11e9-afc1-6aca03636ae4 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 17:40:35.704: INFO: Waiting for pod pod-configmaps-90a59cd9-e472-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:40:35.727: INFO: Pod pod-configmaps-90a59cd9-e472-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:40:35.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-720" for this suite.
Oct  1 17:40:41.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:40:42.490: INFO: namespace configmap-720 deletion completed in 6.752104061s

• [SLOW TEST:11.144 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:40:42.491: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9602
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-974a3b7f-e472-11e9-afc1-6aca03636ae4
STEP: Creating configMap with name cm-test-opt-upd-974a3bd6-e472-11e9-afc1-6aca03636ae4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-974a3b7f-e472-11e9-afc1-6aca03636ae4
STEP: Updating configmap cm-test-opt-upd-974a3bd6-e472-11e9-afc1-6aca03636ae4
STEP: Creating configMap with name cm-test-opt-create-974a3c04-e472-11e9-afc1-6aca03636ae4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:42:14.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9602" for this suite.
Oct  1 17:42:38.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:42:38.978: INFO: namespace projected-9602 deletion completed in 24.352380589s

• [SLOW TEST:116.487 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:42:38.979: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4120
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-4120
Oct  1 17:42:41.236: INFO: Started pod liveness-http in namespace container-probe-4120
STEP: checking the pod's current state and verifying that restartCount is present
Oct  1 17:42:41.250: INFO: Initial restart count of pod liveness-http is 0
Oct  1 17:42:53.332: INFO: Restart count of pod container-probe-4120/liveness-http is now 1 (12.081998607s elapsed)
Oct  1 17:43:13.472: INFO: Restart count of pod container-probe-4120/liveness-http is now 2 (32.221938924s elapsed)
Oct  1 17:43:33.815: INFO: Restart count of pod container-probe-4120/liveness-http is now 3 (52.565149273s elapsed)
Oct  1 17:43:53.949: INFO: Restart count of pod container-probe-4120/liveness-http is now 4 (1m12.699091535s elapsed)
Oct  1 17:44:52.336: INFO: Restart count of pod container-probe-4120/liveness-http is now 5 (2m11.085979615s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:44:52.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4120" for this suite.
Oct  1 17:44:58.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:44:58.735: INFO: namespace container-probe-4120 deletion completed in 6.345822002s

• [SLOW TEST:139.757 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:44:58.737: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7622
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-7622
Oct  1 17:45:03.032: INFO: Started pod liveness-http in namespace container-probe-7622
STEP: checking the pod's current state and verifying that restartCount is present
Oct  1 17:45:03.044: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:49:05.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7622" for this suite.
Oct  1 17:49:11.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:49:11.476: INFO: namespace container-probe-7622 deletion completed in 6.389688594s

• [SLOW TEST:252.739 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:49:11.478: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-851
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1001 17:49:51.803246      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct  1 17:49:51.803: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:49:51.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-851" for this suite.
Oct  1 17:49:59.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:50:00.199: INFO: namespace gc-851 deletion completed in 8.385693185s

• [SLOW TEST:48.721 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:50:00.200: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2501
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:50:04.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2501" for this suite.
Oct  1 17:50:50.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:50:51.317: INFO: namespace kubelet-test-2501 deletion completed in 46.76969178s

• [SLOW TEST:51.117 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:50:51.317: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5913
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-022c44df-e474-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume configMaps
Oct  1 17:50:51.896: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-025f76e3-e474-11e9-afc1-6aca03636ae4" in namespace "projected-5913" to be "success or failure"
Oct  1 17:50:51.956: INFO: Pod "pod-projected-configmaps-025f76e3-e474-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 59.856275ms
Oct  1 17:50:53.979: INFO: Pod "pod-projected-configmaps-025f76e3-e474-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.082952605s
STEP: Saw pod success
Oct  1 17:50:53.979: INFO: Pod "pod-projected-configmaps-025f76e3-e474-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:50:53.993: INFO: Trying to get logs from node 10.75.67.242 pod pod-projected-configmaps-025f76e3-e474-11e9-afc1-6aca03636ae4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 17:50:54.064: INFO: Waiting for pod pod-projected-configmaps-025f76e3-e474-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:50:54.075: INFO: Pod pod-projected-configmaps-025f76e3-e474-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:50:54.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5913" for this suite.
Oct  1 17:51:00.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:51:00.499: INFO: namespace projected-5913 deletion completed in 6.4117365s

• [SLOW TEST:9.182 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:51:00.500: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-157
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 17:51:00.733: INFO: Waiting up to 5m0s for pod "downwardapi-volume-07a56ad6-e474-11e9-afc1-6aca03636ae4" in namespace "projected-157" to be "success or failure"
Oct  1 17:51:00.750: INFO: Pod "downwardapi-volume-07a56ad6-e474-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.34866ms
Oct  1 17:51:02.765: INFO: Pod "downwardapi-volume-07a56ad6-e474-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031835596s
STEP: Saw pod success
Oct  1 17:51:02.765: INFO: Pod "downwardapi-volume-07a56ad6-e474-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:51:02.784: INFO: Trying to get logs from node 10.75.67.233 pod downwardapi-volume-07a56ad6-e474-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 17:51:02.855: INFO: Waiting for pod downwardapi-volume-07a56ad6-e474-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:51:02.875: INFO: Pod downwardapi-volume-07a56ad6-e474-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:51:02.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-157" for this suite.
Oct  1 17:51:08.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:51:09.307: INFO: namespace projected-157 deletion completed in 6.417452889s

• [SLOW TEST:8.807 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:51:09.307: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5583
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 17:51:09.564: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0ce82d8e-e474-11e9-afc1-6aca03636ae4" in namespace "downward-api-5583" to be "success or failure"
Oct  1 17:51:09.583: INFO: Pod "downwardapi-volume-0ce82d8e-e474-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.615967ms
Oct  1 17:51:11.594: INFO: Pod "downwardapi-volume-0ce82d8e-e474-11e9-afc1-6aca03636ae4": Phase="Running", Reason="", readiness=true. Elapsed: 2.029565477s
Oct  1 17:51:13.604: INFO: Pod "downwardapi-volume-0ce82d8e-e474-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03974982s
STEP: Saw pod success
Oct  1 17:51:13.604: INFO: Pod "downwardapi-volume-0ce82d8e-e474-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:51:13.618: INFO: Trying to get logs from node 10.75.67.242 pod downwardapi-volume-0ce82d8e-e474-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 17:51:13.691: INFO: Waiting for pod downwardapi-volume-0ce82d8e-e474-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:51:13.704: INFO: Pod downwardapi-volume-0ce82d8e-e474-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:51:13.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5583" for this suite.
Oct  1 17:51:19.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:51:20.104: INFO: namespace downward-api-5583 deletion completed in 6.383364379s

• [SLOW TEST:10.797 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:51:20.105: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6092
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct  1 17:51:20.319: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  1 17:51:20.342: INFO: Waiting for terminating namespaces to be deleted...
Oct  1 17:51:20.365: INFO: 
Logging pods the kubelet thinks is on node 10.75.67.233 before test
Oct  1 17:51:20.395: INFO: ibm-kube-fluentd-b2lqr from kube-system started at 2019-10-01 15:16:10 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.395: INFO: 	Container fluentd ready: true, restart count 0
Oct  1 17:51:20.395: INFO: coredns-9dd7747c7-gkhfw from kube-system started at 2019-10-01 15:26:45 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.395: INFO: 	Container coredns ready: true, restart count 0
Oct  1 17:51:20.395: INFO: sonobuoy-systemd-logs-daemon-set-4416e0333c0e4618-j5sjs from sonobuoy started at 2019-10-01 16:28:13 +0000 UTC (2 container statuses recorded)
Oct  1 17:51:20.395: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  1 17:51:20.395: INFO: 	Container systemd-logs ready: true, restart count 1
Oct  1 17:51:20.395: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-10-01 15:17:25 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.395: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Oct  1 17:51:20.395: INFO: ibm-master-proxy-static-10.75.67.233 from kube-system started at <nil> (0 container statuses recorded)
Oct  1 17:51:20.395: INFO: ibm-keepalived-watcher-xrgfc from kube-system started at 2019-10-01 15:16:10 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.395: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  1 17:51:20.395: INFO: vpn-7754bb6d4-wzqkn from kube-system started at 2019-10-01 15:26:22 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.395: INFO: 	Container vpn ready: true, restart count 0
Oct  1 17:51:20.395: INFO: calico-node-7zx9m from kube-system started at 2019-10-01 15:16:10 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.395: INFO: 	Container calico-node ready: true, restart count 0
Oct  1 17:51:20.395: INFO: sonobuoy from sonobuoy started at 2019-10-01 16:28:06 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.395: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  1 17:51:20.395: INFO: 
Logging pods the kubelet thinks is on node 10.75.67.237 before test
Oct  1 17:51:20.461: INFO: calico-node-d22c5 from kube-system started at 2019-10-01 15:02:53 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.461: INFO: 	Container calico-node ready: true, restart count 0
Oct  1 17:51:20.461: INFO: kubernetes-dashboard-5c8c9b7546-7f6fb from kube-system started at 2019-10-01 15:03:07 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.461: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct  1 17:51:20.461: INFO: coredns-autoscaler-5d4db8dd68-kkf9n from kube-system started at 2019-10-01 15:03:07 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.461: INFO: 	Container autoscaler ready: true, restart count 0
Oct  1 17:51:20.461: INFO: ibm-file-plugin-6b897f87c5-mqm42 from kube-system started at 2019-10-01 15:03:07 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.461: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct  1 17:51:20.461: INFO: ibm-kube-fluentd-dqt6z from kube-system started at 2019-10-01 15:03:20 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.461: INFO: 	Container fluentd ready: true, restart count 0
Oct  1 17:51:20.461: INFO: calico-kube-controllers-65f9c6c467-crfkj from kube-system started at 2019-10-01 15:03:07 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.461: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct  1 17:51:20.461: INFO: ibm-master-proxy-static-10.75.67.237 from kube-system started at <nil> (0 container statuses recorded)
Oct  1 17:51:20.461: INFO: ibm-storage-watcher-7457b8d444-gqm86 from kube-system started at 2019-10-01 15:03:07 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.461: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct  1 17:51:20.461: INFO: public-crbm9mdfvf0mdrp87rqprg-alb1-7bb44dd846-7zr89 from kube-system started at 2019-10-01 15:06:59 +0000 UTC (4 container statuses recorded)
Oct  1 17:51:20.461: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct  1 17:51:20.461: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct  1 17:51:20.461: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct  1 17:51:20.461: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct  1 17:51:20.461: INFO: coredns-9dd7747c7-psmnx from kube-system started at 2019-10-01 15:26:45 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.461: INFO: 	Container coredns ready: true, restart count 0
Oct  1 17:51:20.461: INFO: ibm-keepalived-watcher-ngkdv from kube-system started at 2019-10-01 15:02:53 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.461: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  1 17:51:20.461: INFO: metrics-server-6758dc85bb-gjn98 from kube-system started at 2019-10-01 15:03:37 +0000 UTC (2 container statuses recorded)
Oct  1 17:51:20.461: INFO: 	Container metrics-server ready: true, restart count 0
Oct  1 17:51:20.461: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct  1 17:51:20.461: INFO: ibm-cloud-provider-ip-161-156-139-203-7c5c6496c4-rdbdn from ibm-system started at 2019-10-01 15:05:51 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.461: INFO: 	Container ibm-cloud-provider-ip-161-156-139-203 ready: true, restart count 0
Oct  1 17:51:20.461: INFO: sonobuoy-e2e-job-12cb5697b8cf4781 from sonobuoy started at 2019-10-01 16:28:13 +0000 UTC (2 container statuses recorded)
Oct  1 17:51:20.461: INFO: 	Container e2e ready: true, restart count 0
Oct  1 17:51:20.461: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  1 17:51:20.461: INFO: sonobuoy-systemd-logs-daemon-set-4416e0333c0e4618-8x5jn from sonobuoy started at 2019-10-01 16:28:13 +0000 UTC (2 container statuses recorded)
Oct  1 17:51:20.461: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  1 17:51:20.461: INFO: 	Container systemd-logs ready: true, restart count 1
Oct  1 17:51:20.461: INFO: 
Logging pods the kubelet thinks is on node 10.75.67.242 before test
Oct  1 17:51:20.488: INFO: public-crbm9mdfvf0mdrp87rqprg-alb1-7bb44dd846-cgfj7 from kube-system started at 2019-10-01 15:06:59 +0000 UTC (4 container statuses recorded)
Oct  1 17:51:20.488: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct  1 17:51:20.488: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct  1 17:51:20.488: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct  1 17:51:20.488: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct  1 17:51:20.488: INFO: ibm-master-proxy-static-10.75.67.242 from kube-system started at <nil> (0 container statuses recorded)
Oct  1 17:51:20.488: INFO: ibm-keepalived-watcher-5g457 from kube-system started at 2019-10-01 15:03:51 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.488: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct  1 17:51:20.488: INFO: ibm-cloud-provider-ip-161-156-139-203-7c5c6496c4-tzjcr from ibm-system started at 2019-10-01 15:05:51 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.488: INFO: 	Container ibm-cloud-provider-ip-161-156-139-203 ready: true, restart count 0
Oct  1 17:51:20.488: INFO: ibm-kube-fluentd-7q4bx from kube-system started at 2019-10-01 15:03:51 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.488: INFO: 	Container fluentd ready: true, restart count 0
Oct  1 17:51:20.488: INFO: calico-node-hb58q from kube-system started at 2019-10-01 15:03:51 +0000 UTC (1 container statuses recorded)
Oct  1 17:51:20.488: INFO: 	Container calico-node ready: true, restart count 0
Oct  1 17:51:20.488: INFO: sonobuoy-systemd-logs-daemon-set-4416e0333c0e4618-9jgt9 from sonobuoy started at 2019-10-01 16:28:13 +0000 UTC (2 container statuses recorded)
Oct  1 17:51:20.488: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  1 17:51:20.488: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-15ddf709-e474-11e9-afc1-6aca03636ae4 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-15ddf709-e474-11e9-afc1-6aca03636ae4 off the node 10.75.67.233
STEP: verifying the node doesn't have the label kubernetes.io/e2e-15ddf709-e474-11e9-afc1-6aca03636ae4
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:51:28.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6092" for this suite.
Oct  1 17:51:40.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:51:41.073: INFO: namespace sched-pred-6092 deletion completed in 12.365455446s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:20.968 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:51:41.074: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9201
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-9201
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct  1 17:51:41.291: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct  1 17:51:57.538: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.248.54:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9201 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:51:57.538: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:51:57.756: INFO: Found all expected endpoints: [netserver-0]
Oct  1 17:51:57.765: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.58.93:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9201 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:51:57.765: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:51:57.961: INFO: Found all expected endpoints: [netserver-1]
Oct  1 17:51:57.970: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.31.62:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9201 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:51:57.970: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:51:58.181: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:51:58.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9201" for this suite.
Oct  1 17:52:22.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:52:22.563: INFO: namespace pod-network-test-9201 deletion completed in 24.368734398s

• [SLOW TEST:41.489 seconds]
[sig-network] Networking
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:52:22.568: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6877
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Oct  1 17:52:22.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 create -f - --namespace=kubectl-6877'
Oct  1 17:52:23.080: INFO: stderr: ""
Oct  1 17:52:23.080: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct  1 17:52:24.093: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 17:52:24.093: INFO: Found 0 / 1
Oct  1 17:52:25.089: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 17:52:25.089: INFO: Found 1 / 1
Oct  1 17:52:25.089: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Oct  1 17:52:25.100: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 17:52:25.100: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct  1 17:52:25.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 patch pod redis-master-r6mz5 --namespace=kubectl-6877 -p {"metadata":{"annotations":{"x":"y"}}}'
Oct  1 17:52:25.214: INFO: stderr: ""
Oct  1 17:52:25.214: INFO: stdout: "pod/redis-master-r6mz5 patched\n"
STEP: checking annotations
Oct  1 17:52:25.224: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 17:52:25.224: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:52:25.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6877" for this suite.
Oct  1 17:52:49.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:52:49.962: INFO: namespace kubectl-6877 deletion completed in 24.722038441s

• [SLOW TEST:27.393 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:52:49.962: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7931
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7931.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7931.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7931.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7931.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7931.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7931.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7931.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7931.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7931.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7931.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7931.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 21.167.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.167.21_udp@PTR;check="$$(dig +tcp +noall +answer +search 21.167.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.167.21_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7931.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7931.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7931.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7931.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7931.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7931.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7931.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7931.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7931.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7931.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7931.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 21.167.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.167.21_udp@PTR;check="$$(dig +tcp +noall +answer +search 21.167.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.167.21_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  1 17:52:54.304: INFO: Unable to read wheezy_udp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:52:54.332: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:52:54.347: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:52:54.361: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:52:54.456: INFO: Unable to read jessie_udp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:52:54.469: INFO: Unable to read jessie_tcp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:52:54.482: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:52:54.497: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:52:54.577: INFO: Lookups using dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4 failed for: [wheezy_udp@dns-test-service.dns-7931.svc.cluster.local wheezy_tcp@dns-test-service.dns-7931.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local jessie_udp@dns-test-service.dns-7931.svc.cluster.local jessie_tcp@dns-test-service.dns-7931.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local]

Oct  1 17:52:59.595: INFO: Unable to read wheezy_udp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:52:59.613: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:52:59.626: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:52:59.642: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:52:59.737: INFO: Unable to read jessie_udp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:52:59.750: INFO: Unable to read jessie_tcp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:52:59.767: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:52:59.788: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:52:59.884: INFO: Lookups using dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4 failed for: [wheezy_udp@dns-test-service.dns-7931.svc.cluster.local wheezy_tcp@dns-test-service.dns-7931.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local jessie_udp@dns-test-service.dns-7931.svc.cluster.local jessie_tcp@dns-test-service.dns-7931.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local]

Oct  1 17:53:04.594: INFO: Unable to read wheezy_udp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:04.613: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:04.629: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:04.645: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:04.851: INFO: Unable to read jessie_udp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:04.870: INFO: Unable to read jessie_tcp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:04.889: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:04.911: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:05.018: INFO: Lookups using dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4 failed for: [wheezy_udp@dns-test-service.dns-7931.svc.cluster.local wheezy_tcp@dns-test-service.dns-7931.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local jessie_udp@dns-test-service.dns-7931.svc.cluster.local jessie_tcp@dns-test-service.dns-7931.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local]

Oct  1 17:53:09.599: INFO: Unable to read wheezy_udp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:09.612: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:09.625: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:09.641: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:09.747: INFO: Unable to read jessie_udp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:09.762: INFO: Unable to read jessie_tcp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:09.776: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:09.794: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:09.900: INFO: Lookups using dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4 failed for: [wheezy_udp@dns-test-service.dns-7931.svc.cluster.local wheezy_tcp@dns-test-service.dns-7931.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local jessie_udp@dns-test-service.dns-7931.svc.cluster.local jessie_tcp@dns-test-service.dns-7931.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local]

Oct  1 17:53:14.593: INFO: Unable to read wheezy_udp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:14.617: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:14.633: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:14.664: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:14.806: INFO: Unable to read jessie_udp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:14.824: INFO: Unable to read jessie_tcp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:14.852: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:14.876: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:15.015: INFO: Lookups using dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4 failed for: [wheezy_udp@dns-test-service.dns-7931.svc.cluster.local wheezy_tcp@dns-test-service.dns-7931.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local jessie_udp@dns-test-service.dns-7931.svc.cluster.local jessie_tcp@dns-test-service.dns-7931.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local]

Oct  1 17:53:19.596: INFO: Unable to read wheezy_udp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:19.609: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:19.624: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:19.646: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:19.833: INFO: Unable to read jessie_udp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:19.849: INFO: Unable to read jessie_tcp@dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:19.865: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:19.880: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local from pod dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4: the server could not find the requested resource (get pods dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4)
Oct  1 17:53:19.975: INFO: Lookups using dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4 failed for: [wheezy_udp@dns-test-service.dns-7931.svc.cluster.local wheezy_tcp@dns-test-service.dns-7931.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local jessie_udp@dns-test-service.dns-7931.svc.cluster.local jessie_tcp@dns-test-service.dns-7931.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7931.svc.cluster.local]

Oct  1 17:53:24.935: INFO: DNS probes using dns-7931/dns-test-48ea639e-e474-11e9-afc1-6aca03636ae4 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:53:25.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7931" for this suite.
Oct  1 17:53:31.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:53:31.554: INFO: namespace dns-7931 deletion completed in 6.434660699s

• [SLOW TEST:41.592 seconds]
[sig-network] DNS
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:53:31.557: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8378
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-8378
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8378 to expose endpoints map[]
Oct  1 17:53:31.820: INFO: Get endpoints failed (12.285235ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Oct  1 17:53:32.830: INFO: successfully validated that service endpoint-test2 in namespace services-8378 exposes endpoints map[] (1.022332525s elapsed)
STEP: Creating pod pod1 in namespace services-8378
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8378 to expose endpoints map[pod1:[80]]
Oct  1 17:53:34.916: INFO: successfully validated that service endpoint-test2 in namespace services-8378 exposes endpoints map[pod1:[80]] (2.067053871s elapsed)
STEP: Creating pod pod2 in namespace services-8378
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8378 to expose endpoints map[pod1:[80] pod2:[80]]
Oct  1 17:53:38.066: INFO: successfully validated that service endpoint-test2 in namespace services-8378 exposes endpoints map[pod1:[80] pod2:[80]] (3.139891146s elapsed)
STEP: Deleting pod pod1 in namespace services-8378
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8378 to expose endpoints map[pod2:[80]]
Oct  1 17:53:38.112: INFO: successfully validated that service endpoint-test2 in namespace services-8378 exposes endpoints map[pod2:[80]] (24.941128ms elapsed)
STEP: Deleting pod pod2 in namespace services-8378
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8378 to expose endpoints map[]
Oct  1 17:53:38.146: INFO: successfully validated that service endpoint-test2 in namespace services-8378 exposes endpoints map[] (14.938265ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:53:38.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8378" for this suite.
Oct  1 17:53:44.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:53:44.735: INFO: namespace services-8378 deletion completed in 6.522966386s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:13.179 seconds]
[sig-network] Services
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:53:44.736: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8422
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct  1 17:53:44.976: INFO: Waiting up to 5m0s for pod "pod-698ac408-e474-11e9-afc1-6aca03636ae4" in namespace "emptydir-8422" to be "success or failure"
Oct  1 17:53:44.993: INFO: Pod "pod-698ac408-e474-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 17.246232ms
Oct  1 17:53:47.009: INFO: Pod "pod-698ac408-e474-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033087965s
Oct  1 17:53:49.019: INFO: Pod "pod-698ac408-e474-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042947378s
STEP: Saw pod success
Oct  1 17:53:49.019: INFO: Pod "pod-698ac408-e474-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:53:49.035: INFO: Trying to get logs from node 10.75.67.242 pod pod-698ac408-e474-11e9-afc1-6aca03636ae4 container test-container: <nil>
STEP: delete the pod
Oct  1 17:53:49.103: INFO: Waiting for pod pod-698ac408-e474-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:53:49.116: INFO: Pod pod-698ac408-e474-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:53:49.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8422" for this suite.
Oct  1 17:53:55.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:53:55.623: INFO: namespace emptydir-8422 deletion completed in 6.494503882s

• [SLOW TEST:10.887 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:53:55.628: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8157
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1174
STEP: creating the pod
Oct  1 17:53:55.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 create -f - --namespace=kubectl-8157'
Oct  1 17:53:56.120: INFO: stderr: ""
Oct  1 17:53:56.120: INFO: stdout: "pod/pause created\n"
Oct  1 17:53:56.120: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct  1 17:53:56.120: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8157" to be "running and ready"
Oct  1 17:53:56.133: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 13.119171ms
Oct  1 17:53:58.143: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.022677608s
Oct  1 17:53:58.143: INFO: Pod "pause" satisfied condition "running and ready"
Oct  1 17:53:58.143: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Oct  1 17:53:58.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 label pods pause testing-label=testing-label-value --namespace=kubectl-8157'
Oct  1 17:53:58.278: INFO: stderr: ""
Oct  1 17:53:58.278: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Oct  1 17:53:58.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pod pause -L testing-label --namespace=kubectl-8157'
Oct  1 17:53:58.387: INFO: stderr: ""
Oct  1 17:53:58.387: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Oct  1 17:53:58.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 label pods pause testing-label- --namespace=kubectl-8157'
Oct  1 17:53:58.520: INFO: stderr: ""
Oct  1 17:53:58.520: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Oct  1 17:53:58.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pod pause -L testing-label --namespace=kubectl-8157'
Oct  1 17:53:58.632: INFO: stderr: ""
Oct  1 17:53:58.633: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1181
STEP: using delete to clean up resources
Oct  1 17:53:58.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 delete --grace-period=0 --force -f - --namespace=kubectl-8157'
Oct  1 17:53:58.793: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 17:53:58.793: INFO: stdout: "pod \"pause\" force deleted\n"
Oct  1 17:53:58.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get rc,svc -l name=pause --no-headers --namespace=kubectl-8157'
Oct  1 17:53:58.913: INFO: stderr: "No resources found.\n"
Oct  1 17:53:58.913: INFO: stdout: ""
Oct  1 17:53:58.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -l name=pause --namespace=kubectl-8157 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  1 17:53:59.017: INFO: stderr: ""
Oct  1 17:53:59.017: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:53:59.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8157" for this suite.
Oct  1 17:54:05.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:54:05.527: INFO: namespace kubectl-8157 deletion completed in 6.496749986s

• [SLOW TEST:9.899 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:54:05.527: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-1386
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:54:07.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1386" for this suite.
Oct  1 17:54:13.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:54:14.429: INFO: namespace emptydir-wrapper-1386 deletion completed in 6.472587385s

• [SLOW TEST:8.902 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:54:14.430: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2105
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 17:54:14.766: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Oct  1 17:54:14.784: INFO: Number of nodes with available pods: 0
Oct  1 17:54:14.784: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Oct  1 17:54:14.844: INFO: Number of nodes with available pods: 0
Oct  1 17:54:14.844: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 17:54:15.855: INFO: Number of nodes with available pods: 0
Oct  1 17:54:15.855: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 17:54:16.857: INFO: Number of nodes with available pods: 0
Oct  1 17:54:16.857: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 17:54:17.858: INFO: Number of nodes with available pods: 1
Oct  1 17:54:17.858: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Oct  1 17:54:17.912: INFO: Number of nodes with available pods: 1
Oct  1 17:54:17.912: INFO: Number of running nodes: 0, number of available pods: 1
Oct  1 17:54:18.923: INFO: Number of nodes with available pods: 0
Oct  1 17:54:18.923: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Oct  1 17:54:18.943: INFO: Number of nodes with available pods: 0
Oct  1 17:54:18.943: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 17:54:19.952: INFO: Number of nodes with available pods: 0
Oct  1 17:54:19.953: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 17:54:20.952: INFO: Number of nodes with available pods: 0
Oct  1 17:54:20.952: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 17:54:21.957: INFO: Number of nodes with available pods: 0
Oct  1 17:54:21.957: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 17:54:22.952: INFO: Number of nodes with available pods: 0
Oct  1 17:54:22.952: INFO: Node 10.75.67.233 is running more than one daemon pod
Oct  1 17:54:23.952: INFO: Number of nodes with available pods: 1
Oct  1 17:54:23.952: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2105, will wait for the garbage collector to delete the pods
Oct  1 17:54:24.039: INFO: Deleting DaemonSet.extensions daemon-set took: 16.06956ms
Oct  1 17:54:24.139: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.248523ms
Oct  1 17:54:27.154: INFO: Number of nodes with available pods: 0
Oct  1 17:54:27.154: INFO: Number of running nodes: 0, number of available pods: 0
Oct  1 17:54:27.161: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2105/daemonsets","resourceVersion":"40940"},"items":null}

Oct  1 17:54:27.171: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2105/pods","resourceVersion":"40940"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:54:27.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2105" for this suite.
Oct  1 17:54:33.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:54:33.599: INFO: namespace daemonsets-2105 deletion completed in 6.345359795s

• [SLOW TEST:19.169 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:54:33.599: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5561
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-86aa5f2c-e474-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume configMaps
Oct  1 17:54:33.851: INFO: Waiting up to 5m0s for pod "pod-configmaps-86ac0ee2-e474-11e9-afc1-6aca03636ae4" in namespace "configmap-5561" to be "success or failure"
Oct  1 17:54:33.874: INFO: Pod "pod-configmaps-86ac0ee2-e474-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 22.193858ms
Oct  1 17:54:35.885: INFO: Pod "pod-configmaps-86ac0ee2-e474-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033841572s
Oct  1 17:54:37.911: INFO: Pod "pod-configmaps-86ac0ee2-e474-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0596335s
STEP: Saw pod success
Oct  1 17:54:37.911: INFO: Pod "pod-configmaps-86ac0ee2-e474-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:54:37.925: INFO: Trying to get logs from node 10.75.67.233 pod pod-configmaps-86ac0ee2-e474-11e9-afc1-6aca03636ae4 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 17:54:37.984: INFO: Waiting for pod pod-configmaps-86ac0ee2-e474-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:54:37.992: INFO: Pod pod-configmaps-86ac0ee2-e474-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:54:37.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5561" for this suite.
Oct  1 17:54:44.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:54:44.364: INFO: namespace configmap-5561 deletion completed in 6.358478729s

• [SLOW TEST:10.765 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:54:44.365: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-292
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Oct  1 17:54:45.146: INFO: created pod pod-service-account-defaultsa
Oct  1 17:54:45.146: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct  1 17:54:45.162: INFO: created pod pod-service-account-mountsa
Oct  1 17:54:45.162: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct  1 17:54:45.174: INFO: created pod pod-service-account-nomountsa
Oct  1 17:54:45.174: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct  1 17:54:45.186: INFO: created pod pod-service-account-defaultsa-mountspec
Oct  1 17:54:45.186: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct  1 17:54:45.199: INFO: created pod pod-service-account-mountsa-mountspec
Oct  1 17:54:45.199: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct  1 17:54:45.209: INFO: created pod pod-service-account-nomountsa-mountspec
Oct  1 17:54:45.209: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct  1 17:54:45.221: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct  1 17:54:45.221: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct  1 17:54:45.232: INFO: created pod pod-service-account-mountsa-nomountspec
Oct  1 17:54:45.232: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct  1 17:54:45.244: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct  1 17:54:45.244: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:54:45.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-292" for this suite.
Oct  1 17:54:51.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:54:51.663: INFO: namespace svcaccounts-292 deletion completed in 6.378339378s

• [SLOW TEST:7.298 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:54:51.663: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7769
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Oct  1 17:54:51.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 create -f - --namespace=kubectl-7769'
Oct  1 17:54:52.109: INFO: stderr: ""
Oct  1 17:54:52.109: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  1 17:54:52.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7769'
Oct  1 17:54:52.219: INFO: stderr: ""
Oct  1 17:54:52.219: INFO: stdout: "update-demo-nautilus-7n5vx update-demo-nautilus-zt9gt "
Oct  1 17:54:52.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-7n5vx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7769'
Oct  1 17:54:52.328: INFO: stderr: ""
Oct  1 17:54:52.328: INFO: stdout: ""
Oct  1 17:54:52.328: INFO: update-demo-nautilus-7n5vx is created but not running
Oct  1 17:54:57.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7769'
Oct  1 17:54:57.442: INFO: stderr: ""
Oct  1 17:54:57.442: INFO: stdout: "update-demo-nautilus-7n5vx update-demo-nautilus-zt9gt "
Oct  1 17:54:57.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-7n5vx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7769'
Oct  1 17:54:57.558: INFO: stderr: ""
Oct  1 17:54:57.558: INFO: stdout: "true"
Oct  1 17:54:57.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-7n5vx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7769'
Oct  1 17:54:57.669: INFO: stderr: ""
Oct  1 17:54:57.669: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 17:54:57.669: INFO: validating pod update-demo-nautilus-7n5vx
Oct  1 17:54:57.686: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 17:54:57.686: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 17:54:57.686: INFO: update-demo-nautilus-7n5vx is verified up and running
Oct  1 17:54:57.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-zt9gt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7769'
Oct  1 17:54:57.829: INFO: stderr: ""
Oct  1 17:54:57.830: INFO: stdout: "true"
Oct  1 17:54:57.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods update-demo-nautilus-zt9gt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7769'
Oct  1 17:54:57.939: INFO: stderr: ""
Oct  1 17:54:57.939: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 17:54:57.939: INFO: validating pod update-demo-nautilus-zt9gt
Oct  1 17:54:57.958: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 17:54:57.959: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 17:54:57.959: INFO: update-demo-nautilus-zt9gt is verified up and running
STEP: using delete to clean up resources
Oct  1 17:54:57.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 delete --grace-period=0 --force -f - --namespace=kubectl-7769'
Oct  1 17:54:58.082: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 17:54:58.082: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct  1 17:54:58.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7769'
Oct  1 17:54:58.203: INFO: stderr: "No resources found.\n"
Oct  1 17:54:58.203: INFO: stdout: ""
Oct  1 17:54:58.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 get pods -l name=update-demo --namespace=kubectl-7769 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  1 17:54:58.297: INFO: stderr: ""
Oct  1 17:54:58.297: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:54:58.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7769" for this suite.
Oct  1 17:55:22.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:55:22.664: INFO: namespace kubectl-7769 deletion completed in 24.353831875s

• [SLOW TEST:31.001 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:55:22.665: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6422
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:55:22.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6422" for this suite.
Oct  1 17:55:28.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:55:29.245: INFO: namespace services-6422 deletion completed in 6.349866511s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.580 seconds]
[sig-network] Services
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:55:29.245: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-527
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 17:55:29.512: INFO: (0) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.998015ms)
Oct  1 17:55:29.527: INFO: (1) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.808665ms)
Oct  1 17:55:29.541: INFO: (2) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.750604ms)
Oct  1 17:55:29.556: INFO: (3) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.432666ms)
Oct  1 17:55:29.572: INFO: (4) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.723558ms)
Oct  1 17:55:29.586: INFO: (5) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.805067ms)
Oct  1 17:55:29.599: INFO: (6) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.438516ms)
Oct  1 17:55:29.615: INFO: (7) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.289444ms)
Oct  1 17:55:29.634: INFO: (8) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 18.271765ms)
Oct  1 17:55:29.649: INFO: (9) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.205602ms)
Oct  1 17:55:29.665: INFO: (10) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.654227ms)
Oct  1 17:55:29.680: INFO: (11) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.066325ms)
Oct  1 17:55:29.696: INFO: (12) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.995609ms)
Oct  1 17:55:29.720: INFO: (13) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.832321ms)
Oct  1 17:55:29.737: INFO: (14) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.136843ms)
Oct  1 17:55:29.752: INFO: (15) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.907465ms)
Oct  1 17:55:29.768: INFO: (16) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.105844ms)
Oct  1 17:55:29.786: INFO: (17) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.869866ms)
Oct  1 17:55:29.799: INFO: (18) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.435361ms)
Oct  1 17:55:29.815: INFO: (19) /api/v1/nodes/10.75.67.233/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.967063ms)
[AfterEach] version v1
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:55:29.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-527" for this suite.
Oct  1 17:55:35.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:55:36.202: INFO: namespace proxy-527 deletion completed in 6.37138583s

• [SLOW TEST:6.957 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:55:36.203: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4114
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct  1 17:55:36.479: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ac0103e2-e474-11e9-afc1-6aca03636ae4" in namespace "downward-api-4114" to be "success or failure"
Oct  1 17:55:36.489: INFO: Pod "downwardapi-volume-ac0103e2-e474-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.933059ms
Oct  1 17:55:38.499: INFO: Pod "downwardapi-volume-ac0103e2-e474-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020435197s
STEP: Saw pod success
Oct  1 17:55:38.500: INFO: Pod "downwardapi-volume-ac0103e2-e474-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:55:38.509: INFO: Trying to get logs from node 10.75.67.233 pod downwardapi-volume-ac0103e2-e474-11e9-afc1-6aca03636ae4 container client-container: <nil>
STEP: delete the pod
Oct  1 17:55:38.569: INFO: Waiting for pod downwardapi-volume-ac0103e2-e474-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:55:38.582: INFO: Pod downwardapi-volume-ac0103e2-e474-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:55:38.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4114" for this suite.
Oct  1 17:55:44.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:55:44.977: INFO: namespace downward-api-4114 deletion completed in 6.378276136s

• [SLOW TEST:8.774 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:55:44.977: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9936
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1001 17:55:46.355986      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct  1 17:55:46.356: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:55:46.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9936" for this suite.
Oct  1 17:55:52.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:55:52.856: INFO: namespace gc-9936 deletion completed in 6.478616119s

• [SLOW TEST:7.879 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:55:52.860: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8857
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct  1 17:55:53.109: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:55:56.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8857" for this suite.
Oct  1 17:56:04.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:56:04.845: INFO: namespace init-container-8857 deletion completed in 8.419551642s

• [SLOW TEST:11.986 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:56:04.847: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3296
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 17:56:05.073: INFO: Creating deployment "test-recreate-deployment"
Oct  1 17:56:05.085: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct  1 17:56:05.114: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct  1 17:56:05.128: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705549365, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705549365, loc:(*time.Location)(0x8830120)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"test-recreate-deployment-6566d46b4b\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705549365, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705549365, loc:(*time.Location)(0x8830120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Oct  1 17:56:07.139: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705549365, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705549365, loc:(*time.Location)(0x8830120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705549365, loc:(*time.Location)(0x8830120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705549365, loc:(*time.Location)(0x8830120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6566d46b4b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 17:56:09.137: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct  1 17:56:09.157: INFO: Updating deployment test-recreate-deployment
Oct  1 17:56:09.157: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct  1 17:56:09.273: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-3296,SelfLink:/apis/apps/v1/namespaces/deployment-3296/deployments/test-recreate-deployment,UID:bd0ff098-e474-11e9-bf88-8e83bb394576,ResourceVersion:41610,Generation:2,CreationTimestamp:2019-10-01 17:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-10-01 17:56:09 +0000 UTC 2019-10-01 17:56:09 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-10-01 17:56:09 +0000 UTC 2019-10-01 17:56:05 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-745fb9c84c" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Oct  1 17:56:09.281: INFO: New ReplicaSet "test-recreate-deployment-745fb9c84c" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c,GenerateName:,Namespace:deployment-3296,SelfLink:/apis/apps/v1/namespaces/deployment-3296/replicasets/test-recreate-deployment-745fb9c84c,UID:bf86e27a-e474-11e9-865f-ced8df5791d3,ResourceVersion:41608,Generation:1,CreationTimestamp:2019-10-01 17:56:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment bd0ff098-e474-11e9-bf88-8e83bb394576 0xc0016dd5d7 0xc0016dd5d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct  1 17:56:09.281: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct  1 17:56:09.282: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6566d46b4b,GenerateName:,Namespace:deployment-3296,SelfLink:/apis/apps/v1/namespaces/deployment-3296/replicasets/test-recreate-deployment-6566d46b4b,UID:bd116239-e474-11e9-865f-ced8df5791d3,ResourceVersion:41598,Generation:2,CreationTimestamp:2019-10-01 17:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment bd0ff098-e474-11e9-bf88-8e83bb394576 0xc0016dd507 0xc0016dd508}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct  1 17:56:09.293: INFO: Pod "test-recreate-deployment-745fb9c84c-d4nqb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c-d4nqb,GenerateName:test-recreate-deployment-745fb9c84c-,Namespace:deployment-3296,SelfLink:/api/v1/namespaces/deployment-3296/pods/test-recreate-deployment-745fb9c84c-d4nqb,UID:bf8802d8-e474-11e9-865f-ced8df5791d3,ResourceVersion:41609,Generation:0,CreationTimestamp:2019-10-01 17:56:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-745fb9c84c bf86e27a-e474-11e9-865f-ced8df5791d3 0xc0016dde87 0xc0016dde88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5f5zd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5f5zd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5f5zd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016ddf20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016ddf40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 17:56:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 17:56:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 17:56:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 17:56:09 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.242,PodIP:,StartTime:2019-10-01 17:56:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:56:09.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3296" for this suite.
Oct  1 17:56:15.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:56:15.771: INFO: namespace deployment-3296 deletion completed in 6.45668205s

• [SLOW TEST:10.924 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:56:15.772: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2712
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Oct  1 17:56:15.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 api-versions'
Oct  1 17:56:16.102: INFO: stderr: ""
Oct  1 17:56:16.103: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:56:16.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2712" for this suite.
Oct  1 17:56:22.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:56:22.485: INFO: namespace kubectl-2712 deletion completed in 6.355418245s

• [SLOW TEST:6.713 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:56:22.485: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-557
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct  1 17:56:22.711: INFO: Waiting up to 5m0s for pod "downward-api-c78fbd44-e474-11e9-afc1-6aca03636ae4" in namespace "downward-api-557" to be "success or failure"
Oct  1 17:56:22.721: INFO: Pod "downward-api-c78fbd44-e474-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.426192ms
Oct  1 17:56:24.735: INFO: Pod "downward-api-c78fbd44-e474-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023974368s
STEP: Saw pod success
Oct  1 17:56:24.735: INFO: Pod "downward-api-c78fbd44-e474-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 17:56:24.747: INFO: Trying to get logs from node 10.75.67.233 pod downward-api-c78fbd44-e474-11e9-afc1-6aca03636ae4 container dapi-container: <nil>
STEP: delete the pod
Oct  1 17:56:24.806: INFO: Waiting for pod downward-api-c78fbd44-e474-11e9-afc1-6aca03636ae4 to disappear
Oct  1 17:56:24.824: INFO: Pod downward-api-c78fbd44-e474-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:56:24.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-557" for this suite.
Oct  1 17:56:30.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:56:31.240: INFO: namespace downward-api-557 deletion completed in 6.401307299s

• [SLOW TEST:8.755 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:56:31.241: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4630
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-ccc87d94-e474-11e9-afc1-6aca03636ae4
Oct  1 17:56:31.476: INFO: Pod name my-hostname-basic-ccc87d94-e474-11e9-afc1-6aca03636ae4: Found 0 pods out of 1
Oct  1 17:56:36.489: INFO: Pod name my-hostname-basic-ccc87d94-e474-11e9-afc1-6aca03636ae4: Found 1 pods out of 1
Oct  1 17:56:36.489: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-ccc87d94-e474-11e9-afc1-6aca03636ae4" are running
Oct  1 17:56:36.500: INFO: Pod "my-hostname-basic-ccc87d94-e474-11e9-afc1-6aca03636ae4-hbmlr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-01 17:56:31 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-01 17:56:33 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-01 17:56:33 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-01 17:56:31 +0000 UTC Reason: Message:}])
Oct  1 17:56:36.500: INFO: Trying to dial the pod
Oct  1 17:56:41.547: INFO: Controller my-hostname-basic-ccc87d94-e474-11e9-afc1-6aca03636ae4: Got expected result from replica 1 [my-hostname-basic-ccc87d94-e474-11e9-afc1-6aca03636ae4-hbmlr]: "my-hostname-basic-ccc87d94-e474-11e9-afc1-6aca03636ae4-hbmlr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:56:41.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4630" for this suite.
Oct  1 17:56:47.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:56:47.981: INFO: namespace replication-controller-4630 deletion completed in 6.417619193s

• [SLOW TEST:16.740 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:56:47.981: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8480
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:56:48.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8480" for this suite.
Oct  1 17:57:12.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:57:12.700: INFO: namespace pods-8480 deletion completed in 24.441517243s

• [SLOW TEST:24.719 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:57:12.701: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-3129
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Oct  1 17:57:19.051: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3129 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:57:19.051: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:57:19.263: INFO: Exec stderr: ""
Oct  1 17:57:19.263: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3129 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:57:19.263: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:57:19.469: INFO: Exec stderr: ""
Oct  1 17:57:19.469: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3129 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:57:19.469: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:57:19.679: INFO: Exec stderr: ""
Oct  1 17:57:19.679: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3129 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:57:19.679: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:57:19.879: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Oct  1 17:57:19.879: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3129 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:57:19.879: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:57:20.093: INFO: Exec stderr: ""
Oct  1 17:57:20.093: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3129 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:57:20.093: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:57:20.307: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Oct  1 17:57:20.307: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3129 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:57:20.307: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:57:20.891: INFO: Exec stderr: ""
Oct  1 17:57:20.891: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3129 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:57:20.891: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:57:21.103: INFO: Exec stderr: ""
Oct  1 17:57:21.103: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3129 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:57:21.103: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:57:21.321: INFO: Exec stderr: ""
Oct  1 17:57:21.321: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3129 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 17:57:21.322: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
Oct  1 17:57:21.509: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:57:21.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-3129" for this suite.
Oct  1 17:58:13.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:58:14.674: INFO: namespace e2e-kubelet-etc-hosts-3129 deletion completed in 53.150684207s

• [SLOW TEST:61.974 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:58:14.675: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-204
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1521
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct  1 17:58:14.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-204'
Oct  1 17:58:15.063: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  1 17:58:15.063: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1526
Oct  1 17:58:17.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-589150881 delete deployment e2e-test-nginx-deployment --namespace=kubectl-204'
Oct  1 17:58:17.215: INFO: stderr: ""
Oct  1 17:58:17.215: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:58:17.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-204" for this suite.
Oct  1 17:58:41.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:58:41.608: INFO: namespace kubectl-204 deletion completed in 24.37247732s

• [SLOW TEST:26.933 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:58:41.608: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9808
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct  1 17:58:41.858: INFO: (0) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.252868ms)
Oct  1 17:58:41.876: INFO: (1) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.937478ms)
Oct  1 17:58:41.891: INFO: (2) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.513272ms)
Oct  1 17:58:41.908: INFO: (3) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.02056ms)
Oct  1 17:58:41.923: INFO: (4) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.628841ms)
Oct  1 17:58:41.946: INFO: (5) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.13444ms)
Oct  1 17:58:41.964: INFO: (6) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.564878ms)
Oct  1 17:58:41.979: INFO: (7) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.104359ms)
Oct  1 17:58:41.997: INFO: (8) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 18.035385ms)
Oct  1 17:58:42.013: INFO: (9) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.266917ms)
Oct  1 17:58:42.028: INFO: (10) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.304861ms)
Oct  1 17:58:42.043: INFO: (11) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.710678ms)
Oct  1 17:58:42.061: INFO: (12) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.647416ms)
Oct  1 17:58:42.075: INFO: (13) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.004877ms)
Oct  1 17:58:42.089: INFO: (14) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.306953ms)
Oct  1 17:58:42.107: INFO: (15) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.760382ms)
Oct  1 17:58:42.124: INFO: (16) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.524064ms)
Oct  1 17:58:42.137: INFO: (17) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.497164ms)
Oct  1 17:58:42.155: INFO: (18) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.651718ms)
Oct  1 17:58:42.170: INFO: (19) /api/v1/nodes/10.75.67.233:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.383209ms)
[AfterEach] version v1
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:58:42.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9808" for this suite.
Oct  1 17:58:50.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 17:58:50.556: INFO: namespace proxy-9808 deletion completed in 8.372369041s

• [SLOW TEST:8.948 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 17:58:50.556: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6852
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct  1 17:58:50.760: INFO: PodSpec: initContainers in spec.initContainers
Oct  1 17:59:35.647: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-1fd10303-e475-11e9-afc1-6aca03636ae4", GenerateName:"", Namespace:"init-container-6852", SelfLink:"/api/v1/namespaces/init-container-6852/pods/pod-init-1fd10303-e475-11e9-afc1-6aca03636ae4", UID:"1fd2c873-e475-11e9-bf88-8e83bb394576", ResourceVersion:"42296", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63705549530, loc:(*time.Location)(0x8830120)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"760889611"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-8c89t", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0032d2500), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8c89t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8c89t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8c89t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00303f658), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.75.67.233", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00285c5a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00303f6e0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00303f700)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00303f708), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00303f70c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705549530, loc:(*time.Location)(0x8830120)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705549530, loc:(*time.Location)(0x8830120)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705549530, loc:(*time.Location)(0x8830120)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705549530, loc:(*time.Location)(0x8830120)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.75.67.233", PodIP:"172.30.31.16", StartTime:(*v1.Time)(0xc002976be0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001a3c850)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001a3c8c0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://8f7f5a82b356288a36fe45db9afa3436f7b03776a8933d7a907cf0a99a4e8e05"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002976c40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002976c20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 17:59:35.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6852" for this suite.
Oct  1 17:59:59.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 18:00:00.025: INFO: namespace init-container-6852 deletion completed in 24.361971013s

• [SLOW TEST:69.469 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 18:00:00.026: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-5205
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Oct  1 18:00:02.335: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-493cb198-e475-11e9-afc1-6aca03636ae4,GenerateName:,Namespace:events-5205,SelfLink:/api/v1/namespaces/events-5205/pods/send-events-493cb198-e475-11e9-afc1-6aca03636ae4,UID:493ea326-e475-11e9-bf88-8e83bb394576,ResourceVersion:42378,Generation:0,CreationTimestamp:2019-10-01 18:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 253180382,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tz68c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tz68c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-tz68c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.75.67.242,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a350d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a350f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 18:00:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 18:00:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 18:00:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 18:00:00 +0000 UTC  }],Message:,Reason:,HostIP:10.75.67.242,PodIP:172.30.248.9,StartTime:2019-10-01 18:00:00 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-10-01 18:00:01 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://f1af5251a106d15a60ae5dd94a1cd558a69595619940e5449b9ce774787c7889}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Oct  1 18:00:04.350: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Oct  1 18:00:06.360: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 18:00:06.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5205" for this suite.
Oct  1 18:00:46.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 18:00:47.077: INFO: namespace events-5205 deletion completed in 40.680470351s

• [SLOW TEST:47.052 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 18:00:47.078: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7595
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-65743413-e475-11e9-afc1-6aca03636ae4
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 18:00:51.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7595" for this suite.
Oct  1 18:01:15.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 18:01:16.199: INFO: namespace configmap-7595 deletion completed in 24.4528142s

• [SLOW TEST:29.122 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 18:01:16.200: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-9742
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Oct  1 18:01:16.514: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9742" to be "success or failure"
Oct  1 18:01:16.532: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 17.367253ms
Oct  1 18:01:18.543: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02834547s
Oct  1 18:01:20.556: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041652624s
STEP: Saw pod success
Oct  1 18:01:20.556: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Oct  1 18:01:20.565: INFO: Trying to get logs from node 10.75.67.242 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Oct  1 18:01:20.625: INFO: Waiting for pod pod-host-path-test to disappear
Oct  1 18:01:20.643: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 18:01:20.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-9742" for this suite.
Oct  1 18:01:26.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 18:01:27.321: INFO: namespace hostpath-9742 deletion completed in 6.661453785s

• [SLOW TEST:11.122 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 18:01:27.323: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3536
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct  1 18:01:31.692: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  1 18:01:31.705: INFO: Pod pod-with-prestop-http-hook still exists
Oct  1 18:01:33.705: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  1 18:01:33.716: INFO: Pod pod-with-prestop-http-hook still exists
Oct  1 18:01:35.705: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  1 18:01:35.718: INFO: Pod pod-with-prestop-http-hook still exists
Oct  1 18:01:37.705: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  1 18:01:37.720: INFO: Pod pod-with-prestop-http-hook still exists
Oct  1 18:01:39.705: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  1 18:01:39.716: INFO: Pod pod-with-prestop-http-hook still exists
Oct  1 18:01:41.705: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  1 18:01:41.717: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 18:01:41.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3536" for this suite.
Oct  1 18:02:05.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 18:02:06.216: INFO: namespace container-lifecycle-hook-3536 deletion completed in 24.453704003s

• [SLOW TEST:38.893 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 18:02:06.218: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-950
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-9476324f-e475-11e9-afc1-6aca03636ae4
STEP: Creating a pod to test consume secrets
Oct  1 18:02:06.496: INFO: Waiting up to 5m0s for pod "pod-secrets-94783e1a-e475-11e9-afc1-6aca03636ae4" in namespace "secrets-950" to be "success or failure"
Oct  1 18:02:06.508: INFO: Pod "pod-secrets-94783e1a-e475-11e9-afc1-6aca03636ae4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.557533ms
Oct  1 18:02:08.517: INFO: Pod "pod-secrets-94783e1a-e475-11e9-afc1-6aca03636ae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0212983s
STEP: Saw pod success
Oct  1 18:02:08.518: INFO: Pod "pod-secrets-94783e1a-e475-11e9-afc1-6aca03636ae4" satisfied condition "success or failure"
Oct  1 18:02:08.527: INFO: Trying to get logs from node 10.75.67.233 pod pod-secrets-94783e1a-e475-11e9-afc1-6aca03636ae4 container secret-volume-test: <nil>
STEP: delete the pod
Oct  1 18:02:08.593: INFO: Waiting for pod pod-secrets-94783e1a-e475-11e9-afc1-6aca03636ae4 to disappear
Oct  1 18:02:08.620: INFO: Pod pod-secrets-94783e1a-e475-11e9-afc1-6aca03636ae4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 18:02:08.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-950" for this suite.
Oct  1 18:02:14.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 18:02:15.078: INFO: namespace secrets-950 deletion completed in 6.440992869s

• [SLOW TEST:8.860 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 18:02:15.079: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8379
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-zxmw
STEP: Creating a pod to test atomic-volume-subpath
Oct  1 18:02:15.569: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-zxmw" in namespace "subpath-8379" to be "success or failure"
Oct  1 18:02:15.588: INFO: Pod "pod-subpath-test-secret-zxmw": Phase="Pending", Reason="", readiness=false. Elapsed: 18.95664ms
Oct  1 18:02:17.598: INFO: Pod "pod-subpath-test-secret-zxmw": Phase="Running", Reason="", readiness=true. Elapsed: 2.029081148s
Oct  1 18:02:19.611: INFO: Pod "pod-subpath-test-secret-zxmw": Phase="Running", Reason="", readiness=true. Elapsed: 4.042014368s
Oct  1 18:02:21.622: INFO: Pod "pod-subpath-test-secret-zxmw": Phase="Running", Reason="", readiness=true. Elapsed: 6.052435337s
Oct  1 18:02:23.636: INFO: Pod "pod-subpath-test-secret-zxmw": Phase="Running", Reason="", readiness=true. Elapsed: 8.067018387s
Oct  1 18:02:25.647: INFO: Pod "pod-subpath-test-secret-zxmw": Phase="Running", Reason="", readiness=true. Elapsed: 10.077640906s
Oct  1 18:02:27.661: INFO: Pod "pod-subpath-test-secret-zxmw": Phase="Running", Reason="", readiness=true. Elapsed: 12.092350397s
Oct  1 18:02:29.674: INFO: Pod "pod-subpath-test-secret-zxmw": Phase="Running", Reason="", readiness=true. Elapsed: 14.105000205s
Oct  1 18:02:31.732: INFO: Pod "pod-subpath-test-secret-zxmw": Phase="Running", Reason="", readiness=true. Elapsed: 16.162841142s
Oct  1 18:02:33.744: INFO: Pod "pod-subpath-test-secret-zxmw": Phase="Running", Reason="", readiness=true. Elapsed: 18.174919745s
Oct  1 18:02:35.754: INFO: Pod "pod-subpath-test-secret-zxmw": Phase="Running", Reason="", readiness=true. Elapsed: 20.18476929s
Oct  1 18:02:37.771: INFO: Pod "pod-subpath-test-secret-zxmw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.201895795s
STEP: Saw pod success
Oct  1 18:02:37.771: INFO: Pod "pod-subpath-test-secret-zxmw" satisfied condition "success or failure"
Oct  1 18:02:37.797: INFO: Trying to get logs from node 10.75.67.242 pod pod-subpath-test-secret-zxmw container test-container-subpath-secret-zxmw: <nil>
STEP: delete the pod
Oct  1 18:02:37.868: INFO: Waiting for pod pod-subpath-test-secret-zxmw to disappear
Oct  1 18:02:37.882: INFO: Pod pod-subpath-test-secret-zxmw no longer exists
STEP: Deleting pod pod-subpath-test-secret-zxmw
Oct  1 18:02:37.882: INFO: Deleting pod "pod-subpath-test-secret-zxmw" in namespace "subpath-8379"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 18:02:37.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8379" for this suite.
Oct  1 18:02:43.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 18:02:44.317: INFO: namespace subpath-8379 deletion completed in 6.401527984s

• [SLOW TEST:29.238 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 18:02:44.317: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2434
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 18:02:47.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2434" for this suite.
Oct  1 18:03:11.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 18:03:12.205: INFO: namespace replication-controller-2434 deletion completed in 24.426535374s

• [SLOW TEST:27.887 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct  1 18:03:12.206: INFO: >>> kubeConfig: /tmp/kubeconfig-589150881
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3062
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct  1 18:03:40.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3062" for this suite.
Oct  1 18:03:46.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 18:03:46.596: INFO: namespace container-runtime-3062 deletion completed in 6.365568116s

• [SLOW TEST:34.390 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.7-beta.0.37+8fca2ec50a6133/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSOct  1 18:03:46.599: INFO: Running AfterSuite actions on all nodes
Oct  1 18:03:46.599: INFO: Running AfterSuite actions on node 1
Oct  1 18:03:46.599: INFO: Skipping dumping logs from cluster

Ran 204 of 3586 Specs in 5705.422 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3382 Skipped PASS

Ginkgo ran 1 suite in 1h35m6.611225435s
Test Suite Passed
