I0731 11:40:12.985464      19 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-228106623
I0731 11:40:12.985575      19 e2e.go:240] Starting e2e run "f437bc50-b387-11e9-82b5-da5bffca47b9" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1564573211 - Will randomize all specs
Will run 204 of 3586 specs

Jul 31 11:40:13.266: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 11:40:13.268: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jul 31 11:40:13.328: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jul 31 11:40:14.560: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (1 seconds elapsed)
Jul 31 11:40:14.560: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Jul 31 11:40:14.560: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jul 31 11:40:14.964: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Jul 31 11:40:14.972: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'container-linux-update-agent' (0 seconds elapsed)
Jul 31 11:40:14.972: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Jul 31 11:40:14.972: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Jul 31 11:40:14.972: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Jul 31 11:40:14.972: INFO: e2e test version: v1.14.4
Jul 31 11:40:15.153: INFO: kube-apiserver version: v1.14.4
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:40:15.154: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
Jul 31 11:40:16.458: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-f770cfac-b387-11e9-82b5-da5bffca47b9
STEP: Creating configMap with name cm-test-opt-upd-f770cfeb-b387-11e9-82b5-da5bffca47b9
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-f770cfac-b387-11e9-82b5-da5bffca47b9
STEP: Updating configmap cm-test-opt-upd-f770cfeb-b387-11e9-82b5-da5bffca47b9
STEP: Creating configMap with name cm-test-opt-create-f770cffb-b387-11e9-82b5-da5bffca47b9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:41:43.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6806" for this suite.
Jul 31 11:42:06.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:42:10.458: INFO: namespace projected-6806 deletion completed in 26.004298524s

• [SLOW TEST:115.304 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:42:10.458: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-6756
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6756 to expose endpoints map[]
Jul 31 11:42:11.094: INFO: Get endpoints failed (11.78747ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jul 31 11:42:12.458: INFO: successfully validated that service multi-endpoint-test in namespace services-6756 exposes endpoints map[] (1.37509999s elapsed)
STEP: Creating pod pod1 in namespace services-6756
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6756 to expose endpoints map[pod1:[100]]
Jul 31 11:42:17.503: INFO: successfully validated that service multi-endpoint-test in namespace services-6756 exposes endpoints map[pod1:[100]] (5.024351215s elapsed)
STEP: Creating pod pod2 in namespace services-6756
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6756 to expose endpoints map[pod1:[100] pod2:[101]]
Jul 31 11:42:26.253: INFO: successfully validated that service multi-endpoint-test in namespace services-6756 exposes endpoints map[pod1:[100] pod2:[101]] (8.717767318s elapsed)
STEP: Deleting pod pod1 in namespace services-6756
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6756 to expose endpoints map[pod2:[101]]
Jul 31 11:42:26.774: INFO: successfully validated that service multi-endpoint-test in namespace services-6756 exposes endpoints map[pod2:[101]] (121.254858ms elapsed)
STEP: Deleting pod pod2 in namespace services-6756
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6756 to expose endpoints map[]
Jul 31 11:42:26.806: INFO: successfully validated that service multi-endpoint-test in namespace services-6756 exposes endpoints map[] (8.058676ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:42:27.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6756" for this suite.
Jul 31 11:42:49.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:42:54.657: INFO: namespace services-6756 deletion completed in 27.584180693s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:44.199 seconds]
[sig-network] Services
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:42:54.658: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jul 31 11:43:14.465: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6159 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 11:43:14.465: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 11:43:17.025: INFO: Exec stderr: ""
Jul 31 11:43:17.025: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6159 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 11:43:17.025: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 11:43:19.653: INFO: Exec stderr: ""
Jul 31 11:43:19.653: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6159 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 11:43:19.653: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 11:43:24.422: INFO: Exec stderr: ""
Jul 31 11:43:24.422: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6159 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 11:43:24.422: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 11:43:28.353: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jul 31 11:43:28.354: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6159 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 11:43:28.354: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 11:43:33.055: INFO: Exec stderr: ""
Jul 31 11:43:33.055: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6159 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 11:43:33.055: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 11:43:38.321: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jul 31 11:43:38.321: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6159 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 11:43:38.322: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 11:43:42.522: INFO: Exec stderr: ""
Jul 31 11:43:42.522: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6159 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 11:43:42.522: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 11:43:46.153: INFO: Exec stderr: ""
Jul 31 11:43:46.153: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6159 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 11:43:46.153: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 11:43:51.257: INFO: Exec stderr: ""
Jul 31 11:43:51.262: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6159 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 11:43:51.263: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 11:43:55.153: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:43:55.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-6159" for this suite.
Jul 31 11:44:37.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:44:45.859: INFO: namespace e2e-kubelet-etc-hosts-6159 deletion completed in 50.693998102s

• [SLOW TEST:111.201 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:44:45.859: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-98b6a362-b388-11e9-82b5-da5bffca47b9
STEP: Creating secret with name s-test-opt-upd-98b6a3a4-b388-11e9-82b5-da5bffca47b9
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-98b6a362-b388-11e9-82b5-da5bffca47b9
STEP: Updating secret s-test-opt-upd-98b6a3a4-b388-11e9-82b5-da5bffca47b9
STEP: Creating secret with name s-test-opt-create-98b6a3d6-b388-11e9-82b5-da5bffca47b9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:46:13.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4456" for this suite.
Jul 31 11:46:37.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:46:48.553: INFO: namespace secrets-4456 deletion completed in 34.6990702s

• [SLOW TEST:122.694 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:46:48.554: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jul 31 11:47:00.066: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:47:00.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9633" for this suite.
Jul 31 11:47:24.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:47:29.964: INFO: namespace replicaset-9633 deletion completed in 28.309943168s

• [SLOW TEST:41.411 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:47:29.965: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 11:47:31.354: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f9f00ad2-b388-11e9-82b5-da5bffca47b9" in namespace "projected-7563" to be "success or failure"
Jul 31 11:47:31.654: INFO: Pod "downwardapi-volume-f9f00ad2-b388-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 299.798922ms
Jul 31 11:47:33.968: INFO: Pod "downwardapi-volume-f9f00ad2-b388-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.614557676s
Jul 31 11:47:36.157: INFO: Pod "downwardapi-volume-f9f00ad2-b388-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.803474771s
Jul 31 11:47:39.253: INFO: Pod "downwardapi-volume-f9f00ad2-b388-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.899777621s
STEP: Saw pod success
Jul 31 11:47:39.254: INFO: Pod "downwardapi-volume-f9f00ad2-b388-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 11:47:39.261: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod downwardapi-volume-f9f00ad2-b388-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 11:47:39.886: INFO: Waiting for pod downwardapi-volume-f9f00ad2-b388-11e9-82b5-da5bffca47b9 to disappear
Jul 31 11:47:39.895: INFO: Pod downwardapi-volume-f9f00ad2-b388-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:47:39.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7563" for this suite.
Jul 31 11:47:46.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:47:49.961: INFO: namespace projected-7563 deletion completed in 10.053891714s

• [SLOW TEST:19.996 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:47:49.962: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1387
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 31 11:47:50.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-9574'
Jul 31 11:47:54.864: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 31 11:47:54.864: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1393
Jul 31 11:47:55.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 delete deployment e2e-test-nginx-deployment --namespace=kubectl-9574'
Jul 31 11:47:56.356: INFO: stderr: ""
Jul 31 11:47:56.356: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:47:56.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9574" for this suite.
Jul 31 11:48:19.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:48:27.458: INFO: namespace kubectl-9574 deletion completed in 30.771342235s

• [SLOW TEST:37.497 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:48:27.458: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Jul 31 11:48:27.954: INFO: Waiting up to 5m0s for pod "pod-1c219f85-b389-11e9-82b5-da5bffca47b9" in namespace "emptydir-5109" to be "success or failure"
Jul 31 11:48:27.961: INFO: Pod "pod-1c219f85-b389-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.294042ms
Jul 31 11:48:29.969: INFO: Pod "pod-1c219f85-b389-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015230594s
Jul 31 11:48:32.271: INFO: Pod "pod-1c219f85-b389-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.316975985s
Jul 31 11:48:34.558: INFO: Pod "pod-1c219f85-b389-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.604116246s
STEP: Saw pod success
Jul 31 11:48:34.558: INFO: Pod "pod-1c219f85-b389-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 11:48:34.569: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-1c219f85-b389-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 11:48:36.270: INFO: Waiting for pod pod-1c219f85-b389-11e9-82b5-da5bffca47b9 to disappear
Jul 31 11:48:36.284: INFO: Pod pod-1c219f85-b389-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:48:36.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5109" for this suite.
Jul 31 11:48:42.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:48:48.454: INFO: namespace emptydir-5109 deletion completed in 12.15248719s

• [SLOW TEST:20.995 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:48:48.455: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Jul 31 11:48:50.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 create -f - --namespace=kubectl-3085'
Jul 31 11:48:50.857: INFO: stderr: ""
Jul 31 11:48:50.857: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 31 11:48:50.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3085'
Jul 31 11:48:51.626: INFO: stderr: ""
Jul 31 11:48:51.626: INFO: stdout: "update-demo-nautilus-hxgqg update-demo-nautilus-qph8z "
Jul 31 11:48:51.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-hxgqg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3085'
Jul 31 11:48:51.878: INFO: stderr: ""
Jul 31 11:48:51.878: INFO: stdout: ""
Jul 31 11:48:51.878: INFO: update-demo-nautilus-hxgqg is created but not running
Jul 31 11:48:56.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3085'
Jul 31 11:48:57.139: INFO: stderr: ""
Jul 31 11:48:57.139: INFO: stdout: "update-demo-nautilus-hxgqg update-demo-nautilus-qph8z "
Jul 31 11:48:57.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-hxgqg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3085'
Jul 31 11:48:57.524: INFO: stderr: ""
Jul 31 11:48:57.524: INFO: stdout: ""
Jul 31 11:48:57.524: INFO: update-demo-nautilus-hxgqg is created but not running
Jul 31 11:49:02.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3085'
Jul 31 11:49:02.903: INFO: stderr: ""
Jul 31 11:49:02.903: INFO: stdout: "update-demo-nautilus-hxgqg update-demo-nautilus-qph8z "
Jul 31 11:49:02.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-hxgqg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3085'
Jul 31 11:49:03.259: INFO: stderr: ""
Jul 31 11:49:03.259: INFO: stdout: "true"
Jul 31 11:49:03.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-hxgqg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3085'
Jul 31 11:49:03.571: INFO: stderr: ""
Jul 31 11:49:03.571: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 11:49:03.571: INFO: validating pod update-demo-nautilus-hxgqg
Jul 31 11:49:04.354: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 11:49:04.354: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 11:49:04.354: INFO: update-demo-nautilus-hxgqg is verified up and running
Jul 31 11:49:04.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-qph8z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3085'
Jul 31 11:49:04.493: INFO: stderr: ""
Jul 31 11:49:04.493: INFO: stdout: "true"
Jul 31 11:49:04.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-qph8z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3085'
Jul 31 11:49:04.679: INFO: stderr: ""
Jul 31 11:49:04.679: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 11:49:04.679: INFO: validating pod update-demo-nautilus-qph8z
Jul 31 11:49:06.454: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 11:49:06.454: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 11:49:06.454: INFO: update-demo-nautilus-qph8z is verified up and running
STEP: using delete to clean up resources
Jul 31 11:49:06.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 delete --grace-period=0 --force -f - --namespace=kubectl-3085'
Jul 31 11:49:07.631: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 11:49:07.631: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jul 31 11:49:07.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3085'
Jul 31 11:49:07.826: INFO: stderr: "No resources found.\n"
Jul 31 11:49:07.826: INFO: stdout: ""
Jul 31 11:49:07.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -l name=update-demo --namespace=kubectl-3085 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 31 11:49:09.037: INFO: stderr: ""
Jul 31 11:49:09.037: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:49:09.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3085" for this suite.
Jul 31 11:49:16.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:49:21.287: INFO: namespace kubectl-3085 deletion completed in 12.029707866s

• [SLOW TEST:32.832 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:49:21.289: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jul 31 11:49:24.454: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:49:34.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2878" for this suite.
Jul 31 11:49:40.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:49:45.861: INFO: namespace init-container-2878 deletion completed in 11.388070552s

• [SLOW TEST:24.572 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:49:45.861: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jul 31 11:49:57.854: INFO: Successfully updated pod "annotationupdate4adcc4d7-b389-11e9-82b5-da5bffca47b9"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:50:00.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8006" for this suite.
Jul 31 11:50:23.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:50:31.297: INFO: namespace downward-api-8006 deletion completed in 30.732282197s

• [SLOW TEST:45.436 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:50:31.298: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jul 31 11:50:32.214: INFO: Waiting up to 5m0s for pod "pod-66694bad-b389-11e9-82b5-da5bffca47b9" in namespace "emptydir-745" to be "success or failure"
Jul 31 11:50:32.229: INFO: Pod "pod-66694bad-b389-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.830361ms
Jul 31 11:50:34.261: INFO: Pod "pod-66694bad-b389-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046286305s
Jul 31 11:50:36.558: INFO: Pod "pod-66694bad-b389-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.343150379s
Jul 31 11:50:39.260: INFO: Pod "pod-66694bad-b389-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.045460694s
Jul 31 11:50:41.271: INFO: Pod "pod-66694bad-b389-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.056120967s
Jul 31 11:50:43.959: INFO: Pod "pod-66694bad-b389-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 11.744175143s
STEP: Saw pod success
Jul 31 11:50:43.959: INFO: Pod "pod-66694bad-b389-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 11:50:44.359: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-66694bad-b389-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 11:50:44.529: INFO: Waiting for pod pod-66694bad-b389-11e9-82b5-da5bffca47b9 to disappear
Jul 31 11:50:44.555: INFO: Pod pod-66694bad-b389-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:50:44.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-745" for this suite.
Jul 31 11:50:50.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:50:57.599: INFO: namespace emptydir-745 deletion completed in 13.035200868s

• [SLOW TEST:26.301 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:50:57.599: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8716.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8716.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul 31 11:51:40.758: INFO: DNS probes using dns-8716/dns-test-76eb6cba-b389-11e9-82b5-da5bffca47b9 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:51:41.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8716" for this suite.
Jul 31 11:51:49.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:52:00.655: INFO: namespace dns-8716 deletion completed in 18.734575528s

• [SLOW TEST:63.056 seconds]
[sig-network] DNS
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:52:00.655: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-9b5152a4-b389-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume configMaps
Jul 31 11:52:01.339: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9b76507f-b389-11e9-82b5-da5bffca47b9" in namespace "projected-2235" to be "success or failure"
Jul 31 11:52:01.348: INFO: Pod "pod-projected-configmaps-9b76507f-b389-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.915664ms
Jul 31 11:52:03.490: INFO: Pod "pod-projected-configmaps-9b76507f-b389-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.151201913s
Jul 31 11:52:05.857: INFO: Pod "pod-projected-configmaps-9b76507f-b389-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.518469759s
Jul 31 11:52:08.259: INFO: Pod "pod-projected-configmaps-9b76507f-b389-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.920094237s
Jul 31 11:52:11.155: INFO: Pod "pod-projected-configmaps-9b76507f-b389-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 9.816013542s
STEP: Saw pod success
Jul 31 11:52:11.155: INFO: Pod "pod-projected-configmaps-9b76507f-b389-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 11:52:11.654: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-projected-configmaps-9b76507f-b389-11e9-82b5-da5bffca47b9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 11:52:14.754: INFO: Waiting for pod pod-projected-configmaps-9b76507f-b389-11e9-82b5-da5bffca47b9 to disappear
Jul 31 11:52:14.762: INFO: Pod pod-projected-configmaps-9b76507f-b389-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:52:14.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2235" for this suite.
Jul 31 11:52:21.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:52:28.458: INFO: namespace projected-2235 deletion completed in 13.688877659s

• [SLOW TEST:27.803 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:52:28.459: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-acefeae6-b389-11e9-82b5-da5bffca47b9
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-acefeae6-b389-11e9-82b5-da5bffca47b9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:53:44.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-706" for this suite.
Jul 31 11:54:07.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:54:15.154: INFO: namespace projected-706 deletion completed in 30.39905935s

• [SLOW TEST:106.698 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:54:15.157: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul 31 11:54:16.754: INFO: Waiting up to 5m0s for pod "downward-api-ec1a64c7-b389-11e9-82b5-da5bffca47b9" in namespace "downward-api-7657" to be "success or failure"
Jul 31 11:54:17.354: INFO: Pod "downward-api-ec1a64c7-b389-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 599.566492ms
Jul 31 11:54:19.655: INFO: Pod "downward-api-ec1a64c7-b389-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.900162716s
Jul 31 11:54:21.960: INFO: Pod "downward-api-ec1a64c7-b389-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.205431428s
Jul 31 11:54:24.254: INFO: Pod "downward-api-ec1a64c7-b389-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.499364372s
STEP: Saw pod success
Jul 31 11:54:24.254: INFO: Pod "downward-api-ec1a64c7-b389-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 11:54:24.271: INFO: Trying to get logs from node loving-darwin-5cd5b754c-ckbcc pod downward-api-ec1a64c7-b389-11e9-82b5-da5bffca47b9 container dapi-container: <nil>
STEP: delete the pod
Jul 31 11:54:25.282: INFO: Waiting for pod downward-api-ec1a64c7-b389-11e9-82b5-da5bffca47b9 to disappear
Jul 31 11:54:25.294: INFO: Pod downward-api-ec1a64c7-b389-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:54:25.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7657" for this suite.
Jul 31 11:54:31.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:54:37.754: INFO: namespace downward-api-7657 deletion completed in 12.452379351s

• [SLOW TEST:22.597 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:54:37.754: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:55:27.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-449" for this suite.
Jul 31 11:55:33.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:55:43.254: INFO: namespace container-runtime-449 deletion completed in 15.498887152s

• [SLOW TEST:65.500 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:55:43.254: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:55:50.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7183" for this suite.
Jul 31 11:55:56.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:55:59.957: INFO: namespace emptydir-wrapper-7183 deletion completed in 9.274232594s

• [SLOW TEST:16.702 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:55:59.957: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-6241
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 31 11:56:02.355: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 31 11:56:35.867: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.25:8080/dial?request=hostName&protocol=udp&host=172.25.0.12&port=8081&tries=1'] Namespace:pod-network-test-6241 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 11:56:35.867: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 11:56:42.154: INFO: Waiting for endpoints: map[]
Jul 31 11:56:43.354: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.25:8080/dial?request=hostName&protocol=udp&host=172.25.1.24&port=8081&tries=1'] Namespace:pod-network-test-6241 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 11:56:43.354: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 11:56:50.322: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:56:50.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6241" for this suite.
Jul 31 11:57:12.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:57:16.754: INFO: namespace pod-network-test-6241 deletion completed in 26.408293228s

• [SLOW TEST:76.797 seconds]
[sig-network] Networking
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:57:16.755: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 11:57:18.254: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5858238a-b38a-11e9-82b5-da5bffca47b9" in namespace "downward-api-9909" to be "success or failure"
Jul 31 11:57:18.554: INFO: Pod "downwardapi-volume-5858238a-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 299.989313ms
Jul 31 11:57:21.854: INFO: Pod "downwardapi-volume-5858238a-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.600303204s
Jul 31 11:57:24.157: INFO: Pod "downwardapi-volume-5858238a-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.903146847s
Jul 31 11:57:26.354: INFO: Pod "downwardapi-volume-5858238a-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.100077348s
Jul 31 11:57:28.554: INFO: Pod "downwardapi-volume-5858238a-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.300676207s
Jul 31 11:57:30.754: INFO: Pod "downwardapi-volume-5858238a-b38a-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.500353202s
STEP: Saw pod success
Jul 31 11:57:30.754: INFO: Pod "downwardapi-volume-5858238a-b38a-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 11:57:31.154: INFO: Trying to get logs from node loving-darwin-5cd5b754c-ckbcc pod downwardapi-volume-5858238a-b38a-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 11:57:32.054: INFO: Waiting for pod downwardapi-volume-5858238a-b38a-11e9-82b5-da5bffca47b9 to disappear
Jul 31 11:57:32.258: INFO: Pod downwardapi-volume-5858238a-b38a-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:57:32.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9909" for this suite.
Jul 31 11:57:38.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:57:42.258: INFO: namespace downward-api-9909 deletion completed in 9.98358711s

• [SLOW TEST:25.503 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:57:42.258: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 11:57:42.396: INFO: Waiting up to 5m0s for pod "downwardapi-volume-66d7bf07-b38a-11e9-82b5-da5bffca47b9" in namespace "projected-3503" to be "success or failure"
Jul 31 11:57:43.254: INFO: Pod "downwardapi-volume-66d7bf07-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 857.785554ms
Jul 31 11:57:45.658: INFO: Pod "downwardapi-volume-66d7bf07-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.262010663s
Jul 31 11:57:47.859: INFO: Pod "downwardapi-volume-66d7bf07-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.462110073s
Jul 31 11:57:49.958: INFO: Pod "downwardapi-volume-66d7bf07-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.561665584s
Jul 31 11:57:52.754: INFO: Pod "downwardapi-volume-66d7bf07-b38a-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.357602892s
STEP: Saw pod success
Jul 31 11:57:52.754: INFO: Pod "downwardapi-volume-66d7bf07-b38a-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 11:57:53.558: INFO: Trying to get logs from node loving-darwin-5cd5b754c-ckbcc pod downwardapi-volume-66d7bf07-b38a-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 11:57:54.154: INFO: Waiting for pod downwardapi-volume-66d7bf07-b38a-11e9-82b5-da5bffca47b9 to disappear
Jul 31 11:57:54.654: INFO: Pod downwardapi-volume-66d7bf07-b38a-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:57:54.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3503" for this suite.
Jul 31 11:58:02.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:58:06.785: INFO: namespace projected-3503 deletion completed in 12.12075038s

• [SLOW TEST:24.527 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:58:06.785: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-3577
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-3577
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3577
Jul 31 11:58:07.796: INFO: Found 0 stateful pods, waiting for 1
Jul 31 11:58:17.816: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jul 31 11:58:17.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-3577 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 11:58:20.072: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 31 11:58:20.072: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 11:58:20.072: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 11:58:20.112: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 31 11:58:20.112: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 11:58:22.854: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jul 31 11:58:22.854: INFO: ss-0  loving-darwin-5cd5b754c-qfktz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:07 +0000 UTC  }]
Jul 31 11:58:22.854: INFO: ss-1                                 Pending         []
Jul 31 11:58:22.854: INFO: 
Jul 31 11:58:22.854: INFO: StatefulSet ss has not reached scale 3, at 2
Jul 31 11:58:24.055: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.01458164s
Jul 31 11:58:25.261: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.813584548s
Jul 31 11:58:26.654: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.607257379s
Jul 31 11:58:27.663: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.21433933s
Jul 31 11:58:28.859: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.205803321s
Jul 31 11:58:30.054: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.009396923s
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3577
Jul 31 11:58:31.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-3577 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 11:58:37.758: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 31 11:58:37.758: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 31 11:58:37.758: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 31 11:58:37.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-3577 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 11:58:41.999: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jul 31 11:58:42.000: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 31 11:58:42.000: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 31 11:58:42.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-3577 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 11:58:46.763: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jul 31 11:58:46.763: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 31 11:58:46.763: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 31 11:58:46.816: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 11:58:46.816: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 11:58:46.816: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jul 31 11:58:46.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-3577 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 11:58:49.855: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 31 11:58:49.855: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 11:58:49.855: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 11:58:49.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-3577 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 11:58:53.123: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 31 11:58:53.123: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 11:58:53.123: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 11:58:53.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-3577 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 11:58:57.865: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 31 11:58:57.865: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 11:58:57.865: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 11:58:57.865: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 11:58:57.962: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jul 31 11:59:08.354: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 31 11:59:08.354: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul 31 11:59:08.354: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul 31 11:59:08.592: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jul 31 11:59:08.592: INFO: ss-0  loving-darwin-5cd5b754c-qfktz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:07 +0000 UTC  }]
Jul 31 11:59:08.592: INFO: ss-1  loving-darwin-5cd5b754c-ckbcc  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:20 +0000 UTC  }]
Jul 31 11:59:08.592: INFO: ss-2  loving-darwin-5cd5b754c-qfktz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:20 +0000 UTC  }]
Jul 31 11:59:08.592: INFO: 
Jul 31 11:59:08.592: INFO: StatefulSet ss has not reached scale 0, at 3
Jul 31 11:59:09.854: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jul 31 11:59:09.854: INFO: ss-0  loving-darwin-5cd5b754c-qfktz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:07 +0000 UTC  }]
Jul 31 11:59:09.854: INFO: ss-1  loving-darwin-5cd5b754c-ckbcc  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:20 +0000 UTC  }]
Jul 31 11:59:09.854: INFO: ss-2  loving-darwin-5cd5b754c-qfktz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:20 +0000 UTC  }]
Jul 31 11:59:09.854: INFO: 
Jul 31 11:59:09.854: INFO: StatefulSet ss has not reached scale 0, at 3
Jul 31 11:59:11.054: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jul 31 11:59:11.054: INFO: ss-0  loving-darwin-5cd5b754c-qfktz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:07 +0000 UTC  }]
Jul 31 11:59:11.055: INFO: ss-1  loving-darwin-5cd5b754c-ckbcc  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:20 +0000 UTC  }]
Jul 31 11:59:11.055: INFO: ss-2  loving-darwin-5cd5b754c-qfktz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:20 +0000 UTC  }]
Jul 31 11:59:11.055: INFO: 
Jul 31 11:59:11.055: INFO: StatefulSet ss has not reached scale 0, at 3
Jul 31 11:59:12.454: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jul 31 11:59:12.454: INFO: ss-0  loving-darwin-5cd5b754c-qfktz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:07 +0000 UTC  }]
Jul 31 11:59:12.454: INFO: ss-1  loving-darwin-5cd5b754c-ckbcc  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:20 +0000 UTC  }]
Jul 31 11:59:12.454: INFO: ss-2  loving-darwin-5cd5b754c-qfktz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:20 +0000 UTC  }]
Jul 31 11:59:12.454: INFO: 
Jul 31 11:59:12.454: INFO: StatefulSet ss has not reached scale 0, at 3
Jul 31 11:59:13.660: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jul 31 11:59:13.660: INFO: ss-0  loving-darwin-5cd5b754c-qfktz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:07 +0000 UTC  }]
Jul 31 11:59:13.660: INFO: ss-2  loving-darwin-5cd5b754c-qfktz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:20 +0000 UTC  }]
Jul 31 11:59:13.660: INFO: 
Jul 31 11:59:13.660: INFO: StatefulSet ss has not reached scale 0, at 2
Jul 31 11:59:15.058: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jul 31 11:59:15.058: INFO: ss-0  loving-darwin-5cd5b754c-qfktz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 11:58:07 +0000 UTC  }]
Jul 31 11:59:15.058: INFO: 
Jul 31 11:59:15.058: INFO: StatefulSet ss has not reached scale 0, at 1
Jul 31 11:59:16.554: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.509711761s
Jul 31 11:59:18.054: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.020039528s
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3577
Jul 31 11:59:19.255: INFO: Scaling statefulset ss to 0
Jul 31 11:59:20.153: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 31 11:59:20.353: INFO: Deleting all statefulset in ns statefulset-3577
Jul 31 11:59:21.154: INFO: Scaling statefulset ss to 0
Jul 31 11:59:22.053: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 11:59:22.253: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:59:22.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3577" for this suite.
Jul 31 11:59:30.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 11:59:34.387: INFO: namespace statefulset-3577 deletion completed in 11.33267332s

• [SLOW TEST:87.602 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 11:59:34.387: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jul 31 11:59:36.553: INFO: Waiting up to 5m0s for pod "pod-aa7abe69-b38a-11e9-82b5-da5bffca47b9" in namespace "emptydir-8164" to be "success or failure"
Jul 31 11:59:36.954: INFO: Pod "pod-aa7abe69-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 400.274673ms
Jul 31 11:59:39.155: INFO: Pod "pod-aa7abe69-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.601292262s
Jul 31 11:59:41.259: INFO: Pod "pod-aa7abe69-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.70542305s
Jul 31 11:59:43.269: INFO: Pod "pod-aa7abe69-b38a-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.715738656s
STEP: Saw pod success
Jul 31 11:59:43.269: INFO: Pod "pod-aa7abe69-b38a-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 11:59:43.277: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-aa7abe69-b38a-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 11:59:44.593: INFO: Waiting for pod pod-aa7abe69-b38a-11e9-82b5-da5bffca47b9 to disappear
Jul 31 11:59:44.601: INFO: Pod pod-aa7abe69-b38a-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 11:59:44.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8164" for this suite.
Jul 31 11:59:50.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:00:00.554: INFO: namespace emptydir-8164 deletion completed in 15.943127537s

• [SLOW TEST:26.167 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:00:00.559: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1579
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 31 12:00:01.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-6976'
Jul 31 12:00:03.665: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 31 12:00:03.665: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1584
Jul 31 12:00:05.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 delete jobs e2e-test-nginx-job --namespace=kubectl-6976'
Jul 31 12:00:06.073: INFO: stderr: ""
Jul 31 12:00:06.073: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:00:06.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6976" for this suite.
Jul 31 12:00:13.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:00:21.285: INFO: namespace kubectl-6976 deletion completed in 14.122753584s

• [SLOW TEST:20.726 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:00:21.285: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jul 31 12:00:34.054: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 31 12:00:34.258: INFO: Pod pod-with-poststart-http-hook still exists
Jul 31 12:00:36.259: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 31 12:00:37.154: INFO: Pod pod-with-poststart-http-hook still exists
Jul 31 12:00:38.258: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 31 12:00:38.563: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:00:38.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1405" for this suite.
Jul 31 12:01:00.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:01:03.492: INFO: namespace container-lifecycle-hook-1405 deletion completed in 24.916967155s

• [SLOW TEST:42.217 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:01:03.502: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 12:01:07.853: INFO: Waiting up to 5m0s for pod "downwardapi-volume-df9edd03-b38a-11e9-82b5-da5bffca47b9" in namespace "projected-9079" to be "success or failure"
Jul 31 12:01:07.861: INFO: Pod "downwardapi-volume-df9edd03-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.235301ms
Jul 31 12:01:10.160: INFO: Pod "downwardapi-volume-df9edd03-b38a-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.306395886s
STEP: Saw pod success
Jul 31 12:01:10.168: INFO: Pod "downwardapi-volume-df9edd03-b38a-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:01:10.176: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod downwardapi-volume-df9edd03-b38a-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 12:01:11.785: INFO: Waiting for pod downwardapi-volume-df9edd03-b38a-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:01:11.791: INFO: Pod downwardapi-volume-df9edd03-b38a-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:01:11.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9079" for this suite.
Jul 31 12:01:18.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:01:25.986: INFO: namespace projected-9079 deletion completed in 14.126873468s

• [SLOW TEST:22.485 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:01:25.986: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 12:01:26.753: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:01:29.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5561" for this suite.
Jul 31 12:01:36.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:01:38.710: INFO: namespace custom-resource-definition-5561 deletion completed in 9.256523396s

• [SLOW TEST:12.724 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:01:38.711: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-f4ce6ba1-b38a-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume secrets
Jul 31 12:01:41.153: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f4fd4b63-b38a-11e9-82b5-da5bffca47b9" in namespace "projected-8608" to be "success or failure"
Jul 31 12:01:41.654: INFO: Pod "pod-projected-secrets-f4fd4b63-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 500.840847ms
Jul 31 12:01:43.754: INFO: Pod "pod-projected-secrets-f4fd4b63-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.600106239s
Jul 31 12:01:46.053: INFO: Pod "pod-projected-secrets-f4fd4b63-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.900014934s
Jul 31 12:01:48.959: INFO: Pod "pod-projected-secrets-f4fd4b63-b38a-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.805298023s
STEP: Saw pod success
Jul 31 12:01:48.959: INFO: Pod "pod-projected-secrets-f4fd4b63-b38a-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:01:48.965: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-projected-secrets-f4fd4b63-b38a-11e9-82b5-da5bffca47b9 container secret-volume-test: <nil>
STEP: delete the pod
Jul 31 12:01:49.195: INFO: Waiting for pod pod-projected-secrets-f4fd4b63-b38a-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:01:49.214: INFO: Pod pod-projected-secrets-f4fd4b63-b38a-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:01:49.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8608" for this suite.
Jul 31 12:01:55.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:01:58.993: INFO: namespace projected-8608 deletion completed in 9.640045124s

• [SLOW TEST:20.282 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:01:58.993: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Jul 31 12:01:59.560: INFO: Waiting up to 5m0s for pod "var-expansion-fff5d0d1-b38a-11e9-82b5-da5bffca47b9" in namespace "var-expansion-7947" to be "success or failure"
Jul 31 12:01:59.574: INFO: Pod "var-expansion-fff5d0d1-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.595503ms
Jul 31 12:02:01.585: INFO: Pod "var-expansion-fff5d0d1-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025071115s
Jul 31 12:02:03.953: INFO: Pod "var-expansion-fff5d0d1-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.393571063s
Jul 31 12:02:06.079: INFO: Pod "var-expansion-fff5d0d1-b38a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.519363304s
Jul 31 12:02:08.459: INFO: Pod "var-expansion-fff5d0d1-b38a-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.899600438s
STEP: Saw pod success
Jul 31 12:02:08.460: INFO: Pod "var-expansion-fff5d0d1-b38a-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:02:08.467: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod var-expansion-fff5d0d1-b38a-11e9-82b5-da5bffca47b9 container dapi-container: <nil>
STEP: delete the pod
Jul 31 12:02:08.888: INFO: Waiting for pod var-expansion-fff5d0d1-b38a-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:02:08.928: INFO: Pod var-expansion-fff5d0d1-b38a-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:02:08.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7947" for this suite.
Jul 31 12:02:15.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:02:21.274: INFO: namespace var-expansion-7947 deletion completed in 12.334400947s

• [SLOW TEST:22.280 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:02:21.275: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 12:02:21.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 version'
Jul 31 12:02:22.143: INFO: stderr: ""
Jul 31 12:02:22.143: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.4\", GitCommit:\"a87e9a978f65a8303aa9467537aa59c18122cbf9\", GitTreeState:\"clean\", BuildDate:\"2019-07-08T08:51:16Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.4\", GitCommit:\"a87e9a978f65a8303aa9467537aa59c18122cbf9\", GitTreeState:\"clean\", BuildDate:\"2019-07-08T08:43:10Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:02:22.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2755" for this suite.
Jul 31 12:02:28.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:02:31.186: INFO: namespace kubectl-2755 deletion completed in 9.033383549s

• [SLOW TEST:9.911 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:02:31.186: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-14ef1315-b38b-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume configMaps
Jul 31 12:02:34.493: INFO: Waiting up to 5m0s for pod "pod-configmaps-14f0c918-b38b-11e9-82b5-da5bffca47b9" in namespace "configmap-9749" to be "success or failure"
Jul 31 12:02:34.499: INFO: Pod "pod-configmaps-14f0c918-b38b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.555041ms
Jul 31 12:02:36.758: INFO: Pod "pod-configmaps-14f0c918-b38b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.264835662s
Jul 31 12:02:39.154: INFO: Pod "pod-configmaps-14f0c918-b38b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.660835434s
Jul 31 12:02:41.356: INFO: Pod "pod-configmaps-14f0c918-b38b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.863070968s
Jul 31 12:02:43.853: INFO: Pod "pod-configmaps-14f0c918-b38b-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 9.360240042s
STEP: Saw pod success
Jul 31 12:02:43.853: INFO: Pod "pod-configmaps-14f0c918-b38b-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:02:44.254: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-configmaps-14f0c918-b38b-11e9-82b5-da5bffca47b9 container configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 12:02:45.650: INFO: Waiting for pod pod-configmaps-14f0c918-b38b-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:02:46.658: INFO: Pod pod-configmaps-14f0c918-b38b-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:02:46.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9749" for this suite.
Jul 31 12:02:53.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:03:00.053: INFO: namespace configmap-9749 deletion completed in 13.386981126s

• [SLOW TEST:28.867 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:03:00.054: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-2625
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-2625
STEP: Creating statefulset with conflicting port in namespace statefulset-2625
STEP: Waiting until pod test-pod will start running in namespace statefulset-2625
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2625
Jul 31 12:03:10.353: INFO: Observed stateful pod in namespace: statefulset-2625, name: ss-0, uid: 2a145636-b38b-11e9-a303-6acf1189be78, status phase: Pending. Waiting for statefulset controller to delete.
Jul 31 12:03:19.154: INFO: Observed stateful pod in namespace: statefulset-2625, name: ss-0, uid: 2a145636-b38b-11e9-a303-6acf1189be78, status phase: Failed. Waiting for statefulset controller to delete.
Jul 31 12:03:19.158: INFO: Observed stateful pod in namespace: statefulset-2625, name: ss-0, uid: 2a145636-b38b-11e9-a303-6acf1189be78, status phase: Failed. Waiting for statefulset controller to delete.
Jul 31 12:03:19.161: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2625
STEP: Removing pod with conflicting port in namespace statefulset-2625
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2625 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 31 12:03:28.856: INFO: Deleting all statefulset in ns statefulset-2625
Jul 31 12:03:29.053: INFO: Scaling statefulset ss to 0
Jul 31 12:03:40.253: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 12:03:40.559: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:03:40.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2625" for this suite.
Jul 31 12:03:47.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:03:50.156: INFO: namespace statefulset-2625 deletion completed in 9.345619699s

• [SLOW TEST:50.103 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:03:50.156: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Jul 31 12:03:50.658: INFO: namespace kubectl-4820
Jul 31 12:03:50.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 create -f - --namespace=kubectl-4820'
Jul 31 12:03:52.355: INFO: stderr: ""
Jul 31 12:03:52.355: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jul 31 12:03:53.363: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:03:53.363: INFO: Found 0 / 1
Jul 31 12:03:56.153: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:03:56.153: INFO: Found 0 / 1
Jul 31 12:03:56.665: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:03:56.665: INFO: Found 0 / 1
Jul 31 12:03:57.368: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:03:57.368: INFO: Found 0 / 1
Jul 31 12:03:58.859: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:03:58.859: INFO: Found 0 / 1
Jul 31 12:03:59.759: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:03:59.759: INFO: Found 0 / 1
Jul 31 12:04:00.559: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:04:00.559: INFO: Found 1 / 1
Jul 31 12:04:00.559: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul 31 12:04:00.954: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:04:00.954: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 31 12:04:00.954: INFO: wait on redis-master startup in kubectl-4820 
Jul 31 12:04:00.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 logs redis-master-qqj9f redis-master --namespace=kubectl-4820'
Jul 31 12:04:02.725: INFO: stderr: ""
Jul 31 12:04:02.725: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 31 Jul 12:03:59.387 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 31 Jul 12:03:59.388 # Server started, Redis version 3.2.12\n1:M 31 Jul 12:03:59.388 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 31 Jul 12:03:59.390 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jul 31 12:04:02.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-4820'
Jul 31 12:04:03.531: INFO: stderr: ""
Jul 31 12:04:03.531: INFO: stdout: "service/rm2 exposed\n"
Jul 31 12:04:03.665: INFO: Service rm2 in namespace kubectl-4820 found.
STEP: exposing service
Jul 31 12:04:06.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-4820'
Jul 31 12:04:07.427: INFO: stderr: ""
Jul 31 12:04:07.427: INFO: stdout: "service/rm3 exposed\n"
Jul 31 12:04:07.763: INFO: Service rm3 in namespace kubectl-4820 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:04:10.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4820" for this suite.
Jul 31 12:04:49.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:04:51.588: INFO: namespace kubectl-4820 deletion completed in 41.133804657s

• [SLOW TEST:61.432 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:04:51.589: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-6730d4f5-b38b-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume secrets
Jul 31 12:04:52.772: INFO: Waiting up to 5m0s for pod "pod-secrets-675dbd1d-b38b-11e9-82b5-da5bffca47b9" in namespace "secrets-7647" to be "success or failure"
Jul 31 12:04:52.780: INFO: Pod "pod-secrets-675dbd1d-b38b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.986704ms
Jul 31 12:04:54.860: INFO: Pod "pod-secrets-675dbd1d-b38b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088431476s
Jul 31 12:04:57.153: INFO: Pod "pod-secrets-675dbd1d-b38b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.381132403s
Jul 31 12:04:59.160: INFO: Pod "pod-secrets-675dbd1d-b38b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.388361265s
Jul 31 12:05:01.180: INFO: Pod "pod-secrets-675dbd1d-b38b-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.407928859s
STEP: Saw pod success
Jul 31 12:05:01.180: INFO: Pod "pod-secrets-675dbd1d-b38b-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:05:01.189: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-secrets-675dbd1d-b38b-11e9-82b5-da5bffca47b9 container secret-env-test: <nil>
STEP: delete the pod
Jul 31 12:05:02.355: INFO: Waiting for pod pod-secrets-675dbd1d-b38b-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:05:02.553: INFO: Pod pod-secrets-675dbd1d-b38b-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:05:02.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7647" for this suite.
Jul 31 12:05:09.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:05:13.553: INFO: namespace secrets-7647 deletion completed in 10.799854239s

• [SLOW TEST:21.965 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:05:13.553: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 12:05:15.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 version --client'
Jul 31 12:05:15.342: INFO: stderr: ""
Jul 31 12:05:15.342: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.4\", GitCommit:\"a87e9a978f65a8303aa9467537aa59c18122cbf9\", GitTreeState:\"clean\", BuildDate:\"2019-07-08T08:51:16Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jul 31 12:05:15.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 create -f - --namespace=kubectl-1612'
Jul 31 12:05:16.329: INFO: stderr: ""
Jul 31 12:05:16.329: INFO: stdout: "replicationcontroller/redis-master created\n"
Jul 31 12:05:16.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 create -f - --namespace=kubectl-1612'
Jul 31 12:05:17.325: INFO: stderr: ""
Jul 31 12:05:17.325: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jul 31 12:05:18.357: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:05:18.357: INFO: Found 0 / 1
Jul 31 12:05:20.153: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:05:20.153: INFO: Found 0 / 1
Jul 31 12:05:21.659: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:05:21.659: INFO: Found 0 / 1
Jul 31 12:05:22.453: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:05:22.453: INFO: Found 0 / 1
Jul 31 12:05:23.854: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:05:23.854: INFO: Found 1 / 1
Jul 31 12:05:23.854: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul 31 12:05:24.353: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:05:24.353: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 31 12:05:24.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 describe pod redis-master-jc5c8 --namespace=kubectl-1612'
Jul 31 12:05:25.356: INFO: stderr: ""
Jul 31 12:05:25.356: INFO: stdout: "Name:               redis-master-jc5c8\nNamespace:          kubectl-1612\nPriority:           0\nPriorityClassName:  <none>\nNode:               loving-darwin-5cd5b754c-qfktz/192.168.1.11\nStart Time:         Wed, 31 Jul 2019 12:05:17 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 172.25.1.38\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://e66635e525f41e1ee5db052d25f6d4ae4038a8029cbd9834f6f8036729a276a7\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 31 Jul 2019 12:05:22 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-b8h6m (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-b8h6m:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-b8h6m\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                    Message\n  ----    ------     ----  ----                                    -------\n  Normal  Scheduled  9s    default-scheduler                       Successfully assigned kubectl-1612/redis-master-jc5c8 to loving-darwin-5cd5b754c-qfktz\n  Normal  Pulled     5s    kubelet, loving-darwin-5cd5b754c-qfktz  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    4s    kubelet, loving-darwin-5cd5b754c-qfktz  Created container redis-master\n  Normal  Started    3s    kubelet, loving-darwin-5cd5b754c-qfktz  Started container redis-master\n"
Jul 31 12:05:25.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 describe rc redis-master --namespace=kubectl-1612'
Jul 31 12:05:26.356: INFO: stderr: ""
Jul 31 12:05:26.356: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-1612\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  10s   replication-controller  Created pod: redis-master-jc5c8\n"
Jul 31 12:05:26.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 describe service redis-master --namespace=kubectl-1612'
Jul 31 12:05:27.224: INFO: stderr: ""
Jul 31 12:05:27.224: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-1612\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.10.10.75\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.25.1.38:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jul 31 12:05:27.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 describe node loving-darwin-5cd5b754c-ckbcc'
Jul 31 12:05:28.279: INFO: stderr: ""
Jul 31 12:05:28.279: INFO: stdout: "Name:               loving-darwin-5cd5b754c-ckbcc\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=090bcc91-6207-465d-aff0-bfcc10a9e063\n                    beta.kubernetes.io/os=linux\n                    container-linux-update.v1.coreos.com/group=stable\n                    container-linux-update.v1.coreos.com/id=coreos\n                    container-linux-update.v1.coreos.com/reboot-needed=false\n                    container-linux-update.v1.coreos.com/version=2135.5.0\n                    failure-domain.beta.kubernetes.io/zone=ix1\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=loving-darwin-5cd5b754c-ckbcc\n                    kubernetes.io/os=linux\n                    kubernetes.io/uses-container-linux=true\n                    machine-controller/owned-by=528b9455-b385-11e9-a303-6acf1189be78\nAnnotations:        cluster.k8s.io/machine: kube-system/loving-darwin-5cd5b754c-ckbcc\n                    container-linux-update.v1.coreos.com/last-checked-time: 1564572808\n                    container-linux-update.v1.coreos.com/new-version: 0.0.0\n                    container-linux-update.v1.coreos.com/reboot-in-progress: false\n                    container-linux-update.v1.coreos.com/reboot-needed: false\n                    container-linux-update.v1.coreos.com/status: UPDATE_STATUS_IDLE\n                    flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"82:f8:5e:cf:65:c0\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.1.8\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 31 Jul 2019 11:25:02 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 31 Jul 2019 12:05:07 +0000   Wed, 31 Jul 2019 11:25:02 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 31 Jul 2019 12:05:07 +0000   Wed, 31 Jul 2019 11:25:02 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 31 Jul 2019 12:05:07 +0000   Wed, 31 Jul 2019 11:25:02 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 31 Jul 2019 12:05:07 +0000   Wed, 31 Jul 2019 11:26:04 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.1.8\n  Hostname:    loving-darwin-5cd5b754c-ckbcc\nCapacity:\n attachable-volumes-cinder:  256\n cpu:                        4\n ephemeral-storage:          17897500Ki\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     8168068Ki\n pods:                       110\nAllocatable:\n attachable-volumes-cinder:  256\n cpu:                        3800m\n ephemeral-storage:          14346852325\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     7860868Ki\n pods:                       110\nSystem Info:\n Machine ID:                 066d733bd76745e0bbcf0de13ee47620\n System UUID:                066d733b-d767-45e0-bbcf-0de13ee47620\n Boot ID:                    eef71acf-cf44-4f19-8acf-e602a4e3086c\n Kernel Version:             4.19.50-coreos-r1\n OS Image:                   Container Linux by CoreOS 2135.5.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.14.4\n Kube-Proxy Version:         v1.14.4\nPodCIDR:                     172.25.0.0/24\nProviderID:                  openstack:///066d733b-d767-45e0-bbcf-0de13ee47620\nNon-terminated Pods:         (11 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-757d48abf2694112-wkcgw    0 (0%)        0 (0%)      0 (0%)           0 (0%)         25m\n  kube-system                canal-tc76d                                                350m (9%)     100m (2%)   50Mi (0%)        50Mi (0%)      40m\n  kube-system                container-linux-update-agent-kbslf                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         39m\n  kube-system                container-linux-update-operator-5d5dcbf65f-mz2zk           0 (0%)        0 (0%)      0 (0%)           0 (0%)         40m\n  kube-system                coredns-fdb754d8d-5gt7g                                    100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     43m\n  kube-system                coredns-fdb754d8d-b2k94                                    100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     43m\n  kube-system                kube-proxy-jdrnh                                           75m (1%)      250m (6%)   50Mi (0%)        250Mi (3%)     40m\n  kube-system                kubernetes-dashboard-57dcd9448b-f4j5n                      75m (1%)      75m (1%)    50Mi (0%)        50Mi (0%)      43m\n  kube-system                node-exporter-pxbl7                                        20m (0%)      45m (1%)    48Mi (0%)        96Mi (1%)      40m\n  kube-system                node-local-dns-g7bdx                                       25m (0%)      0 (0%)      5Mi (0%)         30Mi (0%)      39m\n  kube-system                openvpn-client-7f7cfb8c68-4jbt5                            30m (0%)      200m (5%)   30Mi (0%)        82Mi (1%)      43m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                   Requests    Limits\n  --------                   --------    ------\n  cpu                        775m (20%)  670m (17%)\n  memory                     373Mi (4%)  898Mi (11%)\n  ephemeral-storage          0 (0%)      0 (0%)\n  attachable-volumes-cinder  0           0\nEvents:\n  Type    Reason                   Age                From                                       Message\n  ----    ------                   ----               ----                                       -------\n  Normal  NodeHasSufficientMemory  40m (x7 over 40m)  kubelet, loving-darwin-5cd5b754c-ckbcc     Node loving-darwin-5cd5b754c-ckbcc status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    40m (x7 over 40m)  kubelet, loving-darwin-5cd5b754c-ckbcc     Node loving-darwin-5cd5b754c-ckbcc status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     40m (x7 over 40m)  kubelet, loving-darwin-5cd5b754c-ckbcc     Node loving-darwin-5cd5b754c-ckbcc status is now: NodeHasSufficientPID\n  Normal  Starting                 39m                kube-proxy, loving-darwin-5cd5b754c-ckbcc  Starting kube-proxy.\n  Normal  NodeReady                39m                kubelet, loving-darwin-5cd5b754c-ckbcc     Node loving-darwin-5cd5b754c-ckbcc status is now: NodeReady\n"
Jul 31 12:05:28.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 describe namespace kubectl-1612'
Jul 31 12:05:31.224: INFO: stderr: ""
Jul 31 12:05:31.224: INFO: stdout: "Name:         kubectl-1612\nLabels:       e2e-framework=kubectl\n              e2e-run=f437bc50-b387-11e9-82b5-da5bffca47b9\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:05:31.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1612" for this suite.
Jul 31 12:05:54.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:06:03.855: INFO: namespace kubectl-1612 deletion completed in 32.621417369s

• [SLOW TEST:50.303 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:06:03.856: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Jul 31 12:06:10.357: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5015 pod-service-account-9275cfc8-b38b-11e9-82b5-da5bffca47b9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Jul 31 12:06:13.423: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5015 pod-service-account-9275cfc8-b38b-11e9-82b5-da5bffca47b9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Jul 31 12:06:16.462: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5015 pod-service-account-9275cfc8-b38b-11e9-82b5-da5bffca47b9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:06:22.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5015" for this suite.
Jul 31 12:06:28.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:06:31.928: INFO: namespace svcaccounts-5015 deletion completed in 9.469351061s

• [SLOW TEST:28.071 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:06:31.928: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-a2e9712b-b38b-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume secrets
Jul 31 12:06:32.680: INFO: Waiting up to 5m0s for pod "pod-secrets-a2eb4649-b38b-11e9-82b5-da5bffca47b9" in namespace "secrets-1673" to be "success or failure"
Jul 31 12:06:32.692: INFO: Pod "pod-secrets-a2eb4649-b38b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.25332ms
Jul 31 12:06:34.709: INFO: Pod "pod-secrets-a2eb4649-b38b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028296536s
Jul 31 12:06:36.855: INFO: Pod "pod-secrets-a2eb4649-b38b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.174178888s
Jul 31 12:06:39.465: INFO: Pod "pod-secrets-a2eb4649-b38b-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.784771052s
STEP: Saw pod success
Jul 31 12:06:39.465: INFO: Pod "pod-secrets-a2eb4649-b38b-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:06:39.962: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-secrets-a2eb4649-b38b-11e9-82b5-da5bffca47b9 container secret-volume-test: <nil>
STEP: delete the pod
Jul 31 12:06:41.185: INFO: Waiting for pod pod-secrets-a2eb4649-b38b-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:06:41.191: INFO: Pod pod-secrets-a2eb4649-b38b-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:06:41.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1673" for this suite.
Jul 31 12:06:47.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:06:52.858: INFO: namespace secrets-1673 deletion completed in 11.655390539s

• [SLOW TEST:20.930 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:06:52.858: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Jul 31 12:06:52.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 create -f - --namespace=kubectl-1697'
Jul 31 12:06:53.622: INFO: stderr: ""
Jul 31 12:06:53.622: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jul 31 12:06:54.953: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:06:54.953: INFO: Found 0 / 1
Jul 31 12:06:56.253: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:06:56.253: INFO: Found 0 / 1
Jul 31 12:06:57.862: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:06:57.862: INFO: Found 1 / 1
Jul 31 12:06:57.862: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jul 31 12:06:57.873: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:06:57.873: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 31 12:06:57.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 patch pod redis-master-8k7xr --namespace=kubectl-1697 -p {"metadata":{"annotations":{"x":"y"}}}'
Jul 31 12:06:58.170: INFO: stderr: ""
Jul 31 12:06:58.171: INFO: stdout: "pod/redis-master-8k7xr patched\n"
STEP: checking annotations
Jul 31 12:06:59.453: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:06:59.453: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:06:59.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1697" for this suite.
Jul 31 12:07:21.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:07:26.452: INFO: namespace kubectl-1697 deletion completed in 26.983748787s

• [SLOW TEST:33.594 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:07:26.453: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-6970
Jul 31 12:07:34.353: INFO: Started pod liveness-http in namespace container-probe-6970
STEP: checking the pod's current state and verifying that restartCount is present
Jul 31 12:07:34.653: INFO: Initial restart count of pod liveness-http is 0
Jul 31 12:07:57.553: INFO: Restart count of pod container-probe-6970/liveness-http is now 1 (22.899807507s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:07:57.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6970" for this suite.
Jul 31 12:08:04.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:08:10.421: INFO: namespace container-probe-6970 deletion completed in 12.267462804s

• [SLOW TEST:43.968 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:08:10.421: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-8586
I0731 12:08:11.568031      19 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8586, replica count: 1
I0731 12:08:12.618728      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 12:08:13.618854      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 12:08:14.619182      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 12:08:15.629914      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 12:08:16.641026      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 12:08:17.641291      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 12:08:18.641589      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 12:08:19.641776      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 31 12:08:20.555: INFO: Created: latency-svc-wghqf
Jul 31 12:08:20.555: INFO: Got endpoints: latency-svc-wghqf [312.072475ms]
Jul 31 12:08:20.588: INFO: Created: latency-svc-lkc8t
Jul 31 12:08:20.853: INFO: Created: latency-svc-4lxtz
Jul 31 12:08:20.853: INFO: Created: latency-svc-9pjzt
Jul 31 12:08:20.853: INFO: Got endpoints: latency-svc-9pjzt [295.775382ms]
Jul 31 12:08:20.853: INFO: Got endpoints: latency-svc-lkc8t [297.744883ms]
Jul 31 12:08:20.853: INFO: Got endpoints: latency-svc-4lxtz [296.120271ms]
Jul 31 12:08:20.853: INFO: Created: latency-svc-dqqn7
Jul 31 12:08:20.853: INFO: Got endpoints: latency-svc-dqqn7 [296.134896ms]
Jul 31 12:08:20.854: INFO: Created: latency-svc-ldtck
Jul 31 12:08:20.854: INFO: Got endpoints: latency-svc-ldtck [298.125788ms]
Jul 31 12:08:20.854: INFO: Created: latency-svc-vn7ns
Jul 31 12:08:20.854: INFO: Got endpoints: latency-svc-vn7ns [296.938352ms]
Jul 31 12:08:20.854: INFO: Created: latency-svc-6wz8b
Jul 31 12:08:20.854: INFO: Got endpoints: latency-svc-6wz8b [296.898031ms]
Jul 31 12:08:20.854: INFO: Created: latency-svc-9sggr
Jul 31 12:08:20.854: INFO: Got endpoints: latency-svc-9sggr [296.83008ms]
Jul 31 12:08:20.854: INFO: Created: latency-svc-48jnr
Jul 31 12:08:20.854: INFO: Got endpoints: latency-svc-48jnr [296.705899ms]
Jul 31 12:08:20.854: INFO: Created: latency-svc-bmjlq
Jul 31 12:08:20.854: INFO: Got endpoints: latency-svc-bmjlq [297.27433ms]
Jul 31 12:08:20.855: INFO: Created: latency-svc-9gmx5
Jul 31 12:08:20.855: INFO: Got endpoints: latency-svc-9gmx5 [297.474522ms]
Jul 31 12:08:20.855: INFO: Created: latency-svc-8smvt
Jul 31 12:08:21.057: INFO: Created: latency-svc-l8xnp
Jul 31 12:08:21.057: INFO: Created: latency-svc-mnc7m
Jul 31 12:08:21.057: INFO: Created: latency-svc-7tjcl
Jul 31 12:08:21.057: INFO: Got endpoints: latency-svc-l8xnp [500.48209ms]
Jul 31 12:08:21.058: INFO: Got endpoints: latency-svc-8smvt [500.364703ms]
Jul 31 12:08:21.058: INFO: Got endpoints: latency-svc-mnc7m [500.679307ms]
Jul 31 12:08:21.059: INFO: Got endpoints: latency-svc-7tjcl [502.231235ms]
Jul 31 12:08:21.353: INFO: Created: latency-svc-qj2dp
Jul 31 12:08:21.353: INFO: Created: latency-svc-kdp46
Jul 31 12:08:21.353: INFO: Created: latency-svc-9t52r
Jul 31 12:08:21.353: INFO: Created: latency-svc-p4n84
Jul 31 12:08:21.353: INFO: Got endpoints: latency-svc-p4n84 [499.736093ms]
Jul 31 12:08:21.353: INFO: Got endpoints: latency-svc-kdp46 [500.309207ms]
Jul 31 12:08:21.354: INFO: Got endpoints: latency-svc-9t52r [500.247318ms]
Jul 31 12:08:21.453: INFO: Created: latency-svc-bcjf9
Jul 31 12:08:21.453: INFO: Created: latency-svc-hpqf8
Jul 31 12:08:21.453: INFO: Created: latency-svc-8xlst
Jul 31 12:08:21.453: INFO: Created: latency-svc-jtmbh
Jul 31 12:08:21.453: INFO: Created: latency-svc-pmq2v
Jul 31 12:08:21.453: INFO: Created: latency-svc-rmx9w
Jul 31 12:08:21.453: INFO: Created: latency-svc-275sg
Jul 31 12:08:21.453: INFO: Got endpoints: latency-svc-bcjf9 [599.57411ms]
Jul 31 12:08:21.454: INFO: Got endpoints: latency-svc-qj2dp [599.76917ms]
Jul 31 12:08:21.454: INFO: Got endpoints: latency-svc-hpqf8 [599.251597ms]
Jul 31 12:08:21.454: INFO: Got endpoints: latency-svc-8xlst [600.113262ms]
Jul 31 12:08:21.454: INFO: Got endpoints: latency-svc-jtmbh [600.496379ms]
Jul 31 12:08:21.454: INFO: Got endpoints: latency-svc-pmq2v [601.358881ms]
Jul 31 12:08:21.455: INFO: Got endpoints: latency-svc-rmx9w [600.220768ms]
Jul 31 12:08:21.455: INFO: Got endpoints: latency-svc-275sg [600.61128ms]
Jul 31 12:08:21.553: INFO: Created: latency-svc-b77l5
Jul 31 12:08:21.553: INFO: Created: latency-svc-g4ftz
Jul 31 12:08:21.553: INFO: Created: latency-svc-97hqk
Jul 31 12:08:21.553: INFO: Created: latency-svc-8b9d2
Jul 31 12:08:21.554: INFO: Created: latency-svc-h8t7h
Jul 31 12:08:21.554: INFO: Got endpoints: latency-svc-b77l5 [496.178714ms]
Jul 31 12:08:21.554: INFO: Got endpoints: latency-svc-g4ftz [494.840855ms]
Jul 31 12:08:21.554: INFO: Got endpoints: latency-svc-97hqk [201.313559ms]
Jul 31 12:08:21.555: INFO: Got endpoints: latency-svc-8b9d2 [201.160467ms]
Jul 31 12:08:21.555: INFO: Got endpoints: latency-svc-h8t7h [497.479296ms]
Jul 31 12:08:21.859: INFO: Created: latency-svc-whwqw
Jul 31 12:08:21.859: INFO: Created: latency-svc-4k9mm
Jul 31 12:08:21.860: INFO: Created: latency-svc-pw994
Jul 31 12:08:21.860: INFO: Created: latency-svc-tbvkt
Jul 31 12:08:21.860: INFO: Created: latency-svc-qdxkm
Jul 31 12:08:21.860: INFO: Created: latency-svc-5kcwr
Jul 31 12:08:21.860: INFO: Created: latency-svc-cdp48
Jul 31 12:08:21.860: INFO: Created: latency-svc-zrq46
Jul 31 12:08:21.860: INFO: Created: latency-svc-lrg6j
Jul 31 12:08:21.861: INFO: Created: latency-svc-89s62
Jul 31 12:08:21.861: INFO: Got endpoints: latency-svc-whwqw [407.670066ms]
Jul 31 12:08:21.862: INFO: Got endpoints: latency-svc-4k9mm [803.683351ms]
Jul 31 12:08:21.862: INFO: Got endpoints: latency-svc-pw994 [508.367599ms]
Jul 31 12:08:21.863: INFO: Got endpoints: latency-svc-tbvkt [409.054292ms]
Jul 31 12:08:21.864: INFO: Got endpoints: latency-svc-qdxkm [410.01322ms]
Jul 31 12:08:21.864: INFO: Got endpoints: latency-svc-5kcwr [409.893595ms]
Jul 31 12:08:21.865: INFO: Got endpoints: latency-svc-cdp48 [409.827119ms]
Jul 31 12:08:21.866: INFO: Got endpoints: latency-svc-zrq46 [411.419435ms]
Jul 31 12:08:21.866: INFO: Got endpoints: latency-svc-lrg6j [412.006393ms]
Jul 31 12:08:21.867: INFO: Got endpoints: latency-svc-89s62 [413.06989ms]
Jul 31 12:08:22.255: INFO: Created: latency-svc-2xr8v
Jul 31 12:08:22.255: INFO: Created: latency-svc-bqmmm
Jul 31 12:08:22.255: INFO: Created: latency-svc-g7j5v
Jul 31 12:08:22.255: INFO: Created: latency-svc-ldjpl
Jul 31 12:08:22.256: INFO: Created: latency-svc-pk6fp
Jul 31 12:08:22.256: INFO: Created: latency-svc-hl7hl
Jul 31 12:08:22.256: INFO: Created: latency-svc-qfkx9
Jul 31 12:08:22.256: INFO: Created: latency-svc-nsrvr
Jul 31 12:08:22.256: INFO: Created: latency-svc-2br95
Jul 31 12:08:22.256: INFO: Got endpoints: latency-svc-2br95 [700.899507ms]
Jul 31 12:08:22.257: INFO: Got endpoints: latency-svc-bqmmm [702.814366ms]
Jul 31 12:08:22.258: INFO: Got endpoints: latency-svc-g7j5v [703.27904ms]
Jul 31 12:08:22.258: INFO: Got endpoints: latency-svc-ldjpl [703.5097ms]
Jul 31 12:08:22.259: INFO: Got endpoints: latency-svc-pk6fp [703.867435ms]
Jul 31 12:08:22.259: INFO: Got endpoints: latency-svc-hl7hl [397.581296ms]
Jul 31 12:08:22.260: INFO: Got endpoints: latency-svc-qfkx9 [398.061547ms]
Jul 31 12:08:22.275: INFO: Got endpoints: latency-svc-2xr8v [411.895343ms]
Jul 31 12:08:22.274: INFO: Got endpoints: latency-svc-nsrvr [408.978601ms]
Jul 31 12:08:22.288: INFO: Created: latency-svc-4crps
Jul 31 12:08:22.288: INFO: Got endpoints: latency-svc-4crps [421.766238ms]
Jul 31 12:08:22.653: INFO: Created: latency-svc-dr7tg
Jul 31 12:08:22.653: INFO: Created: latency-svc-hfwf5
Jul 31 12:08:22.653: INFO: Created: latency-svc-qtcn7
Jul 31 12:08:22.653: INFO: Created: latency-svc-5xtzg
Jul 31 12:08:22.654: INFO: Created: latency-svc-qhlb8
Jul 31 12:08:22.654: INFO: Created: latency-svc-g4mvp
Jul 31 12:08:22.654: INFO: Created: latency-svc-qrskq
Jul 31 12:08:22.654: INFO: Created: latency-svc-65lg8
Jul 31 12:08:22.654: INFO: Created: latency-svc-s8dvh
Jul 31 12:08:22.654: INFO: Created: latency-svc-q98j4
Jul 31 12:08:22.654: INFO: Created: latency-svc-vncsg
Jul 31 12:08:22.654: INFO: Got endpoints: latency-svc-vncsg [394.940672ms]
Jul 31 12:08:22.654: INFO: Got endpoints: latency-svc-hfwf5 [789.761304ms]
Jul 31 12:08:22.654: INFO: Got endpoints: latency-svc-qtcn7 [786.706827ms]
Jul 31 12:08:22.654: INFO: Got endpoints: latency-svc-5xtzg [789.810524ms]
Jul 31 12:08:22.654: INFO: Got endpoints: latency-svc-qhlb8 [788.299951ms]
Jul 31 12:08:22.654: INFO: Got endpoints: latency-svc-g4mvp [787.746079ms]
Jul 31 12:08:22.654: INFO: Got endpoints: latency-svc-qrskq [397.85594ms]
Jul 31 12:08:22.654: INFO: Got endpoints: latency-svc-65lg8 [397.597791ms]
Jul 31 12:08:22.655: INFO: Got endpoints: latency-svc-s8dvh [396.869245ms]
Jul 31 12:08:22.655: INFO: Got endpoints: latency-svc-q98j4 [396.451363ms]
Jul 31 12:08:23.253: INFO: Created: latency-svc-gjlqq
Jul 31 12:08:23.260: INFO: Got endpoints: latency-svc-gjlqq [981.740335ms]
Jul 31 12:08:23.259: INFO: Created: latency-svc-w582k
Jul 31 12:08:23.260: INFO: Got endpoints: latency-svc-w582k [987.339291ms]
Jul 31 12:08:23.260: INFO: Got endpoints: latency-svc-dr7tg [1.000560251s]
Jul 31 12:08:23.260: INFO: Created: latency-svc-k7rjc
Jul 31 12:08:23.261: INFO: Got endpoints: latency-svc-k7rjc [985.642987ms]
Jul 31 12:08:23.274: INFO: Created: latency-svc-k4rvr
Jul 31 12:08:23.324: INFO: Got endpoints: latency-svc-k4rvr [670.181065ms]
Jul 31 12:08:24.153: INFO: Created: latency-svc-xwlrz
Jul 31 12:08:24.153: INFO: Got endpoints: latency-svc-xwlrz [1.498785495s]
Jul 31 12:08:24.153: INFO: Created: latency-svc-h6tls
Jul 31 12:08:24.153: INFO: Got endpoints: latency-svc-h6tls [1.49931622s]
Jul 31 12:08:24.154: INFO: Created: latency-svc-dlnwl
Jul 31 12:08:24.154: INFO: Created: latency-svc-pbl45
Jul 31 12:08:24.154: INFO: Got endpoints: latency-svc-pbl45 [1.499289963s]
Jul 31 12:08:24.154: INFO: Created: latency-svc-jvv6v
Jul 31 12:08:24.155: INFO: Created: latency-svc-df2j5
Jul 31 12:08:24.155: INFO: Created: latency-svc-5mk55
Jul 31 12:08:24.155: INFO: Created: latency-svc-5z24p
Jul 31 12:08:24.155: INFO: Created: latency-svc-tx7fv
Jul 31 12:08:24.155: INFO: Created: latency-svc-h9npv
Jul 31 12:08:24.155: INFO: Created: latency-svc-xk6wq
Jul 31 12:08:24.155: INFO: Created: latency-svc-hnhxl
Jul 31 12:08:24.155: INFO: Created: latency-svc-pk489
Jul 31 12:08:24.155: INFO: Created: latency-svc-kzwcn
Jul 31 12:08:24.155: INFO: Created: latency-svc-pd56r
Jul 31 12:08:24.156: INFO: Got endpoints: latency-svc-xk6wq [1.501241401s]
Jul 31 12:08:24.156: INFO: Got endpoints: latency-svc-jvv6v [1.502226596s]
Jul 31 12:08:24.156: INFO: Got endpoints: latency-svc-5mk55 [1.502084391s]
Jul 31 12:08:24.156: INFO: Got endpoints: latency-svc-5z24p [1.502005913s]
Jul 31 12:08:24.157: INFO: Got endpoints: latency-svc-tx7fv [1.502281534s]
Jul 31 12:08:24.157: INFO: Got endpoints: latency-svc-h9npv [1.502151996s]
Jul 31 12:08:24.157: INFO: Got endpoints: latency-svc-df2j5 [1.869499849s]
Jul 31 12:08:24.161: INFO: Got endpoints: latency-svc-pd56r [900.263635ms]
Jul 31 12:08:24.162: INFO: Got endpoints: latency-svc-pk489 [902.751188ms]
Jul 31 12:08:24.162: INFO: Got endpoints: latency-svc-kzwcn [902.462502ms]
Jul 31 12:08:24.163: INFO: Got endpoints: latency-svc-hnhxl [902.399883ms]
Jul 31 12:08:24.163: INFO: Got endpoints: latency-svc-dlnwl [838.613758ms]
Jul 31 12:08:24.229: INFO: Created: latency-svc-mwg52
Jul 31 12:08:24.237: INFO: Got endpoints: latency-svc-mwg52 [83.040635ms]
Jul 31 12:08:24.654: INFO: Created: latency-svc-kczw6
Jul 31 12:08:24.654: INFO: Created: latency-svc-65tw4
Jul 31 12:08:24.654: INFO: Got endpoints: latency-svc-kczw6 [500.987279ms]
Jul 31 12:08:24.654: INFO: Got endpoints: latency-svc-65tw4 [498.757311ms]
Jul 31 12:08:24.655: INFO: Created: latency-svc-rcmpv
Jul 31 12:08:24.655: INFO: Created: latency-svc-vbxrp
Jul 31 12:08:24.655: INFO: Got endpoints: latency-svc-rcmpv [492.194777ms]
Jul 31 12:08:24.655: INFO: Got endpoints: latency-svc-vbxrp [498.651065ms]
Jul 31 12:08:24.655: INFO: Created: latency-svc-mkh55
Jul 31 12:08:24.655: INFO: Got endpoints: latency-svc-mkh55 [501.535835ms]
Jul 31 12:08:24.655: INFO: Created: latency-svc-d2kql
Jul 31 12:08:24.655: INFO: Got endpoints: latency-svc-d2kql [498.858797ms]
Jul 31 12:08:24.655: INFO: Created: latency-svc-rnl8w
Jul 31 12:08:24.655: INFO: Got endpoints: latency-svc-rnl8w [494.38433ms]
Jul 31 12:08:24.655: INFO: Created: latency-svc-b6nhp
Jul 31 12:08:24.655: INFO: Got endpoints: latency-svc-b6nhp [492.762568ms]
Jul 31 12:08:24.655: INFO: Created: latency-svc-dkcz4
Jul 31 12:08:24.655: INFO: Got endpoints: latency-svc-dkcz4 [493.016978ms]
Jul 31 12:08:24.655: INFO: Created: latency-svc-rlfb9
Jul 31 12:08:24.655: INFO: Got endpoints: latency-svc-rlfb9 [492.712616ms]
Jul 31 12:08:24.655: INFO: Created: latency-svc-8czb7
Jul 31 12:08:24.656: INFO: Got endpoints: latency-svc-8czb7 [499.071316ms]
Jul 31 12:08:24.655: INFO: Created: latency-svc-rh4jc
Jul 31 12:08:24.656: INFO: Got endpoints: latency-svc-rh4jc [498.92122ms]
Jul 31 12:08:24.655: INFO: Created: latency-svc-w6xhr
Jul 31 12:08:24.656: INFO: Got endpoints: latency-svc-w6xhr [499.688921ms]
Jul 31 12:08:24.655: INFO: Created: latency-svc-xq4kc
Jul 31 12:08:24.656: INFO: Got endpoints: latency-svc-xq4kc [498.435273ms]
Jul 31 12:08:25.154: INFO: Created: latency-svc-l8zmm
Jul 31 12:08:25.154: INFO: Created: latency-svc-thnhh
Jul 31 12:08:25.154: INFO: Created: latency-svc-fp448
Jul 31 12:08:25.154: INFO: Created: latency-svc-njpcf
Jul 31 12:08:25.154: INFO: Created: latency-svc-4tbc4
Jul 31 12:08:25.154: INFO: Created: latency-svc-7r75s
Jul 31 12:08:25.154: INFO: Created: latency-svc-97mkh
Jul 31 12:08:25.154: INFO: Created: latency-svc-x7snw
Jul 31 12:08:25.154: INFO: Created: latency-svc-htbnr
Jul 31 12:08:25.154: INFO: Created: latency-svc-fntrh
Jul 31 12:08:25.154: INFO: Created: latency-svc-p8f5q
Jul 31 12:08:25.154: INFO: Created: latency-svc-nv6gv
Jul 31 12:08:25.154: INFO: Created: latency-svc-ndr55
Jul 31 12:08:25.154: INFO: Created: latency-svc-fqglh
Jul 31 12:08:25.154: INFO: Created: latency-svc-qzdnf
Jul 31 12:08:25.158: INFO: Got endpoints: latency-svc-l8zmm [921.240627ms]
Jul 31 12:08:25.158: INFO: Got endpoints: latency-svc-x7snw [503.764616ms]
Jul 31 12:08:25.158: INFO: Got endpoints: latency-svc-97mkh [503.458332ms]
Jul 31 12:08:25.158: INFO: Got endpoints: latency-svc-7r75s [502.673373ms]
Jul 31 12:08:25.158: INFO: Got endpoints: latency-svc-thnhh [503.956741ms]
Jul 31 12:08:25.158: INFO: Got endpoints: latency-svc-fp448 [503.468819ms]
Jul 31 12:08:25.158: INFO: Got endpoints: latency-svc-njpcf [503.441828ms]
Jul 31 12:08:25.158: INFO: Got endpoints: latency-svc-4tbc4 [502.83302ms]
Jul 31 12:08:25.159: INFO: Got endpoints: latency-svc-htbnr [503.877174ms]
Jul 31 12:08:25.161: INFO: Got endpoints: latency-svc-p8f5q [505.621291ms]
Jul 31 12:08:25.162: INFO: Got endpoints: latency-svc-ndr55 [505.954416ms]
Jul 31 12:08:25.162: INFO: Got endpoints: latency-svc-qzdnf [506.458797ms]
Jul 31 12:08:25.162: INFO: Got endpoints: latency-svc-nv6gv [506.17623ms]
Jul 31 12:08:25.162: INFO: Got endpoints: latency-svc-fntrh [506.301129ms]
Jul 31 12:08:25.162: INFO: Got endpoints: latency-svc-fqglh [507.031706ms]
Jul 31 12:08:25.368: INFO: Created: latency-svc-ggst9
Jul 31 12:08:25.368: INFO: Created: latency-svc-jxtft
Jul 31 12:08:25.368: INFO: Created: latency-svc-nqvwh
Jul 31 12:08:25.368: INFO: Created: latency-svc-mq9sg
Jul 31 12:08:25.368: INFO: Got endpoints: latency-svc-ggst9 [209.137815ms]
Jul 31 12:08:25.369: INFO: Got endpoints: latency-svc-jxtft [210.830037ms]
Jul 31 12:08:25.369: INFO: Got endpoints: latency-svc-nqvwh [207.99812ms]
Jul 31 12:08:25.370: INFO: Got endpoints: latency-svc-mq9sg [210.869766ms]
Jul 31 12:08:25.379: INFO: Created: latency-svc-m9j4q
Jul 31 12:08:25.384: INFO: Got endpoints: latency-svc-m9j4q [224.832336ms]
Jul 31 12:08:26.054: INFO: Created: latency-svc-c5mr9
Jul 31 12:08:26.054: INFO: Created: latency-svc-gtgwf
Jul 31 12:08:26.054: INFO: Created: latency-svc-mkg7m
Jul 31 12:08:26.054: INFO: Created: latency-svc-mwbdj
Jul 31 12:08:26.054: INFO: Created: latency-svc-zdfns
Jul 31 12:08:26.054: INFO: Created: latency-svc-h64sm
Jul 31 12:08:26.054: INFO: Created: latency-svc-sdndd
Jul 31 12:08:26.054: INFO: Created: latency-svc-2r52l
Jul 31 12:08:26.054: INFO: Created: latency-svc-gmz49
Jul 31 12:08:26.054: INFO: Created: latency-svc-cpkmc
Jul 31 12:08:26.054: INFO: Created: latency-svc-xmvdd
Jul 31 12:08:26.054: INFO: Created: latency-svc-728r8
Jul 31 12:08:26.054: INFO: Created: latency-svc-p97f6
Jul 31 12:08:26.055: INFO: Created: latency-svc-2mc67
Jul 31 12:08:26.055: INFO: Got endpoints: latency-svc-c5mr9 [684.924679ms]
Jul 31 12:08:26.055: INFO: Got endpoints: latency-svc-gtgwf [895.921962ms]
Jul 31 12:08:26.055: INFO: Got endpoints: latency-svc-mkg7m [896.638765ms]
Jul 31 12:08:26.055: INFO: Got endpoints: latency-svc-mwbdj [895.874844ms]
Jul 31 12:08:26.055: INFO: Got endpoints: latency-svc-zdfns [892.657398ms]
Jul 31 12:08:26.055: INFO: Got endpoints: latency-svc-h64sm [893.339232ms]
Jul 31 12:08:26.055: INFO: Got endpoints: latency-svc-sdndd [893.778843ms]
Jul 31 12:08:26.055: INFO: Got endpoints: latency-svc-2r52l [893.763569ms]
Jul 31 12:08:26.056: INFO: Got endpoints: latency-svc-gmz49 [893.309279ms]
Jul 31 12:08:26.056: INFO: Got endpoints: latency-svc-cpkmc [897.449942ms]
Jul 31 12:08:26.056: INFO: Got endpoints: latency-svc-xmvdd [896.813208ms]
Jul 31 12:08:26.056: INFO: Got endpoints: latency-svc-728r8 [686.455125ms]
Jul 31 12:08:26.056: INFO: Got endpoints: latency-svc-p97f6 [686.391418ms]
Jul 31 12:08:26.056: INFO: Got endpoints: latency-svc-2mc67 [688.224637ms]
Jul 31 12:08:26.757: INFO: Created: latency-svc-2j6k5
Jul 31 12:08:26.757: INFO: Created: latency-svc-d2m2d
Jul 31 12:08:26.757: INFO: Created: latency-svc-r9mzr
Jul 31 12:08:26.757: INFO: Created: latency-svc-t4dt5
Jul 31 12:08:26.757: INFO: Created: latency-svc-fvgk5
Jul 31 12:08:26.757: INFO: Created: latency-svc-g7xl8
Jul 31 12:08:26.757: INFO: Created: latency-svc-hqff8
Jul 31 12:08:26.757: INFO: Created: latency-svc-cgzcx
Jul 31 12:08:26.757: INFO: Got endpoints: latency-svc-2j6k5 [701.99637ms]
Jul 31 12:08:26.757: INFO: Got endpoints: latency-svc-d2m2d [701.640326ms]
Jul 31 12:08:26.758: INFO: Got endpoints: latency-svc-t4dt5 [701.806784ms]
Jul 31 12:08:26.757: INFO: Created: latency-svc-tdf97
Jul 31 12:08:26.758: INFO: Got endpoints: latency-svc-tdf97 [702.748945ms]
Jul 31 12:08:26.758: INFO: Created: latency-svc-j8b8p
Jul 31 12:08:26.758: INFO: Got endpoints: latency-svc-j8b8p [702.582837ms]
Jul 31 12:08:26.758: INFO: Created: latency-svc-twsq7
Jul 31 12:08:26.758: INFO: Got endpoints: latency-svc-twsq7 [702.103074ms]
Jul 31 12:08:26.758: INFO: Created: latency-svc-2z9b4
Jul 31 12:08:26.758: INFO: Got endpoints: latency-svc-2z9b4 [702.951148ms]
Jul 31 12:08:26.758: INFO: Created: latency-svc-gzlnb
Jul 31 12:08:26.758: INFO: Got endpoints: latency-svc-gzlnb [702.891722ms]
Jul 31 12:08:26.758: INFO: Got endpoints: latency-svc-cgzcx [702.700393ms]
Jul 31 12:08:26.758: INFO: Got endpoints: latency-svc-r9mzr [1.374147455s]
Jul 31 12:08:26.758: INFO: Got endpoints: latency-svc-g7xl8 [703.269575ms]
Jul 31 12:08:26.758: INFO: Got endpoints: latency-svc-fvgk5 [702.932424ms]
Jul 31 12:08:26.758: INFO: Got endpoints: latency-svc-hqff8 [703.052104ms]
Jul 31 12:08:26.756: INFO: Created: latency-svc-2p6k2
Jul 31 12:08:26.759: INFO: Got endpoints: latency-svc-2p6k2 [702.95149ms]
Jul 31 12:08:26.760: INFO: Created: latency-svc-hb8h8
Jul 31 12:08:26.760: INFO: Got endpoints: latency-svc-hb8h8 [704.673497ms]
Jul 31 12:08:27.053: INFO: Created: latency-svc-fclcz
Jul 31 12:08:27.053: INFO: Created: latency-svc-fvwmq
Jul 31 12:08:27.053: INFO: Created: latency-svc-6jx4b
Jul 31 12:08:27.053: INFO: Created: latency-svc-f2bf7
Jul 31 12:08:27.053: INFO: Got endpoints: latency-svc-f2bf7 [295.022783ms]
Jul 31 12:08:27.054: INFO: Got endpoints: latency-svc-fvwmq [296.629694ms]
Jul 31 12:08:27.054: INFO: Got endpoints: latency-svc-6jx4b [293.959703ms]
Jul 31 12:08:27.153: INFO: Created: latency-svc-5wsnd
Jul 31 12:08:27.153: INFO: Got endpoints: latency-svc-5wsnd [395.614512ms]
Jul 31 12:08:27.153: INFO: Created: latency-svc-5z9lc
Jul 31 12:08:27.153: INFO: Got endpoints: latency-svc-5z9lc [395.972474ms]
Jul 31 12:08:27.154: INFO: Got endpoints: latency-svc-fclcz [396.311813ms]
Jul 31 12:08:27.154: INFO: Created: latency-svc-n2zr8
Jul 31 12:08:27.154: INFO: Created: latency-svc-gpzkv
Jul 31 12:08:27.154: INFO: Got endpoints: latency-svc-gpzkv [395.674863ms]
Jul 31 12:08:27.253: INFO: Created: latency-svc-wkv9x
Jul 31 12:08:27.254: INFO: Created: latency-svc-c85dr
Jul 31 12:08:27.254: INFO: Created: latency-svc-s89zk
Jul 31 12:08:27.254: INFO: Got endpoints: latency-svc-wkv9x [494.818422ms]
Jul 31 12:08:27.254: INFO: Got endpoints: latency-svc-n2zr8 [495.093872ms]
Jul 31 12:08:27.254: INFO: Got endpoints: latency-svc-c85dr [496.090175ms]
Jul 31 12:08:27.254: INFO: Got endpoints: latency-svc-s89zk [495.611615ms]
Jul 31 12:08:27.653: INFO: Created: latency-svc-nfvfv
Jul 31 12:08:27.653: INFO: Created: latency-svc-9cnmm
Jul 31 12:08:27.653: INFO: Created: latency-svc-m5jvb
Jul 31 12:08:27.653: INFO: Created: latency-svc-zhbbn
Jul 31 12:08:27.653: INFO: Created: latency-svc-pzjjz
Jul 31 12:08:27.653: INFO: Created: latency-svc-lzc2s
Jul 31 12:08:27.653: INFO: Created: latency-svc-77l9g
Jul 31 12:08:27.653: INFO: Created: latency-svc-t9mpn
Jul 31 12:08:27.653: INFO: Created: latency-svc-76wkw
Jul 31 12:08:27.653: INFO: Created: latency-svc-p6xh8
Jul 31 12:08:27.654: INFO: Created: latency-svc-wqf9s
Jul 31 12:08:27.654: INFO: Got endpoints: latency-svc-nfvfv [500.264312ms]
Jul 31 12:08:27.655: INFO: Got endpoints: latency-svc-77l9g [600.427863ms]
Jul 31 12:08:27.655: INFO: Got endpoints: latency-svc-9cnmm [896.348281ms]
Jul 31 12:08:27.655: INFO: Got endpoints: latency-svc-m5jvb [897.004683ms]
Jul 31 12:08:27.656: INFO: Got endpoints: latency-svc-zhbbn [897.037976ms]
Jul 31 12:08:27.656: INFO: Got endpoints: latency-svc-pzjjz [896.968442ms]
Jul 31 12:08:27.656: INFO: Got endpoints: latency-svc-lzc2s [602.48808ms]
Jul 31 12:08:27.656: INFO: Got endpoints: latency-svc-p6xh8 [501.489669ms]
Jul 31 12:08:27.656: INFO: Got endpoints: latency-svc-t9mpn [601.527344ms]
Jul 31 12:08:27.656: INFO: Got endpoints: latency-svc-76wkw [502.300208ms]
Jul 31 12:08:27.656: INFO: Got endpoints: latency-svc-wqf9s [502.477868ms]
Jul 31 12:08:27.754: INFO: Created: latency-svc-wlw44
Jul 31 12:08:27.754: INFO: Created: latency-svc-jj45w
Jul 31 12:08:27.754: INFO: Got endpoints: latency-svc-jj45w [499.96864ms]
Jul 31 12:08:27.853: INFO: Created: latency-svc-2pxv4
Jul 31 12:08:27.853: INFO: Created: latency-svc-624fx
Jul 31 12:08:27.853: INFO: Created: latency-svc-clvvq
Jul 31 12:08:27.853: INFO: Created: latency-svc-ljjkt
Jul 31 12:08:27.853: INFO: Got endpoints: latency-svc-2pxv4 [197.001888ms]
Jul 31 12:08:27.853: INFO: Got endpoints: latency-svc-wlw44 [598.800066ms]
Jul 31 12:08:27.853: INFO: Got endpoints: latency-svc-clvvq [599.329854ms]
Jul 31 12:08:27.853: INFO: Got endpoints: latency-svc-624fx [599.20715ms]
Jul 31 12:08:27.854: INFO: Got endpoints: latency-svc-ljjkt [197.637791ms]
Jul 31 12:08:27.954: INFO: Created: latency-svc-g6vwr
Jul 31 12:08:27.954: INFO: Created: latency-svc-5scks
Jul 31 12:08:27.954: INFO: Created: latency-svc-59zmp
Jul 31 12:08:27.954: INFO: Created: latency-svc-l84ll
Jul 31 12:08:27.954: INFO: Got endpoints: latency-svc-l84ll [297.972663ms]
Jul 31 12:08:27.954: INFO: Got endpoints: latency-svc-5scks [300.123576ms]
Jul 31 12:08:27.954: INFO: Got endpoints: latency-svc-59zmp [298.256064ms]
Jul 31 12:08:27.961: INFO: Got endpoints: latency-svc-g6vwr [306.113375ms]
Jul 31 12:08:27.971: INFO: Created: latency-svc-jxwph
Jul 31 12:08:27.987: INFO: Created: latency-svc-zczrm
Jul 31 12:08:28.002: INFO: Created: latency-svc-8xf5m
Jul 31 12:08:28.010: INFO: Got endpoints: latency-svc-jxwph [355.425597ms]
Jul 31 12:08:28.026: INFO: Created: latency-svc-5s8xx
Jul 31 12:08:28.253: INFO: Created: latency-svc-vd55l
Jul 31 12:08:28.253: INFO: Created: latency-svc-pkkdc
Jul 31 12:08:28.253: INFO: Created: latency-svc-fdkkt
Jul 31 12:08:28.253: INFO: Created: latency-svc-nplqg
Jul 31 12:08:28.253: INFO: Created: latency-svc-74tt7
Jul 31 12:08:28.253: INFO: Created: latency-svc-stldg
Jul 31 12:08:28.253: INFO: Got endpoints: latency-svc-fdkkt [499.631548ms]
Jul 31 12:08:28.253: INFO: Created: latency-svc-49f6b
Jul 31 12:08:28.253: INFO: Got endpoints: latency-svc-5s8xx [597.890932ms]
Jul 31 12:08:28.254: INFO: Got endpoints: latency-svc-vd55l [597.832951ms]
Jul 31 12:08:28.254: INFO: Created: latency-svc-dclm7
Jul 31 12:08:28.254: INFO: Created: latency-svc-m2pt7
Jul 31 12:08:28.254: INFO: Created: latency-svc-s92dn
Jul 31 12:08:28.254: INFO: Got endpoints: latency-svc-zczrm [598.031146ms]
Jul 31 12:08:28.254: INFO: Got endpoints: latency-svc-8xf5m [598.42842ms]
Jul 31 12:08:29.254: INFO: Created: latency-svc-t654j
Jul 31 12:08:29.254: INFO: Created: latency-svc-jhlw2
Jul 31 12:08:29.254: INFO: Created: latency-svc-mscfz
Jul 31 12:08:29.255: INFO: Created: latency-svc-ljdxf
Jul 31 12:08:29.255: INFO: Got endpoints: latency-svc-49f6b [1.401417154s]
Jul 31 12:08:29.255: INFO: Got endpoints: latency-svc-74tt7 [1.402141208s]
Jul 31 12:08:29.256: INFO: Got endpoints: latency-svc-stldg [1.402287405s]
Jul 31 12:08:29.256: INFO: Got endpoints: latency-svc-pkkdc [1.402899166s]
Jul 31 12:08:29.256: INFO: Created: latency-svc-pfnw8
Jul 31 12:08:29.256: INFO: Got endpoints: latency-svc-dclm7 [1.402754366s]
Jul 31 12:08:29.256: INFO: Got endpoints: latency-svc-t654j [1.002958742s]
Jul 31 12:08:29.256: INFO: Got endpoints: latency-svc-m2pt7 [1.302505274s]
Jul 31 12:08:29.256: INFO: Got endpoints: latency-svc-s92dn [1.302397717s]
Jul 31 12:08:29.256: INFO: Got endpoints: latency-svc-nplqg [1.302020428s]
Jul 31 12:08:29.256: INFO: Got endpoints: latency-svc-jhlw2 [1.295441116s]
Jul 31 12:08:29.256: INFO: Got endpoints: latency-svc-mscfz [1.246333124s]
Jul 31 12:08:29.256: INFO: Got endpoints: latency-svc-pfnw8 [1.002525086s]
Jul 31 12:08:29.256: INFO: Got endpoints: latency-svc-ljdxf [1.002356112s]
Jul 31 12:08:29.470: INFO: Created: latency-svc-vsml4
Jul 31 12:08:29.470: INFO: Created: latency-svc-jd6fx
Jul 31 12:08:29.470: INFO: Got endpoints: latency-svc-vsml4 [1.21656621s]
Jul 31 12:08:29.470: INFO: Got endpoints: latency-svc-jd6fx [1.216684929s]
Jul 31 12:08:29.553: INFO: Created: latency-svc-grxww
Jul 31 12:08:29.553: INFO: Got endpoints: latency-svc-grxww [297.845134ms]
Jul 31 12:08:29.553: INFO: Created: latency-svc-75hr7
Jul 31 12:08:29.553: INFO: Got endpoints: latency-svc-75hr7 [298.492544ms]
Jul 31 12:08:29.554: INFO: Latencies: [83.040635ms 197.001888ms 197.637791ms 201.160467ms 201.313559ms 207.99812ms 209.137815ms 210.830037ms 210.869766ms 224.832336ms 293.959703ms 295.022783ms 295.775382ms 296.120271ms 296.134896ms 296.629694ms 296.705899ms 296.83008ms 296.898031ms 296.938352ms 297.27433ms 297.474522ms 297.744883ms 297.845134ms 297.972663ms 298.125788ms 298.256064ms 298.492544ms 300.123576ms 306.113375ms 355.425597ms 394.940672ms 395.614512ms 395.674863ms 395.972474ms 396.311813ms 396.451363ms 396.869245ms 397.581296ms 397.597791ms 397.85594ms 398.061547ms 407.670066ms 408.978601ms 409.054292ms 409.827119ms 409.893595ms 410.01322ms 411.419435ms 411.895343ms 412.006393ms 413.06989ms 421.766238ms 492.194777ms 492.712616ms 492.762568ms 493.016978ms 494.38433ms 494.818422ms 494.840855ms 495.093872ms 495.611615ms 496.090175ms 496.178714ms 497.479296ms 498.435273ms 498.651065ms 498.757311ms 498.858797ms 498.92122ms 499.071316ms 499.631548ms 499.688921ms 499.736093ms 499.96864ms 500.247318ms 500.264312ms 500.309207ms 500.364703ms 500.48209ms 500.679307ms 500.987279ms 501.489669ms 501.535835ms 502.231235ms 502.300208ms 502.477868ms 502.673373ms 502.83302ms 503.441828ms 503.458332ms 503.468819ms 503.764616ms 503.877174ms 503.956741ms 505.621291ms 505.954416ms 506.17623ms 506.301129ms 506.458797ms 507.031706ms 508.367599ms 597.832951ms 597.890932ms 598.031146ms 598.42842ms 598.800066ms 599.20715ms 599.251597ms 599.329854ms 599.57411ms 599.76917ms 600.113262ms 600.220768ms 600.427863ms 600.496379ms 600.61128ms 601.358881ms 601.527344ms 602.48808ms 670.181065ms 684.924679ms 686.391418ms 686.455125ms 688.224637ms 700.899507ms 701.640326ms 701.806784ms 701.99637ms 702.103074ms 702.582837ms 702.700393ms 702.748945ms 702.814366ms 702.891722ms 702.932424ms 702.951148ms 702.95149ms 703.052104ms 703.269575ms 703.27904ms 703.5097ms 703.867435ms 704.673497ms 786.706827ms 787.746079ms 788.299951ms 789.761304ms 789.810524ms 803.683351ms 838.613758ms 892.657398ms 893.309279ms 893.339232ms 893.763569ms 893.778843ms 895.874844ms 895.921962ms 896.348281ms 896.638765ms 896.813208ms 896.968442ms 897.004683ms 897.037976ms 897.449942ms 900.263635ms 902.399883ms 902.462502ms 902.751188ms 921.240627ms 981.740335ms 985.642987ms 987.339291ms 1.000560251s 1.002356112s 1.002525086s 1.002958742s 1.21656621s 1.216684929s 1.246333124s 1.295441116s 1.302020428s 1.302397717s 1.302505274s 1.374147455s 1.401417154s 1.402141208s 1.402287405s 1.402754366s 1.402899166s 1.498785495s 1.499289963s 1.49931622s 1.501241401s 1.502005913s 1.502084391s 1.502151996s 1.502226596s 1.502281534s 1.869499849s]
Jul 31 12:08:29.554: INFO: 50 %ile: 507.031706ms
Jul 31 12:08:29.554: INFO: 90 %ile: 1.295441116s
Jul 31 12:08:29.554: INFO: 99 %ile: 1.502281534s
Jul 31 12:08:29.554: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:08:29.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-8586" for this suite.
Jul 31 12:08:47.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:08:49.601: INFO: namespace svc-latency-8586 deletion completed in 19.843522432s

• [SLOW TEST:39.180 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:08:49.601: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:08:55.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5917" for this suite.
Jul 31 12:09:02.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:09:10.071: INFO: namespace kubelet-test-5917 deletion completed in 14.416763428s

• [SLOW TEST:20.470 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:09:10.071: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-22bf
STEP: Creating a pod to test atomic-volume-subpath
Jul 31 12:09:10.753: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-22bf" in namespace "subpath-3277" to be "success or failure"
Jul 31 12:09:11.052: INFO: Pod "pod-subpath-test-projected-22bf": Phase="Pending", Reason="", readiness=false. Elapsed: 299.702171ms
Jul 31 12:09:13.953: INFO: Pod "pod-subpath-test-projected-22bf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.200510278s
Jul 31 12:09:16.653: INFO: Pod "pod-subpath-test-projected-22bf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.900173945s
Jul 31 12:09:19.152: INFO: Pod "pod-subpath-test-projected-22bf": Phase="Running", Reason="", readiness=true. Elapsed: 8.399665796s
Jul 31 12:09:21.658: INFO: Pod "pod-subpath-test-projected-22bf": Phase="Running", Reason="", readiness=true. Elapsed: 10.905121597s
Jul 31 12:09:23.758: INFO: Pod "pod-subpath-test-projected-22bf": Phase="Running", Reason="", readiness=true. Elapsed: 13.004864562s
Jul 31 12:09:25.857: INFO: Pod "pod-subpath-test-projected-22bf": Phase="Running", Reason="", readiness=true. Elapsed: 15.104086932s
Jul 31 12:09:29.757: INFO: Pod "pod-subpath-test-projected-22bf": Phase="Running", Reason="", readiness=true. Elapsed: 19.003875207s
Jul 31 12:09:31.764: INFO: Pod "pod-subpath-test-projected-22bf": Phase="Running", Reason="", readiness=true. Elapsed: 21.011672007s
Jul 31 12:09:34.153: INFO: Pod "pod-subpath-test-projected-22bf": Phase="Running", Reason="", readiness=true. Elapsed: 23.400022989s
Jul 31 12:09:36.372: INFO: Pod "pod-subpath-test-projected-22bf": Phase="Running", Reason="", readiness=true. Elapsed: 25.6196755s
Jul 31 12:09:40.153: INFO: Pod "pod-subpath-test-projected-22bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 29.40066517s
STEP: Saw pod success
Jul 31 12:09:40.153: INFO: Pod "pod-subpath-test-projected-22bf" satisfied condition "success or failure"
Jul 31 12:09:41.353: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-subpath-test-projected-22bf container test-container-subpath-projected-22bf: <nil>
STEP: delete the pod
Jul 31 12:09:42.301: INFO: Waiting for pod pod-subpath-test-projected-22bf to disappear
Jul 31 12:09:43.253: INFO: Pod pod-subpath-test-projected-22bf no longer exists
STEP: Deleting pod pod-subpath-test-projected-22bf
Jul 31 12:09:43.253: INFO: Deleting pod "pod-subpath-test-projected-22bf" in namespace "subpath-3277"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:09:43.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3277" for this suite.
Jul 31 12:09:50.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:10:00.860: INFO: namespace subpath-3277 deletion completed in 17.407051313s

• [SLOW TEST:50.789 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:10:00.861: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Jul 31 12:10:01.453: INFO: Waiting up to 5m0s for pod "pod-1f415508-b38c-11e9-82b5-da5bffca47b9" in namespace "emptydir-5606" to be "success or failure"
Jul 31 12:10:01.559: INFO: Pod "pod-1f415508-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 105.273622ms
Jul 31 12:10:03.858: INFO: Pod "pod-1f415508-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.404080088s
Jul 31 12:10:06.056: INFO: Pod "pod-1f415508-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.602392762s
Jul 31 12:10:08.353: INFO: Pod "pod-1f415508-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.899900058s
Jul 31 12:10:10.653: INFO: Pod "pod-1f415508-b38c-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 9.199471465s
STEP: Saw pod success
Jul 31 12:10:10.653: INFO: Pod "pod-1f415508-b38c-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:10:10.853: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-1f415508-b38c-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 12:10:11.353: INFO: Waiting for pod pod-1f415508-b38c-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:10:11.657: INFO: Pod pod-1f415508-b38c-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:10:11.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5606" for this suite.
Jul 31 12:10:18.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:10:26.042: INFO: namespace emptydir-5606 deletion completed in 14.187635312s

• [SLOW TEST:25.181 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:10:26.043: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 12:10:26.537: INFO: Creating deployment "test-recreate-deployment"
Jul 31 12:10:27.252: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jul 31 12:10:28.553: INFO: Waiting deployment "test-recreate-deployment" to complete
Jul 31 12:10:28.862: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700171826, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700171826, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700171826, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700171826, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6566d46b4b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 12:10:31.105: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700171826, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700171826, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700171826, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700171826, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6566d46b4b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 12:10:34.653: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jul 31 12:10:34.877: INFO: Updating deployment test-recreate-deployment
Jul 31 12:10:34.877: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 31 12:10:37.566: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-9483,SelfLink:/apis/apps/v1/namespaces/deployment-9483/deployments/test-recreate-deployment,UID:2e514dd0-b38c-11e9-a303-6acf1189be78,ResourceVersion:11903,Generation:2,CreationTimestamp:2019-07-31 12:10:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-07-31 12:10:35 +0000 UTC 2019-07-31 12:10:35 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-07-31 12:10:35 +0000 UTC 2019-07-31 12:10:26 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-745fb9c84c" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jul 31 12:10:37.575: INFO: New ReplicaSet "test-recreate-deployment-745fb9c84c" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c,GenerateName:,Namespace:deployment-9483,SelfLink:/apis/apps/v1/namespaces/deployment-9483/replicasets/test-recreate-deployment-745fb9c84c,UID:335fa5a0-b38c-11e9-a303-6acf1189be78,ResourceVersion:11902,Generation:1,CreationTimestamp:2019-07-31 12:10:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 2e514dd0-b38c-11e9-a303-6acf1189be78 0xc0024c76d7 0xc0024c76d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 31 12:10:37.575: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jul 31 12:10:37.575: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6566d46b4b,GenerateName:,Namespace:deployment-9483,SelfLink:/apis/apps/v1/namespaces/deployment-9483/replicasets/test-recreate-deployment-6566d46b4b,UID:2e5bac02-b38c-11e9-a303-6acf1189be78,ResourceVersion:11892,Generation:2,CreationTimestamp:2019-07-31 12:10:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 2e514dd0-b38c-11e9-a303-6acf1189be78 0xc0024c7607 0xc0024c7608}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 31 12:10:37.583: INFO: Pod "test-recreate-deployment-745fb9c84c-52wwb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c-52wwb,GenerateName:test-recreate-deployment-745fb9c84c-,Namespace:deployment-9483,SelfLink:/api/v1/namespaces/deployment-9483/pods/test-recreate-deployment-745fb9c84c-52wwb,UID:33627b31-b38c-11e9-a303-6acf1189be78,ResourceVersion:11906,Generation:0,CreationTimestamp:2019-07-31 12:10:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-745fb9c84c 335fa5a0-b38c-11e9-a303-6acf1189be78 0xc0023ce5f7 0xc0023ce5f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-75pwz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-75pwz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-75pwz true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023ce660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023ce680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 12:10:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 12:10:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 12:10:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 12:10:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.11,PodIP:,StartTime:2019-07-31 12:10:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:10:37.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9483" for this suite.
Jul 31 12:10:44.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:10:49.365: INFO: namespace deployment-9483 deletion completed in 11.766444088s

• [SLOW TEST:23.322 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:10:49.366: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 12:10:53.453: INFO: (0) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.699722497s)
Jul 31 12:10:54.552: INFO: (1) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 1.099579575s)
Jul 31 12:10:55.153: INFO: (2) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 600.543739ms)
Jul 31 12:10:56.452: INFO: (3) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 1.299445443s)
Jul 31 12:10:56.953: INFO: (4) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 500.275124ms)
Jul 31 12:10:57.456: INFO: (5) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 502.809315ms)
Jul 31 12:10:57.958: INFO: (6) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 502.70018ms)
Jul 31 12:10:58.452: INFO: (7) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 494.027187ms)
Jul 31 12:10:58.752: INFO: (8) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 299.909101ms)
Jul 31 12:10:58.952: INFO: (9) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 199.748736ms)
Jul 31 12:10:59.252: INFO: (10) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 300.092667ms)
Jul 31 12:11:01.053: INFO: (11) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 1.800457424s)
Jul 31 12:11:03.952: INFO: (12) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.89929401s)
Jul 31 12:11:08.353: INFO: (13) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.400484629s)
Jul 31 12:11:08.859: INFO: (14) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 505.789868ms)
Jul 31 12:11:09.854: INFO: (15) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 994.928335ms)
Jul 31 12:11:09.865: INFO: (16) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.185556ms)
Jul 31 12:11:11.552: INFO: (17) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 1.687049471s)
Jul 31 12:11:11.606: INFO: (18) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 52.947755ms)
Jul 31 12:11:11.753: INFO: (19) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 147.559912ms)
[AfterEach] version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:11:11.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9697" for this suite.
Jul 31 12:11:17.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:11:19.701: INFO: namespace proxy-9697 deletion completed in 7.929370864s

• [SLOW TEST:30.335 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:11:19.702: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul 31 12:11:20.353: INFO: Waiting up to 5m0s for pod "downward-api-4e1a6f3a-b38c-11e9-82b5-da5bffca47b9" in namespace "downward-api-9410" to be "success or failure"
Jul 31 12:11:20.371: INFO: Pod "downward-api-4e1a6f3a-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 17.939397ms
Jul 31 12:11:23.658: INFO: Pod "downward-api-4e1a6f3a-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.305338753s
Jul 31 12:11:25.767: INFO: Pod "downward-api-4e1a6f3a-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.413462066s
Jul 31 12:11:28.058: INFO: Pod "downward-api-4e1a6f3a-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.704564468s
Jul 31 12:11:30.453: INFO: Pod "downward-api-4e1a6f3a-b38c-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.099571057s
STEP: Saw pod success
Jul 31 12:11:30.453: INFO: Pod "downward-api-4e1a6f3a-b38c-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:11:30.462: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod downward-api-4e1a6f3a-b38c-11e9-82b5-da5bffca47b9 container dapi-container: <nil>
STEP: delete the pod
Jul 31 12:11:32.679: INFO: Waiting for pod downward-api-4e1a6f3a-b38c-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:11:32.685: INFO: Pod downward-api-4e1a6f3a-b38c-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:11:32.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9410" for this suite.
Jul 31 12:11:39.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:11:42.120: INFO: namespace downward-api-9410 deletion completed in 9.427348857s

• [SLOW TEST:22.419 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:11:42.121: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 12:11:42.273: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b730d14-b38c-11e9-82b5-da5bffca47b9" in namespace "projected-421" to be "success or failure"
Jul 31 12:11:42.291: INFO: Pod "downwardapi-volume-5b730d14-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 18.246366ms
Jul 31 12:11:44.957: INFO: Pod "downwardapi-volume-5b730d14-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.683342047s
Jul 31 12:11:46.969: INFO: Pod "downwardapi-volume-5b730d14-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.695332364s
Jul 31 12:11:48.976: INFO: Pod "downwardapi-volume-5b730d14-b38c-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.702849978s
STEP: Saw pod success
Jul 31 12:11:48.976: INFO: Pod "downwardapi-volume-5b730d14-b38c-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:11:48.983: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod downwardapi-volume-5b730d14-b38c-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 12:11:50.153: INFO: Waiting for pod downwardapi-volume-5b730d14-b38c-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:11:50.452: INFO: Pod downwardapi-volume-5b730d14-b38c-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:11:50.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-421" for this suite.
Jul 31 12:11:56.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:12:03.765: INFO: namespace projected-421 deletion completed in 13.292735198s

• [SLOW TEST:21.644 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:12:03.765: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0731 12:12:16.168143      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 31 12:12:16.168: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:12:16.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-875" for this suite.
Jul 31 12:12:22.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:12:28.987: INFO: namespace gc-875 deletion completed in 12.618291811s

• [SLOW TEST:25.222 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:12:28.988: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 12:12:30.302: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"7810d545-b38c-11e9-a303-6acf1189be78", Controller:(*bool)(0xc002c0b016), BlockOwnerDeletion:(*bool)(0xc002c0b017)}}
Jul 31 12:12:30.553: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"7801e36e-b38c-11e9-a303-6acf1189be78", Controller:(*bool)(0xc001d084d6), BlockOwnerDeletion:(*bool)(0xc001d084d7)}}
Jul 31 12:12:30.568: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"780f174c-b38c-11e9-a303-6acf1189be78", Controller:(*bool)(0xc000992536), BlockOwnerDeletion:(*bool)(0xc000992537)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:12:35.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9538" for this suite.
Jul 31 12:12:43.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:12:49.756: INFO: namespace gc-9538 deletion completed in 12.803057509s

• [SLOW TEST:20.768 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:12:49.763: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-83bc741e-b38c-11e9-82b5-da5bffca47b9
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:12:59.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7178" for this suite.
Jul 31 12:13:23.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:13:27.580: INFO: namespace configmap-7178 deletion completed in 26.727286368s

• [SLOW TEST:37.818 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:13:27.581: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:13:37.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3218" for this suite.
Jul 31 12:14:00.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:14:08.053: INFO: namespace replication-controller-3218 deletion completed in 30.396332704s

• [SLOW TEST:40.472 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:14:08.053: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1652
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 31 12:14:09.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1685'
Jul 31 12:14:12.207: INFO: stderr: ""
Jul 31 12:14:12.207: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1657
Jul 31 12:14:12.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 delete pods e2e-test-nginx-pod --namespace=kubectl-1685'
Jul 31 12:14:15.294: INFO: stderr: ""
Jul 31 12:14:15.294: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:14:15.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1685" for this suite.
Jul 31 12:14:22.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:14:27.418: INFO: namespace kubectl-1685 deletion completed in 10.865357687s

• [SLOW TEST:19.365 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:14:27.419: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jul 31 12:14:35.754: INFO: Successfully updated pod "labelsupdatebe092914-b38c-11e9-82b5-da5bffca47b9"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:14:39.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2045" for this suite.
Jul 31 12:15:01.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:15:08.511: INFO: namespace projected-2045 deletion completed in 29.047838742s

• [SLOW TEST:41.093 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:15:08.512: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jul 31 12:15:09.487: INFO: Waiting up to 5m0s for pod "pod-d6f53fb2-b38c-11e9-82b5-da5bffca47b9" in namespace "emptydir-5369" to be "success or failure"
Jul 31 12:15:09.502: INFO: Pod "pod-d6f53fb2-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 15.393856ms
Jul 31 12:15:11.752: INFO: Pod "pod-d6f53fb2-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.265592926s
Jul 31 12:15:14.152: INFO: Pod "pod-d6f53fb2-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.665718406s
Jul 31 12:15:16.361: INFO: Pod "pod-d6f53fb2-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.874298791s
Jul 31 12:15:18.662: INFO: Pod "pod-d6f53fb2-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.175219197s
Jul 31 12:15:20.762: INFO: Pod "pod-d6f53fb2-b38c-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 11.275708819s
STEP: Saw pod success
Jul 31 12:15:20.763: INFO: Pod "pod-d6f53fb2-b38c-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:15:20.770: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-d6f53fb2-b38c-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 12:15:22.581: INFO: Waiting for pod pod-d6f53fb2-b38c-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:15:22.589: INFO: Pod pod-d6f53fb2-b38c-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:15:22.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5369" for this suite.
Jul 31 12:15:28.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:15:30.894: INFO: namespace emptydir-5369 deletion completed in 8.295576033s

• [SLOW TEST:22.382 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:15:30.895: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: Gathering metrics
W0731 12:15:32.606202      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 31 12:15:32.606: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:15:32.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3415" for this suite.
Jul 31 12:15:38.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:15:43.857: INFO: namespace gc-3415 deletion completed in 11.241482149s

• [SLOW TEST:12.962 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:15:43.857: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-eba16b37-b38c-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume configMaps
Jul 31 12:15:44.552: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ebc0495b-b38c-11e9-82b5-da5bffca47b9" in namespace "projected-9794" to be "success or failure"
Jul 31 12:15:44.953: INFO: Pod "pod-projected-configmaps-ebc0495b-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 400.083379ms
Jul 31 12:15:47.058: INFO: Pod "pod-projected-configmaps-ebc0495b-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.505495425s
Jul 31 12:15:49.259: INFO: Pod "pod-projected-configmaps-ebc0495b-b38c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.706748131s
Jul 31 12:15:51.657: INFO: Pod "pod-projected-configmaps-ebc0495b-b38c-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.104351177s
STEP: Saw pod success
Jul 31 12:15:51.657: INFO: Pod "pod-projected-configmaps-ebc0495b-b38c-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:15:51.665: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-projected-configmaps-ebc0495b-b38c-11e9-82b5-da5bffca47b9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 12:15:54.352: INFO: Waiting for pod pod-projected-configmaps-ebc0495b-b38c-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:15:54.362: INFO: Pod pod-projected-configmaps-ebc0495b-b38c-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:15:54.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9794" for this suite.
Jul 31 12:16:00.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:16:02.974: INFO: namespace projected-9794 deletion completed in 8.593621929s

• [SLOW TEST:19.117 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:16:02.975: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Jul 31 12:16:04.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 api-versions'
Jul 31 12:16:04.875: INFO: stderr: ""
Jul 31 12:16:04.875: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncluster.k8s.io/v1alpha1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:16:04.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9143" for this suite.
Jul 31 12:16:12.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:16:20.952: INFO: namespace kubectl-9143 deletion completed in 14.991104164s

• [SLOW TEST:17.978 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:16:20.953: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Jul 31 12:16:22.678: INFO: created pod pod-service-account-defaultsa
Jul 31 12:16:22.678: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jul 31 12:16:22.699: INFO: created pod pod-service-account-mountsa
Jul 31 12:16:22.699: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jul 31 12:16:22.719: INFO: created pod pod-service-account-nomountsa
Jul 31 12:16:22.719: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jul 31 12:16:22.739: INFO: created pod pod-service-account-defaultsa-mountspec
Jul 31 12:16:22.739: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jul 31 12:16:23.571: INFO: created pod pod-service-account-mountsa-mountspec
Jul 31 12:16:23.571: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jul 31 12:16:23.585: INFO: created pod pod-service-account-nomountsa-mountspec
Jul 31 12:16:23.585: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jul 31 12:16:23.630: INFO: created pod pod-service-account-defaultsa-nomountspec
Jul 31 12:16:23.630: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jul 31 12:16:25.153: INFO: created pod pod-service-account-mountsa-nomountspec
Jul 31 12:16:25.153: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jul 31 12:16:25.975: INFO: created pod pod-service-account-nomountsa-nomountspec
Jul 31 12:16:25.975: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:16:25.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9452" for this suite.
Jul 31 12:16:46.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:16:58.276: INFO: namespace svcaccounts-9452 deletion completed in 29.510555437s

• [SLOW TEST:37.323 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:16:58.276: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 12:16:58.673: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:17:14.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7418" for this suite.
Jul 31 12:18:07.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:18:09.892: INFO: namespace pods-7418 deletion completed in 54.93789742s

• [SLOW TEST:71.616 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:18:09.894: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-42b75ca3-b38d-11e9-82b5-da5bffca47b9
STEP: Creating secret with name secret-projected-all-test-volume-42b75c8e-b38d-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test Check all projections for projected volume plugin
Jul 31 12:18:10.352: INFO: Waiting up to 5m0s for pod "projected-volume-42b75c58-b38d-11e9-82b5-da5bffca47b9" in namespace "projected-8606" to be "success or failure"
Jul 31 12:18:11.153: INFO: Pod "projected-volume-42b75c58-b38d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 800.420725ms
Jul 31 12:18:13.752: INFO: Pod "projected-volume-42b75c58-b38d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.400105721s
Jul 31 12:18:15.971: INFO: Pod "projected-volume-42b75c58-b38d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.618895393s
Jul 31 12:18:18.454: INFO: Pod "projected-volume-42b75c58-b38d-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.101948531s
STEP: Saw pod success
Jul 31 12:18:18.454: INFO: Pod "projected-volume-42b75c58-b38d-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:18:19.152: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod projected-volume-42b75c58-b38d-11e9-82b5-da5bffca47b9 container projected-all-volume-test: <nil>
STEP: delete the pod
Jul 31 12:18:20.052: INFO: Waiting for pod projected-volume-42b75c58-b38d-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:18:20.065: INFO: Pod projected-volume-42b75c58-b38d-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:18:20.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8606" for this suite.
Jul 31 12:18:26.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:18:30.960: INFO: namespace projected-8606 deletion completed in 10.886398236s

• [SLOW TEST:21.068 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:18:30.962: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:18:33.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6070" for this suite.
Jul 31 12:21:46.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:21:56.669: INFO: namespace pods-6070 deletion completed in 3m23.306375549s

• [SLOW TEST:205.706 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:21:56.670: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-c9e69172-b38d-11e9-82b5-da5bffca47b9
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:21:57.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1581" for this suite.
Jul 31 12:22:03.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:22:04.580: INFO: namespace configmap-1581 deletion completed in 7.492376048s

• [SLOW TEST:7.910 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:22:04.580: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-8646/configmap-test-ce8d1a9b-b38d-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume configMaps
Jul 31 12:22:04.899: INFO: Waiting up to 5m0s for pod "pod-configmaps-ce8f2844-b38d-11e9-82b5-da5bffca47b9" in namespace "configmap-8646" to be "success or failure"
Jul 31 12:22:05.154: INFO: Pod "pod-configmaps-ce8f2844-b38d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 255.248006ms
Jul 31 12:22:07.857: INFO: Pod "pod-configmaps-ce8f2844-b38d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.958451284s
Jul 31 12:22:10.228: INFO: Pod "pod-configmaps-ce8f2844-b38d-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 5.329642983s
STEP: Saw pod success
Jul 31 12:22:10.229: INFO: Pod "pod-configmaps-ce8f2844-b38d-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:22:10.236: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-configmaps-ce8f2844-b38d-11e9-82b5-da5bffca47b9 container env-test: <nil>
STEP: delete the pod
Jul 31 12:22:11.295: INFO: Waiting for pod pod-configmaps-ce8f2844-b38d-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:22:11.302: INFO: Pod pod-configmaps-ce8f2844-b38d-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:22:11.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8646" for this suite.
Jul 31 12:22:19.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:22:24.883: INFO: namespace configmap-8646 deletion completed in 13.573327608s

• [SLOW TEST:20.304 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:22:24.883: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:22:26.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-802" for this suite.
Jul 31 12:22:35.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:22:39.958: INFO: namespace services-802 deletion completed in 13.392040287s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:15.075 seconds]
[sig-network] Services
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:22:39.961: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-5452
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 31 12:22:41.259: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 31 12:23:12.469: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.71:8080/dial?request=hostName&protocol=http&host=172.25.0.25&port=8080&tries=1'] Namespace:pod-network-test-5452 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 12:23:12.470: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 12:23:16.858: INFO: Waiting for endpoints: map[]
Jul 31 12:23:17.053: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.71:8080/dial?request=hostName&protocol=http&host=172.25.1.70&port=8080&tries=1'] Namespace:pod-network-test-5452 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 12:23:17.053: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 12:23:20.653: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:23:20.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5452" for this suite.
Jul 31 12:23:42.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:23:45.066: INFO: namespace pod-network-test-5452 deletion completed in 24.398138817s

• [SLOW TEST:65.106 seconds]
[sig-network] Networking
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:23:45.067: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:24:46.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2706" for this suite.
Jul 31 12:25:08.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:25:13.681: INFO: namespace container-probe-2706 deletion completed in 26.927948235s

• [SLOW TEST:88.614 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:25:13.685: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1259
STEP: creating an rc
Jul 31 12:25:14.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 create -f - --namespace=kubectl-6764'
Jul 31 12:25:17.439: INFO: stderr: ""
Jul 31 12:25:17.439: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Jul 31 12:25:18.552: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:25:18.552: INFO: Found 0 / 1
Jul 31 12:25:19.652: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:25:19.652: INFO: Found 0 / 1
Jul 31 12:25:20.852: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:25:20.852: INFO: Found 0 / 1
Jul 31 12:25:21.652: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:25:21.652: INFO: Found 0 / 1
Jul 31 12:25:22.754: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:25:22.754: INFO: Found 0 / 1
Jul 31 12:25:23.552: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:25:23.559: INFO: Found 1 / 1
Jul 31 12:25:23.559: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul 31 12:25:23.757: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 12:25:23.757: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jul 31 12:25:23.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 logs redis-master-jn9c6 redis-master --namespace=kubectl-6764'
Jul 31 12:25:25.821: INFO: stderr: ""
Jul 31 12:25:25.821: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 31 Jul 12:25:21.781 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 31 Jul 12:25:21.781 # Server started, Redis version 3.2.12\n1:M 31 Jul 12:25:21.781 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 31 Jul 12:25:21.781 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jul 31 12:25:25.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 log redis-master-jn9c6 redis-master --namespace=kubectl-6764 --tail=1'
Jul 31 12:25:26.323: INFO: stderr: ""
Jul 31 12:25:26.323: INFO: stdout: "1:M 31 Jul 12:25:21.781 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jul 31 12:25:26.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 log redis-master-jn9c6 redis-master --namespace=kubectl-6764 --limit-bytes=1'
Jul 31 12:25:27.323: INFO: stderr: ""
Jul 31 12:25:27.323: INFO: stdout: " "
STEP: exposing timestamps
Jul 31 12:25:27.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 log redis-master-jn9c6 redis-master --namespace=kubectl-6764 --tail=1 --timestamps'
Jul 31 12:25:28.661: INFO: stderr: ""
Jul 31 12:25:28.661: INFO: stdout: "2019-07-31T12:25:21.782348879Z 1:M 31 Jul 12:25:21.781 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jul 31 12:25:31.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 log redis-master-jn9c6 redis-master --namespace=kubectl-6764 --since=1s'
Jul 31 12:25:31.553: INFO: stderr: ""
Jul 31 12:25:31.553: INFO: stdout: ""
Jul 31 12:25:31.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 log redis-master-jn9c6 redis-master --namespace=kubectl-6764 --since=24h'
Jul 31 12:25:32.453: INFO: stderr: ""
Jul 31 12:25:32.453: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 31 Jul 12:25:21.781 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 31 Jul 12:25:21.781 # Server started, Redis version 3.2.12\n1:M 31 Jul 12:25:21.781 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 31 Jul 12:25:21.781 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1265
STEP: using delete to clean up resources
Jul 31 12:25:32.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 delete --grace-period=0 --force -f - --namespace=kubectl-6764'
Jul 31 12:25:33.859: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 12:25:33.859: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jul 31 12:25:33.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get rc,svc -l name=nginx --no-headers --namespace=kubectl-6764'
Jul 31 12:25:34.285: INFO: stderr: "No resources found.\n"
Jul 31 12:25:34.285: INFO: stdout: ""
Jul 31 12:25:34.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -l name=nginx --namespace=kubectl-6764 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 31 12:25:35.459: INFO: stderr: ""
Jul 31 12:25:35.459: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:25:35.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6764" for this suite.
Jul 31 12:25:58.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:26:07.385: INFO: namespace kubectl-6764 deletion completed in 31.532382735s

• [SLOW TEST:53.701 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:26:07.386: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-9693/configmap-test-5f80f154-b38e-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume configMaps
Jul 31 12:26:08.857: INFO: Waiting up to 5m0s for pod "pod-configmaps-5f9f732e-b38e-11e9-82b5-da5bffca47b9" in namespace "configmap-9693" to be "success or failure"
Jul 31 12:26:09.152: INFO: Pod "pod-configmaps-5f9f732e-b38e-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 295.404738ms
Jul 31 12:26:11.352: INFO: Pod "pod-configmaps-5f9f732e-b38e-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.495068422s
Jul 31 12:26:13.565: INFO: Pod "pod-configmaps-5f9f732e-b38e-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.708725421s
Jul 31 12:26:15.754: INFO: Pod "pod-configmaps-5f9f732e-b38e-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.897502389s
STEP: Saw pod success
Jul 31 12:26:15.754: INFO: Pod "pod-configmaps-5f9f732e-b38e-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:26:15.952: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-configmaps-5f9f732e-b38e-11e9-82b5-da5bffca47b9 container env-test: <nil>
STEP: delete the pod
Jul 31 12:26:19.052: INFO: Waiting for pod pod-configmaps-5f9f732e-b38e-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:26:19.252: INFO: Pod pod-configmaps-5f9f732e-b38e-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:26:19.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9693" for this suite.
Jul 31 12:26:25.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:26:29.652: INFO: namespace configmap-9693 deletion completed in 10.194647239s

• [SLOW TEST:22.266 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:26:29.652: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-8129
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-8129
STEP: Deleting pre-stop pod
Jul 31 12:26:54.052: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:26:54.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-8129" for this suite.
Jul 31 12:27:33.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:27:35.785: INFO: namespace prestop-8129 deletion completed in 41.232596046s

• [SLOW TEST:66.132 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:27:35.785: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-2163
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 31 12:27:36.267: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 31 12:28:08.452: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.25.0.26 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2163 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 12:28:08.452: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 12:28:11.121: INFO: Found all expected endpoints: [netserver-0]
Jul 31 12:28:11.181: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.25.1.77 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2163 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 12:28:11.181: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 12:28:15.735: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:28:15.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2163" for this suite.
Jul 31 12:28:38.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:28:44.852: INFO: namespace pod-network-test-2163 deletion completed in 28.399847351s

• [SLOW TEST:69.067 seconds]
[sig-network] Networking
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:28:44.852: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jul 31 12:28:45.962: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:28:56.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2716" for this suite.
Jul 31 12:29:04.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:29:07.295: INFO: namespace init-container-2716 deletion completed in 10.442672847s

• [SLOW TEST:22.443 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:29:07.295: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-cabb817b-b38e-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume configMaps
Jul 31 12:29:07.986: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cabd70eb-b38e-11e9-82b5-da5bffca47b9" in namespace "projected-6664" to be "success or failure"
Jul 31 12:29:08.252: INFO: Pod "pod-projected-configmaps-cabd70eb-b38e-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 265.559758ms
Jul 31 12:29:10.752: INFO: Pod "pod-projected-configmaps-cabd70eb-b38e-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.765914244s
Jul 31 12:29:13.052: INFO: Pod "pod-projected-configmaps-cabd70eb-b38e-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.065484531s
Jul 31 12:29:16.152: INFO: Pod "pod-projected-configmaps-cabd70eb-b38e-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.165557828s
STEP: Saw pod success
Jul 31 12:29:16.152: INFO: Pod "pod-projected-configmaps-cabd70eb-b38e-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:29:16.159: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-projected-configmaps-cabd70eb-b38e-11e9-82b5-da5bffca47b9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 12:29:17.252: INFO: Waiting for pod pod-projected-configmaps-cabd70eb-b38e-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:29:18.454: INFO: Pod pod-projected-configmaps-cabd70eb-b38e-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:29:18.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6664" for this suite.
Jul 31 12:29:25.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:29:29.652: INFO: namespace projected-6664 deletion completed in 11.182997513s

• [SLOW TEST:22.357 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:29:29.652: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 12:29:31.571: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jul 31 12:29:36.852: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul 31 12:29:37.552: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jul 31 12:29:40.152: INFO: Creating deployment "test-rollover-deployment"
Jul 31 12:29:40.458: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jul 31 12:29:40.464: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jul 31 12:29:40.476: INFO: Ensure that both replica sets have 1 created replica
Jul 31 12:29:40.493: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jul 31 12:29:40.852: INFO: Updating deployment test-rollover-deployment
Jul 31 12:29:40.852: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jul 31 12:29:41.557: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jul 31 12:29:41.860: INFO: Make sure deployment "test-rollover-deployment" is complete
Jul 31 12:29:41.874: INFO: all replica sets need to contain the pod-template-hash label
Jul 31 12:29:41.874: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 12:29:44.852: INFO: all replica sets need to contain the pod-template-hash label
Jul 31 12:29:44.852: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 12:29:45.888: INFO: all replica sets need to contain the pod-template-hash label
Jul 31 12:29:45.889: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172985, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 12:29:49.052: INFO: all replica sets need to contain the pod-template-hash label
Jul 31 12:29:49.052: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172985, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 12:29:50.852: INFO: all replica sets need to contain the pod-template-hash label
Jul 31 12:29:50.852: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172985, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 12:29:52.253: INFO: all replica sets need to contain the pod-template-hash label
Jul 31 12:29:52.253: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172985, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 12:29:53.966: INFO: all replica sets need to contain the pod-template-hash label
Jul 31 12:29:53.966: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172985, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700172980, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 12:29:56.570: INFO: 
Jul 31 12:29:56.570: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 31 12:29:56.752: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-9556,SelfLink:/apis/apps/v1/namespaces/deployment-9556/deployments/test-rollover-deployment,UID:ddfbef66-b38e-11e9-a303-6acf1189be78,ResourceVersion:16326,Generation:2,CreationTimestamp:2019-07-31 12:29:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-07-31 12:29:40 +0000 UTC 2019-07-31 12:29:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-07-31 12:29:55 +0000 UTC 2019-07-31 12:29:40 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-659c699649" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jul 31 12:29:56.765: INFO: New ReplicaSet "test-rollover-deployment-659c699649" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649,GenerateName:,Namespace:deployment-9556,SelfLink:/apis/apps/v1/namespaces/deployment-9556/replicasets/test-rollover-deployment-659c699649,UID:de4a11db-b38e-11e9-a303-6acf1189be78,ResourceVersion:16314,Generation:2,CreationTimestamp:2019-07-31 12:29:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ddfbef66-b38e-11e9-a303-6acf1189be78 0xc0018e2e27 0xc0018e2e28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul 31 12:29:56.765: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jul 31 12:29:56.765: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-9556,SelfLink:/apis/apps/v1/namespaces/deployment-9556/replicasets/test-rollover-controller,UID:d8cc70a4-b38e-11e9-a303-6acf1189be78,ResourceVersion:16325,Generation:2,CreationTimestamp:2019-07-31 12:29:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ddfbef66-b38e-11e9-a303-6acf1189be78 0xc0018e2d57 0xc0018e2d58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 31 12:29:56.765: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-7b45b6464,GenerateName:,Namespace:deployment-9556,SelfLink:/apis/apps/v1/namespaces/deployment-9556/replicasets/test-rollover-deployment-7b45b6464,UID:de00e490-b38e-11e9-a303-6acf1189be78,ResourceVersion:16260,Generation:2,CreationTimestamp:2019-07-31 12:29:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ddfbef66-b38e-11e9-a303-6acf1189be78 0xc0018e2ef0 0xc0018e2ef1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 31 12:29:56.773: INFO: Pod "test-rollover-deployment-659c699649-h4psm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649-h4psm,GenerateName:test-rollover-deployment-659c699649-,Namespace:deployment-9556,SelfLink:/api/v1/namespaces/deployment-9556/pods/test-rollover-deployment-659c699649-h4psm,UID:de535be3-b38e-11e9-a303-6acf1189be78,ResourceVersion:16283,Generation:0,CreationTimestamp:2019-07-31 12:29:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-659c699649 de4a11db-b38e-11e9-a303-6acf1189be78 0xc001735d07 0xc001735d08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4fmwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4fmwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-4fmwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001735da0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001735dc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 12:29:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 12:29:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 12:29:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 12:29:40 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.11,PodIP:172.25.1.82,StartTime:2019-07-31 12:29:40 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-07-31 12:29:43 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://7d159d0c2084b1823e25c066e705752d67ed5c06ae6136007cc04e2191129646}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:29:56.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9556" for this suite.
Jul 31 12:30:03.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:30:08.652: INFO: namespace deployment-9556 deletion completed in 11.868807632s

• [SLOW TEST:39.000 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:30:08.653: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0731 12:30:20.180632      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 31 12:30:20.180: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:30:20.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6295" for this suite.
Jul 31 12:30:27.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:30:32.152: INFO: namespace gc-6295 deletion completed in 11.964893611s

• [SLOW TEST:23.499 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:30:32.152: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jul 31 12:30:32.879: INFO: Waiting up to 5m0s for pod "pod-fd56f5fb-b38e-11e9-82b5-da5bffca47b9" in namespace "emptydir-2976" to be "success or failure"
Jul 31 12:30:32.899: INFO: Pod "pod-fd56f5fb-b38e-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 19.830536ms
Jul 31 12:30:34.908: INFO: Pod "pod-fd56f5fb-b38e-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028757416s
Jul 31 12:30:39.172: INFO: Pod "pod-fd56f5fb-b38e-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.292563396s
Jul 31 12:30:42.554: INFO: Pod "pod-fd56f5fb-b38e-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 9.674557338s
STEP: Saw pod success
Jul 31 12:30:42.554: INFO: Pod "pod-fd56f5fb-b38e-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:30:42.568: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-fd56f5fb-b38e-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 12:30:43.152: INFO: Waiting for pod pod-fd56f5fb-b38e-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:30:43.356: INFO: Pod pod-fd56f5fb-b38e-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:30:43.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2976" for this suite.
Jul 31 12:30:50.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:30:59.954: INFO: namespace emptydir-2976 deletion completed in 16.401519986s

• [SLOW TEST:27.802 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:30:59.954: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul 31 12:31:04.552: INFO: Number of nodes with available pods: 0
Jul 31 12:31:04.552: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 12:31:05.869: INFO: Number of nodes with available pods: 0
Jul 31 12:31:05.869: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 12:31:07.452: INFO: Number of nodes with available pods: 0
Jul 31 12:31:07.452: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 12:31:08.389: INFO: Number of nodes with available pods: 0
Jul 31 12:31:08.389: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 12:31:09.553: INFO: Number of nodes with available pods: 0
Jul 31 12:31:09.553: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 12:31:11.352: INFO: Number of nodes with available pods: 2
Jul 31 12:31:11.352: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jul 31 12:31:11.498: INFO: Number of nodes with available pods: 1
Jul 31 12:31:11.498: INFO: Node loving-darwin-5cd5b754c-qfktz is running more than one daemon pod
Jul 31 12:31:13.075: INFO: Number of nodes with available pods: 1
Jul 31 12:31:13.075: INFO: Node loving-darwin-5cd5b754c-qfktz is running more than one daemon pod
Jul 31 12:31:14.952: INFO: Number of nodes with available pods: 1
Jul 31 12:31:14.952: INFO: Node loving-darwin-5cd5b754c-qfktz is running more than one daemon pod
Jul 31 12:31:15.856: INFO: Number of nodes with available pods: 1
Jul 31 12:31:15.856: INFO: Node loving-darwin-5cd5b754c-qfktz is running more than one daemon pod
Jul 31 12:31:18.757: INFO: Number of nodes with available pods: 1
Jul 31 12:31:18.757: INFO: Node loving-darwin-5cd5b754c-qfktz is running more than one daemon pod
Jul 31 12:31:20.552: INFO: Number of nodes with available pods: 1
Jul 31 12:31:20.552: INFO: Node loving-darwin-5cd5b754c-qfktz is running more than one daemon pod
Jul 31 12:31:22.284: INFO: Number of nodes with available pods: 2
Jul 31 12:31:22.284: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8740, will wait for the garbage collector to delete the pods
Jul 31 12:31:22.882: INFO: Deleting DaemonSet.extensions daemon-set took: 535.664372ms
Jul 31 12:31:23.683: INFO: Terminating DaemonSet.extensions daemon-set pods took: 800.511346ms
Jul 31 12:31:33.690: INFO: Number of nodes with available pods: 0
Jul 31 12:31:33.690: INFO: Number of running nodes: 0, number of available pods: 0
Jul 31 12:31:33.699: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8740/daemonsets","resourceVersion":"16765"},"items":null}

Jul 31 12:31:33.710: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8740/pods","resourceVersion":"16765"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:31:34.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8740" for this suite.
Jul 31 12:31:40.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:31:41.745: INFO: namespace daemonsets-8740 deletion completed in 7.189737832s

• [SLOW TEST:41.791 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:31:41.746: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 12:31:42.740: INFO: Waiting up to 5m0s for pod "downwardapi-volume-26fb85f0-b38f-11e9-82b5-da5bffca47b9" in namespace "projected-7065" to be "success or failure"
Jul 31 12:31:42.751: INFO: Pod "downwardapi-volume-26fb85f0-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.785724ms
Jul 31 12:31:44.952: INFO: Pod "downwardapi-volume-26fb85f0-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.21213226s
Jul 31 12:31:47.576: INFO: Pod "downwardapi-volume-26fb85f0-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.836612969s
Jul 31 12:31:49.656: INFO: Pod "downwardapi-volume-26fb85f0-b38f-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.916299048s
STEP: Saw pod success
Jul 31 12:31:49.656: INFO: Pod "downwardapi-volume-26fb85f0-b38f-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:31:49.665: INFO: Trying to get logs from node loving-darwin-5cd5b754c-ckbcc pod downwardapi-volume-26fb85f0-b38f-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 12:31:49.810: INFO: Waiting for pod downwardapi-volume-26fb85f0-b38f-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:31:50.252: INFO: Pod downwardapi-volume-26fb85f0-b38f-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:31:50.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7065" for this suite.
Jul 31 12:31:56.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:32:01.676: INFO: namespace projected-7065 deletion completed in 11.397255423s

• [SLOW TEST:19.929 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:32:01.676: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Jul 31 12:32:01.963: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-228106623 proxy --unix-socket=/tmp/kubectl-proxy-unix031185618/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:32:02.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4704" for this suite.
Jul 31 12:32:08.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:32:17.452: INFO: namespace kubectl-4704 deletion completed in 15.179481393s

• [SLOW TEST:15.779 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:32:17.455: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jul 31 12:32:17.558: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:32:30.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1428" for this suite.
Jul 31 12:32:53.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:33:00.185: INFO: namespace init-container-1428 deletion completed in 29.220398431s

• [SLOW TEST:42.730 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:33:00.185: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Jul 31 12:33:00.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 --namespace=kubectl-1693 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jul 31 12:33:14.423: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jul 31 12:33:14.423: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:33:16.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1693" for this suite.
Jul 31 12:33:24.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:33:29.852: INFO: namespace kubectl-1693 deletion completed in 11.792617916s

• [SLOW TEST:29.667 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:33:29.856: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-679cb536-b38f-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume configMaps
Jul 31 12:33:32.253: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-68077560-b38f-11e9-82b5-da5bffca47b9" in namespace "projected-6391" to be "success or failure"
Jul 31 12:33:32.452: INFO: Pod "pod-projected-configmaps-68077560-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 198.72998ms
Jul 31 12:33:34.752: INFO: Pod "pod-projected-configmaps-68077560-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.499192156s
Jul 31 12:33:36.953: INFO: Pod "pod-projected-configmaps-68077560-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.700249576s
Jul 31 12:33:39.572: INFO: Pod "pod-projected-configmaps-68077560-b38f-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.318867475s
STEP: Saw pod success
Jul 31 12:33:39.572: INFO: Pod "pod-projected-configmaps-68077560-b38f-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:33:39.852: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-projected-configmaps-68077560-b38f-11e9-82b5-da5bffca47b9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 12:33:41.289: INFO: Waiting for pod pod-projected-configmaps-68077560-b38f-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:33:41.296: INFO: Pod pod-projected-configmaps-68077560-b38f-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:33:41.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6391" for this suite.
Jul 31 12:33:48.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:33:55.952: INFO: namespace projected-6391 deletion completed in 14.625057375s

• [SLOW TEST:26.096 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:33:55.952: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 12:33:57.073: INFO: Waiting up to 5m0s for pod "downwardapi-volume-770d1c5d-b38f-11e9-82b5-da5bffca47b9" in namespace "downward-api-7309" to be "success or failure"
Jul 31 12:33:57.084: INFO: Pod "downwardapi-volume-770d1c5d-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.754446ms
Jul 31 12:33:59.854: INFO: Pod "downwardapi-volume-770d1c5d-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.781051854s
Jul 31 12:34:02.053: INFO: Pod "downwardapi-volume-770d1c5d-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.979888561s
Jul 31 12:34:04.354: INFO: Pod "downwardapi-volume-770d1c5d-b38f-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.281414283s
STEP: Saw pod success
Jul 31 12:34:04.354: INFO: Pod "downwardapi-volume-770d1c5d-b38f-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:34:04.652: INFO: Trying to get logs from node loving-darwin-5cd5b754c-ckbcc pod downwardapi-volume-770d1c5d-b38f-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 12:34:05.452: INFO: Waiting for pod downwardapi-volume-770d1c5d-b38f-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:34:05.952: INFO: Pod downwardapi-volume-770d1c5d-b38f-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:34:05.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7309" for this suite.
Jul 31 12:34:13.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:34:17.817: INFO: namespace downward-api-7309 deletion completed in 11.263142723s

• [SLOW TEST:21.864 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:34:17.817: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul 31 12:34:18.271: INFO: Waiting up to 5m0s for pod "downward-api-83b04c3e-b38f-11e9-82b5-da5bffca47b9" in namespace "downward-api-1764" to be "success or failure"
Jul 31 12:34:18.283: INFO: Pod "downward-api-83b04c3e-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.057879ms
Jul 31 12:34:20.652: INFO: Pod "downward-api-83b04c3e-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.381205957s
Jul 31 12:34:23.157: INFO: Pod "downward-api-83b04c3e-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.886041225s
Jul 31 12:34:26.256: INFO: Pod "downward-api-83b04c3e-b38f-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.985625314s
STEP: Saw pod success
Jul 31 12:34:26.256: INFO: Pod "downward-api-83b04c3e-b38f-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:34:26.263: INFO: Trying to get logs from node loving-darwin-5cd5b754c-ckbcc pod downward-api-83b04c3e-b38f-11e9-82b5-da5bffca47b9 container dapi-container: <nil>
STEP: delete the pod
Jul 31 12:34:27.352: INFO: Waiting for pod downward-api-83b04c3e-b38f-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:34:27.359: INFO: Pod downward-api-83b04c3e-b38f-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:34:27.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1764" for this suite.
Jul 31 12:34:33.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:34:39.952: INFO: namespace downward-api-1764 deletion completed in 12.584462306s

• [SLOW TEST:22.135 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:34:39.952: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-91a39798-b38f-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume secrets
Jul 31 12:34:41.753: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-91a55044-b38f-11e9-82b5-da5bffca47b9" in namespace "projected-8782" to be "success or failure"
Jul 31 12:34:41.762: INFO: Pod "pod-projected-secrets-91a55044-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.834076ms
Jul 31 12:34:44.353: INFO: Pod "pod-projected-secrets-91a55044-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.600051507s
Jul 31 12:34:46.558: INFO: Pod "pod-projected-secrets-91a55044-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.805031715s
Jul 31 12:34:48.752: INFO: Pod "pod-projected-secrets-91a55044-b38f-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.999908025s
STEP: Saw pod success
Jul 31 12:34:48.753: INFO: Pod "pod-projected-secrets-91a55044-b38f-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:34:49.052: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-projected-secrets-91a55044-b38f-11e9-82b5-da5bffca47b9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 31 12:34:49.653: INFO: Waiting for pod pod-projected-secrets-91a55044-b38f-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:34:49.955: INFO: Pod pod-projected-secrets-91a55044-b38f-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:34:49.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8782" for this suite.
Jul 31 12:34:57.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:35:01.611: INFO: namespace projected-8782 deletion completed in 11.358250266s

• [SLOW TEST:21.659 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:35:01.612: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-6nqf
STEP: Creating a pod to test atomic-volume-subpath
Jul 31 12:35:02.353: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-6nqf" in namespace "subpath-6861" to be "success or failure"
Jul 31 12:35:02.653: INFO: Pod "pod-subpath-test-downwardapi-6nqf": Phase="Pending", Reason="", readiness=false. Elapsed: 298.970471ms
Jul 31 12:35:05.056: INFO: Pod "pod-subpath-test-downwardapi-6nqf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.702620872s
Jul 31 12:35:07.064: INFO: Pod "pod-subpath-test-downwardapi-6nqf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.710744942s
Jul 31 12:35:09.352: INFO: Pod "pod-subpath-test-downwardapi-6nqf": Phase="Running", Reason="", readiness=true. Elapsed: 6.998722959s
Jul 31 12:35:11.365: INFO: Pod "pod-subpath-test-downwardapi-6nqf": Phase="Running", Reason="", readiness=true. Elapsed: 9.011256924s
Jul 31 12:35:13.669: INFO: Pod "pod-subpath-test-downwardapi-6nqf": Phase="Running", Reason="", readiness=true. Elapsed: 11.314996587s
Jul 31 12:35:16.155: INFO: Pod "pod-subpath-test-downwardapi-6nqf": Phase="Running", Reason="", readiness=true. Elapsed: 13.801882976s
Jul 31 12:35:19.153: INFO: Pod "pod-subpath-test-downwardapi-6nqf": Phase="Running", Reason="", readiness=true. Elapsed: 16.799005891s
Jul 31 12:35:21.163: INFO: Pod "pod-subpath-test-downwardapi-6nqf": Phase="Running", Reason="", readiness=true. Elapsed: 18.809605223s
Jul 31 12:35:23.853: INFO: Pod "pod-subpath-test-downwardapi-6nqf": Phase="Running", Reason="", readiness=true. Elapsed: 21.499211512s
Jul 31 12:35:26.057: INFO: Pod "pod-subpath-test-downwardapi-6nqf": Phase="Running", Reason="", readiness=true. Elapsed: 23.70351819s
Jul 31 12:35:28.352: INFO: Pod "pod-subpath-test-downwardapi-6nqf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 25.998763826s
STEP: Saw pod success
Jul 31 12:35:28.352: INFO: Pod "pod-subpath-test-downwardapi-6nqf" satisfied condition "success or failure"
Jul 31 12:35:28.557: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-subpath-test-downwardapi-6nqf container test-container-subpath-downwardapi-6nqf: <nil>
STEP: delete the pod
Jul 31 12:35:29.154: INFO: Waiting for pod pod-subpath-test-downwardapi-6nqf to disappear
Jul 31 12:35:29.452: INFO: Pod pod-subpath-test-downwardapi-6nqf no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-6nqf
Jul 31 12:35:29.452: INFO: Deleting pod "pod-subpath-test-downwardapi-6nqf" in namespace "subpath-6861"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:35:29.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6861" for this suite.
Jul 31 12:35:36.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:35:43.165: INFO: namespace subpath-6861 deletion completed in 13.211577168s

• [SLOW TEST:41.553 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:35:43.166: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Jul 31 12:35:43.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 cluster-info'
Jul 31 12:35:46.455: INFO: stderr: ""
Jul 31 12:35:46.455: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.10.10.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.10.10.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:35:46.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-155" for this suite.
Jul 31 12:35:53.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:35:59.875: INFO: namespace kubectl-155 deletion completed in 13.122081162s

• [SLOW TEST:16.709 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:35:59.885: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Jul 31 12:36:01.486: INFO: Waiting up to 5m0s for pod "client-containers-c134e4e2-b38f-11e9-82b5-da5bffca47b9" in namespace "containers-9095" to be "success or failure"
Jul 31 12:36:01.510: INFO: Pod "client-containers-c134e4e2-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 24.14451ms
Jul 31 12:36:03.853: INFO: Pod "client-containers-c134e4e2-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.367308339s
Jul 31 12:36:05.892: INFO: Pod "client-containers-c134e4e2-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.40673613s
Jul 31 12:36:07.963: INFO: Pod "client-containers-c134e4e2-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.47785465s
Jul 31 12:36:10.056: INFO: Pod "client-containers-c134e4e2-b38f-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.570246635s
Jul 31 12:36:12.353: INFO: Pod "client-containers-c134e4e2-b38f-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.867259654s
STEP: Saw pod success
Jul 31 12:36:12.353: INFO: Pod "client-containers-c134e4e2-b38f-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:36:12.552: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod client-containers-c134e4e2-b38f-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 12:36:13.253: INFO: Waiting for pod client-containers-c134e4e2-b38f-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:36:13.455: INFO: Pod client-containers-c134e4e2-b38f-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:36:13.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9095" for this suite.
Jul 31 12:36:20.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:36:23.292: INFO: namespace containers-9095 deletion completed in 9.539009081s

• [SLOW TEST:23.407 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:36:23.293: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1688
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 31 12:36:23.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-2366'
Jul 31 12:36:24.263: INFO: stderr: ""
Jul 31 12:36:24.263: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jul 31 12:36:34.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pod e2e-test-nginx-pod --namespace=kubectl-2366 -o json'
Jul 31 12:36:35.130: INFO: stderr: ""
Jul 31 12:36:35.130: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-07-31T12:36:23Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-2366\",\n        \"resourceVersion\": \"17896\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-2366/pods/e2e-test-nginx-pod\",\n        \"uid\": \"ce9c08a4-b38f-11e9-a303-6acf1189be78\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-xvpjh\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"loving-darwin-5cd5b754c-qfktz\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-xvpjh\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-xvpjh\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-31T12:36:24Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-31T12:36:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-31T12:36:28Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-31T12:36:23Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://2600305f62b497531a1a5663b53bc6ec9d39a042f1397032fea49aa1ebe634d7\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-07-31T12:36:27Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.1.11\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.25.1.93\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-07-31T12:36:24Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jul 31 12:36:35.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 replace -f - --namespace=kubectl-2366'
Jul 31 12:36:36.576: INFO: stderr: ""
Jul 31 12:36:36.576: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1693
Jul 31 12:36:36.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 delete pods e2e-test-nginx-pod --namespace=kubectl-2366'
Jul 31 12:36:43.555: INFO: stderr: ""
Jul 31 12:36:43.555: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:36:43.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2366" for this suite.
Jul 31 12:36:50.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:36:57.193: INFO: namespace kubectl-2366 deletion completed in 13.440597438s

• [SLOW TEST:33.909 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:36:57.202: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jul 31 12:36:57.396: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1939,SelfLink:/api/v1/namespaces/watch-1939/configmaps/e2e-watch-test-configmap-a,UID:e288c04a-b38f-11e9-a303-6acf1189be78,ResourceVersion:18000,Generation:0,CreationTimestamp:2019-07-31 12:36:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 31 12:36:57.397: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1939,SelfLink:/api/v1/namespaces/watch-1939/configmaps/e2e-watch-test-configmap-a,UID:e288c04a-b38f-11e9-a303-6acf1189be78,ResourceVersion:18000,Generation:0,CreationTimestamp:2019-07-31 12:36:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jul 31 12:37:08.786: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1939,SelfLink:/api/v1/namespaces/watch-1939/configmaps/e2e-watch-test-configmap-a,UID:e288c04a-b38f-11e9-a303-6acf1189be78,ResourceVersion:18033,Generation:0,CreationTimestamp:2019-07-31 12:36:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jul 31 12:37:08.786: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1939,SelfLink:/api/v1/namespaces/watch-1939/configmaps/e2e-watch-test-configmap-a,UID:e288c04a-b38f-11e9-a303-6acf1189be78,ResourceVersion:18033,Generation:0,CreationTimestamp:2019-07-31 12:36:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jul 31 12:37:18.968: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1939,SelfLink:/api/v1/namespaces/watch-1939/configmaps/e2e-watch-test-configmap-a,UID:e288c04a-b38f-11e9-a303-6acf1189be78,ResourceVersion:18065,Generation:0,CreationTimestamp:2019-07-31 12:36:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 31 12:37:18.968: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1939,SelfLink:/api/v1/namespaces/watch-1939/configmaps/e2e-watch-test-configmap-a,UID:e288c04a-b38f-11e9-a303-6acf1189be78,ResourceVersion:18065,Generation:0,CreationTimestamp:2019-07-31 12:36:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jul 31 12:37:29.653: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1939,SelfLink:/api/v1/namespaces/watch-1939/configmaps/e2e-watch-test-configmap-a,UID:e288c04a-b38f-11e9-a303-6acf1189be78,ResourceVersion:18095,Generation:0,CreationTimestamp:2019-07-31 12:36:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 31 12:37:29.653: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1939,SelfLink:/api/v1/namespaces/watch-1939/configmaps/e2e-watch-test-configmap-a,UID:e288c04a-b38f-11e9-a303-6acf1189be78,ResourceVersion:18095,Generation:0,CreationTimestamp:2019-07-31 12:36:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jul 31 12:37:39.675: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1939,SelfLink:/api/v1/namespaces/watch-1939/configmaps/e2e-watch-test-configmap-b,UID:fbbb3189-b38f-11e9-a303-6acf1189be78,ResourceVersion:18122,Generation:0,CreationTimestamp:2019-07-31 12:37:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 31 12:37:39.675: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1939,SelfLink:/api/v1/namespaces/watch-1939/configmaps/e2e-watch-test-configmap-b,UID:fbbb3189-b38f-11e9-a303-6acf1189be78,ResourceVersion:18122,Generation:0,CreationTimestamp:2019-07-31 12:37:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jul 31 12:37:49.858: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1939,SelfLink:/api/v1/namespaces/watch-1939/configmaps/e2e-watch-test-configmap-b,UID:fbbb3189-b38f-11e9-a303-6acf1189be78,ResourceVersion:18151,Generation:0,CreationTimestamp:2019-07-31 12:37:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 31 12:37:49.858: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1939,SelfLink:/api/v1/namespaces/watch-1939/configmaps/e2e-watch-test-configmap-b,UID:fbbb3189-b38f-11e9-a303-6acf1189be78,ResourceVersion:18151,Generation:0,CreationTimestamp:2019-07-31 12:37:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:37:59.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1939" for this suite.
Jul 31 12:38:06.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:38:17.158: INFO: namespace watch-1939 deletion completed in 17.004258453s

• [SLOW TEST:79.956 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:38:17.158: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0731 12:38:26.554863      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 31 12:38:26.554: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:38:26.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4415" for this suite.
Jul 31 12:38:34.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:38:39.255: INFO: namespace gc-4415 deletion completed in 12.499775688s

• [SLOW TEST:22.098 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:38:39.256: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Jul 31 12:38:39.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 create -f - --namespace=kubectl-7905'
Jul 31 12:38:40.924: INFO: stderr: ""
Jul 31 12:38:40.924: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 31 12:38:40.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7905'
Jul 31 12:38:41.633: INFO: stderr: ""
Jul 31 12:38:41.633: INFO: stdout: "update-demo-nautilus-jrwbj update-demo-nautilus-nxntg "
Jul 31 12:38:41.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-jrwbj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7905'
Jul 31 12:38:41.985: INFO: stderr: ""
Jul 31 12:38:41.985: INFO: stdout: ""
Jul 31 12:38:41.985: INFO: update-demo-nautilus-jrwbj is created but not running
Jul 31 12:38:46.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7905'
Jul 31 12:38:47.235: INFO: stderr: ""
Jul 31 12:38:47.235: INFO: stdout: "update-demo-nautilus-jrwbj update-demo-nautilus-nxntg "
Jul 31 12:38:47.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-jrwbj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7905'
Jul 31 12:38:48.173: INFO: stderr: ""
Jul 31 12:38:48.173: INFO: stdout: "true"
Jul 31 12:38:48.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-jrwbj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7905'
Jul 31 12:38:48.739: INFO: stderr: ""
Jul 31 12:38:48.739: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 12:38:48.739: INFO: validating pod update-demo-nautilus-jrwbj
Jul 31 12:38:50.552: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 12:38:50.553: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 12:38:50.553: INFO: update-demo-nautilus-jrwbj is verified up and running
Jul 31 12:38:50.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-nxntg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7905'
Jul 31 12:38:51.955: INFO: stderr: ""
Jul 31 12:38:51.955: INFO: stdout: "true"
Jul 31 12:38:51.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-nxntg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7905'
Jul 31 12:38:52.756: INFO: stderr: ""
Jul 31 12:38:52.756: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 12:38:52.756: INFO: validating pod update-demo-nautilus-nxntg
Jul 31 12:38:53.353: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 12:38:53.353: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 12:38:53.353: INFO: update-demo-nautilus-nxntg is verified up and running
STEP: scaling down the replication controller
Jul 31 12:38:53.354: INFO: scanned /root for discovery docs: <nil>
Jul 31 12:38:53.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-7905'
Jul 31 12:38:55.023: INFO: stderr: ""
Jul 31 12:38:55.023: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 31 12:38:55.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7905'
Jul 31 12:38:55.826: INFO: stderr: ""
Jul 31 12:38:55.826: INFO: stdout: "update-demo-nautilus-jrwbj update-demo-nautilus-nxntg "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jul 31 12:39:00.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7905'
Jul 31 12:39:01.864: INFO: stderr: ""
Jul 31 12:39:01.864: INFO: stdout: "update-demo-nautilus-jrwbj update-demo-nautilus-nxntg "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jul 31 12:39:06.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7905'
Jul 31 12:39:07.956: INFO: stderr: ""
Jul 31 12:39:07.956: INFO: stdout: "update-demo-nautilus-jrwbj "
Jul 31 12:39:07.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-jrwbj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7905'
Jul 31 12:39:08.158: INFO: stderr: ""
Jul 31 12:39:08.158: INFO: stdout: "true"
Jul 31 12:39:08.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-jrwbj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7905'
Jul 31 12:39:08.954: INFO: stderr: ""
Jul 31 12:39:08.954: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 12:39:08.954: INFO: validating pod update-demo-nautilus-jrwbj
Jul 31 12:39:09.652: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 12:39:09.653: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 12:39:09.653: INFO: update-demo-nautilus-jrwbj is verified up and running
STEP: scaling up the replication controller
Jul 31 12:39:09.654: INFO: scanned /root for discovery docs: <nil>
Jul 31 12:39:09.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-7905'
Jul 31 12:39:11.022: INFO: stderr: ""
Jul 31 12:39:11.022: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 31 12:39:11.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7905'
Jul 31 12:39:11.145: INFO: stderr: ""
Jul 31 12:39:11.145: INFO: stdout: "update-demo-nautilus-2mqrc update-demo-nautilus-jrwbj "
Jul 31 12:39:11.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-2mqrc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7905'
Jul 31 12:39:11.924: INFO: stderr: ""
Jul 31 12:39:11.924: INFO: stdout: ""
Jul 31 12:39:11.924: INFO: update-demo-nautilus-2mqrc is created but not running
Jul 31 12:39:16.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7905'
Jul 31 12:39:17.443: INFO: stderr: ""
Jul 31 12:39:17.443: INFO: stdout: "update-demo-nautilus-2mqrc update-demo-nautilus-jrwbj "
Jul 31 12:39:17.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-2mqrc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7905'
Jul 31 12:39:17.620: INFO: stderr: ""
Jul 31 12:39:17.620: INFO: stdout: "true"
Jul 31 12:39:17.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-2mqrc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7905'
Jul 31 12:39:18.673: INFO: stderr: ""
Jul 31 12:39:18.673: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 12:39:18.673: INFO: validating pod update-demo-nautilus-2mqrc
Jul 31 12:39:19.453: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 12:39:19.453: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 12:39:19.453: INFO: update-demo-nautilus-2mqrc is verified up and running
Jul 31 12:39:19.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-jrwbj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7905'
Jul 31 12:39:20.042: INFO: stderr: ""
Jul 31 12:39:20.042: INFO: stdout: "true"
Jul 31 12:39:20.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-jrwbj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7905'
Jul 31 12:39:20.324: INFO: stderr: ""
Jul 31 12:39:20.324: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 12:39:20.324: INFO: validating pod update-demo-nautilus-jrwbj
Jul 31 12:39:21.253: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 12:39:21.253: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 12:39:21.253: INFO: update-demo-nautilus-jrwbj is verified up and running
STEP: using delete to clean up resources
Jul 31 12:39:21.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 delete --grace-period=0 --force -f - --namespace=kubectl-7905'
Jul 31 12:39:22.323: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 12:39:22.323: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jul 31 12:39:22.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7905'
Jul 31 12:39:22.554: INFO: stderr: "No resources found.\n"
Jul 31 12:39:22.554: INFO: stdout: ""
Jul 31 12:39:22.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -l name=update-demo --namespace=kubectl-7905 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 31 12:39:23.460: INFO: stderr: ""
Jul 31 12:39:23.460: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:39:23.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7905" for this suite.
Jul 31 12:39:30.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:39:36.296: INFO: namespace kubectl-7905 deletion completed in 12.441747965s

• [SLOW TEST:57.040 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:39:36.296: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jul 31 12:39:37.474: INFO: Pod name pod-release: Found 0 pods out of 1
Jul 31 12:39:42.752: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:39:43.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1153" for this suite.
Jul 31 12:39:50.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:39:58.373: INFO: namespace replication-controller-1153 deletion completed in 14.61564168s

• [SLOW TEST:22.077 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:39:58.374: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Jul 31 12:39:59.570: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:40:15.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-706" for this suite.
Jul 31 12:40:21.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:40:27.580: INFO: namespace pods-706 deletion completed in 12.40559744s

• [SLOW TEST:29.207 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:40:27.581: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-5ffdb3ee-b390-11e9-82b5-da5bffca47b9
Jul 31 12:40:27.894: INFO: Pod name my-hostname-basic-5ffdb3ee-b390-11e9-82b5-da5bffca47b9: Found 1 pods out of 1
Jul 31 12:40:27.894: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-5ffdb3ee-b390-11e9-82b5-da5bffca47b9" are running
Jul 31 12:40:35.945: INFO: Pod "my-hostname-basic-5ffdb3ee-b390-11e9-82b5-da5bffca47b9-xqdx5" is running (conditions: [])
Jul 31 12:40:35.945: INFO: Trying to dial the pod
Jul 31 12:40:41.553: INFO: Controller my-hostname-basic-5ffdb3ee-b390-11e9-82b5-da5bffca47b9: Got expected result from replica 1 [my-hostname-basic-5ffdb3ee-b390-11e9-82b5-da5bffca47b9-xqdx5]: "my-hostname-basic-5ffdb3ee-b390-11e9-82b5-da5bffca47b9-xqdx5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:40:41.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8826" for this suite.
Jul 31 12:40:47.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:40:51.912: INFO: namespace replication-controller-8826 deletion completed in 10.349763432s

• [SLOW TEST:24.332 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:40:51.913: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 12:40:52.854: INFO: Creating ReplicaSet my-hostname-basic-6ee30a49-b390-11e9-82b5-da5bffca47b9
Jul 31 12:40:52.891: INFO: Pod name my-hostname-basic-6ee30a49-b390-11e9-82b5-da5bffca47b9: Found 0 pods out of 1
Jul 31 12:40:58.063: INFO: Pod name my-hostname-basic-6ee30a49-b390-11e9-82b5-da5bffca47b9: Found 1 pods out of 1
Jul 31 12:40:58.063: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-6ee30a49-b390-11e9-82b5-da5bffca47b9" is running
Jul 31 12:41:00.753: INFO: Pod "my-hostname-basic-6ee30a49-b390-11e9-82b5-da5bffca47b9-ptxg7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-31 12:40:52 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-31 12:40:52 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-6ee30a49-b390-11e9-82b5-da5bffca47b9]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-31 12:40:52 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-6ee30a49-b390-11e9-82b5-da5bffca47b9]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-31 12:40:52 +0000 UTC Reason: Message:}])
Jul 31 12:41:00.753: INFO: Trying to dial the pod
Jul 31 12:41:06.153: INFO: Controller my-hostname-basic-6ee30a49-b390-11e9-82b5-da5bffca47b9: Got expected result from replica 1 [my-hostname-basic-6ee30a49-b390-11e9-82b5-da5bffca47b9-ptxg7]: "my-hostname-basic-6ee30a49-b390-11e9-82b5-da5bffca47b9-ptxg7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:41:06.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7394" for this suite.
Jul 31 12:41:12.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:41:14.585: INFO: namespace replicaset-7394 deletion completed in 8.324617779s

• [SLOW TEST:22.672 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:41:14.587: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:41:15.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9742" for this suite.
Jul 31 12:41:37.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:41:44.801: INFO: namespace kubelet-test-9742 deletion completed in 29.309517104s

• [SLOW TEST:30.214 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:41:44.803: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-8e4d6cd2-b390-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume secrets
Jul 31 12:41:45.591: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8e4f364a-b390-11e9-82b5-da5bffca47b9" in namespace "projected-3016" to be "success or failure"
Jul 31 12:41:45.620: INFO: Pod "pod-projected-secrets-8e4f364a-b390-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 28.813505ms
Jul 31 12:41:47.659: INFO: Pod "pod-projected-secrets-8e4f364a-b390-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067598752s
Jul 31 12:41:49.757: INFO: Pod "pod-projected-secrets-8e4f364a-b390-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.165892857s
Jul 31 12:41:52.253: INFO: Pod "pod-projected-secrets-8e4f364a-b390-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.661114353s
Jul 31 12:41:54.457: INFO: Pod "pod-projected-secrets-8e4f364a-b390-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.865668504s
STEP: Saw pod success
Jul 31 12:41:54.457: INFO: Pod "pod-projected-secrets-8e4f364a-b390-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:41:54.754: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-projected-secrets-8e4f364a-b390-11e9-82b5-da5bffca47b9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 31 12:41:56.253: INFO: Waiting for pod pod-projected-secrets-8e4f364a-b390-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:41:56.269: INFO: Pod pod-projected-secrets-8e4f364a-b390-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:41:56.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3016" for this suite.
Jul 31 12:42:02.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:42:11.270: INFO: namespace projected-3016 deletion completed in 14.992092844s

• [SLOW TEST:26.467 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:42:11.270: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Jul 31 12:42:16.055: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jul 31 12:42:16.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 create -f - --namespace=kubectl-9957'
Jul 31 12:42:17.254: INFO: stderr: ""
Jul 31 12:42:17.254: INFO: stdout: "service/redis-slave created\n"
Jul 31 12:42:17.254: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jul 31 12:42:17.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 create -f - --namespace=kubectl-9957'
Jul 31 12:42:18.723: INFO: stderr: ""
Jul 31 12:42:18.723: INFO: stdout: "service/redis-master created\n"
Jul 31 12:42:18.723: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jul 31 12:42:18.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 create -f - --namespace=kubectl-9957'
Jul 31 12:42:20.240: INFO: stderr: ""
Jul 31 12:42:20.240: INFO: stdout: "service/frontend created\n"
Jul 31 12:42:20.240: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jul 31 12:42:20.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 create -f - --namespace=kubectl-9957'
Jul 31 12:42:21.940: INFO: stderr: ""
Jul 31 12:42:21.940: INFO: stdout: "deployment.apps/frontend created\n"
Jul 31 12:42:21.940: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jul 31 12:42:21.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 create -f - --namespace=kubectl-9957'
Jul 31 12:42:23.223: INFO: stderr: ""
Jul 31 12:42:23.223: INFO: stdout: "deployment.apps/redis-master created\n"
Jul 31 12:42:23.223: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jul 31 12:42:23.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 create -f - --namespace=kubectl-9957'
Jul 31 12:42:25.355: INFO: stderr: ""
Jul 31 12:42:25.355: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Jul 31 12:42:25.355: INFO: Waiting for all frontend pods to be Running.
Jul 31 12:43:05.603: INFO: Waiting for frontend to serve content.
Jul 31 12:43:10.953: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Jul 31 12:43:18.654: INFO: Trying to add a new entry to the guestbook.
Jul 31 12:43:20.196: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jul 31 12:43:20.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 delete --grace-period=0 --force -f - --namespace=kubectl-9957'
Jul 31 12:43:21.232: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 12:43:21.232: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jul 31 12:43:21.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 delete --grace-period=0 --force -f - --namespace=kubectl-9957'
Jul 31 12:43:23.023: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 12:43:23.023: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jul 31 12:43:23.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 delete --grace-period=0 --force -f - --namespace=kubectl-9957'
Jul 31 12:43:23.727: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 12:43:23.728: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jul 31 12:43:23.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 delete --grace-period=0 --force -f - --namespace=kubectl-9957'
Jul 31 12:43:25.460: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 12:43:25.460: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jul 31 12:43:25.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 delete --grace-period=0 --force -f - --namespace=kubectl-9957'
Jul 31 12:43:25.887: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 12:43:25.887: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jul 31 12:43:25.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 delete --grace-period=0 --force -f - --namespace=kubectl-9957'
Jul 31 12:43:27.351: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 12:43:27.351: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:43:27.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9957" for this suite.
Jul 31 12:44:07.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:44:09.897: INFO: namespace kubectl-9957 deletion completed in 42.133790088s

• [SLOW TEST:118.627 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:44:09.897: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-2023
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Jul 31 12:44:11.662: INFO: Found 1 stateful pods, waiting for 3
Jul 31 12:44:22.458: INFO: Found 2 stateful pods, waiting for 3
Jul 31 12:44:31.758: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 12:44:31.758: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 12:44:31.758: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 12:44:31.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2023 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 12:44:38.197: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 31 12:44:38.197: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 12:44:38.197: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jul 31 12:44:39.096: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jul 31 12:44:50.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2023 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 12:44:54.355: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 31 12:44:54.355: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 31 12:44:54.355: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 31 12:45:05.980: INFO: Waiting for StatefulSet statefulset-2023/ss2 to complete update
Jul 31 12:45:05.980: INFO: Waiting for Pod statefulset-2023/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jul 31 12:45:05.980: INFO: Waiting for Pod statefulset-2023/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jul 31 12:45:16.758: INFO: Waiting for StatefulSet statefulset-2023/ss2 to complete update
Jul 31 12:45:16.758: INFO: Waiting for Pod statefulset-2023/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jul 31 12:45:16.758: INFO: Waiting for Pod statefulset-2023/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jul 31 12:45:26.044: INFO: Waiting for StatefulSet statefulset-2023/ss2 to complete update
Jul 31 12:45:26.044: INFO: Waiting for Pod statefulset-2023/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jul 31 12:45:37.478: INFO: Waiting for StatefulSet statefulset-2023/ss2 to complete update
STEP: Rolling back to a previous revision
Jul 31 12:45:46.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2023 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 12:45:50.154: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 31 12:45:50.154: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 12:45:50.154: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 12:45:50.669: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jul 31 12:46:01.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2023 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 12:46:07.123: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 31 12:46:07.123: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 31 12:46:07.123: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 31 12:46:18.662: INFO: Waiting for StatefulSet statefulset-2023/ss2 to complete update
Jul 31 12:46:18.662: INFO: Waiting for Pod statefulset-2023/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Jul 31 12:46:18.662: INFO: Waiting for Pod statefulset-2023/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Jul 31 12:46:18.662: INFO: Waiting for Pod statefulset-2023/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Jul 31 12:46:29.262: INFO: Waiting for StatefulSet statefulset-2023/ss2 to complete update
Jul 31 12:46:29.262: INFO: Waiting for Pod statefulset-2023/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Jul 31 12:46:29.262: INFO: Waiting for Pod statefulset-2023/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Jul 31 12:46:39.358: INFO: Waiting for StatefulSet statefulset-2023/ss2 to complete update
Jul 31 12:46:39.358: INFO: Waiting for Pod statefulset-2023/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Jul 31 12:46:39.358: INFO: Waiting for Pod statefulset-2023/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Jul 31 12:46:48.765: INFO: Waiting for StatefulSet statefulset-2023/ss2 to complete update
Jul 31 12:46:48.765: INFO: Waiting for Pod statefulset-2023/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Jul 31 12:46:59.053: INFO: Waiting for StatefulSet statefulset-2023/ss2 to complete update
Jul 31 12:46:59.053: INFO: Waiting for Pod statefulset-2023/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 31 12:47:09.253: INFO: Deleting all statefulset in ns statefulset-2023
Jul 31 12:47:09.653: INFO: Scaling statefulset ss2 to 0
Jul 31 12:47:41.153: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 12:47:41.462: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:47:41.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2023" for this suite.
Jul 31 12:47:50.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:47:58.594: INFO: namespace statefulset-2023 deletion completed in 16.917487369s

• [SLOW TEST:228.697 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:47:58.599: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-6da4c9f0-b391-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume configMaps
Jul 31 12:48:00.295: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6da6799e-b391-11e9-82b5-da5bffca47b9" in namespace "projected-2597" to be "success or failure"
Jul 31 12:48:00.309: INFO: Pod "pod-projected-configmaps-6da6799e-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 13.440131ms
Jul 31 12:48:02.754: INFO: Pod "pod-projected-configmaps-6da6799e-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.459373673s
Jul 31 12:48:05.190: INFO: Pod "pod-projected-configmaps-6da6799e-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.895128916s
Jul 31 12:48:07.753: INFO: Pod "pod-projected-configmaps-6da6799e-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.458407796s
Jul 31 12:48:10.053: INFO: Pod "pod-projected-configmaps-6da6799e-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.758540841s
Jul 31 12:48:12.344: INFO: Pod "pod-projected-configmaps-6da6799e-b391-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.048995771s
STEP: Saw pod success
Jul 31 12:48:12.344: INFO: Pod "pod-projected-configmaps-6da6799e-b391-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:48:14.453: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-projected-configmaps-6da6799e-b391-11e9-82b5-da5bffca47b9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 12:48:15.390: INFO: Waiting for pod pod-projected-configmaps-6da6799e-b391-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:48:15.400: INFO: Pod pod-projected-configmaps-6da6799e-b391-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:48:15.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2597" for this suite.
Jul 31 12:48:24.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:48:31.253: INFO: namespace projected-2597 deletion completed in 15.843531501s

• [SLOW TEST:32.654 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:48:31.253: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-81f66713-b391-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume configMaps
Jul 31 12:48:34.581: INFO: Waiting up to 5m0s for pod "pod-configmaps-8214cbd3-b391-11e9-82b5-da5bffca47b9" in namespace "configmap-6756" to be "success or failure"
Jul 31 12:48:34.608: INFO: Pod "pod-configmaps-8214cbd3-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 27.195776ms
Jul 31 12:48:36.781: INFO: Pod "pod-configmaps-8214cbd3-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.200012889s
Jul 31 12:48:38.953: INFO: Pod "pod-configmaps-8214cbd3-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.372367809s
Jul 31 12:48:43.157: INFO: Pod "pod-configmaps-8214cbd3-b391-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.576621471s
STEP: Saw pod success
Jul 31 12:48:43.157: INFO: Pod "pod-configmaps-8214cbd3-b391-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:48:43.165: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-configmaps-8214cbd3-b391-11e9-82b5-da5bffca47b9 container configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 12:48:43.888: INFO: Waiting for pod pod-configmaps-8214cbd3-b391-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:48:43.894: INFO: Pod pod-configmaps-8214cbd3-b391-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:48:43.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6756" for this suite.
Jul 31 12:48:50.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:48:53.885: INFO: namespace configmap-6756 deletion completed in 9.97051777s

• [SLOW TEST:22.632 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:48:53.886: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-9844/secret-test-8f61a26d-b391-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume secrets
Jul 31 12:48:56.897: INFO: Waiting up to 5m0s for pod "pod-configmaps-8f63d1f0-b391-11e9-82b5-da5bffca47b9" in namespace "secrets-9844" to be "success or failure"
Jul 31 12:48:57.153: INFO: Pod "pod-configmaps-8f63d1f0-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 255.617746ms
Jul 31 12:48:59.159: INFO: Pod "pod-configmaps-8f63d1f0-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.261691671s
Jul 31 12:49:01.453: INFO: Pod "pod-configmaps-8f63d1f0-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.555400654s
Jul 31 12:49:05.453: INFO: Pod "pod-configmaps-8f63d1f0-b391-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.555540841s
STEP: Saw pod success
Jul 31 12:49:05.453: INFO: Pod "pod-configmaps-8f63d1f0-b391-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:49:05.861: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-configmaps-8f63d1f0-b391-11e9-82b5-da5bffca47b9 container env-test: <nil>
STEP: delete the pod
Jul 31 12:49:06.583: INFO: Waiting for pod pod-configmaps-8f63d1f0-b391-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:49:06.589: INFO: Pod pod-configmaps-8f63d1f0-b391-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:49:06.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9844" for this suite.
Jul 31 12:49:12.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:49:19.258: INFO: namespace secrets-9844 deletion completed in 12.65978674s

• [SLOW TEST:25.372 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:49:19.258: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 12:49:21.553: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e092eaf-b391-11e9-82b5-da5bffca47b9" in namespace "downward-api-7366" to be "success or failure"
Jul 31 12:49:21.953: INFO: Pod "downwardapi-volume-9e092eaf-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 399.856329ms
Jul 31 12:49:24.153: INFO: Pod "downwardapi-volume-9e092eaf-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.600012449s
Jul 31 12:49:26.161: INFO: Pod "downwardapi-volume-9e092eaf-b391-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.607777809s
STEP: Saw pod success
Jul 31 12:49:26.161: INFO: Pod "downwardapi-volume-9e092eaf-b391-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:49:26.168: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod downwardapi-volume-9e092eaf-b391-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 12:49:27.402: INFO: Waiting for pod downwardapi-volume-9e092eaf-b391-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:49:27.409: INFO: Pod downwardapi-volume-9e092eaf-b391-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:49:27.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7366" for this suite.
Jul 31 12:49:33.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:49:37.304: INFO: namespace downward-api-7366 deletion completed in 9.882001917s

• [SLOW TEST:18.046 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:49:37.325: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jul 31 12:49:46.253: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a7fd7f05-b391-11e9-82b5-da5bffca47b9"
Jul 31 12:49:46.253: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a7fd7f05-b391-11e9-82b5-da5bffca47b9" in namespace "pods-5165" to be "terminated due to deadline exceeded"
Jul 31 12:49:46.453: INFO: Pod "pod-update-activedeadlineseconds-a7fd7f05-b391-11e9-82b5-da5bffca47b9": Phase="Running", Reason="", readiness=true. Elapsed: 199.887808ms
Jul 31 12:49:48.653: INFO: Pod "pod-update-activedeadlineseconds-a7fd7f05-b391-11e9-82b5-da5bffca47b9": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.399606009s
Jul 31 12:49:48.653: INFO: Pod "pod-update-activedeadlineseconds-a7fd7f05-b391-11e9-82b5-da5bffca47b9" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:49:48.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5165" for this suite.
Jul 31 12:49:55.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:50:01.300: INFO: namespace pods-5165 deletion completed in 12.346550578s

• [SLOW TEST:23.975 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:50:01.301: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jul 31 12:50:04.569: INFO: Waiting up to 5m0s for pod "pod-b7b9a6d0-b391-11e9-82b5-da5bffca47b9" in namespace "emptydir-693" to be "success or failure"
Jul 31 12:50:04.579: INFO: Pod "pod-b7b9a6d0-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.052216ms
Jul 31 12:50:06.772: INFO: Pod "pod-b7b9a6d0-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.203010176s
Jul 31 12:50:08.964: INFO: Pod "pod-b7b9a6d0-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.395537534s
Jul 31 12:50:11.353: INFO: Pod "pod-b7b9a6d0-b391-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.784620857s
STEP: Saw pod success
Jul 31 12:50:11.354: INFO: Pod "pod-b7b9a6d0-b391-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:50:11.361: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-b7b9a6d0-b391-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 12:50:14.254: INFO: Waiting for pod pod-b7b9a6d0-b391-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:50:15.157: INFO: Pod pod-b7b9a6d0-b391-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:50:15.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-693" for this suite.
Jul 31 12:50:21.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:50:25.858: INFO: namespace emptydir-693 deletion completed in 10.687501717s

• [SLOW TEST:24.557 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:50:25.858: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1423
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 31 12:50:26.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-3414'
Jul 31 12:50:29.530: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 31 12:50:29.530: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jul 31 12:50:30.853: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-9mb25]
Jul 31 12:50:30.853: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-9mb25" in namespace "kubectl-3414" to be "running and ready"
Jul 31 12:50:31.253: INFO: Pod "e2e-test-nginx-rc-9mb25": Phase="Pending", Reason="", readiness=false. Elapsed: 399.765971ms
Jul 31 12:50:34.361: INFO: Pod "e2e-test-nginx-rc-9mb25": Phase="Pending", Reason="", readiness=false. Elapsed: 3.508101354s
Jul 31 12:50:36.556: INFO: Pod "e2e-test-nginx-rc-9mb25": Phase="Running", Reason="", readiness=true. Elapsed: 5.702797012s
Jul 31 12:50:36.557: INFO: Pod "e2e-test-nginx-rc-9mb25" satisfied condition "running and ready"
Jul 31 12:50:36.557: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-9mb25]
Jul 31 12:50:36.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 logs rc/e2e-test-nginx-rc --namespace=kubectl-3414'
Jul 31 12:50:38.523: INFO: stderr: ""
Jul 31 12:50:38.523: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1428
Jul 31 12:50:38.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 delete rc e2e-test-nginx-rc --namespace=kubectl-3414'
Jul 31 12:50:39.430: INFO: stderr: ""
Jul 31 12:50:39.430: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:50:39.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3414" for this suite.
Jul 31 12:51:05.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:51:12.230: INFO: namespace kubectl-3414 deletion completed in 32.766089872s

• [SLOW TEST:46.372 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:51:12.230: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 12:51:21.585: INFO: Waiting up to 5m0s for pod "client-envvars-e576ca5e-b391-11e9-82b5-da5bffca47b9" in namespace "pods-5194" to be "success or failure"
Jul 31 12:51:21.596: INFO: Pod "client-envvars-e576ca5e-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.006557ms
Jul 31 12:51:24.053: INFO: Pod "client-envvars-e576ca5e-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.467623229s
Jul 31 12:51:26.072: INFO: Pod "client-envvars-e576ca5e-b391-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.486135123s
Jul 31 12:51:28.081: INFO: Pod "client-envvars-e576ca5e-b391-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.495784001s
STEP: Saw pod success
Jul 31 12:51:28.081: INFO: Pod "client-envvars-e576ca5e-b391-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 12:51:28.089: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod client-envvars-e576ca5e-b391-11e9-82b5-da5bffca47b9 container env3cont: <nil>
STEP: delete the pod
Jul 31 12:51:28.655: INFO: Waiting for pod client-envvars-e576ca5e-b391-11e9-82b5-da5bffca47b9 to disappear
Jul 31 12:51:28.855: INFO: Pod client-envvars-e576ca5e-b391-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:51:28.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5194" for this suite.
Jul 31 12:52:15.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:52:20.153: INFO: namespace pods-5194 deletion completed in 51.098721523s

• [SLOW TEST:67.923 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:52:20.154: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jul 31 12:52:33.477: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 12:52:33.485: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 12:52:35.485: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 12:52:36.172: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 12:52:37.485: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 12:52:38.259: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 12:52:39.491: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 12:52:39.754: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 12:52:41.485: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 12:52:41.753: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 12:52:43.485: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 12:52:44.358: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 12:52:45.485: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 12:52:46.267: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 12:52:47.485: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 12:52:47.758: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 12:52:49.485: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 12:52:49.558: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 12:52:51.485: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 12:52:51.558: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 12:52:53.485: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 12:52:53.757: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 12:52:55.485: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 12:52:56.153: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 12:52:57.485: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 12:52:57.754: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 12:52:59.485: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 12:52:59.500: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 12:53:01.485: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 12:53:02.258: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 12:53:03.485: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 12:53:04.458: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:53:04.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7974" for this suite.
Jul 31 12:53:30.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:53:38.960: INFO: namespace container-lifecycle-hook-7974 deletion completed in 34.487366658s

• [SLOW TEST:78.808 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:53:38.962: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-9659
Jul 31 12:53:47.753: INFO: Started pod liveness-http in namespace container-probe-9659
STEP: checking the pod's current state and verifying that restartCount is present
Jul 31 12:53:47.953: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:57:48.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9659" for this suite.
Jul 31 12:57:55.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:58:07.067: INFO: namespace container-probe-9659 deletion completed in 18.113718301s

• [SLOW TEST:268.105 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:58:07.068: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5237.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5237.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5237.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5237.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5237.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5237.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5237.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5237.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5237.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5237.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5237.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5237.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5237.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 139.10.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.10.139_udp@PTR;check="$$(dig +tcp +noall +answer +search 139.10.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.10.139_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5237.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5237.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5237.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5237.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5237.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5237.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5237.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5237.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5237.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5237.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5237.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5237.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5237.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 139.10.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.10.139_udp@PTR;check="$$(dig +tcp +noall +answer +search 139.10.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.10.139_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul 31 12:58:33.853: INFO: DNS probes using dns-5237/dns-test-d83629b8-b392-11e9-82b5-da5bffca47b9 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 12:58:34.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5237" for this suite.
Jul 31 12:58:41.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 12:58:46.353: INFO: namespace dns-5237 deletion completed in 11.292949494s

• [SLOW TEST:39.291 seconds]
[sig-network] DNS
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 12:58:46.365: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-efb25bd7-b392-11e9-82b5-da5bffca47b9
STEP: Creating configMap with name cm-test-opt-upd-efb25c42-b392-11e9-82b5-da5bffca47b9
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-efb25bd7-b392-11e9-82b5-da5bffca47b9
STEP: Updating configmap cm-test-opt-upd-efb25c42-b392-11e9-82b5-da5bffca47b9
STEP: Creating configMap with name cm-test-opt-create-efb25c5c-b392-11e9-82b5-da5bffca47b9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:00:06.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5371" for this suite.
Jul 31 13:00:30.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:00:32.857: INFO: namespace configmap-5371 deletion completed in 25.901663577s

• [SLOW TEST:106.494 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:00:32.859: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-2e76553a-b393-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume configMaps
Jul 31 13:00:33.755: INFO: Waiting up to 5m0s for pod "pod-configmaps-2ea365e2-b393-11e9-82b5-da5bffca47b9" in namespace "configmap-1038" to be "success or failure"
Jul 31 13:00:34.162: INFO: Pod "pod-configmaps-2ea365e2-b393-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 406.296574ms
Jul 31 13:00:36.353: INFO: Pod "pod-configmaps-2ea365e2-b393-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.597900075s
Jul 31 13:00:39.753: INFO: Pod "pod-configmaps-2ea365e2-b393-11e9-82b5-da5bffca47b9": Phase="Running", Reason="", readiness=true. Elapsed: 5.997959808s
Jul 31 13:00:41.761: INFO: Pod "pod-configmaps-2ea365e2-b393-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.005707009s
STEP: Saw pod success
Jul 31 13:00:41.761: INFO: Pod "pod-configmaps-2ea365e2-b393-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:00:41.767: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-configmaps-2ea365e2-b393-11e9-82b5-da5bffca47b9 container configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 13:00:42.380: INFO: Waiting for pod pod-configmaps-2ea365e2-b393-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:00:42.386: INFO: Pod pod-configmaps-2ea365e2-b393-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:00:42.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1038" for this suite.
Jul 31 13:00:48.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:00:51.863: INFO: namespace configmap-1038 deletion completed in 9.468250965s

• [SLOW TEST:19.005 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:00:51.864: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 13:00:51.945: INFO: Waiting up to 5m0s for pod "downwardapi-volume-39977c8f-b393-11e9-82b5-da5bffca47b9" in namespace "downward-api-8629" to be "success or failure"
Jul 31 13:00:52.053: INFO: Pod "downwardapi-volume-39977c8f-b393-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 108.524296ms
Jul 31 13:00:54.619: INFO: Pod "downwardapi-volume-39977c8f-b393-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.674879119s
Jul 31 13:00:57.061: INFO: Pod "downwardapi-volume-39977c8f-b393-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.116250743s
Jul 31 13:00:59.358: INFO: Pod "downwardapi-volume-39977c8f-b393-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.41294686s
Jul 31 13:01:01.560: INFO: Pod "downwardapi-volume-39977c8f-b393-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 9.615477277s
STEP: Saw pod success
Jul 31 13:01:01.560: INFO: Pod "downwardapi-volume-39977c8f-b393-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:01:01.658: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod downwardapi-volume-39977c8f-b393-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 13:01:02.061: INFO: Waiting for pod downwardapi-volume-39977c8f-b393-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:01:02.068: INFO: Pod downwardapi-volume-39977c8f-b393-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:01:02.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8629" for this suite.
Jul 31 13:01:08.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:01:10.253: INFO: namespace downward-api-8629 deletion completed in 8.173810208s

• [SLOW TEST:18.389 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:01:10.253: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-3565
Jul 31 13:01:19.071: INFO: Started pod liveness-exec in namespace container-probe-3565
STEP: checking the pod's current state and verifying that restartCount is present
Jul 31 13:01:19.079: INFO: Initial restart count of pod liveness-exec is 0
Jul 31 13:02:15.953: INFO: Restart count of pod container-probe-3565/liveness-exec is now 1 (56.874269802s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:02:16.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3565" for this suite.
Jul 31 13:02:22.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:02:25.175: INFO: namespace container-probe-3565 deletion completed in 8.421404272s

• [SLOW TEST:74.922 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:02:25.176: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jul 31 13:02:42.349: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 13:02:43.654: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 13:02:45.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 13:02:45.663: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 13:02:47.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 13:02:48.558: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 13:02:49.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 13:02:49.758: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 13:02:51.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 13:02:51.665: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 13:02:53.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 13:02:55.358: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 13:02:55.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 13:02:55.759: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 13:02:57.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 13:02:57.958: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 13:02:59.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 13:02:59.757: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 13:03:01.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 13:03:01.766: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 13:03:03.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 13:03:03.758: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 13:03:05.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 13:03:05.757: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 13:03:07.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 13:03:08.053: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 13:03:09.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 13:03:09.963: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 13:03:11.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 13:03:12.353: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 13:03:13.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 13:03:14.253: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:03:14.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2434" for this suite.
Jul 31 13:03:37.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:03:43.553: INFO: namespace container-lifecycle-hook-2434 deletion completed in 28.599892942s

• [SLOW TEST:78.377 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:03:43.554: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-r4gvd in namespace proxy-1036
I0731 13:03:47.359012      19 runners.go:184] Created replication controller with name: proxy-service-r4gvd, namespace: proxy-1036, replica count: 1
I0731 13:03:48.409604      19 runners.go:184] proxy-service-r4gvd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 13:03:49.409985      19 runners.go:184] proxy-service-r4gvd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 13:03:50.410425      19 runners.go:184] proxy-service-r4gvd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 13:03:51.410648      19 runners.go:184] proxy-service-r4gvd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 13:03:52.410944      19 runners.go:184] proxy-service-r4gvd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 13:03:53.412475      19 runners.go:184] proxy-service-r4gvd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 13:03:54.414250      19 runners.go:184] proxy-service-r4gvd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 13:03:55.414507      19 runners.go:184] proxy-service-r4gvd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0731 13:03:56.414724      19 runners.go:184] proxy-service-r4gvd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0731 13:03:57.419080      19 runners.go:184] proxy-service-r4gvd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0731 13:03:58.419314      19 runners.go:184] proxy-service-r4gvd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0731 13:03:59.419493      19 runners.go:184] proxy-service-r4gvd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0731 13:04:00.419949      19 runners.go:184] proxy-service-r4gvd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0731 13:04:01.420610      19 runners.go:184] proxy-service-r4gvd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0731 13:04:02.421128      19 runners.go:184] proxy-service-r4gvd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0731 13:04:03.421315      19 runners.go:184] proxy-service-r4gvd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0731 13:04:04.426716      19 runners.go:184] proxy-service-r4gvd Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 31 13:04:04.556: INFO: setup took 19.242003449s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jul 31 13:04:05.958: INFO: (0) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 1.401054804s)
Jul 31 13:04:05.960: INFO: (0) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 1.402742135s)
Jul 31 13:04:05.961: INFO: (0) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 1.403790926s)
Jul 31 13:04:05.961: INFO: (0) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 1.404135437s)
Jul 31 13:04:05.961: INFO: (0) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 1.403892442s)
Jul 31 13:04:05.961: INFO: (0) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 1.404089158s)
Jul 31 13:04:05.961: INFO: (0) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 1.404034267s)
Jul 31 13:04:05.961: INFO: (0) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 1.403940796s)
Jul 31 13:04:05.961: INFO: (0) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 1.404590058s)
Jul 31 13:04:05.961: INFO: (0) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 1.403890965s)
Jul 31 13:04:05.961: INFO: (0) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 1.404005947s)
Jul 31 13:04:06.202: INFO: (0) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 1.644646895s)
Jul 31 13:04:06.202: INFO: (0) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 1.645254224s)
Jul 31 13:04:06.203: INFO: (0) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 1.645438812s)
Jul 31 13:04:06.243: INFO: (0) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 1.686179098s)
Jul 31 13:04:06.243: INFO: (0) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 1.686036898s)
Jul 31 13:04:06.557: INFO: (1) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 313.094022ms)
Jul 31 13:04:06.557: INFO: (1) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 313.65268ms)
Jul 31 13:04:06.557: INFO: (1) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 313.232626ms)
Jul 31 13:04:06.557: INFO: (1) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 313.119827ms)
Jul 31 13:04:06.557: INFO: (1) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 313.761857ms)
Jul 31 13:04:06.557: INFO: (1) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 313.160368ms)
Jul 31 13:04:06.557: INFO: (1) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 313.435535ms)
Jul 31 13:04:06.853: INFO: (1) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 609.6951ms)
Jul 31 13:04:06.853: INFO: (1) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 609.431407ms)
Jul 31 13:04:06.853: INFO: (1) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 609.101927ms)
Jul 31 13:04:06.853: INFO: (1) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 609.33613ms)
Jul 31 13:04:06.853: INFO: (1) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 609.966199ms)
Jul 31 13:04:06.853: INFO: (1) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 609.436241ms)
Jul 31 13:04:06.853: INFO: (1) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 609.743746ms)
Jul 31 13:04:06.853: INFO: (1) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 609.086283ms)
Jul 31 13:04:06.853: INFO: (1) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 609.111012ms)
Jul 31 13:04:07.756: INFO: (2) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 901.822187ms)
Jul 31 13:04:07.756: INFO: (2) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 901.809996ms)
Jul 31 13:04:07.756: INFO: (2) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 902.076556ms)
Jul 31 13:04:07.756: INFO: (2) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 902.01867ms)
Jul 31 13:04:07.756: INFO: (2) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 901.976277ms)
Jul 31 13:04:07.756: INFO: (2) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 901.523422ms)
Jul 31 13:04:07.756: INFO: (2) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 901.605463ms)
Jul 31 13:04:07.756: INFO: (2) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 902.218995ms)
Jul 31 13:04:07.756: INFO: (2) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 901.835903ms)
Jul 31 13:04:07.756: INFO: (2) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 902.476676ms)
Jul 31 13:04:07.756: INFO: (2) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 901.623315ms)
Jul 31 13:04:07.756: INFO: (2) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 902.355938ms)
Jul 31 13:04:08.254: INFO: (2) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 1.399582717s)
Jul 31 13:04:08.254: INFO: (2) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 1.399419854s)
Jul 31 13:04:08.254: INFO: (2) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 1.399407183s)
Jul 31 13:04:08.254: INFO: (2) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 1.399678339s)
Jul 31 13:04:08.754: INFO: (3) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 498.890235ms)
Jul 31 13:04:08.754: INFO: (3) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 499.679093ms)
Jul 31 13:04:08.754: INFO: (3) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 499.326716ms)
Jul 31 13:04:08.754: INFO: (3) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 499.421981ms)
Jul 31 13:04:08.754: INFO: (3) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 499.560659ms)
Jul 31 13:04:08.754: INFO: (3) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 500.208118ms)
Jul 31 13:04:08.754: INFO: (3) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 499.223184ms)
Jul 31 13:04:08.754: INFO: (3) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 499.201767ms)
Jul 31 13:04:08.754: INFO: (3) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 499.158942ms)
Jul 31 13:04:08.754: INFO: (3) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 499.142249ms)
Jul 31 13:04:08.754: INFO: (3) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 499.32974ms)
Jul 31 13:04:08.754: INFO: (3) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 499.117908ms)
Jul 31 13:04:08.754: INFO: (3) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 499.754308ms)
Jul 31 13:04:08.754: INFO: (3) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 500.076523ms)
Jul 31 13:04:08.754: INFO: (3) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 500.183612ms)
Jul 31 13:04:08.754: INFO: (3) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 499.715419ms)
Jul 31 13:04:11.353: INFO: (4) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 2.598725464s)
Jul 31 13:04:11.353: INFO: (4) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 2.598769521s)
Jul 31 13:04:11.353: INFO: (4) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 2.598594299s)
Jul 31 13:04:11.353: INFO: (4) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 2.59859761s)
Jul 31 13:04:11.353: INFO: (4) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 2.598759172s)
Jul 31 13:04:11.353: INFO: (4) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 2.598692168s)
Jul 31 13:04:11.353: INFO: (4) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 2.598646242s)
Jul 31 13:04:11.353: INFO: (4) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 2.598899362s)
Jul 31 13:04:11.353: INFO: (4) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 2.598615049s)
Jul 31 13:04:11.353: INFO: (4) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 2.598765217s)
Jul 31 13:04:11.353: INFO: (4) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 2.598835536s)
Jul 31 13:04:11.353: INFO: (4) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 2.598742749s)
Jul 31 13:04:11.353: INFO: (4) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 2.598597062s)
Jul 31 13:04:11.353: INFO: (4) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 2.598711839s)
Jul 31 13:04:11.353: INFO: (4) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 2.599002676s)
Jul 31 13:04:11.353: INFO: (4) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 2.599095116s)
Jul 31 13:04:11.853: INFO: (5) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 499.364999ms)
Jul 31 13:04:11.853: INFO: (5) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 499.467763ms)
Jul 31 13:04:11.853: INFO: (5) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 499.445646ms)
Jul 31 13:04:11.853: INFO: (5) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 499.573102ms)
Jul 31 13:04:11.853: INFO: (5) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 499.573539ms)
Jul 31 13:04:11.853: INFO: (5) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 499.61363ms)
Jul 31 13:04:11.853: INFO: (5) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 499.530232ms)
Jul 31 13:04:11.853: INFO: (5) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 499.603938ms)
Jul 31 13:04:11.853: INFO: (5) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 499.586997ms)
Jul 31 13:04:11.853: INFO: (5) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 499.688999ms)
Jul 31 13:04:11.853: INFO: (5) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 499.583496ms)
Jul 31 13:04:11.853: INFO: (5) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 499.728834ms)
Jul 31 13:04:11.853: INFO: (5) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 499.585491ms)
Jul 31 13:04:11.853: INFO: (5) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 499.73621ms)
Jul 31 13:04:11.853: INFO: (5) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 499.773385ms)
Jul 31 13:04:11.853: INFO: (5) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 499.649001ms)
Jul 31 13:04:12.454: INFO: (6) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 600.236652ms)
Jul 31 13:04:12.454: INFO: (6) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 599.56645ms)
Jul 31 13:04:12.454: INFO: (6) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 599.739011ms)
Jul 31 13:04:12.454: INFO: (6) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 599.652135ms)
Jul 31 13:04:12.454: INFO: (6) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 600.133456ms)
Jul 31 13:04:12.454: INFO: (6) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 600.247948ms)
Jul 31 13:04:12.454: INFO: (6) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 600.082849ms)
Jul 31 13:04:12.454: INFO: (6) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 599.942368ms)
Jul 31 13:04:12.454: INFO: (6) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 600.454292ms)
Jul 31 13:04:12.454: INFO: (6) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 600.223064ms)
Jul 31 13:04:12.454: INFO: (6) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 600.581351ms)
Jul 31 13:04:12.454: INFO: (6) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 600.149936ms)
Jul 31 13:04:12.454: INFO: (6) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 600.406366ms)
Jul 31 13:04:12.454: INFO: (6) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 600.037838ms)
Jul 31 13:04:12.454: INFO: (6) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 599.817878ms)
Jul 31 13:04:12.454: INFO: (6) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 601.010848ms)
Jul 31 13:04:13.755: INFO: (7) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 1.299780545s)
Jul 31 13:04:13.755: INFO: (7) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 1.300029132s)
Jul 31 13:04:13.755: INFO: (7) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 1.300134844s)
Jul 31 13:04:13.755: INFO: (7) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 1.300220588s)
Jul 31 13:04:13.755: INFO: (7) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 1.300440357s)
Jul 31 13:04:13.755: INFO: (7) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 1.30031032s)
Jul 31 13:04:13.755: INFO: (7) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 1.300445497s)
Jul 31 13:04:13.755: INFO: (7) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 1.300372683s)
Jul 31 13:04:13.755: INFO: (7) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 1.300304729s)
Jul 31 13:04:13.755: INFO: (7) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 1.300550522s)
Jul 31 13:04:13.755: INFO: (7) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 1.300289364s)
Jul 31 13:04:13.755: INFO: (7) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 1.300191913s)
Jul 31 13:04:13.755: INFO: (7) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 1.300152447s)
Jul 31 13:04:13.755: INFO: (7) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 1.300261495s)
Jul 31 13:04:13.755: INFO: (7) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 1.300415587s)
Jul 31 13:04:13.755: INFO: (7) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 1.30052648s)
Jul 31 13:04:14.254: INFO: (8) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 495.99447ms)
Jul 31 13:04:14.265: INFO: (8) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 506.347369ms)
Jul 31 13:04:14.265: INFO: (8) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 508.275576ms)
Jul 31 13:04:14.265: INFO: (8) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 508.458794ms)
Jul 31 13:04:14.265: INFO: (8) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 508.644638ms)
Jul 31 13:04:14.265: INFO: (8) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 509.086062ms)
Jul 31 13:04:14.265: INFO: (8) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 508.065568ms)
Jul 31 13:04:14.265: INFO: (8) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 507.075097ms)
Jul 31 13:04:14.266: INFO: (8) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 508.721764ms)
Jul 31 13:04:14.266: INFO: (8) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 507.44017ms)
Jul 31 13:04:14.266: INFO: (8) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 509.420059ms)
Jul 31 13:04:14.266: INFO: (8) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 507.845294ms)
Jul 31 13:04:14.266: INFO: (8) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 508.583416ms)
Jul 31 13:04:14.758: INFO: (8) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 999.471711ms)
Jul 31 13:04:14.758: INFO: (8) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 999.214494ms)
Jul 31 13:04:14.758: INFO: (8) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 999.38323ms)
Jul 31 13:04:15.955: INFO: (9) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 1.195515829s)
Jul 31 13:04:15.955: INFO: (9) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 1.196018262s)
Jul 31 13:04:15.955: INFO: (9) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 1.196238839s)
Jul 31 13:04:15.955: INFO: (9) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 1.195459862s)
Jul 31 13:04:15.955: INFO: (9) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 1.196202581s)
Jul 31 13:04:15.955: INFO: (9) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 1.195604679s)
Jul 31 13:04:15.955: INFO: (9) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 1.19591829s)
Jul 31 13:04:15.955: INFO: (9) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 1.196477197s)
Jul 31 13:04:15.955: INFO: (9) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 1.195722555s)
Jul 31 13:04:15.955: INFO: (9) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 1.195712124s)
Jul 31 13:04:15.955: INFO: (9) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 1.196342785s)
Jul 31 13:04:15.955: INFO: (9) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 1.19664465s)
Jul 31 13:04:15.955: INFO: (9) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 1.196820336s)
Jul 31 13:04:15.955: INFO: (9) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 1.19619717s)
Jul 31 13:04:15.955: INFO: (9) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 1.196267176s)
Jul 31 13:04:15.955: INFO: (9) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 1.195784265s)
Jul 31 13:04:16.970: INFO: (10) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 1.013355637s)
Jul 31 13:04:16.977: INFO: (10) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 1.021890656s)
Jul 31 13:04:16.977: INFO: (10) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 1.021449293s)
Jul 31 13:04:16.977: INFO: (10) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 1.021184454s)
Jul 31 13:04:16.977: INFO: (10) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 1.021621566s)
Jul 31 13:04:16.978: INFO: (10) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 1.02156854s)
Jul 31 13:04:16.978: INFO: (10) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 1.021723908s)
Jul 31 13:04:16.978: INFO: (10) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 1.021418881s)
Jul 31 13:04:16.978: INFO: (10) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 1.022098605s)
Jul 31 13:04:16.978: INFO: (10) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 1.021907485s)
Jul 31 13:04:16.978: INFO: (10) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 1.021371752s)
Jul 31 13:04:16.978: INFO: (10) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 1.021535018s)
Jul 31 13:04:17.353: INFO: (10) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 1.398100062s)
Jul 31 13:04:17.355: INFO: (10) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 1.399476553s)
Jul 31 13:04:17.355: INFO: (10) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 1.399154901s)
Jul 31 13:04:17.355: INFO: (10) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 1.398742203s)
Jul 31 13:04:17.571: INFO: (11) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 215.74386ms)
Jul 31 13:04:17.571: INFO: (11) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 215.768002ms)
Jul 31 13:04:17.571: INFO: (11) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 215.755733ms)
Jul 31 13:04:17.571: INFO: (11) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 215.857459ms)
Jul 31 13:04:17.571: INFO: (11) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 216.165673ms)
Jul 31 13:04:17.571: INFO: (11) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 215.779339ms)
Jul 31 13:04:17.579: INFO: (11) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 223.272909ms)
Jul 31 13:04:17.579: INFO: (11) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 223.725584ms)
Jul 31 13:04:17.579: INFO: (11) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 223.142217ms)
Jul 31 13:04:17.579: INFO: (11) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 223.382925ms)
Jul 31 13:04:17.579: INFO: (11) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 223.425358ms)
Jul 31 13:04:17.579: INFO: (11) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 223.502593ms)
Jul 31 13:04:18.553: INFO: (11) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 1.197749321s)
Jul 31 13:04:18.553: INFO: (11) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 1.197811977s)
Jul 31 13:04:18.553: INFO: (11) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 1.197914156s)
Jul 31 13:04:18.553: INFO: (11) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 1.197903863s)
Jul 31 13:04:20.353: INFO: (12) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 1.79913031s)
Jul 31 13:04:20.353: INFO: (12) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 1.799376775s)
Jul 31 13:04:20.353: INFO: (12) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 1.799370727s)
Jul 31 13:04:20.353: INFO: (12) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 1.799193049s)
Jul 31 13:04:20.353: INFO: (12) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 1.799360776s)
Jul 31 13:04:20.361: INFO: (12) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 1.806813188s)
Jul 31 13:04:20.361: INFO: (12) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 1.807279193s)
Jul 31 13:04:20.361: INFO: (12) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 1.807398375s)
Jul 31 13:04:20.361: INFO: (12) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 1.807484748s)
Jul 31 13:04:20.361: INFO: (12) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 1.807525178s)
Jul 31 13:04:20.361: INFO: (12) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 1.807431543s)
Jul 31 13:04:20.361: INFO: (12) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 1.807731267s)
Jul 31 13:04:20.361: INFO: (12) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 1.8077177s)
Jul 31 13:04:20.362: INFO: (12) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 1.809108404s)
Jul 31 13:04:20.363: INFO: (12) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 1.80874092s)
Jul 31 13:04:20.363: INFO: (12) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 1.808765567s)
Jul 31 13:04:21.774: INFO: (13) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 1.411864467s)
Jul 31 13:04:22.158: INFO: (13) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 1.793742334s)
Jul 31 13:04:22.554: INFO: (13) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 2.189684914s)
Jul 31 13:04:22.554: INFO: (13) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 2.18849533s)
Jul 31 13:04:22.554: INFO: (13) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 2.190506395s)
Jul 31 13:04:22.554: INFO: (13) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 2.189902742s)
Jul 31 13:04:22.554: INFO: (13) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 2.189630447s)
Jul 31 13:04:22.554: INFO: (13) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 2.188599494s)
Jul 31 13:04:22.554: INFO: (13) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 2.190977951s)
Jul 31 13:04:22.554: INFO: (13) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 2.189579495s)
Jul 31 13:04:22.554: INFO: (13) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 2.189767041s)
Jul 31 13:04:22.953: INFO: (13) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 2.589514472s)
Jul 31 13:04:23.554: INFO: (13) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 3.189335669s)
Jul 31 13:04:23.554: INFO: (13) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 3.189426159s)
Jul 31 13:04:23.554: INFO: (13) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 3.188518382s)
Jul 31 13:04:23.554: INFO: (13) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 3.188442706s)
Jul 31 13:04:24.853: INFO: (14) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 1.29949901s)
Jul 31 13:04:24.853: INFO: (14) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 1.299348379s)
Jul 31 13:04:24.854: INFO: (14) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 1.2995392s)
Jul 31 13:04:24.854: INFO: (14) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 1.29776726s)
Jul 31 13:04:24.854: INFO: (14) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 1.299025273s)
Jul 31 13:04:24.854: INFO: (14) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 1.299261931s)
Jul 31 13:04:24.854: INFO: (14) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 1.299182451s)
Jul 31 13:04:24.854: INFO: (14) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 1.299356875s)
Jul 31 13:04:24.854: INFO: (14) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 1.299438696s)
Jul 31 13:04:24.854: INFO: (14) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 1.299061319s)
Jul 31 13:04:24.854: INFO: (14) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 1.299617618s)
Jul 31 13:04:24.854: INFO: (14) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 1.298177569s)
Jul 31 13:04:24.854: INFO: (14) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 1.299188591s)
Jul 31 13:04:24.854: INFO: (14) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 1.29934587s)
Jul 31 13:04:24.854: INFO: (14) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 1.299750283s)
Jul 31 13:04:24.854: INFO: (14) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 1.29948916s)
Jul 31 13:04:25.553: INFO: (15) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 697.91298ms)
Jul 31 13:04:25.553: INFO: (15) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 698.972851ms)
Jul 31 13:04:25.553: INFO: (15) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 697.847162ms)
Jul 31 13:04:25.553: INFO: (15) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 698.498315ms)
Jul 31 13:04:25.553: INFO: (15) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 697.927138ms)
Jul 31 13:04:25.553: INFO: (15) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 698.775588ms)
Jul 31 13:04:25.553: INFO: (15) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 698.623806ms)
Jul 31 13:04:25.553: INFO: (15) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 698.503947ms)
Jul 31 13:04:25.553: INFO: (15) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 698.203423ms)
Jul 31 13:04:25.553: INFO: (15) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 698.748121ms)
Jul 31 13:04:25.554: INFO: (15) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 698.181816ms)
Jul 31 13:04:25.554: INFO: (15) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 698.977563ms)
Jul 31 13:04:25.554: INFO: (15) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 698.355923ms)
Jul 31 13:04:25.554: INFO: (15) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 698.455095ms)
Jul 31 13:04:25.554: INFO: (15) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 698.553837ms)
Jul 31 13:04:25.554: INFO: (15) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 698.18534ms)
Jul 31 13:04:26.453: INFO: (16) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 898.692497ms)
Jul 31 13:04:26.454: INFO: (16) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 898.147037ms)
Jul 31 13:04:26.454: INFO: (16) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 898.21586ms)
Jul 31 13:04:26.454: INFO: (16) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 898.708079ms)
Jul 31 13:04:26.454: INFO: (16) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 897.871868ms)
Jul 31 13:04:26.454: INFO: (16) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 898.435577ms)
Jul 31 13:04:26.454: INFO: (16) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 899.751105ms)
Jul 31 13:04:26.454: INFO: (16) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 899.636819ms)
Jul 31 13:04:26.454: INFO: (16) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 899.864173ms)
Jul 31 13:04:26.454: INFO: (16) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 898.768134ms)
Jul 31 13:04:26.454: INFO: (16) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 898.469227ms)
Jul 31 13:04:26.454: INFO: (16) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 898.849705ms)
Jul 31 13:04:26.454: INFO: (16) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 898.741199ms)
Jul 31 13:04:26.454: INFO: (16) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 898.561814ms)
Jul 31 13:04:26.454: INFO: (16) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 898.02963ms)
Jul 31 13:04:26.454: INFO: (16) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 900.175282ms)
Jul 31 13:04:27.653: INFO: (17) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 1.19909294s)
Jul 31 13:04:27.653: INFO: (17) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 1.198951294s)
Jul 31 13:04:27.653: INFO: (17) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 1.199036105s)
Jul 31 13:04:27.653: INFO: (17) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 1.199104s)
Jul 31 13:04:27.653: INFO: (17) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 1.198892289s)
Jul 31 13:04:27.653: INFO: (17) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 1.19902363s)
Jul 31 13:04:27.653: INFO: (17) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 1.199246838s)
Jul 31 13:04:27.653: INFO: (17) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 1.199105444s)
Jul 31 13:04:27.653: INFO: (17) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 1.198991773s)
Jul 31 13:04:27.653: INFO: (17) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 1.199022965s)
Jul 31 13:04:27.653: INFO: (17) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 1.198995434s)
Jul 31 13:04:27.653: INFO: (17) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 1.199079186s)
Jul 31 13:04:27.653: INFO: (17) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 1.199153764s)
Jul 31 13:04:27.653: INFO: (17) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 1.199060702s)
Jul 31 13:04:27.653: INFO: (17) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 1.199072676s)
Jul 31 13:04:27.654: INFO: (17) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 1.199008441s)
Jul 31 13:04:29.455: INFO: (18) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 1.800831046s)
Jul 31 13:04:29.455: INFO: (18) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 1.800847199s)
Jul 31 13:04:29.455: INFO: (18) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 1.801136511s)
Jul 31 13:04:29.455: INFO: (18) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 1.800898352s)
Jul 31 13:04:29.455: INFO: (18) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 1.801114846s)
Jul 31 13:04:29.455: INFO: (18) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 1.801061255s)
Jul 31 13:04:29.455: INFO: (18) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 1.801124927s)
Jul 31 13:04:29.455: INFO: (18) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 1.801125302s)
Jul 31 13:04:29.455: INFO: (18) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 1.801110849s)
Jul 31 13:04:29.455: INFO: (18) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 1.801247882s)
Jul 31 13:04:29.455: INFO: (18) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 1.801289083s)
Jul 31 13:04:29.455: INFO: (18) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 1.801130274s)
Jul 31 13:04:29.455: INFO: (18) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 1.801151029s)
Jul 31 13:04:29.455: INFO: (18) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 1.80114481s)
Jul 31 13:04:29.455: INFO: (18) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 1.801051633s)
Jul 31 13:04:29.455: INFO: (18) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 1.801175971s)
Jul 31 13:04:33.156: INFO: (19) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">test<... (200; 3.699665598s)
Jul 31 13:04:33.156: INFO: (19) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:1080/proxy/rewriteme">... (200; 3.69969357s)
Jul 31 13:04:33.156: INFO: (19) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:460/proxy/: tls baz (200; 3.698857976s)
Jul 31 13:04:33.156: INFO: (19) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 3.699704287s)
Jul 31 13:04:33.156: INFO: (19) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 3.699525386s)
Jul 31 13:04:33.156: INFO: (19) /api/v1/namespaces/proxy-1036/pods/http:proxy-service-r4gvd-dkdnz:160/proxy/: foo (200; 3.699722228s)
Jul 31 13:04:33.156: INFO: (19) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz/proxy/rewriteme">test</a> (200; 3.699975862s)
Jul 31 13:04:33.156: INFO: (19) /api/v1/namespaces/proxy-1036/pods/proxy-service-r4gvd-dkdnz:162/proxy/: bar (200; 3.699705583s)
Jul 31 13:04:33.156: INFO: (19) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname1/proxy/: tls baz (200; 3.699968626s)
Jul 31 13:04:33.156: INFO: (19) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname2/proxy/: bar (200; 3.699716726s)
Jul 31 13:04:33.156: INFO: (19) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname1/proxy/: foo (200; 3.699528198s)
Jul 31 13:04:33.156: INFO: (19) /api/v1/namespaces/proxy-1036/services/http:proxy-service-r4gvd:portname1/proxy/: foo (200; 3.700157694s)
Jul 31 13:04:33.156: INFO: (19) /api/v1/namespaces/proxy-1036/services/proxy-service-r4gvd:portname2/proxy/: bar (200; 3.699890966s)
Jul 31 13:04:33.156: INFO: (19) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/: <a href="/api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:443/proxy/tlsrewritem... (200; 3.699669264s)
Jul 31 13:04:33.156: INFO: (19) /api/v1/namespaces/proxy-1036/services/https:proxy-service-r4gvd:tlsportname2/proxy/: tls qux (200; 3.699867983s)
Jul 31 13:04:33.156: INFO: (19) /api/v1/namespaces/proxy-1036/pods/https:proxy-service-r4gvd-dkdnz:462/proxy/: tls qux (200; 3.699855078s)
STEP: deleting ReplicationController proxy-service-r4gvd in namespace proxy-1036, will wait for the garbage collector to delete the pods
Jul 31 13:04:33.453: INFO: Deleting ReplicationController proxy-service-r4gvd took: 224.877222ms
Jul 31 13:04:34.053: INFO: Terminating ReplicationController proxy-service-r4gvd pods took: 600.357417ms
[AfterEach] version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:04:39.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1036" for this suite.
Jul 31 13:04:46.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:04:49.453: INFO: namespace proxy-1036 deletion completed in 9.699232764s

• [SLOW TEST:65.899 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:04:49.453: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 13:04:50.857: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jul 31 13:04:50.887: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul 31 13:04:57.054: INFO: Creating deployment "test-rolling-update-deployment"
Jul 31 13:04:57.962: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jul 31 13:04:57.981: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jul 31 13:05:00.356: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jul 31 13:05:00.560: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700175098, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700175098, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700175098, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700175097, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-57b6b5bb54\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 13:05:02.853: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700175098, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700175098, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700175098, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700175097, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-57b6b5bb54\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 13:05:05.654: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 31 13:05:05.766: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-7267,SelfLink:/apis/apps/v1/namespaces/deployment-7267/deployments/test-rolling-update-deployment,UID:cc3b3eb9-b393-11e9-a303-6acf1189be78,ResourceVersion:24380,Generation:1,CreationTimestamp:2019-07-31 13:04:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-07-31 13:04:58 +0000 UTC 2019-07-31 13:04:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-07-31 13:05:04 +0000 UTC 2019-07-31 13:04:57 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-57b6b5bb54" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jul 31 13:05:05.777: INFO: New ReplicaSet "test-rolling-update-deployment-57b6b5bb54" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54,GenerateName:,Namespace:deployment-7267,SelfLink:/apis/apps/v1/namespaces/deployment-7267/replicasets/test-rolling-update-deployment-57b6b5bb54,UID:cc3f6b09-b393-11e9-a303-6acf1189be78,ResourceVersion:24371,Generation:1,CreationTimestamp:2019-07-31 13:04:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment cc3b3eb9-b393-11e9-a303-6acf1189be78 0xc000993897 0xc000993898}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul 31 13:05:05.777: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jul 31 13:05:05.777: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-7267,SelfLink:/apis/apps/v1/namespaces/deployment-7267/replicasets/test-rolling-update-controller,UID:c800f628-b393-11e9-a303-6acf1189be78,ResourceVersion:24379,Generation:2,CreationTimestamp:2019-07-31 13:04:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment cc3b3eb9-b393-11e9-a303-6acf1189be78 0xc0009932c7 0xc0009932c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 31 13:05:05.859: INFO: Pod "test-rolling-update-deployment-57b6b5bb54-5plxx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54-5plxx,GenerateName:test-rolling-update-deployment-57b6b5bb54-,Namespace:deployment-7267,SelfLink:/api/v1/namespaces/deployment-7267/pods/test-rolling-update-deployment-57b6b5bb54-5plxx,UID:cc409f19-b393-11e9-a303-6acf1189be78,ResourceVersion:24370,Generation:0,CreationTimestamp:2019-07-31 13:04:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-57b6b5bb54 cc3f6b09-b393-11e9-a303-6acf1189be78 0xc002e11737 0xc002e11738}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-s5c8j {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s5c8j,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-s5c8j true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e118a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e118c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:04:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:05:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:05:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:04:58 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.11,PodIP:172.25.1.138,StartTime:2019-07-31 13:04:58 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-07-31 13:05:02 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://bde6c0b4a852508c80d357a0a0d24d59ac9cbc3eef061d8e9dc8e31e487ba25e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:05:05.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7267" for this suite.
Jul 31 13:05:12.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:05:17.474: INFO: namespace deployment-7267 deletion completed in 11.601428261s

• [SLOW TEST:28.020 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:05:17.474: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Jul 31 13:05:19.154: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-228106623 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:05:20.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2086" for this suite.
Jul 31 13:05:26.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:05:34.590: INFO: namespace kubectl-2086 deletion completed in 13.935752007s

• [SLOW TEST:17.116 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:05:34.590: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 13:05:36.695: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jul 31 13:05:37.154: INFO: Number of nodes with available pods: 0
Jul 31 13:05:37.154: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jul 31 13:05:37.294: INFO: Number of nodes with available pods: 0
Jul 31 13:05:37.294: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:05:38.460: INFO: Number of nodes with available pods: 0
Jul 31 13:05:38.460: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:05:39.661: INFO: Number of nodes with available pods: 0
Jul 31 13:05:39.661: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:05:40.359: INFO: Number of nodes with available pods: 0
Jul 31 13:05:40.359: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:05:41.653: INFO: Number of nodes with available pods: 0
Jul 31 13:05:41.653: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:05:42.453: INFO: Number of nodes with available pods: 0
Jul 31 13:05:42.453: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:05:43.753: INFO: Number of nodes with available pods: 0
Jul 31 13:05:43.753: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:05:44.553: INFO: Number of nodes with available pods: 1
Jul 31 13:05:44.553: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jul 31 13:05:46.256: INFO: Number of nodes with available pods: 0
Jul 31 13:05:46.256: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jul 31 13:05:46.332: INFO: Number of nodes with available pods: 0
Jul 31 13:05:46.332: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:05:47.953: INFO: Number of nodes with available pods: 0
Jul 31 13:05:47.953: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:05:49.053: INFO: Number of nodes with available pods: 0
Jul 31 13:05:49.053: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:05:49.553: INFO: Number of nodes with available pods: 0
Jul 31 13:05:49.553: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:05:50.771: INFO: Number of nodes with available pods: 0
Jul 31 13:05:50.771: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:05:52.656: INFO: Number of nodes with available pods: 0
Jul 31 13:05:52.656: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:05:53.340: INFO: Number of nodes with available pods: 0
Jul 31 13:05:53.340: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:05:54.366: INFO: Number of nodes with available pods: 0
Jul 31 13:05:54.366: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:05:56.053: INFO: Number of nodes with available pods: 1
Jul 31 13:05:56.053: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9460, will wait for the garbage collector to delete the pods
Jul 31 13:05:57.428: INFO: Deleting DaemonSet.extensions daemon-set took: 17.13954ms
Jul 31 13:05:58.428: INFO: Terminating DaemonSet.extensions daemon-set pods took: 1.000404998s
Jul 31 13:06:03.153: INFO: Number of nodes with available pods: 0
Jul 31 13:06:03.154: INFO: Number of running nodes: 0, number of available pods: 0
Jul 31 13:06:03.553: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9460/daemonsets","resourceVersion":"24634"},"items":null}

Jul 31 13:06:03.753: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9460/pods","resourceVersion":"24634"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:06:05.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9460" for this suite.
Jul 31 13:06:12.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:06:19.453: INFO: namespace daemonsets-9460 deletion completed in 13.999650521s

• [SLOW TEST:44.863 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:06:19.454: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 13:06:20.309: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fd4aa996-b393-11e9-82b5-da5bffca47b9" in namespace "downward-api-6844" to be "success or failure"
Jul 31 13:06:20.328: INFO: Pod "downwardapi-volume-fd4aa996-b393-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 18.76367ms
Jul 31 13:06:22.337: INFO: Pod "downwardapi-volume-fd4aa996-b393-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027473619s
Jul 31 13:06:24.344: INFO: Pod "downwardapi-volume-fd4aa996-b393-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034969817s
Jul 31 13:06:26.455: INFO: Pod "downwardapi-volume-fd4aa996-b393-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.145733099s
STEP: Saw pod success
Jul 31 13:06:26.455: INFO: Pod "downwardapi-volume-fd4aa996-b393-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:06:27.053: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod downwardapi-volume-fd4aa996-b393-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 13:06:29.155: INFO: Waiting for pod downwardapi-volume-fd4aa996-b393-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:06:30.260: INFO: Pod downwardapi-volume-fd4aa996-b393-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:06:30.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6844" for this suite.
Jul 31 13:06:36.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:06:38.614: INFO: namespace downward-api-6844 deletion completed in 8.341677224s

• [SLOW TEST:19.160 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:06:38.614: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-087836ce-b394-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume configMaps
Jul 31 13:06:39.481: INFO: Waiting up to 5m0s for pod "pod-configmaps-087c5f0d-b394-11e9-82b5-da5bffca47b9" in namespace "configmap-4470" to be "success or failure"
Jul 31 13:06:39.499: INFO: Pod "pod-configmaps-087c5f0d-b394-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.758227ms
Jul 31 13:06:42.958: INFO: Pod "pod-configmaps-087c5f0d-b394-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.476349262s
Jul 31 13:06:45.253: INFO: Pod "pod-configmaps-087c5f0d-b394-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 5.771132254s
STEP: Saw pod success
Jul 31 13:06:45.253: INFO: Pod "pod-configmaps-087c5f0d-b394-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:06:45.536: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-configmaps-087c5f0d-b394-11e9-82b5-da5bffca47b9 container configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 13:06:45.646: INFO: Waiting for pod pod-configmaps-087c5f0d-b394-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:06:46.357: INFO: Pod pod-configmaps-087c5f0d-b394-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:06:46.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4470" for this suite.
Jul 31 13:06:52.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:06:56.983: INFO: namespace configmap-4470 deletion completed in 10.613512697s

• [SLOW TEST:18.369 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:06:56.983: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jul 31 13:06:57.482: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8160,SelfLink:/api/v1/namespaces/watch-8160/configmaps/e2e-watch-test-label-changed,UID:13573688-b394-11e9-a303-6acf1189be78,ResourceVersion:24862,Generation:0,CreationTimestamp:2019-07-31 13:06:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 31 13:06:57.482: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8160,SelfLink:/api/v1/namespaces/watch-8160/configmaps/e2e-watch-test-label-changed,UID:13573688-b394-11e9-a303-6acf1189be78,ResourceVersion:24863,Generation:0,CreationTimestamp:2019-07-31 13:06:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jul 31 13:06:57.482: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8160,SelfLink:/api/v1/namespaces/watch-8160/configmaps/e2e-watch-test-label-changed,UID:13573688-b394-11e9-a303-6acf1189be78,ResourceVersion:24864,Generation:0,CreationTimestamp:2019-07-31 13:06:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jul 31 13:07:09.753: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8160,SelfLink:/api/v1/namespaces/watch-8160/configmaps/e2e-watch-test-label-changed,UID:13573688-b394-11e9-a303-6acf1189be78,ResourceVersion:24893,Generation:0,CreationTimestamp:2019-07-31 13:06:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 31 13:07:09.753: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8160,SelfLink:/api/v1/namespaces/watch-8160/configmaps/e2e-watch-test-label-changed,UID:13573688-b394-11e9-a303-6acf1189be78,ResourceVersion:24898,Generation:0,CreationTimestamp:2019-07-31 13:06:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jul 31 13:07:09.753: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8160,SelfLink:/api/v1/namespaces/watch-8160/configmaps/e2e-watch-test-label-changed,UID:13573688-b394-11e9-a303-6acf1189be78,ResourceVersion:24899,Generation:0,CreationTimestamp:2019-07-31 13:06:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:07:09.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8160" for this suite.
Jul 31 13:07:16.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:07:20.175: INFO: namespace watch-8160 deletion completed in 10.221392977s

• [SLOW TEST:23.192 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:07:20.176: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-9094
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 31 13:07:20.753: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 31 13:07:50.474: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.25.0.43:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9094 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 13:07:50.474: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 13:07:54.924: INFO: Found all expected endpoints: [netserver-0]
Jul 31 13:07:55.057: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.25.1.141:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9094 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 13:07:55.057: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
Jul 31 13:08:01.253: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:08:01.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9094" for this suite.
Jul 31 13:08:23.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:08:29.477: INFO: namespace pod-network-test-9094 deletion completed in 28.108518184s

• [SLOW TEST:69.302 seconds]
[sig-network] Networking
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:08:29.478: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 13:08:30.103: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4aab19f9-b394-11e9-82b5-da5bffca47b9" in namespace "projected-5120" to be "success or failure"
Jul 31 13:08:30.120: INFO: Pod "downwardapi-volume-4aab19f9-b394-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.938021ms
Jul 31 13:08:32.653: INFO: Pod "downwardapi-volume-4aab19f9-b394-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.549399079s
Jul 31 13:08:37.958: INFO: Pod "downwardapi-volume-4aab19f9-b394-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.854665327s
STEP: Saw pod success
Jul 31 13:08:37.958: INFO: Pod "downwardapi-volume-4aab19f9-b394-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:08:37.965: INFO: Trying to get logs from node loving-darwin-5cd5b754c-ckbcc pod downwardapi-volume-4aab19f9-b394-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 13:08:39.754: INFO: Waiting for pod downwardapi-volume-4aab19f9-b394-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:08:39.959: INFO: Pod downwardapi-volume-4aab19f9-b394-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:08:39.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5120" for this suite.
Jul 31 13:08:46.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:08:53.316: INFO: namespace projected-5120 deletion completed in 13.342623962s

• [SLOW TEST:23.838 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:08:53.317: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Jul 31 13:08:59.572: INFO: Pod pod-hostip-589bbd56-b394-11e9-82b5-da5bffca47b9 has hostIP: 192.168.1.11
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:08:59.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4825" for this suite.
Jul 31 13:09:21.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:09:30.270: INFO: namespace pods-4825 deletion completed in 30.67605576s

• [SLOW TEST:36.953 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:09:30.270: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Jul 31 13:09:31.763: INFO: Waiting up to 5m0s for pod "client-containers-6f0b239d-b394-11e9-82b5-da5bffca47b9" in namespace "containers-9781" to be "success or failure"
Jul 31 13:09:32.153: INFO: Pod "client-containers-6f0b239d-b394-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 389.213455ms
Jul 31 13:09:34.456: INFO: Pod "client-containers-6f0b239d-b394-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.692228898s
Jul 31 13:09:36.471: INFO: Pod "client-containers-6f0b239d-b394-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.707749404s
Jul 31 13:09:38.953: INFO: Pod "client-containers-6f0b239d-b394-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.189508987s
STEP: Saw pod success
Jul 31 13:09:38.953: INFO: Pod "client-containers-6f0b239d-b394-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:09:39.157: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod client-containers-6f0b239d-b394-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 13:09:40.094: INFO: Waiting for pod client-containers-6f0b239d-b394-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:09:40.108: INFO: Pod client-containers-6f0b239d-b394-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:09:40.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9781" for this suite.
Jul 31 13:09:47.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:09:52.958: INFO: namespace containers-9781 deletion completed in 12.836804763s

• [SLOW TEST:22.688 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:09:52.958: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-7cb8e6a8-b394-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume configMaps
Jul 31 13:09:55.353: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7cd758e5-b394-11e9-82b5-da5bffca47b9" in namespace "projected-6218" to be "success or failure"
Jul 31 13:09:55.753: INFO: Pod "pod-projected-configmaps-7cd758e5-b394-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 400.103216ms
Jul 31 13:09:57.953: INFO: Pod "pod-projected-configmaps-7cd758e5-b394-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.600000712s
Jul 31 13:09:59.977: INFO: Pod "pod-projected-configmaps-7cd758e5-b394-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.62401329s
STEP: Saw pod success
Jul 31 13:09:59.977: INFO: Pod "pod-projected-configmaps-7cd758e5-b394-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:09:59.991: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-projected-configmaps-7cd758e5-b394-11e9-82b5-da5bffca47b9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 13:10:02.359: INFO: Waiting for pod pod-projected-configmaps-7cd758e5-b394-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:10:02.853: INFO: Pod pod-projected-configmaps-7cd758e5-b394-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:10:02.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6218" for this suite.
Jul 31 13:10:09.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:10:14.327: INFO: namespace projected-6218 deletion completed in 10.573064702s

• [SLOW TEST:21.369 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:10:14.328: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jul 31 13:10:22.981: INFO: Successfully updated pod "labelsupdate894d12b8-b394-11e9-82b5-da5bffca47b9"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:10:26.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5004" for this suite.
Jul 31 13:10:49.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:10:53.453: INFO: namespace downward-api-5004 deletion completed in 26.69956905s

• [SLOW TEST:39.125 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:10:53.456: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-wbg8
STEP: Creating a pod to test atomic-volume-subpath
Jul 31 13:10:54.668: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-wbg8" in namespace "subpath-4780" to be "success or failure"
Jul 31 13:10:54.680: INFO: Pod "pod-subpath-test-configmap-wbg8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.416311ms
Jul 31 13:10:56.853: INFO: Pod "pod-subpath-test-configmap-wbg8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.184961867s
Jul 31 13:10:58.959: INFO: Pod "pod-subpath-test-configmap-wbg8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.29048549s
Jul 31 13:11:01.357: INFO: Pod "pod-subpath-test-configmap-wbg8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.689231795s
Jul 31 13:11:03.568: INFO: Pod "pod-subpath-test-configmap-wbg8": Phase="Running", Reason="", readiness=true. Elapsed: 8.899628002s
Jul 31 13:11:05.953: INFO: Pod "pod-subpath-test-configmap-wbg8": Phase="Running", Reason="", readiness=true. Elapsed: 11.284544459s
Jul 31 13:11:08.353: INFO: Pod "pod-subpath-test-configmap-wbg8": Phase="Running", Reason="", readiness=true. Elapsed: 13.684543505s
Jul 31 13:11:10.653: INFO: Pod "pod-subpath-test-configmap-wbg8": Phase="Running", Reason="", readiness=true. Elapsed: 15.984551735s
Jul 31 13:11:12.953: INFO: Pod "pod-subpath-test-configmap-wbg8": Phase="Running", Reason="", readiness=true. Elapsed: 18.284296418s
Jul 31 13:11:14.962: INFO: Pod "pod-subpath-test-configmap-wbg8": Phase="Running", Reason="", readiness=true. Elapsed: 20.294167939s
Jul 31 13:11:17.057: INFO: Pod "pod-subpath-test-configmap-wbg8": Phase="Running", Reason="", readiness=true. Elapsed: 22.38850392s
Jul 31 13:11:19.364: INFO: Pod "pod-subpath-test-configmap-wbg8": Phase="Running", Reason="", readiness=true. Elapsed: 24.696156121s
Jul 31 13:11:21.554: INFO: Pod "pod-subpath-test-configmap-wbg8": Phase="Running", Reason="", readiness=true. Elapsed: 26.886056018s
Jul 31 13:11:23.757: INFO: Pod "pod-subpath-test-configmap-wbg8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 29.089143514s
STEP: Saw pod success
Jul 31 13:11:23.757: INFO: Pod "pod-subpath-test-configmap-wbg8" satisfied condition "success or failure"
Jul 31 13:11:23.764: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-subpath-test-configmap-wbg8 container test-container-subpath-configmap-wbg8: <nil>
STEP: delete the pod
Jul 31 13:11:27.477: INFO: Waiting for pod pod-subpath-test-configmap-wbg8 to disappear
Jul 31 13:11:27.486: INFO: Pod pod-subpath-test-configmap-wbg8 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-wbg8
Jul 31 13:11:27.486: INFO: Deleting pod "pod-subpath-test-configmap-wbg8" in namespace "subpath-4780"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:11:27.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4780" for this suite.
Jul 31 13:11:34.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:11:37.662: INFO: namespace subpath-4780 deletion completed in 10.148154393s

• [SLOW TEST:44.206 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:11:37.664: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Jul 31 13:11:37.786: INFO: Waiting up to 5m0s for pod "client-containers-ba8afbf2-b394-11e9-82b5-da5bffca47b9" in namespace "containers-1915" to be "success or failure"
Jul 31 13:11:37.801: INFO: Pod "client-containers-ba8afbf2-b394-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.874859ms
Jul 31 13:11:40.269: INFO: Pod "client-containers-ba8afbf2-b394-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.482493438s
Jul 31 13:11:42.653: INFO: Pod "client-containers-ba8afbf2-b394-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.866492251s
Jul 31 13:11:44.867: INFO: Pod "client-containers-ba8afbf2-b394-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.080919273s
Jul 31 13:11:47.557: INFO: Pod "client-containers-ba8afbf2-b394-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 9.770627792s
STEP: Saw pod success
Jul 31 13:11:47.557: INFO: Pod "client-containers-ba8afbf2-b394-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:11:47.573: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod client-containers-ba8afbf2-b394-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 13:11:48.923: INFO: Waiting for pod client-containers-ba8afbf2-b394-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:11:48.929: INFO: Pod client-containers-ba8afbf2-b394-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:11:48.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1915" for this suite.
Jul 31 13:11:55.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:12:03.163: INFO: namespace containers-1915 deletion completed in 14.221998206s

• [SLOW TEST:25.499 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:12:03.164: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jul 31 13:12:17.658: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 31 13:12:17.854: INFO: Pod pod-with-prestop-http-hook still exists
Jul 31 13:12:19.859: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 31 13:12:19.871: INFO: Pod pod-with-prestop-http-hook still exists
Jul 31 13:12:21.855: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 31 13:12:22.753: INFO: Pod pod-with-prestop-http-hook still exists
Jul 31 13:12:23.854: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 31 13:12:24.153: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:12:24.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1377" for this suite.
Jul 31 13:12:48.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:12:54.425: INFO: namespace container-lifecycle-hook-1377 deletion completed in 29.171589036s

• [SLOW TEST:51.261 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:12:54.425: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jul 31 13:13:02.852: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-e86ee875-b394-11e9-82b5-da5bffca47b9,GenerateName:,Namespace:events-1672,SelfLink:/api/v1/namespaces/events-1672/pods/send-events-e86ee875-b394-11e9-82b5-da5bffca47b9,UID:e86f752b-b394-11e9-a303-6acf1189be78,ResourceVersion:26204,Generation:0,CreationTimestamp:2019-07-31 13:12:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 762512378,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lssfd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lssfd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-lssfd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa1a20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa1a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:12:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:13:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:13:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:12:54 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.11,PodIP:172.25.1.151,StartTime:2019-07-31 13:12:54 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-07-31 13:13:00 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://bc59f77c9e159d3745cec61afa76626045c560d01dfeb68d3d14d3e0ce34fa71}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jul 31 13:13:04.957: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jul 31 13:13:06.968: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:13:06.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1672" for this suite.
Jul 31 13:13:45.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:13:51.293: INFO: namespace events-1672 deletion completed in 44.280243043s

• [SLOW TEST:56.870 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:13:51.296: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1524
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 31 13:13:51.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-8741'
Jul 31 13:13:54.315: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 31 13:13:54.315: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1529
Jul 31 13:13:56.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 delete deployment e2e-test-nginx-deployment --namespace=kubectl-8741'
Jul 31 13:13:57.241: INFO: stderr: ""
Jul 31 13:13:57.241: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:13:57.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8741" for this suite.
Jul 31 13:14:04.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:14:13.057: INFO: namespace kubectl-8741 deletion completed in 15.793976228s

• [SLOW TEST:21.761 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:14:13.058: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Jul 31 13:14:14.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 create -f - --namespace=kubectl-9016'
Jul 31 13:14:15.945: INFO: stderr: ""
Jul 31 13:14:15.945: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 31 13:14:15.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9016'
Jul 31 13:14:17.147: INFO: stderr: ""
Jul 31 13:14:17.147: INFO: stdout: "update-demo-nautilus-lgnkv update-demo-nautilus-sxhrn "
Jul 31 13:14:17.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-lgnkv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9016'
Jul 31 13:14:17.671: INFO: stderr: ""
Jul 31 13:14:17.671: INFO: stdout: ""
Jul 31 13:14:17.671: INFO: update-demo-nautilus-lgnkv is created but not running
Jul 31 13:14:22.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9016'
Jul 31 13:14:23.366: INFO: stderr: ""
Jul 31 13:14:23.366: INFO: stdout: "update-demo-nautilus-lgnkv update-demo-nautilus-sxhrn "
Jul 31 13:14:23.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-lgnkv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9016'
Jul 31 13:14:24.336: INFO: stderr: ""
Jul 31 13:14:24.336: INFO: stdout: "true"
Jul 31 13:14:24.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-lgnkv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9016'
Jul 31 13:14:25.025: INFO: stderr: ""
Jul 31 13:14:25.025: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 13:14:25.025: INFO: validating pod update-demo-nautilus-lgnkv
Jul 31 13:14:25.252: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 13:14:25.252: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 13:14:25.252: INFO: update-demo-nautilus-lgnkv is verified up and running
Jul 31 13:14:25.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-sxhrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9016'
Jul 31 13:14:25.661: INFO: stderr: ""
Jul 31 13:14:25.661: INFO: stdout: "true"
Jul 31 13:14:25.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-nautilus-sxhrn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9016'
Jul 31 13:14:25.749: INFO: stderr: ""
Jul 31 13:14:25.749: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 13:14:25.749: INFO: validating pod update-demo-nautilus-sxhrn
Jul 31 13:14:26.953: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 13:14:26.953: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 13:14:26.953: INFO: update-demo-nautilus-sxhrn is verified up and running
STEP: rolling-update to new replication controller
Jul 31 13:14:26.955: INFO: scanned /root for discovery docs: <nil>
Jul 31 13:14:26.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-9016'
Jul 31 13:14:54.823: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jul 31 13:14:54.823: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 31 13:14:54.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9016'
Jul 31 13:14:54.916: INFO: stderr: ""
Jul 31 13:14:54.916: INFO: stdout: "update-demo-kitten-9pqnr update-demo-kitten-l5bgt "
Jul 31 13:14:54.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-kitten-9pqnr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9016'
Jul 31 13:14:55.924: INFO: stderr: ""
Jul 31 13:14:55.924: INFO: stdout: "true"
Jul 31 13:14:55.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-kitten-9pqnr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9016'
Jul 31 13:14:56.928: INFO: stderr: ""
Jul 31 13:14:56.928: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jul 31 13:14:56.928: INFO: validating pod update-demo-kitten-9pqnr
Jul 31 13:14:57.553: INFO: got data: {
  "image": "kitten.jpg"
}

Jul 31 13:14:57.553: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jul 31 13:14:57.553: INFO: update-demo-kitten-9pqnr is verified up and running
Jul 31 13:14:57.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-kitten-l5bgt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9016'
Jul 31 13:14:58.054: INFO: stderr: ""
Jul 31 13:14:58.054: INFO: stdout: "true"
Jul 31 13:14:58.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods update-demo-kitten-l5bgt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9016'
Jul 31 13:14:58.156: INFO: stderr: ""
Jul 31 13:14:58.156: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jul 31 13:14:58.156: INFO: validating pod update-demo-kitten-l5bgt
Jul 31 13:14:59.053: INFO: got data: {
  "image": "kitten.jpg"
}

Jul 31 13:14:59.053: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jul 31 13:14:59.053: INFO: update-demo-kitten-l5bgt is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:14:59.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9016" for this suite.
Jul 31 13:15:22.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:15:29.753: INFO: namespace kubectl-9016 deletion completed in 30.594012217s

• [SLOW TEST:76.697 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:15:29.755: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jul 31 13:15:39.605: INFO: Pod name wrapped-volume-race-4aa897ea-b395-11e9-82b5-da5bffca47b9: Found 1 pods out of 5
Jul 31 13:15:44.854: INFO: Pod name wrapped-volume-race-4aa897ea-b395-11e9-82b5-da5bffca47b9: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4aa897ea-b395-11e9-82b5-da5bffca47b9 in namespace emptydir-wrapper-1656, will wait for the garbage collector to delete the pods
Jul 31 13:16:08.852: INFO: Deleting ReplicationController wrapped-volume-race-4aa897ea-b395-11e9-82b5-da5bffca47b9 took: 592.859782ms
Jul 31 13:16:08.953: INFO: Terminating ReplicationController wrapped-volume-race-4aa897ea-b395-11e9-82b5-da5bffca47b9 pods took: 100.25663ms
STEP: Creating RC which spawns configmap-volume pods
Jul 31 13:16:49.956: INFO: Pod name wrapped-volume-race-73f65a36-b395-11e9-82b5-da5bffca47b9: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-73f65a36-b395-11e9-82b5-da5bffca47b9 in namespace emptydir-wrapper-1656, will wait for the garbage collector to delete the pods
Jul 31 13:17:14.153: INFO: Deleting ReplicationController wrapped-volume-race-73f65a36-b395-11e9-82b5-da5bffca47b9 took: 250.057193ms
Jul 31 13:17:14.553: INFO: Terminating ReplicationController wrapped-volume-race-73f65a36-b395-11e9-82b5-da5bffca47b9 pods took: 400.288222ms
STEP: Creating RC which spawns configmap-volume pods
Jul 31 13:17:59.286: INFO: Pod name wrapped-volume-race-9dce2590-b395-11e9-82b5-da5bffca47b9: Found 0 pods out of 5
Jul 31 13:18:04.755: INFO: Pod name wrapped-volume-race-9dce2590-b395-11e9-82b5-da5bffca47b9: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9dce2590-b395-11e9-82b5-da5bffca47b9 in namespace emptydir-wrapper-1656, will wait for the garbage collector to delete the pods
Jul 31 13:18:26.952: INFO: Deleting ReplicationController wrapped-volume-race-9dce2590-b395-11e9-82b5-da5bffca47b9 took: 149.167404ms
Jul 31 13:18:27.453: INFO: Terminating ReplicationController wrapped-volume-race-9dce2590-b395-11e9-82b5-da5bffca47b9 pods took: 500.355462ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:19:17.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1656" for this suite.
Jul 31 13:19:26.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:19:33.899: INFO: namespace emptydir-wrapper-1656 deletion completed in 16.0025267s

• [SLOW TEST:244.144 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:19:33.900: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-d8a3dd9b-b395-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume secrets
Jul 31 13:19:38.375: INFO: Waiting up to 5m0s for pod "pod-secrets-d8ff118d-b395-11e9-82b5-da5bffca47b9" in namespace "secrets-3636" to be "success or failure"
Jul 31 13:19:39.363: INFO: Pod "pod-secrets-d8ff118d-b395-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 987.846064ms
Jul 31 13:19:41.665: INFO: Pod "pod-secrets-d8ff118d-b395-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.289206201s
Jul 31 13:19:44.053: INFO: Pod "pod-secrets-d8ff118d-b395-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.677171411s
Jul 31 13:19:47.157: INFO: Pod "pod-secrets-d8ff118d-b395-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.781596082s
STEP: Saw pod success
Jul 31 13:19:47.157: INFO: Pod "pod-secrets-d8ff118d-b395-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:19:47.169: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-secrets-d8ff118d-b395-11e9-82b5-da5bffca47b9 container secret-volume-test: <nil>
STEP: delete the pod
Jul 31 13:19:47.784: INFO: Waiting for pod pod-secrets-d8ff118d-b395-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:19:47.802: INFO: Pod pod-secrets-d8ff118d-b395-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:19:47.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3636" for this suite.
Jul 31 13:19:54.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:19:57.386: INFO: namespace secrets-3636 deletion completed in 9.425719494s

• [SLOW TEST:23.486 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:19:57.386: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Jul 31 13:19:57.671: INFO: Waiting up to 5m0s for pod "client-containers-e47f7d5a-b395-11e9-82b5-da5bffca47b9" in namespace "containers-4778" to be "success or failure"
Jul 31 13:19:57.686: INFO: Pod "client-containers-e47f7d5a-b395-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.49567ms
Jul 31 13:19:59.857: INFO: Pod "client-containers-e47f7d5a-b395-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.18571131s
Jul 31 13:20:01.959: INFO: Pod "client-containers-e47f7d5a-b395-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.287789682s
Jul 31 13:20:04.257: INFO: Pod "client-containers-e47f7d5a-b395-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.585743141s
STEP: Saw pod success
Jul 31 13:20:04.257: INFO: Pod "client-containers-e47f7d5a-b395-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:20:04.264: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod client-containers-e47f7d5a-b395-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 13:20:05.153: INFO: Waiting for pod client-containers-e47f7d5a-b395-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:20:05.161: INFO: Pod client-containers-e47f7d5a-b395-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:20:05.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4778" for this suite.
Jul 31 13:20:11.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:20:15.570: INFO: namespace containers-4778 deletion completed in 10.115309392s

• [SLOW TEST:18.185 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:20:15.571: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-4497
Jul 31 13:20:26.753: INFO: Started pod liveness-http in namespace container-probe-4497
STEP: checking the pod's current state and verifying that restartCount is present
Jul 31 13:20:27.057: INFO: Initial restart count of pod liveness-http is 0
Jul 31 13:20:39.162: INFO: Restart count of pod container-probe-4497/liveness-http is now 1 (12.104976866s elapsed)
Jul 31 13:20:56.652: INFO: Restart count of pod container-probe-4497/liveness-http is now 2 (29.595245468s elapsed)
Jul 31 13:21:18.452: INFO: Restart count of pod container-probe-4497/liveness-http is now 3 (51.394978382s elapsed)
Jul 31 13:21:38.554: INFO: Restart count of pod container-probe-4497/liveness-http is now 4 (1m11.496840958s elapsed)
Jul 31 13:22:46.860: INFO: Restart count of pod container-probe-4497/liveness-http is now 5 (2m19.802397143s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:22:47.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4497" for this suite.
Jul 31 13:22:55.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:23:00.558: INFO: namespace container-probe-4497 deletion completed in 12.10296152s

• [SLOW TEST:164.987 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:23:00.558: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-51b0f48a-b396-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume secrets
Jul 31 13:23:02.152: INFO: Waiting up to 5m0s for pod "pod-secrets-5249885b-b396-11e9-82b5-da5bffca47b9" in namespace "secrets-1244" to be "success or failure"
Jul 31 13:23:02.359: INFO: Pod "pod-secrets-5249885b-b396-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 206.445193ms
Jul 31 13:23:05.067: INFO: Pod "pod-secrets-5249885b-b396-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.914462996s
Jul 31 13:23:07.664: INFO: Pod "pod-secrets-5249885b-b396-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 5.511984814s
STEP: Saw pod success
Jul 31 13:23:07.665: INFO: Pod "pod-secrets-5249885b-b396-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:23:08.053: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-secrets-5249885b-b396-11e9-82b5-da5bffca47b9 container secret-volume-test: <nil>
STEP: delete the pod
Jul 31 13:23:09.852: INFO: Waiting for pod pod-secrets-5249885b-b396-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:23:10.263: INFO: Pod pod-secrets-5249885b-b396-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:23:10.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1244" for this suite.
Jul 31 13:23:16.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:23:19.480: INFO: namespace secrets-1244 deletion completed in 9.205131404s
STEP: Destroying namespace "secret-namespace-7644" for this suite.
Jul 31 13:23:26.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:23:31.494: INFO: namespace secret-namespace-7644 deletion completed in 12.014073917s

• [SLOW TEST:30.936 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:23:31.495: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul 31 13:23:33.353: INFO: Number of nodes with available pods: 0
Jul 31 13:23:33.353: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:23:34.765: INFO: Number of nodes with available pods: 0
Jul 31 13:23:34.765: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:23:35.761: INFO: Number of nodes with available pods: 0
Jul 31 13:23:35.761: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:23:36.779: INFO: Number of nodes with available pods: 0
Jul 31 13:23:36.779: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:23:37.566: INFO: Number of nodes with available pods: 0
Jul 31 13:23:37.566: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:23:38.684: INFO: Number of nodes with available pods: 0
Jul 31 13:23:38.684: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:23:39.377: INFO: Number of nodes with available pods: 0
Jul 31 13:23:39.378: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:23:40.472: INFO: Number of nodes with available pods: 0
Jul 31 13:23:40.472: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:23:42.253: INFO: Number of nodes with available pods: 1
Jul 31 13:23:42.253: INFO: Node loving-darwin-5cd5b754c-qfktz is running more than one daemon pod
Jul 31 13:23:43.753: INFO: Number of nodes with available pods: 2
Jul 31 13:23:43.753: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jul 31 13:23:45.155: INFO: Number of nodes with available pods: 1
Jul 31 13:23:45.155: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:23:47.553: INFO: Number of nodes with available pods: 1
Jul 31 13:23:47.553: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:23:48.468: INFO: Number of nodes with available pods: 1
Jul 31 13:23:48.468: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:23:49.272: INFO: Number of nodes with available pods: 1
Jul 31 13:23:49.272: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:23:51.753: INFO: Number of nodes with available pods: 2
Jul 31 13:23:51.753: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2632, will wait for the garbage collector to delete the pods
Jul 31 13:23:51.852: INFO: Deleting DaemonSet.extensions daemon-set took: 30.195469ms
Jul 31 13:23:52.753: INFO: Terminating DaemonSet.extensions daemon-set pods took: 900.905076ms
Jul 31 13:23:57.659: INFO: Number of nodes with available pods: 0
Jul 31 13:23:57.659: INFO: Number of running nodes: 0, number of available pods: 0
Jul 31 13:23:57.665: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2632/daemonsets","resourceVersion":"29284"},"items":null}

Jul 31 13:23:57.673: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2632/pods","resourceVersion":"29284"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:23:58.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2632" for this suite.
Jul 31 13:24:04.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:24:10.671: INFO: namespace daemonsets-2632 deletion completed in 12.317231492s

• [SLOW TEST:39.176 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:24:10.675: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Jul 31 13:24:11.672: INFO: Waiting up to 5m0s for pod "pod-7be45e63-b396-11e9-82b5-da5bffca47b9" in namespace "emptydir-7511" to be "success or failure"
Jul 31 13:24:11.683: INFO: Pod "pod-7be45e63-b396-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.909807ms
Jul 31 13:24:14.462: INFO: Pod "pod-7be45e63-b396-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.789991902s
Jul 31 13:24:16.975: INFO: Pod "pod-7be45e63-b396-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.303154655s
Jul 31 13:24:19.858: INFO: Pod "pod-7be45e63-b396-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.18562624s
Jul 31 13:24:22.457: INFO: Pod "pod-7be45e63-b396-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.785471424s
STEP: Saw pod success
Jul 31 13:24:22.457: INFO: Pod "pod-7be45e63-b396-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:24:22.467: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-7be45e63-b396-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 13:24:23.461: INFO: Waiting for pod pod-7be45e63-b396-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:24:23.483: INFO: Pod pod-7be45e63-b396-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:24:23.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7511" for this suite.
Jul 31 13:24:29.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:24:36.253: INFO: namespace emptydir-7511 deletion completed in 12.761075492s

• [SLOW TEST:25.577 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:24:36.253: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-8b26b3f5-b396-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume secrets
Jul 31 13:24:37.752: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8b44f464-b396-11e9-82b5-da5bffca47b9" in namespace "projected-9076" to be "success or failure"
Jul 31 13:24:37.952: INFO: Pod "pod-projected-secrets-8b44f464-b396-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 199.980022ms
Jul 31 13:24:41.158: INFO: Pod "pod-projected-secrets-8b44f464-b396-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.405544299s
Jul 31 13:24:43.660: INFO: Pod "pod-projected-secrets-8b44f464-b396-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.907810584s
Jul 31 13:24:45.853: INFO: Pod "pod-projected-secrets-8b44f464-b396-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.100355961s
STEP: Saw pod success
Jul 31 13:24:45.853: INFO: Pod "pod-projected-secrets-8b44f464-b396-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:24:46.054: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-projected-secrets-8b44f464-b396-11e9-82b5-da5bffca47b9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 31 13:24:46.692: INFO: Waiting for pod pod-projected-secrets-8b44f464-b396-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:24:46.697: INFO: Pod pod-projected-secrets-8b44f464-b396-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:24:46.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9076" for this suite.
Jul 31 13:24:52.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:25:01.669: INFO: namespace projected-9076 deletion completed in 14.964202895s

• [SLOW TEST:25.416 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:25:01.670: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:25:08.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3450" for this suite.
Jul 31 13:25:48.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:25:57.253: INFO: namespace kubelet-test-3450 deletion completed in 48.798764675s

• [SLOW TEST:55.583 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:25:57.253: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Jul 31 13:25:59.153: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Jul 31 13:26:02.952: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 13:26:05.155: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 13:26:07.070: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 13:26:09.058: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 13:26:11.069: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 13:26:13.157: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 13:26:14.959: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176358, loc:(*time.Location)(0x8a1e140)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 13:26:20.052: INFO: Waited 2.299405107s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:26:30.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-2709" for this suite.
Jul 31 13:26:37.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:26:42.662: INFO: namespace aggregator-2709 deletion completed in 12.564113065s

• [SLOW TEST:45.412 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:26:42.665: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Jul 31 13:26:43.752: INFO: PodSpec: initContainers in spec.initContainers
Jul 31 13:27:37.952: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-d68cc2c9-b396-11e9-82b5-da5bffca47b9", GenerateName:"", Namespace:"init-container-3962", SelfLink:"/api/v1/namespaces/init-container-3962/pods/pod-init-d68cc2c9-b396-11e9-82b5-da5bffca47b9", UID:"d68d8bd5-b396-11e9-a303-6acf1189be78", ResourceVersion:"30113", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63700176403, loc:(*time.Location)(0x8a1e140)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"752625767"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-wtd8h", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002403600), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-wtd8h", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-wtd8h", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-wtd8h", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001279148), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"loving-darwin-5cd5b754c-ckbcc", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002c882a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001279220)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001279290)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001279298), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00127929c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176403, loc:(*time.Location)(0x8a1e140)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176403, loc:(*time.Location)(0x8a1e140)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176403, loc:(*time.Location)(0x8a1e140)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700176403, loc:(*time.Location)(0x8a1e140)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.1.8", PodIP:"172.25.0.64", StartTime:(*v1.Time)(0xc002e28f60), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000ab6930)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000ab6a80)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://056e8981eec1f2493116a8e1c73859d4741daa41fe594a2873717f8840e85cdd"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002e29100), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002e29020), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:27:37.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3962" for this suite.
Jul 31 13:28:01.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:28:06.262: INFO: namespace init-container-3962 deletion completed in 28.108537474s

• [SLOW TEST:83.603 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:28:06.268: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul 31 13:28:08.679: INFO: Waiting up to 5m0s for pod "downward-api-07c6aec9-b397-11e9-82b5-da5bffca47b9" in namespace "downward-api-1640" to be "success or failure"
Jul 31 13:28:08.687: INFO: Pod "downward-api-07c6aec9-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.475009ms
Jul 31 13:28:11.557: INFO: Pod "downward-api-07c6aec9-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.876963282s
Jul 31 13:28:13.758: INFO: Pod "downward-api-07c6aec9-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.078144623s
Jul 31 13:28:15.957: INFO: Pod "downward-api-07c6aec9-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.276772236s
Jul 31 13:28:18.056: INFO: Pod "downward-api-07c6aec9-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.376530083s
Jul 31 13:28:20.453: INFO: Pod "downward-api-07c6aec9-b397-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 11.772621842s
STEP: Saw pod success
Jul 31 13:28:20.453: INFO: Pod "downward-api-07c6aec9-b397-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:28:20.853: INFO: Trying to get logs from node loving-darwin-5cd5b754c-ckbcc pod downward-api-07c6aec9-b397-11e9-82b5-da5bffca47b9 container dapi-container: <nil>
STEP: delete the pod
Jul 31 13:28:21.575: INFO: Waiting for pod downward-api-07c6aec9-b397-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:28:21.592: INFO: Pod downward-api-07c6aec9-b397-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:28:21.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1640" for this suite.
Jul 31 13:28:28.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:28:36.857: INFO: namespace downward-api-1640 deletion completed in 15.256439812s

• [SLOW TEST:30.590 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:28:36.858: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-1a6265da-b397-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume configMaps
Jul 31 13:28:38.552: INFO: Waiting up to 5m0s for pod "pod-configmaps-1a9e49a4-b397-11e9-82b5-da5bffca47b9" in namespace "configmap-7036" to be "success or failure"
Jul 31 13:28:38.852: INFO: Pod "pod-configmaps-1a9e49a4-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 299.825653ms
Jul 31 13:28:41.163: INFO: Pod "pod-configmaps-1a9e49a4-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.610155644s
Jul 31 13:28:43.659: INFO: Pod "pod-configmaps-1a9e49a4-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.106256684s
Jul 31 13:28:45.952: INFO: Pod "pod-configmaps-1a9e49a4-b397-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.399673974s
STEP: Saw pod success
Jul 31 13:28:45.952: INFO: Pod "pod-configmaps-1a9e49a4-b397-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:28:46.260: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-configmaps-1a9e49a4-b397-11e9-82b5-da5bffca47b9 container configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 13:28:46.608: INFO: Waiting for pod pod-configmaps-1a9e49a4-b397-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:28:46.614: INFO: Pod pod-configmaps-1a9e49a4-b397-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:28:46.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7036" for this suite.
Jul 31 13:28:53.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:28:57.272: INFO: namespace configmap-7036 deletion completed in 10.649708349s

• [SLOW TEST:20.415 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:28:57.273: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-26b7db56-b397-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume secrets
Jul 31 13:28:58.286: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-26b98bd1-b397-11e9-82b5-da5bffca47b9" in namespace "projected-40" to be "success or failure"
Jul 31 13:28:58.301: INFO: Pod "pod-projected-secrets-26b98bd1-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 15.110192ms
Jul 31 13:29:00.752: INFO: Pod "pod-projected-secrets-26b98bd1-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.466318577s
Jul 31 13:29:02.952: INFO: Pod "pod-projected-secrets-26b98bd1-b397-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.666610134s
STEP: Saw pod success
Jul 31 13:29:02.952: INFO: Pod "pod-projected-secrets-26b98bd1-b397-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:29:05.853: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-projected-secrets-26b98bd1-b397-11e9-82b5-da5bffca47b9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 31 13:29:07.081: INFO: Waiting for pod pod-projected-secrets-26b98bd1-b397-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:29:07.090: INFO: Pod pod-projected-secrets-26b98bd1-b397-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:29:07.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-40" for this suite.
Jul 31 13:29:13.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:29:18.766: INFO: namespace projected-40 deletion completed in 11.664126066s

• [SLOW TEST:21.493 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:29:18.766: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1177
STEP: creating the pod
Jul 31 13:29:19.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 create -f - --namespace=kubectl-8279'
Jul 31 13:29:22.076: INFO: stderr: ""
Jul 31 13:29:22.076: INFO: stdout: "pod/pause created\n"
Jul 31 13:29:22.076: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jul 31 13:29:22.076: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8279" to be "running and ready"
Jul 31 13:29:22.159: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 83.139043ms
Jul 31 13:29:24.170: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.093457054s
Jul 31 13:29:26.458: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.381855257s
Jul 31 13:29:28.556: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 6.479953034s
Jul 31 13:29:28.556: INFO: Pod "pause" satisfied condition "running and ready"
Jul 31 13:29:28.556: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Jul 31 13:29:28.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 label pods pause testing-label=testing-label-value --namespace=kubectl-8279'
Jul 31 13:29:28.960: INFO: stderr: ""
Jul 31 13:29:28.960: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jul 31 13:29:28.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pod pause -L testing-label --namespace=kubectl-8279'
Jul 31 13:29:29.100: INFO: stderr: ""
Jul 31 13:29:29.100: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          7s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jul 31 13:29:29.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 label pods pause testing-label- --namespace=kubectl-8279'
Jul 31 13:29:30.193: INFO: stderr: ""
Jul 31 13:29:30.193: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jul 31 13:29:30.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pod pause -L testing-label --namespace=kubectl-8279'
Jul 31 13:29:30.318: INFO: stderr: ""
Jul 31 13:29:30.318: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          8s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1184
STEP: using delete to clean up resources
Jul 31 13:29:30.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 delete --grace-period=0 --force -f - --namespace=kubectl-8279'
Jul 31 13:29:31.325: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 13:29:31.325: INFO: stdout: "pod \"pause\" force deleted\n"
Jul 31 13:29:31.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get rc,svc -l name=pause --no-headers --namespace=kubectl-8279'
Jul 31 13:29:32.476: INFO: stderr: "No resources found.\n"
Jul 31 13:29:32.476: INFO: stdout: ""
Jul 31 13:29:32.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -l name=pause --namespace=kubectl-8279 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 31 13:29:33.456: INFO: stderr: ""
Jul 31 13:29:33.456: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:29:33.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8279" for this suite.
Jul 31 13:29:40.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:29:42.875: INFO: namespace kubectl-8279 deletion completed in 8.721449603s

• [SLOW TEST:24.109 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:29:42.875: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jul 31 13:29:43.352: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3522,SelfLink:/api/v1/namespaces/watch-3522/configmaps/e2e-watch-test-watch-closed,UID:416cbac5-b397-11e9-a303-6acf1189be78,ResourceVersion:30598,Generation:0,CreationTimestamp:2019-07-31 13:29:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 31 13:29:43.354: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3522,SelfLink:/api/v1/namespaces/watch-3522/configmaps/e2e-watch-test-watch-closed,UID:416cbac5-b397-11e9-a303-6acf1189be78,ResourceVersion:30599,Generation:0,CreationTimestamp:2019-07-31 13:29:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jul 31 13:29:43.415: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3522,SelfLink:/api/v1/namespaces/watch-3522/configmaps/e2e-watch-test-watch-closed,UID:416cbac5-b397-11e9-a303-6acf1189be78,ResourceVersion:30600,Generation:0,CreationTimestamp:2019-07-31 13:29:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 31 13:29:43.428: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3522,SelfLink:/api/v1/namespaces/watch-3522/configmaps/e2e-watch-test-watch-closed,UID:416cbac5-b397-11e9-a303-6acf1189be78,ResourceVersion:30601,Generation:0,CreationTimestamp:2019-07-31 13:29:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:29:43.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3522" for this suite.
Jul 31 13:29:49.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:29:55.257: INFO: namespace watch-3522 deletion completed in 11.603957519s

• [SLOW TEST:12.381 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:29:55.257: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Jul 31 13:29:56.782: INFO: Waiting up to 5m0s for pod "pod-4998b12c-b397-11e9-82b5-da5bffca47b9" in namespace "emptydir-6031" to be "success or failure"
Jul 31 13:29:56.791: INFO: Pod "pod-4998b12c-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.733271ms
Jul 31 13:29:59.057: INFO: Pod "pod-4998b12c-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.274902569s
Jul 31 13:30:01.652: INFO: Pod "pod-4998b12c-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.869909734s
Jul 31 13:30:03.852: INFO: Pod "pod-4998b12c-b397-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.06986772s
STEP: Saw pod success
Jul 31 13:30:03.852: INFO: Pod "pod-4998b12c-b397-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:30:04.061: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-4998b12c-b397-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 13:30:04.860: INFO: Waiting for pod pod-4998b12c-b397-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:30:05.152: INFO: Pod pod-4998b12c-b397-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:30:05.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6031" for this suite.
Jul 31 13:30:11.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:30:16.198: INFO: namespace emptydir-6031 deletion completed in 10.944304113s

• [SLOW TEST:20.941 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:30:16.198: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-559c6ae7-b397-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume configMaps
Jul 31 13:30:17.153: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-55a064b6-b397-11e9-82b5-da5bffca47b9" in namespace "projected-7840" to be "success or failure"
Jul 31 13:30:17.352: INFO: Pod "pod-projected-configmaps-55a064b6-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 199.673226ms
Jul 31 13:30:19.557: INFO: Pod "pod-projected-configmaps-55a064b6-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.404785123s
Jul 31 13:30:21.859: INFO: Pod "pod-projected-configmaps-55a064b6-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.705945839s
Jul 31 13:30:23.957: INFO: Pod "pod-projected-configmaps-55a064b6-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.80442912s
Jul 31 13:30:27.552: INFO: Pod "pod-projected-configmaps-55a064b6-b397-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.399839284s
STEP: Saw pod success
Jul 31 13:30:27.553: INFO: Pod "pod-projected-configmaps-55a064b6-b397-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:30:27.560: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-projected-configmaps-55a064b6-b397-11e9-82b5-da5bffca47b9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 13:30:28.552: INFO: Waiting for pod pod-projected-configmaps-55a064b6-b397-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:30:28.563: INFO: Pod pod-projected-configmaps-55a064b6-b397-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:30:28.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7840" for this suite.
Jul 31 13:30:35.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:30:40.652: INFO: namespace projected-7840 deletion completed in 12.070884894s

• [SLOW TEST:24.454 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:30:40.653: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-m85b
STEP: Creating a pod to test atomic-volume-subpath
Jul 31 13:30:43.052: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-m85b" in namespace "subpath-9036" to be "success or failure"
Jul 31 13:30:43.252: INFO: Pod "pod-subpath-test-secret-m85b": Phase="Pending", Reason="", readiness=false. Elapsed: 199.876459ms
Jul 31 13:30:45.654: INFO: Pod "pod-subpath-test-secret-m85b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.601829768s
Jul 31 13:30:47.953: INFO: Pod "pod-subpath-test-secret-m85b": Phase="Running", Reason="", readiness=true. Elapsed: 4.900375443s
Jul 31 13:30:50.152: INFO: Pod "pod-subpath-test-secret-m85b": Phase="Running", Reason="", readiness=true. Elapsed: 7.099990089s
Jul 31 13:30:52.752: INFO: Pod "pod-subpath-test-secret-m85b": Phase="Running", Reason="", readiness=true. Elapsed: 9.700152354s
Jul 31 13:30:55.752: INFO: Pod "pod-subpath-test-secret-m85b": Phase="Running", Reason="", readiness=true. Elapsed: 12.699867527s
Jul 31 13:30:58.052: INFO: Pod "pod-subpath-test-secret-m85b": Phase="Running", Reason="", readiness=true. Elapsed: 14.999892455s
Jul 31 13:31:00.158: INFO: Pod "pod-subpath-test-secret-m85b": Phase="Running", Reason="", readiness=true. Elapsed: 17.105369458s
Jul 31 13:31:02.352: INFO: Pod "pod-subpath-test-secret-m85b": Phase="Running", Reason="", readiness=true. Elapsed: 19.300207683s
Jul 31 13:31:04.652: INFO: Pod "pod-subpath-test-secret-m85b": Phase="Running", Reason="", readiness=true. Elapsed: 21.600180232s
Jul 31 13:31:07.260: INFO: Pod "pod-subpath-test-secret-m85b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.208203599s
STEP: Saw pod success
Jul 31 13:31:07.261: INFO: Pod "pod-subpath-test-secret-m85b" satisfied condition "success or failure"
Jul 31 13:31:07.271: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-subpath-test-secret-m85b container test-container-subpath-secret-m85b: <nil>
STEP: delete the pod
Jul 31 13:31:09.291: INFO: Waiting for pod pod-subpath-test-secret-m85b to disappear
Jul 31 13:31:09.297: INFO: Pod pod-subpath-test-secret-m85b no longer exists
STEP: Deleting pod pod-subpath-test-secret-m85b
Jul 31 13:31:09.297: INFO: Deleting pod "pod-subpath-test-secret-m85b" in namespace "subpath-9036"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:31:09.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9036" for this suite.
Jul 31 13:31:18.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:31:22.156: INFO: namespace subpath-9036 deletion completed in 12.400348595s

• [SLOW TEST:41.503 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:31:22.156: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 13:31:22.470: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7cab4549-b397-11e9-82b5-da5bffca47b9" in namespace "projected-9601" to be "success or failure"
Jul 31 13:31:22.486: INFO: Pod "downwardapi-volume-7cab4549-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.02046ms
Jul 31 13:31:24.494: INFO: Pod "downwardapi-volume-7cab4549-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024357077s
Jul 31 13:31:26.957: INFO: Pod "downwardapi-volume-7cab4549-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.486627726s
Jul 31 13:31:30.563: INFO: Pod "downwardapi-volume-7cab4549-b397-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.09342879s
STEP: Saw pod success
Jul 31 13:31:30.563: INFO: Pod "downwardapi-volume-7cab4549-b397-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:31:30.752: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod downwardapi-volume-7cab4549-b397-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 13:31:33.229: INFO: Waiting for pod downwardapi-volume-7cab4549-b397-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:31:33.237: INFO: Pod downwardapi-volume-7cab4549-b397-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:31:33.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9601" for this suite.
Jul 31 13:31:40.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:31:48.756: INFO: namespace projected-9601 deletion completed in 15.508886557s

• [SLOW TEST:26.600 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:31:48.756: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-8cc3e4fa-b397-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume secrets
Jul 31 13:31:49.495: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8cc606c2-b397-11e9-82b5-da5bffca47b9" in namespace "projected-2206" to be "success or failure"
Jul 31 13:31:49.508: INFO: Pod "pod-projected-secrets-8cc606c2-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.728341ms
Jul 31 13:31:51.532: INFO: Pod "pod-projected-secrets-8cc606c2-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036253266s
Jul 31 13:31:54.057: INFO: Pod "pod-projected-secrets-8cc606c2-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.561659135s
Jul 31 13:31:57.058: INFO: Pod "pod-projected-secrets-8cc606c2-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.562692265s
Jul 31 13:31:59.457: INFO: Pod "pod-projected-secrets-8cc606c2-b397-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.961991791s
Jul 31 13:32:02.159: INFO: Pod "pod-projected-secrets-8cc606c2-b397-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.663619374s
STEP: Saw pod success
Jul 31 13:32:02.159: INFO: Pod "pod-projected-secrets-8cc606c2-b397-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:32:02.171: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-projected-secrets-8cc606c2-b397-11e9-82b5-da5bffca47b9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 31 13:32:03.953: INFO: Waiting for pod pod-projected-secrets-8cc606c2-b397-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:32:03.960: INFO: Pod pod-projected-secrets-8cc606c2-b397-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:32:03.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2206" for this suite.
Jul 31 13:32:10.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:32:10.992: INFO: namespace projected-2206 deletion completed in 7.017207092s

• [SLOW TEST:22.236 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:32:10.992: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul 31 13:32:11.289: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 31 13:32:11.322: INFO: Waiting for terminating namespaces to be deleted...
Jul 31 13:32:11.334: INFO: 
Logging pods the kubelet thinks is on node loving-darwin-5cd5b754c-ckbcc before test
Jul 31 13:32:11.392: INFO: sonobuoy-systemd-logs-daemon-set-757d48abf2694112-wkcgw from heptio-sonobuoy started at 2019-07-31 11:39:29 +0000 UTC (2 container statuses recorded)
Jul 31 13:32:11.393: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jul 31 13:32:11.393: INFO: 	Container systemd-logs ready: true, restart count 1
Jul 31 13:32:11.393: INFO: container-linux-update-operator-5d5dcbf65f-mz2zk from kube-system started at 2019-07-31 11:26:05 +0000 UTC (1 container statuses recorded)
Jul 31 13:32:11.393: INFO: 	Container update-operator ready: true, restart count 0
Jul 31 13:32:11.393: INFO: coredns-fdb754d8d-5gt7g from kube-system started at 2019-07-31 11:26:07 +0000 UTC (1 container statuses recorded)
Jul 31 13:32:11.393: INFO: 	Container coredns ready: true, restart count 0
Jul 31 13:32:11.393: INFO: container-linux-update-agent-kbslf from kube-system started at 2019-07-31 11:26:05 +0000 UTC (1 container statuses recorded)
Jul 31 13:32:11.394: INFO: 	Container update-agent ready: true, restart count 1
Jul 31 13:32:11.394: INFO: kube-proxy-jdrnh from kube-system started at 2019-07-31 11:25:02 +0000 UTC (1 container statuses recorded)
Jul 31 13:32:11.394: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 31 13:32:11.394: INFO: canal-tc76d from kube-system started at 2019-07-31 11:25:02 +0000 UTC (2 container statuses recorded)
Jul 31 13:32:11.394: INFO: 	Container calico-node ready: true, restart count 0
Jul 31 13:32:11.394: INFO: 	Container kube-flannel ready: true, restart count 0
Jul 31 13:32:11.394: INFO: node-exporter-pxbl7 from kube-system started at 2019-07-31 11:25:02 +0000 UTC (2 container statuses recorded)
Jul 31 13:32:11.394: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jul 31 13:32:11.394: INFO: 	Container node-exporter ready: true, restart count 0
Jul 31 13:32:11.394: INFO: kubernetes-dashboard-57dcd9448b-f4j5n from kube-system started at 2019-07-31 11:26:05 +0000 UTC (1 container statuses recorded)
Jul 31 13:32:11.406: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Jul 31 13:32:11.407: INFO: openvpn-client-7f7cfb8c68-4jbt5 from kube-system started at 2019-07-31 11:26:05 +0000 UTC (2 container statuses recorded)
Jul 31 13:32:11.408: INFO: 	Container dnat-controller ready: true, restart count 0
Jul 31 13:32:11.408: INFO: 	Container openvpn-client ready: true, restart count 1
Jul 31 13:32:11.408: INFO: coredns-fdb754d8d-b2k94 from kube-system started at 2019-07-31 11:26:06 +0000 UTC (1 container statuses recorded)
Jul 31 13:32:11.408: INFO: 	Container coredns ready: true, restart count 0
Jul 31 13:32:11.409: INFO: node-local-dns-g7bdx from kube-system started at 2019-07-31 11:26:05 +0000 UTC (1 container statuses recorded)
Jul 31 13:32:11.409: INFO: 	Container node-cache ready: true, restart count 0
Jul 31 13:32:11.409: INFO: 
Logging pods the kubelet thinks is on node loving-darwin-5cd5b754c-qfktz before test
Jul 31 13:32:11.684: INFO: node-exporter-2wkxq from kube-system started at 2019-07-31 11:25:32 +0000 UTC (2 container statuses recorded)
Jul 31 13:32:11.684: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jul 31 13:32:11.684: INFO: 	Container node-exporter ready: true, restart count 0
Jul 31 13:32:11.684: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-31 11:39:16 +0000 UTC (1 container statuses recorded)
Jul 31 13:32:11.685: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 31 13:32:11.685: INFO: node-local-dns-mxcjw from kube-system started at 2019-07-31 11:26:35 +0000 UTC (1 container statuses recorded)
Jul 31 13:32:11.685: INFO: 	Container node-cache ready: true, restart count 0
Jul 31 13:32:11.685: INFO: sonobuoy-systemd-logs-daemon-set-757d48abf2694112-9lqfv from heptio-sonobuoy started at 2019-07-31 11:39:29 +0000 UTC (2 container statuses recorded)
Jul 31 13:32:11.685: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jul 31 13:32:11.685: INFO: 	Container systemd-logs ready: true, restart count 1
Jul 31 13:32:11.685: INFO: kube-proxy-wff69 from kube-system started at 2019-07-31 11:25:32 +0000 UTC (1 container statuses recorded)
Jul 31 13:32:11.685: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 31 13:32:11.685: INFO: canal-8rl9b from kube-system started at 2019-07-31 11:25:32 +0000 UTC (2 container statuses recorded)
Jul 31 13:32:11.685: INFO: 	Container calico-node ready: true, restart count 0
Jul 31 13:32:11.685: INFO: 	Container kube-flannel ready: true, restart count 0
Jul 31 13:32:11.685: INFO: container-linux-update-agent-9gt4z from kube-system started at 2019-07-31 11:26:35 +0000 UTC (1 container statuses recorded)
Jul 31 13:32:11.685: INFO: 	Container update-agent ready: true, restart count 0
Jul 31 13:32:11.685: INFO: sonobuoy-e2e-job-bb167d7044544260 from heptio-sonobuoy started at 2019-07-31 11:39:29 +0000 UTC (2 container statuses recorded)
Jul 31 13:32:11.685: INFO: 	Container e2e ready: true, restart count 0
Jul 31 13:32:11.685: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node loving-darwin-5cd5b754c-ckbcc
STEP: verifying the node has the label node loving-darwin-5cd5b754c-qfktz
Jul 31 13:32:11.973: INFO: Pod sonobuoy requesting resource cpu=0m on Node loving-darwin-5cd5b754c-qfktz
Jul 31 13:32:11.973: INFO: Pod sonobuoy-e2e-job-bb167d7044544260 requesting resource cpu=0m on Node loving-darwin-5cd5b754c-qfktz
Jul 31 13:32:11.973: INFO: Pod sonobuoy-systemd-logs-daemon-set-757d48abf2694112-9lqfv requesting resource cpu=0m on Node loving-darwin-5cd5b754c-qfktz
Jul 31 13:32:11.973: INFO: Pod sonobuoy-systemd-logs-daemon-set-757d48abf2694112-wkcgw requesting resource cpu=0m on Node loving-darwin-5cd5b754c-ckbcc
Jul 31 13:32:11.973: INFO: Pod canal-8rl9b requesting resource cpu=350m on Node loving-darwin-5cd5b754c-qfktz
Jul 31 13:32:11.973: INFO: Pod canal-tc76d requesting resource cpu=350m on Node loving-darwin-5cd5b754c-ckbcc
Jul 31 13:32:11.973: INFO: Pod container-linux-update-agent-9gt4z requesting resource cpu=0m on Node loving-darwin-5cd5b754c-qfktz
Jul 31 13:32:11.973: INFO: Pod container-linux-update-agent-kbslf requesting resource cpu=0m on Node loving-darwin-5cd5b754c-ckbcc
Jul 31 13:32:11.973: INFO: Pod container-linux-update-operator-5d5dcbf65f-mz2zk requesting resource cpu=0m on Node loving-darwin-5cd5b754c-ckbcc
Jul 31 13:32:11.973: INFO: Pod coredns-fdb754d8d-5gt7g requesting resource cpu=100m on Node loving-darwin-5cd5b754c-ckbcc
Jul 31 13:32:11.973: INFO: Pod coredns-fdb754d8d-b2k94 requesting resource cpu=100m on Node loving-darwin-5cd5b754c-ckbcc
Jul 31 13:32:11.973: INFO: Pod kube-proxy-jdrnh requesting resource cpu=75m on Node loving-darwin-5cd5b754c-ckbcc
Jul 31 13:32:11.973: INFO: Pod kube-proxy-wff69 requesting resource cpu=75m on Node loving-darwin-5cd5b754c-qfktz
Jul 31 13:32:11.973: INFO: Pod kubernetes-dashboard-57dcd9448b-f4j5n requesting resource cpu=75m on Node loving-darwin-5cd5b754c-ckbcc
Jul 31 13:32:11.973: INFO: Pod node-exporter-2wkxq requesting resource cpu=20m on Node loving-darwin-5cd5b754c-qfktz
Jul 31 13:32:11.973: INFO: Pod node-exporter-pxbl7 requesting resource cpu=20m on Node loving-darwin-5cd5b754c-ckbcc
Jul 31 13:32:11.973: INFO: Pod node-local-dns-g7bdx requesting resource cpu=25m on Node loving-darwin-5cd5b754c-ckbcc
Jul 31 13:32:11.973: INFO: Pod node-local-dns-mxcjw requesting resource cpu=25m on Node loving-darwin-5cd5b754c-qfktz
Jul 31 13:32:11.973: INFO: Pod openvpn-client-7f7cfb8c68-4jbt5 requesting resource cpu=30m on Node loving-darwin-5cd5b754c-ckbcc
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9a2f5d75-b397-11e9-82b5-da5bffca47b9.15b68128a1d2ca7f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9770/filler-pod-9a2f5d75-b397-11e9-82b5-da5bffca47b9 to loving-darwin-5cd5b754c-ckbcc]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9a2f5d75-b397-11e9-82b5-da5bffca47b9.15b68129bde8842a], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9a2f5d75-b397-11e9-82b5-da5bffca47b9.15b6812a0dcf3ff1], Reason = [Created], Message = [Created container filler-pod-9a2f5d75-b397-11e9-82b5-da5bffca47b9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9a2f5d75-b397-11e9-82b5-da5bffca47b9.15b6812a4fb279b9], Reason = [Started], Message = [Started container filler-pod-9a2f5d75-b397-11e9-82b5-da5bffca47b9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9a32dd29-b397-11e9-82b5-da5bffca47b9.15b68128a2f1d409], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9770/filler-pod-9a32dd29-b397-11e9-82b5-da5bffca47b9 to loving-darwin-5cd5b754c-qfktz]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9a32dd29-b397-11e9-82b5-da5bffca47b9.15b681294b1c416e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9a32dd29-b397-11e9-82b5-da5bffca47b9.15b6812979fa7fbe], Reason = [Created], Message = [Created container filler-pod-9a32dd29-b397-11e9-82b5-da5bffca47b9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9a32dd29-b397-11e9-82b5-da5bffca47b9.15b68129eafe194b], Reason = [Started], Message = [Started container filler-pod-9a32dd29-b397-11e9-82b5-da5bffca47b9]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15b6812b038c33ea], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node loving-darwin-5cd5b754c-ckbcc
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node loving-darwin-5cd5b754c-qfktz
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:32:24.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9770" for this suite.
Jul 31 13:32:32.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:32:37.077: INFO: namespace sched-pred-9770 deletion completed in 11.906202745s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:26.085 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:32:37.077: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-4791
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Jul 31 13:32:38.495: INFO: Found 0 stateful pods, waiting for 3
Jul 31 13:32:48.667: INFO: Found 2 stateful pods, waiting for 3
Jul 31 13:32:59.253: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 13:32:59.253: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 13:32:59.253: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Jul 31 13:33:08.853: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 13:33:08.853: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 13:33:08.853: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jul 31 13:33:09.252: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jul 31 13:33:11.291: INFO: Updating stateful set ss2
Jul 31 13:33:11.310: INFO: Waiting for Pod statefulset-4791/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Jul 31 13:33:23.752: INFO: Found 2 stateful pods, waiting for 3
Jul 31 13:33:34.153: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 13:33:34.153: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 13:33:34.153: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Jul 31 13:33:43.955: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 13:33:43.963: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 13:33:43.964: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jul 31 13:33:44.952: INFO: Updating stateful set ss2
Jul 31 13:33:45.165: INFO: Waiting for Pod statefulset-4791/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jul 31 13:33:56.968: INFO: Updating stateful set ss2
Jul 31 13:33:56.984: INFO: Waiting for StatefulSet statefulset-4791/ss2 to complete update
Jul 31 13:33:56.984: INFO: Waiting for Pod statefulset-4791/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jul 31 13:34:07.558: INFO: Waiting for StatefulSet statefulset-4791/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 31 13:34:17.065: INFO: Deleting all statefulset in ns statefulset-4791
Jul 31 13:34:17.077: INFO: Scaling statefulset ss2 to 0
Jul 31 13:34:57.654: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 13:34:57.661: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:34:57.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4791" for this suite.
Jul 31 13:35:06.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:35:07.889: INFO: namespace statefulset-4791 deletion completed in 10.136893589s

• [SLOW TEST:150.812 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:35:07.890: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 13:35:07.985: INFO: Creating deployment "nginx-deployment"
Jul 31 13:35:07.996: INFO: Waiting for observed generation 1
Jul 31 13:35:10.656: INFO: Waiting for all required pods to come up
Jul 31 13:35:10.667: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jul 31 13:35:25.758: INFO: Waiting for deployment "nginx-deployment" to complete
Jul 31 13:35:26.754: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jul 31 13:35:27.255: INFO: Updating deployment nginx-deployment
Jul 31 13:35:27.255: INFO: Waiting for observed generation 2
Jul 31 13:35:27.406: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jul 31 13:35:29.959: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jul 31 13:35:30.657: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jul 31 13:35:30.713: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jul 31 13:35:30.713: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jul 31 13:35:30.728: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jul 31 13:35:31.065: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jul 31 13:35:31.065: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jul 31 13:35:31.092: INFO: Updating deployment nginx-deployment
Jul 31 13:35:31.092: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jul 31 13:35:31.154: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jul 31 13:35:31.459: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 31 13:35:32.363: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-6473,SelfLink:/apis/apps/v1/namespaces/deployment-6473/deployments/nginx-deployment,UID:0318cc9b-b398-11e9-a303-6acf1189be78,ResourceVersion:32298,Generation:3,CreationTimestamp:2019-07-31 13:35:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-07-31 13:35:31 +0000 UTC 2019-07-31 13:35:31 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-07-31 13:35:31 +0000 UTC 2019-07-31 13:35:08 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-b79c9d74d" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Jul 31 13:35:32.656: INFO: New ReplicaSet "nginx-deployment-b79c9d74d" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d,GenerateName:,Namespace:deployment-6473,SelfLink:/apis/apps/v1/namespaces/deployment-6473/replicasets/nginx-deployment-b79c9d74d,UID:0e8679cd-b398-11e9-a303-6acf1189be78,ResourceVersion:32290,Generation:3,CreationTimestamp:2019-07-31 13:35:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0318cc9b-b398-11e9-a303-6acf1189be78 0xc000c2df77 0xc000c2df78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 31 13:35:32.656: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jul 31 13:35:32.656: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5,GenerateName:,Namespace:deployment-6473,SelfLink:/apis/apps/v1/namespaces/deployment-6473/replicasets/nginx-deployment-85db8c99c5,UID:031a5d19-b398-11e9-a303-6acf1189be78,ResourceVersion:32289,Generation:3,CreationTimestamp:2019-07-31 13:35:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0318cc9b-b398-11e9-a303-6acf1189be78 0xc000c2dca7 0xc000c2dca8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jul 31 13:35:32.856: INFO: Pod "nginx-deployment-85db8c99c5-285c2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-285c2,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-285c2,UID:031d4aba-b398-11e9-a303-6acf1189be78,ResourceVersion:32116,Generation:0,CreationTimestamp:2019-07-31 13:35:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc000fa09e7 0xc000fa09e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa0a50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa0a70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.11,PodIP:172.25.1.180,StartTime:2019-07-31 13:35:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-31 13:35:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b8401f7eabe0e83493e2d0d6a4c0eca61da7f9717dc60d0366e83c8145079836}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.857: INFO: Pod "nginx-deployment-85db8c99c5-2q7ll" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-2q7ll,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-2q7ll,UID:0326e461-b398-11e9-a303-6acf1189be78,ResourceVersion:32111,Generation:0,CreationTimestamp:2019-07-31 13:35:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc000fa0b57 0xc000fa0b58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa0bc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa0be0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.11,PodIP:172.25.1.179,StartTime:2019-07-31 13:35:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-31 13:35:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b29cd6faa6ccf285d1f43bb408ae1235bffa42227adbe5600ff82cee6e4b054d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.857: INFO: Pod "nginx-deployment-85db8c99c5-5tz2n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-5tz2n,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-5tz2n,UID:10ea3057-b398-11e9-a303-6acf1189be78,ResourceVersion:32270,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc000fa0cb7 0xc000fa0cb8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa0d20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa0d50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.857: INFO: Pod "nginx-deployment-85db8c99c5-6hl4m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-6hl4m,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-6hl4m,UID:031fd994-b398-11e9-a303-6acf1189be78,ResourceVersion:32140,Generation:0,CreationTimestamp:2019-07-31 13:35:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc000fa0dd0 0xc000fa0dd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa0e30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa0e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.11,PodIP:172.25.1.181,StartTime:2019-07-31 13:35:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-31 13:35:18 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c0f48fa6ce664d1bdcbff09e345361e80ea46b87c1df37880b577359299e8bc7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.857: INFO: Pod "nginx-deployment-85db8c99c5-6kbvb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-6kbvb,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-6kbvb,UID:10e4856b-b398-11e9-a303-6acf1189be78,ResourceVersion:32321,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc000fa0f37 0xc000fa0f38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa0fa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa0fc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.11,PodIP:,StartTime:2019-07-31 13:35:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.857: INFO: Pod "nginx-deployment-85db8c99c5-77ppl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-77ppl,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-77ppl,UID:10ea33da-b398-11e9-a303-6acf1189be78,ResourceVersion:32257,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc000fa1097 0xc000fa1098}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-ckbcc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa1100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa1120}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.857: INFO: Pod "nginx-deployment-85db8c99c5-8fpvc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-8fpvc,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-8fpvc,UID:10f0b459-b398-11e9-a303-6acf1189be78,ResourceVersion:32276,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc000fa11a0 0xc000fa11a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa1200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa1220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.858: INFO: Pod "nginx-deployment-85db8c99c5-f4m8k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-f4m8k,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-f4m8k,UID:10f0d9a3-b398-11e9-a303-6acf1189be78,ResourceVersion:32277,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc000fa12a0 0xc000fa12a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-ckbcc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa1340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa1370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.858: INFO: Pod "nginx-deployment-85db8c99c5-fkxzh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-fkxzh,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-fkxzh,UID:10f0df6d-b398-11e9-a303-6acf1189be78,ResourceVersion:32280,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc000fa1400 0xc000fa1401}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-ckbcc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa1470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa1490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.858: INFO: Pod "nginx-deployment-85db8c99c5-hjrlv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-hjrlv,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-hjrlv,UID:10e00b17-b398-11e9-a303-6acf1189be78,ResourceVersion:32312,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc000fa1510 0xc000fa1511}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-ckbcc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa1570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa1590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:,StartTime:2019-07-31 13:35:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.858: INFO: Pod "nginx-deployment-85db8c99c5-l6bxr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-l6bxr,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-l6bxr,UID:0322baa9-b398-11e9-a303-6acf1189be78,ResourceVersion:32122,Generation:0,CreationTimestamp:2019-07-31 13:35:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc000fa16a0 0xc000fa16a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa1730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa1750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.11,PodIP:172.25.1.183,StartTime:2019-07-31 13:35:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-31 13:35:20 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://89388351a67afd322b7bd015f513a1fa02ef2bdfd51b26ecef36eb0b463b6342}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.858: INFO: Pod "nginx-deployment-85db8c99c5-mhkwz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-mhkwz,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-mhkwz,UID:10ea7c6c-b398-11e9-a303-6acf1189be78,ResourceVersion:32259,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc000fa1827 0xc000fa1828}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-ckbcc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa1890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa18b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.858: INFO: Pod "nginx-deployment-85db8c99c5-ndpgn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-ndpgn,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-ndpgn,UID:10f0e630-b398-11e9-a303-6acf1189be78,ResourceVersion:32281,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc000fa1930 0xc000fa1931}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-ckbcc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa1990} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa19b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.858: INFO: Pod "nginx-deployment-85db8c99c5-nhcd5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-nhcd5,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-nhcd5,UID:0322c8e4-b398-11e9-a303-6acf1189be78,ResourceVersion:32134,Generation:0,CreationTimestamp:2019-07-31 13:35:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc000fa1a30 0xc000fa1a31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-ckbcc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa1a90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa1ab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:172.25.0.72,StartTime:2019-07-31 13:35:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-31 13:35:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://762ad0ea98ad4995f4e1f5a779726b6c82754d1be987a00ea6efdec148089052}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.858: INFO: Pod "nginx-deployment-85db8c99c5-nkzqr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-nkzqr,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-nkzqr,UID:0322ada1-b398-11e9-a303-6acf1189be78,ResourceVersion:32125,Generation:0,CreationTimestamp:2019-07-31 13:35:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc000fa1b80 0xc000fa1b81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-ckbcc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa1be0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa1c00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:172.25.0.70,StartTime:2019-07-31 13:35:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-31 13:35:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://673ea11563fe0984f6960369a852499ea7a65338300856552a8e0cdefa1ae69e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.859: INFO: Pod "nginx-deployment-85db8c99c5-nqmd6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-nqmd6,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-nqmd6,UID:10ea483a-b398-11e9-a303-6acf1189be78,ResourceVersion:32260,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc000fa1cd0 0xc000fa1cd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa1d30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa1d50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.859: INFO: Pod "nginx-deployment-85db8c99c5-t5twz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-t5twz,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-t5twz,UID:10e480e6-b398-11e9-a303-6acf1189be78,ResourceVersion:32243,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc001c76090 0xc001c76091}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-ckbcc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c760f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c76110}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.859: INFO: Pod "nginx-deployment-85db8c99c5-vhhlc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-vhhlc,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-vhhlc,UID:0326d8c5-b398-11e9-a303-6acf1189be78,ResourceVersion:32146,Generation:0,CreationTimestamp:2019-07-31 13:35:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc001c76190 0xc001c76191}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c761f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c76210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.11,PodIP:172.25.1.184,StartTime:2019-07-31 13:35:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-31 13:35:20 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7eaf568bb8f88b6a4860ca047e98b423e9c816b9c983c85ef5829c723b5151d9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.859: INFO: Pod "nginx-deployment-85db8c99c5-z952g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-z952g,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-z952g,UID:10f0f40c-b398-11e9-a303-6acf1189be78,ResourceVersion:32279,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc001c762e7 0xc001c762e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c76350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c76370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.859: INFO: Pod "nginx-deployment-85db8c99c5-zz2dj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-zz2dj,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-85db8c99c5-zz2dj,UID:0326f8eb-b398-11e9-a303-6acf1189be78,ResourceVersion:32137,Generation:0,CreationTimestamp:2019-07-31 13:35:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 031a5d19-b398-11e9-a303-6acf1189be78 0xc001c763f0 0xc001c763f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-ckbcc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c76450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c76470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:172.25.0.69,StartTime:2019-07-31 13:35:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-31 13:35:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7309659f4c4a75207c865a1d6b080bf5722fb9a88bcc3384ff5d1c72403a1aa4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.859: INFO: Pod "nginx-deployment-b79c9d74d-4zjj7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-4zjj7,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-b79c9d74d-4zjj7,UID:10eb2ed2-b398-11e9-a303-6acf1189be78,ResourceVersion:32269,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 0e8679cd-b398-11e9-a303-6acf1189be78 0xc001c76540 0xc001c76541}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c765b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c765d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.859: INFO: Pod "nginx-deployment-b79c9d74d-5w9l7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-5w9l7,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-b79c9d74d-5w9l7,UID:10e76793-b398-11e9-a303-6acf1189be78,ResourceVersion:32251,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 0e8679cd-b398-11e9-a303-6acf1189be78 0xc001c76650 0xc001c76651}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c766c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c766e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.860: INFO: Pod "nginx-deployment-b79c9d74d-6cttg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-6cttg,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-b79c9d74d-6cttg,UID:0e88e82f-b398-11e9-a303-6acf1189be78,ResourceVersion:32211,Generation:0,CreationTimestamp:2019-07-31 13:35:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 0e8679cd-b398-11e9-a303-6acf1189be78 0xc001c76760 0xc001c76761}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c767d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c767f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:27 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.11,PodIP:,StartTime:2019-07-31 13:35:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.860: INFO: Pod "nginx-deployment-b79c9d74d-9fzs2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-9fzs2,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-b79c9d74d-9fzs2,UID:10eb42e0-b398-11e9-a303-6acf1189be78,ResourceVersion:32271,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 0e8679cd-b398-11e9-a303-6acf1189be78 0xc001c768c0 0xc001c768c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-ckbcc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c76930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c76950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.860: INFO: Pod "nginx-deployment-b79c9d74d-gjf8m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-gjf8m,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-b79c9d74d-gjf8m,UID:0eac091a-b398-11e9-a303-6acf1189be78,ResourceVersion:32327,Generation:0,CreationTimestamp:2019-07-31 13:35:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 0e8679cd-b398-11e9-a303-6acf1189be78 0xc001c769e0 0xc001c769e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c76a50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c76a70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:27 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.11,PodIP:172.25.1.185,StartTime:2019-07-31 13:35:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.860: INFO: Pod "nginx-deployment-b79c9d74d-gnl7q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-gnl7q,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-b79c9d74d-gnl7q,UID:0e8c12c2-b398-11e9-a303-6acf1189be78,ResourceVersion:32326,Generation:0,CreationTimestamp:2019-07-31 13:35:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 0e8679cd-b398-11e9-a303-6acf1189be78 0xc001c76b50 0xc001c76b51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c76bc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c76be0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:27 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.11,PodIP:172.25.1.186,StartTime:2019-07-31 13:35:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.860: INFO: Pod "nginx-deployment-b79c9d74d-ln96m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-ln96m,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-b79c9d74d-ln96m,UID:0e8c1723-b398-11e9-a303-6acf1189be78,ResourceVersion:32325,Generation:0,CreationTimestamp:2019-07-31 13:35:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 0e8679cd-b398-11e9-a303-6acf1189be78 0xc001c76cc0 0xc001c76cc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-ckbcc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c76d30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c76d50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:27 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:172.25.0.73,StartTime:2019-07-31 13:35:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.860: INFO: Pod "nginx-deployment-b79c9d74d-mqwtr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-mqwtr,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-b79c9d74d-mqwtr,UID:10e75876-b398-11e9-a303-6acf1189be78,ResourceVersion:32254,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 0e8679cd-b398-11e9-a303-6acf1189be78 0xc001c76e30 0xc001c76e31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c76ea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c76ec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.860: INFO: Pod "nginx-deployment-b79c9d74d-vdq4p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-vdq4p,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-b79c9d74d-vdq4p,UID:10e43fdb-b398-11e9-a303-6acf1189be78,ResourceVersion:32239,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 0e8679cd-b398-11e9-a303-6acf1189be78 0xc001c76f40 0xc001c76f41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-ckbcc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c76fb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c76fd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.860: INFO: Pod "nginx-deployment-b79c9d74d-wwsmh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-wwsmh,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-b79c9d74d-wwsmh,UID:10f0ce26-b398-11e9-a303-6acf1189be78,ResourceVersion:32278,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 0e8679cd-b398-11e9-a303-6acf1189be78 0xc001c77050 0xc001c77051}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-ckbcc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c770c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c770e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.860: INFO: Pod "nginx-deployment-b79c9d74d-z5hl8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-z5hl8,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-b79c9d74d-z5hl8,UID:10eb166a-b398-11e9-a303-6acf1189be78,ResourceVersion:32261,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 0e8679cd-b398-11e9-a303-6acf1189be78 0xc001c77160 0xc001c77161}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-ckbcc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c771e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c77210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.860: INFO: Pod "nginx-deployment-b79c9d74d-zt84g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-zt84g,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-b79c9d74d-zt84g,UID:0eb3f86f-b398-11e9-a303-6acf1189be78,ResourceVersion:32220,Generation:0,CreationTimestamp:2019-07-31 13:35:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 0e8679cd-b398-11e9-a303-6acf1189be78 0xc001c77290 0xc001c77291}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-ckbcc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c77310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c77330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:27 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.8,PodIP:,StartTime:2019-07-31 13:35:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 13:35:32.861: INFO: Pod "nginx-deployment-b79c9d74d-zxbsc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-zxbsc,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6473,SelfLink:/api/v1/namespaces/deployment-6473/pods/nginx-deployment-b79c9d74d-zxbsc,UID:10eb2efc-b398-11e9-a303-6acf1189be78,ResourceVersion:32268,Generation:0,CreationTimestamp:2019-07-31 13:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 0e8679cd-b398-11e9-a303-6acf1189be78 0xc001c77410 0xc001c77411}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jppdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jppdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jppdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c77480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c774a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 13:35:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:35:32.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6473" for this suite.
Jul 31 13:35:42.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:35:50.135: INFO: namespace deployment-6473 deletion completed in 16.977716689s

• [SLOW TEST:42.246 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:35:50.136: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1483
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 31 13:35:52.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4678'
Jul 31 13:35:53.144: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 31 13:35:53.144: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Jul 31 13:35:53.774: INFO: scanned /root for discovery docs: <nil>
Jul 31 13:35:53.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-4678'
Jul 31 13:36:13.661: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jul 31 13:36:13.661: INFO: stdout: "Created e2e-test-nginx-rc-156d65a963405888af5938c5be4906c8\nScaling up e2e-test-nginx-rc-156d65a963405888af5938c5be4906c8 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-156d65a963405888af5938c5be4906c8 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-156d65a963405888af5938c5be4906c8 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jul 31 13:36:13.661: INFO: stdout: "Created e2e-test-nginx-rc-156d65a963405888af5938c5be4906c8\nScaling up e2e-test-nginx-rc-156d65a963405888af5938c5be4906c8 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-156d65a963405888af5938c5be4906c8 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-156d65a963405888af5938c5be4906c8 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jul 31 13:36:13.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4678'
Jul 31 13:36:14.742: INFO: stderr: ""
Jul 31 13:36:14.742: INFO: stdout: "e2e-test-nginx-rc-156d65a963405888af5938c5be4906c8-j8szr "
Jul 31 13:36:14.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods e2e-test-nginx-rc-156d65a963405888af5938c5be4906c8-j8szr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4678'
Jul 31 13:36:15.042: INFO: stderr: ""
Jul 31 13:36:15.042: INFO: stdout: "true"
Jul 31 13:36:15.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 get pods e2e-test-nginx-rc-156d65a963405888af5938c5be4906c8-j8szr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4678'
Jul 31 13:36:15.133: INFO: stderr: ""
Jul 31 13:36:15.133: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Jul 31 13:36:15.133: INFO: e2e-test-nginx-rc-156d65a963405888af5938c5be4906c8-j8szr is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1489
Jul 31 13:36:15.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 delete rc e2e-test-nginx-rc --namespace=kubectl-4678'
Jul 31 13:36:15.841: INFO: stderr: ""
Jul 31 13:36:15.841: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:36:15.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4678" for this suite.
Jul 31 13:36:38.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:36:40.452: INFO: namespace kubectl-4678 deletion completed in 24.498489987s

• [SLOW TEST:50.316 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:36:40.452: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Jul 31 13:36:41.184: INFO: Waiting up to 5m0s for pod "var-expansion-3aa12e25-b398-11e9-82b5-da5bffca47b9" in namespace "var-expansion-4080" to be "success or failure"
Jul 31 13:36:41.652: INFO: Pod "var-expansion-3aa12e25-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 458.699055ms
Jul 31 13:36:44.063: INFO: Pod "var-expansion-3aa12e25-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.869888146s
Jul 31 13:36:46.257: INFO: Pod "var-expansion-3aa12e25-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.063669736s
Jul 31 13:36:48.357: INFO: Pod "var-expansion-3aa12e25-b398-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.164285169s
STEP: Saw pod success
Jul 31 13:36:48.357: INFO: Pod "var-expansion-3aa12e25-b398-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:36:48.366: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod var-expansion-3aa12e25-b398-11e9-82b5-da5bffca47b9 container dapi-container: <nil>
STEP: delete the pod
Jul 31 13:36:49.092: INFO: Waiting for pod var-expansion-3aa12e25-b398-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:36:49.104: INFO: Pod var-expansion-3aa12e25-b398-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:36:49.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4080" for this suite.
Jul 31 13:36:56.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:37:00.252: INFO: namespace var-expansion-4080 deletion completed in 10.998459278s

• [SLOW TEST:19.800 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:37:00.253: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0731 13:37:42.253455      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 31 13:37:42.253: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:37:42.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7548" for this suite.
Jul 31 13:37:50.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:37:55.693: INFO: namespace gc-7548 deletion completed in 13.428064392s

• [SLOW TEST:55.440 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:37:55.693: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Jul 31 13:37:56.314: INFO: Waiting up to 5m0s for pod "downward-api-67684e48-b398-11e9-82b5-da5bffca47b9" in namespace "downward-api-4274" to be "success or failure"
Jul 31 13:37:56.362: INFO: Pod "downward-api-67684e48-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 47.410165ms
Jul 31 13:37:58.368: INFO: Pod "downward-api-67684e48-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054277316s
Jul 31 13:38:00.753: INFO: Pod "downward-api-67684e48-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.438572392s
Jul 31 13:38:03.257: INFO: Pod "downward-api-67684e48-b398-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.942435273s
STEP: Saw pod success
Jul 31 13:38:03.257: INFO: Pod "downward-api-67684e48-b398-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:38:03.264: INFO: Trying to get logs from node loving-darwin-5cd5b754c-ckbcc pod downward-api-67684e48-b398-11e9-82b5-da5bffca47b9 container dapi-container: <nil>
STEP: delete the pod
Jul 31 13:38:03.529: INFO: Waiting for pod downward-api-67684e48-b398-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:38:03.541: INFO: Pod downward-api-67684e48-b398-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:38:03.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4274" for this suite.
Jul 31 13:38:10.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:38:11.791: INFO: namespace downward-api-4274 deletion completed in 7.937857124s

• [SLOW TEST:16.099 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:38:11.792: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jul 31 13:38:13.056: INFO: Waiting up to 5m0s for pod "pod-70f5c3f1-b398-11e9-82b5-da5bffca47b9" in namespace "emptydir-8038" to be "success or failure"
Jul 31 13:38:13.064: INFO: Pod "pod-70f5c3f1-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.988173ms
Jul 31 13:38:15.174: INFO: Pod "pod-70f5c3f1-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.117598456s
Jul 31 13:38:17.257: INFO: Pod "pod-70f5c3f1-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.200107083s
Jul 31 13:38:19.552: INFO: Pod "pod-70f5c3f1-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.495584186s
Jul 31 13:38:22.059: INFO: Pod "pod-70f5c3f1-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.002749331s
Jul 31 13:38:24.352: INFO: Pod "pod-70f5c3f1-b398-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 11.295499328s
STEP: Saw pod success
Jul 31 13:38:24.352: INFO: Pod "pod-70f5c3f1-b398-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:38:24.360: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-70f5c3f1-b398-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 13:38:25.579: INFO: Waiting for pod pod-70f5c3f1-b398-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:38:25.585: INFO: Pod pod-70f5c3f1-b398-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:38:25.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8038" for this suite.
Jul 31 13:38:32.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:38:34.665: INFO: namespace emptydir-8038 deletion completed in 9.062613474s

• [SLOW TEST:22.874 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:38:34.665: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5277.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5277.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5277.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5277.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5277.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5277.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul 31 13:38:49.152: INFO: DNS probes using dns-5277/dns-test-7e54689b-b398-11e9-82b5-da5bffca47b9 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:38:49.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5277" for this suite.
Jul 31 13:38:55.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:38:57.784: INFO: namespace dns-5277 deletion completed in 8.22654058s

• [SLOW TEST:23.119 seconds]
[sig-network] DNS
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:38:57.785: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 13:38:58.860: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:39:07.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7261" for this suite.
Jul 31 13:40:06.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:40:12.766: INFO: namespace pods-7261 deletion completed in 1m4.612732725s

• [SLOW TEST:74.981 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:40:12.766: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 13:40:14.693: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jul 31 13:40:14.868: INFO: Number of nodes with available pods: 0
Jul 31 13:40:14.868: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:40:16.377: INFO: Number of nodes with available pods: 0
Jul 31 13:40:16.377: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:40:17.198: INFO: Number of nodes with available pods: 0
Jul 31 13:40:17.223: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:40:20.653: INFO: Number of nodes with available pods: 0
Jul 31 13:40:20.653: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:40:21.370: INFO: Number of nodes with available pods: 0
Jul 31 13:40:21.370: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:40:22.253: INFO: Number of nodes with available pods: 0
Jul 31 13:40:22.253: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:40:22.966: INFO: Number of nodes with available pods: 0
Jul 31 13:40:22.966: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 13:40:23.883: INFO: Number of nodes with available pods: 2
Jul 31 13:40:23.883: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jul 31 13:40:24.186: INFO: Wrong image for pod: daemon-set-79svh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:24.186: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:25.552: INFO: Wrong image for pod: daemon-set-79svh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:25.552: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:26.453: INFO: Wrong image for pod: daemon-set-79svh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:26.453: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:27.853: INFO: Wrong image for pod: daemon-set-79svh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:27.853: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:28.952: INFO: Wrong image for pod: daemon-set-79svh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:28.952: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:29.209: INFO: Wrong image for pod: daemon-set-79svh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:29.209: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:31.152: INFO: Wrong image for pod: daemon-set-79svh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:31.152: INFO: Pod daemon-set-79svh is not available
Jul 31 13:40:31.152: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:31.453: INFO: Wrong image for pod: daemon-set-79svh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:31.453: INFO: Pod daemon-set-79svh is not available
Jul 31 13:40:31.453: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:33.352: INFO: Pod daemon-set-7wtpn is not available
Jul 31 13:40:33.353: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:34.353: INFO: Pod daemon-set-7wtpn is not available
Jul 31 13:40:34.353: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:35.553: INFO: Pod daemon-set-7wtpn is not available
Jul 31 13:40:35.553: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:36.214: INFO: Pod daemon-set-7wtpn is not available
Jul 31 13:40:36.214: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:37.352: INFO: Pod daemon-set-7wtpn is not available
Jul 31 13:40:37.352: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:38.353: INFO: Pod daemon-set-7wtpn is not available
Jul 31 13:40:38.353: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:39.213: INFO: Pod daemon-set-7wtpn is not available
Jul 31 13:40:39.213: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:40.459: INFO: Pod daemon-set-7wtpn is not available
Jul 31 13:40:40.459: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:42.053: INFO: Pod daemon-set-7wtpn is not available
Jul 31 13:40:42.053: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:44.209: INFO: Pod daemon-set-7wtpn is not available
Jul 31 13:40:44.209: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:45.456: INFO: Pod daemon-set-7wtpn is not available
Jul 31 13:40:45.457: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:46.653: INFO: Pod daemon-set-7wtpn is not available
Jul 31 13:40:46.653: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:47.853: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:53.880: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:55.953: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:56.657: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:40:59.653: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:41:01.457: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:41:01.457: INFO: Pod daemon-set-kd9zm is not available
Jul 31 13:41:02.212: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:41:02.212: INFO: Pod daemon-set-kd9zm is not available
Jul 31 13:41:03.457: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:41:03.457: INFO: Pod daemon-set-kd9zm is not available
Jul 31 13:41:04.352: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:41:04.352: INFO: Pod daemon-set-kd9zm is not available
Jul 31 13:41:05.452: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:41:05.452: INFO: Pod daemon-set-kd9zm is not available
Jul 31 13:41:06.352: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:41:06.353: INFO: Pod daemon-set-kd9zm is not available
Jul 31 13:41:07.353: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:41:07.353: INFO: Pod daemon-set-kd9zm is not available
Jul 31 13:41:08.559: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:41:08.559: INFO: Pod daemon-set-kd9zm is not available
Jul 31 13:41:09.552: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:41:09.552: INFO: Pod daemon-set-kd9zm is not available
Jul 31 13:41:11.354: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:41:11.354: INFO: Pod daemon-set-kd9zm is not available
Jul 31 13:41:12.208: INFO: Wrong image for pod: daemon-set-kd9zm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jul 31 13:41:12.208: INFO: Pod daemon-set-kd9zm is not available
Jul 31 13:41:13.670: INFO: Pod daemon-set-4trrf is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Jul 31 13:41:14.464: INFO: Number of nodes with available pods: 1
Jul 31 13:41:14.464: INFO: Node loving-darwin-5cd5b754c-qfktz is running more than one daemon pod
Jul 31 13:41:16.053: INFO: Number of nodes with available pods: 1
Jul 31 13:41:16.053: INFO: Node loving-darwin-5cd5b754c-qfktz is running more than one daemon pod
Jul 31 13:41:16.500: INFO: Number of nodes with available pods: 1
Jul 31 13:41:16.500: INFO: Node loving-darwin-5cd5b754c-qfktz is running more than one daemon pod
Jul 31 13:41:18.071: INFO: Number of nodes with available pods: 1
Jul 31 13:41:18.071: INFO: Node loving-darwin-5cd5b754c-qfktz is running more than one daemon pod
Jul 31 13:41:18.773: INFO: Number of nodes with available pods: 1
Jul 31 13:41:18.773: INFO: Node loving-darwin-5cd5b754c-qfktz is running more than one daemon pod
Jul 31 13:41:20.653: INFO: Number of nodes with available pods: 2
Jul 31 13:41:20.653: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2586, will wait for the garbage collector to delete the pods
Jul 31 13:41:20.950: INFO: Deleting DaemonSet.extensions daemon-set took: 13.222692ms
Jul 31 13:41:21.352: INFO: Terminating DaemonSet.extensions daemon-set pods took: 401.734812ms
Jul 31 13:41:29.652: INFO: Number of nodes with available pods: 0
Jul 31 13:41:29.652: INFO: Number of running nodes: 0, number of available pods: 0
Jul 31 13:41:29.852: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2586/daemonsets","resourceVersion":"34059"},"items":null}

Jul 31 13:41:30.052: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2586/pods","resourceVersion":"34059"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:41:30.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2586" for this suite.
Jul 31 13:41:36.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:41:41.472: INFO: namespace daemonsets-2586 deletion completed in 10.698976531s

• [SLOW TEST:88.706 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:41:41.472: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-edaad0fb-b398-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume secrets
Jul 31 13:41:41.854: INFO: Waiting up to 5m0s for pod "pod-secrets-edada76a-b398-11e9-82b5-da5bffca47b9" in namespace "secrets-6534" to be "success or failure"
Jul 31 13:41:41.892: INFO: Pod "pod-secrets-edada76a-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 38.130363ms
Jul 31 13:41:43.915: INFO: Pod "pod-secrets-edada76a-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061803287s
Jul 31 13:41:46.071: INFO: Pod "pod-secrets-edada76a-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.217399544s
Jul 31 13:41:48.252: INFO: Pod "pod-secrets-edada76a-b398-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.398885804s
STEP: Saw pod success
Jul 31 13:41:48.253: INFO: Pod "pod-secrets-edada76a-b398-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:41:48.452: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-secrets-edada76a-b398-11e9-82b5-da5bffca47b9 container secret-volume-test: <nil>
STEP: delete the pod
Jul 31 13:41:49.553: INFO: Waiting for pod pod-secrets-edada76a-b398-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:41:49.853: INFO: Pod pod-secrets-edada76a-b398-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:41:49.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6534" for this suite.
Jul 31 13:41:56.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:41:58.875: INFO: namespace secrets-6534 deletion completed in 8.817362144s

• [SLOW TEST:17.403 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:41:58.878: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 13:41:59.597: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f86c7fc7-b398-11e9-82b5-da5bffca47b9" in namespace "projected-9983" to be "success or failure"
Jul 31 13:41:59.607: INFO: Pod "downwardapi-volume-f86c7fc7-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.562808ms
Jul 31 13:42:02.261: INFO: Pod "downwardapi-volume-f86c7fc7-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.660417803s
Jul 31 13:42:04.857: INFO: Pod "downwardapi-volume-f86c7fc7-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.256123926s
Jul 31 13:42:07.239: INFO: Pod "downwardapi-volume-f86c7fc7-b398-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.63893315s
Jul 31 13:42:09.247: INFO: Pod "downwardapi-volume-f86c7fc7-b398-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 9.646617937s
STEP: Saw pod success
Jul 31 13:42:09.247: INFO: Pod "downwardapi-volume-f86c7fc7-b398-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:42:09.353: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod downwardapi-volume-f86c7fc7-b398-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 13:42:10.453: INFO: Waiting for pod downwardapi-volume-f86c7fc7-b398-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:42:10.675: INFO: Pod downwardapi-volume-f86c7fc7-b398-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:42:10.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9983" for this suite.
Jul 31 13:42:18.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:42:26.798: INFO: namespace projected-9983 deletion completed in 15.744242177s

• [SLOW TEST:27.921 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:42:26.799: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 13:42:27.728: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0930c108-b399-11e9-82b5-da5bffca47b9" in namespace "downward-api-9815" to be "success or failure"
Jul 31 13:42:27.749: INFO: Pod "downwardapi-volume-0930c108-b399-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 20.438382ms
Jul 31 13:42:29.953: INFO: Pod "downwardapi-volume-0930c108-b399-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.224419845s
Jul 31 13:42:32.057: INFO: Pod "downwardapi-volume-0930c108-b399-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.32830829s
Jul 31 13:42:34.963: INFO: Pod "downwardapi-volume-0930c108-b399-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.235043365s
STEP: Saw pod success
Jul 31 13:42:34.963: INFO: Pod "downwardapi-volume-0930c108-b399-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:42:34.983: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod downwardapi-volume-0930c108-b399-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 13:42:35.606: INFO: Waiting for pod downwardapi-volume-0930c108-b399-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:42:35.665: INFO: Pod downwardapi-volume-0930c108-b399-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:42:35.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9815" for this suite.
Jul 31 13:42:41.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:42:47.687: INFO: namespace downward-api-9815 deletion completed in 11.923143658s

• [SLOW TEST:20.888 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:42:47.687: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-155372c9-b399-11e9-82b5-da5bffca47b9
STEP: Creating secret with name s-test-opt-upd-1553730f-b399-11e9-82b5-da5bffca47b9
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-155372c9-b399-11e9-82b5-da5bffca47b9
STEP: Updating secret s-test-opt-upd-1553730f-b399-11e9-82b5-da5bffca47b9
STEP: Creating secret with name s-test-opt-create-15537323-b399-11e9-82b5-da5bffca47b9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:44:18.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2835" for this suite.
Jul 31 13:44:42.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:44:47.385: INFO: namespace projected-2835 deletion completed in 28.821425828s

• [SLOW TEST:119.698 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:44:47.386: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-5d42f4fb-b399-11e9-82b5-da5bffca47b9
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-5d42f4fb-b399-11e9-82b5-da5bffca47b9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:46:20.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-297" for this suite.
Jul 31 13:46:44.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:46:52.553: INFO: namespace configmap-297 deletion completed in 32.198233827s

• [SLOW TEST:125.167 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:46:52.554: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Jul 31 13:46:52.686: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9023" to be "success or failure"
Jul 31 13:46:52.699: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 13.767067ms
Jul 31 13:46:54.857: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.171637171s
Jul 31 13:46:57.360: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.674201502s
Jul 31 13:46:59.853: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.167572191s
STEP: Saw pod success
Jul 31 13:46:59.853: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jul 31 13:47:00.253: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jul 31 13:47:01.254: INFO: Waiting for pod pod-host-path-test to disappear
Jul 31 13:47:01.954: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:47:01.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-9023" for this suite.
Jul 31 13:47:09.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:47:13.095: INFO: namespace hostpath-9023 deletion completed in 10.510135167s

• [SLOW TEST:20.542 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:47:13.095: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jul 31 13:47:23.830: INFO: Successfully updated pod "pod-update-b3ce9258-b399-11e9-82b5-da5bffca47b9"
STEP: verifying the updated pod is in kubernetes
Jul 31 13:47:25.053: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:47:25.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6738" for this suite.
Jul 31 13:47:48.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:47:50.087: INFO: namespace pods-6738 deletion completed in 24.332246539s

• [SLOW TEST:36.992 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:47:50.088: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:47:59.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-968" for this suite.
Jul 31 13:48:05.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:48:15.454: INFO: namespace namespaces-968 deletion completed in 16.19864482s
STEP: Destroying namespace "nsdeletetest-5336" for this suite.
Jul 31 13:48:15.653: INFO: Namespace nsdeletetest-5336 was already deleted
STEP: Destroying namespace "nsdeletetest-261" for this suite.
Jul 31 13:48:23.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:48:27.628: INFO: namespace nsdeletetest-261 deletion completed in 11.97492104s

• [SLOW TEST:37.540 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:48:27.629: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-2602
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-2602
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2602
Jul 31 13:48:28.240: INFO: Found 0 stateful pods, waiting for 1
Jul 31 13:48:38.357: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jul 31 13:48:38.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 13:48:42.558: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 31 13:48:42.558: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 13:48:42.558: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 13:48:42.565: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jul 31 13:48:52.573: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 31 13:48:52.573: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 13:48:53.058: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999576s
Jul 31 13:48:54.070: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.541401281s
Jul 31 13:48:55.158: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.529742298s
Jul 31 13:48:56.258: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.441581755s
Jul 31 13:48:57.654: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.341220013s
Jul 31 13:48:59.254: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.943904277s
Jul 31 13:49:00.263: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.345226149s
Jul 31 13:49:01.358: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.336464535s
Jul 31 13:49:02.467: INFO: Verifying statefulset ss doesn't scale past 1 for another 240.980859ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2602
Jul 31 13:49:04.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:49:08.760: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 31 13:49:08.760: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 31 13:49:08.760: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 31 13:49:08.858: INFO: Found 2 stateful pods, waiting for 3
Jul 31 13:49:18.959: INFO: Found 2 stateful pods, waiting for 3
Jul 31 13:49:29.055: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 13:49:29.055: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 13:49:29.055: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jul 31 13:49:29.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 13:49:35.661: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 31 13:49:35.661: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 13:49:35.661: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 13:49:35.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 13:49:39.870: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 31 13:49:39.870: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 13:49:39.870: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 13:49:39.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 13:49:46.255: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jul 31 13:49:46.255: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 13:49:46.255: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 13:49:46.255: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 13:49:46.572: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 31 13:49:46.572: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul 31 13:49:46.572: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul 31 13:49:48.759: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999566s
Jul 31 13:49:50.253: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.694198411s
Jul 31 13:49:52.154: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.199880757s
Jul 31 13:49:53.186: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.29662122s
Jul 31 13:49:54.854: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.266728334s
Jul 31 13:49:56.455: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.599624997s
Jul 31 13:49:57.465: INFO: Verifying statefulset ss doesn't scale past 3 for another 997.315778ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2602
Jul 31 13:49:58.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:50:03.823: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 31 13:50:03.823: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 31 13:50:03.823: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 31 13:50:03.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:50:08.656: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jul 31 13:50:08.656: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 31 13:50:08.656: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 31 13:50:08.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:50:11.656: INFO: rc: 1
Jul 31 13:50:11.656: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server: 
 [] <nil> 0xc0017ac6c0 exit status 1 <nil> <nil> true [0xc002e36000 0xc002e36038 0xc002e36050] [0xc002e36000 0xc002e36038 0xc002e36050] [0xc002e36030 0xc002e36048] [0x9c00a0 0x9c00a0] 0xc0010744e0 <nil>}:
Command stdout:

stderr:
Error from server: 

error:
exit status 1

Jul 31 13:50:21.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:50:22.524: INFO: rc: 1
Jul 31 13:50:22.524: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001f9c480 exit status 1 <nil> <nil> true [0xc002d940a8 0xc002d940d0 0xc002d94108] [0xc002d940a8 0xc002d940d0 0xc002d94108] [0xc002d940c8 0xc002d940f8] [0x9c00a0 0x9c00a0] 0xc001cc2ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:50:32.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:50:33.666: INFO: rc: 1
Jul 31 13:50:33.667: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002e38060 exit status 1 <nil> <nil> true [0xc000527488 0xc0005274d0 0xc000527538] [0xc000527488 0xc0005274d0 0xc000527538] [0xc0005274b0 0xc000527508] [0x9c00a0 0x9c00a0] 0xc002731bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:50:43.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:50:44.855: INFO: rc: 1
Jul 31 13:50:44.855: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0017acbd0 exit status 1 <nil> <nil> true [0xc002e36068 0xc002e360a8 0xc002e360c0] [0xc002e36068 0xc002e360a8 0xc002e360c0] [0xc002e36090 0xc002e360b8] [0x9c00a0 0x9c00a0] 0xc001074a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:50:54.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:50:54.978: INFO: rc: 1
Jul 31 13:50:54.978: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00169e480 exit status 1 <nil> <nil> true [0xc00018e060 0xc000010a50 0xc000010e28] [0xc00018e060 0xc000010a50 0xc000010e28] [0xc000010960 0xc000010d98] [0x9c00a0 0x9c00a0] 0xc000188720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:51:04.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:51:05.764: INFO: rc: 1
Jul 31 13:51:05.764: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00169e870 exit status 1 <nil> <nil> true [0xc000011728 0xc0000cc958 0xc0000cd0c8] [0xc000011728 0xc0000cc958 0xc0000cd0c8] [0xc000011df8 0xc0000cce70] [0x9c00a0 0x9c00a0] 0xc002ce2600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:51:15.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:51:15.936: INFO: rc: 1
Jul 31 13:51:15.936: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d302a0 exit status 1 <nil> <nil> true [0xc001bba0a0 0xc001bba128 0xc001bba188] [0xc001bba0a0 0xc001bba128 0xc001bba188] [0xc001bba120 0xc001bba178] [0x9c00a0 0x9c00a0] 0xc0024be420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:51:25.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:51:26.862: INFO: rc: 1
Jul 31 13:51:26.862: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00268a330 exit status 1 <nil> <nil> true [0xc002e36000 0xc002e36038 0xc002e36050] [0xc002e36000 0xc002e36038 0xc002e36050] [0xc002e36030 0xc002e36048] [0x9c00a0 0x9c00a0] 0xc00304ec00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:51:36.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:51:37.002: INFO: rc: 1
Jul 31 13:51:37.002: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00268a9c0 exit status 1 <nil> <nil> true [0xc002e36068 0xc002e360a8 0xc002e360c0] [0xc002e36068 0xc002e360a8 0xc002e360c0] [0xc002e36090 0xc002e360b8] [0x9c00a0 0x9c00a0] 0xc00304f140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:51:47.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:51:47.828: INFO: rc: 1
Jul 31 13:51:47.828: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00268ad80 exit status 1 <nil> <nil> true [0xc002e360c8 0xc002e360e0 0xc002e360f8] [0xc002e360c8 0xc002e360e0 0xc002e360f8] [0xc002e360d8 0xc002e360f0] [0x9c00a0 0x9c00a0] 0xc00304f740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:51:57.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:51:58.433: INFO: rc: 1
Jul 31 13:51:58.433: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d30660 exit status 1 <nil> <nil> true [0xc001bba1a0 0xc001bba298 0xc001bba460] [0xc001bba1a0 0xc001bba298 0xc001bba460] [0xc001bba220 0xc001bba3b8] [0x9c00a0 0x9c00a0] 0xc0024be8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:52:08.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:52:09.156: INFO: rc: 1
Jul 31 13:52:09.156: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00268b110 exit status 1 <nil> <nil> true [0xc002e36100 0xc002e36118 0xc002e36130] [0xc002e36100 0xc002e36118 0xc002e36130] [0xc002e36110 0xc002e36128] [0x9c00a0 0x9c00a0] 0xc00304fc80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:52:19.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:52:19.556: INFO: rc: 1
Jul 31 13:52:19.556: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021ea7b0 exit status 1 <nil> <nil> true [0xc000526bf8 0xc000526d48 0xc000526da0] [0xc000526bf8 0xc000526d48 0xc000526da0] [0xc000526d40 0xc000526d80] [0x9c00a0 0x9c00a0] 0xc002e18720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:52:29.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:52:30.034: INFO: rc: 1
Jul 31 13:52:30.034: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00169ec00 exit status 1 <nil> <nil> true [0xc0000cd100 0xc0000cd758 0xc0000cda58] [0xc0000cd100 0xc0000cd758 0xc0000cda58] [0xc0000cd650 0xc0000cd918] [0x9c00a0 0x9c00a0] 0xc002ce3440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:52:40.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:52:40.783: INFO: rc: 1
Jul 31 13:52:40.783: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00169f0e0 exit status 1 <nil> <nil> true [0xc0000cdc18 0xc0000cdf38 0xc002d94030] [0xc0000cdc18 0xc0000cdf38 0xc002d94030] [0xc0000cdec8 0xc002d94008] [0x9c00a0 0x9c00a0] 0xc0010741e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:52:50.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:52:51.823: INFO: rc: 1
Jul 31 13:52:51.823: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00169f470 exit status 1 <nil> <nil> true [0xc002d94038 0xc002d94068 0xc002d94088] [0xc002d94038 0xc002d94068 0xc002d94088] [0xc002d94060 0xc002d94078] [0x9c00a0 0x9c00a0] 0xc001074780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:53:01.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:53:01.982: INFO: rc: 1
Jul 31 13:53:01.982: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d302d0 exit status 1 <nil> <nil> true [0xc0000ccaa0 0xc0000cd100 0xc0000cd758] [0xc0000ccaa0 0xc0000cd100 0xc0000cd758] [0xc0000cd0c8 0xc0000cd650] [0x9c00a0 0x9c00a0] 0xc002ce25a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:53:11.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:53:12.832: INFO: rc: 1
Jul 31 13:53:12.832: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00169e4b0 exit status 1 <nil> <nil> true [0xc0000107f8 0xc000010d48 0xc000011728] [0xc0000107f8 0xc000010d48 0xc000011728] [0xc000010a50 0xc000010e28] [0x9c00a0 0x9c00a0] 0xc002377ec0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:53:22.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:53:23.290: INFO: rc: 1
Jul 31 13:53:23.290: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d306c0 exit status 1 <nil> <nil> true [0xc0000cd808 0xc0000cdc18 0xc0000cdf38] [0xc0000cd808 0xc0000cdc18 0xc0000cdf38] [0xc0000cda58 0xc0000cdec8] [0x9c00a0 0x9c00a0] 0xc002ce3320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:53:33.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:53:33.924: INFO: rc: 1
Jul 31 13:53:33.924: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d30a20 exit status 1 <nil> <nil> true [0xc00018e000 0xc001bba118 0xc001bba140] [0xc00018e000 0xc001bba118 0xc001bba140] [0xc001bba0a0 0xc001bba128] [0x9c00a0 0x9c00a0] 0xc001074120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:53:43.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:53:44.070: INFO: rc: 1
Jul 31 13:53:44.070: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d30db0 exit status 1 <nil> <nil> true [0xc001bba178 0xc001bba1d8 0xc001bba318] [0xc001bba178 0xc001bba1d8 0xc001bba318] [0xc001bba1a0 0xc001bba298] [0x9c00a0 0x9c00a0] 0xc001074720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:53:54.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:53:54.666: INFO: rc: 1
Jul 31 13:53:54.666: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d31290 exit status 1 <nil> <nil> true [0xc001bba3b8 0xc001bba538 0xc001bba5d0] [0xc001bba3b8 0xc001bba538 0xc001bba5d0] [0xc001bba4e8 0xc001bba5a0] [0x9c00a0 0x9c00a0] 0xc001074c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:54:04.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:54:04.928: INFO: rc: 1
Jul 31 13:54:04.928: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d315f0 exit status 1 <nil> <nil> true [0xc001bba620 0xc001bba6f8 0xc001bba870] [0xc001bba620 0xc001bba6f8 0xc001bba870] [0xc001bba6d0 0xc001bba820] [0x9c00a0 0x9c00a0] 0xc001075320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:54:14.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:54:16.437: INFO: rc: 1
Jul 31 13:54:16.437: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d31980 exit status 1 <nil> <nil> true [0xc001bba8b0 0xc001bba920 0xc001bba980] [0xc001bba8b0 0xc001bba920 0xc001bba980] [0xc001bba900 0xc001bba958] [0x9c00a0 0x9c00a0] 0xc001075a40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:54:26.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:54:26.622: INFO: rc: 1
Jul 31 13:54:26.622: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00169e8d0 exit status 1 <nil> <nil> true [0xc000011ae8 0xc002d94008 0xc002d94048] [0xc000011ae8 0xc002d94008 0xc002d94048] [0xc002d94000 0xc002d94038] [0x9c00a0 0x9c00a0] 0xc0024be480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:54:36.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:54:37.556: INFO: rc: 1
Jul 31 13:54:37.556: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00169ec60 exit status 1 <nil> <nil> true [0xc002d94060 0xc002d94078 0xc002d940b0] [0xc002d94060 0xc002d94078 0xc002d940b0] [0xc002d94070 0xc002d940a8] [0x9c00a0 0x9c00a0] 0xc0024bec00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:54:47.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:54:48.525: INFO: rc: 1
Jul 31 13:54:48.525: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021ea870 exit status 1 <nil> <nil> true [0xc000526bf8 0xc000526d48 0xc000526da0] [0xc000526bf8 0xc000526d48 0xc000526da0] [0xc000526d40 0xc000526d80] [0x9c00a0 0x9c00a0] 0xc002e18720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:54:58.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:54:59.533: INFO: rc: 1
Jul 31 13:54:59.533: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d31dd0 exit status 1 <nil> <nil> true [0xc001bba9c0 0xc001bbaa08 0xc001bbaa70] [0xc001bba9c0 0xc001bbaa08 0xc001bbaa70] [0xc001bba9e8 0xc001bbaa58] [0x9c00a0 0x9c00a0] 0xc00304e000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jul 31 13:55:09.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228106623 exec --namespace=statefulset-2602 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 13:55:09.631: INFO: rc: 1
Jul 31 13:55:09.631: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Jul 31 13:55:09.631: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 31 13:55:10.348: INFO: Deleting all statefulset in ns statefulset-2602
Jul 31 13:55:10.721: INFO: Scaling statefulset ss to 0
Jul 31 13:55:12.023: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 13:55:12.221: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:55:13.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2602" for this suite.
Jul 31 13:55:22.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:55:26.141: INFO: namespace statefulset-2602 deletion completed in 12.772305801s

• [SLOW TEST:418.512 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:55:26.141: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:56:06.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5514" for this suite.
Jul 31 13:56:12.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:56:14.838: INFO: namespace namespaces-5514 deletion completed in 7.992590927s
STEP: Destroying namespace "nsdeletetest-5537" for this suite.
Jul 31 13:56:14.843: INFO: Namespace nsdeletetest-5537 was already deleted
STEP: Destroying namespace "nsdeletetest-2473" for this suite.
Jul 31 13:56:21.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:56:25.752: INFO: namespace nsdeletetest-2473 deletion completed in 10.908611297s

• [SLOW TEST:59.611 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:56:25.752: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 13:56:26.576: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fd2dde7e-b39a-11e9-82b5-da5bffca47b9" in namespace "projected-1409" to be "success or failure"
Jul 31 13:56:26.592: INFO: Pod "downwardapi-volume-fd2dde7e-b39a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.442672ms
Jul 31 13:56:29.224: INFO: Pod "downwardapi-volume-fd2dde7e-b39a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.648200266s
Jul 31 13:56:31.527: INFO: Pod "downwardapi-volume-fd2dde7e-b39a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.95160802s
Jul 31 13:56:33.722: INFO: Pod "downwardapi-volume-fd2dde7e-b39a-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.14630071s
Jul 31 13:56:36.122: INFO: Pod "downwardapi-volume-fd2dde7e-b39a-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 9.54601855s
STEP: Saw pod success
Jul 31 13:56:36.122: INFO: Pod "downwardapi-volume-fd2dde7e-b39a-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:56:36.426: INFO: Trying to get logs from node loving-darwin-5cd5b754c-ckbcc pod downwardapi-volume-fd2dde7e-b39a-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 13:56:37.422: INFO: Waiting for pod downwardapi-volume-fd2dde7e-b39a-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:56:37.722: INFO: Pod downwardapi-volume-fd2dde7e-b39a-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:56:37.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1409" for this suite.
Jul 31 13:56:44.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:56:51.423: INFO: namespace projected-1409 deletion completed in 13.500413653s

• [SLOW TEST:25.671 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:56:51.424: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-0c8b0bd8-b39b-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume secrets
Jul 31 13:56:52.363: INFO: Waiting up to 5m0s for pod "pod-secrets-0c8eeaeb-b39b-11e9-82b5-da5bffca47b9" in namespace "secrets-4124" to be "success or failure"
Jul 31 13:56:52.376: INFO: Pod "pod-secrets-0c8eeaeb-b39b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.553132ms
Jul 31 13:56:54.753: INFO: Pod "pod-secrets-0c8eeaeb-b39b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.389108623s
Jul 31 13:56:56.762: INFO: Pod "pod-secrets-0c8eeaeb-b39b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.398576037s
Jul 31 13:56:59.023: INFO: Pod "pod-secrets-0c8eeaeb-b39b-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.659121348s
STEP: Saw pod success
Jul 31 13:56:59.023: INFO: Pod "pod-secrets-0c8eeaeb-b39b-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:56:59.127: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-secrets-0c8eeaeb-b39b-11e9-82b5-da5bffca47b9 container secret-volume-test: <nil>
STEP: delete the pod
Jul 31 13:56:59.922: INFO: Waiting for pod pod-secrets-0c8eeaeb-b39b-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:57:00.421: INFO: Pod pod-secrets-0c8eeaeb-b39b-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:57:00.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4124" for this suite.
Jul 31 13:57:07.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:57:11.632: INFO: namespace secrets-4124 deletion completed in 11.009155568s

• [SLOW TEST:20.208 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:57:11.632: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Jul 31 13:57:11.822: INFO: Waiting up to 5m0s for pod "pod-1819ab8b-b39b-11e9-82b5-da5bffca47b9" in namespace "emptydir-5504" to be "success or failure"
Jul 31 13:57:12.121: INFO: Pod "pod-1819ab8b-b39b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 299.777631ms
Jul 31 13:57:14.230: INFO: Pod "pod-1819ab8b-b39b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.408285995s
Jul 31 13:57:16.422: INFO: Pod "pod-1819ab8b-b39b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.600136527s
Jul 31 13:57:18.634: INFO: Pod "pod-1819ab8b-b39b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.812291455s
Jul 31 13:57:21.237: INFO: Pod "pod-1819ab8b-b39b-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 9.415233309s
STEP: Saw pod success
Jul 31 13:57:21.237: INFO: Pod "pod-1819ab8b-b39b-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:57:21.722: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-1819ab8b-b39b-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 13:57:21.795: INFO: Waiting for pod pod-1819ab8b-b39b-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:57:21.800: INFO: Pod pod-1819ab8b-b39b-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:57:21.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5504" for this suite.
Jul 31 13:57:30.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:57:32.260: INFO: namespace emptydir-5504 deletion completed in 10.137287999s

• [SLOW TEST:20.628 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:57:32.261: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-8868
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8868 to expose endpoints map[]
Jul 31 13:57:32.728: INFO: successfully validated that service endpoint-test2 in namespace services-8868 exposes endpoints map[] (6.626817ms elapsed)
STEP: Creating pod pod1 in namespace services-8868
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8868 to expose endpoints map[pod1:[80]]
Jul 31 13:57:41.522: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (8.779989538s elapsed, will retry)
Jul 31 13:57:43.026: INFO: successfully validated that service endpoint-test2 in namespace services-8868 exposes endpoints map[pod1:[80]] (10.284364841s elapsed)
STEP: Creating pod pod2 in namespace services-8868
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8868 to expose endpoints map[pod1:[80] pod2:[80]]
Jul 31 13:57:50.357: INFO: successfully validated that service endpoint-test2 in namespace services-8868 exposes endpoints map[pod1:[80] pod2:[80]] (6.425170359s elapsed)
STEP: Deleting pod pod1 in namespace services-8868
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8868 to expose endpoints map[pod2:[80]]
Jul 31 13:57:51.402: INFO: successfully validated that service endpoint-test2 in namespace services-8868 exposes endpoints map[pod2:[80]] (1.032742537s elapsed)
STEP: Deleting pod pod2 in namespace services-8868
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8868 to expose endpoints map[]
Jul 31 13:57:51.721: INFO: successfully validated that service endpoint-test2 in namespace services-8868 exposes endpoints map[] (302.887889ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:57:52.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8868" for this suite.
Jul 31 13:57:58.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:58:07.068: INFO: namespace services-8868 deletion completed in 14.830739427s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:34.807 seconds]
[sig-network] Services
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:58:07.070: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-39c9881b-b39b-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume secrets
Jul 31 13:58:08.899: INFO: Waiting up to 5m0s for pod "pod-secrets-3a2385d0-b39b-11e9-82b5-da5bffca47b9" in namespace "secrets-9495" to be "success or failure"
Jul 31 13:58:10.328: INFO: Pod "pod-secrets-3a2385d0-b39b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.428440187s
Jul 31 13:58:12.341: INFO: Pod "pod-secrets-3a2385d0-b39b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.441208598s
Jul 31 13:58:15.324: INFO: Pod "pod-secrets-3a2385d0-b39b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.424143924s
Jul 31 13:58:17.336: INFO: Pod "pod-secrets-3a2385d0-b39b-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.436434191s
STEP: Saw pod success
Jul 31 13:58:17.336: INFO: Pod "pod-secrets-3a2385d0-b39b-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 13:58:17.347: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-secrets-3a2385d0-b39b-11e9-82b5-da5bffca47b9 container secret-volume-test: <nil>
STEP: delete the pod
Jul 31 13:58:18.056: INFO: Waiting for pod pod-secrets-3a2385d0-b39b-11e9-82b5-da5bffca47b9 to disappear
Jul 31 13:58:18.062: INFO: Pod pod-secrets-3a2385d0-b39b-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 13:58:18.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9495" for this suite.
Jul 31 13:58:24.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 13:58:29.370: INFO: namespace secrets-9495 deletion completed in 11.262003871s

• [SLOW TEST:22.300 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 13:58:29.370: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-5707
Jul 31 13:58:37.834: INFO: Started pod liveness-exec in namespace container-probe-5707
STEP: checking the pod's current state and verifying that restartCount is present
Jul 31 13:58:37.840: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:02:39.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5707" for this suite.
Jul 31 14:02:45.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:02:49.923: INFO: namespace container-probe-5707 deletion completed in 10.679158278s

• [SLOW TEST:260.553 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:02:49.924: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Jul 31 14:02:50.622: INFO: Waiting up to 5m0s for pod "pod-e1fc60bb-b39b-11e9-82b5-da5bffca47b9" in namespace "emptydir-7949" to be "success or failure"
Jul 31 14:02:50.822: INFO: Pod "pod-e1fc60bb-b39b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 199.35063ms
Jul 31 14:02:53.022: INFO: Pod "pod-e1fc60bb-b39b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.399139037s
Jul 31 14:02:55.329: INFO: Pod "pod-e1fc60bb-b39b-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.706273041s
Jul 31 14:02:57.522: INFO: Pod "pod-e1fc60bb-b39b-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.899289811s
STEP: Saw pod success
Jul 31 14:02:57.522: INFO: Pod "pod-e1fc60bb-b39b-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 14:02:57.529: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-e1fc60bb-b39b-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 14:02:58.622: INFO: Waiting for pod pod-e1fc60bb-b39b-11e9-82b5-da5bffca47b9 to disappear
Jul 31 14:02:59.422: INFO: Pod pod-e1fc60bb-b39b-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:02:59.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7949" for this suite.
Jul 31 14:03:06.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:03:08.645: INFO: namespace emptydir-7949 deletion completed in 9.017264423s

• [SLOW TEST:18.722 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:03:08.646: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 14:03:10.927: INFO: (0) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 1.286267014s)
Jul 31 14:03:11.422: INFO: (1) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 494.965279ms)
Jul 31 14:03:11.922: INFO: (2) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 499.976581ms)
Jul 31 14:03:11.939: INFO: (3) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 17.37071ms)
Jul 31 14:03:12.529: INFO: (4) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 589.539067ms)
Jul 31 14:03:12.640: INFO: (5) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 111.275588ms)
Jul 31 14:03:12.822: INFO: (6) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 181.538592ms)
Jul 31 14:03:12.836: INFO: (7) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 14.318425ms)
Jul 31 14:03:13.722: INFO: (8) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 885.687309ms)
Jul 31 14:03:13.930: INFO: (9) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 207.912104ms)
Jul 31 14:03:14.159: INFO: (10) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 229.63135ms)
Jul 31 14:03:14.224: INFO: (11) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 64.809541ms)
Jul 31 14:03:14.822: INFO: (12) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 596.395784ms)
Jul 31 14:03:16.522: INFO: (13) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 1.700010502s)
Jul 31 14:03:17.727: INFO: (14) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 1.204679877s)
Jul 31 14:03:18.622: INFO: (15) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 894.919732ms)
Jul 31 14:03:20.322: INFO: (16) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 1.700172886s)
Jul 31 14:03:21.122: INFO: (17) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 799.578382ms)
Jul 31 14:03:21.722: INFO: (18) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 600.083553ms)
Jul 31 14:03:23.244: INFO: (19) /api/v1/nodes/loving-darwin-5cd5b754c-ckbcc:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 1.521843975s)
[AfterEach] version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:03:23.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8891" for this suite.
Jul 31 14:03:30.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:03:33.322: INFO: namespace proxy-8891 deletion completed in 10.069725125s

• [SLOW TEST:24.676 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:03:33.323: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul 31 14:03:33.591: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 31 14:03:33.642: INFO: Waiting for terminating namespaces to be deleted...
Jul 31 14:03:33.652: INFO: 
Logging pods the kubelet thinks is on node loving-darwin-5cd5b754c-ckbcc before test
Jul 31 14:03:35.226: INFO: node-exporter-pxbl7 from kube-system started at 2019-07-31 11:25:02 +0000 UTC (2 container statuses recorded)
Jul 31 14:03:35.226: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jul 31 14:03:35.226: INFO: 	Container node-exporter ready: true, restart count 0
Jul 31 14:03:35.226: INFO: kubernetes-dashboard-57dcd9448b-f4j5n from kube-system started at 2019-07-31 11:26:05 +0000 UTC (1 container statuses recorded)
Jul 31 14:03:35.226: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Jul 31 14:03:35.226: INFO: openvpn-client-7f7cfb8c68-4jbt5 from kube-system started at 2019-07-31 11:26:05 +0000 UTC (2 container statuses recorded)
Jul 31 14:03:35.226: INFO: 	Container dnat-controller ready: true, restart count 0
Jul 31 14:03:35.226: INFO: 	Container openvpn-client ready: true, restart count 1
Jul 31 14:03:35.226: INFO: coredns-fdb754d8d-b2k94 from kube-system started at 2019-07-31 11:26:06 +0000 UTC (1 container statuses recorded)
Jul 31 14:03:35.226: INFO: 	Container coredns ready: true, restart count 0
Jul 31 14:03:35.226: INFO: container-linux-update-agent-kbslf from kube-system started at 2019-07-31 11:26:05 +0000 UTC (1 container statuses recorded)
Jul 31 14:03:35.226: INFO: 	Container update-agent ready: true, restart count 1
Jul 31 14:03:35.226: INFO: coredns-fdb754d8d-5gt7g from kube-system started at 2019-07-31 11:26:07 +0000 UTC (1 container statuses recorded)
Jul 31 14:03:35.226: INFO: 	Container coredns ready: true, restart count 0
Jul 31 14:03:35.226: INFO: kube-proxy-jdrnh from kube-system started at 2019-07-31 11:25:02 +0000 UTC (1 container statuses recorded)
Jul 31 14:03:35.226: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 31 14:03:35.226: INFO: canal-tc76d from kube-system started at 2019-07-31 11:25:02 +0000 UTC (2 container statuses recorded)
Jul 31 14:03:35.226: INFO: 	Container calico-node ready: true, restart count 0
Jul 31 14:03:35.226: INFO: 	Container kube-flannel ready: true, restart count 0
Jul 31 14:03:35.226: INFO: node-local-dns-g7bdx from kube-system started at 2019-07-31 11:26:05 +0000 UTC (1 container statuses recorded)
Jul 31 14:03:35.226: INFO: 	Container node-cache ready: true, restart count 0
Jul 31 14:03:35.226: INFO: sonobuoy-systemd-logs-daemon-set-757d48abf2694112-wkcgw from heptio-sonobuoy started at 2019-07-31 11:39:29 +0000 UTC (2 container statuses recorded)
Jul 31 14:03:35.226: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Jul 31 14:03:35.226: INFO: 	Container systemd-logs ready: true, restart count 2
Jul 31 14:03:35.226: INFO: container-linux-update-operator-5d5dcbf65f-mz2zk from kube-system started at 2019-07-31 11:26:05 +0000 UTC (1 container statuses recorded)
Jul 31 14:03:35.226: INFO: 	Container update-operator ready: true, restart count 0
Jul 31 14:03:35.226: INFO: 
Logging pods the kubelet thinks is on node loving-darwin-5cd5b754c-qfktz before test
Jul 31 14:03:35.425: INFO: sonobuoy-e2e-job-bb167d7044544260 from heptio-sonobuoy started at 2019-07-31 11:39:29 +0000 UTC (2 container statuses recorded)
Jul 31 14:03:35.425: INFO: 	Container e2e ready: true, restart count 0
Jul 31 14:03:35.425: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 31 14:03:35.425: INFO: container-linux-update-agent-9gt4z from kube-system started at 2019-07-31 11:26:35 +0000 UTC (1 container statuses recorded)
Jul 31 14:03:35.425: INFO: 	Container update-agent ready: true, restart count 0
Jul 31 14:03:35.425: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-31 11:39:16 +0000 UTC (1 container statuses recorded)
Jul 31 14:03:35.425: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 31 14:03:35.425: INFO: node-exporter-2wkxq from kube-system started at 2019-07-31 11:25:32 +0000 UTC (2 container statuses recorded)
Jul 31 14:03:35.425: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jul 31 14:03:35.425: INFO: 	Container node-exporter ready: true, restart count 0
Jul 31 14:03:35.425: INFO: canal-8rl9b from kube-system started at 2019-07-31 11:25:32 +0000 UTC (2 container statuses recorded)
Jul 31 14:03:35.425: INFO: 	Container calico-node ready: true, restart count 0
Jul 31 14:03:35.425: INFO: 	Container kube-flannel ready: true, restart count 0
Jul 31 14:03:35.425: INFO: node-local-dns-mxcjw from kube-system started at 2019-07-31 11:26:35 +0000 UTC (1 container statuses recorded)
Jul 31 14:03:35.425: INFO: 	Container node-cache ready: true, restart count 0
Jul 31 14:03:35.425: INFO: sonobuoy-systemd-logs-daemon-set-757d48abf2694112-9lqfv from heptio-sonobuoy started at 2019-07-31 11:39:29 +0000 UTC (2 container statuses recorded)
Jul 31 14:03:35.425: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Jul 31 14:03:35.425: INFO: 	Container systemd-logs ready: true, restart count 2
Jul 31 14:03:35.425: INFO: kube-proxy-wff69 from kube-system started at 2019-07-31 11:25:32 +0000 UTC (1 container statuses recorded)
Jul 31 14:03:35.426: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-022c7acd-b39c-11e9-82b5-da5bffca47b9 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-022c7acd-b39c-11e9-82b5-da5bffca47b9 off the node loving-darwin-5cd5b754c-qfktz
STEP: verifying the node doesn't have the label kubernetes.io/e2e-022c7acd-b39c-11e9-82b5-da5bffca47b9
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:03:52.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4477" for this suite.
Jul 31 14:04:05.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:04:08.043: INFO: namespace sched-pred-4477 deletion completed in 15.110915898s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:34.721 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:04:08.044: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jul 31 14:04:11.090: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-3738,SelfLink:/api/v1/namespaces/watch-3738/configmaps/e2e-watch-test-resource-version,UID:108b2c07-b39c-11e9-a303-6acf1189be78,ResourceVersion:38638,Generation:0,CreationTimestamp:2019-07-31 14:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 31 14:04:11.090: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-3738,SelfLink:/api/v1/namespaces/watch-3738/configmaps/e2e-watch-test-resource-version,UID:108b2c07-b39c-11e9-a303-6acf1189be78,ResourceVersion:38639,Generation:0,CreationTimestamp:2019-07-31 14:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:04:11.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3738" for this suite.
Jul 31 14:04:17.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:04:23.477: INFO: namespace watch-3738 deletion completed in 12.377363955s

• [SLOW TEST:15.433 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:04:23.477: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-19f45cc5-b39c-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume secrets
Jul 31 14:04:24.823: INFO: Waiting up to 5m0s for pod "pod-secrets-1a12cda1-b39c-11e9-82b5-da5bffca47b9" in namespace "secrets-8330" to be "success or failure"
Jul 31 14:04:25.227: INFO: Pod "pod-secrets-1a12cda1-b39c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 403.095719ms
Jul 31 14:04:27.429: INFO: Pod "pod-secrets-1a12cda1-b39c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.605544259s
Jul 31 14:04:29.626: INFO: Pod "pod-secrets-1a12cda1-b39c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.802373409s
Jul 31 14:04:31.730: INFO: Pod "pod-secrets-1a12cda1-b39c-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.905974867s
STEP: Saw pod success
Jul 31 14:04:31.730: INFO: Pod "pod-secrets-1a12cda1-b39c-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 14:04:31.763: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-secrets-1a12cda1-b39c-11e9-82b5-da5bffca47b9 container secret-volume-test: <nil>
STEP: delete the pod
Jul 31 14:04:33.351: INFO: Waiting for pod pod-secrets-1a12cda1-b39c-11e9-82b5-da5bffca47b9 to disappear
Jul 31 14:04:33.357: INFO: Pod pod-secrets-1a12cda1-b39c-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:04:33.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8330" for this suite.
Jul 31 14:04:39.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:04:45.129: INFO: namespace secrets-8330 deletion completed in 11.707588362s

• [SLOW TEST:21.652 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:04:45.130: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-269811ed-b39c-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume configMaps
Jul 31 14:04:46.051: INFO: Waiting up to 5m0s for pod "pod-configmaps-26e37d02-b39c-11e9-82b5-da5bffca47b9" in namespace "configmap-1479" to be "success or failure"
Jul 31 14:04:46.424: INFO: Pod "pod-configmaps-26e37d02-b39c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 372.426221ms
Jul 31 14:04:48.528: INFO: Pod "pod-configmaps-26e37d02-b39c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.476783502s
Jul 31 14:04:50.827: INFO: Pod "pod-configmaps-26e37d02-b39c-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.775388229s
STEP: Saw pod success
Jul 31 14:04:50.827: INFO: Pod "pod-configmaps-26e37d02-b39c-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 14:04:50.834: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-configmaps-26e37d02-b39c-11e9-82b5-da5bffca47b9 container configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 14:04:51.392: INFO: Waiting for pod pod-configmaps-26e37d02-b39c-11e9-82b5-da5bffca47b9 to disappear
Jul 31 14:04:51.403: INFO: Pod pod-configmaps-26e37d02-b39c-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:04:51.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1479" for this suite.
Jul 31 14:04:58.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:05:02.068: INFO: namespace configmap-1479 deletion completed in 10.65722909s

• [SLOW TEST:16.938 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:05:02.069: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Jul 31 14:05:03.243: INFO: Waiting up to 5m0s for pod "pod-3124f937-b39c-11e9-82b5-da5bffca47b9" in namespace "emptydir-1988" to be "success or failure"
Jul 31 14:05:03.260: INFO: Pod "pod-3124f937-b39c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 17.275385ms
Jul 31 14:05:05.826: INFO: Pod "pod-3124f937-b39c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.58284005s
Jul 31 14:05:08.334: INFO: Pod "pod-3124f937-b39c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.091273885s
Jul 31 14:05:10.348: INFO: Pod "pod-3124f937-b39c-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.104987507s
STEP: Saw pod success
Jul 31 14:05:10.349: INFO: Pod "pod-3124f937-b39c-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 14:05:10.364: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-3124f937-b39c-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 14:05:11.822: INFO: Waiting for pod pod-3124f937-b39c-11e9-82b5-da5bffca47b9 to disappear
Jul 31 14:05:11.836: INFO: Pod pod-3124f937-b39c-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:05:11.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1988" for this suite.
Jul 31 14:05:19.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:05:26.145: INFO: namespace emptydir-1988 deletion completed in 14.299587167s

• [SLOW TEST:24.076 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:05:26.145: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 14:05:26.258: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3eda04ab-b39c-11e9-82b5-da5bffca47b9" in namespace "downward-api-4849" to be "success or failure"
Jul 31 14:05:26.274: INFO: Pod "downwardapi-volume-3eda04ab-b39c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 15.559553ms
Jul 31 14:05:28.626: INFO: Pod "downwardapi-volume-3eda04ab-b39c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.368186271s
Jul 31 14:05:31.622: INFO: Pod "downwardapi-volume-3eda04ab-b39c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.364328334s
Jul 31 14:05:34.129: INFO: Pod "downwardapi-volume-3eda04ab-b39c-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.870881735s
STEP: Saw pod success
Jul 31 14:05:34.136: INFO: Pod "downwardapi-volume-3eda04ab-b39c-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 14:05:34.155: INFO: Trying to get logs from node loving-darwin-5cd5b754c-ckbcc pod downwardapi-volume-3eda04ab-b39c-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 14:05:35.299: INFO: Waiting for pod downwardapi-volume-3eda04ab-b39c-11e9-82b5-da5bffca47b9 to disappear
Jul 31 14:05:35.306: INFO: Pod downwardapi-volume-3eda04ab-b39c-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:05:35.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4849" for this suite.
Jul 31 14:05:42.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:05:44.359: INFO: namespace downward-api-4849 deletion completed in 9.044478964s

• [SLOW TEST:18.214 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:05:44.360: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 14:05:49.323: INFO: Create a RollingUpdate DaemonSet
Jul 31 14:05:49.337: INFO: Check that daemon pods launch on every node of the cluster
Jul 31 14:05:49.352: INFO: Number of nodes with available pods: 0
Jul 31 14:05:49.352: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 14:05:50.385: INFO: Number of nodes with available pods: 0
Jul 31 14:05:50.385: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 14:05:52.034: INFO: Number of nodes with available pods: 0
Jul 31 14:05:52.034: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 14:05:52.538: INFO: Number of nodes with available pods: 0
Jul 31 14:05:52.538: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 14:05:54.624: INFO: Number of nodes with available pods: 0
Jul 31 14:05:54.624: INFO: Node loving-darwin-5cd5b754c-ckbcc is running more than one daemon pod
Jul 31 14:05:56.323: INFO: Number of nodes with available pods: 2
Jul 31 14:05:56.323: INFO: Number of running nodes: 2, number of available pods: 2
Jul 31 14:05:56.323: INFO: Update the DaemonSet to trigger a rollout
Jul 31 14:05:57.130: INFO: Updating DaemonSet daemon-set
Jul 31 14:06:02.669: INFO: Roll back the DaemonSet before rollout is complete
Jul 31 14:06:02.689: INFO: Updating DaemonSet daemon-set
Jul 31 14:06:02.689: INFO: Make sure DaemonSet rollback is complete
Jul 31 14:06:02.714: INFO: Wrong image for pod: daemon-set-jvpqb. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Jul 31 14:06:02.714: INFO: Pod daemon-set-jvpqb is not available
Jul 31 14:06:05.625: INFO: Wrong image for pod: daemon-set-jvpqb. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Jul 31 14:06:05.625: INFO: Pod daemon-set-jvpqb is not available
Jul 31 14:06:07.022: INFO: Pod daemon-set-zzdg4 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3647, will wait for the garbage collector to delete the pods
Jul 31 14:06:08.222: INFO: Deleting DaemonSet.extensions daemon-set took: 223.853434ms
Jul 31 14:06:09.623: INFO: Terminating DaemonSet.extensions daemon-set pods took: 1.401098532s
Jul 31 14:07:28.630: INFO: Number of nodes with available pods: 0
Jul 31 14:07:28.630: INFO: Number of running nodes: 0, number of available pods: 0
Jul 31 14:07:28.635: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3647/daemonsets","resourceVersion":"39362"},"items":null}

Jul 31 14:07:28.644: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3647/pods","resourceVersion":"39362"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:07:29.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3647" for this suite.
Jul 31 14:07:36.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:07:43.622: INFO: namespace daemonsets-3647 deletion completed in 13.598631629s

• [SLOW TEST:119.262 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:07:43.623: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Jul 31 14:07:46.747: INFO: Waiting up to 5m0s for pod "pod-9298230c-b39c-11e9-82b5-da5bffca47b9" in namespace "emptydir-1992" to be "success or failure"
Jul 31 14:07:46.754: INFO: Pod "pod-9298230c-b39c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.491296ms
Jul 31 14:07:49.022: INFO: Pod "pod-9298230c-b39c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.274918881s
Jul 31 14:07:52.122: INFO: Pod "pod-9298230c-b39c-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.375251047s
Jul 31 14:07:55.122: INFO: Pod "pod-9298230c-b39c-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.3747696s
STEP: Saw pod success
Jul 31 14:07:55.122: INFO: Pod "pod-9298230c-b39c-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 14:07:55.128: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-9298230c-b39c-11e9-82b5-da5bffca47b9 container test-container: <nil>
STEP: delete the pod
Jul 31 14:07:56.122: INFO: Waiting for pod pod-9298230c-b39c-11e9-82b5-da5bffca47b9 to disappear
Jul 31 14:07:56.722: INFO: Pod pod-9298230c-b39c-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:07:56.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1992" for this suite.
Jul 31 14:08:03.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:08:08.722: INFO: namespace emptydir-1992 deletion completed in 11.498537386s

• [SLOW TEST:25.099 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:08:08.722: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 14:08:30.528: INFO: Container started at 2019-07-31 14:08:13 +0000 UTC, pod became ready at 2019-07-31 14:08:28 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:08:30.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8911" for this suite.
Jul 31 14:08:52.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:08:59.457: INFO: namespace container-probe-8911 deletion completed in 28.918784216s

• [SLOW TEST:50.735 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:08:59.458: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Jul 31 14:09:08.349: INFO: Successfully updated pod "annotationupdatebe9d6065-b39c-11e9-82b5-da5bffca47b9"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:09:13.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3420" for this suite.
Jul 31 14:09:37.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:09:40.338: INFO: namespace projected-3420 deletion completed in 26.41439655s

• [SLOW TEST:40.880 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:09:40.338: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:09:47.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6333" for this suite.
Jul 31 14:10:40.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:10:44.122: INFO: namespace kubelet-test-6333 deletion completed in 56.542907233s

• [SLOW TEST:63.784 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:10:44.123: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul 31 14:10:45.130: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 31 14:10:45.147: INFO: Waiting for terminating namespaces to be deleted...
Jul 31 14:10:45.157: INFO: 
Logging pods the kubelet thinks is on node loving-darwin-5cd5b754c-ckbcc before test
Jul 31 14:10:46.460: INFO: container-linux-update-agent-kbslf from kube-system started at 2019-07-31 11:26:05 +0000 UTC (1 container statuses recorded)
Jul 31 14:10:46.460: INFO: 	Container update-agent ready: true, restart count 1
Jul 31 14:10:46.460: INFO: coredns-fdb754d8d-5gt7g from kube-system started at 2019-07-31 11:26:07 +0000 UTC (1 container statuses recorded)
Jul 31 14:10:46.460: INFO: 	Container coredns ready: true, restart count 0
Jul 31 14:10:46.460: INFO: kube-proxy-jdrnh from kube-system started at 2019-07-31 11:25:02 +0000 UTC (1 container statuses recorded)
Jul 31 14:10:46.460: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 31 14:10:46.460: INFO: canal-tc76d from kube-system started at 2019-07-31 11:25:02 +0000 UTC (2 container statuses recorded)
Jul 31 14:10:46.460: INFO: 	Container calico-node ready: true, restart count 0
Jul 31 14:10:46.460: INFO: 	Container kube-flannel ready: true, restart count 0
Jul 31 14:10:46.460: INFO: node-local-dns-g7bdx from kube-system started at 2019-07-31 11:26:05 +0000 UTC (1 container statuses recorded)
Jul 31 14:10:46.460: INFO: 	Container node-cache ready: true, restart count 0
Jul 31 14:10:46.460: INFO: sonobuoy-systemd-logs-daemon-set-757d48abf2694112-wkcgw from heptio-sonobuoy started at 2019-07-31 11:39:29 +0000 UTC (2 container statuses recorded)
Jul 31 14:10:46.460: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Jul 31 14:10:46.460: INFO: 	Container systemd-logs ready: true, restart count 2
Jul 31 14:10:46.460: INFO: container-linux-update-operator-5d5dcbf65f-mz2zk from kube-system started at 2019-07-31 11:26:05 +0000 UTC (1 container statuses recorded)
Jul 31 14:10:46.460: INFO: 	Container update-operator ready: true, restart count 0
Jul 31 14:10:46.460: INFO: node-exporter-pxbl7 from kube-system started at 2019-07-31 11:25:02 +0000 UTC (2 container statuses recorded)
Jul 31 14:10:46.460: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jul 31 14:10:46.460: INFO: 	Container node-exporter ready: true, restart count 0
Jul 31 14:10:46.460: INFO: kubernetes-dashboard-57dcd9448b-f4j5n from kube-system started at 2019-07-31 11:26:05 +0000 UTC (1 container statuses recorded)
Jul 31 14:10:46.460: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Jul 31 14:10:46.460: INFO: openvpn-client-7f7cfb8c68-4jbt5 from kube-system started at 2019-07-31 11:26:05 +0000 UTC (2 container statuses recorded)
Jul 31 14:10:46.460: INFO: 	Container dnat-controller ready: true, restart count 0
Jul 31 14:10:46.460: INFO: 	Container openvpn-client ready: true, restart count 1
Jul 31 14:10:46.460: INFO: coredns-fdb754d8d-b2k94 from kube-system started at 2019-07-31 11:26:06 +0000 UTC (1 container statuses recorded)
Jul 31 14:10:46.460: INFO: 	Container coredns ready: true, restart count 0
Jul 31 14:10:46.460: INFO: 
Logging pods the kubelet thinks is on node loving-darwin-5cd5b754c-qfktz before test
Jul 31 14:10:47.733: INFO: node-exporter-2wkxq from kube-system started at 2019-07-31 11:25:32 +0000 UTC (2 container statuses recorded)
Jul 31 14:10:47.733: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jul 31 14:10:47.733: INFO: 	Container node-exporter ready: true, restart count 0
Jul 31 14:10:47.733: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-31 11:39:16 +0000 UTC (1 container statuses recorded)
Jul 31 14:10:47.733: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 31 14:10:47.733: INFO: kube-proxy-wff69 from kube-system started at 2019-07-31 11:25:32 +0000 UTC (1 container statuses recorded)
Jul 31 14:10:47.733: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 31 14:10:47.733: INFO: canal-8rl9b from kube-system started at 2019-07-31 11:25:32 +0000 UTC (2 container statuses recorded)
Jul 31 14:10:47.733: INFO: 	Container calico-node ready: true, restart count 0
Jul 31 14:10:47.733: INFO: 	Container kube-flannel ready: true, restart count 0
Jul 31 14:10:47.733: INFO: node-local-dns-mxcjw from kube-system started at 2019-07-31 11:26:35 +0000 UTC (1 container statuses recorded)
Jul 31 14:10:47.733: INFO: 	Container node-cache ready: true, restart count 0
Jul 31 14:10:47.733: INFO: sonobuoy-systemd-logs-daemon-set-757d48abf2694112-9lqfv from heptio-sonobuoy started at 2019-07-31 11:39:29 +0000 UTC (2 container statuses recorded)
Jul 31 14:10:47.733: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Jul 31 14:10:47.733: INFO: 	Container systemd-logs ready: true, restart count 2
Jul 31 14:10:47.733: INFO: container-linux-update-agent-9gt4z from kube-system started at 2019-07-31 11:26:35 +0000 UTC (1 container statuses recorded)
Jul 31 14:10:47.733: INFO: 	Container update-agent ready: true, restart count 0
Jul 31 14:10:47.733: INFO: sonobuoy-e2e-job-bb167d7044544260 from heptio-sonobuoy started at 2019-07-31 11:39:29 +0000 UTC (2 container statuses recorded)
Jul 31 14:10:47.733: INFO: 	Container e2e ready: true, restart count 0
Jul 31 14:10:47.733: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15b68343cbed3c5c], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:10:49.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1375" for this suite.
Jul 31 14:10:56.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:10:59.129: INFO: namespace sched-pred-1375 deletion completed in 9.394680738s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:15.006 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:10:59.129: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:11:06.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1734" for this suite.
Jul 31 14:11:49.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:11:52.742: INFO: namespace kubelet-test-1734 deletion completed in 45.917555862s

• [SLOW TEST:53.612 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:11:52.743: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 14:11:53.954: INFO: Waiting up to 5m0s for pod "downwardapi-volume-25f06031-b39d-11e9-82b5-da5bffca47b9" in namespace "downward-api-6629" to be "success or failure"
Jul 31 14:11:53.980: INFO: Pod "downwardapi-volume-25f06031-b39d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 26.226404ms
Jul 31 14:11:56.035: INFO: Pod "downwardapi-volume-25f06031-b39d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.081770752s
Jul 31 14:11:58.223: INFO: Pod "downwardapi-volume-25f06031-b39d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.269170897s
Jul 31 14:12:00.723: INFO: Pod "downwardapi-volume-25f06031-b39d-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.769610501s
STEP: Saw pod success
Jul 31 14:12:00.733: INFO: Pod "downwardapi-volume-25f06031-b39d-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 14:12:01.022: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod downwardapi-volume-25f06031-b39d-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 14:12:01.522: INFO: Waiting for pod downwardapi-volume-25f06031-b39d-11e9-82b5-da5bffca47b9 to disappear
Jul 31 14:12:01.730: INFO: Pod downwardapi-volume-25f06031-b39d-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:12:01.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6629" for this suite.
Jul 31 14:12:08.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:12:12.654: INFO: namespace downward-api-6629 deletion completed in 10.630860807s

• [SLOW TEST:19.911 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:12:12.655: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-xqbd
STEP: Creating a pod to test atomic-volume-subpath
Jul 31 14:12:14.328: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xqbd" in namespace "subpath-7782" to be "success or failure"
Jul 31 14:12:15.527: INFO: Pod "pod-subpath-test-configmap-xqbd": Phase="Pending", Reason="", readiness=false. Elapsed: 1.198753056s
Jul 31 14:12:17.923: INFO: Pod "pod-subpath-test-configmap-xqbd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.595189213s
Jul 31 14:12:20.034: INFO: Pod "pod-subpath-test-configmap-xqbd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.706243876s
Jul 31 14:12:22.222: INFO: Pod "pod-subpath-test-configmap-xqbd": Phase="Running", Reason="", readiness=true. Elapsed: 7.894645755s
Jul 31 14:12:24.522: INFO: Pod "pod-subpath-test-configmap-xqbd": Phase="Running", Reason="", readiness=true. Elapsed: 10.194080192s
Jul 31 14:12:26.626: INFO: Pod "pod-subpath-test-configmap-xqbd": Phase="Running", Reason="", readiness=true. Elapsed: 12.298056578s
Jul 31 14:12:29.622: INFO: Pod "pod-subpath-test-configmap-xqbd": Phase="Running", Reason="", readiness=true. Elapsed: 15.294062424s
Jul 31 14:12:32.022: INFO: Pod "pod-subpath-test-configmap-xqbd": Phase="Running", Reason="", readiness=true. Elapsed: 17.693961955s
Jul 31 14:12:35.822: INFO: Pod "pod-subpath-test-configmap-xqbd": Phase="Running", Reason="", readiness=true. Elapsed: 21.494450002s
Jul 31 14:12:38.423: INFO: Pod "pod-subpath-test-configmap-xqbd": Phase="Running", Reason="", readiness=true. Elapsed: 24.095617076s
Jul 31 14:12:40.922: INFO: Pod "pod-subpath-test-configmap-xqbd": Phase="Running", Reason="", readiness=true. Elapsed: 26.59391201s
Jul 31 14:12:44.122: INFO: Pod "pod-subpath-test-configmap-xqbd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 29.7940594s
STEP: Saw pod success
Jul 31 14:12:44.122: INFO: Pod "pod-subpath-test-configmap-xqbd" satisfied condition "success or failure"
Jul 31 14:12:44.822: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-subpath-test-configmap-xqbd container test-container-subpath-configmap-xqbd: <nil>
STEP: delete the pod
Jul 31 14:12:46.380: INFO: Waiting for pod pod-subpath-test-configmap-xqbd to disappear
Jul 31 14:12:46.389: INFO: Pod pod-subpath-test-configmap-xqbd no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xqbd
Jul 31 14:12:46.389: INFO: Deleting pod "pod-subpath-test-configmap-xqbd" in namespace "subpath-7782"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:12:46.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7782" for this suite.
Jul 31 14:12:54.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:13:01.624: INFO: namespace subpath-7782 deletion completed in 15.201773736s

• [SLOW TEST:48.969 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:13:01.625: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Jul 31 14:13:02.930: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul 31 14:13:09.329: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 31 14:13:18.422: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-8747,SelfLink:/apis/apps/v1/namespaces/deployment-8747/deployments/test-cleanup-deployment,UID:53007daf-b39d-11e9-a303-6acf1189be78,ResourceVersion:40611,Generation:1,CreationTimestamp:2019-07-31 14:13:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-07-31 14:13:09 +0000 UTC 2019-07-31 14:13:09 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-07-31 14:13:16 +0000 UTC 2019-07-31 14:13:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-6865c98b76" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jul 31 14:13:18.822: INFO: New ReplicaSet "test-cleanup-deployment-6865c98b76" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76,GenerateName:,Namespace:deployment-8747,SelfLink:/apis/apps/v1/namespaces/deployment-8747/replicasets/test-cleanup-deployment-6865c98b76,UID:5311546c-b39d-11e9-a303-6acf1189be78,ResourceVersion:40602,Generation:1,CreationTimestamp:2019-07-31 14:13:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 53007daf-b39d-11e9-a303-6acf1189be78 0xc000fa1a17 0xc000fa1a18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul 31 14:13:19.022: INFO: Pod "test-cleanup-deployment-6865c98b76-54rhj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76-54rhj,GenerateName:test-cleanup-deployment-6865c98b76-,Namespace:deployment-8747,SelfLink:/api/v1/namespaces/deployment-8747/pods/test-cleanup-deployment-6865c98b76-54rhj,UID:5325350f-b39d-11e9-a303-6acf1189be78,ResourceVersion:40601,Generation:0,CreationTimestamp:2019-07-31 14:13:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-6865c98b76 5311546c-b39d-11e9-a303-6acf1189be78 0xc0026f9f27 0xc0026f9f28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-cnsgv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cnsgv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-cnsgv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:loving-darwin-5cd5b754c-qfktz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026f9f90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026f9fb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 14:13:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 14:13:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 14:13:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 14:13:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.11,PodIP:172.25.1.234,StartTime:2019-07-31 14:13:09 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-07-31 14:13:15 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e7917f7bac70fba9ce3c6fcb719132599fbc1cb8aa0a1ea667ad080f14f57c82}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:13:19.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8747" for this suite.
Jul 31 14:13:26.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:13:30.558: INFO: namespace deployment-8747 deletion completed in 10.824871558s

• [SLOW TEST:28.934 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:13:30.558: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0731 14:14:01.253971      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 31 14:14:01.254: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:14:01.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2141" for this suite.
Jul 31 14:14:07.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:14:20.039: INFO: namespace gc-2141 deletion completed in 18.779417126s

• [SLOW TEST:49.481 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:14:20.039: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-7d8ecbaf-b39d-11e9-82b5-da5bffca47b9
STEP: Creating a pod to test consume configMaps
Jul 31 14:14:20.998: INFO: Waiting up to 5m0s for pod "pod-configmaps-7d93e37f-b39d-11e9-82b5-da5bffca47b9" in namespace "configmap-9303" to be "success or failure"
Jul 31 14:14:21.022: INFO: Pod "pod-configmaps-7d93e37f-b39d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 23.358102ms
Jul 31 14:14:23.626: INFO: Pod "pod-configmaps-7d93e37f-b39d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.627775401s
Jul 31 14:14:25.922: INFO: Pod "pod-configmaps-7d93e37f-b39d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.923592062s
Jul 31 14:14:28.522: INFO: Pod "pod-configmaps-7d93e37f-b39d-11e9-82b5-da5bffca47b9": Phase="Running", Reason="", readiness=true. Elapsed: 7.523767716s
Jul 31 14:14:30.529: INFO: Pod "pod-configmaps-7d93e37f-b39d-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 9.530982906s
STEP: Saw pod success
Jul 31 14:14:30.529: INFO: Pod "pod-configmaps-7d93e37f-b39d-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 14:14:30.536: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod pod-configmaps-7d93e37f-b39d-11e9-82b5-da5bffca47b9 container configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 14:14:32.425: INFO: Waiting for pod pod-configmaps-7d93e37f-b39d-11e9-82b5-da5bffca47b9 to disappear
Jul 31 14:14:32.622: INFO: Pod pod-configmaps-7d93e37f-b39d-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:14:32.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9303" for this suite.
Jul 31 14:14:39.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:14:46.322: INFO: namespace configmap-9303 deletion completed in 13.198353415s

• [SLOW TEST:26.283 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:14:46.322: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Jul 31 14:14:47.223: INFO: Waiting up to 5m0s for pod "var-expansion-8d1da547-b39d-11e9-82b5-da5bffca47b9" in namespace "var-expansion-436" to be "success or failure"
Jul 31 14:14:47.423: INFO: Pod "var-expansion-8d1da547-b39d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 198.768912ms
Jul 31 14:14:51.523: INFO: Pod "var-expansion-8d1da547-b39d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.298866955s
Jul 31 14:14:53.729: INFO: Pod "var-expansion-8d1da547-b39d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.505703117s
Jul 31 14:14:56.122: INFO: Pod "var-expansion-8d1da547-b39d-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.897905358s
STEP: Saw pod success
Jul 31 14:14:56.122: INFO: Pod "var-expansion-8d1da547-b39d-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 14:14:56.425: INFO: Trying to get logs from node loving-darwin-5cd5b754c-qfktz pod var-expansion-8d1da547-b39d-11e9-82b5-da5bffca47b9 container dapi-container: <nil>
STEP: delete the pod
Jul 31 14:14:57.648: INFO: Waiting for pod var-expansion-8d1da547-b39d-11e9-82b5-da5bffca47b9 to disappear
Jul 31 14:14:57.653: INFO: Pod var-expansion-8d1da547-b39d-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:14:57.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-436" for this suite.
Jul 31 14:15:04.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:15:11.822: INFO: namespace var-expansion-436 deletion completed in 14.161662847s

• [SLOW TEST:25.500 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Jul 31 14:15:11.823: INFO: >>> kubeConfig: /tmp/kubeconfig-228106623
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Jul 31 14:15:13.522: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9c9ca079-b39d-11e9-82b5-da5bffca47b9" in namespace "downward-api-3688" to be "success or failure"
Jul 31 14:15:13.722: INFO: Pod "downwardapi-volume-9c9ca079-b39d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 199.847684ms
Jul 31 14:15:16.528: INFO: Pod "downwardapi-volume-9c9ca079-b39d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.006475738s
Jul 31 14:15:18.871: INFO: Pod "downwardapi-volume-9c9ca079-b39d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.349101233s
Jul 31 14:15:21.522: INFO: Pod "downwardapi-volume-9c9ca079-b39d-11e9-82b5-da5bffca47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.999984249s
Jul 31 14:15:23.823: INFO: Pod "downwardapi-volume-9c9ca079-b39d-11e9-82b5-da5bffca47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.301516872s
STEP: Saw pod success
Jul 31 14:15:23.823: INFO: Pod "downwardapi-volume-9c9ca079-b39d-11e9-82b5-da5bffca47b9" satisfied condition "success or failure"
Jul 31 14:15:24.423: INFO: Trying to get logs from node loving-darwin-5cd5b754c-ckbcc pod downwardapi-volume-9c9ca079-b39d-11e9-82b5-da5bffca47b9 container client-container: <nil>
STEP: delete the pod
Jul 31 14:15:24.469: INFO: Waiting for pod downwardapi-volume-9c9ca079-b39d-11e9-82b5-da5bffca47b9 to disappear
Jul 31 14:15:24.475: INFO: Pod downwardapi-volume-9c9ca079-b39d-11e9-82b5-da5bffca47b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Jul 31 14:15:24.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3688" for this suite.
Jul 31 14:15:32.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 14:15:38.134: INFO: namespace downward-api-3688 deletion completed in 13.651296675s

• [SLOW TEST:26.311 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.4-beta.0.46+a87e9a978f65a8/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSJul 31 14:15:38.134: INFO: Running AfterSuite actions on all nodes
Jul 31 14:15:38.134: INFO: Running AfterSuite actions on node 1
Jul 31 14:15:38.134: INFO: Skipping dumping logs from cluster

Ran 204 of 3586 Specs in 9324.885 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3382 Skipped PASS

Ginkgo ran 1 suite in 2h35m27.190443567s
Test Suite Passed
