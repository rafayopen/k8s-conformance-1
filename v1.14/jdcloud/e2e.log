I0918 12:35:14.580966      19 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-496730594
I0918 12:35:14.581098      19 e2e.go:240] Starting e2e run "c31118f4-da10-11e9-8fe5-1a4434d30f67" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1568810113 - Will randomize all specs
Will run 204 of 3586 specs

Sep 18 12:35:14.691: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 12:35:14.693: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep 18 12:35:14.723: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep 18 12:35:14.758: INFO: 8 / 8 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep 18 12:35:14.758: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Sep 18 12:35:14.758: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep 18 12:35:14.768: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'jdcloud-k8s-ipamd' (0 seconds elapsed)
Sep 18 12:35:14.768: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Sep 18 12:35:14.768: INFO: e2e test version: v1.14.6
Sep 18 12:35:14.770: INFO: kube-apiserver version: v1.14.6-23.3d03dd1
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:35:14.770: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename container-probe
Sep 18 12:35:14.828: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-8746
Sep 18 12:35:16.858: INFO: Started pod liveness-http in namespace container-probe-8746
STEP: checking the pod's current state and verifying that restartCount is present
Sep 18 12:35:16.865: INFO: Initial restart count of pod liveness-http is 0
Sep 18 12:35:34.944: INFO: Restart count of pod container-probe-8746/liveness-http is now 1 (18.078845645s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:35:34.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8746" for this suite.
Sep 18 12:35:41.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:35:41.226: INFO: namespace container-probe-8746 deletion completed in 6.242767125s

• [SLOW TEST:26.456 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:35:41.226: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 12:35:41.298: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d36ab5d4-da10-11e9-8fe5-1a4434d30f67" in namespace "downward-api-9814" to be "success or failure"
Sep 18 12:35:41.305: INFO: Pod "downwardapi-volume-d36ab5d4-da10-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.651844ms
Sep 18 12:35:43.313: INFO: Pod "downwardapi-volume-d36ab5d4-da10-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015667006s
STEP: Saw pod success
Sep 18 12:35:43.313: INFO: Pod "downwardapi-volume-d36ab5d4-da10-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:35:43.320: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-d36ab5d4-da10-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 12:35:43.361: INFO: Waiting for pod downwardapi-volume-d36ab5d4-da10-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:35:43.368: INFO: Pod downwardapi-volume-d36ab5d4-da10-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:35:43.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9814" for this suite.
Sep 18 12:35:49.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:35:49.630: INFO: namespace downward-api-9814 deletion completed in 6.251649985s

• [SLOW TEST:8.404 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:35:49.630: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 12:35:49.699: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d86ca32f-da10-11e9-8fe5-1a4434d30f67" in namespace "projected-6725" to be "success or failure"
Sep 18 12:35:49.706: INFO: Pod "downwardapi-volume-d86ca32f-da10-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.562573ms
Sep 18 12:35:51.714: INFO: Pod "downwardapi-volume-d86ca32f-da10-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014591257s
STEP: Saw pod success
Sep 18 12:35:51.714: INFO: Pod "downwardapi-volume-d86ca32f-da10-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:35:51.721: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-d86ca32f-da10-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 12:35:51.762: INFO: Waiting for pod downwardapi-volume-d86ca32f-da10-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:35:51.768: INFO: Pod downwardapi-volume-d86ca32f-da10-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:35:51.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6725" for this suite.
Sep 18 12:35:57.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:35:58.025: INFO: namespace projected-6725 deletion completed in 6.245580872s

• [SLOW TEST:8.394 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:35:58.025: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-dd6e6c96-da10-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume configMaps
Sep 18 12:35:58.105: INFO: Waiting up to 5m0s for pod "pod-configmaps-dd6fa347-da10-11e9-8fe5-1a4434d30f67" in namespace "configmap-2366" to be "success or failure"
Sep 18 12:35:58.115: INFO: Pod "pod-configmaps-dd6fa347-da10-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 10.127638ms
Sep 18 12:36:00.123: INFO: Pod "pod-configmaps-dd6fa347-da10-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01850287s
STEP: Saw pod success
Sep 18 12:36:00.123: INFO: Pod "pod-configmaps-dd6fa347-da10-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:36:00.130: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-configmaps-dd6fa347-da10-11e9-8fe5-1a4434d30f67 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 18 12:36:00.168: INFO: Waiting for pod pod-configmaps-dd6fa347-da10-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:36:00.174: INFO: Pod pod-configmaps-dd6fa347-da10-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:36:00.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2366" for this suite.
Sep 18 12:36:06.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:36:06.478: INFO: namespace configmap-2366 deletion completed in 6.293679459s

• [SLOW TEST:8.453 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:36:06.478: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-8358
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 18 12:36:06.542: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 18 12:36:20.680: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.0.192.7:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8358 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 12:36:20.680: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 12:36:20.773: INFO: Found all expected endpoints: [netserver-0]
Sep 18 12:36:20.780: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.0.192.15:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8358 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 12:36:20.780: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 12:36:20.870: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:36:20.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8358" for this suite.
Sep 18 12:36:44.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:36:45.126: INFO: namespace pod-network-test-8358 deletion completed in 24.245436962s

• [SLOW TEST:38.648 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:36:45.127: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 18 12:36:45.197: INFO: Waiting up to 5m0s for pod "pod-f9813f37-da10-11e9-8fe5-1a4434d30f67" in namespace "emptydir-8147" to be "success or failure"
Sep 18 12:36:45.203: INFO: Pod "pod-f9813f37-da10-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.543202ms
Sep 18 12:36:47.211: INFO: Pod "pod-f9813f37-da10-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014413856s
STEP: Saw pod success
Sep 18 12:36:47.211: INFO: Pod "pod-f9813f37-da10-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:36:47.218: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-f9813f37-da10-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 12:36:47.257: INFO: Waiting for pod pod-f9813f37-da10-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:36:47.264: INFO: Pod pod-f9813f37-da10-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:36:47.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8147" for this suite.
Sep 18 12:36:53.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:36:53.526: INFO: namespace emptydir-8147 deletion completed in 6.25132374s

• [SLOW TEST:8.399 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:36:53.526: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:36:53.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1501" for this suite.
Sep 18 12:36:59.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:36:59.869: INFO: namespace kubelet-test-1501 deletion completed in 6.24284343s

• [SLOW TEST:6.343 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:36:59.869: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-024b1fb2-da11-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume secrets
Sep 18 12:36:59.949: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-024c4e3c-da11-11e9-8fe5-1a4434d30f67" in namespace "projected-1253" to be "success or failure"
Sep 18 12:36:59.956: INFO: Pod "pod-projected-secrets-024c4e3c-da11-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.740053ms
Sep 18 12:37:01.964: INFO: Pod "pod-projected-secrets-024c4e3c-da11-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014823077s
STEP: Saw pod success
Sep 18 12:37:01.964: INFO: Pod "pod-projected-secrets-024c4e3c-da11-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:37:01.971: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-projected-secrets-024c4e3c-da11-11e9-8fe5-1a4434d30f67 container secret-volume-test: <nil>
STEP: delete the pod
Sep 18 12:37:02.015: INFO: Waiting for pod pod-projected-secrets-024c4e3c-da11-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:37:02.023: INFO: Pod pod-projected-secrets-024c4e3c-da11-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:37:02.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1253" for this suite.
Sep 18 12:37:08.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:37:08.280: INFO: namespace projected-1253 deletion completed in 6.245181652s

• [SLOW TEST:8.411 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:37:08.280: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep 18 12:37:10.919: INFO: Successfully updated pod "annotationupdate074e2fc0-da11-11e9-8fe5-1a4434d30f67"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:37:12.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9287" for this suite.
Sep 18 12:37:34.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:37:35.213: INFO: namespace projected-9287 deletion completed in 22.249132966s

• [SLOW TEST:26.933 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:37:35.213: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-175c2a57-da11-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume configMaps
Sep 18 12:37:35.296: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-175d662d-da11-11e9-8fe5-1a4434d30f67" in namespace "projected-5053" to be "success or failure"
Sep 18 12:37:35.305: INFO: Pod "pod-projected-configmaps-175d662d-da11-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 8.500564ms
Sep 18 12:37:37.312: INFO: Pod "pod-projected-configmaps-175d662d-da11-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016075075s
STEP: Saw pod success
Sep 18 12:37:37.313: INFO: Pod "pod-projected-configmaps-175d662d-da11-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:37:37.319: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-projected-configmaps-175d662d-da11-11e9-8fe5-1a4434d30f67 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 18 12:37:37.363: INFO: Waiting for pod pod-projected-configmaps-175d662d-da11-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:37:37.369: INFO: Pod pod-projected-configmaps-175d662d-da11-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:37:37.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5053" for this suite.
Sep 18 12:37:43.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:37:43.626: INFO: namespace projected-5053 deletion completed in 6.246515881s

• [SLOW TEST:8.413 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:37:43.626: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0918 12:37:53.746158      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 18 12:37:53.746: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:37:53.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4729" for this suite.
Sep 18 12:37:59.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:38:00.019: INFO: namespace gc-4729 deletion completed in 6.262694563s

• [SLOW TEST:16.392 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:38:00.019: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:38:03.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3580" for this suite.
Sep 18 12:38:25.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:38:25.388: INFO: namespace replication-controller-3580 deletion completed in 22.243073035s

• [SLOW TEST:25.369 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:38:25.388: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Sep 18 12:38:25.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 create -f - --namespace=kubectl-6180'
Sep 18 12:38:25.664: INFO: stderr: ""
Sep 18 12:38:25.664: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 18 12:38:25.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6180'
Sep 18 12:38:25.734: INFO: stderr: ""
Sep 18 12:38:25.734: INFO: stdout: "update-demo-nautilus-2qtwc update-demo-nautilus-9c6j4 "
Sep 18 12:38:25.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-2qtwc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6180'
Sep 18 12:38:25.797: INFO: stderr: ""
Sep 18 12:38:25.797: INFO: stdout: ""
Sep 18 12:38:25.797: INFO: update-demo-nautilus-2qtwc is created but not running
Sep 18 12:38:30.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6180'
Sep 18 12:38:30.863: INFO: stderr: ""
Sep 18 12:38:30.863: INFO: stdout: "update-demo-nautilus-2qtwc update-demo-nautilus-9c6j4 "
Sep 18 12:38:30.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-2qtwc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6180'
Sep 18 12:38:30.924: INFO: stderr: ""
Sep 18 12:38:30.924: INFO: stdout: "true"
Sep 18 12:38:30.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-2qtwc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6180'
Sep 18 12:38:30.988: INFO: stderr: ""
Sep 18 12:38:30.988: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 18 12:38:30.989: INFO: validating pod update-demo-nautilus-2qtwc
Sep 18 12:38:30.998: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 18 12:38:30.998: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 18 12:38:30.998: INFO: update-demo-nautilus-2qtwc is verified up and running
Sep 18 12:38:30.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-9c6j4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6180'
Sep 18 12:38:31.063: INFO: stderr: ""
Sep 18 12:38:31.063: INFO: stdout: "true"
Sep 18 12:38:31.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-9c6j4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6180'
Sep 18 12:38:31.125: INFO: stderr: ""
Sep 18 12:38:31.125: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 18 12:38:31.125: INFO: validating pod update-demo-nautilus-9c6j4
Sep 18 12:38:31.136: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 18 12:38:31.136: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 18 12:38:31.136: INFO: update-demo-nautilus-9c6j4 is verified up and running
STEP: rolling-update to new replication controller
Sep 18 12:38:31.137: INFO: scanned /root for discovery docs: <nil>
Sep 18 12:38:31.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-6180'
Sep 18 12:38:53.587: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep 18 12:38:53.587: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 18 12:38:53.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6180'
Sep 18 12:38:53.655: INFO: stderr: ""
Sep 18 12:38:53.655: INFO: stdout: "update-demo-kitten-bsrjh update-demo-kitten-qjxnq "
Sep 18 12:38:53.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-kitten-bsrjh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6180'
Sep 18 12:38:53.723: INFO: stderr: ""
Sep 18 12:38:53.723: INFO: stdout: "true"
Sep 18 12:38:53.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-kitten-bsrjh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6180'
Sep 18 12:38:53.787: INFO: stderr: ""
Sep 18 12:38:53.787: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep 18 12:38:53.787: INFO: validating pod update-demo-kitten-bsrjh
Sep 18 12:38:53.799: INFO: got data: {
  "image": "kitten.jpg"
}

Sep 18 12:38:53.799: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep 18 12:38:53.799: INFO: update-demo-kitten-bsrjh is verified up and running
Sep 18 12:38:53.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-kitten-qjxnq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6180'
Sep 18 12:38:53.863: INFO: stderr: ""
Sep 18 12:38:53.863: INFO: stdout: "true"
Sep 18 12:38:53.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-kitten-qjxnq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6180'
Sep 18 12:38:53.927: INFO: stderr: ""
Sep 18 12:38:53.927: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep 18 12:38:53.927: INFO: validating pod update-demo-kitten-qjxnq
Sep 18 12:38:53.936: INFO: got data: {
  "image": "kitten.jpg"
}

Sep 18 12:38:53.936: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep 18 12:38:53.936: INFO: update-demo-kitten-qjxnq is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:38:53.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6180" for this suite.
Sep 18 12:39:17.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:39:18.189: INFO: namespace kubectl-6180 deletion completed in 24.242485274s

• [SLOW TEST:52.802 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:39:18.189: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1521
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 18 12:39:18.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-4234'
Sep 18 12:39:18.324: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 18 12:39:18.324: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1526
Sep 18 12:39:22.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 delete deployment e2e-test-nginx-deployment --namespace=kubectl-4234'
Sep 18 12:39:22.434: INFO: stderr: ""
Sep 18 12:39:22.434: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:39:22.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4234" for this suite.
Sep 18 12:39:28.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:39:28.693: INFO: namespace kubectl-4234 deletion completed in 6.248245712s

• [SLOW TEST:10.504 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:39:28.693: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Sep 18 12:39:30.791: INFO: Pod pod-hostip-5aff2858-da11-11e9-8fe5-1a4434d30f67 has hostIP: 10.0.224.5
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:39:30.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1951" for this suite.
Sep 18 12:39:52.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:39:53.045: INFO: namespace pods-1951 deletion completed in 22.242750191s

• [SLOW TEST:24.351 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:39:53.045: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep 18 12:39:53.101: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:39:56.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3000" for this suite.
Sep 18 12:40:18.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:40:18.885: INFO: namespace init-container-3000 deletion completed in 22.246211575s

• [SLOW TEST:25.840 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:40:18.885: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 18 12:40:18.953: INFO: Waiting up to 5m0s for pod "pod-78e9e307-da11-11e9-8fe5-1a4434d30f67" in namespace "emptydir-3029" to be "success or failure"
Sep 18 12:40:18.960: INFO: Pod "pod-78e9e307-da11-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.33945ms
Sep 18 12:40:20.968: INFO: Pod "pod-78e9e307-da11-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014607534s
STEP: Saw pod success
Sep 18 12:40:20.968: INFO: Pod "pod-78e9e307-da11-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:40:20.975: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-78e9e307-da11-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 12:40:21.016: INFO: Waiting for pod pod-78e9e307-da11-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:40:21.023: INFO: Pod pod-78e9e307-da11-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:40:21.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3029" for this suite.
Sep 18 12:40:27.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:40:27.284: INFO: namespace emptydir-3029 deletion completed in 6.250211967s

• [SLOW TEST:8.399 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:40:27.284: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 18 12:40:27.358: INFO: Waiting up to 5m0s for pod "pod-7dec60bb-da11-11e9-8fe5-1a4434d30f67" in namespace "emptydir-3235" to be "success or failure"
Sep 18 12:40:27.365: INFO: Pod "pod-7dec60bb-da11-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.862327ms
Sep 18 12:40:29.373: INFO: Pod "pod-7dec60bb-da11-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014940075s
STEP: Saw pod success
Sep 18 12:40:29.373: INFO: Pod "pod-7dec60bb-da11-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:40:29.380: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-7dec60bb-da11-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 12:40:29.419: INFO: Waiting for pod pod-7dec60bb-da11-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:40:29.427: INFO: Pod pod-7dec60bb-da11-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:40:29.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3235" for this suite.
Sep 18 12:40:35.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:40:35.682: INFO: namespace emptydir-3235 deletion completed in 6.244186551s

• [SLOW TEST:8.398 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:40:35.682: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 12:40:35.736: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:40:37.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4310" for this suite.
Sep 18 12:41:23.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:41:24.054: INFO: namespace pods-4310 deletion completed in 46.244947614s

• [SLOW TEST:48.372 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:41:24.054: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-9fc1e67e-da11-11e9-8fe5-1a4434d30f67
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:41:24.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7752" for this suite.
Sep 18 12:41:30.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:41:30.377: INFO: namespace configmap-7752 deletion completed in 6.25369253s

• [SLOW TEST:6.323 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:41:30.377: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-1467
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-1467
STEP: Deleting pre-stop pod
Sep 18 12:41:39.521: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:41:39.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-1467" for this suite.
Sep 18 12:42:19.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:42:19.787: INFO: namespace prestop-1467 deletion completed in 40.242309524s

• [SLOW TEST:49.410 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:42:19.787: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:42:23.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6715" for this suite.
Sep 18 12:42:29.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:42:30.127: INFO: namespace kubelet-test-6715 deletion completed in 6.244097478s

• [SLOW TEST:10.340 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:42:30.127: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep 18 12:42:30.620: INFO: Pod name wrapped-volume-race-c7624a9c-da11-11e9-8fe5-1a4434d30f67: Found 0 pods out of 5
Sep 18 12:42:35.636: INFO: Pod name wrapped-volume-race-c7624a9c-da11-11e9-8fe5-1a4434d30f67: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c7624a9c-da11-11e9-8fe5-1a4434d30f67 in namespace emptydir-wrapper-9032, will wait for the garbage collector to delete the pods
Sep 18 12:42:43.782: INFO: Deleting ReplicationController wrapped-volume-race-c7624a9c-da11-11e9-8fe5-1a4434d30f67 took: 17.428716ms
Sep 18 12:42:44.082: INFO: Terminating ReplicationController wrapped-volume-race-c7624a9c-da11-11e9-8fe5-1a4434d30f67 pods took: 300.19868ms
STEP: Creating RC which spawns configmap-volume pods
Sep 18 12:43:20.128: INFO: Pod name wrapped-volume-race-e4e2067a-da11-11e9-8fe5-1a4434d30f67: Found 0 pods out of 5
Sep 18 12:43:25.148: INFO: Pod name wrapped-volume-race-e4e2067a-da11-11e9-8fe5-1a4434d30f67: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e4e2067a-da11-11e9-8fe5-1a4434d30f67 in namespace emptydir-wrapper-9032, will wait for the garbage collector to delete the pods
Sep 18 12:43:37.281: INFO: Deleting ReplicationController wrapped-volume-race-e4e2067a-da11-11e9-8fe5-1a4434d30f67 took: 17.074424ms
Sep 18 12:43:37.581: INFO: Terminating ReplicationController wrapped-volume-race-e4e2067a-da11-11e9-8fe5-1a4434d30f67 pods took: 300.167386ms
STEP: Creating RC which spawns configmap-volume pods
Sep 18 12:44:11.315: INFO: Pod name wrapped-volume-race-036660c2-da12-11e9-8fe5-1a4434d30f67: Found 0 pods out of 5
Sep 18 12:44:16.329: INFO: Pod name wrapped-volume-race-036660c2-da12-11e9-8fe5-1a4434d30f67: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-036660c2-da12-11e9-8fe5-1a4434d30f67 in namespace emptydir-wrapper-9032, will wait for the garbage collector to delete the pods
Sep 18 12:44:28.463: INFO: Deleting ReplicationController wrapped-volume-race-036660c2-da12-11e9-8fe5-1a4434d30f67 took: 17.484812ms
Sep 18 12:44:28.763: INFO: Terminating ReplicationController wrapped-volume-race-036660c2-da12-11e9-8fe5-1a4434d30f67 pods took: 300.200905ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:45:08.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9032" for this suite.
Sep 18 12:45:16.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:45:16.408: INFO: namespace emptydir-wrapper-9032 deletion completed in 8.24579207s

• [SLOW TEST:166.281 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:45:16.408: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-dc6x
STEP: Creating a pod to test atomic-volume-subpath
Sep 18 12:45:16.493: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-dc6x" in namespace "subpath-9496" to be "success or failure"
Sep 18 12:45:16.500: INFO: Pod "pod-subpath-test-configmap-dc6x": Phase="Pending", Reason="", readiness=false. Elapsed: 6.65726ms
Sep 18 12:45:18.508: INFO: Pod "pod-subpath-test-configmap-dc6x": Phase="Running", Reason="", readiness=true. Elapsed: 2.014990802s
Sep 18 12:45:20.516: INFO: Pod "pod-subpath-test-configmap-dc6x": Phase="Running", Reason="", readiness=true. Elapsed: 4.023028588s
Sep 18 12:45:22.524: INFO: Pod "pod-subpath-test-configmap-dc6x": Phase="Running", Reason="", readiness=true. Elapsed: 6.030963425s
Sep 18 12:45:24.532: INFO: Pod "pod-subpath-test-configmap-dc6x": Phase="Running", Reason="", readiness=true. Elapsed: 8.039012367s
Sep 18 12:45:26.540: INFO: Pod "pod-subpath-test-configmap-dc6x": Phase="Running", Reason="", readiness=true. Elapsed: 10.046982008s
Sep 18 12:45:28.548: INFO: Pod "pod-subpath-test-configmap-dc6x": Phase="Running", Reason="", readiness=true. Elapsed: 12.054991372s
Sep 18 12:45:30.556: INFO: Pod "pod-subpath-test-configmap-dc6x": Phase="Running", Reason="", readiness=true. Elapsed: 14.062874318s
Sep 18 12:45:32.564: INFO: Pod "pod-subpath-test-configmap-dc6x": Phase="Running", Reason="", readiness=true. Elapsed: 16.070761544s
Sep 18 12:45:34.572: INFO: Pod "pod-subpath-test-configmap-dc6x": Phase="Running", Reason="", readiness=true. Elapsed: 18.078929767s
Sep 18 12:45:36.580: INFO: Pod "pod-subpath-test-configmap-dc6x": Phase="Running", Reason="", readiness=true. Elapsed: 20.086634062s
Sep 18 12:45:38.588: INFO: Pod "pod-subpath-test-configmap-dc6x": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.094752783s
STEP: Saw pod success
Sep 18 12:45:38.588: INFO: Pod "pod-subpath-test-configmap-dc6x" satisfied condition "success or failure"
Sep 18 12:45:38.595: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-subpath-test-configmap-dc6x container test-container-subpath-configmap-dc6x: <nil>
STEP: delete the pod
Sep 18 12:45:38.637: INFO: Waiting for pod pod-subpath-test-configmap-dc6x to disappear
Sep 18 12:45:38.644: INFO: Pod pod-subpath-test-configmap-dc6x no longer exists
STEP: Deleting pod pod-subpath-test-configmap-dc6x
Sep 18 12:45:38.644: INFO: Deleting pod "pod-subpath-test-configmap-dc6x" in namespace "subpath-9496"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:45:38.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9496" for this suite.
Sep 18 12:45:44.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:45:44.907: INFO: namespace subpath-9496 deletion completed in 6.245695283s

• [SLOW TEST:28.499 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:45:44.907: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 12:45:44.978: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3b3d7bba-da12-11e9-8fe5-1a4434d30f67" in namespace "projected-6678" to be "success or failure"
Sep 18 12:45:44.986: INFO: Pod "downwardapi-volume-3b3d7bba-da12-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.361829ms
Sep 18 12:45:46.994: INFO: Pod "downwardapi-volume-3b3d7bba-da12-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015446052s
STEP: Saw pod success
Sep 18 12:45:46.994: INFO: Pod "downwardapi-volume-3b3d7bba-da12-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:45:47.001: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-3b3d7bba-da12-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 12:45:47.074: INFO: Waiting for pod downwardapi-volume-3b3d7bba-da12-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:45:47.081: INFO: Pod downwardapi-volume-3b3d7bba-da12-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:45:47.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6678" for this suite.
Sep 18 12:45:53.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:45:53.338: INFO: namespace projected-6678 deletion completed in 6.246797504s

• [SLOW TEST:8.431 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:45:53.338: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:45:59.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8927" for this suite.
Sep 18 12:46:05.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:46:05.798: INFO: namespace namespaces-8927 deletion completed in 6.24536888s
STEP: Destroying namespace "nsdeletetest-499" for this suite.
Sep 18 12:46:05.805: INFO: Namespace nsdeletetest-499 was already deleted
STEP: Destroying namespace "nsdeletetest-5228" for this suite.
Sep 18 12:46:11.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:46:12.046: INFO: namespace nsdeletetest-5228 deletion completed in 6.240965131s

• [SLOW TEST:18.707 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:46:12.046: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 12:46:12.114: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4b69debb-da12-11e9-8fe5-1a4434d30f67" in namespace "projected-5210" to be "success or failure"
Sep 18 12:46:12.122: INFO: Pod "downwardapi-volume-4b69debb-da12-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 8.214859ms
Sep 18 12:46:14.130: INFO: Pod "downwardapi-volume-4b69debb-da12-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016378015s
STEP: Saw pod success
Sep 18 12:46:14.130: INFO: Pod "downwardapi-volume-4b69debb-da12-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:46:14.137: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-4b69debb-da12-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 12:46:14.176: INFO: Waiting for pod downwardapi-volume-4b69debb-da12-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:46:14.182: INFO: Pod downwardapi-volume-4b69debb-da12-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:46:14.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5210" for this suite.
Sep 18 12:46:20.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:46:20.443: INFO: namespace projected-5210 deletion completed in 6.249361663s

• [SLOW TEST:8.397 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:46:20.443: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 18 12:46:20.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-3898'
Sep 18 12:46:20.566: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 18 12:46:20.566: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Sep 18 12:46:20.577: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Sep 18 12:46:20.581: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Sep 18 12:46:20.590: INFO: scanned /root for discovery docs: <nil>
Sep 18 12:46:20.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-3898'
Sep 18 12:46:36.835: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep 18 12:46:36.835: INFO: stdout: "Created e2e-test-nginx-rc-de42b5ef86a84de26e2c00b305186d8d\nScaling up e2e-test-nginx-rc-de42b5ef86a84de26e2c00b305186d8d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-de42b5ef86a84de26e2c00b305186d8d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-de42b5ef86a84de26e2c00b305186d8d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Sep 18 12:46:36.835: INFO: stdout: "Created e2e-test-nginx-rc-de42b5ef86a84de26e2c00b305186d8d\nScaling up e2e-test-nginx-rc-de42b5ef86a84de26e2c00b305186d8d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-de42b5ef86a84de26e2c00b305186d8d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-de42b5ef86a84de26e2c00b305186d8d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Sep 18 12:46:36.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-3898'
Sep 18 12:46:36.902: INFO: stderr: ""
Sep 18 12:46:36.902: INFO: stdout: "e2e-test-nginx-rc-de42b5ef86a84de26e2c00b305186d8d-krjq9 "
Sep 18 12:46:36.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods e2e-test-nginx-rc-de42b5ef86a84de26e2c00b305186d8d-krjq9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3898'
Sep 18 12:46:36.966: INFO: stderr: ""
Sep 18 12:46:36.966: INFO: stdout: "true"
Sep 18 12:46:36.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods e2e-test-nginx-rc-de42b5ef86a84de26e2c00b305186d8d-krjq9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3898'
Sep 18 12:46:37.029: INFO: stderr: ""
Sep 18 12:46:37.029: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Sep 18 12:46:37.029: INFO: e2e-test-nginx-rc-de42b5ef86a84de26e2c00b305186d8d-krjq9 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1486
Sep 18 12:46:37.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 delete rc e2e-test-nginx-rc --namespace=kubectl-3898'
Sep 18 12:46:37.109: INFO: stderr: ""
Sep 18 12:46:37.109: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:46:37.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3898" for this suite.
Sep 18 12:46:59.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:46:59.367: INFO: namespace kubectl-3898 deletion completed in 22.246425565s

• [SLOW TEST:38.924 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:46:59.367: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 18 12:47:01.985: INFO: Successfully updated pod "pod-update-679ef9ae-da12-11e9-8fe5-1a4434d30f67"
STEP: verifying the updated pod is in kubernetes
Sep 18 12:47:01.999: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:47:01.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7362" for this suite.
Sep 18 12:47:24.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:47:24.259: INFO: namespace pods-7362 deletion completed in 22.247478312s

• [SLOW TEST:24.892 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:47:24.259: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0918 12:47:24.938307      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 18 12:47:24.938: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:47:24.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4218" for this suite.
Sep 18 12:47:30.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:47:31.203: INFO: namespace gc-4218 deletion completed in 6.254782077s

• [SLOW TEST:6.944 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:47:31.203: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0918 12:48:01.835548      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 18 12:48:01.835: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:48:01.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3324" for this suite.
Sep 18 12:48:07.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:48:08.097: INFO: namespace gc-3324 deletion completed in 6.250975916s

• [SLOW TEST:36.894 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:48:08.097: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep 18 12:48:08.154: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 18 12:48:08.175: INFO: Waiting for terminating namespaces to be deleted...
Sep 18 12:48:08.181: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm1qxh-95up3dyso1 before test
Sep 18 12:48:08.195: INFO: sonobuoy-systemd-logs-daemon-set-c0812b53cb224d4d-cbx95 from heptio-sonobuoy started at 2019-09-18 12:35:13 +0000 UTC (2 container statuses recorded)
Sep 18 12:48:08.195: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 18 12:48:08.195: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 18 12:48:08.195: INFO: jdcloud-k8s-ipamd-6sz6f from kube-system started at 2019-09-17 13:31:44 +0000 UTC (1 container statuses recorded)
Sep 18 12:48:08.195: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Sep 18 12:48:08.195: INFO: csi-jdcloudplugin-z2wwd from jke-system started at 2019-09-17 13:32:00 +0000 UTC (2 container statuses recorded)
Sep 18 12:48:08.195: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 18 12:48:08.195: INFO: 	Container jdcloud-csi ready: true, restart count 0
Sep 18 12:48:08.195: INFO: coredns-6b4fdb779b-qzqfd from kube-system started at 2019-09-18 09:40:53 +0000 UTC (1 container statuses recorded)
Sep 18 12:48:08.195: INFO: 	Container coredns ready: true, restart count 8
Sep 18 12:48:08.195: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-18 12:31:22 +0000 UTC (1 container statuses recorded)
Sep 18 12:48:08.195: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 18 12:48:08.195: INFO: node-exporter-fwmxn from jke-system started at 2019-09-17 13:32:00 +0000 UTC (1 container statuses recorded)
Sep 18 12:48:08.195: INFO: 	Container node-exporter ready: true, restart count 0
Sep 18 12:48:08.195: INFO: kube-proxy-hx4lq from kube-system started at 2019-09-17 13:32:00 +0000 UTC (1 container statuses recorded)
Sep 18 12:48:08.195: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 18 12:48:08.195: INFO: sonobuoy-e2e-job-f17ac7a1786c4dde from heptio-sonobuoy started at 2019-09-18 12:35:13 +0000 UTC (2 container statuses recorded)
Sep 18 12:48:08.195: INFO: 	Container e2e ready: true, restart count 0
Sep 18 12:48:08.195: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 18 12:48:08.195: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm599z-95up3dyso1 before test
Sep 18 12:48:08.211: INFO: jdcloud-k8s-ipamd-sc9ft from kube-system started at 2019-09-17 13:31:00 +0000 UTC (1 container statuses recorded)
Sep 18 12:48:08.211: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Sep 18 12:48:08.211: INFO: heapster-77dc7fd7fd-xzfww from kube-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 12:48:08.211: INFO: 	Container heapster ready: true, restart count 0
Sep 18 12:48:08.211: INFO: prometheus-559998dfcb-v6rsx from jke-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 12:48:08.211: INFO: 	Container prometheus ready: true, restart count 0
Sep 18 12:48:08.211: INFO: kube-proxy-l4vgf from kube-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 12:48:08.211: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 18 12:48:08.211: INFO: csi-jdcloudplugin-xrkh7 from jke-system started at 2019-09-17 13:31:14 +0000 UTC (2 container statuses recorded)
Sep 18 12:48:08.211: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 18 12:48:08.211: INFO: 	Container jdcloud-csi ready: true, restart count 0
Sep 18 12:48:08.211: INFO: node-exporter-hx9hf from jke-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 12:48:08.211: INFO: 	Container node-exporter ready: true, restart count 0
Sep 18 12:48:08.211: INFO: sonobuoy-systemd-logs-daemon-set-c0812b53cb224d4d-dtpxn from heptio-sonobuoy started at 2019-09-18 12:35:13 +0000 UTC (2 container statuses recorded)
Sep 18 12:48:08.211: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 18 12:48:08.211: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 18 12:48:08.211: INFO: prometheus-jdmon-5f8bdc758-r998b from jke-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 12:48:08.211: INFO: 	Container k8s-metrics-to-jdmon ready: true, restart count 2
Sep 18 12:48:08.211: INFO: csi-jdcloudplugin-controller-0 from jke-system started at 2019-09-17 13:31:14 +0000 UTC (4 container statuses recorded)
Sep 18 12:48:08.211: INFO: 	Container csi-attacher ready: true, restart count 0
Sep 18 12:48:08.211: INFO: 	Container csi-provisioner ready: true, restart count 0
Sep 18 12:48:08.211: INFO: 	Container jdcloud-csi ready: true, restart count 0
Sep 18 12:48:08.211: INFO: 	Container liveness-probe ready: true, restart count 0
Sep 18 12:48:08.211: INFO: kube-state-metrics-546cf6cfd8-4q5ww from jke-system started at 2019-09-17 13:31:14 +0000 UTC (2 container statuses recorded)
Sep 18 12:48:08.211: INFO: 	Container addon-resizer ready: true, restart count 0
Sep 18 12:48:08.211: INFO: 	Container kube-state-metrics ready: true, restart count 0
Sep 18 12:48:08.211: INFO: kubernetes-dashboard-5c846c6494-t95sr from kube-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 12:48:08.211: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 18 12:48:08.211: INFO: coredns-6b4fdb779b-g9pl5 from kube-system started at 2019-09-17 13:31:22 +0000 UTC (1 container statuses recorded)
Sep 18 12:48:08.211: INFO: 	Container coredns ready: true, restart count 9
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-91d9335b-da12-11e9-8fe5-1a4434d30f67 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-91d9335b-da12-11e9-8fe5-1a4434d30f67 off the node k8s-node-vm1qxh-95up3dyso1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-91d9335b-da12-11e9-8fe5-1a4434d30f67
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:48:12.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6232" for this suite.
Sep 18 12:48:32.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:48:32.631: INFO: namespace sched-pred-6232 deletion completed in 20.24916152s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:24.534 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:48:32.631: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-9f3546ed-da12-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume secrets
Sep 18 12:48:32.706: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9f36779a-da12-11e9-8fe5-1a4434d30f67" in namespace "projected-9171" to be "success or failure"
Sep 18 12:48:32.713: INFO: Pod "pod-projected-secrets-9f36779a-da12-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.529949ms
Sep 18 12:48:34.721: INFO: Pod "pod-projected-secrets-9f36779a-da12-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015259095s
STEP: Saw pod success
Sep 18 12:48:34.721: INFO: Pod "pod-projected-secrets-9f36779a-da12-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:48:34.728: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-projected-secrets-9f36779a-da12-11e9-8fe5-1a4434d30f67 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 18 12:48:34.767: INFO: Waiting for pod pod-projected-secrets-9f36779a-da12-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:48:34.778: INFO: Pod pod-projected-secrets-9f36779a-da12-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:48:34.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9171" for this suite.
Sep 18 12:48:40.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:48:41.031: INFO: namespace projected-9171 deletion completed in 6.243234634s

• [SLOW TEST:8.400 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:48:41.031: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-5945/secret-test-a4374bc8-da12-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume secrets
Sep 18 12:48:41.106: INFO: Waiting up to 5m0s for pod "pod-configmaps-a438818a-da12-11e9-8fe5-1a4434d30f67" in namespace "secrets-5945" to be "success or failure"
Sep 18 12:48:41.114: INFO: Pod "pod-configmaps-a438818a-da12-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.941479ms
Sep 18 12:48:43.122: INFO: Pod "pod-configmaps-a438818a-da12-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015774569s
STEP: Saw pod success
Sep 18 12:48:43.122: INFO: Pod "pod-configmaps-a438818a-da12-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:48:43.129: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-configmaps-a438818a-da12-11e9-8fe5-1a4434d30f67 container env-test: <nil>
STEP: delete the pod
Sep 18 12:48:43.170: INFO: Waiting for pod pod-configmaps-a438818a-da12-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:48:43.177: INFO: Pod pod-configmaps-a438818a-da12-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:48:43.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5945" for this suite.
Sep 18 12:48:49.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:48:49.437: INFO: namespace secrets-5945 deletion completed in 6.249941627s

• [SLOW TEST:8.406 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:48:49.438: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep 18 12:48:49.522: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7182,SelfLink:/api/v1/namespaces/watch-7182/configmaps/e2e-watch-test-watch-closed,UID:a93c2ce7-da12-11e9-b983-fa163edda742,ResourceVersion:225330,Generation:0,CreationTimestamp:2019-09-18 12:48:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 18 12:48:49.522: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7182,SelfLink:/api/v1/namespaces/watch-7182/configmaps/e2e-watch-test-watch-closed,UID:a93c2ce7-da12-11e9-b983-fa163edda742,ResourceVersion:225331,Generation:0,CreationTimestamp:2019-09-18 12:48:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep 18 12:48:49.555: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7182,SelfLink:/api/v1/namespaces/watch-7182/configmaps/e2e-watch-test-watch-closed,UID:a93c2ce7-da12-11e9-b983-fa163edda742,ResourceVersion:225332,Generation:0,CreationTimestamp:2019-09-18 12:48:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 18 12:48:49.555: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7182,SelfLink:/api/v1/namespaces/watch-7182/configmaps/e2e-watch-test-watch-closed,UID:a93c2ce7-da12-11e9-b983-fa163edda742,ResourceVersion:225333,Generation:0,CreationTimestamp:2019-09-18 12:48:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:48:49.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7182" for this suite.
Sep 18 12:48:55.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:48:55.814: INFO: namespace watch-7182 deletion completed in 6.248591472s

• [SLOW TEST:6.376 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:48:55.814: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-ad086e2d-da12-11e9-8fe5-1a4434d30f67
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:48:57.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4436" for this suite.
Sep 18 12:49:19.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:49:20.207: INFO: namespace configmap-4436 deletion completed in 22.242813355s

• [SLOW TEST:24.393 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:49:20.207: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-bb911844-da12-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume configMaps
Sep 18 12:49:20.286: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bb925580-da12-11e9-8fe5-1a4434d30f67" in namespace "projected-5736" to be "success or failure"
Sep 18 12:49:20.292: INFO: Pod "pod-projected-configmaps-bb925580-da12-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.416423ms
Sep 18 12:49:22.300: INFO: Pod "pod-projected-configmaps-bb925580-da12-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014693649s
STEP: Saw pod success
Sep 18 12:49:22.300: INFO: Pod "pod-projected-configmaps-bb925580-da12-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:49:22.307: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-projected-configmaps-bb925580-da12-11e9-8fe5-1a4434d30f67 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 18 12:49:22.347: INFO: Waiting for pod pod-projected-configmaps-bb925580-da12-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:49:22.354: INFO: Pod pod-projected-configmaps-bb925580-da12-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:49:22.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5736" for this suite.
Sep 18 12:49:28.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:49:28.617: INFO: namespace projected-5736 deletion completed in 6.252694425s

• [SLOW TEST:8.410 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:49:28.617: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0918 12:49:38.818960      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 18 12:49:38.818: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:49:38.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1638" for this suite.
Sep 18 12:49:46.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:49:47.080: INFO: namespace gc-1638 deletion completed in 8.250687158s

• [SLOW TEST:18.462 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:49:47.080: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep 18 12:49:47.153: INFO: Waiting up to 5m0s for pod "downward-api-cb963680-da12-11e9-8fe5-1a4434d30f67" in namespace "downward-api-8850" to be "success or failure"
Sep 18 12:49:47.160: INFO: Pod "downward-api-cb963680-da12-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.477004ms
Sep 18 12:49:49.168: INFO: Pod "downward-api-cb963680-da12-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014533759s
STEP: Saw pod success
Sep 18 12:49:49.168: INFO: Pod "downward-api-cb963680-da12-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:49:49.175: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downward-api-cb963680-da12-11e9-8fe5-1a4434d30f67 container dapi-container: <nil>
STEP: delete the pod
Sep 18 12:49:49.217: INFO: Waiting for pod downward-api-cb963680-da12-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:49:49.225: INFO: Pod downward-api-cb963680-da12-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:49:49.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8850" for this suite.
Sep 18 12:49:55.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:49:55.483: INFO: namespace downward-api-8850 deletion completed in 6.24627405s

• [SLOW TEST:8.403 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:49:55.483: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 18 12:49:59.621: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 18 12:49:59.628: INFO: Pod pod-with-prestop-http-hook still exists
Sep 18 12:50:01.628: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 18 12:50:01.636: INFO: Pod pod-with-prestop-http-hook still exists
Sep 18 12:50:03.628: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 18 12:50:03.636: INFO: Pod pod-with-prestop-http-hook still exists
Sep 18 12:50:05.628: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 18 12:50:05.636: INFO: Pod pod-with-prestop-http-hook still exists
Sep 18 12:50:07.628: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 18 12:50:07.636: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:50:07.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2643" for this suite.
Sep 18 12:50:29.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:50:29.923: INFO: namespace container-lifecycle-hook-2643 deletion completed in 22.26051318s

• [SLOW TEST:34.441 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:50:29.924: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-4369
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4369 to expose endpoints map[]
Sep 18 12:50:30.059: INFO: successfully validated that service endpoint-test2 in namespace services-4369 exposes endpoints map[] (6.635206ms elapsed)
STEP: Creating pod pod1 in namespace services-4369
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4369 to expose endpoints map[pod1:[80]]
Sep 18 12:50:31.106: INFO: successfully validated that service endpoint-test2 in namespace services-4369 exposes endpoints map[pod1:[80]] (1.031340767s elapsed)
STEP: Creating pod pod2 in namespace services-4369
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4369 to expose endpoints map[pod1:[80] pod2:[80]]
Sep 18 12:50:33.183: INFO: successfully validated that service endpoint-test2 in namespace services-4369 exposes endpoints map[pod1:[80] pod2:[80]] (2.068593113s elapsed)
STEP: Deleting pod pod1 in namespace services-4369
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4369 to expose endpoints map[pod2:[80]]
Sep 18 12:50:34.228: INFO: successfully validated that service endpoint-test2 in namespace services-4369 exposes endpoints map[pod2:[80]] (1.032001447s elapsed)
STEP: Deleting pod pod2 in namespace services-4369
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4369 to expose endpoints map[]
Sep 18 12:50:34.247: INFO: successfully validated that service endpoint-test2 in namespace services-4369 exposes endpoints map[] (7.110551ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:50:34.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4369" for this suite.
Sep 18 12:50:40.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:50:40.549: INFO: namespace services-4369 deletion completed in 6.251035334s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:10.626 seconds]
[sig-network] Services
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:50:40.549: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 12:50:40.618: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb7468c0-da12-11e9-8fe5-1a4434d30f67" in namespace "projected-2747" to be "success or failure"
Sep 18 12:50:40.625: INFO: Pod "downwardapi-volume-eb7468c0-da12-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.618354ms
Sep 18 12:50:42.633: INFO: Pod "downwardapi-volume-eb7468c0-da12-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014282722s
STEP: Saw pod success
Sep 18 12:50:42.633: INFO: Pod "downwardapi-volume-eb7468c0-da12-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:50:42.639: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-eb7468c0-da12-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 12:50:42.684: INFO: Waiting for pod downwardapi-volume-eb7468c0-da12-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:50:42.693: INFO: Pod downwardapi-volume-eb7468c0-da12-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:50:42.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2747" for this suite.
Sep 18 12:50:48.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:50:48.950: INFO: namespace projected-2747 deletion completed in 6.245850063s

• [SLOW TEST:8.400 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:50:48.950: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-f075eb76-da12-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume configMaps
Sep 18 12:50:49.026: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f07725ce-da12-11e9-8fe5-1a4434d30f67" in namespace "projected-984" to be "success or failure"
Sep 18 12:50:49.033: INFO: Pod "pod-projected-configmaps-f07725ce-da12-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.526386ms
Sep 18 12:50:51.040: INFO: Pod "pod-projected-configmaps-f07725ce-da12-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01378582s
STEP: Saw pod success
Sep 18 12:50:51.040: INFO: Pod "pod-projected-configmaps-f07725ce-da12-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:50:51.051: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-projected-configmaps-f07725ce-da12-11e9-8fe5-1a4434d30f67 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 18 12:50:51.093: INFO: Waiting for pod pod-projected-configmaps-f07725ce-da12-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:50:51.099: INFO: Pod pod-projected-configmaps-f07725ce-da12-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:50:51.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-984" for this suite.
Sep 18 12:50:57.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:50:57.356: INFO: namespace projected-984 deletion completed in 6.246406208s

• [SLOW TEST:8.406 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:50:57.356: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-f5797009-da12-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume secrets
Sep 18 12:50:57.436: INFO: Waiting up to 5m0s for pod "pod-secrets-f57abd75-da12-11e9-8fe5-1a4434d30f67" in namespace "secrets-7939" to be "success or failure"
Sep 18 12:50:57.443: INFO: Pod "pod-secrets-f57abd75-da12-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.77794ms
Sep 18 12:50:59.451: INFO: Pod "pod-secrets-f57abd75-da12-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014838147s
STEP: Saw pod success
Sep 18 12:50:59.451: INFO: Pod "pod-secrets-f57abd75-da12-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:50:59.458: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-secrets-f57abd75-da12-11e9-8fe5-1a4434d30f67 container secret-volume-test: <nil>
STEP: delete the pod
Sep 18 12:50:59.499: INFO: Waiting for pod pod-secrets-f57abd75-da12-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:50:59.506: INFO: Pod pod-secrets-f57abd75-da12-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:50:59.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7939" for this suite.
Sep 18 12:51:05.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:51:05.757: INFO: namespace secrets-7939 deletion completed in 6.240907957s

• [SLOW TEST:8.401 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:51:05.757: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Sep 18 12:51:05.823: INFO: Waiting up to 5m0s for pod "var-expansion-fa7a7315-da12-11e9-8fe5-1a4434d30f67" in namespace "var-expansion-6777" to be "success or failure"
Sep 18 12:51:05.833: INFO: Pod "var-expansion-fa7a7315-da12-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 9.648624ms
Sep 18 12:51:07.841: INFO: Pod "var-expansion-fa7a7315-da12-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017564879s
STEP: Saw pod success
Sep 18 12:51:07.841: INFO: Pod "var-expansion-fa7a7315-da12-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:51:07.848: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod var-expansion-fa7a7315-da12-11e9-8fe5-1a4434d30f67 container dapi-container: <nil>
STEP: delete the pod
Sep 18 12:51:07.897: INFO: Waiting for pod var-expansion-fa7a7315-da12-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:51:07.903: INFO: Pod var-expansion-fa7a7315-da12-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:51:07.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6777" for this suite.
Sep 18 12:51:13.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:51:14.158: INFO: namespace var-expansion-6777 deletion completed in 6.24399351s

• [SLOW TEST:8.401 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:51:14.158: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2786.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2786.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 18 12:51:16.325: INFO: DNS probes using dns-2786/dns-test-ff7d69fb-da12-11e9-8fe5-1a4434d30f67 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:51:16.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2786" for this suite.
Sep 18 12:51:22.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:51:22.614: INFO: namespace dns-2786 deletion completed in 6.254484672s

• [SLOW TEST:8.456 seconds]
[sig-network] DNS
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:51:22.614: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Sep 18 12:51:22.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 api-versions'
Sep 18 12:51:22.728: INFO: stderr: ""
Sep 18 12:51:22.728: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:51:22.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2777" for this suite.
Sep 18 12:51:28.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:51:28.983: INFO: namespace kubectl-2777 deletion completed in 6.243247896s

• [SLOW TEST:6.369 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:51:28.983: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 18 12:51:29.052: INFO: Waiting up to 5m0s for pod "pod-0852a5c3-da13-11e9-8fe5-1a4434d30f67" in namespace "emptydir-4478" to be "success or failure"
Sep 18 12:51:29.058: INFO: Pod "pod-0852a5c3-da13-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.578803ms
Sep 18 12:51:31.066: INFO: Pod "pod-0852a5c3-da13-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014437818s
STEP: Saw pod success
Sep 18 12:51:31.066: INFO: Pod "pod-0852a5c3-da13-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:51:31.073: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-0852a5c3-da13-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 12:51:31.111: INFO: Waiting for pod pod-0852a5c3-da13-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:51:31.118: INFO: Pod pod-0852a5c3-da13-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:51:31.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4478" for this suite.
Sep 18 12:51:37.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:51:37.375: INFO: namespace emptydir-4478 deletion completed in 6.246540217s

• [SLOW TEST:8.392 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:51:37.375: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0918 12:51:43.497526      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 18 12:51:43.497: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:51:43.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4075" for this suite.
Sep 18 12:51:51.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:51:51.760: INFO: namespace gc-4075 deletion completed in 8.252671413s

• [SLOW TEST:14.385 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:51:51.760: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 18 12:51:51.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-1369'
Sep 18 12:51:51.962: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 18 12:51:51.962: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Sep 18 12:51:51.977: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-wdnnl]
Sep 18 12:51:51.977: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-wdnnl" in namespace "kubectl-1369" to be "running and ready"
Sep 18 12:51:51.986: INFO: Pod "e2e-test-nginx-rc-wdnnl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.698678ms
Sep 18 12:51:53.994: INFO: Pod "e2e-test-nginx-rc-wdnnl": Phase="Running", Reason="", readiness=true. Elapsed: 2.016704253s
Sep 18 12:51:53.994: INFO: Pod "e2e-test-nginx-rc-wdnnl" satisfied condition "running and ready"
Sep 18 12:51:53.994: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-wdnnl]
Sep 18 12:51:53.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 logs rc/e2e-test-nginx-rc --namespace=kubectl-1369'
Sep 18 12:51:54.096: INFO: stderr: ""
Sep 18 12:51:54.096: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1425
Sep 18 12:51:54.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 delete rc e2e-test-nginx-rc --namespace=kubectl-1369'
Sep 18 12:51:54.175: INFO: stderr: ""
Sep 18 12:51:54.175: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:51:54.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1369" for this suite.
Sep 18 12:52:16.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:52:16.440: INFO: namespace kubectl-1369 deletion completed in 22.253910446s

• [SLOW TEST:24.680 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:52:16.440: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-249c6d19-da13-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume configMaps
Sep 18 12:52:16.519: INFO: Waiting up to 5m0s for pod "pod-configmaps-249d9c6c-da13-11e9-8fe5-1a4434d30f67" in namespace "configmap-5988" to be "success or failure"
Sep 18 12:52:16.527: INFO: Pod "pod-configmaps-249d9c6c-da13-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 8.476437ms
Sep 18 12:52:18.535: INFO: Pod "pod-configmaps-249d9c6c-da13-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016348726s
STEP: Saw pod success
Sep 18 12:52:18.535: INFO: Pod "pod-configmaps-249d9c6c-da13-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:52:18.542: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-configmaps-249d9c6c-da13-11e9-8fe5-1a4434d30f67 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 18 12:52:18.580: INFO: Waiting for pod pod-configmaps-249d9c6c-da13-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:52:18.587: INFO: Pod pod-configmaps-249d9c6c-da13-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:52:18.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5988" for this suite.
Sep 18 12:52:24.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:52:24.842: INFO: namespace configmap-5988 deletion completed in 6.244785069s

• [SLOW TEST:8.402 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:52:24.842: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6482
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-6482
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6482
Sep 18 12:52:24.925: INFO: Found 0 stateful pods, waiting for 1
Sep 18 12:52:34.934: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep 18 12:52:34.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 18 12:52:35.100: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 18 12:52:35.100: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 18 12:52:35.100: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 18 12:52:35.107: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 18 12:52:45.116: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 18 12:52:45.116: INFO: Waiting for statefulset status.replicas updated to 0
Sep 18 12:52:45.145: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Sep 18 12:52:45.145: INFO: ss-0  k8s-node-vm1qxh-95up3dyso1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  }]
Sep 18 12:52:45.145: INFO: 
Sep 18 12:52:45.145: INFO: StatefulSet ss has not reached scale 3, at 1
Sep 18 12:52:46.153: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992941828s
Sep 18 12:52:47.161: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985175215s
Sep 18 12:52:48.172: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.977118705s
Sep 18 12:52:49.179: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.966532494s
Sep 18 12:52:50.188: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.958935657s
Sep 18 12:52:51.196: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.950036336s
Sep 18 12:52:52.204: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.942306354s
Sep 18 12:52:53.211: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.934549144s
Sep 18 12:52:54.219: INFO: Verifying statefulset ss doesn't scale past 3 for another 927.075391ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6482
Sep 18 12:52:55.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:52:55.380: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 18 12:52:55.380: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 18 12:52:55.380: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 18 12:52:55.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:52:55.528: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 18 12:52:55.528: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 18 12:52:55.528: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 18 12:52:55.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:52:55.681: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 18 12:52:55.681: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 18 12:52:55.681: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 18 12:52:55.689: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Sep 18 12:53:05.696: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 18 12:53:05.696: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 18 12:53:05.696: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep 18 12:53:05.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 18 12:53:05.857: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 18 12:53:05.857: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 18 12:53:05.857: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 18 12:53:05.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 18 12:53:06.002: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 18 12:53:06.002: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 18 12:53:06.002: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 18 12:53:06.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 18 12:53:06.158: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 18 12:53:06.158: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 18 12:53:06.158: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 18 12:53:06.158: INFO: Waiting for statefulset status.replicas updated to 0
Sep 18 12:53:06.165: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Sep 18 12:53:16.180: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 18 12:53:16.180: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 18 12:53:16.180: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 18 12:53:16.203: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Sep 18 12:53:16.203: INFO: ss-0  k8s-node-vm1qxh-95up3dyso1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  }]
Sep 18 12:53:16.203: INFO: ss-1  k8s-node-vm599z-95up3dyso1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  }]
Sep 18 12:53:16.203: INFO: ss-2  k8s-node-vm1qxh-95up3dyso1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  }]
Sep 18 12:53:16.203: INFO: 
Sep 18 12:53:16.203: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 18 12:53:17.210: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Sep 18 12:53:17.210: INFO: ss-0  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  }]
Sep 18 12:53:17.210: INFO: ss-1  k8s-node-vm599z-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  }]
Sep 18 12:53:17.210: INFO: ss-2  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  }]
Sep 18 12:53:17.210: INFO: 
Sep 18 12:53:17.210: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 18 12:53:18.218: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Sep 18 12:53:18.218: INFO: ss-0  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  }]
Sep 18 12:53:18.218: INFO: ss-1  k8s-node-vm599z-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  }]
Sep 18 12:53:18.218: INFO: ss-2  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  }]
Sep 18 12:53:18.218: INFO: 
Sep 18 12:53:18.218: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 18 12:53:19.225: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Sep 18 12:53:19.225: INFO: ss-0  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  }]
Sep 18 12:53:19.225: INFO: ss-1  k8s-node-vm599z-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  }]
Sep 18 12:53:19.225: INFO: ss-2  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  }]
Sep 18 12:53:19.225: INFO: 
Sep 18 12:53:19.225: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 18 12:53:20.233: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Sep 18 12:53:20.233: INFO: ss-0  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  }]
Sep 18 12:53:20.233: INFO: ss-1  k8s-node-vm599z-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  }]
Sep 18 12:53:20.233: INFO: ss-2  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  }]
Sep 18 12:53:20.233: INFO: 
Sep 18 12:53:20.233: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 18 12:53:21.241: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Sep 18 12:53:21.241: INFO: ss-0  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  }]
Sep 18 12:53:21.241: INFO: ss-1  k8s-node-vm599z-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  }]
Sep 18 12:53:21.241: INFO: ss-2  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  }]
Sep 18 12:53:21.241: INFO: 
Sep 18 12:53:21.241: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 18 12:53:22.249: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Sep 18 12:53:22.249: INFO: ss-0  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  }]
Sep 18 12:53:22.249: INFO: ss-2  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  }]
Sep 18 12:53:22.249: INFO: 
Sep 18 12:53:22.249: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 18 12:53:23.257: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Sep 18 12:53:23.257: INFO: ss-0  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  }]
Sep 18 12:53:23.257: INFO: ss-2  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  }]
Sep 18 12:53:23.257: INFO: 
Sep 18 12:53:23.257: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 18 12:53:24.265: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Sep 18 12:53:24.265: INFO: ss-0  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  }]
Sep 18 12:53:24.265: INFO: ss-2  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  }]
Sep 18 12:53:24.265: INFO: 
Sep 18 12:53:24.265: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 18 12:53:25.273: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Sep 18 12:53:25.273: INFO: ss-0  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:24 +0000 UTC  }]
Sep 18 12:53:25.273: INFO: ss-2  k8s-node-vm1qxh-95up3dyso1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:53:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 12:52:45 +0000 UTC  }]
Sep 18 12:53:25.273: INFO: 
Sep 18 12:53:25.273: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6482
Sep 18 12:53:26.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:53:26.385: INFO: rc: 1
Sep 18 12:53:26.385: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc001e841e0 exit status 1 <nil> <nil> true [0xc002576a40 0xc002576a58 0xc002576a70] [0xc002576a40 0xc002576a58 0xc002576a70] [0xc002576a50 0xc002576a68] [0x9c0ae0 0x9c0ae0] 0xc000e6d200 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Sep 18 12:53:36.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:53:36.446: INFO: rc: 1
Sep 18 12:53:36.446: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002a92330 exit status 1 <nil> <nil> true [0xc0006660e0 0xc0006664c8 0xc000666610] [0xc0006660e0 0xc0006664c8 0xc000666610] [0xc0006663f0 0xc000666588] [0x9c0ae0 0x9c0ae0] 0xc002c9a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:53:46.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:53:46.505: INFO: rc: 1
Sep 18 12:53:46.506: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e72360 exit status 1 <nil> <nil> true [0xc000ef2020 0xc000ef20c8 0xc000ef2108] [0xc000ef2020 0xc000ef20c8 0xc000ef2108] [0xc000ef20a0 0xc000ef20f8] [0x9c0ae0 0x9c0ae0] 0xc002a485a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:53:56.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:53:56.565: INFO: rc: 1
Sep 18 12:53:56.565: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e726c0 exit status 1 <nil> <nil> true [0xc000ef2130 0xc000ef2190 0xc000ef21e0] [0xc000ef2130 0xc000ef2190 0xc000ef21e0] [0xc000ef2180 0xc000ef21c8] [0x9c0ae0 0x9c0ae0] 0xc002a48ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:54:06.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:54:06.625: INFO: rc: 1
Sep 18 12:54:06.625: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e72a20 exit status 1 <nil> <nil> true [0xc000ef2238 0xc000ef2290 0xc000ef22f0] [0xc000ef2238 0xc000ef2290 0xc000ef22f0] [0xc000ef2248 0xc000ef22e0] [0x9c0ae0 0x9c0ae0] 0xc002a48e40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:54:16.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:54:16.687: INFO: rc: 1
Sep 18 12:54:16.687: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e72db0 exit status 1 <nil> <nil> true [0xc000ef2310 0xc000ef23c8 0xc000ef2410] [0xc000ef2310 0xc000ef23c8 0xc000ef2410] [0xc000ef2370 0xc000ef23f8] [0x9c0ae0 0x9c0ae0] 0xc002a491a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:54:26.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:54:26.749: INFO: rc: 1
Sep 18 12:54:26.749: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e73140 exit status 1 <nil> <nil> true [0xc000ef2448 0xc000ef24e8 0xc000ef2558] [0xc000ef2448 0xc000ef24e8 0xc000ef2558] [0xc000ef24c0 0xc000ef2518] [0x9c0ae0 0x9c0ae0] 0xc002a49500 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:54:36.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:54:36.810: INFO: rc: 1
Sep 18 12:54:36.810: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002f1e360 exit status 1 <nil> <nil> true [0xc000a6c000 0xc000a6c158 0xc000a6c698] [0xc000a6c000 0xc000a6c158 0xc000a6c698] [0xc000a6c128 0xc000a6c238] [0x9c0ae0 0x9c0ae0] 0xc00315a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:54:46.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:54:46.872: INFO: rc: 1
Sep 18 12:54:46.872: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002f1e6c0 exit status 1 <nil> <nil> true [0xc000a6c7e8 0xc000a6ca78 0xc000a6d078] [0xc000a6c7e8 0xc000a6ca78 0xc000a6d078] [0xc000a6c9f0 0xc000a6cf10] [0x9c0ae0 0x9c0ae0] 0xc00315a600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:54:56.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:54:56.932: INFO: rc: 1
Sep 18 12:54:56.932: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0028ba390 exit status 1 <nil> <nil> true [0xc0000100c0 0xc0003c55a8 0xc0003c56b0] [0xc0000100c0 0xc0003c55a8 0xc0003c56b0] [0xc0003c5538 0xc0003c56a0] [0x9c0ae0 0x9c0ae0] 0xc002f262a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:55:06.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:55:06.993: INFO: rc: 1
Sep 18 12:55:06.993: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e734a0 exit status 1 <nil> <nil> true [0xc000ef2598 0xc000ef25f8 0xc000ef2698] [0xc000ef2598 0xc000ef25f8 0xc000ef2698] [0xc000ef25e8 0xc000ef2650] [0x9c0ae0 0x9c0ae0] 0xc002a49860 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:55:16.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:55:17.055: INFO: rc: 1
Sep 18 12:55:17.055: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002a926f0 exit status 1 <nil> <nil> true [0xc000666750 0xc000666940 0xc000666a98] [0xc000666750 0xc000666940 0xc000666a98] [0xc0006668c0 0xc000666a40] [0x9c0ae0 0x9c0ae0] 0xc002c9a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:55:27.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:55:27.120: INFO: rc: 1
Sep 18 12:55:27.120: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0028ba870 exit status 1 <nil> <nil> true [0xc0003c5708 0xc0003c5868 0xc0003c58e8] [0xc0003c5708 0xc0003c5868 0xc0003c58e8] [0xc0003c5830 0xc0003c58c8] [0x9c0ae0 0x9c0ae0] 0xc002f26600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:55:37.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:55:37.182: INFO: rc: 1
Sep 18 12:55:37.182: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002f1e330 exit status 1 <nil> <nil> true [0xc000a6c000 0xc000a6c158 0xc000a6c698] [0xc000a6c000 0xc000a6c158 0xc000a6c698] [0xc000a6c128 0xc000a6c238] [0x9c0ae0 0x9c0ae0] 0xc00315a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:55:47.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:55:47.250: INFO: rc: 1
Sep 18 12:55:47.250: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0028ba330 exit status 1 <nil> <nil> true [0xc0003c5300 0xc0003c5628 0xc0003c5708] [0xc0003c5300 0xc0003c5628 0xc0003c5708] [0xc0003c55a8 0xc0003c56b0] [0x9c0ae0 0x9c0ae0] 0xc002f262a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:55:57.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:55:57.311: INFO: rc: 1
Sep 18 12:55:57.311: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0028ba7e0 exit status 1 <nil> <nil> true [0xc0003c5728 0xc0003c5888 0xc0003c5928] [0xc0003c5728 0xc0003c5888 0xc0003c5928] [0xc0003c5868 0xc0003c58e8] [0x9c0ae0 0x9c0ae0] 0xc002f26600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:56:07.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:56:07.376: INFO: rc: 1
Sep 18 12:56:07.376: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0028babd0 exit status 1 <nil> <nil> true [0xc0003c5938 0xc0003c5dc8 0xc0003c5e38] [0xc0003c5938 0xc0003c5dc8 0xc0003c5e38] [0xc0003c5da0 0xc0003c5e18] [0x9c0ae0 0x9c0ae0] 0xc002f26960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:56:17.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:56:17.439: INFO: rc: 1
Sep 18 12:56:17.439: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e72330 exit status 1 <nil> <nil> true [0xc000ef2020 0xc000ef20c8 0xc000ef2108] [0xc000ef2020 0xc000ef20c8 0xc000ef2108] [0xc000ef20a0 0xc000ef20f8] [0x9c0ae0 0x9c0ae0] 0xc002a485a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:56:27.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:56:27.505: INFO: rc: 1
Sep 18 12:56:27.505: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002a92390 exit status 1 <nil> <nil> true [0xc000666010 0xc0006663f0 0xc000666588] [0xc000666010 0xc0006663f0 0xc000666588] [0xc000666318 0xc000666528] [0x9c0ae0 0x9c0ae0] 0xc002c9a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:56:37.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:56:37.567: INFO: rc: 1
Sep 18 12:56:37.567: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002a92750 exit status 1 <nil> <nil> true [0xc000666610 0xc0006668c0 0xc000666a40] [0xc000666610 0xc0006668c0 0xc000666a40] [0xc0006667f0 0xc0006669c0] [0x9c0ae0 0x9c0ae0] 0xc002c9a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:56:47.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:56:47.630: INFO: rc: 1
Sep 18 12:56:47.630: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002a92ae0 exit status 1 <nil> <nil> true [0xc000666a98 0xc000666be0 0xc000666eb8] [0xc000666a98 0xc000666be0 0xc000666eb8] [0xc000666b28 0xc000666dc8] [0x9c0ae0 0x9c0ae0] 0xc002c9a9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:56:57.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:56:57.695: INFO: rc: 1
Sep 18 12:56:57.695: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002f1e750 exit status 1 <nil> <nil> true [0xc000a6c7e8 0xc000a6ca78 0xc000a6d078] [0xc000a6c7e8 0xc000a6ca78 0xc000a6d078] [0xc000a6c9f0 0xc000a6cf10] [0x9c0ae0 0x9c0ae0] 0xc00315a600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:57:07.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:57:07.759: INFO: rc: 1
Sep 18 12:57:07.759: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e72720 exit status 1 <nil> <nil> true [0xc000ef2130 0xc000ef2190 0xc000ef21e0] [0xc000ef2130 0xc000ef2190 0xc000ef21e0] [0xc000ef2180 0xc000ef21c8] [0x9c0ae0 0x9c0ae0] 0xc002a48ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:57:17.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:57:17.821: INFO: rc: 1
Sep 18 12:57:17.821: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002f1eae0 exit status 1 <nil> <nil> true [0xc000a6d0d8 0xc000a6d320 0xc000a6d500] [0xc000a6d0d8 0xc000a6d320 0xc000a6d500] [0xc000a6d1e0 0xc000a6d3e0] [0x9c0ae0 0x9c0ae0] 0xc00315a960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:57:27.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:57:27.881: INFO: rc: 1
Sep 18 12:57:27.881: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e72ab0 exit status 1 <nil> <nil> true [0xc000ef2238 0xc000ef2290 0xc000ef22f0] [0xc000ef2238 0xc000ef2290 0xc000ef22f0] [0xc000ef2248 0xc000ef22e0] [0x9c0ae0 0x9c0ae0] 0xc002a48e40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:57:37.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:57:37.945: INFO: rc: 1
Sep 18 12:57:37.945: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002a92330 exit status 1 <nil> <nil> true [0xc000666010 0xc0006663f0 0xc000666588] [0xc000666010 0xc0006663f0 0xc000666588] [0xc000666318 0xc000666528] [0x9c0ae0 0x9c0ae0] 0xc002c9a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:57:47.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:57:48.006: INFO: rc: 1
Sep 18 12:57:48.006: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002f1e360 exit status 1 <nil> <nil> true [0xc0003c5300 0xc0003c5628 0xc0003c5708] [0xc0003c5300 0xc0003c5628 0xc0003c5708] [0xc0003c55a8 0xc0003c56b0] [0x9c0ae0 0x9c0ae0] 0xc00315a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:57:58.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:57:58.066: INFO: rc: 1
Sep 18 12:57:58.066: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002a926f0 exit status 1 <nil> <nil> true [0xc000666610 0xc0006668c0 0xc000666a40] [0xc000666610 0xc0006668c0 0xc000666a40] [0xc0006667f0 0xc0006669c0] [0x9c0ae0 0x9c0ae0] 0xc002c9a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:58:08.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:58:08.128: INFO: rc: 1
Sep 18 12:58:08.128: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0028ba3c0 exit status 1 <nil> <nil> true [0xc000a6c000 0xc000a6c158 0xc000a6c698] [0xc000a6c000 0xc000a6c158 0xc000a6c698] [0xc000a6c128 0xc000a6c238] [0x9c0ae0 0x9c0ae0] 0xc002f262a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:58:18.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:58:18.192: INFO: rc: 1
Sep 18 12:58:18.192: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002a92a80 exit status 1 <nil> <nil> true [0xc000666a98 0xc000666be0 0xc000666eb8] [0xc000666a98 0xc000666be0 0xc000666eb8] [0xc000666b28 0xc000666dc8] [0x9c0ae0 0x9c0ae0] 0xc002c9a9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep 18 12:58:28.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-6482 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 12:58:28.252: INFO: rc: 1
Sep 18 12:58:28.252: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Sep 18 12:58:28.252: INFO: Scaling statefulset ss to 0
Sep 18 12:58:28.273: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep 18 12:58:28.280: INFO: Deleting all statefulset in ns statefulset-6482
Sep 18 12:58:28.286: INFO: Scaling statefulset ss to 0
Sep 18 12:58:28.306: INFO: Waiting for statefulset status.replicas updated to 0
Sep 18 12:58:28.314: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:58:28.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6482" for this suite.
Sep 18 12:58:34.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:58:34.608: INFO: namespace statefulset-6482 deletion completed in 6.252767684s

• [SLOW TEST:369.766 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:58:34.609: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Sep 18 12:58:34.664: INFO: namespace kubectl-1049
Sep 18 12:58:34.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 create -f - --namespace=kubectl-1049'
Sep 18 12:58:34.783: INFO: stderr: ""
Sep 18 12:58:34.783: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 18 12:58:35.791: INFO: Selector matched 1 pods for map[app:redis]
Sep 18 12:58:35.791: INFO: Found 1 / 1
Sep 18 12:58:35.791: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 18 12:58:35.798: INFO: Selector matched 1 pods for map[app:redis]
Sep 18 12:58:35.798: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 18 12:58:35.798: INFO: wait on redis-master startup in kubectl-1049 
Sep 18 12:58:35.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 logs redis-master-2df7z redis-master --namespace=kubectl-1049'
Sep 18 12:58:35.887: INFO: stderr: ""
Sep 18 12:58:35.887: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Sep 12:58:35.357 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Sep 12:58:35.357 # Server started, Redis version 3.2.12\n1:M 18 Sep 12:58:35.357 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Sep 12:58:35.357 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Sep 18 12:58:35.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-1049'
Sep 18 12:58:35.985: INFO: stderr: ""
Sep 18 12:58:35.985: INFO: stdout: "service/rm2 exposed\n"
Sep 18 12:58:35.991: INFO: Service rm2 in namespace kubectl-1049 found.
STEP: exposing service
Sep 18 12:58:38.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-1049'
Sep 18 12:58:38.099: INFO: stderr: ""
Sep 18 12:58:38.099: INFO: stdout: "service/rm3 exposed\n"
Sep 18 12:58:38.107: INFO: Service rm3 in namespace kubectl-1049 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:58:40.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1049" for this suite.
Sep 18 12:59:02.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:59:02.386: INFO: namespace kubectl-1049 deletion completed in 22.253859642s

• [SLOW TEST:27.777 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:59:02.386: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Sep 18 12:59:02.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 create -f - --namespace=kubectl-9389'
Sep 18 12:59:02.569: INFO: stderr: ""
Sep 18 12:59:02.569: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 18 12:59:02.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9389'
Sep 18 12:59:02.639: INFO: stderr: ""
Sep 18 12:59:02.639: INFO: stdout: "update-demo-nautilus-6ctv2 update-demo-nautilus-mmk58 "
Sep 18 12:59:02.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-6ctv2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9389'
Sep 18 12:59:02.704: INFO: stderr: ""
Sep 18 12:59:02.704: INFO: stdout: ""
Sep 18 12:59:02.704: INFO: update-demo-nautilus-6ctv2 is created but not running
Sep 18 12:59:07.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9389'
Sep 18 12:59:07.777: INFO: stderr: ""
Sep 18 12:59:07.777: INFO: stdout: "update-demo-nautilus-6ctv2 update-demo-nautilus-mmk58 "
Sep 18 12:59:07.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-6ctv2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9389'
Sep 18 12:59:07.853: INFO: stderr: ""
Sep 18 12:59:07.853: INFO: stdout: "true"
Sep 18 12:59:07.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-6ctv2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9389'
Sep 18 12:59:07.919: INFO: stderr: ""
Sep 18 12:59:07.919: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 18 12:59:07.919: INFO: validating pod update-demo-nautilus-6ctv2
Sep 18 12:59:07.928: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 18 12:59:07.928: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 18 12:59:07.928: INFO: update-demo-nautilus-6ctv2 is verified up and running
Sep 18 12:59:07.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-mmk58 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9389'
Sep 18 12:59:07.995: INFO: stderr: ""
Sep 18 12:59:07.995: INFO: stdout: "true"
Sep 18 12:59:07.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-mmk58 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9389'
Sep 18 12:59:08.062: INFO: stderr: ""
Sep 18 12:59:08.062: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 18 12:59:08.062: INFO: validating pod update-demo-nautilus-mmk58
Sep 18 12:59:08.077: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 18 12:59:08.077: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 18 12:59:08.077: INFO: update-demo-nautilus-mmk58 is verified up and running
STEP: using delete to clean up resources
Sep 18 12:59:08.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 delete --grace-period=0 --force -f - --namespace=kubectl-9389'
Sep 18 12:59:08.160: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 18 12:59:08.160: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 18 12:59:08.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9389'
Sep 18 12:59:08.234: INFO: stderr: "No resources found.\n"
Sep 18 12:59:08.234: INFO: stdout: ""
Sep 18 12:59:08.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods -l name=update-demo --namespace=kubectl-9389 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 18 12:59:08.304: INFO: stderr: ""
Sep 18 12:59:08.304: INFO: stdout: "update-demo-nautilus-6ctv2\nupdate-demo-nautilus-mmk58\n"
Sep 18 12:59:08.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9389'
Sep 18 12:59:08.879: INFO: stderr: "No resources found.\n"
Sep 18 12:59:08.879: INFO: stdout: ""
Sep 18 12:59:08.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods -l name=update-demo --namespace=kubectl-9389 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 18 12:59:08.947: INFO: stderr: ""
Sep 18 12:59:08.947: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:59:08.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9389" for this suite.
Sep 18 12:59:14.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:59:15.209: INFO: namespace kubectl-9389 deletion completed in 6.251005817s

• [SLOW TEST:12.823 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:59:15.209: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Sep 18 12:59:15.282: INFO: Waiting up to 5m0s for pod "client-containers-1e37d6ff-da14-11e9-8fe5-1a4434d30f67" in namespace "containers-5331" to be "success or failure"
Sep 18 12:59:15.290: INFO: Pod "client-containers-1e37d6ff-da14-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.250993ms
Sep 18 12:59:17.298: INFO: Pod "client-containers-1e37d6ff-da14-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015339581s
STEP: Saw pod success
Sep 18 12:59:17.298: INFO: Pod "client-containers-1e37d6ff-da14-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 12:59:17.305: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod client-containers-1e37d6ff-da14-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 12:59:17.344: INFO: Waiting for pod client-containers-1e37d6ff-da14-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 12:59:17.351: INFO: Pod client-containers-1e37d6ff-da14-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 12:59:17.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5331" for this suite.
Sep 18 12:59:23.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 12:59:23.611: INFO: namespace containers-5331 deletion completed in 6.25021401s

• [SLOW TEST:8.402 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 12:59:23.611: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:00:23.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4760" for this suite.
Sep 18 13:00:45.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:00:45.986: INFO: namespace container-probe-4760 deletion completed in 22.287874961s

• [SLOW TEST:82.375 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:00:45.986: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-3164
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3164
STEP: Creating statefulset with conflicting port in namespace statefulset-3164
STEP: Waiting until pod test-pod will start running in namespace statefulset-3164
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3164
Sep 18 13:00:48.103: INFO: Observed stateful pod in namespace: statefulset-3164, name: ss-0, uid: 5509ff03-da14-11e9-b983-fa163edda742, status phase: Failed. Waiting for statefulset controller to delete.
Sep 18 13:00:48.107: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3164
STEP: Removing pod with conflicting port in namespace statefulset-3164
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3164 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep 18 13:00:52.159: INFO: Deleting all statefulset in ns statefulset-3164
Sep 18 13:00:52.166: INFO: Scaling statefulset ss to 0
Sep 18 13:01:02.199: INFO: Waiting for statefulset status.replicas updated to 0
Sep 18 13:01:02.207: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:01:02.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3164" for this suite.
Sep 18 13:01:08.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:01:08.503: INFO: namespace statefulset-3164 deletion completed in 6.255916497s

• [SLOW TEST:22.517 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:01:08.503: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Sep 18 13:01:08.975: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Sep 18 13:01:11.067: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704408468, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704408468, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704408469, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704408468, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 18 13:01:13.719: INFO: Waited 634.633416ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:01:14.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5664" for this suite.
Sep 18 13:01:20.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:01:20.498: INFO: namespace aggregator-5664 deletion completed in 6.309603742s

• [SLOW TEST:11.994 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:01:20.498: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 13:01:20.573: INFO: Waiting up to 5m0s for pod "downwardapi-volume-68e5a03a-da14-11e9-8fe5-1a4434d30f67" in namespace "projected-206" to be "success or failure"
Sep 18 13:01:20.581: INFO: Pod "downwardapi-volume-68e5a03a-da14-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.957546ms
Sep 18 13:01:22.589: INFO: Pod "downwardapi-volume-68e5a03a-da14-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015823198s
STEP: Saw pod success
Sep 18 13:01:22.589: INFO: Pod "downwardapi-volume-68e5a03a-da14-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:01:22.596: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-68e5a03a-da14-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 13:01:22.634: INFO: Waiting for pod downwardapi-volume-68e5a03a-da14-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:01:22.642: INFO: Pod downwardapi-volume-68e5a03a-da14-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:01:22.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-206" for this suite.
Sep 18 13:01:28.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:01:28.898: INFO: namespace projected-206 deletion completed in 6.24595055s

• [SLOW TEST:8.400 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:01:28.898: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep 18 13:01:28.965: INFO: Waiting up to 5m0s for pod "downward-api-6de66637-da14-11e9-8fe5-1a4434d30f67" in namespace "downward-api-8422" to be "success or failure"
Sep 18 13:01:28.973: INFO: Pod "downward-api-6de66637-da14-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.574468ms
Sep 18 13:01:30.981: INFO: Pod "downward-api-6de66637-da14-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01557686s
STEP: Saw pod success
Sep 18 13:01:30.981: INFO: Pod "downward-api-6de66637-da14-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:01:30.988: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downward-api-6de66637-da14-11e9-8fe5-1a4434d30f67 container dapi-container: <nil>
STEP: delete the pod
Sep 18 13:01:31.031: INFO: Waiting for pod downward-api-6de66637-da14-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:01:31.037: INFO: Pod downward-api-6de66637-da14-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:01:31.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8422" for this suite.
Sep 18 13:01:37.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:01:37.294: INFO: namespace downward-api-8422 deletion completed in 6.246882145s

• [SLOW TEST:8.396 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:01:37.295: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-72e84486-da14-11e9-8fe5-1a4434d30f67
Sep 18 13:01:37.375: INFO: Pod name my-hostname-basic-72e84486-da14-11e9-8fe5-1a4434d30f67: Found 0 pods out of 1
Sep 18 13:01:42.383: INFO: Pod name my-hostname-basic-72e84486-da14-11e9-8fe5-1a4434d30f67: Found 1 pods out of 1
Sep 18 13:01:42.383: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-72e84486-da14-11e9-8fe5-1a4434d30f67" are running
Sep 18 13:01:42.390: INFO: Pod "my-hostname-basic-72e84486-da14-11e9-8fe5-1a4434d30f67-nmr4n" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-18 13:01:37 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-18 13:01:38 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-18 13:01:38 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-18 13:01:37 +0000 UTC Reason: Message:}])
Sep 18 13:01:42.390: INFO: Trying to dial the pod
Sep 18 13:01:47.418: INFO: Controller my-hostname-basic-72e84486-da14-11e9-8fe5-1a4434d30f67: Got expected result from replica 1 [my-hostname-basic-72e84486-da14-11e9-8fe5-1a4434d30f67-nmr4n]: "my-hostname-basic-72e84486-da14-11e9-8fe5-1a4434d30f67-nmr4n", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:01:47.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6398" for this suite.
Sep 18 13:01:53.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:01:53.688: INFO: namespace replication-controller-6398 deletion completed in 6.257849913s

• [SLOW TEST:16.393 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:01:53.688: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-7caeb9fd-da14-11e9-8fe5-1a4434d30f67
STEP: Creating secret with name s-test-opt-upd-7caeba61-da14-11e9-8fe5-1a4434d30f67
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7caeb9fd-da14-11e9-8fe5-1a4434d30f67
STEP: Updating secret s-test-opt-upd-7caeba61-da14-11e9-8fe5-1a4434d30f67
STEP: Creating secret with name s-test-opt-create-7caeba77-da14-11e9-8fe5-1a4434d30f67
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:01:57.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4584" for this suite.
Sep 18 13:02:19.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:02:20.202: INFO: namespace secrets-4584 deletion completed in 22.247300563s

• [SLOW TEST:26.514 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:02:20.202: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep 18 13:02:24.329: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4907 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 13:02:24.329: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 13:02:24.424: INFO: Exec stderr: ""
Sep 18 13:02:24.424: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4907 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 13:02:24.424: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 13:02:24.512: INFO: Exec stderr: ""
Sep 18 13:02:24.512: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4907 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 13:02:24.512: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 13:02:24.600: INFO: Exec stderr: ""
Sep 18 13:02:24.600: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4907 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 13:02:24.600: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 13:02:24.686: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep 18 13:02:24.686: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4907 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 13:02:24.686: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 13:02:24.774: INFO: Exec stderr: ""
Sep 18 13:02:24.774: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4907 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 13:02:24.774: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 13:02:24.860: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep 18 13:02:24.860: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4907 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 13:02:24.860: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 13:02:24.947: INFO: Exec stderr: ""
Sep 18 13:02:24.947: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4907 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 13:02:24.947: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 13:02:25.034: INFO: Exec stderr: ""
Sep 18 13:02:25.034: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4907 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 13:02:25.034: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 13:02:25.121: INFO: Exec stderr: ""
Sep 18 13:02:25.121: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4907 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 13:02:25.121: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 13:02:25.208: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:02:25.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4907" for this suite.
Sep 18 13:03:09.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:03:09.463: INFO: namespace e2e-kubelet-etc-hosts-4907 deletion completed in 44.244557618s

• [SLOW TEST:49.261 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:03:09.464: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 13:03:09.559: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"a9dc5bad-da14-11e9-b983-fa163edda742", Controller:(*bool)(0xc002e206fa), BlockOwnerDeletion:(*bool)(0xc002e206fb)}}
Sep 18 13:03:09.572: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"a9d9b565-da14-11e9-b983-fa163edda742", Controller:(*bool)(0xc002e208ba), BlockOwnerDeletion:(*bool)(0xc002e208bb)}}
Sep 18 13:03:09.582: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"a9daf867-da14-11e9-b983-fa163edda742", Controller:(*bool)(0xc002e20a5a), BlockOwnerDeletion:(*bool)(0xc002e20a5b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:03:14.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2409" for this suite.
Sep 18 13:03:20.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:03:20.863: INFO: namespace gc-2409 deletion completed in 6.249550094s

• [SLOW TEST:11.400 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:03:20.864: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 13:03:20.933: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b0a35122-da14-11e9-8fe5-1a4434d30f67" in namespace "downward-api-9505" to be "success or failure"
Sep 18 13:03:20.940: INFO: Pod "downwardapi-volume-b0a35122-da14-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.662608ms
Sep 18 13:03:22.947: INFO: Pod "downwardapi-volume-b0a35122-da14-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014468543s
STEP: Saw pod success
Sep 18 13:03:22.947: INFO: Pod "downwardapi-volume-b0a35122-da14-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:03:22.955: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-b0a35122-da14-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 13:03:22.996: INFO: Waiting for pod downwardapi-volume-b0a35122-da14-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:03:23.002: INFO: Pod downwardapi-volume-b0a35122-da14-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:03:23.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9505" for this suite.
Sep 18 13:03:29.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:03:29.268: INFO: namespace downward-api-9505 deletion completed in 6.255382542s

• [SLOW TEST:8.405 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:03:29.268: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 13:03:29.337: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b5a58cb1-da14-11e9-8fe5-1a4434d30f67" in namespace "downward-api-6700" to be "success or failure"
Sep 18 13:03:29.347: INFO: Pod "downwardapi-volume-b5a58cb1-da14-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 9.337336ms
Sep 18 13:03:31.355: INFO: Pod "downwardapi-volume-b5a58cb1-da14-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017884844s
STEP: Saw pod success
Sep 18 13:03:31.355: INFO: Pod "downwardapi-volume-b5a58cb1-da14-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:03:31.362: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-b5a58cb1-da14-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 13:03:31.400: INFO: Waiting for pod downwardapi-volume-b5a58cb1-da14-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:03:31.407: INFO: Pod downwardapi-volume-b5a58cb1-da14-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:03:31.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6700" for this suite.
Sep 18 13:03:37.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:03:37.669: INFO: namespace downward-api-6700 deletion completed in 6.250807949s

• [SLOW TEST:8.401 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:03:37.669: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep 18 13:03:37.741: INFO: Pod name pod-release: Found 0 pods out of 1
Sep 18 13:03:42.749: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:03:43.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-123" for this suite.
Sep 18 13:03:49.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:03:50.039: INFO: namespace replication-controller-123 deletion completed in 6.244091897s

• [SLOW TEST:12.370 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:03:50.039: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Sep 18 13:03:50.095: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-496730594 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:03:50.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9384" for this suite.
Sep 18 13:03:56.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:03:56.405: INFO: namespace kubectl-9384 deletion completed in 6.242587081s

• [SLOW TEST:6.366 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:03:56.405: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 18 13:03:56.489: INFO: Waiting up to 5m0s for pod "pod-c5d46d37-da14-11e9-8fe5-1a4434d30f67" in namespace "emptydir-6163" to be "success or failure"
Sep 18 13:03:56.499: INFO: Pod "pod-c5d46d37-da14-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 10.485577ms
Sep 18 13:03:58.507: INFO: Pod "pod-c5d46d37-da14-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017971816s
STEP: Saw pod success
Sep 18 13:03:58.507: INFO: Pod "pod-c5d46d37-da14-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:03:58.513: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-c5d46d37-da14-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 13:03:58.554: INFO: Waiting for pod pod-c5d46d37-da14-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:03:58.561: INFO: Pod pod-c5d46d37-da14-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:03:58.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6163" for this suite.
Sep 18 13:04:04.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:04:04.813: INFO: namespace emptydir-6163 deletion completed in 6.241797927s

• [SLOW TEST:8.408 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:04:04.813: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-5215
I0918 13:04:04.877393      19 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5215, replica count: 1
I0918 13:04:05.927825      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 18 13:04:06.048: INFO: Created: latency-svc-8mf8w
Sep 18 13:04:06.056: INFO: Got endpoints: latency-svc-8mf8w [28.44378ms]
Sep 18 13:04:06.076: INFO: Created: latency-svc-76nd9
Sep 18 13:04:06.086: INFO: Created: latency-svc-lqq9l
Sep 18 13:04:06.087: INFO: Got endpoints: latency-svc-76nd9 [30.886915ms]
Sep 18 13:04:06.094: INFO: Got endpoints: latency-svc-lqq9l [38.261812ms]
Sep 18 13:04:06.098: INFO: Created: latency-svc-zdrrl
Sep 18 13:04:06.106: INFO: Got endpoints: latency-svc-zdrrl [49.402779ms]
Sep 18 13:04:06.107: INFO: Created: latency-svc-prt54
Sep 18 13:04:06.116: INFO: Got endpoints: latency-svc-prt54 [60.169347ms]
Sep 18 13:04:06.118: INFO: Created: latency-svc-vt5ps
Sep 18 13:04:06.126: INFO: Got endpoints: latency-svc-vt5ps [69.971163ms]
Sep 18 13:04:06.128: INFO: Created: latency-svc-2rqlx
Sep 18 13:04:06.136: INFO: Got endpoints: latency-svc-2rqlx [79.508478ms]
Sep 18 13:04:06.139: INFO: Created: latency-svc-xjxkz
Sep 18 13:04:06.147: INFO: Got endpoints: latency-svc-xjxkz [90.856609ms]
Sep 18 13:04:06.152: INFO: Created: latency-svc-mcs2p
Sep 18 13:04:06.160: INFO: Got endpoints: latency-svc-mcs2p [103.95139ms]
Sep 18 13:04:06.161: INFO: Created: latency-svc-n9vvp
Sep 18 13:04:06.169: INFO: Got endpoints: latency-svc-n9vvp [112.564095ms]
Sep 18 13:04:06.178: INFO: Created: latency-svc-th2cp
Sep 18 13:04:06.184: INFO: Created: latency-svc-hfgqr
Sep 18 13:04:06.187: INFO: Got endpoints: latency-svc-th2cp [130.448973ms]
Sep 18 13:04:06.193: INFO: Got endpoints: latency-svc-hfgqr [136.735647ms]
Sep 18 13:04:06.198: INFO: Created: latency-svc-tb6qx
Sep 18 13:04:06.210: INFO: Got endpoints: latency-svc-tb6qx [153.958815ms]
Sep 18 13:04:06.212: INFO: Created: latency-svc-bwmv9
Sep 18 13:04:06.219: INFO: Got endpoints: latency-svc-bwmv9 [163.01011ms]
Sep 18 13:04:06.221: INFO: Created: latency-svc-hgs8j
Sep 18 13:04:06.229: INFO: Got endpoints: latency-svc-hgs8j [172.616932ms]
Sep 18 13:04:06.232: INFO: Created: latency-svc-hdjq6
Sep 18 13:04:06.239: INFO: Got endpoints: latency-svc-hdjq6 [183.168507ms]
Sep 18 13:04:06.243: INFO: Created: latency-svc-nsvvl
Sep 18 13:04:06.250: INFO: Got endpoints: latency-svc-nsvvl [162.765739ms]
Sep 18 13:04:06.253: INFO: Created: latency-svc-znl7g
Sep 18 13:04:06.264: INFO: Got endpoints: latency-svc-znl7g [170.050231ms]
Sep 18 13:04:06.265: INFO: Created: latency-svc-28hnw
Sep 18 13:04:06.274: INFO: Got endpoints: latency-svc-28hnw [167.885691ms]
Sep 18 13:04:06.278: INFO: Created: latency-svc-9g86x
Sep 18 13:04:06.289: INFO: Created: latency-svc-xgm8c
Sep 18 13:04:06.290: INFO: Got endpoints: latency-svc-9g86x [173.638082ms]
Sep 18 13:04:06.298: INFO: Got endpoints: latency-svc-xgm8c [171.939275ms]
Sep 18 13:04:06.303: INFO: Created: latency-svc-td972
Sep 18 13:04:06.313: INFO: Got endpoints: latency-svc-td972 [177.309793ms]
Sep 18 13:04:06.314: INFO: Created: latency-svc-xhh5n
Sep 18 13:04:06.326: INFO: Got endpoints: latency-svc-xhh5n [179.021048ms]
Sep 18 13:04:06.330: INFO: Created: latency-svc-s6gjn
Sep 18 13:04:06.337: INFO: Got endpoints: latency-svc-s6gjn [176.793096ms]
Sep 18 13:04:06.342: INFO: Created: latency-svc-mvtmc
Sep 18 13:04:06.353: INFO: Created: latency-svc-gsd8q
Sep 18 13:04:06.354: INFO: Got endpoints: latency-svc-mvtmc [185.661309ms]
Sep 18 13:04:06.362: INFO: Got endpoints: latency-svc-gsd8q [175.618772ms]
Sep 18 13:04:06.364: INFO: Created: latency-svc-wvmkd
Sep 18 13:04:06.376: INFO: Created: latency-svc-n4l4j
Sep 18 13:04:06.378: INFO: Got endpoints: latency-svc-wvmkd [184.773767ms]
Sep 18 13:04:06.384: INFO: Got endpoints: latency-svc-n4l4j [173.568971ms]
Sep 18 13:04:06.388: INFO: Created: latency-svc-98nhl
Sep 18 13:04:06.395: INFO: Got endpoints: latency-svc-98nhl [175.32612ms]
Sep 18 13:04:06.402: INFO: Created: latency-svc-c5f26
Sep 18 13:04:06.410: INFO: Got endpoints: latency-svc-c5f26 [181.406138ms]
Sep 18 13:04:06.417: INFO: Created: latency-svc-ngs88
Sep 18 13:04:06.424: INFO: Got endpoints: latency-svc-ngs88 [184.784293ms]
Sep 18 13:04:06.429: INFO: Created: latency-svc-w8jwd
Sep 18 13:04:06.437: INFO: Got endpoints: latency-svc-w8jwd [186.972549ms]
Sep 18 13:04:06.440: INFO: Created: latency-svc-pqzp6
Sep 18 13:04:06.448: INFO: Got endpoints: latency-svc-pqzp6 [183.47454ms]
Sep 18 13:04:06.454: INFO: Created: latency-svc-44vmt
Sep 18 13:04:06.462: INFO: Created: latency-svc-t8vqd
Sep 18 13:04:06.465: INFO: Got endpoints: latency-svc-44vmt [191.614729ms]
Sep 18 13:04:06.472: INFO: Got endpoints: latency-svc-t8vqd [182.067759ms]
Sep 18 13:04:06.473: INFO: Created: latency-svc-rqr7g
Sep 18 13:04:06.482: INFO: Got endpoints: latency-svc-rqr7g [184.131172ms]
Sep 18 13:04:06.485: INFO: Created: latency-svc-7txz7
Sep 18 13:04:06.493: INFO: Got endpoints: latency-svc-7txz7 [180.160302ms]
Sep 18 13:04:06.497: INFO: Created: latency-svc-6qmzk
Sep 18 13:04:06.502: INFO: Got endpoints: latency-svc-6qmzk [175.704238ms]
Sep 18 13:04:06.508: INFO: Created: latency-svc-44qnt
Sep 18 13:04:06.518: INFO: Got endpoints: latency-svc-44qnt [181.174848ms]
Sep 18 13:04:06.523: INFO: Created: latency-svc-qg8cd
Sep 18 13:04:06.545: INFO: Created: latency-svc-wd2d7
Sep 18 13:04:06.556: INFO: Got endpoints: latency-svc-qg8cd [201.536487ms]
Sep 18 13:04:06.558: INFO: Created: latency-svc-bzprt
Sep 18 13:04:06.567: INFO: Created: latency-svc-hgm75
Sep 18 13:04:06.578: INFO: Created: latency-svc-szhjt
Sep 18 13:04:06.590: INFO: Created: latency-svc-b45nl
Sep 18 13:04:06.601: INFO: Created: latency-svc-rxpt6
Sep 18 13:04:06.608: INFO: Got endpoints: latency-svc-wd2d7 [245.25209ms]
Sep 18 13:04:06.614: INFO: Created: latency-svc-f8bsk
Sep 18 13:04:06.627: INFO: Created: latency-svc-hdl7g
Sep 18 13:04:06.639: INFO: Created: latency-svc-plpcq
Sep 18 13:04:06.649: INFO: Created: latency-svc-cj8rn
Sep 18 13:04:06.656: INFO: Got endpoints: latency-svc-bzprt [277.893763ms]
Sep 18 13:04:06.662: INFO: Created: latency-svc-9wdbr
Sep 18 13:04:06.675: INFO: Created: latency-svc-dn2ld
Sep 18 13:04:06.682: INFO: Created: latency-svc-tstzd
Sep 18 13:04:06.691: INFO: Created: latency-svc-gqsc7
Sep 18 13:04:06.703: INFO: Created: latency-svc-4d642
Sep 18 13:04:06.704: INFO: Got endpoints: latency-svc-hgm75 [320.418267ms]
Sep 18 13:04:06.713: INFO: Created: latency-svc-nmtms
Sep 18 13:04:06.723: INFO: Created: latency-svc-mlbc8
Sep 18 13:04:06.733: INFO: Created: latency-svc-t59xp
Sep 18 13:04:06.759: INFO: Got endpoints: latency-svc-szhjt [364.797371ms]
Sep 18 13:04:06.778: INFO: Created: latency-svc-pxxqm
Sep 18 13:04:06.805: INFO: Got endpoints: latency-svc-b45nl [394.833909ms]
Sep 18 13:04:06.823: INFO: Created: latency-svc-8xmbd
Sep 18 13:04:06.855: INFO: Got endpoints: latency-svc-rxpt6 [430.684728ms]
Sep 18 13:04:06.875: INFO: Created: latency-svc-8zhjb
Sep 18 13:04:06.905: INFO: Got endpoints: latency-svc-f8bsk [468.5235ms]
Sep 18 13:04:06.927: INFO: Created: latency-svc-fkdtl
Sep 18 13:04:06.956: INFO: Got endpoints: latency-svc-hdl7g [507.6645ms]
Sep 18 13:04:06.976: INFO: Created: latency-svc-tlh7c
Sep 18 13:04:07.006: INFO: Got endpoints: latency-svc-plpcq [540.892308ms]
Sep 18 13:04:07.026: INFO: Created: latency-svc-bhmsw
Sep 18 13:04:07.057: INFO: Got endpoints: latency-svc-cj8rn [584.760359ms]
Sep 18 13:04:07.075: INFO: Created: latency-svc-svxwh
Sep 18 13:04:07.105: INFO: Got endpoints: latency-svc-9wdbr [622.900866ms]
Sep 18 13:04:07.125: INFO: Created: latency-svc-ks4bg
Sep 18 13:04:07.156: INFO: Got endpoints: latency-svc-dn2ld [662.460264ms]
Sep 18 13:04:07.183: INFO: Created: latency-svc-9jdzw
Sep 18 13:04:07.206: INFO: Got endpoints: latency-svc-tstzd [704.639927ms]
Sep 18 13:04:07.225: INFO: Created: latency-svc-rlnd2
Sep 18 13:04:07.256: INFO: Got endpoints: latency-svc-gqsc7 [738.021164ms]
Sep 18 13:04:07.276: INFO: Created: latency-svc-cqmh2
Sep 18 13:04:07.306: INFO: Got endpoints: latency-svc-4d642 [749.461562ms]
Sep 18 13:04:07.329: INFO: Created: latency-svc-ffvqv
Sep 18 13:04:07.356: INFO: Got endpoints: latency-svc-nmtms [748.163687ms]
Sep 18 13:04:07.375: INFO: Created: latency-svc-qvk98
Sep 18 13:04:07.405: INFO: Got endpoints: latency-svc-mlbc8 [749.50064ms]
Sep 18 13:04:07.426: INFO: Created: latency-svc-bds88
Sep 18 13:04:07.456: INFO: Got endpoints: latency-svc-t59xp [751.778794ms]
Sep 18 13:04:07.478: INFO: Created: latency-svc-mxw7b
Sep 18 13:04:07.508: INFO: Got endpoints: latency-svc-pxxqm [748.30107ms]
Sep 18 13:04:07.530: INFO: Created: latency-svc-ks96b
Sep 18 13:04:07.557: INFO: Got endpoints: latency-svc-8xmbd [751.311145ms]
Sep 18 13:04:07.578: INFO: Created: latency-svc-2tm5d
Sep 18 13:04:07.607: INFO: Got endpoints: latency-svc-8zhjb [751.55502ms]
Sep 18 13:04:07.624: INFO: Created: latency-svc-mn52q
Sep 18 13:04:07.655: INFO: Got endpoints: latency-svc-fkdtl [749.918595ms]
Sep 18 13:04:07.674: INFO: Created: latency-svc-m7tvc
Sep 18 13:04:07.706: INFO: Got endpoints: latency-svc-tlh7c [749.921277ms]
Sep 18 13:04:07.725: INFO: Created: latency-svc-6j7gp
Sep 18 13:04:07.755: INFO: Got endpoints: latency-svc-bhmsw [748.843625ms]
Sep 18 13:04:07.774: INFO: Created: latency-svc-f7ppl
Sep 18 13:04:07.805: INFO: Got endpoints: latency-svc-svxwh [748.222546ms]
Sep 18 13:04:07.825: INFO: Created: latency-svc-42n5x
Sep 18 13:04:07.857: INFO: Got endpoints: latency-svc-ks4bg [751.482879ms]
Sep 18 13:04:07.875: INFO: Created: latency-svc-btf7m
Sep 18 13:04:07.905: INFO: Got endpoints: latency-svc-9jdzw [749.345026ms]
Sep 18 13:04:07.924: INFO: Created: latency-svc-sxmnr
Sep 18 13:04:07.955: INFO: Got endpoints: latency-svc-rlnd2 [748.848849ms]
Sep 18 13:04:07.977: INFO: Created: latency-svc-2c6lk
Sep 18 13:04:08.005: INFO: Got endpoints: latency-svc-cqmh2 [748.922797ms]
Sep 18 13:04:08.023: INFO: Created: latency-svc-c5td2
Sep 18 13:04:08.055: INFO: Got endpoints: latency-svc-ffvqv [749.613346ms]
Sep 18 13:04:08.073: INFO: Created: latency-svc-gb2f9
Sep 18 13:04:08.105: INFO: Got endpoints: latency-svc-qvk98 [749.587033ms]
Sep 18 13:04:08.127: INFO: Created: latency-svc-gwnxb
Sep 18 13:04:08.156: INFO: Got endpoints: latency-svc-bds88 [750.396503ms]
Sep 18 13:04:08.175: INFO: Created: latency-svc-97vd6
Sep 18 13:04:08.207: INFO: Got endpoints: latency-svc-mxw7b [751.063539ms]
Sep 18 13:04:08.225: INFO: Created: latency-svc-lf7rs
Sep 18 13:04:08.257: INFO: Got endpoints: latency-svc-ks96b [749.150577ms]
Sep 18 13:04:08.277: INFO: Created: latency-svc-v8vhf
Sep 18 13:04:08.307: INFO: Got endpoints: latency-svc-2tm5d [750.505697ms]
Sep 18 13:04:08.330: INFO: Created: latency-svc-xr222
Sep 18 13:04:08.357: INFO: Got endpoints: latency-svc-mn52q [750.375557ms]
Sep 18 13:04:08.379: INFO: Created: latency-svc-42c5t
Sep 18 13:04:08.406: INFO: Got endpoints: latency-svc-m7tvc [750.736772ms]
Sep 18 13:04:08.425: INFO: Created: latency-svc-vtb6l
Sep 18 13:04:08.455: INFO: Got endpoints: latency-svc-6j7gp [749.395813ms]
Sep 18 13:04:08.473: INFO: Created: latency-svc-8sw75
Sep 18 13:04:08.505: INFO: Got endpoints: latency-svc-f7ppl [750.142239ms]
Sep 18 13:04:08.527: INFO: Created: latency-svc-pmsb7
Sep 18 13:04:08.556: INFO: Got endpoints: latency-svc-42n5x [750.264366ms]
Sep 18 13:04:08.576: INFO: Created: latency-svc-czbxb
Sep 18 13:04:08.605: INFO: Got endpoints: latency-svc-btf7m [748.30846ms]
Sep 18 13:04:08.625: INFO: Created: latency-svc-g7lxp
Sep 18 13:04:08.656: INFO: Got endpoints: latency-svc-sxmnr [750.833321ms]
Sep 18 13:04:08.674: INFO: Created: latency-svc-jn5rb
Sep 18 13:04:08.706: INFO: Got endpoints: latency-svc-2c6lk [750.138196ms]
Sep 18 13:04:08.725: INFO: Created: latency-svc-j6fnt
Sep 18 13:04:08.755: INFO: Got endpoints: latency-svc-c5td2 [750.175086ms]
Sep 18 13:04:08.774: INFO: Created: latency-svc-grmqb
Sep 18 13:04:08.805: INFO: Got endpoints: latency-svc-gb2f9 [750.181329ms]
Sep 18 13:04:08.823: INFO: Created: latency-svc-hzlwx
Sep 18 13:04:08.855: INFO: Got endpoints: latency-svc-gwnxb [749.458419ms]
Sep 18 13:04:08.873: INFO: Created: latency-svc-trcnt
Sep 18 13:04:08.906: INFO: Got endpoints: latency-svc-97vd6 [750.732733ms]
Sep 18 13:04:08.925: INFO: Created: latency-svc-wf6wh
Sep 18 13:04:08.956: INFO: Got endpoints: latency-svc-lf7rs [748.333875ms]
Sep 18 13:04:08.974: INFO: Created: latency-svc-h8dzf
Sep 18 13:04:09.006: INFO: Got endpoints: latency-svc-v8vhf [748.698892ms]
Sep 18 13:04:09.024: INFO: Created: latency-svc-fh9b9
Sep 18 13:04:09.058: INFO: Got endpoints: latency-svc-xr222 [751.089124ms]
Sep 18 13:04:09.077: INFO: Created: latency-svc-pdfdj
Sep 18 13:04:09.106: INFO: Got endpoints: latency-svc-42c5t [748.624666ms]
Sep 18 13:04:09.124: INFO: Created: latency-svc-gx4vl
Sep 18 13:04:09.155: INFO: Got endpoints: latency-svc-vtb6l [749.32487ms]
Sep 18 13:04:09.174: INFO: Created: latency-svc-nhzm9
Sep 18 13:04:09.207: INFO: Got endpoints: latency-svc-8sw75 [752.035111ms]
Sep 18 13:04:09.228: INFO: Created: latency-svc-qnmhd
Sep 18 13:04:09.255: INFO: Got endpoints: latency-svc-pmsb7 [749.899744ms]
Sep 18 13:04:09.275: INFO: Created: latency-svc-22bsq
Sep 18 13:04:09.307: INFO: Got endpoints: latency-svc-czbxb [751.119505ms]
Sep 18 13:04:09.332: INFO: Created: latency-svc-lxj8m
Sep 18 13:04:09.356: INFO: Got endpoints: latency-svc-g7lxp [750.548596ms]
Sep 18 13:04:09.381: INFO: Created: latency-svc-587qv
Sep 18 13:04:09.405: INFO: Got endpoints: latency-svc-jn5rb [749.390187ms]
Sep 18 13:04:09.425: INFO: Created: latency-svc-qplxl
Sep 18 13:04:09.456: INFO: Got endpoints: latency-svc-j6fnt [750.060569ms]
Sep 18 13:04:09.475: INFO: Created: latency-svc-jjsrh
Sep 18 13:04:09.505: INFO: Got endpoints: latency-svc-grmqb [749.852489ms]
Sep 18 13:04:09.527: INFO: Created: latency-svc-tlv98
Sep 18 13:04:09.556: INFO: Got endpoints: latency-svc-hzlwx [750.622583ms]
Sep 18 13:04:09.574: INFO: Created: latency-svc-v85m2
Sep 18 13:04:09.605: INFO: Got endpoints: latency-svc-trcnt [750.423163ms]
Sep 18 13:04:09.623: INFO: Created: latency-svc-v2n8f
Sep 18 13:04:09.656: INFO: Got endpoints: latency-svc-wf6wh [749.405425ms]
Sep 18 13:04:09.673: INFO: Created: latency-svc-62x6m
Sep 18 13:04:09.706: INFO: Got endpoints: latency-svc-h8dzf [750.347707ms]
Sep 18 13:04:09.724: INFO: Created: latency-svc-t6hsh
Sep 18 13:04:09.756: INFO: Got endpoints: latency-svc-fh9b9 [749.841559ms]
Sep 18 13:04:09.773: INFO: Created: latency-svc-qwls6
Sep 18 13:04:09.806: INFO: Got endpoints: latency-svc-pdfdj [747.45697ms]
Sep 18 13:04:09.823: INFO: Created: latency-svc-87m4c
Sep 18 13:04:09.855: INFO: Got endpoints: latency-svc-gx4vl [749.389073ms]
Sep 18 13:04:09.873: INFO: Created: latency-svc-6h55d
Sep 18 13:04:09.906: INFO: Got endpoints: latency-svc-nhzm9 [750.73495ms]
Sep 18 13:04:09.925: INFO: Created: latency-svc-5lxw5
Sep 18 13:04:09.955: INFO: Got endpoints: latency-svc-qnmhd [748.272419ms]
Sep 18 13:04:09.974: INFO: Created: latency-svc-tfv5l
Sep 18 13:04:10.006: INFO: Got endpoints: latency-svc-22bsq [750.546445ms]
Sep 18 13:04:10.023: INFO: Created: latency-svc-htn8q
Sep 18 13:04:10.055: INFO: Got endpoints: latency-svc-lxj8m [748.060905ms]
Sep 18 13:04:10.081: INFO: Created: latency-svc-jjvgs
Sep 18 13:04:10.106: INFO: Got endpoints: latency-svc-587qv [750.047654ms]
Sep 18 13:04:10.125: INFO: Created: latency-svc-g9v2j
Sep 18 13:04:10.155: INFO: Got endpoints: latency-svc-qplxl [749.424703ms]
Sep 18 13:04:10.176: INFO: Created: latency-svc-dgbbv
Sep 18 13:04:10.208: INFO: Got endpoints: latency-svc-jjsrh [752.686513ms]
Sep 18 13:04:10.227: INFO: Created: latency-svc-n7rfz
Sep 18 13:04:10.263: INFO: Got endpoints: latency-svc-tlv98 [757.752114ms]
Sep 18 13:04:10.288: INFO: Created: latency-svc-4ggwj
Sep 18 13:04:10.309: INFO: Got endpoints: latency-svc-v85m2 [753.410193ms]
Sep 18 13:04:10.330: INFO: Created: latency-svc-wh8hj
Sep 18 13:04:10.360: INFO: Got endpoints: latency-svc-v2n8f [754.300467ms]
Sep 18 13:04:10.380: INFO: Created: latency-svc-6wh5d
Sep 18 13:04:10.406: INFO: Got endpoints: latency-svc-62x6m [749.83922ms]
Sep 18 13:04:10.427: INFO: Created: latency-svc-wjrrq
Sep 18 13:04:10.455: INFO: Got endpoints: latency-svc-t6hsh [749.271235ms]
Sep 18 13:04:10.474: INFO: Created: latency-svc-tqksz
Sep 18 13:04:10.506: INFO: Got endpoints: latency-svc-qwls6 [750.472091ms]
Sep 18 13:04:10.535: INFO: Created: latency-svc-hxm7t
Sep 18 13:04:10.555: INFO: Got endpoints: latency-svc-87m4c [749.625497ms]
Sep 18 13:04:10.575: INFO: Created: latency-svc-v5n67
Sep 18 13:04:10.606: INFO: Got endpoints: latency-svc-6h55d [750.581892ms]
Sep 18 13:04:10.624: INFO: Created: latency-svc-khvk2
Sep 18 13:04:10.655: INFO: Got endpoints: latency-svc-5lxw5 [748.717514ms]
Sep 18 13:04:10.673: INFO: Created: latency-svc-vw7df
Sep 18 13:04:10.706: INFO: Got endpoints: latency-svc-tfv5l [750.950295ms]
Sep 18 13:04:10.724: INFO: Created: latency-svc-z2874
Sep 18 13:04:10.755: INFO: Got endpoints: latency-svc-htn8q [749.676944ms]
Sep 18 13:04:10.776: INFO: Created: latency-svc-q928d
Sep 18 13:04:10.805: INFO: Got endpoints: latency-svc-jjvgs [750.035938ms]
Sep 18 13:04:10.823: INFO: Created: latency-svc-c454f
Sep 18 13:04:10.856: INFO: Got endpoints: latency-svc-g9v2j [749.759653ms]
Sep 18 13:04:10.875: INFO: Created: latency-svc-f7g4b
Sep 18 13:04:10.906: INFO: Got endpoints: latency-svc-dgbbv [750.946208ms]
Sep 18 13:04:10.924: INFO: Created: latency-svc-6lxjh
Sep 18 13:04:10.957: INFO: Got endpoints: latency-svc-n7rfz [748.247958ms]
Sep 18 13:04:10.977: INFO: Created: latency-svc-ljwc8
Sep 18 13:04:11.006: INFO: Got endpoints: latency-svc-4ggwj [742.552021ms]
Sep 18 13:04:11.023: INFO: Created: latency-svc-5x7v7
Sep 18 13:04:11.055: INFO: Got endpoints: latency-svc-wh8hj [745.749176ms]
Sep 18 13:04:11.074: INFO: Created: latency-svc-msq5q
Sep 18 13:04:11.106: INFO: Got endpoints: latency-svc-6wh5d [746.683384ms]
Sep 18 13:04:11.126: INFO: Created: latency-svc-rj4hc
Sep 18 13:04:11.156: INFO: Got endpoints: latency-svc-wjrrq [749.985583ms]
Sep 18 13:04:11.174: INFO: Created: latency-svc-sznvb
Sep 18 13:04:11.210: INFO: Got endpoints: latency-svc-tqksz [755.151199ms]
Sep 18 13:04:11.230: INFO: Created: latency-svc-hbnmv
Sep 18 13:04:11.258: INFO: Got endpoints: latency-svc-hxm7t [751.891326ms]
Sep 18 13:04:11.284: INFO: Created: latency-svc-kp58s
Sep 18 13:04:11.311: INFO: Got endpoints: latency-svc-v5n67 [755.963795ms]
Sep 18 13:04:11.333: INFO: Created: latency-svc-dh6fq
Sep 18 13:04:11.358: INFO: Got endpoints: latency-svc-khvk2 [752.766681ms]
Sep 18 13:04:11.381: INFO: Created: latency-svc-kbgj5
Sep 18 13:04:11.406: INFO: Got endpoints: latency-svc-vw7df [750.858856ms]
Sep 18 13:04:11.426: INFO: Created: latency-svc-66lws
Sep 18 13:04:11.456: INFO: Got endpoints: latency-svc-z2874 [749.901083ms]
Sep 18 13:04:11.475: INFO: Created: latency-svc-mw8tm
Sep 18 13:04:11.506: INFO: Got endpoints: latency-svc-q928d [750.475472ms]
Sep 18 13:04:11.524: INFO: Created: latency-svc-5nssx
Sep 18 13:04:11.556: INFO: Got endpoints: latency-svc-c454f [751.128889ms]
Sep 18 13:04:11.575: INFO: Created: latency-svc-57vfj
Sep 18 13:04:11.618: INFO: Got endpoints: latency-svc-f7g4b [762.472046ms]
Sep 18 13:04:11.636: INFO: Created: latency-svc-hfvzv
Sep 18 13:04:11.655: INFO: Got endpoints: latency-svc-6lxjh [749.124778ms]
Sep 18 13:04:11.672: INFO: Created: latency-svc-cvm8g
Sep 18 13:04:11.705: INFO: Got endpoints: latency-svc-ljwc8 [748.739078ms]
Sep 18 13:04:11.728: INFO: Created: latency-svc-5vwtx
Sep 18 13:04:11.756: INFO: Got endpoints: latency-svc-5x7v7 [749.883503ms]
Sep 18 13:04:11.777: INFO: Created: latency-svc-jq6h4
Sep 18 13:04:11.806: INFO: Got endpoints: latency-svc-msq5q [750.970472ms]
Sep 18 13:04:11.824: INFO: Created: latency-svc-jswtn
Sep 18 13:04:11.857: INFO: Got endpoints: latency-svc-rj4hc [750.901413ms]
Sep 18 13:04:11.875: INFO: Created: latency-svc-24zpz
Sep 18 13:04:11.906: INFO: Got endpoints: latency-svc-sznvb [750.251944ms]
Sep 18 13:04:11.927: INFO: Created: latency-svc-9ss77
Sep 18 13:04:11.956: INFO: Got endpoints: latency-svc-hbnmv [745.213461ms]
Sep 18 13:04:11.974: INFO: Created: latency-svc-j4558
Sep 18 13:04:12.005: INFO: Got endpoints: latency-svc-kp58s [747.225979ms]
Sep 18 13:04:12.023: INFO: Created: latency-svc-2g6z2
Sep 18 13:04:12.055: INFO: Got endpoints: latency-svc-dh6fq [743.699669ms]
Sep 18 13:04:12.075: INFO: Created: latency-svc-dsxkm
Sep 18 13:04:12.105: INFO: Got endpoints: latency-svc-kbgj5 [746.002949ms]
Sep 18 13:04:12.126: INFO: Created: latency-svc-kwgbs
Sep 18 13:04:12.155: INFO: Got endpoints: latency-svc-66lws [749.054616ms]
Sep 18 13:04:12.174: INFO: Created: latency-svc-tk66s
Sep 18 13:04:12.207: INFO: Got endpoints: latency-svc-mw8tm [750.284052ms]
Sep 18 13:04:12.228: INFO: Created: latency-svc-vkrth
Sep 18 13:04:12.255: INFO: Got endpoints: latency-svc-5nssx [749.33746ms]
Sep 18 13:04:12.274: INFO: Created: latency-svc-rfwvg
Sep 18 13:04:12.308: INFO: Got endpoints: latency-svc-57vfj [751.406402ms]
Sep 18 13:04:12.328: INFO: Created: latency-svc-q2q4g
Sep 18 13:04:12.358: INFO: Got endpoints: latency-svc-hfvzv [739.573908ms]
Sep 18 13:04:12.378: INFO: Created: latency-svc-wfvbv
Sep 18 13:04:12.407: INFO: Got endpoints: latency-svc-cvm8g [752.014183ms]
Sep 18 13:04:12.426: INFO: Created: latency-svc-nkndw
Sep 18 13:04:12.455: INFO: Got endpoints: latency-svc-5vwtx [749.360606ms]
Sep 18 13:04:12.473: INFO: Created: latency-svc-26k2k
Sep 18 13:04:12.506: INFO: Got endpoints: latency-svc-jq6h4 [749.939758ms]
Sep 18 13:04:12.524: INFO: Created: latency-svc-ggtpb
Sep 18 13:04:12.557: INFO: Got endpoints: latency-svc-jswtn [750.669352ms]
Sep 18 13:04:12.574: INFO: Created: latency-svc-fwlpq
Sep 18 13:04:12.605: INFO: Got endpoints: latency-svc-24zpz [747.326416ms]
Sep 18 13:04:12.623: INFO: Created: latency-svc-l6zkr
Sep 18 13:04:12.655: INFO: Got endpoints: latency-svc-9ss77 [748.912261ms]
Sep 18 13:04:12.674: INFO: Created: latency-svc-mvm5c
Sep 18 13:04:12.706: INFO: Got endpoints: latency-svc-j4558 [750.415559ms]
Sep 18 13:04:12.725: INFO: Created: latency-svc-7kcnb
Sep 18 13:04:12.756: INFO: Got endpoints: latency-svc-2g6z2 [750.665896ms]
Sep 18 13:04:12.776: INFO: Created: latency-svc-8wql9
Sep 18 13:04:12.806: INFO: Got endpoints: latency-svc-dsxkm [750.52654ms]
Sep 18 13:04:12.823: INFO: Created: latency-svc-h5fqx
Sep 18 13:04:12.858: INFO: Got endpoints: latency-svc-kwgbs [753.464485ms]
Sep 18 13:04:12.876: INFO: Created: latency-svc-tf25j
Sep 18 13:04:12.907: INFO: Got endpoints: latency-svc-tk66s [751.614017ms]
Sep 18 13:04:12.925: INFO: Created: latency-svc-8x4kp
Sep 18 13:04:12.955: INFO: Got endpoints: latency-svc-vkrth [748.624224ms]
Sep 18 13:04:12.974: INFO: Created: latency-svc-w4dkp
Sep 18 13:04:13.006: INFO: Got endpoints: latency-svc-rfwvg [751.118935ms]
Sep 18 13:04:13.024: INFO: Created: latency-svc-h7q6g
Sep 18 13:04:13.055: INFO: Got endpoints: latency-svc-q2q4g [747.61051ms]
Sep 18 13:04:13.075: INFO: Created: latency-svc-4v9p7
Sep 18 13:04:13.105: INFO: Got endpoints: latency-svc-wfvbv [747.224169ms]
Sep 18 13:04:13.124: INFO: Created: latency-svc-8w7f9
Sep 18 13:04:13.156: INFO: Got endpoints: latency-svc-nkndw [748.822345ms]
Sep 18 13:04:13.176: INFO: Created: latency-svc-g9glk
Sep 18 13:04:13.207: INFO: Got endpoints: latency-svc-26k2k [751.927316ms]
Sep 18 13:04:13.229: INFO: Created: latency-svc-thphz
Sep 18 13:04:13.254: INFO: Got endpoints: latency-svc-ggtpb [748.853237ms]
Sep 18 13:04:13.277: INFO: Created: latency-svc-stns8
Sep 18 13:04:13.307: INFO: Got endpoints: latency-svc-fwlpq [750.002417ms]
Sep 18 13:04:13.329: INFO: Created: latency-svc-lbgp8
Sep 18 13:04:13.357: INFO: Got endpoints: latency-svc-l6zkr [751.89104ms]
Sep 18 13:04:13.377: INFO: Created: latency-svc-czj68
Sep 18 13:04:13.407: INFO: Got endpoints: latency-svc-mvm5c [751.579483ms]
Sep 18 13:04:13.427: INFO: Created: latency-svc-w76w2
Sep 18 13:04:13.455: INFO: Got endpoints: latency-svc-7kcnb [748.67201ms]
Sep 18 13:04:13.477: INFO: Created: latency-svc-8dm9j
Sep 18 13:04:13.505: INFO: Got endpoints: latency-svc-8wql9 [748.909279ms]
Sep 18 13:04:13.523: INFO: Created: latency-svc-ljg57
Sep 18 13:04:13.556: INFO: Got endpoints: latency-svc-h5fqx [750.173008ms]
Sep 18 13:04:13.573: INFO: Created: latency-svc-wtcwl
Sep 18 13:04:13.606: INFO: Got endpoints: latency-svc-tf25j [747.867224ms]
Sep 18 13:04:13.626: INFO: Created: latency-svc-r965c
Sep 18 13:04:13.654: INFO: Got endpoints: latency-svc-8x4kp [747.860414ms]
Sep 18 13:04:13.672: INFO: Created: latency-svc-nsdm7
Sep 18 13:04:13.705: INFO: Got endpoints: latency-svc-w4dkp [749.806534ms]
Sep 18 13:04:13.724: INFO: Created: latency-svc-gvqwb
Sep 18 13:04:13.755: INFO: Got endpoints: latency-svc-h7q6g [748.537472ms]
Sep 18 13:04:13.778: INFO: Created: latency-svc-frgtz
Sep 18 13:04:13.806: INFO: Got endpoints: latency-svc-4v9p7 [750.799834ms]
Sep 18 13:04:13.826: INFO: Created: latency-svc-jd5nz
Sep 18 13:04:13.855: INFO: Got endpoints: latency-svc-8w7f9 [750.48488ms]
Sep 18 13:04:13.873: INFO: Created: latency-svc-wrc2m
Sep 18 13:04:13.905: INFO: Got endpoints: latency-svc-g9glk [749.537498ms]
Sep 18 13:04:13.955: INFO: Got endpoints: latency-svc-thphz [748.633205ms]
Sep 18 13:04:14.006: INFO: Got endpoints: latency-svc-stns8 [751.03256ms]
Sep 18 13:04:14.056: INFO: Got endpoints: latency-svc-lbgp8 [749.092122ms]
Sep 18 13:04:14.106: INFO: Got endpoints: latency-svc-czj68 [749.219446ms]
Sep 18 13:04:14.156: INFO: Got endpoints: latency-svc-w76w2 [749.670739ms]
Sep 18 13:04:14.206: INFO: Got endpoints: latency-svc-8dm9j [751.056207ms]
Sep 18 13:04:14.255: INFO: Got endpoints: latency-svc-ljg57 [750.207101ms]
Sep 18 13:04:14.307: INFO: Got endpoints: latency-svc-wtcwl [751.216683ms]
Sep 18 13:04:14.360: INFO: Got endpoints: latency-svc-r965c [754.054026ms]
Sep 18 13:04:14.406: INFO: Got endpoints: latency-svc-nsdm7 [751.325021ms]
Sep 18 13:04:14.456: INFO: Got endpoints: latency-svc-gvqwb [750.708007ms]
Sep 18 13:04:14.507: INFO: Got endpoints: latency-svc-frgtz [752.194802ms]
Sep 18 13:04:14.556: INFO: Got endpoints: latency-svc-jd5nz [749.488926ms]
Sep 18 13:04:14.605: INFO: Got endpoints: latency-svc-wrc2m [749.694933ms]
Sep 18 13:04:14.605: INFO: Latencies: [30.886915ms 38.261812ms 49.402779ms 60.169347ms 69.971163ms 79.508478ms 90.856609ms 103.95139ms 112.564095ms 130.448973ms 136.735647ms 153.958815ms 162.765739ms 163.01011ms 167.885691ms 170.050231ms 171.939275ms 172.616932ms 173.568971ms 173.638082ms 175.32612ms 175.618772ms 175.704238ms 176.793096ms 177.309793ms 179.021048ms 180.160302ms 181.174848ms 181.406138ms 182.067759ms 183.168507ms 183.47454ms 184.131172ms 184.773767ms 184.784293ms 185.661309ms 186.972549ms 191.614729ms 201.536487ms 245.25209ms 277.893763ms 320.418267ms 364.797371ms 394.833909ms 430.684728ms 468.5235ms 507.6645ms 540.892308ms 584.760359ms 622.900866ms 662.460264ms 704.639927ms 738.021164ms 739.573908ms 742.552021ms 743.699669ms 745.213461ms 745.749176ms 746.002949ms 746.683384ms 747.224169ms 747.225979ms 747.326416ms 747.45697ms 747.61051ms 747.860414ms 747.867224ms 748.060905ms 748.163687ms 748.222546ms 748.247958ms 748.272419ms 748.30107ms 748.30846ms 748.333875ms 748.537472ms 748.624224ms 748.624666ms 748.633205ms 748.67201ms 748.698892ms 748.717514ms 748.739078ms 748.822345ms 748.843625ms 748.848849ms 748.853237ms 748.909279ms 748.912261ms 748.922797ms 749.054616ms 749.092122ms 749.124778ms 749.150577ms 749.219446ms 749.271235ms 749.32487ms 749.33746ms 749.345026ms 749.360606ms 749.389073ms 749.390187ms 749.395813ms 749.405425ms 749.424703ms 749.458419ms 749.461562ms 749.488926ms 749.50064ms 749.537498ms 749.587033ms 749.613346ms 749.625497ms 749.670739ms 749.676944ms 749.694933ms 749.759653ms 749.806534ms 749.83922ms 749.841559ms 749.852489ms 749.883503ms 749.899744ms 749.901083ms 749.918595ms 749.921277ms 749.939758ms 749.985583ms 750.002417ms 750.035938ms 750.047654ms 750.060569ms 750.138196ms 750.142239ms 750.173008ms 750.175086ms 750.181329ms 750.207101ms 750.251944ms 750.264366ms 750.284052ms 750.347707ms 750.375557ms 750.396503ms 750.415559ms 750.423163ms 750.472091ms 750.475472ms 750.48488ms 750.505697ms 750.52654ms 750.546445ms 750.548596ms 750.581892ms 750.622583ms 750.665896ms 750.669352ms 750.708007ms 750.732733ms 750.73495ms 750.736772ms 750.799834ms 750.833321ms 750.858856ms 750.901413ms 750.946208ms 750.950295ms 750.970472ms 751.03256ms 751.056207ms 751.063539ms 751.089124ms 751.118935ms 751.119505ms 751.128889ms 751.216683ms 751.311145ms 751.325021ms 751.406402ms 751.482879ms 751.55502ms 751.579483ms 751.614017ms 751.778794ms 751.89104ms 751.891326ms 751.927316ms 752.014183ms 752.035111ms 752.194802ms 752.686513ms 752.766681ms 753.410193ms 753.464485ms 754.054026ms 754.300467ms 755.151199ms 755.963795ms 757.752114ms 762.472046ms]
Sep 18 13:04:14.605: INFO: 50 %ile: 749.389073ms
Sep 18 13:04:14.605: INFO: 90 %ile: 751.55502ms
Sep 18 13:04:14.605: INFO: 99 %ile: 757.752114ms
Sep 18 13:04:14.605: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:04:14.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-5215" for this suite.
Sep 18 13:04:30.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:04:30.877: INFO: namespace svc-latency-5215 deletion completed in 16.258276633s

• [SLOW TEST:26.063 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:04:30.877: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-da5e0f46-da14-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume secrets
Sep 18 13:04:30.955: INFO: Waiting up to 5m0s for pod "pod-secrets-da5f4803-da14-11e9-8fe5-1a4434d30f67" in namespace "secrets-1069" to be "success or failure"
Sep 18 13:04:30.962: INFO: Pod "pod-secrets-da5f4803-da14-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.604961ms
Sep 18 13:04:32.969: INFO: Pod "pod-secrets-da5f4803-da14-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014354871s
STEP: Saw pod success
Sep 18 13:04:32.969: INFO: Pod "pod-secrets-da5f4803-da14-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:04:32.976: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-secrets-da5f4803-da14-11e9-8fe5-1a4434d30f67 container secret-volume-test: <nil>
STEP: delete the pod
Sep 18 13:04:33.015: INFO: Waiting for pod pod-secrets-da5f4803-da14-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:04:33.022: INFO: Pod pod-secrets-da5f4803-da14-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:04:33.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1069" for this suite.
Sep 18 13:04:39.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:04:39.284: INFO: namespace secrets-1069 deletion completed in 6.2516179s

• [SLOW TEST:8.407 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:04:39.284: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-df619445-da14-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume configMaps
Sep 18 13:04:39.364: INFO: Waiting up to 5m0s for pod "pod-configmaps-df62de31-da14-11e9-8fe5-1a4434d30f67" in namespace "configmap-4870" to be "success or failure"
Sep 18 13:04:39.370: INFO: Pod "pod-configmaps-df62de31-da14-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.762246ms
Sep 18 13:04:41.379: INFO: Pod "pod-configmaps-df62de31-da14-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014959942s
STEP: Saw pod success
Sep 18 13:04:41.379: INFO: Pod "pod-configmaps-df62de31-da14-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:04:41.385: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-configmaps-df62de31-da14-11e9-8fe5-1a4434d30f67 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 18 13:04:41.426: INFO: Waiting for pod pod-configmaps-df62de31-da14-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:04:41.432: INFO: Pod pod-configmaps-df62de31-da14-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:04:41.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4870" for this suite.
Sep 18 13:04:47.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:04:47.692: INFO: namespace configmap-4870 deletion completed in 6.249129729s

• [SLOW TEST:8.408 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:04:47.692: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6794.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6794.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6794.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6794.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6794.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6794.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6794.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6794.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6794.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6794.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6794.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6794.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6794.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 8.250.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.250.8_udp@PTR;check="$$(dig +tcp +noall +answer +search 8.250.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.250.8_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6794.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6794.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6794.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6794.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6794.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6794.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6794.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6794.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6794.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6794.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6794.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6794.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6794.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 8.250.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.250.8_udp@PTR;check="$$(dig +tcp +noall +answer +search 8.250.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.250.8_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 18 13:04:49.834: INFO: Unable to read wheezy_udp@dns-test-service.dns-6794.svc.cluster.local from pod dns-6794/dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67: the server could not find the requested resource (get pods dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67)
Sep 18 13:04:49.843: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6794.svc.cluster.local from pod dns-6794/dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67: the server could not find the requested resource (get pods dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67)
Sep 18 13:04:49.851: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6794.svc.cluster.local from pod dns-6794/dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67: the server could not find the requested resource (get pods dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67)
Sep 18 13:04:49.859: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6794.svc.cluster.local from pod dns-6794/dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67: the server could not find the requested resource (get pods dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67)
Sep 18 13:04:49.918: INFO: Unable to read jessie_udp@dns-test-service.dns-6794.svc.cluster.local from pod dns-6794/dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67: the server could not find the requested resource (get pods dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67)
Sep 18 13:04:49.927: INFO: Unable to read jessie_tcp@dns-test-service.dns-6794.svc.cluster.local from pod dns-6794/dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67: the server could not find the requested resource (get pods dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67)
Sep 18 13:04:49.935: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6794.svc.cluster.local from pod dns-6794/dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67: the server could not find the requested resource (get pods dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67)
Sep 18 13:04:49.943: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6794.svc.cluster.local from pod dns-6794/dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67: the server could not find the requested resource (get pods dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67)
Sep 18 13:04:49.992: INFO: Lookups using dns-6794/dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67 failed for: [wheezy_udp@dns-test-service.dns-6794.svc.cluster.local wheezy_tcp@dns-test-service.dns-6794.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6794.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6794.svc.cluster.local jessie_udp@dns-test-service.dns-6794.svc.cluster.local jessie_tcp@dns-test-service.dns-6794.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6794.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6794.svc.cluster.local]

Sep 18 13:04:55.162: INFO: DNS probes using dns-6794/dns-test-e4687223-da14-11e9-8fe5-1a4434d30f67 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:04:55.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6794" for this suite.
Sep 18 13:05:01.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:05:01.543: INFO: namespace dns-6794 deletion completed in 6.250771558s

• [SLOW TEST:13.851 seconds]
[sig-network] DNS
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:05:01.543: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9667
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Sep 18 13:05:01.624: INFO: Found 0 stateful pods, waiting for 3
Sep 18 13:05:11.633: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 18 13:05:11.633: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 18 13:05:11.633: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep 18 13:05:11.680: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep 18 13:05:21.738: INFO: Updating stateful set ss2
Sep 18 13:05:21.753: INFO: Waiting for Pod statefulset-9667/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Sep 18 13:05:31.830: INFO: Found 2 stateful pods, waiting for 3
Sep 18 13:05:41.838: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 18 13:05:41.838: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 18 13:05:41.838: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep 18 13:05:41.878: INFO: Updating stateful set ss2
Sep 18 13:05:41.892: INFO: Waiting for Pod statefulset-9667/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep 18 13:05:51.941: INFO: Updating stateful set ss2
Sep 18 13:05:51.958: INFO: Waiting for StatefulSet statefulset-9667/ss2 to complete update
Sep 18 13:05:51.958: INFO: Waiting for Pod statefulset-9667/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep 18 13:06:01.973: INFO: Waiting for StatefulSet statefulset-9667/ss2 to complete update
Sep 18 13:06:01.973: INFO: Waiting for Pod statefulset-9667/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep 18 13:06:11.973: INFO: Deleting all statefulset in ns statefulset-9667
Sep 18 13:06:11.980: INFO: Scaling statefulset ss2 to 0
Sep 18 13:06:32.012: INFO: Waiting for statefulset status.replicas updated to 0
Sep 18 13:06:32.019: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:06:32.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9667" for this suite.
Sep 18 13:06:40.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:06:40.310: INFO: namespace statefulset-9667 deletion completed in 8.251271241s

• [SLOW TEST:98.767 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:06:40.311: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 18 13:06:42.931: INFO: Successfully updated pod "pod-update-activedeadlineseconds-27847f0e-da15-11e9-8fe5-1a4434d30f67"
Sep 18 13:06:42.931: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-27847f0e-da15-11e9-8fe5-1a4434d30f67" in namespace "pods-8743" to be "terminated due to deadline exceeded"
Sep 18 13:06:42.937: INFO: Pod "pod-update-activedeadlineseconds-27847f0e-da15-11e9-8fe5-1a4434d30f67": Phase="Running", Reason="", readiness=true. Elapsed: 6.723862ms
Sep 18 13:06:44.945: INFO: Pod "pod-update-activedeadlineseconds-27847f0e-da15-11e9-8fe5-1a4434d30f67": Phase="Running", Reason="", readiness=true. Elapsed: 2.014765134s
Sep 18 13:06:46.953: INFO: Pod "pod-update-activedeadlineseconds-27847f0e-da15-11e9-8fe5-1a4434d30f67": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.022513813s
Sep 18 13:06:46.953: INFO: Pod "pod-update-activedeadlineseconds-27847f0e-da15-11e9-8fe5-1a4434d30f67" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:06:46.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8743" for this suite.
Sep 18 13:06:52.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:06:53.207: INFO: namespace pods-8743 deletion completed in 6.242974021s

• [SLOW TEST:12.896 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:06:53.207: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-2f34ac02-da15-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume configMaps
Sep 18 13:06:53.288: INFO: Waiting up to 5m0s for pod "pod-configmaps-2f35e2f7-da15-11e9-8fe5-1a4434d30f67" in namespace "configmap-7147" to be "success or failure"
Sep 18 13:06:53.296: INFO: Pod "pod-configmaps-2f35e2f7-da15-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 8.099313ms
Sep 18 13:06:55.304: INFO: Pod "pod-configmaps-2f35e2f7-da15-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016090232s
STEP: Saw pod success
Sep 18 13:06:55.304: INFO: Pod "pod-configmaps-2f35e2f7-da15-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:06:55.311: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-configmaps-2f35e2f7-da15-11e9-8fe5-1a4434d30f67 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 18 13:06:55.352: INFO: Waiting for pod pod-configmaps-2f35e2f7-da15-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:06:55.359: INFO: Pod pod-configmaps-2f35e2f7-da15-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:06:55.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7147" for this suite.
Sep 18 13:07:01.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:07:01.617: INFO: namespace configmap-7147 deletion completed in 6.247853407s

• [SLOW TEST:8.410 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:07:01.618: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 13:07:01.693: INFO: (0) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.988459ms)
Sep 18 13:07:01.702: INFO: (1) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.818668ms)
Sep 18 13:07:01.711: INFO: (2) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.637635ms)
Sep 18 13:07:01.720: INFO: (3) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.5501ms)
Sep 18 13:07:01.728: INFO: (4) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.501138ms)
Sep 18 13:07:01.737: INFO: (5) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.68334ms)
Sep 18 13:07:01.746: INFO: (6) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.796215ms)
Sep 18 13:07:01.754: INFO: (7) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.736436ms)
Sep 18 13:07:01.763: INFO: (8) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.616985ms)
Sep 18 13:07:01.772: INFO: (9) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.580881ms)
Sep 18 13:07:01.780: INFO: (10) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.51863ms)
Sep 18 13:07:01.789: INFO: (11) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.44237ms)
Sep 18 13:07:01.797: INFO: (12) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.540789ms)
Sep 18 13:07:01.806: INFO: (13) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.608297ms)
Sep 18 13:07:01.814: INFO: (14) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.504521ms)
Sep 18 13:07:01.823: INFO: (15) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.638755ms)
Sep 18 13:07:01.832: INFO: (16) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.644977ms)
Sep 18 13:07:01.840: INFO: (17) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.531334ms)
Sep 18 13:07:01.849: INFO: (18) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.54544ms)
Sep 18 13:07:01.857: INFO: (19) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.533134ms)
[AfterEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:07:01.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8333" for this suite.
Sep 18 13:07:07.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:07:08.123: INFO: namespace proxy-8333 deletion completed in 6.255103784s

• [SLOW TEST:6.505 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:07:08.123: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Sep 18 13:07:08.189: INFO: Waiting up to 5m0s for pod "pod-3817cf82-da15-11e9-8fe5-1a4434d30f67" in namespace "emptydir-9765" to be "success or failure"
Sep 18 13:07:08.195: INFO: Pod "pod-3817cf82-da15-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.561631ms
Sep 18 13:07:10.203: INFO: Pod "pod-3817cf82-da15-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014071367s
STEP: Saw pod success
Sep 18 13:07:10.203: INFO: Pod "pod-3817cf82-da15-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:07:10.210: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-3817cf82-da15-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 13:07:10.249: INFO: Waiting for pod pod-3817cf82-da15-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:07:10.255: INFO: Pod pod-3817cf82-da15-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:07:10.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9765" for this suite.
Sep 18 13:07:16.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:07:16.521: INFO: namespace emptydir-9765 deletion completed in 6.255274988s

• [SLOW TEST:8.398 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:07:16.522: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 18 13:07:16.652: INFO: Number of nodes with available pods: 0
Sep 18 13:07:16.652: INFO: Node k8s-node-vm1qxh-95up3dyso1 is running more than one daemon pod
Sep 18 13:07:17.670: INFO: Number of nodes with available pods: 0
Sep 18 13:07:17.670: INFO: Node k8s-node-vm1qxh-95up3dyso1 is running more than one daemon pod
Sep 18 13:07:18.670: INFO: Number of nodes with available pods: 2
Sep 18 13:07:18.670: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep 18 13:07:18.713: INFO: Number of nodes with available pods: 1
Sep 18 13:07:18.713: INFO: Node k8s-node-vm1qxh-95up3dyso1 is running more than one daemon pod
Sep 18 13:07:19.732: INFO: Number of nodes with available pods: 1
Sep 18 13:07:19.732: INFO: Node k8s-node-vm1qxh-95up3dyso1 is running more than one daemon pod
Sep 18 13:07:20.733: INFO: Number of nodes with available pods: 2
Sep 18 13:07:20.733: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4595, will wait for the garbage collector to delete the pods
Sep 18 13:07:20.830: INFO: Deleting DaemonSet.extensions daemon-set took: 25.294466ms
Sep 18 13:07:21.131: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.38674ms
Sep 18 13:07:31.938: INFO: Number of nodes with available pods: 0
Sep 18 13:07:31.938: INFO: Number of running nodes: 0, number of available pods: 0
Sep 18 13:07:31.946: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4595/daemonsets","resourceVersion":"231194"},"items":null}

Sep 18 13:07:31.952: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4595/pods","resourceVersion":"231194"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:07:31.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4595" for this suite.
Sep 18 13:07:38.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:07:38.239: INFO: namespace daemonsets-4595 deletion completed in 6.246578736s

• [SLOW TEST:21.718 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:07:38.240: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-4a0d9a5a-da15-11e9-8fe5-1a4434d30f67
STEP: Creating configMap with name cm-test-opt-upd-4a0d9a86-da15-11e9-8fe5-1a4434d30f67
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-4a0d9a5a-da15-11e9-8fe5-1a4434d30f67
STEP: Updating configmap cm-test-opt-upd-4a0d9a86-da15-11e9-8fe5-1a4434d30f67
STEP: Creating configMap with name cm-test-opt-create-4a0d9a98-da15-11e9-8fe5-1a4434d30f67
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:08:45.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1593" for this suite.
Sep 18 13:09:07.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:09:07.345: INFO: namespace projected-1593 deletion completed in 22.244141468s

• [SLOW TEST:89.106 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:09:07.346: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 13:09:07.421: INFO: (0) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.757304ms)
Sep 18 13:09:07.429: INFO: (1) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.467271ms)
Sep 18 13:09:07.438: INFO: (2) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.574721ms)
Sep 18 13:09:07.446: INFO: (3) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.468663ms)
Sep 18 13:09:07.455: INFO: (4) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.573585ms)
Sep 18 13:09:07.464: INFO: (5) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.62713ms)
Sep 18 13:09:07.473: INFO: (6) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.002556ms)
Sep 18 13:09:07.482: INFO: (7) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.699696ms)
Sep 18 13:09:07.492: INFO: (8) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.859341ms)
Sep 18 13:09:07.501: INFO: (9) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.79629ms)
Sep 18 13:09:07.510: INFO: (10) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.598563ms)
Sep 18 13:09:07.518: INFO: (11) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.608551ms)
Sep 18 13:09:07.527: INFO: (12) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.511076ms)
Sep 18 13:09:07.535: INFO: (13) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.626601ms)
Sep 18 13:09:07.544: INFO: (14) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.624078ms)
Sep 18 13:09:07.553: INFO: (15) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.793674ms)
Sep 18 13:09:07.561: INFO: (16) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.623082ms)
Sep 18 13:09:07.570: INFO: (17) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.746713ms)
Sep 18 13:09:07.579: INFO: (18) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.632056ms)
Sep 18 13:09:07.587: INFO: (19) /api/v1/nodes/k8s-node-vm1qxh-95up3dyso1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.579205ms)
[AfterEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:09:07.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2664" for this suite.
Sep 18 13:09:13.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:09:13.838: INFO: namespace proxy-2664 deletion completed in 6.240039124s

• [SLOW TEST:6.492 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:09:13.838: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep 18 13:09:13.951: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-5193,SelfLink:/api/v1/namespaces/watch-5193/configmaps/e2e-watch-test-resource-version,UID:83086b75-da15-11e9-b983-fa163edda742,ResourceVersion:231485,Generation:0,CreationTimestamp:2019-09-18 13:09:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 18 13:09:13.951: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-5193,SelfLink:/api/v1/namespaces/watch-5193/configmaps/e2e-watch-test-resource-version,UID:83086b75-da15-11e9-b983-fa163edda742,ResourceVersion:231486,Generation:0,CreationTimestamp:2019-09-18 13:09:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:09:13.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5193" for this suite.
Sep 18 13:09:19.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:09:20.209: INFO: namespace watch-5193 deletion completed in 6.246806142s

• [SLOW TEST:6.370 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:09:20.209: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 18 13:09:20.277: INFO: Waiting up to 5m0s for pod "pod-86d2dffa-da15-11e9-8fe5-1a4434d30f67" in namespace "emptydir-1316" to be "success or failure"
Sep 18 13:09:20.283: INFO: Pod "pod-86d2dffa-da15-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.570601ms
Sep 18 13:09:22.291: INFO: Pod "pod-86d2dffa-da15-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014514408s
STEP: Saw pod success
Sep 18 13:09:22.291: INFO: Pod "pod-86d2dffa-da15-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:09:22.298: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-86d2dffa-da15-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 13:09:22.341: INFO: Waiting for pod pod-86d2dffa-da15-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:09:22.349: INFO: Pod pod-86d2dffa-da15-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:09:22.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1316" for this suite.
Sep 18 13:09:28.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:09:28.612: INFO: namespace emptydir-1316 deletion completed in 6.252939748s

• [SLOW TEST:8.404 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:09:28.612: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 13:09:28.666: INFO: Creating deployment "nginx-deployment"
Sep 18 13:09:28.677: INFO: Waiting for observed generation 1
Sep 18 13:09:30.692: INFO: Waiting for all required pods to come up
Sep 18 13:09:30.702: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep 18 13:09:32.719: INFO: Waiting for deployment "nginx-deployment" to complete
Sep 18 13:09:32.733: INFO: Updating deployment "nginx-deployment" with a non-existent image
Sep 18 13:09:32.749: INFO: Updating deployment nginx-deployment
Sep 18 13:09:32.749: INFO: Waiting for observed generation 2
Sep 18 13:09:34.765: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep 18 13:09:34.771: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep 18 13:09:34.778: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep 18 13:09:34.798: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep 18 13:09:34.799: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep 18 13:09:34.805: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep 18 13:09:34.818: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Sep 18 13:09:34.818: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Sep 18 13:09:34.834: INFO: Updating deployment nginx-deployment
Sep 18 13:09:34.834: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Sep 18 13:09:34.852: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep 18 13:09:34.866: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep 18 13:09:36.896: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-7119,SelfLink:/apis/apps/v1/namespaces/deployment-7119/deployments/nginx-deployment,UID:8bd6a1fa-da15-11e9-b983-fa163edda742,ResourceVersion:231842,Generation:3,CreationTimestamp:2019-09-18 13:09:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:12,UnavailableReplicas:21,Conditions:[{Available False 2019-09-18 13:09:34 +0000 UTC 2019-09-18 13:09:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-18 13:09:36 +0000 UTC 2019-09-18 13:09:28 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-b79c9d74d" is progressing.}],ReadyReplicas:12,CollisionCount:nil,},}

Sep 18 13:09:36.903: INFO: New ReplicaSet "nginx-deployment-b79c9d74d" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d,GenerateName:,Namespace:deployment-7119,SelfLink:/apis/apps/v1/namespaces/deployment-7119/replicasets/nginx-deployment-b79c9d74d,UID:8e457abf-da15-11e9-b983-fa163edda742,ResourceVersion:231786,Generation:3,CreationTimestamp:2019-09-18 13:09:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8bd6a1fa-da15-11e9-b983-fa163edda742 0xc000309b07 0xc000309b08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 18 13:09:36.903: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Sep 18 13:09:36.903: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5,GenerateName:,Namespace:deployment-7119,SelfLink:/apis/apps/v1/namespaces/deployment-7119/replicasets/nginx-deployment-85db8c99c5,UID:8bd8129e-da15-11e9-b983-fa163edda742,ResourceVersion:231841,Generation:3,CreationTimestamp:2019-09-18 13:09:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8bd6a1fa-da15-11e9-b983-fa163edda742 0xc000309487 0xc000309488}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:12,AvailableReplicas:12,Conditions:[],},}
Sep 18 13:09:36.917: INFO: Pod "nginx-deployment-85db8c99c5-4kmx5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-4kmx5,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-4kmx5,UID:8f88f0df-da15-11e9-b983-fa163edda742,ResourceVersion:231857,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc0025afb87 0xc0025afb88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1qxh-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025afbf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025afc10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:36 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.5,PodIP:,StartTime:2019-09-18 13:09:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.917: INFO: Pod "nginx-deployment-85db8c99c5-5z85p" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-5z85p,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-5z85p,UID:8bde1273-da15-11e9-b983-fa163edda742,ResourceVersion:231630,Generation:0,CreationTimestamp:2019-09-18 13:09:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc0025afce0 0xc0025afce1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm599z-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025afd40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025afd60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.6,PodIP:10.0.192.6,StartTime:2019-09-18 13:09:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-18 13:09:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://bb57e8a3a2c62508017d3f180a4091348b5fb046a36dde44f4533c9200743409}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.917: INFO: Pod "nginx-deployment-85db8c99c5-78g9k" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-78g9k,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-78g9k,UID:8bda1563-da15-11e9-b983-fa163edda742,ResourceVersion:231625,Generation:0,CreationTimestamp:2019-09-18 13:09:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc0025afe40 0xc0025afe41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1qxh-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025afea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025afec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:28 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.5,PodIP:10.0.192.16,StartTime:2019-09-18 13:09:28 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-18 13:09:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://fdc31414f856d564c7147a7c0a71233ac453bc6d0e76281218c0df465cf65c34}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.917: INFO: Pod "nginx-deployment-85db8c99c5-8ngxj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-8ngxj,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-8ngxj,UID:8f88d6cb-da15-11e9-b983-fa163edda742,ResourceVersion:231825,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc0025aff90 0xc0025aff91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm599z-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025afff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d98010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.6,PodIP:,StartTime:2019-09-18 13:09:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.917: INFO: Pod "nginx-deployment-85db8c99c5-cb2lq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-cb2lq,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-cb2lq,UID:8f861e2c-da15-11e9-b983-fa163edda742,ResourceVersion:231829,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc001d980f0 0xc001d980f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1qxh-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d98150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d98180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:34 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.5,PodIP:10.0.192.19,StartTime:2019-09-18 13:09:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-18 13:09:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://e5b6117ca437f24fabf5440a6edf820da2c226d5976c7d3bf2b44ff7cf963575}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.917: INFO: Pod "nginx-deployment-85db8c99c5-cz462" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-cz462,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-cz462,UID:8f88de75-da15-11e9-b983-fa163edda742,ResourceVersion:231832,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc001d98260 0xc001d98261}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1qxh-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d982f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d98310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.5,PodIP:10.0.192.29,StartTime:2019-09-18 13:09:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-18 13:09:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://b39e01f64e789001720d90cbf4ae8143eeeb3f526a5e5f61e12ba4e4f0dc443f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.917: INFO: Pod "nginx-deployment-85db8c99c5-d9zq6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-d9zq6,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-d9zq6,UID:8bdff526-da15-11e9-b983-fa163edda742,ResourceVersion:231660,Generation:0,CreationTimestamp:2019-09-18 13:09:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc001d98420 0xc001d98421}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm599z-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d98480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d984a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.6,PodIP:10.0.192.10,StartTime:2019-09-18 13:09:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-18 13:09:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://e119e75e1535151fe9f3577954b89a5ee7ce30292a053f17ab47f7d4584acf35}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.917: INFO: Pod "nginx-deployment-85db8c99c5-fkwhm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-fkwhm,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-fkwhm,UID:8f8c108a-da15-11e9-b983-fa163edda742,ResourceVersion:231761,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc001d98580 0xc001d98581}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d985e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d98600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.917: INFO: Pod "nginx-deployment-85db8c99c5-g9d6k" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-g9d6k,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-g9d6k,UID:8bde24b2-da15-11e9-b983-fa163edda742,ResourceVersion:231655,Generation:0,CreationTimestamp:2019-09-18 13:09:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc001d98670 0xc001d98671}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1qxh-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d986d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d986f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.5,PodIP:10.0.192.18,StartTime:2019-09-18 13:09:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-18 13:09:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://5ddd497f6e51df5be7cc06644daa5a595cae16d80455c41cb3b00e718477280a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.917: INFO: Pod "nginx-deployment-85db8c99c5-gctwj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-gctwj,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-gctwj,UID:8bdb9926-da15-11e9-b983-fa163edda742,ResourceVersion:231621,Generation:0,CreationTimestamp:2019-09-18 13:09:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc001d987c0 0xc001d987c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1qxh-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d98820} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d98840}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:28 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.5,PodIP:10.0.192.30,StartTime:2019-09-18 13:09:28 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-18 13:09:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://9ee8a3a3f740dc18e0e2fb00d09d92382fbc53f308320c4eb470992ac0a2c93a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.918: INFO: Pod "nginx-deployment-85db8c99c5-h8q4v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-h8q4v,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-h8q4v,UID:8f8c2c5e-da15-11e9-b983-fa163edda742,ResourceVersion:231766,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc001d98910 0xc001d98911}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d98970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d98990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.918: INFO: Pod "nginx-deployment-85db8c99c5-hf6vg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-hf6vg,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-hf6vg,UID:8f8c2248-da15-11e9-b983-fa163edda742,ResourceVersion:231765,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc001d98a00 0xc001d98a01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d98a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d98a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.918: INFO: Pod "nginx-deployment-85db8c99c5-lm69h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-lm69h,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-lm69h,UID:8f8c1828-da15-11e9-b983-fa163edda742,ResourceVersion:231763,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc001d98af0 0xc001d98af1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d98b50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d98b70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.918: INFO: Pod "nginx-deployment-85db8c99c5-lsbsg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-lsbsg,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-lsbsg,UID:8f865a65-da15-11e9-b983-fa163edda742,ResourceVersion:231837,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc001d98bf0 0xc001d98bf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm599z-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d98c50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d98c70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:34 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.6,PodIP:10.0.192.9,StartTime:2019-09-18 13:09:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-18 13:09:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://f89038f66037477456a0481a95ae4c758449806942e100125efbe540a322e27d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.918: INFO: Pod "nginx-deployment-85db8c99c5-p56rf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-p56rf,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-p56rf,UID:8bdb765b-da15-11e9-b983-fa163edda742,ResourceVersion:231635,Generation:0,CreationTimestamp:2019-09-18 13:09:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc001d98d40 0xc001d98d41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm599z-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d98db0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d98dd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:28 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.6,PodIP:10.0.192.49,StartTime:2019-09-18 13:09:28 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-18 13:09:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://a8034c0d83f8e53b2c713318dc82f47f3b28f9c4b766791dff4f40f7cc6d5f47}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.918: INFO: Pod "nginx-deployment-85db8c99c5-p86vq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-p86vq,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-p86vq,UID:8f88ec65-da15-11e9-b983-fa163edda742,ResourceVersion:231852,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc001d98ea0 0xc001d98ea1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1qxh-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d98f10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d98f30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:36 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.5,PodIP:,StartTime:2019-09-18 13:09:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.918: INFO: Pod "nginx-deployment-85db8c99c5-stj27" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-stj27,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-stj27,UID:8f8c2437-da15-11e9-b983-fa163edda742,ResourceVersion:231762,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc001d98ff0 0xc001d98ff1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d99050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d99080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.918: INFO: Pod "nginx-deployment-85db8c99c5-tshlr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-tshlr,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-tshlr,UID:8f84c6bd-da15-11e9-b983-fa163edda742,ResourceVersion:231839,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc001d990f0 0xc001d990f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm599z-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d99150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d99170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:34 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.6,PodIP:10.0.192.12,StartTime:2019-09-18 13:09:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-18 13:09:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://d84cf97d06d5852ebe2a508282a3053662c46fc7cb1a495a95e305430ee6e979}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.918: INFO: Pod "nginx-deployment-85db8c99c5-vkrnw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-vkrnw,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-vkrnw,UID:8bddfc0d-da15-11e9-b983-fa163edda742,ResourceVersion:231619,Generation:0,CreationTimestamp:2019-09-18 13:09:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc001d99250 0xc001d99251}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1qxh-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d992b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d992d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:28 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.5,PodIP:10.0.192.17,StartTime:2019-09-18 13:09:28 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-18 13:09:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://1e808dea5fa5f47445f1c94df769b362118e6532078066290753f5b180f90a3c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.919: INFO: Pod "nginx-deployment-85db8c99c5-vxmpg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-vxmpg,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-85db8c99c5-vxmpg,UID:8bddee45-da15-11e9-b983-fa163edda742,ResourceVersion:231628,Generation:0,CreationTimestamp:2019-09-18 13:09:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 8bd8129e-da15-11e9-b983-fa163edda742 0xc001d993a0 0xc001d993a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm599z-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d99400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d99420}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:28 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.6,PodIP:10.0.192.7,StartTime:2019-09-18 13:09:28 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-18 13:09:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://70c4af9486caa1502ae6f3b6d41b3d3deb19329cc6f10b46f651494ef890da5f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.919: INFO: Pod "nginx-deployment-b79c9d74d-5c7b7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-5c7b7,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-b79c9d74d-5c7b7,UID:8f8c001c-da15-11e9-b983-fa163edda742,ResourceVersion:231759,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 8e457abf-da15-11e9-b983-fa163edda742 0xc001d994f0 0xc001d994f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d99560} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d99580}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.919: INFO: Pod "nginx-deployment-b79c9d74d-6vldd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-6vldd,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-b79c9d74d-6vldd,UID:8f88d28d-da15-11e9-b983-fa163edda742,ResourceVersion:231845,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 8e457abf-da15-11e9-b983-fa163edda742 0xc001d995f0 0xc001d995f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1qxh-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d99660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d99680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:36 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.5,PodIP:,StartTime:2019-09-18 13:09:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.919: INFO: Pod "nginx-deployment-b79c9d74d-7qmr2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-7qmr2,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-b79c9d74d-7qmr2,UID:8f8c0c5a-da15-11e9-b983-fa163edda742,ResourceVersion:231760,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 8e457abf-da15-11e9-b983-fa163edda742 0xc001d99750 0xc001d99751}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d997c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d997e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.919: INFO: Pod "nginx-deployment-b79c9d74d-dhxrt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-dhxrt,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-b79c9d74d-dhxrt,UID:8e4ec282-da15-11e9-b983-fa163edda742,ResourceVersion:231724,Generation:0,CreationTimestamp:2019-09-18 13:09:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 8e457abf-da15-11e9-b983-fa163edda742 0xc001d99850 0xc001d99851}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm599z-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d998c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d998e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.6,PodIP:,StartTime:2019-09-18 13:09:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.919: INFO: Pod "nginx-deployment-b79c9d74d-h5fcs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-h5fcs,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-b79c9d74d-h5fcs,UID:8e505040-da15-11e9-b983-fa163edda742,ResourceVersion:231727,Generation:0,CreationTimestamp:2019-09-18 13:09:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 8e457abf-da15-11e9-b983-fa163edda742 0xc001d999b0 0xc001d999b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1qxh-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d99a20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d99a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.5,PodIP:,StartTime:2019-09-18 13:09:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.919: INFO: Pod "nginx-deployment-b79c9d74d-kbh8b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-kbh8b,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-b79c9d74d-kbh8b,UID:8f8ed4c8-da15-11e9-b983-fa163edda742,ResourceVersion:231768,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 8e457abf-da15-11e9-b983-fa163edda742 0xc001d99b10 0xc001d99b11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d99b80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d99ba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.919: INFO: Pod "nginx-deployment-b79c9d74d-knmvl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-knmvl,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-b79c9d74d-knmvl,UID:8f8c1bd8-da15-11e9-b983-fa163edda742,ResourceVersion:231764,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 8e457abf-da15-11e9-b983-fa163edda742 0xc001d99c10 0xc001d99c11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d99c90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d99cb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.920: INFO: Pod "nginx-deployment-b79c9d74d-lhmld" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-lhmld,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-b79c9d74d-lhmld,UID:8e4843a8-da15-11e9-b983-fa163edda742,ResourceVersion:231716,Generation:0,CreationTimestamp:2019-09-18 13:09:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 8e457abf-da15-11e9-b983-fa163edda742 0xc001d99d20 0xc001d99d21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm599z-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d99d90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d99db0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.6,PodIP:,StartTime:2019-09-18 13:09:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.920: INFO: Pod "nginx-deployment-b79c9d74d-lxkwg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-lxkwg,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-b79c9d74d-lxkwg,UID:8e487395-da15-11e9-b983-fa163edda742,ResourceVersion:231720,Generation:0,CreationTimestamp:2019-09-18 13:09:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 8e457abf-da15-11e9-b983-fa163edda742 0xc001d99e90 0xc001d99e91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1qxh-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d99f00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d99f30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.5,PodIP:,StartTime:2019-09-18 13:09:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.920: INFO: Pod "nginx-deployment-b79c9d74d-nq744" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-nq744,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-b79c9d74d-nq744,UID:8f8beb82-da15-11e9-b983-fa163edda742,ResourceVersion:231758,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 8e457abf-da15-11e9-b983-fa163edda742 0xc002bc6000 0xc002bc6001}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bc6070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bc6090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.920: INFO: Pod "nginx-deployment-b79c9d74d-ql9fb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-ql9fb,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-b79c9d74d-ql9fb,UID:8e46998b-da15-11e9-b983-fa163edda742,ResourceVersion:231708,Generation:0,CreationTimestamp:2019-09-18 13:09:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 8e457abf-da15-11e9-b983-fa163edda742 0xc002bc6100 0xc002bc6101}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1qxh-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bc6170} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bc6190}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:32 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.5,PodIP:,StartTime:2019-09-18 13:09:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.920: INFO: Pod "nginx-deployment-b79c9d74d-s58pc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-s58pc,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-b79c9d74d-s58pc,UID:8f86477f-da15-11e9-b983-fa163edda742,ResourceVersion:231790,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 8e457abf-da15-11e9-b983-fa163edda742 0xc002bc6270 0xc002bc6271}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm599z-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bc62e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bc6300}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.6,PodIP:,StartTime:2019-09-18 13:09:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 18 13:09:36.920: INFO: Pod "nginx-deployment-b79c9d74d-vk6f9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-vk6f9,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7119,SelfLink:/api/v1/namespaces/deployment-7119/pods/nginx-deployment-b79c9d74d-vk6f9,UID:8f88c6a1-da15-11e9-b983-fa163edda742,ResourceVersion:231793,Generation:0,CreationTimestamp:2019-09-18 13:09:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 8e457abf-da15-11e9-b983-fa163edda742 0xc002bc63e0 0xc002bc63e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d5r99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5r99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d5r99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm599z-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bc6450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bc6470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:09:35 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.6,PodIP:,StartTime:2019-09-18 13:09:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:09:36.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7119" for this suite.
Sep 18 13:09:44.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:09:45.177: INFO: namespace deployment-7119 deletion completed in 8.24662591s

• [SLOW TEST:16.565 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:09:45.177: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 18 13:09:45.245: INFO: Waiting up to 5m0s for pod "pod-95b4a988-da15-11e9-8fe5-1a4434d30f67" in namespace "emptydir-6860" to be "success or failure"
Sep 18 13:09:45.251: INFO: Pod "pod-95b4a988-da15-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.386577ms
Sep 18 13:09:47.259: INFO: Pod "pod-95b4a988-da15-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014410175s
STEP: Saw pod success
Sep 18 13:09:47.259: INFO: Pod "pod-95b4a988-da15-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:09:47.266: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-95b4a988-da15-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 13:09:47.308: INFO: Waiting for pod pod-95b4a988-da15-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:09:47.314: INFO: Pod pod-95b4a988-da15-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:09:47.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6860" for this suite.
Sep 18 13:09:53.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:09:53.573: INFO: namespace emptydir-6860 deletion completed in 6.248289386s

• [SLOW TEST:8.395 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:09:53.573: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:09:53.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3558" for this suite.
Sep 18 13:09:59.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:09:59.892: INFO: namespace services-3558 deletion completed in 6.247646715s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.319 seconds]
[sig-network] Services
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:09:59.892: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-4045/configmap-test-9e7a6f73-da15-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume configMaps
Sep 18 13:09:59.971: INFO: Waiting up to 5m0s for pod "pod-configmaps-9e7ba457-da15-11e9-8fe5-1a4434d30f67" in namespace "configmap-4045" to be "success or failure"
Sep 18 13:09:59.978: INFO: Pod "pod-configmaps-9e7ba457-da15-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.523442ms
Sep 18 13:10:01.986: INFO: Pod "pod-configmaps-9e7ba457-da15-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014761803s
STEP: Saw pod success
Sep 18 13:10:01.986: INFO: Pod "pod-configmaps-9e7ba457-da15-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:10:01.993: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-configmaps-9e7ba457-da15-11e9-8fe5-1a4434d30f67 container env-test: <nil>
STEP: delete the pod
Sep 18 13:10:02.043: INFO: Waiting for pod pod-configmaps-9e7ba457-da15-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:10:02.049: INFO: Pod pod-configmaps-9e7ba457-da15-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:10:02.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4045" for this suite.
Sep 18 13:10:08.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:10:08.305: INFO: namespace configmap-4045 deletion completed in 6.244543062s

• [SLOW TEST:8.412 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:10:08.305: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Sep 18 13:10:08.916: INFO: created pod pod-service-account-defaultsa
Sep 18 13:10:08.916: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep 18 13:10:08.925: INFO: created pod pod-service-account-mountsa
Sep 18 13:10:08.925: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep 18 13:10:08.934: INFO: created pod pod-service-account-nomountsa
Sep 18 13:10:08.934: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep 18 13:10:08.944: INFO: created pod pod-service-account-defaultsa-mountspec
Sep 18 13:10:08.944: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep 18 13:10:08.958: INFO: created pod pod-service-account-mountsa-mountspec
Sep 18 13:10:08.958: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep 18 13:10:08.969: INFO: created pod pod-service-account-nomountsa-mountspec
Sep 18 13:10:08.969: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep 18 13:10:08.979: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep 18 13:10:08.979: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep 18 13:10:08.988: INFO: created pod pod-service-account-mountsa-nomountspec
Sep 18 13:10:08.988: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep 18 13:10:08.999: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep 18 13:10:08.999: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:10:08.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7866" for this suite.
Sep 18 13:10:33.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:10:33.253: INFO: namespace svcaccounts-7866 deletion completed in 24.241418278s

• [SLOW TEST:24.948 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:10:33.253: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 13:10:33.310: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:10:35.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4042" for this suite.
Sep 18 13:11:21.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:11:21.687: INFO: namespace pods-4042 deletion completed in 46.249853036s

• [SLOW TEST:48.434 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:11:21.687: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep 18 13:11:24.309: INFO: Successfully updated pod "labelsupdatecf3a82a2-da15-11e9-8fe5-1a4434d30f67"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:11:26.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9002" for this suite.
Sep 18 13:11:48.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:11:48.610: INFO: namespace downward-api-9002 deletion completed in 22.25640125s

• [SLOW TEST:26.923 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:11:48.610: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 18 13:11:52.761: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 18 13:11:52.768: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 18 13:11:54.769: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 18 13:11:54.776: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 18 13:11:56.769: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 18 13:11:56.776: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 18 13:11:58.769: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 18 13:11:58.776: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 18 13:12:00.769: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 18 13:12:00.776: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 18 13:12:02.769: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 18 13:12:02.776: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 18 13:12:04.769: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 18 13:12:04.776: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 18 13:12:06.769: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 18 13:12:06.776: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 18 13:12:08.769: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 18 13:12:08.776: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 18 13:12:10.769: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 18 13:12:10.776: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 18 13:12:12.769: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 18 13:12:12.776: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 18 13:12:14.769: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 18 13:12:14.776: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 18 13:12:16.769: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 18 13:12:16.776: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 18 13:12:18.769: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 18 13:12:18.776: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:12:18.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2335" for this suite.
Sep 18 13:12:40.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:12:41.033: INFO: namespace container-lifecycle-hook-2335 deletion completed in 22.245867129s

• [SLOW TEST:52.422 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:12:41.033: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 18 13:12:45.168: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 18 13:12:45.175: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 18 13:12:47.175: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 18 13:12:47.182: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 18 13:12:49.175: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 18 13:12:49.183: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 18 13:12:51.175: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 18 13:12:51.183: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 18 13:12:53.175: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 18 13:12:53.183: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 18 13:12:55.175: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 18 13:12:55.183: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 18 13:12:57.175: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 18 13:12:57.183: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 18 13:12:59.175: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 18 13:12:59.183: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 18 13:13:01.175: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 18 13:13:01.183: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 18 13:13:03.175: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 18 13:13:03.183: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 18 13:13:05.175: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 18 13:13:05.183: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 18 13:13:07.175: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 18 13:13:07.183: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 18 13:13:09.175: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 18 13:13:09.183: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:13:09.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6512" for this suite.
Sep 18 13:13:31.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:13:31.457: INFO: namespace container-lifecycle-hook-6512 deletion completed in 22.246777836s

• [SLOW TEST:50.424 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:13:31.457: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 13:13:31.529: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1c94e27c-da16-11e9-8fe5-1a4434d30f67" in namespace "projected-3033" to be "success or failure"
Sep 18 13:13:31.537: INFO: Pod "downwardapi-volume-1c94e27c-da16-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.692756ms
Sep 18 13:13:33.545: INFO: Pod "downwardapi-volume-1c94e27c-da16-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016030415s
STEP: Saw pod success
Sep 18 13:13:33.545: INFO: Pod "downwardapi-volume-1c94e27c-da16-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:13:33.552: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-1c94e27c-da16-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 13:13:33.592: INFO: Waiting for pod downwardapi-volume-1c94e27c-da16-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:13:33.598: INFO: Pod downwardapi-volume-1c94e27c-da16-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:13:33.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3033" for this suite.
Sep 18 13:13:39.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:13:39.853: INFO: namespace projected-3033 deletion completed in 6.243980486s

• [SLOW TEST:8.396 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:13:39.853: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:13:42.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4177" for this suite.
Sep 18 13:13:48.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:13:48.280: INFO: namespace emptydir-wrapper-4177 deletion completed in 6.247343036s

• [SLOW TEST:8.427 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:13:48.280: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-269b8f41-da16-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume configMaps
Sep 18 13:13:48.362: INFO: Waiting up to 5m0s for pod "pod-configmaps-269d4fc1-da16-11e9-8fe5-1a4434d30f67" in namespace "configmap-1750" to be "success or failure"
Sep 18 13:13:48.371: INFO: Pod "pod-configmaps-269d4fc1-da16-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 8.405796ms
Sep 18 13:13:50.379: INFO: Pod "pod-configmaps-269d4fc1-da16-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016319538s
STEP: Saw pod success
Sep 18 13:13:50.379: INFO: Pod "pod-configmaps-269d4fc1-da16-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:13:50.385: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-configmaps-269d4fc1-da16-11e9-8fe5-1a4434d30f67 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 18 13:13:50.424: INFO: Waiting for pod pod-configmaps-269d4fc1-da16-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:13:50.431: INFO: Pod pod-configmaps-269d4fc1-da16-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:13:50.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1750" for this suite.
Sep 18 13:13:56.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:13:56.730: INFO: namespace configmap-1750 deletion completed in 6.288463988s

• [SLOW TEST:8.450 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:13:56.731: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 13:13:56.802: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2ba515a6-da16-11e9-8fe5-1a4434d30f67" in namespace "downward-api-2045" to be "success or failure"
Sep 18 13:13:56.809: INFO: Pod "downwardapi-volume-2ba515a6-da16-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.265884ms
Sep 18 13:13:58.817: INFO: Pod "downwardapi-volume-2ba515a6-da16-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015455993s
STEP: Saw pod success
Sep 18 13:13:58.817: INFO: Pod "downwardapi-volume-2ba515a6-da16-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:13:58.824: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-2ba515a6-da16-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 13:13:58.867: INFO: Waiting for pod downwardapi-volume-2ba515a6-da16-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:13:58.874: INFO: Pod downwardapi-volume-2ba515a6-da16-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:13:58.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2045" for this suite.
Sep 18 13:14:04.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:14:05.133: INFO: namespace downward-api-2045 deletion completed in 6.248877946s

• [SLOW TEST:8.402 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:14:05.133: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 18 13:14:05.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-4763'
Sep 18 13:14:05.309: INFO: stderr: ""
Sep 18 13:14:05.309: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Sep 18 13:14:10.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pod e2e-test-nginx-pod --namespace=kubectl-4763 -o json'
Sep 18 13:14:10.457: INFO: stderr: ""
Sep 18 13:14:10.457: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-09-18T13:14:05Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-4763\",\n        \"resourceVersion\": \"233009\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-4763/pods/e2e-test-nginx-pod\",\n        \"uid\": \"30b8dc99-da16-11e9-b983-fa163edda742\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-lg9z9\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"k8s-node-vm1qxh-95up3dyso1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-lg9z9\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-lg9z9\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-18T13:14:05Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-18T13:14:06Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-18T13:14:06Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-18T13:14:05Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://18df69824fb6f56d17adb3e80db9b8074f35bde593ea8d2df1896d28fcd0c24e\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-09-18T13:14:05Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.224.5\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.0.192.15\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-09-18T13:14:05Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep 18 13:14:10.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 replace -f - --namespace=kubectl-4763'
Sep 18 13:14:10.639: INFO: stderr: ""
Sep 18 13:14:10.639: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Sep 18 13:14:10.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 delete pods e2e-test-nginx-pod --namespace=kubectl-4763'
Sep 18 13:14:17.227: INFO: stderr: ""
Sep 18 13:14:17.227: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:14:17.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4763" for this suite.
Sep 18 13:14:23.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:14:23.480: INFO: namespace kubectl-4763 deletion completed in 6.242514456s

• [SLOW TEST:18.347 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:14:23.480: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:14:43.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2395" for this suite.
Sep 18 13:14:49.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:14:50.184: INFO: namespace container-runtime-2395 deletion completed in 6.248187307s

• [SLOW TEST:26.703 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:14:50.184: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-xvctq in namespace proxy-6913
I0918 13:14:50.269205      19 runners.go:184] Created replication controller with name: proxy-service-xvctq, namespace: proxy-6913, replica count: 1
I0918 13:14:51.319854      19 runners.go:184] proxy-service-xvctq Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0918 13:14:52.320109      19 runners.go:184] proxy-service-xvctq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0918 13:14:53.320403      19 runners.go:184] proxy-service-xvctq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0918 13:14:54.320671      19 runners.go:184] proxy-service-xvctq Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 18 13:14:54.327: INFO: setup took 4.087122292s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep 18 13:14:54.343: INFO: (0) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 15.362765ms)
Sep 18 13:14:54.343: INFO: (0) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 15.512714ms)
Sep 18 13:14:54.343: INFO: (0) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 15.656472ms)
Sep 18 13:14:54.343: INFO: (0) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 15.56916ms)
Sep 18 13:14:54.344: INFO: (0) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 16.99788ms)
Sep 18 13:14:54.345: INFO: (0) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 16.913647ms)
Sep 18 13:14:54.345: INFO: (0) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 16.984095ms)
Sep 18 13:14:54.345: INFO: (0) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 17.547601ms)
Sep 18 13:14:54.347: INFO: (0) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 19.424126ms)
Sep 18 13:14:54.347: INFO: (0) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 19.718267ms)
Sep 18 13:14:54.347: INFO: (0) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 19.745021ms)
Sep 18 13:14:54.354: INFO: (0) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 26.190331ms)
Sep 18 13:14:54.355: INFO: (0) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 27.572126ms)
Sep 18 13:14:54.355: INFO: (0) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 27.803343ms)
Sep 18 13:14:54.357: INFO: (0) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 29.805307ms)
Sep 18 13:14:54.357: INFO: (0) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 29.810255ms)
Sep 18 13:14:54.366: INFO: (1) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 8.554821ms)
Sep 18 13:14:54.371: INFO: (1) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 13.611408ms)
Sep 18 13:14:54.371: INFO: (1) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 13.494986ms)
Sep 18 13:14:54.371: INFO: (1) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 13.731247ms)
Sep 18 13:14:54.371: INFO: (1) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 13.79077ms)
Sep 18 13:14:54.371: INFO: (1) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 13.89468ms)
Sep 18 13:14:54.372: INFO: (1) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 13.927486ms)
Sep 18 13:14:54.372: INFO: (1) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 13.938568ms)
Sep 18 13:14:54.372: INFO: (1) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 13.997266ms)
Sep 18 13:14:54.372: INFO: (1) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 14.117076ms)
Sep 18 13:14:54.374: INFO: (1) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 16.028183ms)
Sep 18 13:14:54.377: INFO: (1) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 19.720958ms)
Sep 18 13:14:54.377: INFO: (1) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 19.675402ms)
Sep 18 13:14:54.377: INFO: (1) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 19.809162ms)
Sep 18 13:14:54.377: INFO: (1) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 19.860297ms)
Sep 18 13:14:54.377: INFO: (1) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 19.737317ms)
Sep 18 13:14:54.390: INFO: (2) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 12.079153ms)
Sep 18 13:14:54.390: INFO: (2) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 12.178561ms)
Sep 18 13:14:54.390: INFO: (2) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.108612ms)
Sep 18 13:14:54.390: INFO: (2) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 12.120389ms)
Sep 18 13:14:54.390: INFO: (2) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 12.232952ms)
Sep 18 13:14:54.390: INFO: (2) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 12.323568ms)
Sep 18 13:14:54.390: INFO: (2) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 12.384145ms)
Sep 18 13:14:54.390: INFO: (2) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.427308ms)
Sep 18 13:14:54.390: INFO: (2) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 12.426189ms)
Sep 18 13:14:54.390: INFO: (2) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 12.583483ms)
Sep 18 13:14:54.391: INFO: (2) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 13.714853ms)
Sep 18 13:14:54.392: INFO: (2) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 14.531793ms)
Sep 18 13:14:54.392: INFO: (2) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 14.688148ms)
Sep 18 13:14:54.392: INFO: (2) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 14.908163ms)
Sep 18 13:14:54.394: INFO: (2) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 16.647788ms)
Sep 18 13:14:54.394: INFO: (2) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 16.820158ms)
Sep 18 13:14:54.403: INFO: (3) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 8.340793ms)
Sep 18 13:14:54.407: INFO: (3) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 12.196877ms)
Sep 18 13:14:54.407: INFO: (3) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.293948ms)
Sep 18 13:14:54.407: INFO: (3) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 12.301478ms)
Sep 18 13:14:54.407: INFO: (3) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 12.501558ms)
Sep 18 13:14:54.407: INFO: (3) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 12.55359ms)
Sep 18 13:14:54.407: INFO: (3) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 12.563972ms)
Sep 18 13:14:54.407: INFO: (3) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 12.60953ms)
Sep 18 13:14:54.407: INFO: (3) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 12.697877ms)
Sep 18 13:14:54.407: INFO: (3) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.973428ms)
Sep 18 13:14:54.409: INFO: (3) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 14.941709ms)
Sep 18 13:14:54.413: INFO: (3) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 18.505578ms)
Sep 18 13:14:54.413: INFO: (3) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 18.674744ms)
Sep 18 13:14:54.413: INFO: (3) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 18.668265ms)
Sep 18 13:14:54.413: INFO: (3) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 18.708499ms)
Sep 18 13:14:54.413: INFO: (3) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 18.707156ms)
Sep 18 13:14:54.421: INFO: (4) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 8.197047ms)
Sep 18 13:14:54.426: INFO: (4) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 13.067071ms)
Sep 18 13:14:54.426: INFO: (4) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 13.076761ms)
Sep 18 13:14:54.426: INFO: (4) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 13.163849ms)
Sep 18 13:14:54.426: INFO: (4) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 13.147905ms)
Sep 18 13:14:54.426: INFO: (4) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 13.175601ms)
Sep 18 13:14:54.426: INFO: (4) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 13.210359ms)
Sep 18 13:14:54.427: INFO: (4) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 13.211484ms)
Sep 18 13:14:54.427: INFO: (4) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 13.237511ms)
Sep 18 13:14:54.427: INFO: (4) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 13.238386ms)
Sep 18 13:14:54.429: INFO: (4) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 15.784951ms)
Sep 18 13:14:54.431: INFO: (4) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 18.157804ms)
Sep 18 13:14:54.433: INFO: (4) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 19.280228ms)
Sep 18 13:14:54.433: INFO: (4) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 19.520466ms)
Sep 18 13:14:54.433: INFO: (4) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 19.614191ms)
Sep 18 13:14:54.433: INFO: (4) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 19.596379ms)
Sep 18 13:14:54.443: INFO: (5) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 10.444757ms)
Sep 18 13:14:54.443: INFO: (5) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 10.342733ms)
Sep 18 13:14:54.444: INFO: (5) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 11.368847ms)
Sep 18 13:14:54.445: INFO: (5) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 11.628878ms)
Sep 18 13:14:54.447: INFO: (5) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 13.870467ms)
Sep 18 13:14:54.447: INFO: (5) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 14.172365ms)
Sep 18 13:14:54.447: INFO: (5) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 14.107601ms)
Sep 18 13:14:54.447: INFO: (5) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 14.365379ms)
Sep 18 13:14:54.448: INFO: (5) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 14.589886ms)
Sep 18 13:14:54.448: INFO: (5) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 14.65073ms)
Sep 18 13:14:54.448: INFO: (5) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 15.543755ms)
Sep 18 13:14:54.451: INFO: (5) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 17.74374ms)
Sep 18 13:14:54.451: INFO: (5) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 17.885695ms)
Sep 18 13:14:54.451: INFO: (5) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 17.882274ms)
Sep 18 13:14:54.451: INFO: (5) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 17.931268ms)
Sep 18 13:14:54.451: INFO: (5) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 17.88236ms)
Sep 18 13:14:54.463: INFO: (6) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 12.065731ms)
Sep 18 13:14:54.463: INFO: (6) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 11.904713ms)
Sep 18 13:14:54.463: INFO: (6) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 12.197134ms)
Sep 18 13:14:54.463: INFO: (6) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 12.23156ms)
Sep 18 13:14:54.463: INFO: (6) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.256053ms)
Sep 18 13:14:54.463: INFO: (6) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 12.283044ms)
Sep 18 13:14:54.464: INFO: (6) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 13.164122ms)
Sep 18 13:14:54.464: INFO: (6) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 13.221932ms)
Sep 18 13:14:54.465: INFO: (6) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 13.54856ms)
Sep 18 13:14:54.465: INFO: (6) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 13.520031ms)
Sep 18 13:14:54.465: INFO: (6) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 14.237996ms)
Sep 18 13:14:54.469: INFO: (6) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 17.848172ms)
Sep 18 13:14:54.469: INFO: (6) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 17.903603ms)
Sep 18 13:14:54.469: INFO: (6) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 17.840783ms)
Sep 18 13:14:54.469: INFO: (6) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 17.980621ms)
Sep 18 13:14:54.469: INFO: (6) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 17.927994ms)
Sep 18 13:14:54.478: INFO: (7) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 8.994018ms)
Sep 18 13:14:54.480: INFO: (7) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 11.214672ms)
Sep 18 13:14:54.480: INFO: (7) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 11.368735ms)
Sep 18 13:14:54.480: INFO: (7) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 11.43423ms)
Sep 18 13:14:54.483: INFO: (7) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 14.366392ms)
Sep 18 13:14:54.483: INFO: (7) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 14.355764ms)
Sep 18 13:14:54.483: INFO: (7) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 14.343634ms)
Sep 18 13:14:54.483: INFO: (7) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 14.392106ms)
Sep 18 13:14:54.484: INFO: (7) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 14.682347ms)
Sep 18 13:14:54.484: INFO: (7) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 14.624272ms)
Sep 18 13:14:54.484: INFO: (7) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 15.127575ms)
Sep 18 13:14:54.486: INFO: (7) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 17.078751ms)
Sep 18 13:14:54.488: INFO: (7) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 19.240153ms)
Sep 18 13:14:54.488: INFO: (7) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 19.154717ms)
Sep 18 13:14:54.488: INFO: (7) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 19.249911ms)
Sep 18 13:14:54.488: INFO: (7) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 19.268383ms)
Sep 18 13:14:54.499: INFO: (8) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 10.439485ms)
Sep 18 13:14:54.502: INFO: (8) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 14.031231ms)
Sep 18 13:14:54.502: INFO: (8) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 14.004ms)
Sep 18 13:14:54.503: INFO: (8) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 14.27369ms)
Sep 18 13:14:54.503: INFO: (8) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 14.21927ms)
Sep 18 13:14:54.503: INFO: (8) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 14.230811ms)
Sep 18 13:14:54.503: INFO: (8) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 14.350718ms)
Sep 18 13:14:54.503: INFO: (8) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 14.35705ms)
Sep 18 13:14:54.503: INFO: (8) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 14.464705ms)
Sep 18 13:14:54.504: INFO: (8) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 15.719848ms)
Sep 18 13:14:54.504: INFO: (8) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 15.658889ms)
Sep 18 13:14:54.505: INFO: (8) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 16.680425ms)
Sep 18 13:14:54.505: INFO: (8) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 16.700078ms)
Sep 18 13:14:54.505: INFO: (8) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 16.671883ms)
Sep 18 13:14:54.505: INFO: (8) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 17.00972ms)
Sep 18 13:14:54.506: INFO: (8) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 17.041635ms)
Sep 18 13:14:54.519: INFO: (9) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.940026ms)
Sep 18 13:14:54.519: INFO: (9) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 12.978783ms)
Sep 18 13:14:54.519: INFO: (9) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 13.267916ms)
Sep 18 13:14:54.519: INFO: (9) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 13.199326ms)
Sep 18 13:14:54.519: INFO: (9) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 13.195781ms)
Sep 18 13:14:54.519: INFO: (9) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 13.181888ms)
Sep 18 13:14:54.519: INFO: (9) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 13.230695ms)
Sep 18 13:14:54.519: INFO: (9) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 13.195249ms)
Sep 18 13:14:54.520: INFO: (9) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 14.508237ms)
Sep 18 13:14:54.520: INFO: (9) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 14.594083ms)
Sep 18 13:14:54.522: INFO: (9) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 16.349728ms)
Sep 18 13:14:54.524: INFO: (9) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 18.443928ms)
Sep 18 13:14:54.525: INFO: (9) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 19.757275ms)
Sep 18 13:14:54.525: INFO: (9) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 19.781814ms)
Sep 18 13:14:54.525: INFO: (9) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 19.835903ms)
Sep 18 13:14:54.525: INFO: (9) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 19.850766ms)
Sep 18 13:14:54.538: INFO: (10) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 12.40035ms)
Sep 18 13:14:54.538: INFO: (10) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 12.444964ms)
Sep 18 13:14:54.538: INFO: (10) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 12.636958ms)
Sep 18 13:14:54.538: INFO: (10) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 12.589472ms)
Sep 18 13:14:54.538: INFO: (10) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.719062ms)
Sep 18 13:14:54.538: INFO: (10) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 12.76171ms)
Sep 18 13:14:54.538: INFO: (10) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.759212ms)
Sep 18 13:14:54.538: INFO: (10) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 12.845986ms)
Sep 18 13:14:54.538: INFO: (10) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 12.822282ms)
Sep 18 13:14:54.540: INFO: (10) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 13.887827ms)
Sep 18 13:14:54.540: INFO: (10) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 14.720727ms)
Sep 18 13:14:54.540: INFO: (10) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 14.675908ms)
Sep 18 13:14:54.541: INFO: (10) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 15.007514ms)
Sep 18 13:14:54.542: INFO: (10) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 16.877423ms)
Sep 18 13:14:54.542: INFO: (10) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 16.829938ms)
Sep 18 13:14:54.542: INFO: (10) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 16.852427ms)
Sep 18 13:14:54.552: INFO: (11) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 9.223766ms)
Sep 18 13:14:54.556: INFO: (11) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.932672ms)
Sep 18 13:14:54.556: INFO: (11) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 12.986899ms)
Sep 18 13:14:54.556: INFO: (11) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 13.012382ms)
Sep 18 13:14:54.556: INFO: (11) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 12.960982ms)
Sep 18 13:14:54.556: INFO: (11) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 13.139194ms)
Sep 18 13:14:54.556: INFO: (11) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 13.164251ms)
Sep 18 13:14:54.556: INFO: (11) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 13.247904ms)
Sep 18 13:14:54.556: INFO: (11) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 13.224094ms)
Sep 18 13:14:54.556: INFO: (11) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 13.164432ms)
Sep 18 13:14:54.560: INFO: (11) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 17.31135ms)
Sep 18 13:14:54.564: INFO: (11) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 20.851784ms)
Sep 18 13:14:54.564: INFO: (11) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 20.843428ms)
Sep 18 13:14:54.564: INFO: (11) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 20.889119ms)
Sep 18 13:14:54.564: INFO: (11) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 20.897748ms)
Sep 18 13:14:54.564: INFO: (11) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 20.912744ms)
Sep 18 13:14:54.576: INFO: (12) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.417608ms)
Sep 18 13:14:54.576: INFO: (12) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.45361ms)
Sep 18 13:14:54.576: INFO: (12) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 12.592617ms)
Sep 18 13:14:54.576: INFO: (12) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 12.697553ms)
Sep 18 13:14:54.577: INFO: (12) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 13.151027ms)
Sep 18 13:14:54.577: INFO: (12) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 13.301161ms)
Sep 18 13:14:54.577: INFO: (12) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 13.461312ms)
Sep 18 13:14:54.577: INFO: (12) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 13.448961ms)
Sep 18 13:14:54.578: INFO: (12) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 14.02003ms)
Sep 18 13:14:54.578: INFO: (12) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 14.141868ms)
Sep 18 13:14:54.578: INFO: (12) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 14.039131ms)
Sep 18 13:14:54.580: INFO: (12) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 15.975625ms)
Sep 18 13:14:54.580: INFO: (12) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 16.239172ms)
Sep 18 13:14:54.580: INFO: (12) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 16.308853ms)
Sep 18 13:14:54.580: INFO: (12) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 16.626033ms)
Sep 18 13:14:54.580: INFO: (12) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 16.689476ms)
Sep 18 13:14:54.589: INFO: (13) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 8.311146ms)
Sep 18 13:14:54.592: INFO: (13) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 11.931179ms)
Sep 18 13:14:54.593: INFO: (13) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.066398ms)
Sep 18 13:14:54.593: INFO: (13) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 12.078318ms)
Sep 18 13:14:54.593: INFO: (13) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 12.346687ms)
Sep 18 13:14:54.593: INFO: (13) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 12.401058ms)
Sep 18 13:14:54.593: INFO: (13) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 12.63274ms)
Sep 18 13:14:54.593: INFO: (13) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 12.699863ms)
Sep 18 13:14:54.593: INFO: (13) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 12.758696ms)
Sep 18 13:14:54.594: INFO: (13) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 13.514402ms)
Sep 18 13:14:54.595: INFO: (13) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 14.81425ms)
Sep 18 13:14:54.599: INFO: (13) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 18.870791ms)
Sep 18 13:14:54.599: INFO: (13) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 18.941278ms)
Sep 18 13:14:54.599: INFO: (13) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 18.877271ms)
Sep 18 13:14:54.599: INFO: (13) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 18.880621ms)
Sep 18 13:14:54.599: INFO: (13) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 18.94264ms)
Sep 18 13:14:54.608: INFO: (14) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 8.289208ms)
Sep 18 13:14:54.611: INFO: (14) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 11.192845ms)
Sep 18 13:14:54.611: INFO: (14) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 11.217643ms)
Sep 18 13:14:54.613: INFO: (14) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 13.149374ms)
Sep 18 13:14:54.613: INFO: (14) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 13.338449ms)
Sep 18 13:14:54.614: INFO: (14) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 14.495179ms)
Sep 18 13:14:54.614: INFO: (14) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 14.597447ms)
Sep 18 13:14:54.614: INFO: (14) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 14.775098ms)
Sep 18 13:14:54.614: INFO: (14) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 14.901729ms)
Sep 18 13:14:54.615: INFO: (14) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 15.035454ms)
Sep 18 13:14:54.616: INFO: (14) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 16.799669ms)
Sep 18 13:14:54.617: INFO: (14) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 17.974732ms)
Sep 18 13:14:54.618: INFO: (14) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 17.940649ms)
Sep 18 13:14:54.618: INFO: (14) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 18.114116ms)
Sep 18 13:14:54.619: INFO: (14) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 19.210422ms)
Sep 18 13:14:54.619: INFO: (14) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 19.386874ms)
Sep 18 13:14:54.631: INFO: (15) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 12.277481ms)
Sep 18 13:14:54.631: INFO: (15) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 12.421909ms)
Sep 18 13:14:54.631: INFO: (15) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.461947ms)
Sep 18 13:14:54.631: INFO: (15) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 12.400125ms)
Sep 18 13:14:54.631: INFO: (15) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.523145ms)
Sep 18 13:14:54.632: INFO: (15) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 12.711971ms)
Sep 18 13:14:54.632: INFO: (15) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 12.661507ms)
Sep 18 13:14:54.632: INFO: (15) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 12.652634ms)
Sep 18 13:14:54.632: INFO: (15) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 12.736241ms)
Sep 18 13:14:54.632: INFO: (15) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 12.816672ms)
Sep 18 13:14:54.633: INFO: (15) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 14.370004ms)
Sep 18 13:14:54.635: INFO: (15) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 15.733733ms)
Sep 18 13:14:54.637: INFO: (15) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 17.752478ms)
Sep 18 13:14:54.637: INFO: (15) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 17.890288ms)
Sep 18 13:14:54.637: INFO: (15) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 17.924961ms)
Sep 18 13:14:54.637: INFO: (15) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 17.957021ms)
Sep 18 13:14:54.645: INFO: (16) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 8.188127ms)
Sep 18 13:14:54.649: INFO: (16) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 12.117023ms)
Sep 18 13:14:54.649: INFO: (16) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 12.143462ms)
Sep 18 13:14:54.650: INFO: (16) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 12.457755ms)
Sep 18 13:14:54.650: INFO: (16) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 12.50653ms)
Sep 18 13:14:54.650: INFO: (16) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 12.515975ms)
Sep 18 13:14:54.650: INFO: (16) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.621776ms)
Sep 18 13:14:54.650: INFO: (16) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.594701ms)
Sep 18 13:14:54.650: INFO: (16) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 12.665325ms)
Sep 18 13:14:54.650: INFO: (16) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 12.712869ms)
Sep 18 13:14:54.651: INFO: (16) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 14.070637ms)
Sep 18 13:14:54.652: INFO: (16) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 14.466489ms)
Sep 18 13:14:54.654: INFO: (16) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 16.79527ms)
Sep 18 13:14:54.654: INFO: (16) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 16.806662ms)
Sep 18 13:14:54.654: INFO: (16) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 16.805195ms)
Sep 18 13:14:54.654: INFO: (16) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 16.804349ms)
Sep 18 13:14:54.662: INFO: (17) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 8.328108ms)
Sep 18 13:14:54.666: INFO: (17) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 11.556635ms)
Sep 18 13:14:54.666: INFO: (17) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 11.655412ms)
Sep 18 13:14:54.666: INFO: (17) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 11.715954ms)
Sep 18 13:14:54.666: INFO: (17) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 11.825831ms)
Sep 18 13:14:54.668: INFO: (17) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 13.785631ms)
Sep 18 13:14:54.668: INFO: (17) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 13.773528ms)
Sep 18 13:14:54.668: INFO: (17) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 13.981967ms)
Sep 18 13:14:54.668: INFO: (17) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 14.037738ms)
Sep 18 13:14:54.668: INFO: (17) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 13.949148ms)
Sep 18 13:14:54.668: INFO: (17) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 14.271753ms)
Sep 18 13:14:54.672: INFO: (17) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 17.711794ms)
Sep 18 13:14:54.672: INFO: (17) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 17.812365ms)
Sep 18 13:14:54.672: INFO: (17) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 17.767278ms)
Sep 18 13:14:54.672: INFO: (17) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 17.763901ms)
Sep 18 13:14:54.672: INFO: (17) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 17.86406ms)
Sep 18 13:14:54.680: INFO: (18) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 8.039348ms)
Sep 18 13:14:54.684: INFO: (18) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 12.35432ms)
Sep 18 13:14:54.685: INFO: (18) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.45753ms)
Sep 18 13:14:54.685: INFO: (18) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 12.844631ms)
Sep 18 13:14:54.685: INFO: (18) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 12.790967ms)
Sep 18 13:14:54.685: INFO: (18) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 12.930676ms)
Sep 18 13:14:54.685: INFO: (18) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 13.226332ms)
Sep 18 13:14:54.685: INFO: (18) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 13.180428ms)
Sep 18 13:14:54.685: INFO: (18) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 13.285288ms)
Sep 18 13:14:54.686: INFO: (18) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 14.001004ms)
Sep 18 13:14:54.688: INFO: (18) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 15.440398ms)
Sep 18 13:14:54.691: INFO: (18) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 19.23302ms)
Sep 18 13:14:54.691: INFO: (18) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 19.246406ms)
Sep 18 13:14:54.691: INFO: (18) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 19.327985ms)
Sep 18 13:14:54.691: INFO: (18) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 19.290847ms)
Sep 18 13:14:54.691: INFO: (18) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 19.404428ms)
Sep 18 13:14:54.700: INFO: (19) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:462/proxy/: tls qux (200; 8.559441ms)
Sep 18 13:14:54.704: INFO: (19) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:460/proxy/: tls baz (200; 12.347258ms)
Sep 18 13:14:54.704: INFO: (19) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:162/proxy/: bar (200; 12.473829ms)
Sep 18 13:14:54.704: INFO: (19) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:1080/proxy/rewriteme">... (200; 12.491495ms)
Sep 18 13:14:54.704: INFO: (19) /api/v1/namespaces/proxy-6913/pods/http:proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.54332ms)
Sep 18 13:14:54.704: INFO: (19) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz/proxy/rewriteme">test</a> (200; 12.770316ms)
Sep 18 13:14:54.704: INFO: (19) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:1080/proxy/rewriteme">test<... (200; 12.746711ms)
Sep 18 13:14:54.704: INFO: (19) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:162/proxy/: bar (200; 12.780243ms)
Sep 18 13:14:54.704: INFO: (19) /api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/: <a href="/api/v1/namespaces/proxy-6913/pods/https:proxy-service-xvctq-24kfz:443/proxy/tlsrewritem... (200; 12.862623ms)
Sep 18 13:14:54.704: INFO: (19) /api/v1/namespaces/proxy-6913/pods/proxy-service-xvctq-24kfz:160/proxy/: foo (200; 12.863282ms)
Sep 18 13:14:54.705: INFO: (19) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname1/proxy/: tls baz (200; 13.978755ms)
Sep 18 13:14:54.709: INFO: (19) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname1/proxy/: foo (200; 17.010424ms)
Sep 18 13:14:54.712: INFO: (19) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname2/proxy/: bar (200; 20.075153ms)
Sep 18 13:14:54.712: INFO: (19) /api/v1/namespaces/proxy-6913/services/https:proxy-service-xvctq:tlsportname2/proxy/: tls qux (200; 20.856702ms)
Sep 18 13:14:54.712: INFO: (19) /api/v1/namespaces/proxy-6913/services/http:proxy-service-xvctq:portname1/proxy/: foo (200; 20.890471ms)
Sep 18 13:14:54.714: INFO: (19) /api/v1/namespaces/proxy-6913/services/proxy-service-xvctq:portname2/proxy/: bar (200; 22.198773ms)
STEP: deleting ReplicationController proxy-service-xvctq in namespace proxy-6913, will wait for the garbage collector to delete the pods
Sep 18 13:14:54.803: INFO: Deleting ReplicationController proxy-service-xvctq took: 29.604878ms
Sep 18 13:14:55.104: INFO: Terminating ReplicationController proxy-service-xvctq pods took: 300.18109ms
[AfterEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:15:07.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6913" for this suite.
Sep 18 13:15:13.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:15:13.562: INFO: namespace proxy-6913 deletion completed in 6.246894798s

• [SLOW TEST:23.378 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:15:13.562: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Sep 18 13:15:13.632: INFO: Waiting up to 5m0s for pod "var-expansion-59708cd7-da16-11e9-8fe5-1a4434d30f67" in namespace "var-expansion-1623" to be "success or failure"
Sep 18 13:15:13.642: INFO: Pod "var-expansion-59708cd7-da16-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 9.612648ms
Sep 18 13:15:15.649: INFO: Pod "var-expansion-59708cd7-da16-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016738501s
STEP: Saw pod success
Sep 18 13:15:15.649: INFO: Pod "var-expansion-59708cd7-da16-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:15:15.656: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod var-expansion-59708cd7-da16-11e9-8fe5-1a4434d30f67 container dapi-container: <nil>
STEP: delete the pod
Sep 18 13:15:15.701: INFO: Waiting for pod var-expansion-59708cd7-da16-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:15:15.708: INFO: Pod var-expansion-59708cd7-da16-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:15:15.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1623" for this suite.
Sep 18 13:15:21.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:15:21.961: INFO: namespace var-expansion-1623 deletion completed in 6.242518122s

• [SLOW TEST:8.399 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:15:21.961: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep 18 13:15:22.017: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:15:23.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-489" for this suite.
Sep 18 13:15:29.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:15:30.130: INFO: namespace init-container-489 deletion completed in 6.25156702s

• [SLOW TEST:8.169 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:15:30.130: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Sep 18 13:15:30.196: INFO: Waiting up to 5m0s for pod "var-expansion-63502027-da16-11e9-8fe5-1a4434d30f67" in namespace "var-expansion-8381" to be "success or failure"
Sep 18 13:15:30.203: INFO: Pod "var-expansion-63502027-da16-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.44762ms
Sep 18 13:15:32.211: INFO: Pod "var-expansion-63502027-da16-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014349237s
STEP: Saw pod success
Sep 18 13:15:32.211: INFO: Pod "var-expansion-63502027-da16-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:15:32.218: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod var-expansion-63502027-da16-11e9-8fe5-1a4434d30f67 container dapi-container: <nil>
STEP: delete the pod
Sep 18 13:15:32.260: INFO: Waiting for pod var-expansion-63502027-da16-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:15:32.268: INFO: Pod var-expansion-63502027-da16-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:15:32.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8381" for this suite.
Sep 18 13:15:38.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:15:38.530: INFO: namespace var-expansion-8381 deletion completed in 6.251818317s

• [SLOW TEST:8.400 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:15:38.530: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-623
Sep 18 13:15:40.618: INFO: Started pod liveness-http in namespace container-probe-623
STEP: checking the pod's current state and verifying that restartCount is present
Sep 18 13:15:40.625: INFO: Initial restart count of pod liveness-http is 0
Sep 18 13:15:52.678: INFO: Restart count of pod container-probe-623/liveness-http is now 1 (12.053261184s elapsed)
Sep 18 13:16:12.757: INFO: Restart count of pod container-probe-623/liveness-http is now 2 (32.131964496s elapsed)
Sep 18 13:16:32.835: INFO: Restart count of pod container-probe-623/liveness-http is now 3 (52.210115197s elapsed)
Sep 18 13:16:52.915: INFO: Restart count of pod container-probe-623/liveness-http is now 4 (1m12.290627382s elapsed)
Sep 18 13:18:03.198: INFO: Restart count of pod container-probe-623/liveness-http is now 5 (2m22.573425494s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:18:03.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-623" for this suite.
Sep 18 13:18:09.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:18:09.487: INFO: namespace container-probe-623 deletion completed in 6.25388575s

• [SLOW TEST:150.957 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:18:09.488: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-3992
Sep 18 13:18:11.578: INFO: Started pod liveness-http in namespace container-probe-3992
STEP: checking the pod's current state and verifying that restartCount is present
Sep 18 13:18:11.585: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:22:12.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3992" for this suite.
Sep 18 13:22:18.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:22:18.827: INFO: namespace container-probe-3992 deletion completed in 6.244603397s

• [SLOW TEST:249.340 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:22:18.828: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep 18 13:22:18.881: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:22:21.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5597" for this suite.
Sep 18 13:22:28.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:22:28.258: INFO: namespace init-container-5597 deletion completed in 6.25139772s

• [SLOW TEST:9.431 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:22:28.258: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 18 13:22:28.331: INFO: Waiting up to 5m0s for pod "pod-5c8a3ad7-da17-11e9-8fe5-1a4434d30f67" in namespace "emptydir-8836" to be "success or failure"
Sep 18 13:22:28.338: INFO: Pod "pod-5c8a3ad7-da17-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.408306ms
Sep 18 13:22:30.347: INFO: Pod "pod-5c8a3ad7-da17-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015472243s
STEP: Saw pod success
Sep 18 13:22:30.347: INFO: Pod "pod-5c8a3ad7-da17-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:22:30.354: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-5c8a3ad7-da17-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 13:22:30.395: INFO: Waiting for pod pod-5c8a3ad7-da17-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:22:30.402: INFO: Pod pod-5c8a3ad7-da17-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:22:30.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8836" for this suite.
Sep 18 13:22:36.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:22:36.661: INFO: namespace emptydir-8836 deletion completed in 6.248056761s

• [SLOW TEST:8.403 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:22:36.661: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 13:22:36.732: INFO: Waiting up to 5m0s for pod "downwardapi-volume-618c04fc-da17-11e9-8fe5-1a4434d30f67" in namespace "downward-api-2889" to be "success or failure"
Sep 18 13:22:36.740: INFO: Pod "downwardapi-volume-618c04fc-da17-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.627448ms
Sep 18 13:22:38.748: INFO: Pod "downwardapi-volume-618c04fc-da17-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01567006s
STEP: Saw pod success
Sep 18 13:22:38.748: INFO: Pod "downwardapi-volume-618c04fc-da17-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:22:38.755: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-618c04fc-da17-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 13:22:38.796: INFO: Waiting for pod downwardapi-volume-618c04fc-da17-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:22:38.802: INFO: Pod downwardapi-volume-618c04fc-da17-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:22:38.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2889" for this suite.
Sep 18 13:22:44.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:22:45.061: INFO: namespace downward-api-2889 deletion completed in 6.249174099s

• [SLOW TEST:8.400 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:22:45.062: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-668f23c1-da17-11e9-8fe5-1a4434d30f67
STEP: Creating secret with name s-test-opt-upd-668f23f8-da17-11e9-8fe5-1a4434d30f67
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-668f23c1-da17-11e9-8fe5-1a4434d30f67
STEP: Updating secret s-test-opt-upd-668f23f8-da17-11e9-8fe5-1a4434d30f67
STEP: Creating secret with name s-test-opt-create-668f240c-da17-11e9-8fe5-1a4434d30f67
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:23:53.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4484" for this suite.
Sep 18 13:24:15.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:24:16.194: INFO: namespace projected-4484 deletion completed in 22.258706249s

• [SLOW TEST:91.132 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:24:16.194: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 13:24:16.248: INFO: Creating deployment "test-recreate-deployment"
Sep 18 13:24:16.257: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep 18 13:24:16.276: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Sep 18 13:24:18.291: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep 18 13:24:18.298: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep 18 13:24:18.316: INFO: Updating deployment test-recreate-deployment
Sep 18 13:24:18.316: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep 18 13:24:18.428: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-7660,SelfLink:/apis/apps/v1/namespaces/deployment-7660/deployments/test-recreate-deployment,UID:9ce147be-da17-11e9-b983-fa163edda742,ResourceVersion:234694,Generation:2,CreationTimestamp:2019-09-18 13:24:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-09-18 13:24:18 +0000 UTC 2019-09-18 13:24:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-18 13:24:18 +0000 UTC 2019-09-18 13:24:16 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-745fb9c84c" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Sep 18 13:24:18.438: INFO: New ReplicaSet "test-recreate-deployment-745fb9c84c" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c,GenerateName:,Namespace:deployment-7660,SelfLink:/apis/apps/v1/namespaces/deployment-7660/replicasets/test-recreate-deployment-745fb9c84c,UID:9e24ab0b-da17-11e9-b983-fa163edda742,ResourceVersion:234692,Generation:1,CreationTimestamp:2019-09-18 13:24:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 9ce147be-da17-11e9-b983-fa163edda742 0xc002031677 0xc002031678}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 18 13:24:18.438: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep 18 13:24:18.438: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6566d46b4b,GenerateName:,Namespace:deployment-7660,SelfLink:/apis/apps/v1/namespaces/deployment-7660/replicasets/test-recreate-deployment-6566d46b4b,UID:9ce28b04-da17-11e9-b983-fa163edda742,ResourceVersion:234685,Generation:2,CreationTimestamp:2019-09-18 13:24:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 9ce147be-da17-11e9-b983-fa163edda742 0xc0020315a7 0xc0020315a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 18 13:24:18.446: INFO: Pod "test-recreate-deployment-745fb9c84c-ptjfm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c-ptjfm,GenerateName:test-recreate-deployment-745fb9c84c-,Namespace:deployment-7660,SelfLink:/api/v1/namespaces/deployment-7660/pods/test-recreate-deployment-745fb9c84c-ptjfm,UID:9e260076-da17-11e9-b983-fa163edda742,ResourceVersion:234697,Generation:0,CreationTimestamp:2019-09-18 13:24:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-745fb9c84c 9e24ab0b-da17-11e9-b983-fa163edda742 0xc0034eabd7 0xc0034eabd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kcf4v {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kcf4v,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kcf4v true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1qxh-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034eac40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034eac60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:24:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:24:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:24:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:24:18 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.5,PodIP:,StartTime:2019-09-18 13:24:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:24:18.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7660" for this suite.
Sep 18 13:24:24.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:24:24.708: INFO: namespace deployment-7660 deletion completed in 6.25155083s

• [SLOW TEST:8.514 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:24:24.708: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 18 13:24:24.776: INFO: Waiting up to 5m0s for pod "pod-a1f2622e-da17-11e9-8fe5-1a4434d30f67" in namespace "emptydir-8601" to be "success or failure"
Sep 18 13:24:24.782: INFO: Pod "pod-a1f2622e-da17-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.49954ms
Sep 18 13:24:26.791: INFO: Pod "pod-a1f2622e-da17-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014549879s
STEP: Saw pod success
Sep 18 13:24:26.791: INFO: Pod "pod-a1f2622e-da17-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:24:26.797: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-a1f2622e-da17-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 13:24:26.838: INFO: Waiting for pod pod-a1f2622e-da17-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:24:26.845: INFO: Pod pod-a1f2622e-da17-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:24:26.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8601" for this suite.
Sep 18 13:24:32.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:24:33.097: INFO: namespace emptydir-8601 deletion completed in 6.241507107s

• [SLOW TEST:8.389 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:24:33.097: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep 18 13:24:36.221: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:24:37.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-527" for this suite.
Sep 18 13:24:59.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:24:59.513: INFO: namespace replicaset-527 deletion completed in 22.248409299s

• [SLOW TEST:26.416 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:24:59.513: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep 18 13:24:59.613: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3275,SelfLink:/api/v1/namespaces/watch-3275/configmaps/e2e-watch-test-label-changed,UID:b6b4b27f-da17-11e9-b983-fa163edda742,ResourceVersion:234888,Generation:0,CreationTimestamp:2019-09-18 13:24:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 18 13:24:59.614: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3275,SelfLink:/api/v1/namespaces/watch-3275/configmaps/e2e-watch-test-label-changed,UID:b6b4b27f-da17-11e9-b983-fa163edda742,ResourceVersion:234889,Generation:0,CreationTimestamp:2019-09-18 13:24:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep 18 13:24:59.614: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3275,SelfLink:/api/v1/namespaces/watch-3275/configmaps/e2e-watch-test-label-changed,UID:b6b4b27f-da17-11e9-b983-fa163edda742,ResourceVersion:234890,Generation:0,CreationTimestamp:2019-09-18 13:24:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep 18 13:25:09.676: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3275,SelfLink:/api/v1/namespaces/watch-3275/configmaps/e2e-watch-test-label-changed,UID:b6b4b27f-da17-11e9-b983-fa163edda742,ResourceVersion:234912,Generation:0,CreationTimestamp:2019-09-18 13:24:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 18 13:25:09.676: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3275,SelfLink:/api/v1/namespaces/watch-3275/configmaps/e2e-watch-test-label-changed,UID:b6b4b27f-da17-11e9-b983-fa163edda742,ResourceVersion:234913,Generation:0,CreationTimestamp:2019-09-18 13:24:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Sep 18 13:25:09.676: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3275,SelfLink:/api/v1/namespaces/watch-3275/configmaps/e2e-watch-test-label-changed,UID:b6b4b27f-da17-11e9-b983-fa163edda742,ResourceVersion:234914,Generation:0,CreationTimestamp:2019-09-18 13:24:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:25:09.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3275" for this suite.
Sep 18 13:25:15.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:25:15.929: INFO: namespace watch-3275 deletion completed in 6.241983575s

• [SLOW TEST:16.416 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:25:15.929: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 13:25:16.025: INFO: Create a RollingUpdate DaemonSet
Sep 18 13:25:16.033: INFO: Check that daemon pods launch on every node of the cluster
Sep 18 13:25:16.050: INFO: Number of nodes with available pods: 0
Sep 18 13:25:16.050: INFO: Node k8s-node-vm1qxh-95up3dyso1 is running more than one daemon pod
Sep 18 13:25:17.072: INFO: Number of nodes with available pods: 2
Sep 18 13:25:17.072: INFO: Number of running nodes: 2, number of available pods: 2
Sep 18 13:25:17.072: INFO: Update the DaemonSet to trigger a rollout
Sep 18 13:25:17.088: INFO: Updating DaemonSet daemon-set
Sep 18 13:25:32.112: INFO: Roll back the DaemonSet before rollout is complete
Sep 18 13:25:32.127: INFO: Updating DaemonSet daemon-set
Sep 18 13:25:32.127: INFO: Make sure DaemonSet rollback is complete
Sep 18 13:25:32.137: INFO: Wrong image for pod: daemon-set-rr9th. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 18 13:25:32.137: INFO: Pod daemon-set-rr9th is not available
Sep 18 13:25:33.155: INFO: Wrong image for pod: daemon-set-rr9th. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 18 13:25:33.155: INFO: Pod daemon-set-rr9th is not available
Sep 18 13:25:34.156: INFO: Wrong image for pod: daemon-set-rr9th. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 18 13:25:34.156: INFO: Pod daemon-set-rr9th is not available
Sep 18 13:25:35.156: INFO: Pod daemon-set-7pvjn is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9384, will wait for the garbage collector to delete the pods
Sep 18 13:25:35.254: INFO: Deleting DaemonSet.extensions daemon-set took: 16.007834ms
Sep 18 13:25:35.555: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.202625ms
Sep 18 13:25:47.262: INFO: Number of nodes with available pods: 0
Sep 18 13:25:47.262: INFO: Number of running nodes: 0, number of available pods: 0
Sep 18 13:25:47.268: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9384/daemonsets","resourceVersion":"235076"},"items":null}

Sep 18 13:25:47.274: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9384/pods","resourceVersion":"235076"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:25:47.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9384" for this suite.
Sep 18 13:25:53.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:25:53.558: INFO: namespace daemonsets-9384 deletion completed in 6.247064001s

• [SLOW TEST:37.629 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:25:53.559: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-9974
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 18 13:25:53.615: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 18 13:26:11.749: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.0.192.17 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9974 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 13:26:11.749: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 13:26:12.837: INFO: Found all expected endpoints: [netserver-0]
Sep 18 13:26:12.845: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.0.192.9 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9974 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 13:26:12.845: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 13:26:13.928: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:26:13.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9974" for this suite.
Sep 18 13:26:37.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:26:38.185: INFO: namespace pod-network-test-9974 deletion completed in 24.245234442s

• [SLOW TEST:44.626 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:26:38.185: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1576
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 18 13:26:38.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-5685'
Sep 18 13:26:38.361: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 18 13:26:38.361: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1581
Sep 18 13:26:38.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 delete jobs e2e-test-nginx-job --namespace=kubectl-5685'
Sep 18 13:26:38.455: INFO: stderr: ""
Sep 18 13:26:38.455: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:26:38.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5685" for this suite.
Sep 18 13:27:00.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:27:00.726: INFO: namespace kubectl-5685 deletion completed in 22.259977694s

• [SLOW TEST:22.541 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:27:00.726: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Sep 18 13:27:00.794: INFO: Waiting up to 5m0s for pod "client-containers-fef0bcec-da17-11e9-8fe5-1a4434d30f67" in namespace "containers-8291" to be "success or failure"
Sep 18 13:27:00.801: INFO: Pod "client-containers-fef0bcec-da17-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.096143ms
Sep 18 13:27:02.809: INFO: Pod "client-containers-fef0bcec-da17-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015032118s
STEP: Saw pod success
Sep 18 13:27:02.809: INFO: Pod "client-containers-fef0bcec-da17-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:27:02.816: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod client-containers-fef0bcec-da17-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 13:27:02.856: INFO: Waiting for pod client-containers-fef0bcec-da17-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:27:02.863: INFO: Pod client-containers-fef0bcec-da17-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:27:02.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8291" for this suite.
Sep 18 13:27:08.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:27:09.122: INFO: namespace containers-8291 deletion completed in 6.248223501s

• [SLOW TEST:8.397 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:27:09.123: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 13:27:09.195: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep 18 13:27:14.203: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 18 13:27:14.203: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep 18 13:27:16.266: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-2000,SelfLink:/apis/apps/v1/namespaces/deployment-2000/deployments/test-cleanup-deployment,UID:06f480be-da18-11e9-b983-fa163edda742,ResourceVersion:235447,Generation:1,CreationTimestamp:2019-09-18 13:27:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-18 13:27:14 +0000 UTC 2019-09-18 13:27:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-18 13:27:15 +0000 UTC 2019-09-18 13:27:14 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-6865c98b76" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep 18 13:27:16.273: INFO: New ReplicaSet "test-cleanup-deployment-6865c98b76" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76,GenerateName:,Namespace:deployment-2000,SelfLink:/apis/apps/v1/namespaces/deployment-2000/replicasets/test-cleanup-deployment-6865c98b76,UID:06f81107-da18-11e9-b983-fa163edda742,ResourceVersion:235436,Generation:1,CreationTimestamp:2019-09-18 13:27:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 06f480be-da18-11e9-b983-fa163edda742 0xc002692227 0xc002692228}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep 18 13:27:16.280: INFO: Pod "test-cleanup-deployment-6865c98b76-jjhhx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76-jjhhx,GenerateName:test-cleanup-deployment-6865c98b76-,Namespace:deployment-2000,SelfLink:/api/v1/namespaces/deployment-2000/pods/test-cleanup-deployment-6865c98b76-jjhhx,UID:06f92025-da18-11e9-b983-fa163edda742,ResourceVersion:235435,Generation:0,CreationTimestamp:2019-09-18 13:27:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-6865c98b76 06f81107-da18-11e9-b983-fa163edda742 0xc002692807 0xc002692808}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tkg77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tkg77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-tkg77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1qxh-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002692870} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002692890}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:27:14 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:27:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:27:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:27:14 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.5,PodIP:10.0.192.37,StartTime:2019-09-18 13:27:14 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-18 13:27:14 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/kubernetes-e2e-test-images/redis@sha256:2238f5a02d2648d41cc94a88f084060fbfa860890220328eb92696bf2ac649c9 docker://90589d5a0d41cc28360ef5b654c7034f5fa6caf82596ea5326dfc81a83b13377}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:27:16.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2000" for this suite.
Sep 18 13:27:22.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:27:22.541: INFO: namespace deployment-2000 deletion completed in 6.25040452s

• [SLOW TEST:13.418 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:27:22.541: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 18 13:27:22.615: INFO: Waiting up to 5m0s for pod "pod-0bf27879-da18-11e9-8fe5-1a4434d30f67" in namespace "emptydir-3009" to be "success or failure"
Sep 18 13:27:22.621: INFO: Pod "pod-0bf27879-da18-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.577896ms
Sep 18 13:27:24.629: INFO: Pod "pod-0bf27879-da18-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014381026s
STEP: Saw pod success
Sep 18 13:27:24.629: INFO: Pod "pod-0bf27879-da18-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:27:24.636: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-0bf27879-da18-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 13:27:24.677: INFO: Waiting for pod pod-0bf27879-da18-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:27:24.684: INFO: Pod pod-0bf27879-da18-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:27:24.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3009" for this suite.
Sep 18 13:27:30.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:27:30.944: INFO: namespace emptydir-3009 deletion completed in 6.249451815s

• [SLOW TEST:8.403 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:27:30.944: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1256
STEP: creating an rc
Sep 18 13:27:30.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 create -f - --namespace=kubectl-9654'
Sep 18 13:27:31.116: INFO: stderr: ""
Sep 18 13:27:31.116: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Sep 18 13:27:32.124: INFO: Selector matched 1 pods for map[app:redis]
Sep 18 13:27:32.124: INFO: Found 1 / 1
Sep 18 13:27:32.124: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 18 13:27:32.131: INFO: Selector matched 1 pods for map[app:redis]
Sep 18 13:27:32.131: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Sep 18 13:27:32.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 logs redis-master-b6mt7 redis-master --namespace=kubectl-9654'
Sep 18 13:27:32.219: INFO: stderr: ""
Sep 18 13:27:32.219: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Sep 13:27:31.666 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Sep 13:27:31.666 # Server started, Redis version 3.2.12\n1:M 18 Sep 13:27:31.666 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Sep 13:27:31.666 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Sep 18 13:27:32.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 log redis-master-b6mt7 redis-master --namespace=kubectl-9654 --tail=1'
Sep 18 13:27:32.298: INFO: stderr: ""
Sep 18 13:27:32.298: INFO: stdout: "1:M 18 Sep 13:27:31.666 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Sep 18 13:27:32.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 log redis-master-b6mt7 redis-master --namespace=kubectl-9654 --limit-bytes=1'
Sep 18 13:27:32.379: INFO: stderr: ""
Sep 18 13:27:32.379: INFO: stdout: " "
STEP: exposing timestamps
Sep 18 13:27:32.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 log redis-master-b6mt7 redis-master --namespace=kubectl-9654 --tail=1 --timestamps'
Sep 18 13:27:32.460: INFO: stderr: ""
Sep 18 13:27:32.461: INFO: stdout: "2019-09-18T13:27:31.667189292Z 1:M 18 Sep 13:27:31.666 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Sep 18 13:27:34.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 log redis-master-b6mt7 redis-master --namespace=kubectl-9654 --since=1s'
Sep 18 13:27:35.054: INFO: stderr: ""
Sep 18 13:27:35.054: INFO: stdout: ""
Sep 18 13:27:35.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 log redis-master-b6mt7 redis-master --namespace=kubectl-9654 --since=24h'
Sep 18 13:27:35.137: INFO: stderr: ""
Sep 18 13:27:35.137: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Sep 13:27:31.666 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Sep 13:27:31.666 # Server started, Redis version 3.2.12\n1:M 18 Sep 13:27:31.666 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Sep 13:27:31.666 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
STEP: using delete to clean up resources
Sep 18 13:27:35.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 delete --grace-period=0 --force -f - --namespace=kubectl-9654'
Sep 18 13:27:35.216: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 18 13:27:35.216: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Sep 18 13:27:35.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get rc,svc -l name=nginx --no-headers --namespace=kubectl-9654'
Sep 18 13:27:35.286: INFO: stderr: "No resources found.\n"
Sep 18 13:27:35.286: INFO: stdout: ""
Sep 18 13:27:35.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods -l name=nginx --namespace=kubectl-9654 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 18 13:27:35.349: INFO: stderr: ""
Sep 18 13:27:35.349: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:27:35.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9654" for this suite.
Sep 18 13:27:57.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:27:57.610: INFO: namespace kubectl-9654 deletion completed in 22.250168471s

• [SLOW TEST:26.665 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:27:57.610: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1649
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 18 13:27:57.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1438'
Sep 18 13:27:57.737: INFO: stderr: ""
Sep 18 13:27:57.737: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1654
Sep 18 13:27:57.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 delete pods e2e-test-nginx-pod --namespace=kubectl-1438'
Sep 18 13:28:07.224: INFO: stderr: ""
Sep 18 13:28:07.224: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:28:07.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1438" for this suite.
Sep 18 13:28:13.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:28:13.496: INFO: namespace kubectl-1438 deletion completed in 6.261211002s

• [SLOW TEST:15.887 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:28:13.497: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-418
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 18 13:28:13.553: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 18 13:28:29.687: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.0.192.24:8080/dial?request=hostName&protocol=udp&host=10.0.192.19&port=8081&tries=1'] Namespace:pod-network-test-418 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 13:28:29.687: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 13:28:29.774: INFO: Waiting for endpoints: map[]
Sep 18 13:28:29.781: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.0.192.24:8080/dial?request=hostName&protocol=udp&host=10.0.192.6&port=8081&tries=1'] Namespace:pod-network-test-418 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 13:28:29.781: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 13:28:29.870: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:28:29.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-418" for this suite.
Sep 18 13:28:53.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:28:54.125: INFO: namespace pod-network-test-418 deletion completed in 24.244020164s

• [SLOW TEST:40.628 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:28:54.125: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 13:28:54.185: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:28:55.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5680" for this suite.
Sep 18 13:29:01.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:29:01.556: INFO: namespace custom-resource-definition-5680 deletion completed in 6.264133444s

• [SLOW TEST:7.431 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:32
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:29:01.557: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Sep 18 13:29:01.613: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-496730594 proxy --unix-socket=/tmp/kubectl-proxy-unix389868573/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:29:01.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7786" for this suite.
Sep 18 13:29:07.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:29:07.917: INFO: namespace kubectl-7786 deletion completed in 6.25001125s

• [SLOW TEST:6.361 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:29:07.917: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-4ac0d9bc-da18-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume secrets
Sep 18 13:29:07.995: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4ac220a4-da18-11e9-8fe5-1a4434d30f67" in namespace "projected-5688" to be "success or failure"
Sep 18 13:29:08.002: INFO: Pod "pod-projected-secrets-4ac220a4-da18-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.135209ms
Sep 18 13:29:10.010: INFO: Pod "pod-projected-secrets-4ac220a4-da18-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014937159s
STEP: Saw pod success
Sep 18 13:29:10.010: INFO: Pod "pod-projected-secrets-4ac220a4-da18-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:29:10.017: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-projected-secrets-4ac220a4-da18-11e9-8fe5-1a4434d30f67 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 18 13:29:10.060: INFO: Waiting for pod pod-projected-secrets-4ac220a4-da18-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:29:10.067: INFO: Pod pod-projected-secrets-4ac220a4-da18-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:29:10.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5688" for this suite.
Sep 18 13:29:16.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:29:16.322: INFO: namespace projected-5688 deletion completed in 6.244522174s

• [SLOW TEST:8.405 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:29:16.322: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Sep 18 13:29:16.391: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9415" to be "success or failure"
Sep 18 13:29:16.403: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 11.947996ms
Sep 18 13:29:18.411: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019771307s
STEP: Saw pod success
Sep 18 13:29:18.411: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Sep 18 13:29:18.418: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep 18 13:29:18.457: INFO: Waiting for pod pod-host-path-test to disappear
Sep 18 13:29:18.464: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:29:18.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-9415" for this suite.
Sep 18 13:29:24.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:29:24.773: INFO: namespace hostpath-9415 deletion completed in 6.298614949s

• [SLOW TEST:8.450 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:29:24.773: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-b6bd
STEP: Creating a pod to test atomic-volume-subpath
Sep 18 13:29:24.857: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-b6bd" in namespace "subpath-5240" to be "success or failure"
Sep 18 13:29:24.863: INFO: Pod "pod-subpath-test-secret-b6bd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.381538ms
Sep 18 13:29:26.871: INFO: Pod "pod-subpath-test-secret-b6bd": Phase="Running", Reason="", readiness=true. Elapsed: 2.014325458s
Sep 18 13:29:28.879: INFO: Pod "pod-subpath-test-secret-b6bd": Phase="Running", Reason="", readiness=true. Elapsed: 4.022144609s
Sep 18 13:29:30.887: INFO: Pod "pod-subpath-test-secret-b6bd": Phase="Running", Reason="", readiness=true. Elapsed: 6.030356894s
Sep 18 13:29:32.895: INFO: Pod "pod-subpath-test-secret-b6bd": Phase="Running", Reason="", readiness=true. Elapsed: 8.038389992s
Sep 18 13:29:34.903: INFO: Pod "pod-subpath-test-secret-b6bd": Phase="Running", Reason="", readiness=true. Elapsed: 10.046372787s
Sep 18 13:29:36.911: INFO: Pod "pod-subpath-test-secret-b6bd": Phase="Running", Reason="", readiness=true. Elapsed: 12.053945141s
Sep 18 13:29:38.918: INFO: Pod "pod-subpath-test-secret-b6bd": Phase="Running", Reason="", readiness=true. Elapsed: 14.061255555s
Sep 18 13:29:40.926: INFO: Pod "pod-subpath-test-secret-b6bd": Phase="Running", Reason="", readiness=true. Elapsed: 16.069332288s
Sep 18 13:29:42.934: INFO: Pod "pod-subpath-test-secret-b6bd": Phase="Running", Reason="", readiness=true. Elapsed: 18.077252157s
Sep 18 13:29:44.942: INFO: Pod "pod-subpath-test-secret-b6bd": Phase="Running", Reason="", readiness=true. Elapsed: 20.085215317s
Sep 18 13:29:46.951: INFO: Pod "pod-subpath-test-secret-b6bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.093783331s
STEP: Saw pod success
Sep 18 13:29:46.951: INFO: Pod "pod-subpath-test-secret-b6bd" satisfied condition "success or failure"
Sep 18 13:29:46.958: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-subpath-test-secret-b6bd container test-container-subpath-secret-b6bd: <nil>
STEP: delete the pod
Sep 18 13:29:47.002: INFO: Waiting for pod pod-subpath-test-secret-b6bd to disappear
Sep 18 13:29:47.009: INFO: Pod pod-subpath-test-secret-b6bd no longer exists
STEP: Deleting pod pod-subpath-test-secret-b6bd
Sep 18 13:29:47.009: INFO: Deleting pod "pod-subpath-test-secret-b6bd" in namespace "subpath-5240"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:29:47.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5240" for this suite.
Sep 18 13:29:53.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:29:53.272: INFO: namespace subpath-5240 deletion completed in 6.246633698s

• [SLOW TEST:28.500 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:29:53.273: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep 18 13:29:53.329: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 18 13:29:53.352: INFO: Waiting for terminating namespaces to be deleted...
Sep 18 13:29:53.359: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm1qxh-95up3dyso1 before test
Sep 18 13:29:53.375: INFO: sonobuoy-e2e-job-f17ac7a1786c4dde from heptio-sonobuoy started at 2019-09-18 12:35:13 +0000 UTC (2 container statuses recorded)
Sep 18 13:29:53.375: INFO: 	Container e2e ready: true, restart count 0
Sep 18 13:29:53.375: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 18 13:29:53.375: INFO: coredns-6b4fdb779b-qzqfd from kube-system started at 2019-09-18 09:40:53 +0000 UTC (1 container statuses recorded)
Sep 18 13:29:53.375: INFO: 	Container coredns ready: true, restart count 8
Sep 18 13:29:53.375: INFO: sonobuoy-systemd-logs-daemon-set-c0812b53cb224d4d-cbx95 from heptio-sonobuoy started at 2019-09-18 12:35:13 +0000 UTC (2 container statuses recorded)
Sep 18 13:29:53.375: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 18 13:29:53.375: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 18 13:29:53.375: INFO: node-exporter-fwmxn from jke-system started at 2019-09-17 13:32:00 +0000 UTC (1 container statuses recorded)
Sep 18 13:29:53.375: INFO: 	Container node-exporter ready: true, restart count 0
Sep 18 13:29:53.375: INFO: kube-proxy-hx4lq from kube-system started at 2019-09-17 13:32:00 +0000 UTC (1 container statuses recorded)
Sep 18 13:29:53.375: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 18 13:29:53.375: INFO: jdcloud-k8s-ipamd-6sz6f from kube-system started at 2019-09-17 13:31:44 +0000 UTC (1 container statuses recorded)
Sep 18 13:29:53.375: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Sep 18 13:29:53.375: INFO: csi-jdcloudplugin-z2wwd from jke-system started at 2019-09-17 13:32:00 +0000 UTC (2 container statuses recorded)
Sep 18 13:29:53.375: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 18 13:29:53.375: INFO: 	Container jdcloud-csi ready: true, restart count 0
Sep 18 13:29:53.375: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-18 12:31:22 +0000 UTC (1 container statuses recorded)
Sep 18 13:29:53.375: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 18 13:29:53.375: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm599z-95up3dyso1 before test
Sep 18 13:29:53.399: INFO: kube-state-metrics-546cf6cfd8-4q5ww from jke-system started at 2019-09-17 13:31:14 +0000 UTC (2 container statuses recorded)
Sep 18 13:29:53.399: INFO: 	Container addon-resizer ready: true, restart count 0
Sep 18 13:29:53.399: INFO: 	Container kube-state-metrics ready: true, restart count 0
Sep 18 13:29:53.399: INFO: coredns-6b4fdb779b-g9pl5 from kube-system started at 2019-09-17 13:31:22 +0000 UTC (1 container statuses recorded)
Sep 18 13:29:53.399: INFO: 	Container coredns ready: true, restart count 9
Sep 18 13:29:53.399: INFO: kubernetes-dashboard-5c846c6494-t95sr from kube-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 13:29:53.399: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 18 13:29:53.399: INFO: heapster-77dc7fd7fd-xzfww from kube-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 13:29:53.399: INFO: 	Container heapster ready: true, restart count 0
Sep 18 13:29:53.399: INFO: prometheus-559998dfcb-v6rsx from jke-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 13:29:53.399: INFO: 	Container prometheus ready: true, restart count 0
Sep 18 13:29:53.399: INFO: kube-proxy-l4vgf from kube-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 13:29:53.399: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 18 13:29:53.399: INFO: csi-jdcloudplugin-xrkh7 from jke-system started at 2019-09-17 13:31:14 +0000 UTC (2 container statuses recorded)
Sep 18 13:29:53.399: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 18 13:29:53.399: INFO: 	Container jdcloud-csi ready: true, restart count 0
Sep 18 13:29:53.399: INFO: node-exporter-hx9hf from jke-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 13:29:53.399: INFO: 	Container node-exporter ready: true, restart count 0
Sep 18 13:29:53.399: INFO: jdcloud-k8s-ipamd-sc9ft from kube-system started at 2019-09-17 13:31:00 +0000 UTC (1 container statuses recorded)
Sep 18 13:29:53.399: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Sep 18 13:29:53.399: INFO: prometheus-jdmon-5f8bdc758-r998b from jke-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 13:29:53.399: INFO: 	Container k8s-metrics-to-jdmon ready: true, restart count 2
Sep 18 13:29:53.399: INFO: csi-jdcloudplugin-controller-0 from jke-system started at 2019-09-17 13:31:14 +0000 UTC (4 container statuses recorded)
Sep 18 13:29:53.399: INFO: 	Container csi-attacher ready: true, restart count 0
Sep 18 13:29:53.399: INFO: 	Container csi-provisioner ready: true, restart count 0
Sep 18 13:29:53.399: INFO: 	Container jdcloud-csi ready: true, restart count 0
Sep 18 13:29:53.399: INFO: 	Container liveness-probe ready: true, restart count 0
Sep 18 13:29:53.399: INFO: sonobuoy-systemd-logs-daemon-set-c0812b53cb224d4d-dtpxn from heptio-sonobuoy started at 2019-09-18 12:35:13 +0000 UTC (2 container statuses recorded)
Sep 18 13:29:53.399: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 18 13:29:53.399: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c58b782b94275c], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:29:54.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9466" for this suite.
Sep 18 13:30:00.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:30:00.708: INFO: namespace sched-pred-9466 deletion completed in 6.249890368s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.435 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:30:00.708: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 13:30:00.778: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a38553d-da18-11e9-8fe5-1a4434d30f67" in namespace "projected-2058" to be "success or failure"
Sep 18 13:30:00.785: INFO: Pod "downwardapi-volume-6a38553d-da18-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.232583ms
Sep 18 13:30:02.793: INFO: Pod "downwardapi-volume-6a38553d-da18-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014922261s
STEP: Saw pod success
Sep 18 13:30:02.793: INFO: Pod "downwardapi-volume-6a38553d-da18-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:30:02.799: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-6a38553d-da18-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 13:30:02.839: INFO: Waiting for pod downwardapi-volume-6a38553d-da18-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:30:02.846: INFO: Pod downwardapi-volume-6a38553d-da18-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:30:02.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2058" for this suite.
Sep 18 13:30:08.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:30:09.104: INFO: namespace projected-2058 deletion completed in 6.247887248s

• [SLOW TEST:8.396 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:30:09.105: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1174
STEP: creating the pod
Sep 18 13:30:09.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 create -f - --namespace=kubectl-1797'
Sep 18 13:30:09.294: INFO: stderr: ""
Sep 18 13:30:09.294: INFO: stdout: "pod/pause created\n"
Sep 18 13:30:09.294: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep 18 13:30:09.294: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1797" to be "running and ready"
Sep 18 13:30:09.301: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 7.425062ms
Sep 18 13:30:11.309: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.015268379s
Sep 18 13:30:11.309: INFO: Pod "pause" satisfied condition "running and ready"
Sep 18 13:30:11.309: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Sep 18 13:30:11.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 label pods pause testing-label=testing-label-value --namespace=kubectl-1797'
Sep 18 13:30:11.384: INFO: stderr: ""
Sep 18 13:30:11.384: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep 18 13:30:11.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pod pause -L testing-label --namespace=kubectl-1797'
Sep 18 13:30:11.447: INFO: stderr: ""
Sep 18 13:30:11.447: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep 18 13:30:11.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 label pods pause testing-label- --namespace=kubectl-1797'
Sep 18 13:30:11.523: INFO: stderr: ""
Sep 18 13:30:11.523: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep 18 13:30:11.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pod pause -L testing-label --namespace=kubectl-1797'
Sep 18 13:30:11.587: INFO: stderr: ""
Sep 18 13:30:11.587: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1181
STEP: using delete to clean up resources
Sep 18 13:30:11.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 delete --grace-period=0 --force -f - --namespace=kubectl-1797'
Sep 18 13:30:11.672: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 18 13:30:11.672: INFO: stdout: "pod \"pause\" force deleted\n"
Sep 18 13:30:11.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get rc,svc -l name=pause --no-headers --namespace=kubectl-1797'
Sep 18 13:30:11.755: INFO: stderr: "No resources found.\n"
Sep 18 13:30:11.755: INFO: stdout: ""
Sep 18 13:30:11.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods -l name=pause --namespace=kubectl-1797 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 18 13:30:11.820: INFO: stderr: ""
Sep 18 13:30:11.820: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:30:11.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1797" for this suite.
Sep 18 13:30:17.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:30:18.075: INFO: namespace kubectl-1797 deletion completed in 6.244258152s

• [SLOW TEST:8.970 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:30:18.075: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-7491ee22-da18-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume secrets
Sep 18 13:30:18.152: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-74931ed0-da18-11e9-8fe5-1a4434d30f67" in namespace "projected-7366" to be "success or failure"
Sep 18 13:30:18.160: INFO: Pod "pod-projected-secrets-74931ed0-da18-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.591353ms
Sep 18 13:30:20.168: INFO: Pod "pod-projected-secrets-74931ed0-da18-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015695584s
STEP: Saw pod success
Sep 18 13:30:20.168: INFO: Pod "pod-projected-secrets-74931ed0-da18-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:30:20.175: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-projected-secrets-74931ed0-da18-11e9-8fe5-1a4434d30f67 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 18 13:30:20.218: INFO: Waiting for pod pod-projected-secrets-74931ed0-da18-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:30:20.224: INFO: Pod pod-projected-secrets-74931ed0-da18-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:30:20.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7366" for this suite.
Sep 18 13:30:26.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:30:26.486: INFO: namespace projected-7366 deletion completed in 6.251600694s

• [SLOW TEST:8.411 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:30:26.486: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 13:30:26.583: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep 18 13:30:26.601: INFO: Number of nodes with available pods: 0
Sep 18 13:30:26.601: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep 18 13:30:26.649: INFO: Number of nodes with available pods: 0
Sep 18 13:30:26.649: INFO: Node k8s-node-vm1qxh-95up3dyso1 is running more than one daemon pod
Sep 18 13:30:27.657: INFO: Number of nodes with available pods: 0
Sep 18 13:30:27.657: INFO: Node k8s-node-vm1qxh-95up3dyso1 is running more than one daemon pod
Sep 18 13:30:28.657: INFO: Number of nodes with available pods: 1
Sep 18 13:30:28.657: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep 18 13:30:28.701: INFO: Number of nodes with available pods: 1
Sep 18 13:30:28.701: INFO: Number of running nodes: 0, number of available pods: 1
Sep 18 13:30:29.709: INFO: Number of nodes with available pods: 0
Sep 18 13:30:29.709: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep 18 13:30:29.730: INFO: Number of nodes with available pods: 0
Sep 18 13:30:29.730: INFO: Node k8s-node-vm1qxh-95up3dyso1 is running more than one daemon pod
Sep 18 13:30:30.738: INFO: Number of nodes with available pods: 0
Sep 18 13:30:30.738: INFO: Node k8s-node-vm1qxh-95up3dyso1 is running more than one daemon pod
Sep 18 13:30:31.738: INFO: Number of nodes with available pods: 0
Sep 18 13:30:31.738: INFO: Node k8s-node-vm1qxh-95up3dyso1 is running more than one daemon pod
Sep 18 13:30:32.738: INFO: Number of nodes with available pods: 0
Sep 18 13:30:32.738: INFO: Node k8s-node-vm1qxh-95up3dyso1 is running more than one daemon pod
Sep 18 13:30:33.738: INFO: Number of nodes with available pods: 1
Sep 18 13:30:33.738: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7332, will wait for the garbage collector to delete the pods
Sep 18 13:30:33.825: INFO: Deleting DaemonSet.extensions daemon-set took: 16.754073ms
Sep 18 13:30:34.126: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.340011ms
Sep 18 13:30:47.333: INFO: Number of nodes with available pods: 0
Sep 18 13:30:47.333: INFO: Number of running nodes: 0, number of available pods: 0
Sep 18 13:30:47.340: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7332/daemonsets","resourceVersion":"236301"},"items":null}

Sep 18 13:30:47.346: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7332/pods","resourceVersion":"236301"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:30:47.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7332" for this suite.
Sep 18 13:30:53.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:30:53.653: INFO: namespace daemonsets-7332 deletion completed in 6.251505177s

• [SLOW TEST:27.166 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:30:53.653: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Sep 18 13:30:53.721: INFO: Waiting up to 5m0s for pod "client-containers-89c6b93f-da18-11e9-8fe5-1a4434d30f67" in namespace "containers-4695" to be "success or failure"
Sep 18 13:30:53.728: INFO: Pod "client-containers-89c6b93f-da18-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.503281ms
Sep 18 13:30:55.736: INFO: Pod "client-containers-89c6b93f-da18-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015297966s
STEP: Saw pod success
Sep 18 13:30:55.736: INFO: Pod "client-containers-89c6b93f-da18-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:30:55.743: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod client-containers-89c6b93f-da18-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 13:30:55.783: INFO: Waiting for pod client-containers-89c6b93f-da18-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:30:55.790: INFO: Pod client-containers-89c6b93f-da18-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:30:55.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4695" for this suite.
Sep 18 13:31:01.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:31:02.049: INFO: namespace containers-4695 deletion completed in 6.248519124s

• [SLOW TEST:8.396 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:31:02.049: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 18 13:31:02.195: INFO: Number of nodes with available pods: 0
Sep 18 13:31:02.196: INFO: Node k8s-node-vm1qxh-95up3dyso1 is running more than one daemon pod
Sep 18 13:31:03.215: INFO: Number of nodes with available pods: 1
Sep 18 13:31:03.215: INFO: Node k8s-node-vm1qxh-95up3dyso1 is running more than one daemon pod
Sep 18 13:31:04.215: INFO: Number of nodes with available pods: 2
Sep 18 13:31:04.215: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep 18 13:31:04.258: INFO: Number of nodes with available pods: 1
Sep 18 13:31:04.258: INFO: Node k8s-node-vm599z-95up3dyso1 is running more than one daemon pod
Sep 18 13:31:05.277: INFO: Number of nodes with available pods: 1
Sep 18 13:31:05.277: INFO: Node k8s-node-vm599z-95up3dyso1 is running more than one daemon pod
Sep 18 13:31:06.277: INFO: Number of nodes with available pods: 1
Sep 18 13:31:06.277: INFO: Node k8s-node-vm599z-95up3dyso1 is running more than one daemon pod
Sep 18 13:31:07.278: INFO: Number of nodes with available pods: 1
Sep 18 13:31:07.278: INFO: Node k8s-node-vm599z-95up3dyso1 is running more than one daemon pod
Sep 18 13:31:08.278: INFO: Number of nodes with available pods: 1
Sep 18 13:31:08.278: INFO: Node k8s-node-vm599z-95up3dyso1 is running more than one daemon pod
Sep 18 13:31:09.277: INFO: Number of nodes with available pods: 1
Sep 18 13:31:09.277: INFO: Node k8s-node-vm599z-95up3dyso1 is running more than one daemon pod
Sep 18 13:31:10.278: INFO: Number of nodes with available pods: 1
Sep 18 13:31:10.278: INFO: Node k8s-node-vm599z-95up3dyso1 is running more than one daemon pod
Sep 18 13:31:11.276: INFO: Number of nodes with available pods: 1
Sep 18 13:31:11.276: INFO: Node k8s-node-vm599z-95up3dyso1 is running more than one daemon pod
Sep 18 13:31:12.277: INFO: Number of nodes with available pods: 1
Sep 18 13:31:12.277: INFO: Node k8s-node-vm599z-95up3dyso1 is running more than one daemon pod
Sep 18 13:31:13.277: INFO: Number of nodes with available pods: 2
Sep 18 13:31:13.277: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-345, will wait for the garbage collector to delete the pods
Sep 18 13:31:13.360: INFO: Deleting DaemonSet.extensions daemon-set took: 18.181807ms
Sep 18 13:31:13.660: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.217742ms
Sep 18 13:31:21.968: INFO: Number of nodes with available pods: 0
Sep 18 13:31:21.968: INFO: Number of running nodes: 0, number of available pods: 0
Sep 18 13:31:21.974: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-345/daemonsets","resourceVersion":"236472"},"items":null}

Sep 18 13:31:21.980: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-345/pods","resourceVersion":"236472"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:31:22.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-345" for this suite.
Sep 18 13:31:28.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:31:28.262: INFO: namespace daemonsets-345 deletion completed in 6.244596592s

• [SLOW TEST:26.213 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:31:28.262: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 13:31:28.331: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e67ccbf-da18-11e9-8fe5-1a4434d30f67" in namespace "downward-api-1572" to be "success or failure"
Sep 18 13:31:28.338: INFO: Pod "downwardapi-volume-9e67ccbf-da18-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.021241ms
Sep 18 13:31:30.346: INFO: Pod "downwardapi-volume-9e67ccbf-da18-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014989912s
STEP: Saw pod success
Sep 18 13:31:30.346: INFO: Pod "downwardapi-volume-9e67ccbf-da18-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:31:30.353: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-9e67ccbf-da18-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 13:31:30.395: INFO: Waiting for pod downwardapi-volume-9e67ccbf-da18-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:31:30.402: INFO: Pod downwardapi-volume-9e67ccbf-da18-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:31:30.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1572" for this suite.
Sep 18 13:31:36.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:31:36.661: INFO: namespace downward-api-1572 deletion completed in 6.249171324s

• [SLOW TEST:8.399 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:31:36.662: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 13:31:36.731: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep 18 13:31:41.738: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 18 13:31:41.738: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep 18 13:31:43.746: INFO: Creating deployment "test-rollover-deployment"
Sep 18 13:31:43.763: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep 18 13:31:45.778: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep 18 13:31:45.791: INFO: Ensure that both replica sets have 1 created replica
Sep 18 13:31:45.805: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep 18 13:31:45.820: INFO: Updating deployment test-rollover-deployment
Sep 18 13:31:45.820: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep 18 13:31:47.836: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep 18 13:31:47.850: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep 18 13:31:47.864: INFO: all replica sets need to contain the pod-template-hash label
Sep 18 13:31:47.864: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410303, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410303, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410306, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410303, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 18 13:31:49.879: INFO: all replica sets need to contain the pod-template-hash label
Sep 18 13:31:49.879: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410303, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410303, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410306, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410303, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 18 13:31:51.879: INFO: all replica sets need to contain the pod-template-hash label
Sep 18 13:31:51.879: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410303, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410303, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410306, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410303, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 18 13:31:53.879: INFO: all replica sets need to contain the pod-template-hash label
Sep 18 13:31:53.879: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410303, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410303, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410306, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410303, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 18 13:31:55.879: INFO: all replica sets need to contain the pod-template-hash label
Sep 18 13:31:55.879: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410303, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410303, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410306, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704410303, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 18 13:31:57.878: INFO: 
Sep 18 13:31:57.879: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep 18 13:31:57.898: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-6472,SelfLink:/apis/apps/v1/namespaces/deployment-6472/deployments/test-rollover-deployment,UID:a79c3a4a-da18-11e9-b983-fa163edda742,ResourceVersion:236660,Generation:2,CreationTimestamp:2019-09-18 13:31:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-18 13:31:43 +0000 UTC 2019-09-18 13:31:43 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-18 13:31:56 +0000 UTC 2019-09-18 13:31:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-659c699649" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep 18 13:31:57.905: INFO: New ReplicaSet "test-rollover-deployment-659c699649" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649,GenerateName:,Namespace:deployment-6472,SelfLink:/apis/apps/v1/namespaces/deployment-6472/replicasets/test-rollover-deployment-659c699649,UID:a8d87ee1-da18-11e9-b983-fa163edda742,ResourceVersion:236649,Generation:2,CreationTimestamp:2019-09-18 13:31:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a79c3a4a-da18-11e9-b983-fa163edda742 0xc002a77bd7 0xc002a77bd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep 18 13:31:57.905: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep 18 13:31:57.905: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-6472,SelfLink:/apis/apps/v1/namespaces/deployment-6472/replicasets/test-rollover-controller,UID:a36b6d8f-da18-11e9-b983-fa163edda742,ResourceVersion:236659,Generation:2,CreationTimestamp:2019-09-18 13:31:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a79c3a4a-da18-11e9-b983-fa163edda742 0xc002a77af7 0xc002a77af8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 18 13:31:57.905: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-7b45b6464,GenerateName:,Namespace:deployment-6472,SelfLink:/apis/apps/v1/namespaces/deployment-6472/replicasets/test-rollover-deployment-7b45b6464,UID:a79f921c-da18-11e9-b983-fa163edda742,ResourceVersion:236617,Generation:2,CreationTimestamp:2019-09-18 13:31:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a79c3a4a-da18-11e9-b983-fa163edda742 0xc002a77ca0 0xc002a77ca1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 18 13:31:57.912: INFO: Pod "test-rollover-deployment-659c699649-8n7sl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649-8n7sl,GenerateName:test-rollover-deployment-659c699649-,Namespace:deployment-6472,SelfLink:/api/v1/namespaces/deployment-6472/pods/test-rollover-deployment-659c699649-8n7sl,UID:a8df40fc-da18-11e9-b983-fa163edda742,ResourceVersion:236626,Generation:0,CreationTimestamp:2019-09-18 13:31:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-659c699649 a8d87ee1-da18-11e9-b983-fa163edda742 0xc0018c0d77 0xc0018c0d78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lbxkr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lbxkr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-lbxkr true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1qxh-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018c0de0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018c0e00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:31:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:31:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:31:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:31:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.5,PodIP:10.0.192.16,StartTime:2019-09-18 13:31:45 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-18 13:31:46 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/kubernetes-e2e-test-images/redis@sha256:2238f5a02d2648d41cc94a88f084060fbfa860890220328eb92696bf2ac649c9 docker://72026ebc79525b3781df832f01f217620ca906b0c3b5b46780f9afaee2dc1739}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:31:57.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6472" for this suite.
Sep 18 13:32:03.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:32:04.177: INFO: namespace deployment-6472 deletion completed in 6.254593312s

• [SLOW TEST:27.516 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:32:04.177: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-b3d03abd-da18-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume secrets
Sep 18 13:32:04.260: INFO: Waiting up to 5m0s for pod "pod-secrets-b3d1b812-da18-11e9-8fe5-1a4434d30f67" in namespace "secrets-1085" to be "success or failure"
Sep 18 13:32:04.268: INFO: Pod "pod-secrets-b3d1b812-da18-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.69879ms
Sep 18 13:32:06.276: INFO: Pod "pod-secrets-b3d1b812-da18-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015836071s
STEP: Saw pod success
Sep 18 13:32:06.276: INFO: Pod "pod-secrets-b3d1b812-da18-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:32:06.283: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-secrets-b3d1b812-da18-11e9-8fe5-1a4434d30f67 container secret-volume-test: <nil>
STEP: delete the pod
Sep 18 13:32:06.324: INFO: Waiting for pod pod-secrets-b3d1b812-da18-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:32:06.330: INFO: Pod pod-secrets-b3d1b812-da18-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:32:06.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1085" for this suite.
Sep 18 13:32:12.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:32:12.594: INFO: namespace secrets-1085 deletion completed in 6.252973392s

• [SLOW TEST:8.416 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:32:12.594: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 13:32:12.662: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b8d411eb-da18-11e9-8fe5-1a4434d30f67" in namespace "projected-3322" to be "success or failure"
Sep 18 13:32:12.669: INFO: Pod "downwardapi-volume-b8d411eb-da18-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.596215ms
Sep 18 13:32:14.678: INFO: Pod "downwardapi-volume-b8d411eb-da18-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015903742s
STEP: Saw pod success
Sep 18 13:32:14.678: INFO: Pod "downwardapi-volume-b8d411eb-da18-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:32:14.685: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-b8d411eb-da18-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 13:32:14.727: INFO: Waiting for pod downwardapi-volume-b8d411eb-da18-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:32:14.734: INFO: Pod downwardapi-volume-b8d411eb-da18-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:32:14.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3322" for this suite.
Sep 18 13:32:20.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:32:20.987: INFO: namespace projected-3322 deletion completed in 6.242302093s

• [SLOW TEST:8.393 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:32:20.988: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Sep 18 13:32:21.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 --namespace=kubectl-1913 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Sep 18 13:32:21.835: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Sep 18 13:32:21.835: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:32:23.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1913" for this suite.
Sep 18 13:32:29.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:32:30.103: INFO: namespace kubectl-1913 deletion completed in 6.243050171s

• [SLOW TEST:9.115 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:32:30.103: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep 18 13:32:30.156: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 18 13:32:30.177: INFO: Waiting for terminating namespaces to be deleted...
Sep 18 13:32:30.183: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm1qxh-95up3dyso1 before test
Sep 18 13:32:30.198: INFO: sonobuoy-e2e-job-f17ac7a1786c4dde from heptio-sonobuoy started at 2019-09-18 12:35:13 +0000 UTC (2 container statuses recorded)
Sep 18 13:32:30.198: INFO: 	Container e2e ready: true, restart count 0
Sep 18 13:32:30.198: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 18 13:32:30.198: INFO: coredns-6b4fdb779b-qzqfd from kube-system started at 2019-09-18 09:40:53 +0000 UTC (1 container statuses recorded)
Sep 18 13:32:30.198: INFO: 	Container coredns ready: true, restart count 8
Sep 18 13:32:30.198: INFO: sonobuoy-systemd-logs-daemon-set-c0812b53cb224d4d-cbx95 from heptio-sonobuoy started at 2019-09-18 12:35:13 +0000 UTC (2 container statuses recorded)
Sep 18 13:32:30.198: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 18 13:32:30.198: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 18 13:32:30.198: INFO: node-exporter-fwmxn from jke-system started at 2019-09-17 13:32:00 +0000 UTC (1 container statuses recorded)
Sep 18 13:32:30.198: INFO: 	Container node-exporter ready: true, restart count 0
Sep 18 13:32:30.198: INFO: kube-proxy-hx4lq from kube-system started at 2019-09-17 13:32:00 +0000 UTC (1 container statuses recorded)
Sep 18 13:32:30.198: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 18 13:32:30.198: INFO: jdcloud-k8s-ipamd-6sz6f from kube-system started at 2019-09-17 13:31:44 +0000 UTC (1 container statuses recorded)
Sep 18 13:32:30.198: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Sep 18 13:32:30.198: INFO: csi-jdcloudplugin-z2wwd from jke-system started at 2019-09-17 13:32:00 +0000 UTC (2 container statuses recorded)
Sep 18 13:32:30.198: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 18 13:32:30.198: INFO: 	Container jdcloud-csi ready: true, restart count 0
Sep 18 13:32:30.198: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-18 12:31:22 +0000 UTC (1 container statuses recorded)
Sep 18 13:32:30.198: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 18 13:32:30.198: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm599z-95up3dyso1 before test
Sep 18 13:32:30.212: INFO: csi-jdcloudplugin-controller-0 from jke-system started at 2019-09-17 13:31:14 +0000 UTC (4 container statuses recorded)
Sep 18 13:32:30.212: INFO: 	Container csi-attacher ready: true, restart count 0
Sep 18 13:32:30.212: INFO: 	Container csi-provisioner ready: true, restart count 0
Sep 18 13:32:30.212: INFO: 	Container jdcloud-csi ready: true, restart count 0
Sep 18 13:32:30.212: INFO: 	Container liveness-probe ready: true, restart count 0
Sep 18 13:32:30.212: INFO: sonobuoy-systemd-logs-daemon-set-c0812b53cb224d4d-dtpxn from heptio-sonobuoy started at 2019-09-18 12:35:13 +0000 UTC (2 container statuses recorded)
Sep 18 13:32:30.212: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 18 13:32:30.212: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 18 13:32:30.212: INFO: prometheus-jdmon-5f8bdc758-r998b from jke-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 13:32:30.212: INFO: 	Container k8s-metrics-to-jdmon ready: true, restart count 2
Sep 18 13:32:30.212: INFO: kube-state-metrics-546cf6cfd8-4q5ww from jke-system started at 2019-09-17 13:31:14 +0000 UTC (2 container statuses recorded)
Sep 18 13:32:30.212: INFO: 	Container addon-resizer ready: true, restart count 0
Sep 18 13:32:30.212: INFO: 	Container kube-state-metrics ready: true, restart count 0
Sep 18 13:32:30.212: INFO: kubernetes-dashboard-5c846c6494-t95sr from kube-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 13:32:30.212: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 18 13:32:30.212: INFO: coredns-6b4fdb779b-g9pl5 from kube-system started at 2019-09-17 13:31:22 +0000 UTC (1 container statuses recorded)
Sep 18 13:32:30.212: INFO: 	Container coredns ready: true, restart count 9
Sep 18 13:32:30.212: INFO: prometheus-559998dfcb-v6rsx from jke-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 13:32:30.212: INFO: 	Container prometheus ready: true, restart count 0
Sep 18 13:32:30.212: INFO: kube-proxy-l4vgf from kube-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 13:32:30.212: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 18 13:32:30.212: INFO: csi-jdcloudplugin-xrkh7 from jke-system started at 2019-09-17 13:31:14 +0000 UTC (2 container statuses recorded)
Sep 18 13:32:30.212: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 18 13:32:30.212: INFO: 	Container jdcloud-csi ready: true, restart count 0
Sep 18 13:32:30.212: INFO: node-exporter-hx9hf from jke-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 13:32:30.212: INFO: 	Container node-exporter ready: true, restart count 0
Sep 18 13:32:30.212: INFO: jdcloud-k8s-ipamd-sc9ft from kube-system started at 2019-09-17 13:31:00 +0000 UTC (1 container statuses recorded)
Sep 18 13:32:30.212: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Sep 18 13:32:30.212: INFO: heapster-77dc7fd7fd-xzfww from kube-system started at 2019-09-17 13:31:14 +0000 UTC (1 container statuses recorded)
Sep 18 13:32:30.212: INFO: 	Container heapster ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node k8s-node-vm1qxh-95up3dyso1
STEP: verifying the node has the label node k8s-node-vm599z-95up3dyso1
Sep 18 13:32:30.295: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s-node-vm1qxh-95up3dyso1
Sep 18 13:32:30.295: INFO: Pod sonobuoy-e2e-job-f17ac7a1786c4dde requesting resource cpu=0m on Node k8s-node-vm1qxh-95up3dyso1
Sep 18 13:32:30.295: INFO: Pod sonobuoy-systemd-logs-daemon-set-c0812b53cb224d4d-cbx95 requesting resource cpu=0m on Node k8s-node-vm1qxh-95up3dyso1
Sep 18 13:32:30.295: INFO: Pod sonobuoy-systemd-logs-daemon-set-c0812b53cb224d4d-dtpxn requesting resource cpu=0m on Node k8s-node-vm599z-95up3dyso1
Sep 18 13:32:30.295: INFO: Pod csi-jdcloudplugin-controller-0 requesting resource cpu=0m on Node k8s-node-vm599z-95up3dyso1
Sep 18 13:32:30.295: INFO: Pod csi-jdcloudplugin-xrkh7 requesting resource cpu=0m on Node k8s-node-vm599z-95up3dyso1
Sep 18 13:32:30.295: INFO: Pod csi-jdcloudplugin-z2wwd requesting resource cpu=0m on Node k8s-node-vm1qxh-95up3dyso1
Sep 18 13:32:30.295: INFO: Pod kube-state-metrics-546cf6cfd8-4q5ww requesting resource cpu=202m on Node k8s-node-vm599z-95up3dyso1
Sep 18 13:32:30.295: INFO: Pod node-exporter-fwmxn requesting resource cpu=0m on Node k8s-node-vm1qxh-95up3dyso1
Sep 18 13:32:30.295: INFO: Pod node-exporter-hx9hf requesting resource cpu=0m on Node k8s-node-vm599z-95up3dyso1
Sep 18 13:32:30.295: INFO: Pod prometheus-559998dfcb-v6rsx requesting resource cpu=0m on Node k8s-node-vm599z-95up3dyso1
Sep 18 13:32:30.295: INFO: Pod prometheus-jdmon-5f8bdc758-r998b requesting resource cpu=0m on Node k8s-node-vm599z-95up3dyso1
Sep 18 13:32:30.295: INFO: Pod coredns-6b4fdb779b-g9pl5 requesting resource cpu=100m on Node k8s-node-vm599z-95up3dyso1
Sep 18 13:32:30.295: INFO: Pod coredns-6b4fdb779b-qzqfd requesting resource cpu=100m on Node k8s-node-vm1qxh-95up3dyso1
Sep 18 13:32:30.295: INFO: Pod heapster-77dc7fd7fd-xzfww requesting resource cpu=0m on Node k8s-node-vm599z-95up3dyso1
Sep 18 13:32:30.295: INFO: Pod jdcloud-k8s-ipamd-6sz6f requesting resource cpu=0m on Node k8s-node-vm1qxh-95up3dyso1
Sep 18 13:32:30.295: INFO: Pod jdcloud-k8s-ipamd-sc9ft requesting resource cpu=0m on Node k8s-node-vm599z-95up3dyso1
Sep 18 13:32:30.296: INFO: Pod kube-proxy-hx4lq requesting resource cpu=0m on Node k8s-node-vm1qxh-95up3dyso1
Sep 18 13:32:30.296: INFO: Pod kube-proxy-l4vgf requesting resource cpu=0m on Node k8s-node-vm599z-95up3dyso1
Sep 18 13:32:30.296: INFO: Pod kubernetes-dashboard-5c846c6494-t95sr requesting resource cpu=0m on Node k8s-node-vm599z-95up3dyso1
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c358d5d3-da18-11e9-8fe5-1a4434d30f67.15c58b9cb352375e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-524/filler-pod-c358d5d3-da18-11e9-8fe5-1a4434d30f67 to k8s-node-vm599z-95up3dyso1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c358d5d3-da18-11e9-8fe5-1a4434d30f67.15c58b9ccd752a97], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c358d5d3-da18-11e9-8fe5-1a4434d30f67.15c58b9cceb13303], Reason = [Created], Message = [Created container filler-pod-c358d5d3-da18-11e9-8fe5-1a4434d30f67]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c358d5d3-da18-11e9-8fe5-1a4434d30f67.15c58b9cd21a943b], Reason = [Started], Message = [Started container filler-pod-c358d5d3-da18-11e9-8fe5-1a4434d30f67]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c35b3a09-da18-11e9-8fe5-1a4434d30f67.15c58b9cb4504a60], Reason = [Scheduled], Message = [Successfully assigned sched-pred-524/filler-pod-c35b3a09-da18-11e9-8fe5-1a4434d30f67 to k8s-node-vm1qxh-95up3dyso1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c35b3a09-da18-11e9-8fe5-1a4434d30f67.15c58b9cce13a99d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c35b3a09-da18-11e9-8fe5-1a4434d30f67.15c58b9ccf41c115], Reason = [Created], Message = [Created container filler-pod-c35b3a09-da18-11e9-8fe5-1a4434d30f67]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c35b3a09-da18-11e9-8fe5-1a4434d30f67.15c58b9cd2d09d3f], Reason = [Started], Message = [Started container filler-pod-c35b3a09-da18-11e9-8fe5-1a4434d30f67]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c58b9d2c67f6e7], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node k8s-node-vm1qxh-95up3dyso1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-node-vm599z-95up3dyso1
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:32:33.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-524" for this suite.
Sep 18 13:32:39.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:32:39.705: INFO: namespace sched-pred-524 deletion completed in 6.249275278s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.602 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:32:39.705: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Sep 18 13:32:39.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 cluster-info'
Sep 18 13:32:39.829: INFO: stderr: ""
Sep 18 13:32:39.829: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.0.248.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.0.248.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.0.248.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:32:39.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5990" for this suite.
Sep 18 13:32:45.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:32:46.086: INFO: namespace kubectl-5990 deletion completed in 6.245635601s

• [SLOW TEST:6.381 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:32:46.086: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-76nn
STEP: Creating a pod to test atomic-volume-subpath
Sep 18 13:32:46.168: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-76nn" in namespace "subpath-7600" to be "success or failure"
Sep 18 13:32:46.174: INFO: Pod "pod-subpath-test-projected-76nn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.614581ms
Sep 18 13:32:48.182: INFO: Pod "pod-subpath-test-projected-76nn": Phase="Running", Reason="", readiness=true. Elapsed: 2.014732932s
Sep 18 13:32:50.190: INFO: Pod "pod-subpath-test-projected-76nn": Phase="Running", Reason="", readiness=true. Elapsed: 4.022739334s
Sep 18 13:32:52.198: INFO: Pod "pod-subpath-test-projected-76nn": Phase="Running", Reason="", readiness=true. Elapsed: 6.03041485s
Sep 18 13:32:54.206: INFO: Pod "pod-subpath-test-projected-76nn": Phase="Running", Reason="", readiness=true. Elapsed: 8.038001167s
Sep 18 13:32:56.213: INFO: Pod "pod-subpath-test-projected-76nn": Phase="Running", Reason="", readiness=true. Elapsed: 10.045503709s
Sep 18 13:32:58.221: INFO: Pod "pod-subpath-test-projected-76nn": Phase="Running", Reason="", readiness=true. Elapsed: 12.053270913s
Sep 18 13:33:00.229: INFO: Pod "pod-subpath-test-projected-76nn": Phase="Running", Reason="", readiness=true. Elapsed: 14.061163809s
Sep 18 13:33:02.237: INFO: Pod "pod-subpath-test-projected-76nn": Phase="Running", Reason="", readiness=true. Elapsed: 16.069126509s
Sep 18 13:33:04.245: INFO: Pod "pod-subpath-test-projected-76nn": Phase="Running", Reason="", readiness=true. Elapsed: 18.07724745s
Sep 18 13:33:06.253: INFO: Pod "pod-subpath-test-projected-76nn": Phase="Running", Reason="", readiness=true. Elapsed: 20.084928162s
Sep 18 13:33:08.260: INFO: Pod "pod-subpath-test-projected-76nn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.092653482s
STEP: Saw pod success
Sep 18 13:33:08.260: INFO: Pod "pod-subpath-test-projected-76nn" satisfied condition "success or failure"
Sep 18 13:33:08.267: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-subpath-test-projected-76nn container test-container-subpath-projected-76nn: <nil>
STEP: delete the pod
Sep 18 13:33:08.318: INFO: Waiting for pod pod-subpath-test-projected-76nn to disappear
Sep 18 13:33:08.325: INFO: Pod pod-subpath-test-projected-76nn no longer exists
STEP: Deleting pod pod-subpath-test-projected-76nn
Sep 18 13:33:08.325: INFO: Deleting pod "pod-subpath-test-projected-76nn" in namespace "subpath-7600"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:33:08.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7600" for this suite.
Sep 18 13:33:14.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:33:14.607: INFO: namespace subpath-7600 deletion completed in 6.265673791s

• [SLOW TEST:28.522 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:33:14.608: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 13:33:14.678: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ddcac44e-da18-11e9-8fe5-1a4434d30f67" in namespace "downward-api-6901" to be "success or failure"
Sep 18 13:33:14.685: INFO: Pod "downwardapi-volume-ddcac44e-da18-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.583129ms
Sep 18 13:33:16.693: INFO: Pod "downwardapi-volume-ddcac44e-da18-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01555302s
STEP: Saw pod success
Sep 18 13:33:16.693: INFO: Pod "downwardapi-volume-ddcac44e-da18-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:33:16.700: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-ddcac44e-da18-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 13:33:16.741: INFO: Waiting for pod downwardapi-volume-ddcac44e-da18-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:33:16.748: INFO: Pod downwardapi-volume-ddcac44e-da18-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:33:16.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6901" for this suite.
Sep 18 13:33:22.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:33:23.005: INFO: namespace downward-api-6901 deletion completed in 6.246710399s

• [SLOW TEST:8.397 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:33:23.005: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 18 13:33:27.158: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 18 13:33:27.164: INFO: Pod pod-with-poststart-http-hook still exists
Sep 18 13:33:29.165: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 18 13:33:29.172: INFO: Pod pod-with-poststart-http-hook still exists
Sep 18 13:33:31.165: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 18 13:33:31.172: INFO: Pod pod-with-poststart-http-hook still exists
Sep 18 13:33:33.165: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 18 13:33:33.172: INFO: Pod pod-with-poststart-http-hook still exists
Sep 18 13:33:35.165: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 18 13:33:35.173: INFO: Pod pod-with-poststart-http-hook still exists
Sep 18 13:33:37.165: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 18 13:33:37.173: INFO: Pod pod-with-poststart-http-hook still exists
Sep 18 13:33:39.165: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 18 13:33:39.173: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:33:39.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2270" for this suite.
Sep 18 13:34:01.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:34:01.429: INFO: namespace container-lifecycle-hook-2270 deletion completed in 22.2454881s

• [SLOW TEST:38.424 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:34:01.429: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-f9b39de4-da18-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume secrets
Sep 18 13:34:01.509: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f9b4e494-da18-11e9-8fe5-1a4434d30f67" in namespace "projected-5437" to be "success or failure"
Sep 18 13:34:01.516: INFO: Pod "pod-projected-secrets-f9b4e494-da18-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.985158ms
Sep 18 13:34:03.525: INFO: Pod "pod-projected-secrets-f9b4e494-da18-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015094891s
STEP: Saw pod success
Sep 18 13:34:03.525: INFO: Pod "pod-projected-secrets-f9b4e494-da18-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:34:03.532: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-projected-secrets-f9b4e494-da18-11e9-8fe5-1a4434d30f67 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 18 13:34:03.572: INFO: Waiting for pod pod-projected-secrets-f9b4e494-da18-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:34:03.579: INFO: Pod pod-projected-secrets-f9b4e494-da18-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:34:03.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5437" for this suite.
Sep 18 13:34:09.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:34:09.837: INFO: namespace projected-5437 deletion completed in 6.247123746s

• [SLOW TEST:8.408 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:34:09.837: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-5452
Sep 18 13:34:11.920: INFO: Started pod liveness-exec in namespace container-probe-5452
STEP: checking the pod's current state and verifying that restartCount is present
Sep 18 13:34:11.927: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:38:12.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5452" for this suite.
Sep 18 13:38:18.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:38:19.170: INFO: namespace container-probe-5452 deletion completed in 6.244864989s

• [SLOW TEST:249.333 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:38:19.170: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-9353e0b6-da19-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume secrets
Sep 18 13:38:19.252: INFO: Waiting up to 5m0s for pod "pod-secrets-93550ddf-da19-11e9-8fe5-1a4434d30f67" in namespace "secrets-3917" to be "success or failure"
Sep 18 13:38:19.258: INFO: Pod "pod-secrets-93550ddf-da19-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.599281ms
Sep 18 13:38:21.267: INFO: Pod "pod-secrets-93550ddf-da19-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015251606s
Sep 18 13:38:23.275: INFO: Pod "pod-secrets-93550ddf-da19-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023454625s
STEP: Saw pod success
Sep 18 13:38:23.275: INFO: Pod "pod-secrets-93550ddf-da19-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:38:23.283: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-secrets-93550ddf-da19-11e9-8fe5-1a4434d30f67 container secret-volume-test: <nil>
STEP: delete the pod
Sep 18 13:38:23.327: INFO: Waiting for pod pod-secrets-93550ddf-da19-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:38:23.334: INFO: Pod pod-secrets-93550ddf-da19-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:38:23.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3917" for this suite.
Sep 18 13:38:29.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:38:29.593: INFO: namespace secrets-3917 deletion completed in 6.246465283s

• [SLOW TEST:10.422 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:38:29.593: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-7301
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 18 13:38:29.645: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 18 13:38:49.778: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.0.192.19:8080/dial?request=hostName&protocol=http&host=10.0.192.15&port=8080&tries=1'] Namespace:pod-network-test-7301 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 13:38:49.778: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 13:38:49.870: INFO: Waiting for endpoints: map[]
Sep 18 13:38:49.878: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.0.192.19:8080/dial?request=hostName&protocol=http&host=10.0.192.9&port=8080&tries=1'] Namespace:pod-network-test-7301 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 18 13:38:49.878: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
Sep 18 13:38:49.965: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:38:49.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7301" for this suite.
Sep 18 13:39:14.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:39:14.235: INFO: namespace pod-network-test-7301 deletion completed in 24.259224198s

• [SLOW TEST:44.643 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:39:14.236: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 13:39:16.364: INFO: Waiting up to 5m0s for pod "client-envvars-b5608b64-da19-11e9-8fe5-1a4434d30f67" in namespace "pods-9011" to be "success or failure"
Sep 18 13:39:16.373: INFO: Pod "client-envvars-b5608b64-da19-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 9.327826ms
Sep 18 13:39:18.381: INFO: Pod "client-envvars-b5608b64-da19-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016814936s
STEP: Saw pod success
Sep 18 13:39:18.381: INFO: Pod "client-envvars-b5608b64-da19-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:39:18.387: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod client-envvars-b5608b64-da19-11e9-8fe5-1a4434d30f67 container env3cont: <nil>
STEP: delete the pod
Sep 18 13:39:18.428: INFO: Waiting for pod client-envvars-b5608b64-da19-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:39:18.440: INFO: Pod client-envvars-b5608b64-da19-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:39:18.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9011" for this suite.
Sep 18 13:39:58.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:39:58.705: INFO: namespace pods-9011 deletion completed in 40.253089668s

• [SLOW TEST:44.469 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:39:58.705: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep 18 13:40:01.339: INFO: Successfully updated pod "annotationupdatecea734fa-da19-11e9-8fe5-1a4434d30f67"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:40:03.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-726" for this suite.
Sep 18 13:40:25.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:40:25.630: INFO: namespace downward-api-726 deletion completed in 22.245997211s

• [SLOW TEST:26.925 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:40:25.630: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-deb3af4f-da19-11e9-8fe5-1a4434d30f67
STEP: Creating secret with name secret-projected-all-test-volume-deb3af3d-da19-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep 18 13:40:25.715: INFO: Waiting up to 5m0s for pod "projected-volume-deb3af0a-da19-11e9-8fe5-1a4434d30f67" in namespace "projected-1900" to be "success or failure"
Sep 18 13:40:25.722: INFO: Pod "projected-volume-deb3af0a-da19-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.774836ms
Sep 18 13:40:27.730: INFO: Pod "projected-volume-deb3af0a-da19-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015728931s
STEP: Saw pod success
Sep 18 13:40:27.730: INFO: Pod "projected-volume-deb3af0a-da19-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:40:27.737: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod projected-volume-deb3af0a-da19-11e9-8fe5-1a4434d30f67 container projected-all-volume-test: <nil>
STEP: delete the pod
Sep 18 13:40:27.779: INFO: Waiting for pod projected-volume-deb3af0a-da19-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:40:27.786: INFO: Pod projected-volume-deb3af0a-da19-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:40:27.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1900" for this suite.
Sep 18 13:40:33.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:40:34.036: INFO: namespace projected-1900 deletion completed in 6.240153927s

• [SLOW TEST:8.406 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:40:34.036: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep 18 13:40:34.106: INFO: Waiting up to 5m0s for pod "downward-api-e3b68996-da19-11e9-8fe5-1a4434d30f67" in namespace "downward-api-3664" to be "success or failure"
Sep 18 13:40:34.114: INFO: Pod "downward-api-e3b68996-da19-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.550252ms
Sep 18 13:40:36.122: INFO: Pod "downward-api-e3b68996-da19-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015148119s
STEP: Saw pod success
Sep 18 13:40:36.122: INFO: Pod "downward-api-e3b68996-da19-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:40:36.129: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downward-api-e3b68996-da19-11e9-8fe5-1a4434d30f67 container dapi-container: <nil>
STEP: delete the pod
Sep 18 13:40:36.173: INFO: Waiting for pod downward-api-e3b68996-da19-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:40:36.179: INFO: Pod downward-api-e3b68996-da19-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:40:36.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3664" for this suite.
Sep 18 13:40:42.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:40:42.443: INFO: namespace downward-api-3664 deletion completed in 6.251023279s

• [SLOW TEST:8.407 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:40:42.443: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 13:40:42.514: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8b9300c-da19-11e9-8fe5-1a4434d30f67" in namespace "downward-api-2417" to be "success or failure"
Sep 18 13:40:42.522: INFO: Pod "downwardapi-volume-e8b9300c-da19-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 8.100106ms
Sep 18 13:40:44.531: INFO: Pod "downwardapi-volume-e8b9300c-da19-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016537321s
STEP: Saw pod success
Sep 18 13:40:44.531: INFO: Pod "downwardapi-volume-e8b9300c-da19-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:40:44.538: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-e8b9300c-da19-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 13:40:44.579: INFO: Waiting for pod downwardapi-volume-e8b9300c-da19-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:40:44.586: INFO: Pod downwardapi-volume-e8b9300c-da19-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:40:44.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2417" for this suite.
Sep 18 13:40:50.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:40:50.846: INFO: namespace downward-api-2417 deletion completed in 6.249335255s

• [SLOW TEST:8.403 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:40:50.846: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 13:40:50.903: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep 18 13:40:50.919: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep 18 13:40:55.927: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 18 13:40:55.927: INFO: Creating deployment "test-rolling-update-deployment"
Sep 18 13:40:55.937: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep 18 13:40:55.951: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep 18 13:40:57.967: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep 18 13:40:57.974: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep 18 13:40:57.994: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-1151,SelfLink:/apis/apps/v1/namespaces/deployment-1151/deployments/test-rolling-update-deployment,UID:f0bc9356-da19-11e9-b983-fa163edda742,ResourceVersion:238378,Generation:1,CreationTimestamp:2019-09-18 13:40:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-18 13:40:55 +0000 UTC 2019-09-18 13:40:55 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-18 13:40:56 +0000 UTC 2019-09-18 13:40:55 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-57b6b5bb54" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep 18 13:40:58.000: INFO: New ReplicaSet "test-rolling-update-deployment-57b6b5bb54" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54,GenerateName:,Namespace:deployment-1151,SelfLink:/apis/apps/v1/namespaces/deployment-1151/replicasets/test-rolling-update-deployment-57b6b5bb54,UID:f0bfd3ff-da19-11e9-b983-fa163edda742,ResourceVersion:238367,Generation:1,CreationTimestamp:2019-09-18 13:40:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f0bc9356-da19-11e9-b983-fa163edda742 0xc00311cd77 0xc00311cd78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep 18 13:40:58.000: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep 18 13:40:58.001: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-1151,SelfLink:/apis/apps/v1/namespaces/deployment-1151/replicasets/test-rolling-update-controller,UID:edbde24d-da19-11e9-b983-fa163edda742,ResourceVersion:238376,Generation:2,CreationTimestamp:2019-09-18 13:40:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f0bc9356-da19-11e9-b983-fa163edda742 0xc00311cca7 0xc00311cca8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 18 13:40:58.007: INFO: Pod "test-rolling-update-deployment-57b6b5bb54-m52zp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54-m52zp,GenerateName:test-rolling-update-deployment-57b6b5bb54-,Namespace:deployment-1151,SelfLink:/api/v1/namespaces/deployment-1151/pods/test-rolling-update-deployment-57b6b5bb54-m52zp,UID:f0c10798-da19-11e9-b983-fa163edda742,ResourceVersion:238366,Generation:0,CreationTimestamp:2019-09-18 13:40:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-57b6b5bb54 f0bfd3ff-da19-11e9-b983-fa163edda742 0xc00311da87 0xc00311da88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7w8bc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7w8bc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-7w8bc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1qxh-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00311daf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00311db10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:40:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:40:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:40:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:40:56 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.5,PodIP:10.0.192.18,StartTime:2019-09-18 13:40:56 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-18 13:40:56 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/kubernetes-e2e-test-images/redis@sha256:2238f5a02d2648d41cc94a88f084060fbfa860890220328eb92696bf2ac649c9 docker://2db91a0564344925fb26f6de35e6aa355fa20e6397a0817eab7120a40cfb407c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:40:58.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1151" for this suite.
Sep 18 13:41:04.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:41:04.275: INFO: namespace deployment-1151 deletion completed in 6.257505765s

• [SLOW TEST:13.429 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:41:04.276: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:41:04.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1681" for this suite.
Sep 18 13:41:26.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:41:26.624: INFO: namespace pods-1681 deletion completed in 22.253812128s

• [SLOW TEST:22.348 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:41:26.624: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-030e0b63-da1a-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume secrets
Sep 18 13:41:26.696: INFO: Waiting up to 5m0s for pod "pod-secrets-030f39d1-da1a-11e9-8fe5-1a4434d30f67" in namespace "secrets-3984" to be "success or failure"
Sep 18 13:41:26.703: INFO: Pod "pod-secrets-030f39d1-da1a-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.603416ms
Sep 18 13:41:28.710: INFO: Pod "pod-secrets-030f39d1-da1a-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013760887s
STEP: Saw pod success
Sep 18 13:41:28.710: INFO: Pod "pod-secrets-030f39d1-da1a-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:41:28.717: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-secrets-030f39d1-da1a-11e9-8fe5-1a4434d30f67 container secret-volume-test: <nil>
STEP: delete the pod
Sep 18 13:41:28.757: INFO: Waiting for pod pod-secrets-030f39d1-da1a-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:41:28.765: INFO: Pod pod-secrets-030f39d1-da1a-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:41:28.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3984" for this suite.
Sep 18 13:41:34.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:41:35.018: INFO: namespace secrets-3984 deletion completed in 6.242646133s

• [SLOW TEST:8.394 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:41:35.018: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:41:37.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4204" for this suite.
Sep 18 13:42:19.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:42:19.394: INFO: namespace kubelet-test-4204 deletion completed in 42.253778191s

• [SLOW TEST:44.376 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:42:19.394: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Sep 18 13:42:19.456: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Sep 18 13:42:19.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 create -f - --namespace=kubectl-2758'
Sep 18 13:42:19.629: INFO: stderr: ""
Sep 18 13:42:19.629: INFO: stdout: "service/redis-slave created\n"
Sep 18 13:42:19.629: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Sep 18 13:42:19.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 create -f - --namespace=kubectl-2758'
Sep 18 13:42:19.763: INFO: stderr: ""
Sep 18 13:42:19.763: INFO: stdout: "service/redis-master created\n"
Sep 18 13:42:19.764: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep 18 13:42:19.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 create -f - --namespace=kubectl-2758'
Sep 18 13:42:19.895: INFO: stderr: ""
Sep 18 13:42:19.895: INFO: stdout: "service/frontend created\n"
Sep 18 13:42:19.895: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Sep 18 13:42:19.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 create -f - --namespace=kubectl-2758'
Sep 18 13:42:20.024: INFO: stderr: ""
Sep 18 13:42:20.024: INFO: stdout: "deployment.apps/frontend created\n"
Sep 18 13:42:20.024: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep 18 13:42:20.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 create -f - --namespace=kubectl-2758'
Sep 18 13:42:20.145: INFO: stderr: ""
Sep 18 13:42:20.145: INFO: stdout: "deployment.apps/redis-master created\n"
Sep 18 13:42:20.145: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Sep 18 13:42:20.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 create -f - --namespace=kubectl-2758'
Sep 18 13:42:20.268: INFO: stderr: ""
Sep 18 13:42:20.268: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Sep 18 13:42:20.268: INFO: Waiting for all frontend pods to be Running.
Sep 18 13:42:25.319: INFO: Waiting for frontend to serve content.
Sep 18 13:42:25.346: INFO: Trying to add a new entry to the guestbook.
Sep 18 13:42:25.364: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Sep 18 13:42:25.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 delete --grace-period=0 --force -f - --namespace=kubectl-2758'
Sep 18 13:42:25.486: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 18 13:42:25.486: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep 18 13:42:25.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 delete --grace-period=0 --force -f - --namespace=kubectl-2758'
Sep 18 13:42:25.593: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 18 13:42:25.594: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 18 13:42:25.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 delete --grace-period=0 --force -f - --namespace=kubectl-2758'
Sep 18 13:42:25.697: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 18 13:42:25.697: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 18 13:42:25.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 delete --grace-period=0 --force -f - --namespace=kubectl-2758'
Sep 18 13:42:25.783: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 18 13:42:25.783: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 18 13:42:25.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 delete --grace-period=0 --force -f - --namespace=kubectl-2758'
Sep 18 13:42:25.867: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 18 13:42:25.868: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 18 13:42:25.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 delete --grace-period=0 --force -f - --namespace=kubectl-2758'
Sep 18 13:42:25.946: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 18 13:42:25.946: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:42:25.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2758" for this suite.
Sep 18 13:43:05.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:43:06.204: INFO: namespace kubectl-2758 deletion completed in 40.247317764s

• [SLOW TEST:46.810 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:43:06.205: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Sep 18 13:43:06.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 create -f - --namespace=kubectl-1420'
Sep 18 13:43:06.384: INFO: stderr: ""
Sep 18 13:43:06.384: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 18 13:43:07.392: INFO: Selector matched 1 pods for map[app:redis]
Sep 18 13:43:07.392: INFO: Found 0 / 1
Sep 18 13:43:08.392: INFO: Selector matched 1 pods for map[app:redis]
Sep 18 13:43:08.392: INFO: Found 1 / 1
Sep 18 13:43:08.392: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep 18 13:43:08.399: INFO: Selector matched 1 pods for map[app:redis]
Sep 18 13:43:08.399: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 18 13:43:08.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 patch pod redis-master-njfw5 --namespace=kubectl-1420 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep 18 13:43:08.476: INFO: stderr: ""
Sep 18 13:43:08.476: INFO: stdout: "pod/redis-master-njfw5 patched\n"
STEP: checking annotations
Sep 18 13:43:08.483: INFO: Selector matched 1 pods for map[app:redis]
Sep 18 13:43:08.483: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:43:08.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1420" for this suite.
Sep 18 13:43:30.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:43:30.740: INFO: namespace kubectl-1420 deletion completed in 22.245629722s

• [SLOW TEST:24.535 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:43:30.740: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep 18 13:43:30.807: INFO: Waiting up to 5m0s for pod "downward-api-4d090128-da1a-11e9-8fe5-1a4434d30f67" in namespace "downward-api-5219" to be "success or failure"
Sep 18 13:43:30.815: INFO: Pod "downward-api-4d090128-da1a-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.216878ms
Sep 18 13:43:32.825: INFO: Pod "downward-api-4d090128-da1a-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017070616s
STEP: Saw pod success
Sep 18 13:43:32.825: INFO: Pod "downward-api-4d090128-da1a-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:43:32.831: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downward-api-4d090128-da1a-11e9-8fe5-1a4434d30f67 container dapi-container: <nil>
STEP: delete the pod
Sep 18 13:43:32.878: INFO: Waiting for pod downward-api-4d090128-da1a-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:43:32.886: INFO: Pod downward-api-4d090128-da1a-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:43:32.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5219" for this suite.
Sep 18 13:43:38.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:43:39.140: INFO: namespace downward-api-5219 deletion completed in 6.24370983s

• [SLOW TEST:8.401 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:43:39.141: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1384
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 18 13:43:39.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-7083'
Sep 18 13:43:39.267: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 18 13:43:39.267: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1390
Sep 18 13:43:41.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 delete deployment e2e-test-nginx-deployment --namespace=kubectl-7083'
Sep 18 13:43:41.364: INFO: stderr: ""
Sep 18 13:43:41.364: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:43:41.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7083" for this suite.
Sep 18 13:44:03.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:44:03.624: INFO: namespace kubectl-7083 deletion completed in 22.249349475s

• [SLOW TEST:24.483 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:44:03.624: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-60a2bc1e-da1a-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume configMaps
Sep 18 13:44:03.702: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-60a3fa3f-da1a-11e9-8fe5-1a4434d30f67" in namespace "projected-6962" to be "success or failure"
Sep 18 13:44:03.710: INFO: Pod "pod-projected-configmaps-60a3fa3f-da1a-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 8.36273ms
Sep 18 13:44:05.718: INFO: Pod "pod-projected-configmaps-60a3fa3f-da1a-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016044068s
STEP: Saw pod success
Sep 18 13:44:05.718: INFO: Pod "pod-projected-configmaps-60a3fa3f-da1a-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:44:05.725: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-projected-configmaps-60a3fa3f-da1a-11e9-8fe5-1a4434d30f67 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 18 13:44:05.770: INFO: Waiting for pod pod-projected-configmaps-60a3fa3f-da1a-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:44:05.778: INFO: Pod pod-projected-configmaps-60a3fa3f-da1a-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:44:05.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6962" for this suite.
Sep 18 13:44:11.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:44:12.038: INFO: namespace projected-6962 deletion completed in 6.248239132s

• [SLOW TEST:8.414 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:44:12.038: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-65a68b78-da1a-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume configMaps
Sep 18 13:44:12.114: INFO: Waiting up to 5m0s for pod "pod-configmaps-65a7c173-da1a-11e9-8fe5-1a4434d30f67" in namespace "configmap-9623" to be "success or failure"
Sep 18 13:44:12.121: INFO: Pod "pod-configmaps-65a7c173-da1a-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.125803ms
Sep 18 13:44:14.129: INFO: Pod "pod-configmaps-65a7c173-da1a-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015324493s
STEP: Saw pod success
Sep 18 13:44:14.129: INFO: Pod "pod-configmaps-65a7c173-da1a-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:44:14.136: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-configmaps-65a7c173-da1a-11e9-8fe5-1a4434d30f67 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 18 13:44:14.176: INFO: Waiting for pod pod-configmaps-65a7c173-da1a-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:44:14.183: INFO: Pod pod-configmaps-65a7c173-da1a-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:44:14.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9623" for this suite.
Sep 18 13:44:20.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:44:20.437: INFO: namespace configmap-9623 deletion completed in 6.244213848s

• [SLOW TEST:8.400 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:44:20.437: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0918 13:45:00.566033      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 18 13:45:00.566: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:45:00.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3052" for this suite.
Sep 18 13:45:08.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:45:08.822: INFO: namespace gc-3052 deletion completed in 8.246370781s

• [SLOW TEST:48.385 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:45:08.822: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 13:45:08.891: INFO: Waiting up to 5m0s for pod "downwardapi-volume-877f5c6c-da1a-11e9-8fe5-1a4434d30f67" in namespace "projected-4069" to be "success or failure"
Sep 18 13:45:08.897: INFO: Pod "downwardapi-volume-877f5c6c-da1a-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.555328ms
Sep 18 13:45:10.905: INFO: Pod "downwardapi-volume-877f5c6c-da1a-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014617113s
STEP: Saw pod success
Sep 18 13:45:10.905: INFO: Pod "downwardapi-volume-877f5c6c-da1a-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:45:10.912: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-877f5c6c-da1a-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 13:45:10.955: INFO: Waiting for pod downwardapi-volume-877f5c6c-da1a-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:45:10.961: INFO: Pod downwardapi-volume-877f5c6c-da1a-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:45:10.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4069" for this suite.
Sep 18 13:45:16.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:45:17.221: INFO: namespace projected-4069 deletion completed in 6.249362116s

• [SLOW TEST:8.399 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:45:17.221: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-8c836919-da1a-11e9-8fe5-1a4434d30f67
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-8c836919-da1a-11e9-8fe5-1a4434d30f67
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:45:23.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9848" for this suite.
Sep 18 13:45:45.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:45:45.682: INFO: namespace configmap-9848 deletion completed in 22.248899278s

• [SLOW TEST:28.460 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:45:45.682: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep 18 13:45:45.753: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3186,SelfLink:/api/v1/namespaces/watch-3186/configmaps/e2e-watch-test-configmap-a,UID:9d7b5e9c-da1a-11e9-b983-fa163edda742,ResourceVersion:239644,Generation:0,CreationTimestamp:2019-09-18 13:45:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 18 13:45:45.754: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3186,SelfLink:/api/v1/namespaces/watch-3186/configmaps/e2e-watch-test-configmap-a,UID:9d7b5e9c-da1a-11e9-b983-fa163edda742,ResourceVersion:239644,Generation:0,CreationTimestamp:2019-09-18 13:45:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep 18 13:45:55.770: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3186,SelfLink:/api/v1/namespaces/watch-3186/configmaps/e2e-watch-test-configmap-a,UID:9d7b5e9c-da1a-11e9-b983-fa163edda742,ResourceVersion:239665,Generation:0,CreationTimestamp:2019-09-18 13:45:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep 18 13:45:55.770: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3186,SelfLink:/api/v1/namespaces/watch-3186/configmaps/e2e-watch-test-configmap-a,UID:9d7b5e9c-da1a-11e9-b983-fa163edda742,ResourceVersion:239665,Generation:0,CreationTimestamp:2019-09-18 13:45:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep 18 13:46:05.786: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3186,SelfLink:/api/v1/namespaces/watch-3186/configmaps/e2e-watch-test-configmap-a,UID:9d7b5e9c-da1a-11e9-b983-fa163edda742,ResourceVersion:239687,Generation:0,CreationTimestamp:2019-09-18 13:45:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 18 13:46:05.787: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3186,SelfLink:/api/v1/namespaces/watch-3186/configmaps/e2e-watch-test-configmap-a,UID:9d7b5e9c-da1a-11e9-b983-fa163edda742,ResourceVersion:239687,Generation:0,CreationTimestamp:2019-09-18 13:45:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep 18 13:46:15.805: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3186,SelfLink:/api/v1/namespaces/watch-3186/configmaps/e2e-watch-test-configmap-a,UID:9d7b5e9c-da1a-11e9-b983-fa163edda742,ResourceVersion:239708,Generation:0,CreationTimestamp:2019-09-18 13:45:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 18 13:46:15.805: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3186,SelfLink:/api/v1/namespaces/watch-3186/configmaps/e2e-watch-test-configmap-a,UID:9d7b5e9c-da1a-11e9-b983-fa163edda742,ResourceVersion:239708,Generation:0,CreationTimestamp:2019-09-18 13:45:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep 18 13:46:25.819: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3186,SelfLink:/api/v1/namespaces/watch-3186/configmaps/e2e-watch-test-configmap-b,UID:b55c16aa-da1a-11e9-b983-fa163edda742,ResourceVersion:239729,Generation:0,CreationTimestamp:2019-09-18 13:46:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 18 13:46:25.819: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3186,SelfLink:/api/v1/namespaces/watch-3186/configmaps/e2e-watch-test-configmap-b,UID:b55c16aa-da1a-11e9-b983-fa163edda742,ResourceVersion:239729,Generation:0,CreationTimestamp:2019-09-18 13:46:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep 18 13:46:35.835: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3186,SelfLink:/api/v1/namespaces/watch-3186/configmaps/e2e-watch-test-configmap-b,UID:b55c16aa-da1a-11e9-b983-fa163edda742,ResourceVersion:239750,Generation:0,CreationTimestamp:2019-09-18 13:46:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 18 13:46:35.835: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3186,SelfLink:/api/v1/namespaces/watch-3186/configmaps/e2e-watch-test-configmap-b,UID:b55c16aa-da1a-11e9-b983-fa163edda742,ResourceVersion:239750,Generation:0,CreationTimestamp:2019-09-18 13:46:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:46:45.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3186" for this suite.
Sep 18 13:46:51.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:46:52.092: INFO: namespace watch-3186 deletion completed in 6.244992573s

• [SLOW TEST:66.410 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:46:52.092: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-c50f2c5e-da1a-11e9-8fe5-1a4434d30f67
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-c50f2c5e-da1a-11e9-8fe5-1a4434d30f67
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:46:56.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4102" for this suite.
Sep 18 13:47:18.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:47:18.525: INFO: namespace projected-4102 deletion completed in 22.2516134s

• [SLOW TEST:26.433 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:47:18.525: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-2484
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2484 to expose endpoints map[]
Sep 18 13:47:18.605: INFO: successfully validated that service multi-endpoint-test in namespace services-2484 exposes endpoints map[] (8.153112ms elapsed)
STEP: Creating pod pod1 in namespace services-2484
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2484 to expose endpoints map[pod1:[100]]
Sep 18 13:47:19.648: INFO: successfully validated that service multi-endpoint-test in namespace services-2484 exposes endpoints map[pod1:[100]] (1.029056567s elapsed)
STEP: Creating pod pod2 in namespace services-2484
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2484 to expose endpoints map[pod1:[100] pod2:[101]]
Sep 18 13:47:20.699: INFO: successfully validated that service multi-endpoint-test in namespace services-2484 exposes endpoints map[pod1:[100] pod2:[101]] (1.042862609s elapsed)
STEP: Deleting pod pod1 in namespace services-2484
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2484 to expose endpoints map[pod2:[101]]
Sep 18 13:47:21.741: INFO: successfully validated that service multi-endpoint-test in namespace services-2484 exposes endpoints map[pod2:[101]] (1.02840735s elapsed)
STEP: Deleting pod pod2 in namespace services-2484
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2484 to expose endpoints map[]
Sep 18 13:47:21.763: INFO: successfully validated that service multi-endpoint-test in namespace services-2484 exposes endpoints map[] (7.280861ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:47:21.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2484" for this suite.
Sep 18 13:47:27.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:47:28.060: INFO: namespace services-2484 deletion completed in 6.246327779s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:9.535 seconds]
[sig-network] Services
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:47:28.060: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-da7e1af1-da1a-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume configMaps
Sep 18 13:47:28.141: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-da7f484b-da1a-11e9-8fe5-1a4434d30f67" in namespace "projected-8753" to be "success or failure"
Sep 18 13:47:28.149: INFO: Pod "pod-projected-configmaps-da7f484b-da1a-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.912771ms
Sep 18 13:47:30.157: INFO: Pod "pod-projected-configmaps-da7f484b-da1a-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015273777s
STEP: Saw pod success
Sep 18 13:47:30.157: INFO: Pod "pod-projected-configmaps-da7f484b-da1a-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:47:30.163: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-projected-configmaps-da7f484b-da1a-11e9-8fe5-1a4434d30f67 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 18 13:47:30.204: INFO: Waiting for pod pod-projected-configmaps-da7f484b-da1a-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:47:30.210: INFO: Pod pod-projected-configmaps-da7f484b-da1a-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:47:30.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8753" for this suite.
Sep 18 13:47:36.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:47:36.468: INFO: namespace projected-8753 deletion completed in 6.247586414s

• [SLOW TEST:8.408 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:47:36.469: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-df809970-da1a-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume configMaps
Sep 18 13:47:36.548: INFO: Waiting up to 5m0s for pod "pod-configmaps-df81d7be-da1a-11e9-8fe5-1a4434d30f67" in namespace "configmap-9822" to be "success or failure"
Sep 18 13:47:36.554: INFO: Pod "pod-configmaps-df81d7be-da1a-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.654991ms
Sep 18 13:47:38.562: INFO: Pod "pod-configmaps-df81d7be-da1a-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01484359s
STEP: Saw pod success
Sep 18 13:47:38.562: INFO: Pod "pod-configmaps-df81d7be-da1a-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:47:38.569: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-configmaps-df81d7be-da1a-11e9-8fe5-1a4434d30f67 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 18 13:47:38.614: INFO: Waiting for pod pod-configmaps-df81d7be-da1a-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:47:38.620: INFO: Pod pod-configmaps-df81d7be-da1a-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:47:38.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9822" for this suite.
Sep 18 13:47:44.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:47:44.876: INFO: namespace configmap-9822 deletion completed in 6.244717379s

• [SLOW TEST:8.407 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:47:44.876: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:47:46.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-374" for this suite.
Sep 18 13:48:27.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:48:27.239: INFO: namespace kubelet-test-374 deletion completed in 40.244312001s

• [SLOW TEST:42.363 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:48:27.239: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep 18 13:48:27.309: INFO: Waiting up to 5m0s for pod "pod-fdc363a8-da1a-11e9-8fe5-1a4434d30f67" in namespace "emptydir-3408" to be "success or failure"
Sep 18 13:48:27.315: INFO: Pod "pod-fdc363a8-da1a-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.820362ms
Sep 18 13:48:29.323: INFO: Pod "pod-fdc363a8-da1a-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014309926s
STEP: Saw pod success
Sep 18 13:48:29.323: INFO: Pod "pod-fdc363a8-da1a-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:48:29.330: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-fdc363a8-da1a-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 13:48:29.372: INFO: Waiting for pod pod-fdc363a8-da1a-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:48:29.379: INFO: Pod pod-fdc363a8-da1a-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:48:29.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3408" for this suite.
Sep 18 13:48:35.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:48:35.638: INFO: namespace emptydir-3408 deletion completed in 6.249008099s

• [SLOW TEST:8.399 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:48:35.638: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-02c47977-da1b-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume secrets
Sep 18 13:48:35.713: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-02c5c91e-da1b-11e9-8fe5-1a4434d30f67" in namespace "projected-5883" to be "success or failure"
Sep 18 13:48:35.720: INFO: Pod "pod-projected-secrets-02c5c91e-da1b-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.472638ms
Sep 18 13:48:37.728: INFO: Pod "pod-projected-secrets-02c5c91e-da1b-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015571371s
STEP: Saw pod success
Sep 18 13:48:37.728: INFO: Pod "pod-projected-secrets-02c5c91e-da1b-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:48:37.735: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-projected-secrets-02c5c91e-da1b-11e9-8fe5-1a4434d30f67 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 18 13:48:37.778: INFO: Waiting for pod pod-projected-secrets-02c5c91e-da1b-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:48:37.785: INFO: Pod pod-projected-secrets-02c5c91e-da1b-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:48:37.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5883" for this suite.
Sep 18 13:48:43.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:48:44.045: INFO: namespace projected-5883 deletion completed in 6.250229425s

• [SLOW TEST:8.407 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:48:44.045: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-07c7b390-da1b-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume secrets
Sep 18 13:48:44.123: INFO: Waiting up to 5m0s for pod "pod-secrets-07c90245-da1b-11e9-8fe5-1a4434d30f67" in namespace "secrets-7813" to be "success or failure"
Sep 18 13:48:44.130: INFO: Pod "pod-secrets-07c90245-da1b-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.492236ms
Sep 18 13:48:46.139: INFO: Pod "pod-secrets-07c90245-da1b-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015851969s
STEP: Saw pod success
Sep 18 13:48:46.139: INFO: Pod "pod-secrets-07c90245-da1b-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:48:46.146: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-secrets-07c90245-da1b-11e9-8fe5-1a4434d30f67 container secret-env-test: <nil>
STEP: delete the pod
Sep 18 13:48:46.186: INFO: Waiting for pod pod-secrets-07c90245-da1b-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:48:46.193: INFO: Pod pod-secrets-07c90245-da1b-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:48:46.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7813" for this suite.
Sep 18 13:48:52.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:48:52.445: INFO: namespace secrets-7813 deletion completed in 6.242157946s

• [SLOW TEST:8.400 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:48:52.446: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Sep 18 13:48:52.519: INFO: Waiting up to 5m0s for pod "client-containers-0cca2d8f-da1b-11e9-8fe5-1a4434d30f67" in namespace "containers-139" to be "success or failure"
Sep 18 13:48:52.527: INFO: Pod "client-containers-0cca2d8f-da1b-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.822755ms
Sep 18 13:48:54.535: INFO: Pod "client-containers-0cca2d8f-da1b-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015758095s
STEP: Saw pod success
Sep 18 13:48:54.535: INFO: Pod "client-containers-0cca2d8f-da1b-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:48:54.542: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod client-containers-0cca2d8f-da1b-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 13:48:54.579: INFO: Waiting for pod client-containers-0cca2d8f-da1b-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:48:54.587: INFO: Pod client-containers-0cca2d8f-da1b-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:48:54.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-139" for this suite.
Sep 18 13:49:00.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:49:00.854: INFO: namespace containers-139 deletion completed in 6.255833592s

• [SLOW TEST:8.408 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:49:00.854: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep 18 13:49:00.927: INFO: Waiting up to 5m0s for pod "downward-api-11cce23b-da1b-11e9-8fe5-1a4434d30f67" in namespace "downward-api-6424" to be "success or failure"
Sep 18 13:49:00.934: INFO: Pod "downward-api-11cce23b-da1b-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.839474ms
Sep 18 13:49:02.942: INFO: Pod "downward-api-11cce23b-da1b-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015911574s
STEP: Saw pod success
Sep 18 13:49:02.942: INFO: Pod "downward-api-11cce23b-da1b-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:49:02.949: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downward-api-11cce23b-da1b-11e9-8fe5-1a4434d30f67 container dapi-container: <nil>
STEP: delete the pod
Sep 18 13:49:02.991: INFO: Waiting for pod downward-api-11cce23b-da1b-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:49:02.998: INFO: Pod downward-api-11cce23b-da1b-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:49:02.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6424" for this suite.
Sep 18 13:49:09.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:49:09.264: INFO: namespace downward-api-6424 deletion completed in 6.255641556s

• [SLOW TEST:8.410 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:49:09.264: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-678
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Sep 18 13:49:09.363: INFO: Found 0 stateful pods, waiting for 3
Sep 18 13:49:19.372: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 18 13:49:19.372: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 18 13:49:19.372: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep 18 13:49:19.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-678 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 18 13:49:19.546: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 18 13:49:19.546: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 18 13:49:19.546: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep 18 13:49:29.604: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep 18 13:49:39.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-678 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 13:49:39.787: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 18 13:49:39.788: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 18 13:49:39.788: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

STEP: Rolling back to a previous revision
Sep 18 13:49:49.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-678 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 18 13:49:49.976: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 18 13:49:49.976: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 18 13:49:49.976: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 18 13:50:00.033: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep 18 13:50:10.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-678 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 13:50:10.226: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 18 13:50:10.226: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 18 13:50:10.226: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep 18 13:50:30.269: INFO: Deleting all statefulset in ns statefulset-678
Sep 18 13:50:30.276: INFO: Scaling statefulset ss2 to 0
Sep 18 13:50:40.309: INFO: Waiting for statefulset status.replicas updated to 0
Sep 18 13:50:40.315: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:50:40.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-678" for this suite.
Sep 18 13:50:48.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:50:48.608: INFO: namespace statefulset-678 deletion completed in 8.249699721s

• [SLOW TEST:99.344 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:50:48.608: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-dlgq
STEP: Creating a pod to test atomic-volume-subpath
Sep 18 13:50:48.692: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-dlgq" in namespace "subpath-6072" to be "success or failure"
Sep 18 13:50:48.699: INFO: Pod "pod-subpath-test-downwardapi-dlgq": Phase="Pending", Reason="", readiness=false. Elapsed: 6.528535ms
Sep 18 13:50:50.707: INFO: Pod "pod-subpath-test-downwardapi-dlgq": Phase="Running", Reason="", readiness=true. Elapsed: 2.014828804s
Sep 18 13:50:52.715: INFO: Pod "pod-subpath-test-downwardapi-dlgq": Phase="Running", Reason="", readiness=true. Elapsed: 4.022793597s
Sep 18 13:50:54.723: INFO: Pod "pod-subpath-test-downwardapi-dlgq": Phase="Running", Reason="", readiness=true. Elapsed: 6.030839334s
Sep 18 13:50:56.731: INFO: Pod "pod-subpath-test-downwardapi-dlgq": Phase="Running", Reason="", readiness=true. Elapsed: 8.038800848s
Sep 18 13:50:58.739: INFO: Pod "pod-subpath-test-downwardapi-dlgq": Phase="Running", Reason="", readiness=true. Elapsed: 10.046912036s
Sep 18 13:51:00.747: INFO: Pod "pod-subpath-test-downwardapi-dlgq": Phase="Running", Reason="", readiness=true. Elapsed: 12.054814095s
Sep 18 13:51:02.757: INFO: Pod "pod-subpath-test-downwardapi-dlgq": Phase="Running", Reason="", readiness=true. Elapsed: 14.065133951s
Sep 18 13:51:04.765: INFO: Pod "pod-subpath-test-downwardapi-dlgq": Phase="Running", Reason="", readiness=true. Elapsed: 16.072983751s
Sep 18 13:51:06.773: INFO: Pod "pod-subpath-test-downwardapi-dlgq": Phase="Running", Reason="", readiness=true. Elapsed: 18.080981097s
Sep 18 13:51:08.781: INFO: Pod "pod-subpath-test-downwardapi-dlgq": Phase="Running", Reason="", readiness=true. Elapsed: 20.088919827s
Sep 18 13:51:10.789: INFO: Pod "pod-subpath-test-downwardapi-dlgq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.096501914s
STEP: Saw pod success
Sep 18 13:51:10.789: INFO: Pod "pod-subpath-test-downwardapi-dlgq" satisfied condition "success or failure"
Sep 18 13:51:10.796: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-subpath-test-downwardapi-dlgq container test-container-subpath-downwardapi-dlgq: <nil>
STEP: delete the pod
Sep 18 13:51:10.837: INFO: Waiting for pod pod-subpath-test-downwardapi-dlgq to disappear
Sep 18 13:51:10.845: INFO: Pod pod-subpath-test-downwardapi-dlgq no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-dlgq
Sep 18 13:51:10.845: INFO: Deleting pod "pod-subpath-test-downwardapi-dlgq" in namespace "subpath-6072"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:51:10.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6072" for this suite.
Sep 18 13:51:16.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:51:17.117: INFO: namespace subpath-6072 deletion completed in 6.255527998s

• [SLOW TEST:28.509 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:51:17.118: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 13:51:17.215: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep 18 13:51:17.245: INFO: Number of nodes with available pods: 0
Sep 18 13:51:17.245: INFO: Node k8s-node-vm1qxh-95up3dyso1 is running more than one daemon pod
Sep 18 13:51:18.263: INFO: Number of nodes with available pods: 2
Sep 18 13:51:18.263: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep 18 13:51:18.323: INFO: Wrong image for pod: daemon-set-7cml4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 18 13:51:18.323: INFO: Wrong image for pod: daemon-set-tv7wv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 18 13:51:19.342: INFO: Wrong image for pod: daemon-set-7cml4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 18 13:51:19.342: INFO: Wrong image for pod: daemon-set-tv7wv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 18 13:51:20.342: INFO: Wrong image for pod: daemon-set-7cml4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 18 13:51:20.342: INFO: Wrong image for pod: daemon-set-tv7wv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 18 13:51:21.342: INFO: Wrong image for pod: daemon-set-7cml4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 18 13:51:21.342: INFO: Wrong image for pod: daemon-set-tv7wv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 18 13:51:21.342: INFO: Pod daemon-set-tv7wv is not available
Sep 18 13:51:22.342: INFO: Wrong image for pod: daemon-set-7cml4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 18 13:51:22.342: INFO: Pod daemon-set-shf4c is not available
Sep 18 13:51:23.342: INFO: Wrong image for pod: daemon-set-7cml4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 18 13:51:23.342: INFO: Pod daemon-set-7cml4 is not available
Sep 18 13:51:24.342: INFO: Pod daemon-set-dznq8 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Sep 18 13:51:24.369: INFO: Number of nodes with available pods: 1
Sep 18 13:51:24.369: INFO: Node k8s-node-vm599z-95up3dyso1 is running more than one daemon pod
Sep 18 13:51:25.387: INFO: Number of nodes with available pods: 2
Sep 18 13:51:25.387: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-556, will wait for the garbage collector to delete the pods
Sep 18 13:51:25.494: INFO: Deleting DaemonSet.extensions daemon-set took: 17.006257ms
Sep 18 13:51:25.794: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.147258ms
Sep 18 13:51:37.302: INFO: Number of nodes with available pods: 0
Sep 18 13:51:37.302: INFO: Number of running nodes: 0, number of available pods: 0
Sep 18 13:51:37.308: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-556/daemonsets","resourceVersion":"241082"},"items":null}

Sep 18 13:51:37.315: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-556/pods","resourceVersion":"241082"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:51:37.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-556" for this suite.
Sep 18 13:51:43.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:51:43.603: INFO: namespace daemonsets-556 deletion completed in 6.250896429s

• [SLOW TEST:26.485 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:51:43.603: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep 18 13:51:45.702: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-72cdf079-da1b-11e9-8fe5-1a4434d30f67,GenerateName:,Namespace:events-3305,SelfLink:/api/v1/namespaces/events-3305/pods/send-events-72cdf079-da1b-11e9-8fe5-1a4434d30f67,UID:72d14d0a-da1b-11e9-b983-fa163edda742,ResourceVersion:241143,Generation:0,CreationTimestamp:2019-09-18 13:51:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 658205915,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8m9vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8m9vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-8m9vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1qxh-95up3dyso1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a3b090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a3b0b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:51:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:51:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:51:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-18 13:51:43 +0000 UTC  }],Message:,Reason:,HostIP:10.0.224.5,PodIP:10.0.192.17,StartTime:2019-09-18 13:51:43 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-09-18 13:51:44 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/kubernetes-e2e-test-images/serve-hostname@sha256:53c28beabd3509fb5b1d1185b2962e8204384cef7562982d8b216b71292aabf9 docker://79271e11aafe9d1d7762c9d50ac69d65c205fda7f63b8a6c91a66a85d571ab19}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Sep 18 13:51:47.710: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep 18 13:51:49.718: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:51:49.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3305" for this suite.
Sep 18 13:52:29.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:52:29.983: INFO: namespace events-3305 deletion completed in 40.240209553s

• [SLOW TEST:46.380 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:52:29.983: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-4913
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4913
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4913
Sep 18 13:52:30.070: INFO: Found 0 stateful pods, waiting for 1
Sep 18 13:52:40.078: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep 18 13:52:40.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-4913 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 18 13:52:40.246: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 18 13:52:40.246: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 18 13:52:40.246: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 18 13:52:40.253: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 18 13:52:50.261: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 18 13:52:50.261: INFO: Waiting for statefulset status.replicas updated to 0
Sep 18 13:52:50.291: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999705s
Sep 18 13:52:51.299: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993067889s
Sep 18 13:52:52.307: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.98522971s
Sep 18 13:52:53.315: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.977401456s
Sep 18 13:52:54.323: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.96998587s
Sep 18 13:52:55.331: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.961854306s
Sep 18 13:52:56.339: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.953800283s
Sep 18 13:52:57.347: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.945732157s
Sep 18 13:52:58.355: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.937658476s
Sep 18 13:52:59.363: INFO: Verifying statefulset ss doesn't scale past 1 for another 929.735496ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4913
Sep 18 13:53:00.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-4913 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 13:53:00.528: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 18 13:53:00.528: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 18 13:53:00.528: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 18 13:53:00.535: INFO: Found 1 stateful pods, waiting for 3
Sep 18 13:53:10.543: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 18 13:53:10.543: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 18 13:53:10.543: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep 18 13:53:10.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-4913 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 18 13:53:10.719: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 18 13:53:10.719: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 18 13:53:10.719: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 18 13:53:10.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-4913 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 18 13:53:10.872: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 18 13:53:10.872: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 18 13:53:10.872: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 18 13:53:10.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-4913 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 18 13:53:11.038: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 18 13:53:11.038: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 18 13:53:11.038: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 18 13:53:11.038: INFO: Waiting for statefulset status.replicas updated to 0
Sep 18 13:53:11.045: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep 18 13:53:21.061: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 18 13:53:21.061: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 18 13:53:21.061: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 18 13:53:21.084: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999697s
Sep 18 13:53:22.092: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991220505s
Sep 18 13:53:23.100: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.983174152s
Sep 18 13:53:24.108: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.975345938s
Sep 18 13:53:25.116: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.967072913s
Sep 18 13:53:26.124: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.959241958s
Sep 18 13:53:27.132: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.95147123s
Sep 18 13:53:28.140: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.943675368s
Sep 18 13:53:29.147: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.935725892s
Sep 18 13:53:30.156: INFO: Verifying statefulset ss doesn't scale past 3 for another 927.930776ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4913
Sep 18 13:53:31.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-4913 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 13:53:31.326: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 18 13:53:31.326: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 18 13:53:31.326: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 18 13:53:31.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-4913 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 13:53:31.474: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 18 13:53:31.474: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 18 13:53:31.474: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 18 13:53:31.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 exec --namespace=statefulset-4913 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 18 13:53:31.630: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 18 13:53:31.630: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 18 13:53:31.630: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 18 13:53:31.630: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep 18 13:53:51.661: INFO: Deleting all statefulset in ns statefulset-4913
Sep 18 13:53:51.667: INFO: Scaling statefulset ss to 0
Sep 18 13:53:51.688: INFO: Waiting for statefulset status.replicas updated to 0
Sep 18 13:53:51.694: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:53:51.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4913" for this suite.
Sep 18 13:53:57.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:53:57.982: INFO: namespace statefulset-4913 deletion completed in 6.247803698s

• [SLOW TEST:88.000 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:53:57.983: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 13:54:18.074: INFO: Container started at 2019-09-18 13:53:58 +0000 UTC, pod became ready at 2019-09-18 13:54:17 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:54:18.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3450" for this suite.
Sep 18 13:54:40.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:54:40.327: INFO: namespace container-probe-3450 deletion completed in 22.243004015s

• [SLOW TEST:42.345 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:54:40.328: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 13:54:40.388: INFO: Creating ReplicaSet my-hostname-basic-dc24e2ee-da1b-11e9-8fe5-1a4434d30f67
Sep 18 13:54:40.411: INFO: Pod name my-hostname-basic-dc24e2ee-da1b-11e9-8fe5-1a4434d30f67: Found 0 pods out of 1
Sep 18 13:54:45.419: INFO: Pod name my-hostname-basic-dc24e2ee-da1b-11e9-8fe5-1a4434d30f67: Found 1 pods out of 1
Sep 18 13:54:45.419: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-dc24e2ee-da1b-11e9-8fe5-1a4434d30f67" is running
Sep 18 13:54:45.426: INFO: Pod "my-hostname-basic-dc24e2ee-da1b-11e9-8fe5-1a4434d30f67-z8rcn" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-18 13:54:40 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-18 13:54:40 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-18 13:54:40 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-18 13:54:40 +0000 UTC Reason: Message:}])
Sep 18 13:54:45.426: INFO: Trying to dial the pod
Sep 18 13:54:50.452: INFO: Controller my-hostname-basic-dc24e2ee-da1b-11e9-8fe5-1a4434d30f67: Got expected result from replica 1 [my-hostname-basic-dc24e2ee-da1b-11e9-8fe5-1a4434d30f67-z8rcn]: "my-hostname-basic-dc24e2ee-da1b-11e9-8fe5-1a4434d30f67-z8rcn", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:54:50.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5205" for this suite.
Sep 18 13:54:56.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:54:56.709: INFO: namespace replicaset-5205 deletion completed in 6.245599532s

• [SLOW TEST:16.381 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:54:56.709: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-2984
Sep 18 13:54:58.789: INFO: Started pod liveness-exec in namespace container-probe-2984
STEP: checking the pod's current state and verifying that restartCount is present
Sep 18 13:54:58.796: INFO: Initial restart count of pod liveness-exec is 0
Sep 18 13:55:53.015: INFO: Restart count of pod container-probe-2984/liveness-exec is now 1 (54.218774175s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:55:53.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2984" for this suite.
Sep 18 13:55:59.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:55:59.295: INFO: namespace container-probe-2984 deletion completed in 6.244907056s

• [SLOW TEST:62.586 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:55:59.295: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-0b362021-da1c-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume secrets
Sep 18 13:55:59.443: INFO: Waiting up to 5m0s for pod "pod-secrets-0b4166c0-da1c-11e9-8fe5-1a4434d30f67" in namespace "secrets-8457" to be "success or failure"
Sep 18 13:55:59.450: INFO: Pod "pod-secrets-0b4166c0-da1c-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.6096ms
Sep 18 13:56:01.458: INFO: Pod "pod-secrets-0b4166c0-da1c-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015534682s
STEP: Saw pod success
Sep 18 13:56:01.458: INFO: Pod "pod-secrets-0b4166c0-da1c-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:56:01.465: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-secrets-0b4166c0-da1c-11e9-8fe5-1a4434d30f67 container secret-volume-test: <nil>
STEP: delete the pod
Sep 18 13:56:01.510: INFO: Waiting for pod pod-secrets-0b4166c0-da1c-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:56:01.516: INFO: Pod pod-secrets-0b4166c0-da1c-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:56:01.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8457" for this suite.
Sep 18 13:56:07.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:56:07.778: INFO: namespace secrets-8457 deletion completed in 6.251643877s
STEP: Destroying namespace "secret-namespace-6048" for this suite.
Sep 18 13:56:13.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:56:14.030: INFO: namespace secret-namespace-6048 deletion completed in 6.251688279s

• [SLOW TEST:14.735 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:56:14.030: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-13ff5dee-da1c-11e9-8fe5-1a4434d30f67
STEP: Creating configMap with name cm-test-opt-upd-13ff5e1b-da1c-11e9-8fe5-1a4434d30f67
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-13ff5dee-da1c-11e9-8fe5-1a4434d30f67
STEP: Updating configmap cm-test-opt-upd-13ff5e1b-da1c-11e9-8fe5-1a4434d30f67
STEP: Creating configMap with name cm-test-opt-create-13ff5e2a-da1c-11e9-8fe5-1a4434d30f67
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:56:20.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8164" for this suite.
Sep 18 13:56:42.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:56:42.571: INFO: namespace configmap-8164 deletion completed in 22.259023486s

• [SLOW TEST:28.541 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:56:42.571: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep 18 13:56:45.197: INFO: Successfully updated pod "labelsupdate2501125e-da1c-11e9-8fe5-1a4434d30f67"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:56:47.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5013" for this suite.
Sep 18 13:57:09.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:57:09.503: INFO: namespace projected-5013 deletion completed in 22.262498732s

• [SLOW TEST:26.932 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:57:09.503: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 18 13:57:09.569: INFO: Waiting up to 5m0s for pod "pod-350e065a-da1c-11e9-8fe5-1a4434d30f67" in namespace "emptydir-6745" to be "success or failure"
Sep 18 13:57:09.576: INFO: Pod "pod-350e065a-da1c-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.632083ms
Sep 18 13:57:11.584: INFO: Pod "pod-350e065a-da1c-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014729718s
STEP: Saw pod success
Sep 18 13:57:11.584: INFO: Pod "pod-350e065a-da1c-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:57:11.591: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-350e065a-da1c-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 13:57:11.633: INFO: Waiting for pod pod-350e065a-da1c-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:57:11.639: INFO: Pod pod-350e065a-da1c-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:57:11.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6745" for this suite.
Sep 18 13:57:17.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:57:17.893: INFO: namespace emptydir-6745 deletion completed in 6.243921736s

• [SLOW TEST:8.390 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:57:17.894: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9389.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9389.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9389.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9389.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9389.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9389.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 18 13:57:20.068: INFO: DNS probes using dns-9389/dns-test-3a105a4a-da1c-11e9-8fe5-1a4434d30f67 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:57:20.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9389" for this suite.
Sep 18 13:57:26.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:57:26.351: INFO: namespace dns-9389 deletion completed in 6.243627511s

• [SLOW TEST:8.458 seconds]
[sig-network] DNS
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:57:26.351: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep 18 13:57:26.407: INFO: PodSpec: initContainers in spec.initContainers
Sep 18 13:58:12.478: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-3f195a65-da1c-11e9-8fe5-1a4434d30f67", GenerateName:"", Namespace:"init-container-2659", SelfLink:"/api/v1/namespaces/init-container-2659/pods/pod-init-3f195a65-da1c-11e9-8fe5-1a4434d30f67", UID:"3f1cd66f-da1c-11e9-b983-fa163edda742", ResourceVersion:"242424", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63704411846, loc:(*time.Location)(0x8825120)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"407643845"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fd4bp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0029cf1c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fd4bp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fd4bp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fd4bp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00217ff18), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-node-vm1qxh-95up3dyso1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0020b6d80), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00217ff90)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00217ffb0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00217ffb8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00217ffbc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704411846, loc:(*time.Location)(0x8825120)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704411846, loc:(*time.Location)(0x8825120)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704411846, loc:(*time.Location)(0x8825120)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704411846, loc:(*time.Location)(0x8825120)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.224.5", PodIP:"10.0.192.25", StartTime:(*v1.Time)(0xc00176cd80), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000a023f0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000a02620)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/busybox@sha256:e004c2cc521c95383aebb1fb5893719aa7a8eae2e7a71f316a4410784edb00a9", ContainerID:"docker://f3771b1f6667c7752393b2655ab84d4bc8e0ae9372729146f22f8764a7f14752"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00176cdc0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00176cda0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:58:12.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2659" for this suite.
Sep 18 13:58:34.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:58:34.748: INFO: namespace init-container-2659 deletion completed in 22.247417597s

• [SLOW TEST:68.397 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:58:34.749: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-67ddf5a2-da1c-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume secrets
Sep 18 13:58:34.825: INFO: Waiting up to 5m0s for pod "pod-secrets-67df1f7e-da1c-11e9-8fe5-1a4434d30f67" in namespace "secrets-3148" to be "success or failure"
Sep 18 13:58:34.833: INFO: Pod "pod-secrets-67df1f7e-da1c-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.517736ms
Sep 18 13:58:36.841: INFO: Pod "pod-secrets-67df1f7e-da1c-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015315952s
STEP: Saw pod success
Sep 18 13:58:36.841: INFO: Pod "pod-secrets-67df1f7e-da1c-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:58:36.848: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-secrets-67df1f7e-da1c-11e9-8fe5-1a4434d30f67 container secret-volume-test: <nil>
STEP: delete the pod
Sep 18 13:58:36.890: INFO: Waiting for pod pod-secrets-67df1f7e-da1c-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:58:36.897: INFO: Pod pod-secrets-67df1f7e-da1c-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:58:36.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3148" for this suite.
Sep 18 13:58:42.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:58:43.161: INFO: namespace secrets-3148 deletion completed in 6.253447906s

• [SLOW TEST:8.412 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:58:43.161: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-m62s
STEP: Creating a pod to test atomic-volume-subpath
Sep 18 13:58:43.245: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-m62s" in namespace "subpath-3601" to be "success or failure"
Sep 18 13:58:43.252: INFO: Pod "pod-subpath-test-configmap-m62s": Phase="Pending", Reason="", readiness=false. Elapsed: 6.651428ms
Sep 18 13:58:45.259: INFO: Pod "pod-subpath-test-configmap-m62s": Phase="Running", Reason="", readiness=true. Elapsed: 2.014029389s
Sep 18 13:58:47.266: INFO: Pod "pod-subpath-test-configmap-m62s": Phase="Running", Reason="", readiness=true. Elapsed: 4.021224673s
Sep 18 13:58:49.276: INFO: Pod "pod-subpath-test-configmap-m62s": Phase="Running", Reason="", readiness=true. Elapsed: 6.031336295s
Sep 18 13:58:51.285: INFO: Pod "pod-subpath-test-configmap-m62s": Phase="Running", Reason="", readiness=true. Elapsed: 8.039817267s
Sep 18 13:58:53.293: INFO: Pod "pod-subpath-test-configmap-m62s": Phase="Running", Reason="", readiness=true. Elapsed: 10.0474695s
Sep 18 13:58:55.300: INFO: Pod "pod-subpath-test-configmap-m62s": Phase="Running", Reason="", readiness=true. Elapsed: 12.055089037s
Sep 18 13:58:57.308: INFO: Pod "pod-subpath-test-configmap-m62s": Phase="Running", Reason="", readiness=true. Elapsed: 14.06261631s
Sep 18 13:58:59.315: INFO: Pod "pod-subpath-test-configmap-m62s": Phase="Running", Reason="", readiness=true. Elapsed: 16.070112309s
Sep 18 13:59:01.322: INFO: Pod "pod-subpath-test-configmap-m62s": Phase="Running", Reason="", readiness=true. Elapsed: 18.077290977s
Sep 18 13:59:03.333: INFO: Pod "pod-subpath-test-configmap-m62s": Phase="Running", Reason="", readiness=true. Elapsed: 20.088013707s
Sep 18 13:59:05.340: INFO: Pod "pod-subpath-test-configmap-m62s": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.095113122s
STEP: Saw pod success
Sep 18 13:59:05.340: INFO: Pod "pod-subpath-test-configmap-m62s" satisfied condition "success or failure"
Sep 18 13:59:05.348: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-subpath-test-configmap-m62s container test-container-subpath-configmap-m62s: <nil>
STEP: delete the pod
Sep 18 13:59:05.389: INFO: Waiting for pod pod-subpath-test-configmap-m62s to disappear
Sep 18 13:59:05.396: INFO: Pod pod-subpath-test-configmap-m62s no longer exists
STEP: Deleting pod pod-subpath-test-configmap-m62s
Sep 18 13:59:05.396: INFO: Deleting pod "pod-subpath-test-configmap-m62s" in namespace "subpath-3601"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:59:05.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3601" for this suite.
Sep 18 13:59:11.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:59:11.659: INFO: namespace subpath-3601 deletion completed in 6.245846973s

• [SLOW TEST:28.498 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:59:11.659: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-7dde2f84-da1c-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume configMaps
Sep 18 13:59:11.738: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7ddf655e-da1c-11e9-8fe5-1a4434d30f67" in namespace "projected-3861" to be "success or failure"
Sep 18 13:59:11.746: INFO: Pod "pod-projected-configmaps-7ddf655e-da1c-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 8.162251ms
Sep 18 13:59:13.754: INFO: Pod "pod-projected-configmaps-7ddf655e-da1c-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016213077s
STEP: Saw pod success
Sep 18 13:59:13.754: INFO: Pod "pod-projected-configmaps-7ddf655e-da1c-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 13:59:13.761: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-projected-configmaps-7ddf655e-da1c-11e9-8fe5-1a4434d30f67 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 18 13:59:13.801: INFO: Waiting for pod pod-projected-configmaps-7ddf655e-da1c-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 13:59:13.808: INFO: Pod pod-projected-configmaps-7ddf655e-da1c-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:59:13.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3861" for this suite.
Sep 18 13:59:19.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:59:20.073: INFO: namespace projected-3861 deletion completed in 6.254754259s

• [SLOW TEST:8.414 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:59:20.073: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Sep 18 13:59:22.680: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1201 pod-service-account-8331a443-da1c-11e9-8fe5-1a4434d30f67 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Sep 18 13:59:22.837: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1201 pod-service-account-8331a443-da1c-11e9-8fe5-1a4434d30f67 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Sep 18 13:59:22.991: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1201 pod-service-account-8331a443-da1c-11e9-8fe5-1a4434d30f67 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:59:23.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1201" for this suite.
Sep 18 13:59:29.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:59:29.411: INFO: namespace svcaccounts-1201 deletion completed in 6.249921727s

• [SLOW TEST:9.338 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 13:59:29.412: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 13:59:53.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3869" for this suite.
Sep 18 13:59:59.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 13:59:59.891: INFO: namespace namespaces-3869 deletion completed in 6.245307384s
STEP: Destroying namespace "nsdeletetest-1021" for this suite.
Sep 18 13:59:59.898: INFO: Namespace nsdeletetest-1021 was already deleted
STEP: Destroying namespace "nsdeletetest-756" for this suite.
Sep 18 14:00:05.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 14:00:06.138: INFO: namespace nsdeletetest-756 deletion completed in 6.240676481s

• [SLOW TEST:36.727 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 14:00:06.139: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-6892/configmap-test-9e568bbd-da1c-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume configMaps
Sep 18 14:00:06.214: INFO: Waiting up to 5m0s for pod "pod-configmaps-9e57bd27-da1c-11e9-8fe5-1a4434d30f67" in namespace "configmap-6892" to be "success or failure"
Sep 18 14:00:06.220: INFO: Pod "pod-configmaps-9e57bd27-da1c-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.563027ms
Sep 18 14:00:08.228: INFO: Pod "pod-configmaps-9e57bd27-da1c-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014407744s
STEP: Saw pod success
Sep 18 14:00:08.228: INFO: Pod "pod-configmaps-9e57bd27-da1c-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 14:00:08.235: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-configmaps-9e57bd27-da1c-11e9-8fe5-1a4434d30f67 container env-test: <nil>
STEP: delete the pod
Sep 18 14:00:08.277: INFO: Waiting for pod pod-configmaps-9e57bd27-da1c-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 14:00:08.285: INFO: Pod pod-configmaps-9e57bd27-da1c-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 14:00:08.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6892" for this suite.
Sep 18 14:00:14.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 14:00:14.547: INFO: namespace configmap-6892 deletion completed in 6.251114421s

• [SLOW TEST:8.408 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 14:00:14.548: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Sep 18 14:00:14.613: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Sep 18 14:00:21.685: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 14:00:21.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2816" for this suite.
Sep 18 14:00:27.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 14:00:27.946: INFO: namespace pods-2816 deletion completed in 6.243077277s

• [SLOW TEST:13.398 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 14:00:27.946: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 14:00:28.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 create -f - --namespace=kubectl-3132'
Sep 18 14:00:28.192: INFO: stderr: ""
Sep 18 14:00:28.192: INFO: stdout: "replicationcontroller/redis-master created\n"
Sep 18 14:00:28.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 create -f - --namespace=kubectl-3132'
Sep 18 14:00:28.337: INFO: stderr: ""
Sep 18 14:00:28.337: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 18 14:00:29.345: INFO: Selector matched 1 pods for map[app:redis]
Sep 18 14:00:29.345: INFO: Found 0 / 1
Sep 18 14:00:30.345: INFO: Selector matched 1 pods for map[app:redis]
Sep 18 14:00:30.345: INFO: Found 1 / 1
Sep 18 14:00:30.345: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 18 14:00:30.351: INFO: Selector matched 1 pods for map[app:redis]
Sep 18 14:00:30.351: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 18 14:00:30.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 describe pod redis-master-sjvgb --namespace=kubectl-3132'
Sep 18 14:00:30.436: INFO: stderr: ""
Sep 18 14:00:30.436: INFO: stdout: "Name:               redis-master-sjvgb\nNamespace:          kubectl-3132\nPriority:           0\nPriorityClassName:  <none>\nNode:               k8s-node-vm1qxh-95up3dyso1/10.0.224.5\nStart Time:         Wed, 18 Sep 2019 14:00:28 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.0.192.23\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://3b65a377e91318710c9608fbf49e481d55784bc5f7fe9d650e9f148441f9d12f\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/kubernetes-e2e-test-images/redis@sha256:2238f5a02d2648d41cc94a88f084060fbfa860890220328eb92696bf2ac649c9\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 18 Sep 2019 14:00:28 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-b874d (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-b874d:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-b874d\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                 Message\n  ----    ------     ----  ----                                 -------\n  Normal  Scheduled  2s    default-scheduler                    Successfully assigned kubectl-3132/redis-master-sjvgb to k8s-node-vm1qxh-95up3dyso1\n  Normal  Pulled     2s    kubelet, k8s-node-vm1qxh-95up3dyso1  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, k8s-node-vm1qxh-95up3dyso1  Created container redis-master\n  Normal  Started    2s    kubelet, k8s-node-vm1qxh-95up3dyso1  Started container redis-master\n"
Sep 18 14:00:30.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 describe rc redis-master --namespace=kubectl-3132'
Sep 18 14:00:30.526: INFO: stderr: ""
Sep 18 14:00:30.526: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-3132\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-sjvgb\n"
Sep 18 14:00:30.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 describe service redis-master --namespace=kubectl-3132'
Sep 18 14:00:30.611: INFO: stderr: ""
Sep 18 14:00:30.611: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-3132\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.0.250.83\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.0.192.23:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep 18 14:00:30.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 describe node k8s-node-vm1qxh-95up3dyso1'
Sep 18 14:00:30.730: INFO: stderr: ""
Sep 18 14:00:30.730: INFO: stdout: "Name:               k8s-node-vm1qxh-95up3dyso1\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=g.n2.2xlarge\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/jke-fd=1\n                    failure-domain.beta.kubernetes.io/jke-nodegroup=ng-95up3dyso1\n                    failure-domain.beta.kubernetes.io/region=cn-east-2\n                    failure-domain.beta.kubernetes.io/zone=cn-east-2a\n                    group=default\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=k8s-node-vm1qxh-95up3dyso1\n                    kubernetes.io/os=linux\n                    topology.zbs.csi.jdcloud.com/zone=cn-east-2a\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"zbs.csi.jdcloud.com\":\"i-qhu7hlnzk9\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 17 Sep 2019 13:31:09 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 18 Sep 2019 14:00:30 +0000   Tue, 17 Sep 2019 13:31:09 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 18 Sep 2019 14:00:30 +0000   Tue, 17 Sep 2019 13:31:09 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 18 Sep 2019 14:00:30 +0000   Tue, 17 Sep 2019 13:31:09 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 18 Sep 2019 14:00:30 +0000   Tue, 17 Sep 2019 13:31:59 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.224.5\nCapacity:\n attachable-volumes-csi-zbs.csi.jdcloud.com:  25\n cpu:                                         8\n ephemeral-storage:                           103079844Ki\n hugepages-1Gi:                               0\n hugepages-2Mi:                               0\n memory:                                      32781220Ki\n pods:                                        110\nAllocatable:\n attachable-volumes-csi-zbs.csi.jdcloud.com:  25\n cpu:                                         7910m\n ephemeral-storage:                           94998384074\n hugepages-1Gi:                               0\n hugepages-2Mi:                               0\n memory:                                      29048740Ki\n pods:                                        110\nSystem Info:\n Machine ID:                 14a3101311244529baf9bae25e18d934\n System UUID:                E3E5EE35-63BC-484D-BCD9-57628C0C60ED\n Boot ID:                    b7b12f33-9a34-46e0-89fb-de7f3eb8bc31\n Kernel Version:             3.10.0-693.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.6.2\n Kubelet Version:            v1.14.6-23.3d03dd1\n Kube-Proxy Version:         v1.14.6-23.3d03dd1\nProviderID:                  jdcloud:///cn-east-2a/i-qhu7hlnzk9\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         89m\n  heptio-sonobuoy            sonobuoy-e2e-job-f17ac7a1786c4dde                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         85m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-c0812b53cb224d4d-cbx95    0 (0%)        0 (0%)      0 (0%)           0 (0%)         85m\n  jke-system                 csi-jdcloudplugin-z2wwd                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         24h\n  jke-system                 node-exporter-fwmxn                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         24h\n  kube-system                coredns-6b4fdb779b-qzqfd                                   100m (1%)     0 (0%)      70Mi (0%)        170Mi (0%)     4h19m\n  kube-system                jdcloud-k8s-ipamd-6sz6f                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         24h\n  kube-system                kube-proxy-hx4lq                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         24h\n  kubectl-3132               redis-master-sjvgb                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                                    Requests   Limits\n  --------                                    --------   ------\n  cpu                                         100m (1%)  0 (0%)\n  memory                                      70Mi (0%)  170Mi (0%)\n  ephemeral-storage                           0 (0%)     0 (0%)\n  attachable-volumes-csi-zbs.csi.jdcloud.com  0          0\nEvents:                                       <none>\n"
Sep 18 14:00:30.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 describe namespace kubectl-3132'
Sep 18 14:00:30.814: INFO: stderr: ""
Sep 18 14:00:30.814: INFO: stdout: "Name:         kubectl-3132\nLabels:       e2e-framework=kubectl\n              e2e-run=c31118f4-da10-11e9-8fe5-1a4434d30f67\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 14:00:30.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3132" for this suite.
Sep 18 14:00:52.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 14:00:53.075: INFO: namespace kubectl-3132 deletion completed in 22.251140114s

• [SLOW TEST:25.129 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 14:00:53.075: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 18 14:00:53.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 version'
Sep 18 14:00:53.185: INFO: stderr: ""
Sep 18 14:00:53.185: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.6\", GitCommit:\"96fac5cd13a5dc064f7d9f4f23030a6aeface6cc\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:13:49Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14+\", GitVersion:\"v1.14.6-23.3d03dd1\", GitCommit:\"3d03dd1a6daf2e8bff23e2aa2e2c30394a1fbfe9\", GitTreeState:\"clean\", BuildDate:\"2019-09-07T13:17:45Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 14:00:53.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7725" for this suite.
Sep 18 14:00:59.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 14:00:59.443: INFO: namespace kubectl-7725 deletion completed in 6.246647205s

• [SLOW TEST:6.367 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 14:00:59.443: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-be1c883d-da1c-11e9-8fe5-1a4434d30f67
STEP: Creating a pod to test consume configMaps
Sep 18 14:00:59.520: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-be1dcec2-da1c-11e9-8fe5-1a4434d30f67" in namespace "projected-3840" to be "success or failure"
Sep 18 14:00:59.528: INFO: Pod "pod-projected-configmaps-be1dcec2-da1c-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 7.318503ms
Sep 18 14:01:01.535: INFO: Pod "pod-projected-configmaps-be1dcec2-da1c-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015260444s
STEP: Saw pod success
Sep 18 14:01:01.536: INFO: Pod "pod-projected-configmaps-be1dcec2-da1c-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 14:01:01.543: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-projected-configmaps-be1dcec2-da1c-11e9-8fe5-1a4434d30f67 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 18 14:01:01.585: INFO: Waiting for pod pod-projected-configmaps-be1dcec2-da1c-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 14:01:01.592: INFO: Pod pod-projected-configmaps-be1dcec2-da1c-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 14:01:01.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3840" for this suite.
Sep 18 14:01:07.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 14:01:07.844: INFO: namespace projected-3840 deletion completed in 6.241666602s

• [SLOW TEST:8.401 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 14:01:07.844: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 18 14:01:07.911: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c31e259f-da1c-11e9-8fe5-1a4434d30f67" in namespace "downward-api-6952" to be "success or failure"
Sep 18 14:01:07.918: INFO: Pod "downwardapi-volume-c31e259f-da1c-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.673036ms
Sep 18 14:01:09.926: INFO: Pod "downwardapi-volume-c31e259f-da1c-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015246207s
STEP: Saw pod success
Sep 18 14:01:09.926: INFO: Pod "downwardapi-volume-c31e259f-da1c-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 14:01:09.933: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod downwardapi-volume-c31e259f-da1c-11e9-8fe5-1a4434d30f67 container client-container: <nil>
STEP: delete the pod
Sep 18 14:01:09.973: INFO: Waiting for pod downwardapi-volume-c31e259f-da1c-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 14:01:09.979: INFO: Pod downwardapi-volume-c31e259f-da1c-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 14:01:09.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6952" for this suite.
Sep 18 14:01:16.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 14:01:16.249: INFO: namespace downward-api-6952 deletion completed in 6.259071468s

• [SLOW TEST:8.405 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 14:01:16.250: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 14:01:18.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-223" for this suite.
Sep 18 14:01:58.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 14:01:58.625: INFO: namespace kubelet-test-223 deletion completed in 40.251737162s

• [SLOW TEST:42.376 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 14:01:58.626: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 18 14:01:58.697: INFO: Waiting up to 5m0s for pod "pod-e1633382-da1c-11e9-8fe5-1a4434d30f67" in namespace "emptydir-3167" to be "success or failure"
Sep 18 14:01:58.704: INFO: Pod "pod-e1633382-da1c-11e9-8fe5-1a4434d30f67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.522697ms
Sep 18 14:02:00.711: INFO: Pod "pod-e1633382-da1c-11e9-8fe5-1a4434d30f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0144524s
STEP: Saw pod success
Sep 18 14:02:00.711: INFO: Pod "pod-e1633382-da1c-11e9-8fe5-1a4434d30f67" satisfied condition "success or failure"
Sep 18 14:02:00.718: INFO: Trying to get logs from node k8s-node-vm1qxh-95up3dyso1 pod pod-e1633382-da1c-11e9-8fe5-1a4434d30f67 container test-container: <nil>
STEP: delete the pod
Sep 18 14:02:00.759: INFO: Waiting for pod pod-e1633382-da1c-11e9-8fe5-1a4434d30f67 to disappear
Sep 18 14:02:00.767: INFO: Pod pod-e1633382-da1c-11e9-8fe5-1a4434d30f67 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 14:02:00.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3167" for this suite.
Sep 18 14:02:06.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 14:02:07.045: INFO: namespace emptydir-3167 deletion completed in 6.267316039s

• [SLOW TEST:8.419 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 18 14:02:07.045: INFO: >>> kubeConfig: /tmp/kubeconfig-496730594
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Sep 18 14:02:07.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 create -f - --namespace=kubectl-4121'
Sep 18 14:02:07.236: INFO: stderr: ""
Sep 18 14:02:07.236: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 18 14:02:07.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4121'
Sep 18 14:02:07.305: INFO: stderr: ""
Sep 18 14:02:07.305: INFO: stdout: "update-demo-nautilus-4fn8m update-demo-nautilus-vpksq "
Sep 18 14:02:07.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-4fn8m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4121'
Sep 18 14:02:07.368: INFO: stderr: ""
Sep 18 14:02:07.368: INFO: stdout: ""
Sep 18 14:02:07.368: INFO: update-demo-nautilus-4fn8m is created but not running
Sep 18 14:02:12.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4121'
Sep 18 14:02:12.433: INFO: stderr: ""
Sep 18 14:02:12.433: INFO: stdout: "update-demo-nautilus-4fn8m update-demo-nautilus-vpksq "
Sep 18 14:02:12.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-4fn8m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4121'
Sep 18 14:02:12.496: INFO: stderr: ""
Sep 18 14:02:12.496: INFO: stdout: "true"
Sep 18 14:02:12.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-4fn8m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4121'
Sep 18 14:02:12.558: INFO: stderr: ""
Sep 18 14:02:12.558: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 18 14:02:12.558: INFO: validating pod update-demo-nautilus-4fn8m
Sep 18 14:02:12.569: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 18 14:02:12.570: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 18 14:02:12.570: INFO: update-demo-nautilus-4fn8m is verified up and running
Sep 18 14:02:12.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-vpksq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4121'
Sep 18 14:02:12.633: INFO: stderr: ""
Sep 18 14:02:12.633: INFO: stdout: "true"
Sep 18 14:02:12.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-vpksq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4121'
Sep 18 14:02:12.697: INFO: stderr: ""
Sep 18 14:02:12.697: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 18 14:02:12.697: INFO: validating pod update-demo-nautilus-vpksq
Sep 18 14:02:12.708: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 18 14:02:12.708: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 18 14:02:12.708: INFO: update-demo-nautilus-vpksq is verified up and running
STEP: scaling down the replication controller
Sep 18 14:02:12.709: INFO: scanned /root for discovery docs: <nil>
Sep 18 14:02:12.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-4121'
Sep 18 14:02:13.814: INFO: stderr: ""
Sep 18 14:02:13.814: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 18 14:02:13.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4121'
Sep 18 14:02:13.878: INFO: stderr: ""
Sep 18 14:02:13.878: INFO: stdout: "update-demo-nautilus-4fn8m update-demo-nautilus-vpksq "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep 18 14:02:18.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4121'
Sep 18 14:02:18.945: INFO: stderr: ""
Sep 18 14:02:18.945: INFO: stdout: "update-demo-nautilus-4fn8m "
Sep 18 14:02:18.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-4fn8m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4121'
Sep 18 14:02:19.007: INFO: stderr: ""
Sep 18 14:02:19.007: INFO: stdout: "true"
Sep 18 14:02:19.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-4fn8m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4121'
Sep 18 14:02:19.070: INFO: stderr: ""
Sep 18 14:02:19.070: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 18 14:02:19.070: INFO: validating pod update-demo-nautilus-4fn8m
Sep 18 14:02:19.078: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 18 14:02:19.078: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 18 14:02:19.079: INFO: update-demo-nautilus-4fn8m is verified up and running
STEP: scaling up the replication controller
Sep 18 14:02:19.079: INFO: scanned /root for discovery docs: <nil>
Sep 18 14:02:19.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-4121'
Sep 18 14:02:20.184: INFO: stderr: ""
Sep 18 14:02:20.184: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 18 14:02:20.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4121'
Sep 18 14:02:20.253: INFO: stderr: ""
Sep 18 14:02:20.253: INFO: stdout: "update-demo-nautilus-4fn8m update-demo-nautilus-wxrnp "
Sep 18 14:02:20.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-4fn8m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4121'
Sep 18 14:02:20.315: INFO: stderr: ""
Sep 18 14:02:20.315: INFO: stdout: "true"
Sep 18 14:02:20.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-4fn8m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4121'
Sep 18 14:02:20.378: INFO: stderr: ""
Sep 18 14:02:20.378: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 18 14:02:20.378: INFO: validating pod update-demo-nautilus-4fn8m
Sep 18 14:02:20.387: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 18 14:02:20.387: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 18 14:02:20.387: INFO: update-demo-nautilus-4fn8m is verified up and running
Sep 18 14:02:20.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-wxrnp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4121'
Sep 18 14:02:20.449: INFO: stderr: ""
Sep 18 14:02:20.449: INFO: stdout: "true"
Sep 18 14:02:20.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods update-demo-nautilus-wxrnp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4121'
Sep 18 14:02:20.512: INFO: stderr: ""
Sep 18 14:02:20.512: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 18 14:02:20.512: INFO: validating pod update-demo-nautilus-wxrnp
Sep 18 14:02:20.521: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 18 14:02:20.521: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 18 14:02:20.521: INFO: update-demo-nautilus-wxrnp is verified up and running
STEP: using delete to clean up resources
Sep 18 14:02:20.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 delete --grace-period=0 --force -f - --namespace=kubectl-4121'
Sep 18 14:02:20.600: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 18 14:02:20.600: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 18 14:02:20.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4121'
Sep 18 14:02:20.671: INFO: stderr: "No resources found.\n"
Sep 18 14:02:20.671: INFO: stdout: ""
Sep 18 14:02:20.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods -l name=update-demo --namespace=kubectl-4121 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 18 14:02:20.738: INFO: stderr: ""
Sep 18 14:02:20.738: INFO: stdout: "update-demo-nautilus-4fn8m\nupdate-demo-nautilus-wxrnp\n"
Sep 18 14:02:21.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4121'
Sep 18 14:02:21.310: INFO: stderr: "No resources found.\n"
Sep 18 14:02:21.310: INFO: stdout: ""
Sep 18 14:02:21.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-496730594 get pods -l name=update-demo --namespace=kubectl-4121 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 18 14:02:21.376: INFO: stderr: ""
Sep 18 14:02:21.376: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 18 14:02:21.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4121" for this suite.
Sep 18 14:02:43.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 18 14:02:43.636: INFO: namespace kubectl-4121 deletion completed in 22.248732773s

• [SLOW TEST:36.591 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSep 18 14:02:43.636: INFO: Running AfterSuite actions on all nodes
Sep 18 14:02:43.636: INFO: Running AfterSuite actions on node 1
Sep 18 14:02:43.636: INFO: Skipping dumping logs from cluster

Ran 204 of 3586 Specs in 5248.945 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3382 Skipped PASS

Ginkgo ran 1 suite in 1h27m29.853436336s
Test Suite Passed
