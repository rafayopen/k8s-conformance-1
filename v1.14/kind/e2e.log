Client Version: version.Info{Major:"1", Minor:"14", GitVersion:"v1.14.0", GitCommit:"641856db18352033a0d96dbc99153fa3b27298e5", GitTreeState:"clean", BuildDate:"2019-03-26T00:21:23Z", GoVersion:"go1.12.1", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"14", GitVersion:"v1.14.0", GitCommit:"641856db18352033a0d96dbc99153fa3b27298e5", GitTreeState:"clean", BuildDate:"2019-03-25T23:47:43Z", GoVersion:"go1.12.1", Compiler:"gc", Platform:"linux/amd64"}
Conformance test: not doing test setup.
I0325 17:27:40.786417   72333 e2e.go:240] Starting e2e run "f6b0a356-4f5d-11e9-91ba-a08cfdecc127" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: [1m1553560060[0m - Will randomize all specs
Will run [1m182[0m of [1m3584[0m specs

Mar 25 17:27:40.913: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 17:27:40.915: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar 25 17:27:40.930: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar 25 17:27:40.958: INFO: 12 / 12 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar 25 17:27:40.958: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Mar 25 17:27:40.958: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar 25 17:27:40.963: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Mar 25 17:27:40.963: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'weave-net' (0 seconds elapsed)
Mar 25 17:27:40.963: INFO: e2e test version: v1.14.0
Mar 25 17:27:40.964: INFO: kube-apiserver version: v1.14.0
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Subpath[0m [90mAtomic writer volumes[0m 
  [1mshould support subpaths with projected pod [LinuxOnly] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Subpath
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:27:40.965: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename subpath
Mar 25 17:27:40.991: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
[1mSTEP[0m: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating pod pod-subpath-test-projected-7qdd
[1mSTEP[0m: Creating a pod to test atomic-volume-subpath
Mar 25 17:27:40.999: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-7qdd" in namespace "subpath-4036" to be "success or failure"
Mar 25 17:27:41.003: INFO: Pod "pod-subpath-test-projected-7qdd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.219697ms
Mar 25 17:27:43.007: INFO: Pod "pod-subpath-test-projected-7qdd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008239849s
Mar 25 17:27:45.011: INFO: Pod "pod-subpath-test-projected-7qdd": Phase="Running", Reason="", readiness=true. Elapsed: 4.011710609s
Mar 25 17:27:47.015: INFO: Pod "pod-subpath-test-projected-7qdd": Phase="Running", Reason="", readiness=true. Elapsed: 6.015522491s
Mar 25 17:27:49.018: INFO: Pod "pod-subpath-test-projected-7qdd": Phase="Running", Reason="", readiness=true. Elapsed: 8.018582654s
Mar 25 17:27:51.022: INFO: Pod "pod-subpath-test-projected-7qdd": Phase="Running", Reason="", readiness=true. Elapsed: 10.022389563s
Mar 25 17:27:53.026: INFO: Pod "pod-subpath-test-projected-7qdd": Phase="Running", Reason="", readiness=true. Elapsed: 12.026468673s
Mar 25 17:27:55.030: INFO: Pod "pod-subpath-test-projected-7qdd": Phase="Running", Reason="", readiness=true. Elapsed: 14.030478081s
Mar 25 17:27:57.034: INFO: Pod "pod-subpath-test-projected-7qdd": Phase="Running", Reason="", readiness=true. Elapsed: 16.034487504s
Mar 25 17:27:59.037: INFO: Pod "pod-subpath-test-projected-7qdd": Phase="Running", Reason="", readiness=true. Elapsed: 18.037739887s
Mar 25 17:28:01.041: INFO: Pod "pod-subpath-test-projected-7qdd": Phase="Running", Reason="", readiness=true. Elapsed: 20.04183933s
Mar 25 17:28:03.045: INFO: Pod "pod-subpath-test-projected-7qdd": Phase="Running", Reason="", readiness=true. Elapsed: 22.045994454s
Mar 25 17:28:05.049: INFO: Pod "pod-subpath-test-projected-7qdd": Phase="Running", Reason="", readiness=true. Elapsed: 24.049422602s
Mar 25 17:28:07.053: INFO: Pod "pod-subpath-test-projected-7qdd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.053721497s
[1mSTEP[0m: Saw pod success
Mar 25 17:28:07.053: INFO: Pod "pod-subpath-test-projected-7qdd" satisfied condition "success or failure"
Mar 25 17:28:07.056: INFO: Trying to get logs from node conformance-worker2 pod pod-subpath-test-projected-7qdd container test-container-subpath-projected-7qdd: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:28:07.087: INFO: Waiting for pod pod-subpath-test-projected-7qdd to disappear
Mar 25 17:28:07.089: INFO: Pod pod-subpath-test-projected-7qdd no longer exists
[1mSTEP[0m: Deleting pod pod-subpath-test-projected-7qdd
Mar 25 17:28:07.089: INFO: Deleting pod "pod-subpath-test-projected-7qdd" in namespace "subpath-4036"
[AfterEach] [sig-storage] Subpath
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:28:07.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "subpath-4036" for this suite.
Mar 25 17:28:13.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:28:13.156: INFO: namespace subpath-4036 deletion completed in 6.063905462s
[32mâ€¢[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Namespaces [Serial][0m 
  [1mshould ensure that all pods are removed when a namespace is deleted [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:28:13.156: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename namespaces
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a test namespace
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[1mSTEP[0m: Creating a pod in the namespace
[1mSTEP[0m: Waiting for the pod to have running status
[1mSTEP[0m: Deleting the namespace
[1mSTEP[0m: Waiting for the namespace to be removed.
[1mSTEP[0m: Recreating the namespace
[1mSTEP[0m: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:28:37.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "namespaces-3861" for this suite.
Mar 25 17:28:43.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:28:43.321: INFO: namespace namespaces-3861 deletion completed in 6.063235119s
[1mSTEP[0m: Destroying namespace "nsdeletetest-9507" for this suite.
Mar 25 17:28:43.323: INFO: Namespace nsdeletetest-9507 was already deleted
[1mSTEP[0m: Destroying namespace "nsdeletetest-768" for this suite.
Mar 25 17:28:49.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:28:49.384: INFO: namespace nsdeletetest-768 deletion completed in 6.060820819s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] KubeletManagedEtcHosts[0m 
  [1mshould test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:28:49.384: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename e2e-kubelet-etc-hosts
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Setting up the test
[1mSTEP[0m: Creating hostNetwork=false pod
[1mSTEP[0m: Creating hostNetwork=true pod
[1mSTEP[0m: Running the test
[1mSTEP[0m: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar 25 17:29:01.453: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9468 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 17:29:01.453: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 17:29:01.661: INFO: Exec stderr: ""
Mar 25 17:29:01.661: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9468 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 17:29:01.661: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 17:29:01.810: INFO: Exec stderr: ""
Mar 25 17:29:01.810: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9468 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 17:29:01.811: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 17:29:01.983: INFO: Exec stderr: ""
Mar 25 17:29:01.983: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9468 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 17:29:01.983: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 17:29:02.131: INFO: Exec stderr: ""
[1mSTEP[0m: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar 25 17:29:02.131: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9468 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 17:29:02.131: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 17:29:02.298: INFO: Exec stderr: ""
Mar 25 17:29:02.298: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9468 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 17:29:02.298: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 17:29:02.454: INFO: Exec stderr: ""
[1mSTEP[0m: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar 25 17:29:02.454: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9468 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 17:29:02.454: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 17:29:02.623: INFO: Exec stderr: ""
Mar 25 17:29:02.623: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9468 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 17:29:02.623: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 17:29:02.770: INFO: Exec stderr: ""
Mar 25 17:29:02.770: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9468 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 17:29:02.770: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 17:29:02.927: INFO: Exec stderr: ""
Mar 25 17:29:02.927: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9468 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 17:29:02.927: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 17:29:03.092: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:29:03.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-kubelet-etc-hosts-9468" for this suite.
Mar 25 17:29:49.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:29:49.152: INFO: namespace e2e-kubelet-etc-hosts-9468 deletion completed in 46.056377957s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Subpath[0m [90mAtomic writer volumes[0m 
  [1mshould support subpaths with configmap pod [LinuxOnly] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Subpath
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:29:49.152: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename subpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
[1mSTEP[0m: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating pod pod-subpath-test-configmap-qxsl
[1mSTEP[0m: Creating a pod to test atomic-volume-subpath
Mar 25 17:29:49.185: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-qxsl" in namespace "subpath-6024" to be "success or failure"
Mar 25 17:29:49.191: INFO: Pod "pod-subpath-test-configmap-qxsl": Phase="Pending", Reason="", readiness=false. Elapsed: 6.075713ms
Mar 25 17:29:51.195: INFO: Pod "pod-subpath-test-configmap-qxsl": Phase="Running", Reason="", readiness=true. Elapsed: 2.010029334s
Mar 25 17:29:53.199: INFO: Pod "pod-subpath-test-configmap-qxsl": Phase="Running", Reason="", readiness=true. Elapsed: 4.013928343s
Mar 25 17:29:55.202: INFO: Pod "pod-subpath-test-configmap-qxsl": Phase="Running", Reason="", readiness=true. Elapsed: 6.016890447s
Mar 25 17:29:57.206: INFO: Pod "pod-subpath-test-configmap-qxsl": Phase="Running", Reason="", readiness=true. Elapsed: 8.020729907s
Mar 25 17:29:59.209: INFO: Pod "pod-subpath-test-configmap-qxsl": Phase="Running", Reason="", readiness=true. Elapsed: 10.024191716s
Mar 25 17:30:01.213: INFO: Pod "pod-subpath-test-configmap-qxsl": Phase="Running", Reason="", readiness=true. Elapsed: 12.028152136s
Mar 25 17:30:03.216: INFO: Pod "pod-subpath-test-configmap-qxsl": Phase="Running", Reason="", readiness=true. Elapsed: 14.030834345s
Mar 25 17:30:05.220: INFO: Pod "pod-subpath-test-configmap-qxsl": Phase="Running", Reason="", readiness=true. Elapsed: 16.034780735s
Mar 25 17:30:07.224: INFO: Pod "pod-subpath-test-configmap-qxsl": Phase="Running", Reason="", readiness=true. Elapsed: 18.038951079s
Mar 25 17:30:09.227: INFO: Pod "pod-subpath-test-configmap-qxsl": Phase="Running", Reason="", readiness=true. Elapsed: 20.042574223s
Mar 25 17:30:11.232: INFO: Pod "pod-subpath-test-configmap-qxsl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.047118644s
[1mSTEP[0m: Saw pod success
Mar 25 17:30:11.232: INFO: Pod "pod-subpath-test-configmap-qxsl" satisfied condition "success or failure"
Mar 25 17:30:11.236: INFO: Trying to get logs from node conformance-worker2 pod pod-subpath-test-configmap-qxsl container test-container-subpath-configmap-qxsl: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:30:11.253: INFO: Waiting for pod pod-subpath-test-configmap-qxsl to disappear
Mar 25 17:30:11.255: INFO: Pod pod-subpath-test-configmap-qxsl no longer exists
[1mSTEP[0m: Deleting pod pod-subpath-test-configmap-qxsl
Mar 25 17:30:11.255: INFO: Deleting pod "pod-subpath-test-configmap-qxsl" in namespace "subpath-6024"
[AfterEach] [sig-storage] Subpath
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:30:11.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "subpath-6024" for this suite.
Mar 25 17:30:17.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:30:17.342: INFO: namespace subpath-6024 deletion completed in 6.082847262s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-auth] ServiceAccounts[0m 
  [1mshould allow opting out of API token automount  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-auth] ServiceAccounts
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:30:17.343: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename svcaccounts
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: getting the auto-created API token
Mar 25 17:30:17.891: INFO: created pod pod-service-account-defaultsa
Mar 25 17:30:17.891: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar 25 17:30:17.896: INFO: created pod pod-service-account-mountsa
Mar 25 17:30:17.896: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar 25 17:30:17.903: INFO: created pod pod-service-account-nomountsa
Mar 25 17:30:17.903: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar 25 17:30:17.911: INFO: created pod pod-service-account-defaultsa-mountspec
Mar 25 17:30:17.911: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar 25 17:30:17.920: INFO: created pod pod-service-account-mountsa-mountspec
Mar 25 17:30:17.920: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar 25 17:30:17.929: INFO: created pod pod-service-account-nomountsa-mountspec
Mar 25 17:30:17.929: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar 25 17:30:17.933: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar 25 17:30:17.933: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar 25 17:30:17.943: INFO: created pod pod-service-account-mountsa-nomountspec
Mar 25 17:30:17.943: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar 25 17:30:17.959: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar 25 17:30:17.959: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:30:17.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "svcaccounts-5718" for this suite.
Mar 25 17:30:39.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:30:40.070: INFO: namespace svcaccounts-5718 deletion completed in 22.103348876s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould delete RS created by deployment when not orphaning [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:30:40.071: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: create the deployment
[1mSTEP[0m: Wait for the Deployment to create new ReplicaSet
[1mSTEP[0m: delete the deployment
[1mSTEP[0m: wait for all rs to be garbage collected
[1mSTEP[0m: expected 0 rs, got 1 rs
[1mSTEP[0m: expected 0 pods, got 2 pods
[1mSTEP[0m: Gathering metrics
W0325 17:30:41.129374   72333 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 25 17:30:41.129: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:30:41.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "gc-483" for this suite.
Mar 25 17:30:47.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:30:47.205: INFO: namespace gc-483 deletion completed in 6.072105487s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould support retrieving logs from the container over websockets [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:30:47.205: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Mar 25 17:30:47.234: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:30:51.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-6053" for this suite.
Mar 25 17:31:41.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:31:41.362: INFO: namespace pods-6053 deletion completed in 50.078568338s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Runtime[0m [90mblackbox test[0m [0mwhen starting a container that exits[0m 
  [1mshould run with the expected status [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Container Runtime
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:31:41.362: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename container-runtime
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
[1mSTEP[0m: Container 'terminate-cmd-rpa': should get the expected 'Phase'
[1mSTEP[0m: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
[1mSTEP[0m: Container 'terminate-cmd-rpa': should get the expected 'State'
[1mSTEP[0m: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
[1mSTEP[0m: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
[1mSTEP[0m: Container 'terminate-cmd-rpof': should get the expected 'Phase'
[1mSTEP[0m: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
[1mSTEP[0m: Container 'terminate-cmd-rpof': should get the expected 'State'
[1mSTEP[0m: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
[1mSTEP[0m: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
[1mSTEP[0m: Container 'terminate-cmd-rpn': should get the expected 'Phase'
[1mSTEP[0m: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
[1mSTEP[0m: Container 'terminate-cmd-rpn': should get the expected 'State'
[1mSTEP[0m: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:32:08.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-runtime-6753" for this suite.
Mar 25 17:32:14.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:32:14.641: INFO: namespace container-runtime-6753 deletion completed in 6.06060414s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Services[0m 
  [1mshould serve multiport endpoints from pods  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-network] Services
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:32:14.641: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename services
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating service multi-endpoint-test in namespace services-4761
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace services-4761 to expose endpoints map[]
Mar 25 17:32:14.683: INFO: Get endpoints failed (2.301122ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Mar 25 17:32:15.686: INFO: successfully validated that service multi-endpoint-test in namespace services-4761 exposes endpoints map[] (1.005798065s elapsed)
[1mSTEP[0m: Creating pod pod1 in namespace services-4761
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace services-4761 to expose endpoints map[pod1:[100]]
Mar 25 17:32:17.712: INFO: successfully validated that service multi-endpoint-test in namespace services-4761 exposes endpoints map[pod1:[100]] (2.020067208s elapsed)
[1mSTEP[0m: Creating pod pod2 in namespace services-4761
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace services-4761 to expose endpoints map[pod1:[100] pod2:[101]]
Mar 25 17:32:19.748: INFO: successfully validated that service multi-endpoint-test in namespace services-4761 exposes endpoints map[pod1:[100] pod2:[101]] (2.032195743s elapsed)
[1mSTEP[0m: Deleting pod pod1 in namespace services-4761
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace services-4761 to expose endpoints map[pod2:[101]]
Mar 25 17:32:19.761: INFO: successfully validated that service multi-endpoint-test in namespace services-4761 exposes endpoints map[pod2:[101]] (8.186068ms elapsed)
[1mSTEP[0m: Deleting pod pod2 in namespace services-4761
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace services-4761 to expose endpoints map[]
Mar 25 17:32:20.773: INFO: successfully validated that service multi-endpoint-test in namespace services-4761 exposes endpoints map[] (1.007129015s elapsed)
[AfterEach] [sig-network] Services
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:32:20.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "services-4761" for this suite.
Mar 25 17:32:42.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:32:42.867: INFO: namespace services-4761 deletion completed in 22.074268618s
[AfterEach] [sig-network] Services
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[32mâ€¢[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-network] Networking
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:32:42.867: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename pod-network-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Performing setup for networking test in namespace pod-network-test-2976
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
Mar 25 17:32:42.898: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[1mSTEP[0m: Creating test pods
Mar 25 17:33:08.948: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.32.0.2 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2976 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 17:33:08.948: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 17:33:10.149: INFO: Found all expected endpoints: [netserver-0]
Mar 25 17:33:10.152: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.38.0.1 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2976 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 17:33:10.152: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 17:33:11.309: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:33:11.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "pod-network-test-2976" for this suite.
Mar 25 17:33:33.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:33:33.371: INFO: namespace pod-network-test-2976 deletion completed in 22.059873949s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-auth] ServiceAccounts[0m 
  [1mshould mount an API token into pods  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-auth] ServiceAccounts
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:33:33.372: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename svcaccounts
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: getting the auto-created API token
[1mSTEP[0m: reading a file in the container
Mar 25 17:33:37.914: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl exec --namespace=svcaccounts-9597 pod-service-account-c9953f68-4f5e-11e9-91ba-a08cfdecc127 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
[1mSTEP[0m: reading a file in the container
Mar 25 17:33:38.192: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl exec --namespace=svcaccounts-9597 pod-service-account-c9953f68-4f5e-11e9-91ba-a08cfdecc127 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
[1mSTEP[0m: reading a file in the container
Mar 25 17:33:38.421: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl exec --namespace=svcaccounts-9597 pod-service-account-c9953f68-4f5e-11e9-91ba-a08cfdecc127 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:33:38.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "svcaccounts-9597" for this suite.
Mar 25 17:33:44.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:33:44.725: INFO: namespace svcaccounts-9597 deletion completed in 6.07146976s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mShould recreate evicted statefulset [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:33:44.725: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace statefulset-5542
[It] Should recreate evicted statefulset [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Looking for a node to schedule stateful set and pod
[1mSTEP[0m: Creating pod with conflicting port in namespace statefulset-5542
[1mSTEP[0m: Creating statefulset with conflicting port in namespace statefulset-5542
[1mSTEP[0m: Waiting until pod test-pod will start running in namespace statefulset-5542
[1mSTEP[0m: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-5542
Mar 25 17:33:46.799: INFO: Observed stateful pod in namespace: statefulset-5542, name: ss-0, uid: d01a054e-4f5e-11e9-8304-02427cbbc9a0, status phase: Pending. Waiting for statefulset controller to delete.
Mar 25 17:33:48.519: INFO: Observed stateful pod in namespace: statefulset-5542, name: ss-0, uid: d01a054e-4f5e-11e9-8304-02427cbbc9a0, status phase: Failed. Waiting for statefulset controller to delete.
Mar 25 17:33:48.525: INFO: Observed stateful pod in namespace: statefulset-5542, name: ss-0, uid: d01a054e-4f5e-11e9-8304-02427cbbc9a0, status phase: Failed. Waiting for statefulset controller to delete.
Mar 25 17:33:48.529: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-5542
[1mSTEP[0m: Removing pod with conflicting port in namespace statefulset-5542
[1mSTEP[0m: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-5542 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 25 17:33:50.546: INFO: Deleting all statefulset in ns statefulset-5542
Mar 25 17:33:50.550: INFO: Scaling statefulset ss to 0
Mar 25 17:34:00.563: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 17:34:00.566: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:34:00.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "statefulset-5542" for this suite.
Mar 25 17:34:06.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:34:06.644: INFO: namespace statefulset-5542 deletion completed in 6.067366174s
[32mâ€¢[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Subpath[0m [90mAtomic writer volumes[0m 
  [1mshould support subpaths with downward pod [LinuxOnly] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Subpath
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:34:06.644: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename subpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
[1mSTEP[0m: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating pod pod-subpath-test-downwardapi-qq6h
[1mSTEP[0m: Creating a pod to test atomic-volume-subpath
Mar 25 17:34:06.680: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-qq6h" in namespace "subpath-6200" to be "success or failure"
Mar 25 17:34:06.682: INFO: Pod "pod-subpath-test-downwardapi-qq6h": Phase="Pending", Reason="", readiness=false. Elapsed: 1.967204ms
Mar 25 17:34:08.685: INFO: Pod "pod-subpath-test-downwardapi-qq6h": Phase="Running", Reason="", readiness=true. Elapsed: 2.005048739s
Mar 25 17:34:10.689: INFO: Pod "pod-subpath-test-downwardapi-qq6h": Phase="Running", Reason="", readiness=true. Elapsed: 4.008594455s
Mar 25 17:34:12.691: INFO: Pod "pod-subpath-test-downwardapi-qq6h": Phase="Running", Reason="", readiness=true. Elapsed: 6.011056057s
Mar 25 17:34:14.695: INFO: Pod "pod-subpath-test-downwardapi-qq6h": Phase="Running", Reason="", readiness=true. Elapsed: 8.014865429s
Mar 25 17:34:16.699: INFO: Pod "pod-subpath-test-downwardapi-qq6h": Phase="Running", Reason="", readiness=true. Elapsed: 10.018789854s
Mar 25 17:34:18.703: INFO: Pod "pod-subpath-test-downwardapi-qq6h": Phase="Running", Reason="", readiness=true. Elapsed: 12.022571652s
Mar 25 17:34:20.706: INFO: Pod "pod-subpath-test-downwardapi-qq6h": Phase="Running", Reason="", readiness=true. Elapsed: 14.025793039s
Mar 25 17:34:22.710: INFO: Pod "pod-subpath-test-downwardapi-qq6h": Phase="Running", Reason="", readiness=true. Elapsed: 16.029566233s
Mar 25 17:34:24.713: INFO: Pod "pod-subpath-test-downwardapi-qq6h": Phase="Running", Reason="", readiness=true. Elapsed: 18.032426539s
Mar 25 17:34:26.716: INFO: Pod "pod-subpath-test-downwardapi-qq6h": Phase="Running", Reason="", readiness=true. Elapsed: 20.036143751s
Mar 25 17:34:28.719: INFO: Pod "pod-subpath-test-downwardapi-qq6h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.038653968s
[1mSTEP[0m: Saw pod success
Mar 25 17:34:28.719: INFO: Pod "pod-subpath-test-downwardapi-qq6h" satisfied condition "success or failure"
Mar 25 17:34:28.721: INFO: Trying to get logs from node conformance-worker2 pod pod-subpath-test-downwardapi-qq6h container test-container-subpath-downwardapi-qq6h: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:34:28.734: INFO: Waiting for pod pod-subpath-test-downwardapi-qq6h to disappear
Mar 25 17:34:28.739: INFO: Pod pod-subpath-test-downwardapi-qq6h no longer exists
[1mSTEP[0m: Deleting pod pod-subpath-test-downwardapi-qq6h
Mar 25 17:34:28.739: INFO: Deleting pod "pod-subpath-test-downwardapi-qq6h" in namespace "subpath-6200"
[AfterEach] [sig-storage] Subpath
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:34:28.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "subpath-6200" for this suite.
Mar 25 17:34:34.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:34:34.816: INFO: namespace subpath-6200 deletion completed in 6.070588078s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mbinary data should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:34:34.816: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name configmap-test-upd-edef9163-4f5e-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Waiting for pod with text data
[1mSTEP[0m: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:34:36.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-3918" for this suite.
Mar 25 17:34:58.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:34:58.991: INFO: namespace configmap-3918 deletion completed in 22.066072274s
[32mâ€¢[0m
[90m------------------------------[0m
[0m[k8s.io] Variable Expansion[0m 
  [1mshould allow substituting values in a container's args [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Variable Expansion
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:34:58.991: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename var-expansion
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test substitution in container's args
Mar 25 17:34:59.023: INFO: Waiting up to 5m0s for pod "var-expansion-fc511268-4f5e-11e9-91ba-a08cfdecc127" in namespace "var-expansion-7649" to be "success or failure"
Mar 25 17:34:59.025: INFO: Pod "var-expansion-fc511268-4f5e-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.513053ms
Mar 25 17:35:01.028: INFO: Pod "var-expansion-fc511268-4f5e-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00493307s
[1mSTEP[0m: Saw pod success
Mar 25 17:35:01.028: INFO: Pod "var-expansion-fc511268-4f5e-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:35:01.031: INFO: Trying to get logs from node conformance-worker2 pod var-expansion-fc511268-4f5e-11e9-91ba-a08cfdecc127 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:35:01.046: INFO: Waiting for pod var-expansion-fc511268-4f5e-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:35:01.048: INFO: Pod var-expansion-fc511268-4f5e-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:35:01.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "var-expansion-7649" for this suite.
Mar 25 17:35:07.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:35:07.122: INFO: namespace var-expansion-7649 deletion completed in 6.07151129s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable in multiple volumes in the same pod [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:35:07.122: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name configmap-test-volume-012a0245-4f5f-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 25 17:35:07.160: INFO: Waiting up to 5m0s for pod "pod-configmaps-012a55dd-4f5f-11e9-91ba-a08cfdecc127" in namespace "configmap-8183" to be "success or failure"
Mar 25 17:35:07.161: INFO: Pod "pod-configmaps-012a55dd-4f5f-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.567508ms
Mar 25 17:35:09.166: INFO: Pod "pod-configmaps-012a55dd-4f5f-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005802179s
Mar 25 17:35:11.169: INFO: Pod "pod-configmaps-012a55dd-4f5f-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009344996s
[1mSTEP[0m: Saw pod success
Mar 25 17:35:11.169: INFO: Pod "pod-configmaps-012a55dd-4f5f-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:35:11.172: INFO: Trying to get logs from node conformance-worker pod pod-configmaps-012a55dd-4f5f-11e9-91ba-a08cfdecc127 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:35:11.191: INFO: Waiting for pod pod-configmaps-012a55dd-4f5f-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:35:11.193: INFO: Pod pod-configmaps-012a55dd-4f5f-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:35:11.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-8183" for this suite.
Mar 25 17:35:17.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:35:17.275: INFO: namespace configmap-8183 deletion completed in 6.078497994s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Subpath[0m [90mAtomic writer volumes[0m 
  [1mshould support subpaths with secret pod [LinuxOnly] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Subpath
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:35:17.276: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename subpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
[1mSTEP[0m: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating pod pod-subpath-test-secret-xsrv
[1mSTEP[0m: Creating a pod to test atomic-volume-subpath
Mar 25 17:35:17.314: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-xsrv" in namespace "subpath-2886" to be "success or failure"
Mar 25 17:35:17.315: INFO: Pod "pod-subpath-test-secret-xsrv": Phase="Pending", Reason="", readiness=false. Elapsed: 1.566372ms
Mar 25 17:35:19.319: INFO: Pod "pod-subpath-test-secret-xsrv": Phase="Running", Reason="", readiness=true. Elapsed: 2.005660018s
Mar 25 17:35:21.324: INFO: Pod "pod-subpath-test-secret-xsrv": Phase="Running", Reason="", readiness=true. Elapsed: 4.010059616s
Mar 25 17:35:23.327: INFO: Pod "pod-subpath-test-secret-xsrv": Phase="Running", Reason="", readiness=true. Elapsed: 6.013280814s
Mar 25 17:35:25.330: INFO: Pod "pod-subpath-test-secret-xsrv": Phase="Running", Reason="", readiness=true. Elapsed: 8.016948017s
Mar 25 17:35:27.336: INFO: Pod "pod-subpath-test-secret-xsrv": Phase="Running", Reason="", readiness=true. Elapsed: 10.022282036s
Mar 25 17:35:29.339: INFO: Pod "pod-subpath-test-secret-xsrv": Phase="Running", Reason="", readiness=true. Elapsed: 12.025465964s
Mar 25 17:35:31.343: INFO: Pod "pod-subpath-test-secret-xsrv": Phase="Running", Reason="", readiness=true. Elapsed: 14.029203533s
Mar 25 17:35:33.346: INFO: Pod "pod-subpath-test-secret-xsrv": Phase="Running", Reason="", readiness=true. Elapsed: 16.032429827s
Mar 25 17:35:35.350: INFO: Pod "pod-subpath-test-secret-xsrv": Phase="Running", Reason="", readiness=true. Elapsed: 18.036383214s
Mar 25 17:35:37.354: INFO: Pod "pod-subpath-test-secret-xsrv": Phase="Running", Reason="", readiness=true. Elapsed: 20.040584331s
Mar 25 17:35:39.358: INFO: Pod "pod-subpath-test-secret-xsrv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.044387397s
[1mSTEP[0m: Saw pod success
Mar 25 17:35:39.358: INFO: Pod "pod-subpath-test-secret-xsrv" satisfied condition "success or failure"
Mar 25 17:35:39.361: INFO: Trying to get logs from node conformance-worker2 pod pod-subpath-test-secret-xsrv container test-container-subpath-secret-xsrv: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:35:39.385: INFO: Waiting for pod pod-subpath-test-secret-xsrv to disappear
Mar 25 17:35:39.389: INFO: Pod pod-subpath-test-secret-xsrv no longer exists
[1mSTEP[0m: Deleting pod pod-subpath-test-secret-xsrv
Mar 25 17:35:39.389: INFO: Deleting pod "pod-subpath-test-secret-xsrv" in namespace "subpath-2886"
[AfterEach] [sig-storage] Subpath
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:35:39.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "subpath-2886" for this suite.
Mar 25 17:35:45.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:35:45.454: INFO: namespace subpath-2886 deletion completed in 6.061567971s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide container's memory limit [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:35:45.455: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 17:35:45.492: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1803a538-4f5f-11e9-91ba-a08cfdecc127" in namespace "projected-6274" to be "success or failure"
Mar 25 17:35:45.495: INFO: Pod "downwardapi-volume-1803a538-4f5f-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.49913ms
Mar 25 17:35:47.500: INFO: Pod "downwardapi-volume-1803a538-4f5f-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00782171s
[1mSTEP[0m: Saw pod success
Mar 25 17:35:47.500: INFO: Pod "downwardapi-volume-1803a538-4f5f-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:35:47.503: INFO: Trying to get logs from node conformance-worker pod downwardapi-volume-1803a538-4f5f-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:35:47.517: INFO: Waiting for pod downwardapi-volume-1803a538-4f5f-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:35:47.520: INFO: Pod downwardapi-volume-1803a538-4f5f-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:35:47.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-6274" for this suite.
Mar 25 17:35:53.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:35:53.592: INFO: namespace projected-6274 deletion completed in 6.069890995s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould update annotations on modification [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:35:53.592: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating the pod
Mar 25 17:35:56.151: INFO: Successfully updated pod "annotationupdate1cdc3405-4f5f-11e9-91ba-a08cfdecc127"
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:35:58.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-3554" for this suite.
Mar 25 17:36:20.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:36:20.252: INFO: namespace projected-3554 deletion completed in 22.080475191s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:36:20.252: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test emptydir 0666 on tmpfs
Mar 25 17:36:20.288: INFO: Waiting up to 5m0s for pod "pod-2cc0cdb2-4f5f-11e9-91ba-a08cfdecc127" in namespace "emptydir-910" to be "success or failure"
Mar 25 17:36:20.294: INFO: Pod "pod-2cc0cdb2-4f5f-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 6.444081ms
Mar 25 17:36:22.297: INFO: Pod "pod-2cc0cdb2-4f5f-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009506444s
Mar 25 17:36:24.301: INFO: Pod "pod-2cc0cdb2-4f5f-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012889587s
[1mSTEP[0m: Saw pod success
Mar 25 17:36:24.301: INFO: Pod "pod-2cc0cdb2-4f5f-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:36:24.303: INFO: Trying to get logs from node conformance-worker pod pod-2cc0cdb2-4f5f-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:36:24.320: INFO: Waiting for pod pod-2cc0cdb2-4f5f-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:36:24.322: INFO: Pod pod-2cc0cdb2-4f5f-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:36:24.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-910" for this suite.
Mar 25 17:36:30.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:36:30.393: INFO: namespace emptydir-910 deletion completed in 6.068968595s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Lifecycle Hook[0m [90mwhen create a pod with lifecycle hook[0m 
  [1mshould execute prestop exec hook properly [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:36:30.393: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename container-lifecycle-hook
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
[1mSTEP[0m: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: create the pod with lifecycle hook
[1mSTEP[0m: delete the pod with lifecycle hook
Mar 25 17:36:38.453: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 17:36:38.456: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 17:36:40.456: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 17:36:40.460: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 17:36:42.456: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 17:36:42.459: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 17:36:44.456: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 17:36:44.460: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 17:36:46.456: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 17:36:46.460: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 17:36:48.456: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 17:36:48.459: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 17:36:50.456: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 17:36:50.460: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 17:36:52.456: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 17:36:52.460: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 17:36:54.456: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 17:36:54.459: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 17:36:56.456: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 17:36:56.460: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 17:36:58.456: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 17:36:58.460: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 25 17:37:00.456: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 25 17:37:00.459: INFO: Pod pod-with-prestop-exec-hook no longer exists
[1mSTEP[0m: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:37:00.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-lifecycle-hook-376" for this suite.
Mar 25 17:37:22.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:37:22.539: INFO: namespace container-lifecycle-hook-376 deletion completed in 22.069456227s
[32mâ€¢[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:37:22.539: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating secret with name s-test-opt-del-51e10c03-4f5f-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating secret with name s-test-opt-upd-51e10c3e-4f5f-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting secret s-test-opt-del-51e10c03-4f5f-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Updating secret s-test-opt-upd-51e10c3e-4f5f-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating secret with name s-test-opt-create-51e10c51-4f5f-11e9-91ba-a08cfdecc127
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:37:30.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "secrets-8977" for this suite.
Mar 25 17:37:52.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:37:52.744: INFO: namespace secrets-8977 deletion completed in 22.071162232s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould support remote command execution over websockets [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:37:52.745: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Mar 25 17:37:52.779: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:37:54.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-5822" for this suite.
Mar 25 17:38:38.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:38:39.031: INFO: namespace pods-5822 deletion completed in 44.075602175s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] InitContainer [NodeConformance][0m 
  [1mshould invoke init containers on a RestartAlways pod [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:38:39.031: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename init-container
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating the pod
Mar 25 17:38:39.054: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:38:51.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "init-container-748" for this suite.
Mar 25 17:39:13.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:39:13.809: INFO: namespace init-container-748 deletion completed in 22.074476273s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] ConfigMap[0m 
  [1mshould be consumable via the environment [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-node] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:39:13.809: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap configmap-9992/configmap-test-94332651-4f5f-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 25 17:39:13.843: INFO: Waiting up to 5m0s for pod "pod-configmaps-94337858-4f5f-11e9-91ba-a08cfdecc127" in namespace "configmap-9992" to be "success or failure"
Mar 25 17:39:13.847: INFO: Pod "pod-configmaps-94337858-4f5f-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.850871ms
Mar 25 17:39:15.850: INFO: Pod "pod-configmaps-94337858-4f5f-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007235009s
Mar 25 17:39:17.854: INFO: Pod "pod-configmaps-94337858-4f5f-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011167137s
[1mSTEP[0m: Saw pod success
Mar 25 17:39:17.854: INFO: Pod "pod-configmaps-94337858-4f5f-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:39:17.857: INFO: Trying to get logs from node conformance-worker pod pod-configmaps-94337858-4f5f-11e9-91ba-a08cfdecc127 container env-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:39:17.876: INFO: Waiting for pod pod-configmaps-94337858-4f5f-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:39:17.878: INFO: Pod pod-configmaps-94337858-4f5f-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-node] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:39:17.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-9992" for this suite.
Mar 25 17:39:23.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:39:23.956: INFO: namespace configmap-9992 deletion completed in 6.075580333s
[32mâ€¢[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould update labels on modification [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:39:23.956: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating the pod
Mar 25 17:39:26.515: INFO: Successfully updated pod "labelsupdate9a3f735f-4f5f-11e9-91ba-a08cfdecc127"
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:39:28.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-1044" for this suite.
Mar 25 17:39:50.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:39:50.592: INFO: namespace downward-api-1044 deletion completed in 22.058098048s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:39:50.592: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test emptydir 0777 on node default medium
Mar 25 17:39:50.644: INFO: Waiting up to 5m0s for pod "pod-aa22da67-4f5f-11e9-91ba-a08cfdecc127" in namespace "emptydir-9024" to be "success or failure"
Mar 25 17:39:50.650: INFO: Pod "pod-aa22da67-4f5f-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 6.370829ms
Mar 25 17:39:52.654: INFO: Pod "pod-aa22da67-4f5f-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010394257s
Mar 25 17:39:54.658: INFO: Pod "pod-aa22da67-4f5f-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013949002s
[1mSTEP[0m: Saw pod success
Mar 25 17:39:54.658: INFO: Pod "pod-aa22da67-4f5f-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:39:54.661: INFO: Trying to get logs from node conformance-worker pod pod-aa22da67-4f5f-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:39:54.679: INFO: Waiting for pod pod-aa22da67-4f5f-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:39:54.681: INFO: Pod pod-aa22da67-4f5f-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:39:54.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-9024" for this suite.
Mar 25 17:40:00.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:40:00.757: INFO: namespace emptydir-9024 deletion completed in 6.073243398s
[32mâ€¢[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's cpu request [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:40:00.757: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 17:40:00.790: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b02eeef3-4f5f-11e9-91ba-a08cfdecc127" in namespace "downward-api-182" to be "success or failure"
Mar 25 17:40:00.793: INFO: Pod "downwardapi-volume-b02eeef3-4f5f-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.471684ms
Mar 25 17:40:02.797: INFO: Pod "downwardapi-volume-b02eeef3-4f5f-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006655282s
[1mSTEP[0m: Saw pod success
Mar 25 17:40:02.797: INFO: Pod "downwardapi-volume-b02eeef3-4f5f-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:40:02.800: INFO: Trying to get logs from node conformance-worker2 pod downwardapi-volume-b02eeef3-4f5f-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:40:02.816: INFO: Waiting for pod downwardapi-volume-b02eeef3-4f5f-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:40:02.818: INFO: Pod downwardapi-volume-b02eeef3-4f5f-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:40:02.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-182" for this suite.
Mar 25 17:40:08.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:40:08.889: INFO: namespace downward-api-182 deletion completed in 6.068924737s
[32mâ€¢[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] InitContainer [NodeConformance][0m 
  [1mshould invoke init containers on a RestartNever pod [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:40:08.889: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename init-container
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating the pod
Mar 25 17:40:08.916: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:40:12.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "init-container-6676" for this suite.
Mar 25 17:40:18.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:40:18.884: INFO: namespace init-container-6676 deletion completed in 6.067995969s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicationController[0m 
  [1mshould serve a basic image on each replica with a public image  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] ReplicationController
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:40:18.884: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename replication-controller
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating replication controller my-hostname-basic-bafd11e0-4f5f-11e9-91ba-a08cfdecc127
Mar 25 17:40:18.918: INFO: Pod name my-hostname-basic-bafd11e0-4f5f-11e9-91ba-a08cfdecc127: Found 0 pods out of 1
Mar 25 17:40:23.922: INFO: Pod name my-hostname-basic-bafd11e0-4f5f-11e9-91ba-a08cfdecc127: Found 1 pods out of 1
Mar 25 17:40:23.922: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-bafd11e0-4f5f-11e9-91ba-a08cfdecc127" are running
Mar 25 17:40:23.925: INFO: Pod "my-hostname-basic-bafd11e0-4f5f-11e9-91ba-a08cfdecc127-vqwvq" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-25 17:40:18 -0700 PDT Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-25 17:40:22 -0700 PDT Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-25 17:40:22 -0700 PDT Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-25 17:40:18 -0700 PDT Reason: Message:}])
Mar 25 17:40:23.925: INFO: Trying to dial the pod
Mar 25 17:40:28.935: INFO: Controller my-hostname-basic-bafd11e0-4f5f-11e9-91ba-a08cfdecc127: Got expected result from replica 1 [my-hostname-basic-bafd11e0-4f5f-11e9-91ba-a08cfdecc127-vqwvq]: "my-hostname-basic-bafd11e0-4f5f-11e9-91ba-a08cfdecc127-vqwvq", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:40:28.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "replication-controller-6358" for this suite.
Mar 25 17:40:34.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:40:35.010: INFO: namespace replication-controller-6358 deletion completed in 6.071793471s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide podname only [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:40:35.011: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 17:40:35.047: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c49a52e7-4f5f-11e9-91ba-a08cfdecc127" in namespace "downward-api-3475" to be "success or failure"
Mar 25 17:40:35.051: INFO: Pod "downwardapi-volume-c49a52e7-4f5f-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.594818ms
Mar 25 17:40:37.054: INFO: Pod "downwardapi-volume-c49a52e7-4f5f-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007039882s
[1mSTEP[0m: Saw pod success
Mar 25 17:40:37.054: INFO: Pod "downwardapi-volume-c49a52e7-4f5f-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:40:37.057: INFO: Trying to get logs from node conformance-worker pod downwardapi-volume-c49a52e7-4f5f-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:40:37.074: INFO: Waiting for pod downwardapi-volume-c49a52e7-4f5f-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:40:37.077: INFO: Pod downwardapi-volume-c49a52e7-4f5f-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:40:37.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-3475" for this suite.
Mar 25 17:40:43.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:40:43.164: INFO: namespace downward-api-3475 deletion completed in 6.085022435s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:40:43.164: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test emptydir 0777 on node default medium
Mar 25 17:40:43.195: INFO: Waiting up to 5m0s for pod "pod-c9755ee3-4f5f-11e9-91ba-a08cfdecc127" in namespace "emptydir-3317" to be "success or failure"
Mar 25 17:40:43.197: INFO: Pod "pod-c9755ee3-4f5f-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.976589ms
Mar 25 17:40:45.200: INFO: Pod "pod-c9755ee3-4f5f-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005075801s
[1mSTEP[0m: Saw pod success
Mar 25 17:40:45.200: INFO: Pod "pod-c9755ee3-4f5f-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:40:45.203: INFO: Trying to get logs from node conformance-worker2 pod pod-c9755ee3-4f5f-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:40:45.219: INFO: Waiting for pod pod-c9755ee3-4f5f-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:40:45.221: INFO: Pod pod-c9755ee3-4f5f-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:40:45.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-3317" for this suite.
Mar 25 17:40:51.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:40:51.291: INFO: namespace emptydir-3317 deletion completed in 6.067246233s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould delete pods created by rc when not orphaning [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:40:51.291: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: create the rc
[1mSTEP[0m: delete the rc
[1mSTEP[0m: wait for all pods to be garbage collected
[1mSTEP[0m: Gathering metrics
W0325 17:41:01.337471   72333 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 25 17:41:01.337: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:41:01.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "gc-2613" for this suite.
Mar 25 17:41:07.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:41:07.418: INFO: namespace gc-2613 deletion completed in 6.077296023s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mvolume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:41:07.418: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test emptydir volume type on tmpfs
Mar 25 17:41:07.448: INFO: Waiting up to 5m0s for pod "pod-d7ea1cf6-4f5f-11e9-91ba-a08cfdecc127" in namespace "emptydir-5558" to be "success or failure"
Mar 25 17:41:07.452: INFO: Pod "pod-d7ea1cf6-4f5f-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.947346ms
Mar 25 17:41:09.456: INFO: Pod "pod-d7ea1cf6-4f5f-11e9-91ba-a08cfdecc127": Phase="Running", Reason="", readiness=true. Elapsed: 2.007700334s
Mar 25 17:41:11.460: INFO: Pod "pod-d7ea1cf6-4f5f-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011591435s
[1mSTEP[0m: Saw pod success
Mar 25 17:41:11.460: INFO: Pod "pod-d7ea1cf6-4f5f-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:41:11.463: INFO: Trying to get logs from node conformance-worker2 pod pod-d7ea1cf6-4f5f-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:41:11.480: INFO: Waiting for pod pod-d7ea1cf6-4f5f-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:41:11.482: INFO: Pod pod-d7ea1cf6-4f5f-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:41:11.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-5558" for this suite.
Mar 25 17:41:17.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:41:17.562: INFO: namespace emptydir-5558 deletion completed in 6.077168502s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir wrapper volumes[0m 
  [1mshould not cause race condition when used for configmaps [Serial] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:41:17.562: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename emptydir-wrapper
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating 50 configmaps
[1mSTEP[0m: Creating RC which spawns configmap-volume pods
Mar 25 17:41:17.822: INFO: Pod name wrapped-volume-race-de05407a-4f5f-11e9-91ba-a08cfdecc127: Found 5 pods out of 5
[1mSTEP[0m: Ensuring each pod is running
[1mSTEP[0m: deleting ReplicationController wrapped-volume-race-de05407a-4f5f-11e9-91ba-a08cfdecc127 in namespace emptydir-wrapper-9934, will wait for the garbage collector to delete the pods
Mar 25 17:41:33.944: INFO: Deleting ReplicationController wrapped-volume-race-de05407a-4f5f-11e9-91ba-a08cfdecc127 took: 7.327427ms
Mar 25 17:41:34.244: INFO: Terminating ReplicationController wrapped-volume-race-de05407a-4f5f-11e9-91ba-a08cfdecc127 pods took: 300.211732ms
[1mSTEP[0m: Creating RC which spawns configmap-volume pods
Mar 25 17:42:10.355: INFO: Pod name wrapped-volume-race-fd6807d3-4f5f-11e9-91ba-a08cfdecc127: Found 0 pods out of 5
Mar 25 17:42:15.361: INFO: Pod name wrapped-volume-race-fd6807d3-4f5f-11e9-91ba-a08cfdecc127: Found 5 pods out of 5
[1mSTEP[0m: Ensuring each pod is running
[1mSTEP[0m: deleting ReplicationController wrapped-volume-race-fd6807d3-4f5f-11e9-91ba-a08cfdecc127 in namespace emptydir-wrapper-9934, will wait for the garbage collector to delete the pods
Mar 25 17:42:25.444: INFO: Deleting ReplicationController wrapped-volume-race-fd6807d3-4f5f-11e9-91ba-a08cfdecc127 took: 5.919891ms
Mar 25 17:42:25.744: INFO: Terminating ReplicationController wrapped-volume-race-fd6807d3-4f5f-11e9-91ba-a08cfdecc127 pods took: 300.17348ms
[1mSTEP[0m: Creating RC which spawns configmap-volume pods
Mar 25 17:43:02.058: INFO: Pod name wrapped-volume-race-1c38b86b-4f60-11e9-91ba-a08cfdecc127: Found 0 pods out of 5
Mar 25 17:43:07.065: INFO: Pod name wrapped-volume-race-1c38b86b-4f60-11e9-91ba-a08cfdecc127: Found 5 pods out of 5
[1mSTEP[0m: Ensuring each pod is running
[1mSTEP[0m: deleting ReplicationController wrapped-volume-race-1c38b86b-4f60-11e9-91ba-a08cfdecc127 in namespace emptydir-wrapper-9934, will wait for the garbage collector to delete the pods
Mar 25 17:43:17.151: INFO: Deleting ReplicationController wrapped-volume-race-1c38b86b-4f60-11e9-91ba-a08cfdecc127 took: 7.690134ms
Mar 25 17:43:17.451: INFO: Terminating ReplicationController wrapped-volume-race-1c38b86b-4f60-11e9-91ba-a08cfdecc127 pods took: 300.254072ms
[1mSTEP[0m: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:43:59.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-wrapper-9934" for this suite.
Mar 25 17:44:05.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:44:05.186: INFO: namespace emptydir-wrapper-9934 deletion completed in 6.072786128s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould contain environment variables for services [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:44:05.187: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Mar 25 17:44:07.236: INFO: Waiting up to 5m0s for pod "client-envvars-431396f2-4f60-11e9-91ba-a08cfdecc127" in namespace "pods-9935" to be "success or failure"
Mar 25 17:44:07.241: INFO: Pod "client-envvars-431396f2-4f60-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 4.724134ms
Mar 25 17:44:09.245: INFO: Pod "client-envvars-431396f2-4f60-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008798466s
Mar 25 17:44:11.249: INFO: Pod "client-envvars-431396f2-4f60-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012666988s
[1mSTEP[0m: Saw pod success
Mar 25 17:44:11.249: INFO: Pod "client-envvars-431396f2-4f60-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:44:11.252: INFO: Trying to get logs from node conformance-worker pod client-envvars-431396f2-4f60-11e9-91ba-a08cfdecc127 container env3cont: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:44:11.276: INFO: Waiting for pod client-envvars-431396f2-4f60-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:44:11.279: INFO: Pod client-envvars-431396f2-4f60-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:44:11.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-9935" for this suite.
Mar 25 17:45:09.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:45:09.357: INFO: namespace pods-9935 deletion completed in 58.075324476s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould update annotations on modification [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:45:09.357: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating the pod
Mar 25 17:45:13.919: INFO: Successfully updated pod "annotationupdate681f865a-4f60-11e9-91ba-a08cfdecc127"
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:45:15.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-5105" for this suite.
Mar 25 17:45:37.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:45:38.019: INFO: namespace downward-api-5105 deletion completed in 22.078581438s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1mshould be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected secret
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:45:38.019: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-7935bb42-4f60-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 25 17:45:38.058: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-79360914-4f60-11e9-91ba-a08cfdecc127" in namespace "projected-1344" to be "success or failure"
Mar 25 17:45:38.062: INFO: Pod "pod-projected-secrets-79360914-4f60-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.380347ms
Mar 25 17:45:40.064: INFO: Pod "pod-projected-secrets-79360914-4f60-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00615034s
Mar 25 17:45:42.068: INFO: Pod "pod-projected-secrets-79360914-4f60-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010097205s
[1mSTEP[0m: Saw pod success
Mar 25 17:45:42.068: INFO: Pod "pod-projected-secrets-79360914-4f60-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:45:42.072: INFO: Trying to get logs from node conformance-worker pod pod-projected-secrets-79360914-4f60-11e9-91ba-a08cfdecc127 container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:45:42.088: INFO: Waiting for pod pod-projected-secrets-79360914-4f60-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:45:42.090: INFO: Pod pod-projected-secrets-79360914-4f60-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected secret
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:45:42.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-1344" for this suite.
Mar 25 17:45:48.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:45:48.166: INFO: namespace projected-1344 deletion completed in 6.073351289s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide podname only [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:45:48.166: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 17:45:48.198: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7f4137eb-4f60-11e9-91ba-a08cfdecc127" in namespace "projected-1867" to be "success or failure"
Mar 25 17:45:48.200: INFO: Pod "downwardapi-volume-7f4137eb-4f60-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.854466ms
Mar 25 17:45:50.204: INFO: Pod "downwardapi-volume-7f4137eb-4f60-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005898562s
[1mSTEP[0m: Saw pod success
Mar 25 17:45:50.204: INFO: Pod "downwardapi-volume-7f4137eb-4f60-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:45:50.206: INFO: Trying to get logs from node conformance-worker2 pod downwardapi-volume-7f4137eb-4f60-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:45:50.221: INFO: Waiting for pod downwardapi-volume-7f4137eb-4f60-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:45:50.223: INFO: Pod downwardapi-volume-7f4137eb-4f60-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:45:50.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-1867" for this suite.
Mar 25 17:45:56.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:45:56.297: INFO: namespace projected-1867 deletion completed in 6.072190205s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Namespaces [Serial][0m 
  [1mshould ensure that all services are removed when a namespace is deleted [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:45:56.297: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename namespaces
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a test namespace
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[1mSTEP[0m: Creating a service in the namespace
[1mSTEP[0m: Deleting the namespace
[1mSTEP[0m: Waiting for the namespace to be removed.
[1mSTEP[0m: Recreating the namespace
[1mSTEP[0m: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:46:02.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "namespaces-4643" for this suite.
Mar 25 17:46:08.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:46:08.477: INFO: namespace namespaces-4643 deletion completed in 6.077952773s
[1mSTEP[0m: Destroying namespace "nsdeletetest-5797" for this suite.
Mar 25 17:46:08.479: INFO: Namespace nsdeletetest-5797 was already deleted
[1mSTEP[0m: Destroying namespace "nsdeletetest-4505" for this suite.
Mar 25 17:46:14.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:46:14.569: INFO: namespace nsdeletetest-4505 deletion completed in 6.089431011s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-scheduling] SchedulerPredicates [Serial][0m 
  [1mvalidates that NodeSelector is respected if matching  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:46:14.569: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename sched-pred
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 25 17:46:14.594: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 25 17:46:14.597: INFO: Waiting for terminating namespaces to be deleted...
Mar 25 17:46:14.599: INFO: 
Logging pods the kubelet thinks is on node conformance-worker before test
Mar 25 17:46:14.602: INFO: kube-proxy-94s4s from kube-system started at 2019-03-25 17:14:28 -0700 PDT (1 container statuses recorded)
Mar 25 17:46:14.602: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 25 17:46:14.602: INFO: weave-net-dswmc from kube-system started at 2019-03-25 17:14:28 -0700 PDT (2 container statuses recorded)
Mar 25 17:46:14.602: INFO: 	Container weave ready: true, restart count 1
Mar 25 17:46:14.602: INFO: 	Container weave-npc ready: true, restart count 0
Mar 25 17:46:14.602: INFO: 
Logging pods the kubelet thinks is on node conformance-worker2 before test
Mar 25 17:46:14.604: INFO: kube-proxy-ld748 from kube-system started at 2019-03-25 17:14:41 -0700 PDT (1 container statuses recorded)
Mar 25 17:46:14.604: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 25 17:46:14.604: INFO: weave-net-grwls from kube-system started at 2019-03-25 17:14:41 -0700 PDT (2 container statuses recorded)
Mar 25 17:46:14.604: INFO: 	Container weave ready: true, restart count 1
Mar 25 17:46:14.604: INFO: 	Container weave-npc ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Trying to launch a pod without a label to get a node which can launch it.
[1mSTEP[0m: Explicitly delete pod here to free the resource it takes.
[1mSTEP[0m: Trying to apply a random label on the found node.
[1mSTEP[0m: verifying the node has the label kubernetes.io/e2e-90330cc1-4f60-11e9-91ba-a08cfdecc127 42
[1mSTEP[0m: Trying to relaunch the pod, now with labels.
[1mSTEP[0m: removing the label kubernetes.io/e2e-90330cc1-4f60-11e9-91ba-a08cfdecc127 off the node conformance-worker
[1mSTEP[0m: verifying the node doesn't have the label kubernetes.io/e2e-90330cc1-4f60-11e9-91ba-a08cfdecc127
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:46:20.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "sched-pred-77" for this suite.
Mar 25 17:46:48.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:46:48.732: INFO: namespace sched-pred-77 deletion completed in 28.07412797s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected combined[0m 
  [1mshould project all components that make up the projection API [Projection][NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected combined
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:46:48.733: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name configmap-projected-all-test-volume-a35c089a-4f60-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating secret with name secret-projected-all-test-volume-a35c088a-4f60-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test Check all projections for projected volume plugin
Mar 25 17:46:48.797: INFO: Waiting up to 5m0s for pod "projected-volume-a35c0810-4f60-11e9-91ba-a08cfdecc127" in namespace "projected-4910" to be "success or failure"
Mar 25 17:46:48.803: INFO: Pod "projected-volume-a35c0810-4f60-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 5.448178ms
Mar 25 17:46:50.805: INFO: Pod "projected-volume-a35c0810-4f60-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00803191s
[1mSTEP[0m: Saw pod success
Mar 25 17:46:50.805: INFO: Pod "projected-volume-a35c0810-4f60-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:46:50.808: INFO: Trying to get logs from node conformance-worker2 pod projected-volume-a35c0810-4f60-11e9-91ba-a08cfdecc127 container projected-all-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:46:50.824: INFO: Waiting for pod projected-volume-a35c0810-4f60-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:46:50.826: INFO: Pod projected-volume-a35c0810-4f60-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected combined
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:46:50.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-4910" for this suite.
Mar 25 17:46:56.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:46:56.898: INFO: namespace projected-4910 deletion completed in 6.068977841s
[32mâ€¢[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould observe an object deletion if it stops meeting the requirements of the selector [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-api-machinery] Watchers
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:46:56.898: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename watch
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating a watch on configmaps with a certain label
[1mSTEP[0m: creating a new configmap
[1mSTEP[0m: modifying the configmap once
[1mSTEP[0m: changing the label value of the configmap
[1mSTEP[0m: Expecting to observe a delete notification for the watched object
Mar 25 17:46:56.938: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5826,SelfLink:/api/v1/namespaces/watch-5826/configmaps/e2e-watch-test-label-changed,UID:a839349c-4f60-11e9-8304-02427cbbc9a0,ResourceVersion:6062,Generation:0,CreationTimestamp:2019-03-25 17:46:56 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 25 17:46:56.939: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5826,SelfLink:/api/v1/namespaces/watch-5826/configmaps/e2e-watch-test-label-changed,UID:a839349c-4f60-11e9-8304-02427cbbc9a0,ResourceVersion:6063,Generation:0,CreationTimestamp:2019-03-25 17:46:56 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 25 17:46:56.939: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5826,SelfLink:/api/v1/namespaces/watch-5826/configmaps/e2e-watch-test-label-changed,UID:a839349c-4f60-11e9-8304-02427cbbc9a0,ResourceVersion:6064,Generation:0,CreationTimestamp:2019-03-25 17:46:56 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying the configmap a second time
[1mSTEP[0m: Expecting not to observe a notification because the object no longer meets the selector's requirements
[1mSTEP[0m: changing the label value of the configmap back
[1mSTEP[0m: modifying the configmap a third time
[1mSTEP[0m: deleting the configmap
[1mSTEP[0m: Expecting to observe an add notification for the watched object when the label value was restored
Mar 25 17:47:06.957: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5826,SelfLink:/api/v1/namespaces/watch-5826/configmaps/e2e-watch-test-label-changed,UID:a839349c-4f60-11e9-8304-02427cbbc9a0,ResourceVersion:6082,Generation:0,CreationTimestamp:2019-03-25 17:46:56 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 25 17:47:06.957: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5826,SelfLink:/api/v1/namespaces/watch-5826/configmaps/e2e-watch-test-label-changed,UID:a839349c-4f60-11e9-8304-02427cbbc9a0,ResourceVersion:6083,Generation:0,CreationTimestamp:2019-03-25 17:46:56 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar 25 17:47:06.957: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5826,SelfLink:/api/v1/namespaces/watch-5826/configmaps/e2e-watch-test-label-changed,UID:a839349c-4f60-11e9-8304-02427cbbc9a0,ResourceVersion:6084,Generation:0,CreationTimestamp:2019-03-25 17:46:56 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:47:06.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "watch-5826" for this suite.
Mar 25 17:47:12.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:47:13.027: INFO: namespace watch-5826 deletion completed in 6.067146003s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] Downward API[0m 
  [1mshould provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-node] Downward API
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:47:13.027: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward api env vars
Mar 25 17:47:13.058: INFO: Waiting up to 5m0s for pod "downward-api-b1d5cf19-4f60-11e9-91ba-a08cfdecc127" in namespace "downward-api-4609" to be "success or failure"
Mar 25 17:47:13.062: INFO: Pod "downward-api-b1d5cf19-4f60-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.89814ms
Mar 25 17:47:15.065: INFO: Pod "downward-api-b1d5cf19-4f60-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006703246s
[1mSTEP[0m: Saw pod success
Mar 25 17:47:15.065: INFO: Pod "downward-api-b1d5cf19-4f60-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:47:15.067: INFO: Trying to get logs from node conformance-worker pod downward-api-b1d5cf19-4f60-11e9-91ba-a08cfdecc127 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:47:15.081: INFO: Waiting for pod downward-api-b1d5cf19-4f60-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:47:15.085: INFO: Pod downward-api-b1d5cf19-4f60-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-node] Downward API
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:47:15.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-4609" for this suite.
Mar 25 17:47:21.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:47:21.158: INFO: namespace downward-api-4609 deletion completed in 6.070990791s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mScaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:47:21.158: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace statefulset-83
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Initializing watcher for selector baz=blah,foo=bar
[1mSTEP[0m: Creating stateful set ss in namespace statefulset-83
[1mSTEP[0m: Waiting until all stateful set ss replicas will be running in namespace statefulset-83
Mar 25 17:47:21.192: INFO: Found 0 stateful pods, waiting for 1
Mar 25 17:47:31.196: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar 25 17:47:31.200: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-83 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 17:47:31.478: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 17:47:31.478: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 17:47:31.478: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 17:47:31.481: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 25 17:47:41.485: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 25 17:47:41.485: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 17:47:41.500: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999724s
Mar 25 17:47:42.503: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.992625217s
Mar 25 17:47:43.506: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.989171805s
Mar 25 17:47:44.510: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.985999465s
Mar 25 17:47:45.515: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.981830054s
Mar 25 17:47:46.518: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.977702141s
Mar 25 17:47:47.522: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.974319515s
Mar 25 17:47:48.526: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.970124414s
Mar 25 17:47:49.530: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.966286429s
Mar 25 17:47:50.532: INFO: Verifying statefulset ss doesn't scale past 1 for another 962.477219ms
[1mSTEP[0m: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-83
Mar 25 17:47:51.536: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-83 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 17:47:51.798: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar 25 17:47:51.798: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 17:47:51.798: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 17:47:51.801: INFO: Found 1 stateful pods, waiting for 3
Mar 25 17:48:01.805: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 17:48:01.805: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 17:48:01.805: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Verifying that stateful set ss was scaled up in order
[1mSTEP[0m: Scale down will halt with unhealthy stateful pod
Mar 25 17:48:01.812: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-83 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 17:48:02.071: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 17:48:02.071: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 17:48:02.071: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 17:48:02.071: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-83 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 17:48:02.322: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 17:48:02.322: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 17:48:02.322: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 17:48:02.322: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-83 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 17:48:02.552: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 17:48:02.552: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 17:48:02.553: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 17:48:02.553: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 17:48:02.555: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Mar 25 17:48:12.563: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 25 17:48:12.563: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 25 17:48:12.563: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 25 17:48:12.572: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999734s
Mar 25 17:48:13.576: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996739814s
Mar 25 17:48:14.579: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992909962s
Mar 25 17:48:15.582: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989227621s
Mar 25 17:48:16.587: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.98622374s
Mar 25 17:48:17.591: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.982028465s
Mar 25 17:48:18.595: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.978119011s
Mar 25 17:48:19.600: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.973582376s
Mar 25 17:48:20.604: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.96885053s
Mar 25 17:48:21.607: INFO: Verifying statefulset ss doesn't scale past 3 for another 965.073402ms
[1mSTEP[0m: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-83
Mar 25 17:48:22.611: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-83 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 17:48:22.857: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar 25 17:48:22.857: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 17:48:22.857: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 17:48:22.857: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-83 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 17:48:23.079: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar 25 17:48:23.079: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 17:48:23.079: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 17:48:23.079: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-83 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 17:48:23.323: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar 25 17:48:23.323: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 17:48:23.323: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 17:48:23.323: INFO: Scaling statefulset ss to 0
[1mSTEP[0m: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 25 17:48:53.335: INFO: Deleting all statefulset in ns statefulset-83
Mar 25 17:48:53.338: INFO: Scaling statefulset ss to 0
Mar 25 17:48:53.346: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 17:48:53.348: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:48:53.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "statefulset-83" for this suite.
Mar 25 17:48:59.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:48:59.434: INFO: namespace statefulset-83 deletion completed in 6.073682624s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-scheduling] SchedulerPredicates [Serial][0m 
  [1mvalidates that NodeSelector is respected if not matching  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:48:59.434: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename sched-pred
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 25 17:48:59.461: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 25 17:48:59.468: INFO: Waiting for terminating namespaces to be deleted...
Mar 25 17:48:59.469: INFO: 
Logging pods the kubelet thinks is on node conformance-worker before test
Mar 25 17:48:59.472: INFO: kube-proxy-94s4s from kube-system started at 2019-03-25 17:14:28 -0700 PDT (1 container statuses recorded)
Mar 25 17:48:59.472: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 25 17:48:59.472: INFO: weave-net-dswmc from kube-system started at 2019-03-25 17:14:28 -0700 PDT (2 container statuses recorded)
Mar 25 17:48:59.472: INFO: 	Container weave ready: true, restart count 1
Mar 25 17:48:59.472: INFO: 	Container weave-npc ready: true, restart count 0
Mar 25 17:48:59.472: INFO: 
Logging pods the kubelet thinks is on node conformance-worker2 before test
Mar 25 17:48:59.474: INFO: kube-proxy-ld748 from kube-system started at 2019-03-25 17:14:41 -0700 PDT (1 container statuses recorded)
Mar 25 17:48:59.474: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 25 17:48:59.474: INFO: weave-net-grwls from kube-system started at 2019-03-25 17:14:41 -0700 PDT (2 container statuses recorded)
Mar 25 17:48:59.474: INFO: 	Container weave ready: true, restart count 1
Mar 25 17:48:59.474: INFO: 	Container weave-npc ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Trying to schedule Pod with nonempty NodeSelector.
[1mSTEP[0m: Considering event: 
Type = [Warning], Name = [restricted-pod.158f5bcea0be97df], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:49:00.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "sched-pred-6071" for this suite.
Mar 25 17:49:06.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:49:06.571: INFO: namespace sched-pred-6071 deletion completed in 6.079349965s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70
[32mâ€¢[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:49:06.571: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name configmap-test-volume-map-f582f5e8-4f60-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 25 17:49:06.602: INFO: Waiting up to 5m0s for pod "pod-configmaps-f5834d37-4f60-11e9-91ba-a08cfdecc127" in namespace "configmap-4521" to be "success or failure"
Mar 25 17:49:06.606: INFO: Pod "pod-configmaps-f5834d37-4f60-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.703117ms
Mar 25 17:49:08.609: INFO: Pod "pod-configmaps-f5834d37-4f60-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007197542s
Mar 25 17:49:10.613: INFO: Pod "pod-configmaps-f5834d37-4f60-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011095037s
[1mSTEP[0m: Saw pod success
Mar 25 17:49:10.613: INFO: Pod "pod-configmaps-f5834d37-4f60-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:49:10.616: INFO: Trying to get logs from node conformance-worker pod pod-configmaps-f5834d37-4f60-11e9-91ba-a08cfdecc127 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:49:10.641: INFO: Waiting for pod pod-configmaps-f5834d37-4f60-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:49:10.643: INFO: Pod pod-configmaps-f5834d37-4f60-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:49:10.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-4521" for this suite.
Mar 25 17:49:16.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:49:16.719: INFO: namespace configmap-4521 deletion completed in 6.073197553s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mupdates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:49:16.719: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating projection with configMap that has name projected-configmap-test-upd-fb905908-4f60-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Updating configmap projected-configmap-test-upd-fb905908-4f60-11e9-91ba-a08cfdecc127
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:50:31.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-7323" for this suite.
Mar 25 17:50:53.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:50:53.215: INFO: namespace projected-7323 deletion completed in 22.07279174s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould have monotonically increasing restart count [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:50:53.215: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating pod liveness-http in namespace container-probe-8713
Mar 25 17:50:57.253: INFO: Started pod liveness-http in namespace container-probe-8713
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
Mar 25 17:50:57.256: INFO: Initial restart count of pod liveness-http is 0
Mar 25 17:51:09.281: INFO: Restart count of pod container-probe-8713/liveness-http is now 1 (12.024939733s elapsed)
Mar 25 17:51:29.315: INFO: Restart count of pod container-probe-8713/liveness-http is now 2 (32.059113471s elapsed)
Mar 25 17:51:49.355: INFO: Restart count of pod container-probe-8713/liveness-http is now 3 (52.098916648s elapsed)
Mar 25 17:52:09.401: INFO: Restart count of pod container-probe-8713/liveness-http is now 4 (1m12.145138302s elapsed)
Mar 25 17:53:21.534: INFO: Restart count of pod container-probe-8713/liveness-http is now 5 (2m24.27814043s elapsed)
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:53:21.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-probe-8713" for this suite.
Mar 25 17:53:27.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:53:27.620: INFO: namespace container-probe-8713 deletion completed in 6.072155106s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:53:27.621: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 17:53:27.664: INFO: Waiting up to 5m0s for pod "downwardapi-volume-911e0fa5-4f61-11e9-91ba-a08cfdecc127" in namespace "projected-5787" to be "success or failure"
Mar 25 17:53:27.666: INFO: Pod "downwardapi-volume-911e0fa5-4f61-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.108865ms
Mar 25 17:53:29.669: INFO: Pod "downwardapi-volume-911e0fa5-4f61-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005407519s
Mar 25 17:53:31.672: INFO: Pod "downwardapi-volume-911e0fa5-4f61-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008437252s
[1mSTEP[0m: Saw pod success
Mar 25 17:53:31.672: INFO: Pod "downwardapi-volume-911e0fa5-4f61-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:53:31.674: INFO: Trying to get logs from node conformance-worker2 pod downwardapi-volume-911e0fa5-4f61-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:53:31.693: INFO: Waiting for pod downwardapi-volume-911e0fa5-4f61-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:53:31.695: INFO: Pod downwardapi-volume-911e0fa5-4f61-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:53:31.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-5787" for this suite.
Mar 25 17:53:37.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:53:37.773: INFO: namespace projected-5787 deletion completed in 6.076604932s
[32mâ€¢[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected secret
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:53:37.774: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating secret with name s-test-opt-del-972b28b1-4f61-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating secret with name s-test-opt-upd-972b290e-4f61-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting secret s-test-opt-del-972b28b1-4f61-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Updating secret s-test-opt-upd-972b290e-4f61-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating secret with name s-test-opt-create-972b292d-4f61-11e9-91ba-a08cfdecc127
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:53:45.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-7298" for this suite.
Mar 25 17:54:07.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:54:07.957: INFO: namespace projected-7298 deletion completed in 22.056897881s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:54:07.957: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test emptydir 0644 on tmpfs
Mar 25 17:54:07.985: INFO: Waiting up to 5m0s for pod "pod-a926589b-4f61-11e9-91ba-a08cfdecc127" in namespace "emptydir-1958" to be "success or failure"
Mar 25 17:54:07.989: INFO: Pod "pod-a926589b-4f61-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 4.576868ms
Mar 25 17:54:09.993: INFO: Pod "pod-a926589b-4f61-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008093447s
Mar 25 17:54:11.996: INFO: Pod "pod-a926589b-4f61-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010987005s
[1mSTEP[0m: Saw pod success
Mar 25 17:54:11.996: INFO: Pod "pod-a926589b-4f61-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:54:11.998: INFO: Trying to get logs from node conformance-worker2 pod pod-a926589b-4f61-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:54:12.011: INFO: Waiting for pod pod-a926589b-4f61-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:54:12.013: INFO: Pod pod-a926589b-4f61-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:54:12.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-1958" for this suite.
Mar 25 17:54:18.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:54:18.087: INFO: namespace emptydir-1958 deletion completed in 6.072725329s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:54:18.088: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name configmap-test-volume-af303360-4f61-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 25 17:54:18.120: INFO: Waiting up to 5m0s for pod "pod-configmaps-af30fbac-4f61-11e9-91ba-a08cfdecc127" in namespace "configmap-3587" to be "success or failure"
Mar 25 17:54:18.122: INFO: Pod "pod-configmaps-af30fbac-4f61-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.726632ms
Mar 25 17:54:20.126: INFO: Pod "pod-configmaps-af30fbac-4f61-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00576596s
Mar 25 17:54:22.129: INFO: Pod "pod-configmaps-af30fbac-4f61-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009547023s
[1mSTEP[0m: Saw pod success
Mar 25 17:54:22.129: INFO: Pod "pod-configmaps-af30fbac-4f61-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:54:22.134: INFO: Trying to get logs from node conformance-worker pod pod-configmaps-af30fbac-4f61-11e9-91ba-a08cfdecc127 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:54:22.146: INFO: Waiting for pod pod-configmaps-af30fbac-4f61-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:54:22.149: INFO: Pod pod-configmaps-af30fbac-4f61-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:54:22.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-3587" for this suite.
Mar 25 17:54:28.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:54:28.221: INFO: namespace configmap-3587 deletion completed in 6.069532311s
[32mâ€¢[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould update labels on modification [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:54:28.221: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating the pod
Mar 25 17:54:30.781: INFO: Successfully updated pod "labelsupdateb53b6cf1-4f61-11e9-91ba-a08cfdecc127"
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:54:32.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-8482" for this suite.
Mar 25 17:54:54.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:54:54.863: INFO: namespace projected-8482 deletion completed in 22.060306961s
[32mâ€¢[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] Pods Extended[0m [90m[k8s.io] Pods Set QOS Class[0m 
  [1mshould be submitted and removed  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:54:54.863: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:54:54.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-3654" for this suite.
Mar 25 17:55:38.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:55:38.970: INFO: namespace pods-3654 deletion completed in 44.071925986s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:55:38.971: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test emptydir 0666 on node default medium
Mar 25 17:55:39.004: INFO: Waiting up to 5m0s for pod "pod-df671910-4f61-11e9-91ba-a08cfdecc127" in namespace "emptydir-6649" to be "success or failure"
Mar 25 17:55:39.008: INFO: Pod "pod-df671910-4f61-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.780556ms
Mar 25 17:55:41.011: INFO: Pod "pod-df671910-4f61-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00743527s
[1mSTEP[0m: Saw pod success
Mar 25 17:55:41.011: INFO: Pod "pod-df671910-4f61-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:55:41.014: INFO: Trying to get logs from node conformance-worker2 pod pod-df671910-4f61-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:55:41.029: INFO: Waiting for pod pod-df671910-4f61-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:55:41.031: INFO: Pod pod-df671910-4f61-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:55:41.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-6649" for this suite.
Mar 25 17:55:47.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:55:47.108: INFO: namespace emptydir-6649 deletion completed in 6.074441335s
[32mâ€¢[0m
[90m------------------------------[0m
[0m[k8s.io] Container Lifecycle Hook[0m [90mwhen create a pod with lifecycle hook[0m 
  [1mshould execute poststart exec hook properly [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:55:47.108: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename container-lifecycle-hook
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
[1mSTEP[0m: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: create the pod with lifecycle hook
[1mSTEP[0m: check poststart hook
[1mSTEP[0m: delete the pod with lifecycle hook
Mar 25 17:58:35.179: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 17:58:35.181: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 17:58:37.182: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 17:58:37.186: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 17:58:39.182: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 17:58:39.186: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 17:58:41.182: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 17:58:41.186: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 17:58:43.182: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 17:58:43.185: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 17:58:45.182: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 17:58:45.185: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 17:58:47.182: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 17:58:47.185: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 17:58:49.182: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 17:58:49.187: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 17:58:51.182: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 17:58:51.189: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 17:58:53.182: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 17:58:53.186: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 17:58:55.182: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 17:58:55.186: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 17:58:57.182: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 17:58:57.187: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 25 17:58:59.182: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 25 17:58:59.186: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:58:59.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-lifecycle-hook-1352" for this suite.
Mar 25 17:59:21.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:59:21.271: INFO: namespace container-lifecycle-hook-1352 deletion completed in 22.082148322s
[32mâ€¢[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:59:21.272: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name configmap-test-volume-map-63e73694-4f62-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 25 17:59:21.306: INFO: Waiting up to 5m0s for pod "pod-configmaps-63e7a296-4f62-11e9-91ba-a08cfdecc127" in namespace "configmap-157" to be "success or failure"
Mar 25 17:59:21.311: INFO: Pod "pod-configmaps-63e7a296-4f62-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 5.686944ms
Mar 25 17:59:23.315: INFO: Pod "pod-configmaps-63e7a296-4f62-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009047654s
[1mSTEP[0m: Saw pod success
Mar 25 17:59:23.315: INFO: Pod "pod-configmaps-63e7a296-4f62-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 17:59:23.317: INFO: Trying to get logs from node conformance-worker pod pod-configmaps-63e7a296-4f62-11e9-91ba-a08cfdecc127 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 17:59:23.329: INFO: Waiting for pod pod-configmaps-63e7a296-4f62-11e9-91ba-a08cfdecc127 to disappear
Mar 25 17:59:23.330: INFO: Pod pod-configmaps-63e7a296-4f62-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 17:59:23.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-157" for this suite.
Mar 25 17:59:29.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 17:59:29.402: INFO: namespace configmap-157 deletion completed in 6.067600662s
[32mâ€¢[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 17:59:29.402: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating pod liveness-exec in namespace container-probe-486
Mar 25 17:59:31.437: INFO: Started pod liveness-exec in namespace container-probe-486
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
Mar 25 17:59:31.439: INFO: Initial restart count of pod liveness-exec is 0
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:03:31.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-probe-486" for this suite.
Mar 25 18:03:37.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:03:37.963: INFO: namespace container-probe-486 deletion completed in 6.072036825s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:03:37.963: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test emptydir 0777 on tmpfs
Mar 25 18:03:37.999: INFO: Waiting up to 5m0s for pod "pod-fce7eec5-4f62-11e9-91ba-a08cfdecc127" in namespace "emptydir-2712" to be "success or failure"
Mar 25 18:03:38.003: INFO: Pod "pod-fce7eec5-4f62-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.79143ms
Mar 25 18:03:40.007: INFO: Pod "pod-fce7eec5-4f62-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007550025s
[1mSTEP[0m: Saw pod success
Mar 25 18:03:40.007: INFO: Pod "pod-fce7eec5-4f62-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:03:40.010: INFO: Trying to get logs from node conformance-worker pod pod-fce7eec5-4f62-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:03:40.027: INFO: Waiting for pod pod-fce7eec5-4f62-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:03:40.029: INFO: Pod pod-fce7eec5-4f62-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:03:40.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-2712" for this suite.
Mar 25 18:03:46.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:03:46.103: INFO: namespace emptydir-2712 deletion completed in 6.07223001s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected secret
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:03:46.104: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-01c0f02f-4f63-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 25 18:03:46.134: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-01c147c0-4f63-11e9-91ba-a08cfdecc127" in namespace "projected-2185" to be "success or failure"
Mar 25 18:03:46.136: INFO: Pod "pod-projected-secrets-01c147c0-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.929431ms
Mar 25 18:03:48.140: INFO: Pod "pod-projected-secrets-01c147c0-4f63-11e9-91ba-a08cfdecc127": Phase="Running", Reason="", readiness=true. Elapsed: 2.006071906s
Mar 25 18:03:50.144: INFO: Pod "pod-projected-secrets-01c147c0-4f63-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009976106s
[1mSTEP[0m: Saw pod success
Mar 25 18:03:50.144: INFO: Pod "pod-projected-secrets-01c147c0-4f63-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:03:50.148: INFO: Trying to get logs from node conformance-worker2 pod pod-projected-secrets-01c147c0-4f63-11e9-91ba-a08cfdecc127 container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:03:50.165: INFO: Waiting for pod pod-projected-secrets-01c147c0-4f63-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:03:50.167: INFO: Pod pod-projected-secrets-01c147c0-4f63-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected secret
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:03:50.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-2185" for this suite.
Mar 25 18:03:56.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:03:56.252: INFO: namespace projected-2185 deletion completed in 6.083243264s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Variable Expansion[0m 
  [1mshould allow substituting values in a container's command [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Variable Expansion
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:03:56.252: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename var-expansion
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test substitution in container's command
Mar 25 18:03:56.295: INFO: Waiting up to 5m0s for pod "var-expansion-07ceef2d-4f63-11e9-91ba-a08cfdecc127" in namespace "var-expansion-5031" to be "success or failure"
Mar 25 18:03:56.297: INFO: Pod "var-expansion-07ceef2d-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.332403ms
Mar 25 18:03:58.301: INFO: Pod "var-expansion-07ceef2d-4f63-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006365456s
[1mSTEP[0m: Saw pod success
Mar 25 18:03:58.301: INFO: Pod "var-expansion-07ceef2d-4f63-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:03:58.305: INFO: Trying to get logs from node conformance-worker pod var-expansion-07ceef2d-4f63-11e9-91ba-a08cfdecc127 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:03:58.320: INFO: Waiting for pod var-expansion-07ceef2d-4f63-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:03:58.324: INFO: Pod var-expansion-07ceef2d-4f63-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:03:58.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "var-expansion-5031" for this suite.
Mar 25 18:04:04.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:04:04.398: INFO: namespace var-expansion-5031 deletion completed in 6.072001707s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:04:04.398: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test emptydir 0644 on node default medium
Mar 25 18:04:04.431: INFO: Waiting up to 5m0s for pod "pod-0ca93229-4f63-11e9-91ba-a08cfdecc127" in namespace "emptydir-6886" to be "success or failure"
Mar 25 18:04:04.433: INFO: Pod "pod-0ca93229-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.75154ms
Mar 25 18:04:06.437: INFO: Pod "pod-0ca93229-4f63-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005993037s
[1mSTEP[0m: Saw pod success
Mar 25 18:04:06.438: INFO: Pod "pod-0ca93229-4f63-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:04:06.441: INFO: Trying to get logs from node conformance-worker2 pod pod-0ca93229-4f63-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:04:06.459: INFO: Waiting for pod pod-0ca93229-4f63-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:04:06.461: INFO: Pod pod-0ca93229-4f63-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:04:06.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-6886" for this suite.
Mar 25 18:04:12.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:04:12.534: INFO: namespace emptydir-6886 deletion completed in 6.070408497s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould be updated [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:04:12.534: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: updating the pod
Mar 25 18:04:15.084: INFO: Successfully updated pod "pod-update-1181c196-4f63-11e9-91ba-a08cfdecc127"
[1mSTEP[0m: verifying the updated pod is in kubernetes
Mar 25 18:04:15.093: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:04:15.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-1634" for this suite.
Mar 25 18:04:31.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:04:31.171: INFO: namespace pods-1634 deletion completed in 16.075880215s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-scheduling] SchedulerPredicates [Serial][0m 
  [1mvalidates resource limits of pods that are allowed to run  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:04:31.171: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename sched-pred
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 25 18:04:31.201: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 25 18:04:31.204: INFO: Waiting for terminating namespaces to be deleted...
Mar 25 18:04:31.206: INFO: 
Logging pods the kubelet thinks is on node conformance-worker before test
Mar 25 18:04:31.209: INFO: weave-net-dswmc from kube-system started at 2019-03-25 17:14:28 -0700 PDT (2 container statuses recorded)
Mar 25 18:04:31.209: INFO: 	Container weave ready: true, restart count 1
Mar 25 18:04:31.209: INFO: 	Container weave-npc ready: true, restart count 0
Mar 25 18:04:31.209: INFO: kube-proxy-94s4s from kube-system started at 2019-03-25 17:14:28 -0700 PDT (1 container statuses recorded)
Mar 25 18:04:31.209: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 25 18:04:31.209: INFO: 
Logging pods the kubelet thinks is on node conformance-worker2 before test
Mar 25 18:04:31.212: INFO: kube-proxy-ld748 from kube-system started at 2019-03-25 17:14:41 -0700 PDT (1 container statuses recorded)
Mar 25 18:04:31.212: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 25 18:04:31.212: INFO: weave-net-grwls from kube-system started at 2019-03-25 17:14:41 -0700 PDT (2 container statuses recorded)
Mar 25 18:04:31.212: INFO: 	Container weave ready: true, restart count 1
Mar 25 18:04:31.212: INFO: 	Container weave-npc ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: verifying the node has the label node conformance-worker
[1mSTEP[0m: verifying the node has the label node conformance-worker2
Mar 25 18:04:31.232: INFO: Pod kube-proxy-94s4s requesting resource cpu=0m on Node conformance-worker
Mar 25 18:04:31.232: INFO: Pod kube-proxy-ld748 requesting resource cpu=0m on Node conformance-worker2
Mar 25 18:04:31.232: INFO: Pod weave-net-dswmc requesting resource cpu=20m on Node conformance-worker
Mar 25 18:04:31.232: INFO: Pod weave-net-grwls requesting resource cpu=20m on Node conformance-worker2
[1mSTEP[0m: Starting Pods to consume most of the cluster CPU.
[1mSTEP[0m: Creating another pod that requires unavailable amount of CPU.
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-1ca338fb-4f63-11e9-91ba-a08cfdecc127.158f5ca791a77fab], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6401/filler-pod-1ca338fb-4f63-11e9-91ba-a08cfdecc127 to conformance-worker]
[1mSTEP[0m: Considering event: 
Type = [Warning], Name = [filler-pod-1ca338fb-4f63-11e9-91ba-a08cfdecc127.158f5ca7a495bb4e], Reason = [DNSConfigForming], Message = [Search Line limits were exceeded, some search paths have been omitted, the applied search line is: sched-pred-6401.svc.cluster.local svc.cluster.local cluster.local corp.google.com prod.google.com prodz.google.com]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-1ca338fb-4f63-11e9-91ba-a08cfdecc127.158f5ca7d115449a], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-1ca338fb-4f63-11e9-91ba-a08cfdecc127.158f5ca7d7757f85], Reason = [Created], Message = [Created container filler-pod-1ca338fb-4f63-11e9-91ba-a08cfdecc127]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-1ca338fb-4f63-11e9-91ba-a08cfdecc127.158f5ca7e7c8e454], Reason = [Started], Message = [Started container filler-pod-1ca338fb-4f63-11e9-91ba-a08cfdecc127]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-1ca3ea3a-4f63-11e9-91ba-a08cfdecc127.158f5ca791f9cbdc], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6401/filler-pod-1ca3ea3a-4f63-11e9-91ba-a08cfdecc127 to conformance-worker2]
[1mSTEP[0m: Considering event: 
Type = [Warning], Name = [filler-pod-1ca3ea3a-4f63-11e9-91ba-a08cfdecc127.158f5ca7a4bfbbdf], Reason = [DNSConfigForming], Message = [Search Line limits were exceeded, some search paths have been omitted, the applied search line is: sched-pred-6401.svc.cluster.local svc.cluster.local cluster.local corp.google.com prod.google.com prodz.google.com]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-1ca3ea3a-4f63-11e9-91ba-a08cfdecc127.158f5ca7d12abaa0], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-1ca3ea3a-4f63-11e9-91ba-a08cfdecc127.158f5ca7d7765281], Reason = [Created], Message = [Created container filler-pod-1ca3ea3a-4f63-11e9-91ba-a08cfdecc127]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-1ca3ea3a-4f63-11e9-91ba-a08cfdecc127.158f5ca7e78f5828], Reason = [Started], Message = [Started container filler-pod-1ca3ea3a-4f63-11e9-91ba-a08cfdecc127]
[1mSTEP[0m: Considering event: 
Type = [Warning], Name = [additional-pod.158f5ca88159dfc0], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
[1mSTEP[0m: removing the label node off the node conformance-worker
[1mSTEP[0m: verifying the node doesn't have the label node
[1mSTEP[0m: removing the label node off the node conformance-worker2
[1mSTEP[0m: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:04:36.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "sched-pred-6401" for this suite.
Mar 25 18:04:42.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:04:42.364: INFO: namespace sched-pred-6401 deletion completed in 6.080209665s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] CustomResourceDefinition resources[0m [90mSimple CustomResourceDefinition[0m 
  [1mcreating/deleting custom resource definition objects works  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:04:42.365: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename custom-resource-definition
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Mar 25 18:04:42.395: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:04:43.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "custom-resource-definition-6893" for this suite.
Mar 25 18:04:49.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:04:49.521: INFO: namespace custom-resource-definition-6893 deletion completed in 6.075977464s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:04:49.521: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating secret with name secret-test-278d7b95-4f63-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 25 18:04:49.577: INFO: Waiting up to 5m0s for pod "pod-secrets-2791d450-4f63-11e9-91ba-a08cfdecc127" in namespace "secrets-6343" to be "success or failure"
Mar 25 18:04:49.579: INFO: Pod "pod-secrets-2791d450-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.878741ms
Mar 25 18:04:51.583: INFO: Pod "pod-secrets-2791d450-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006015245s
Mar 25 18:04:53.587: INFO: Pod "pod-secrets-2791d450-4f63-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010038069s
[1mSTEP[0m: Saw pod success
Mar 25 18:04:53.587: INFO: Pod "pod-secrets-2791d450-4f63-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:04:53.590: INFO: Trying to get logs from node conformance-worker2 pod pod-secrets-2791d450-4f63-11e9-91ba-a08cfdecc127 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:04:53.607: INFO: Waiting for pod pod-secrets-2791d450-4f63-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:04:53.609: INFO: Pod pod-secrets-2791d450-4f63-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:04:53.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "secrets-6343" for this suite.
Mar 25 18:04:59.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:04:59.683: INFO: namespace secrets-6343 deletion completed in 6.07078826s
[1mSTEP[0m: Destroying namespace "secret-namespace-915" for this suite.
Mar 25 18:05:05.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:05:05.760: INFO: namespace secret-namespace-915 deletion completed in 6.077585139s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould use the image defaults if command and args are blank [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Docker Containers
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:05:05.761: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename containers
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test use defaults
Mar 25 18:05:05.811: INFO: Waiting up to 5m0s for pod "client-containers-313ecaef-4f63-11e9-91ba-a08cfdecc127" in namespace "containers-5347" to be "success or failure"
Mar 25 18:05:05.817: INFO: Pod "client-containers-313ecaef-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 5.980296ms
Mar 25 18:05:07.821: INFO: Pod "client-containers-313ecaef-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009805114s
Mar 25 18:05:09.825: INFO: Pod "client-containers-313ecaef-4f63-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013662277s
[1mSTEP[0m: Saw pod success
Mar 25 18:05:09.825: INFO: Pod "client-containers-313ecaef-4f63-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:05:09.827: INFO: Trying to get logs from node conformance-worker pod client-containers-313ecaef-4f63-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:05:09.843: INFO: Waiting for pod client-containers-313ecaef-4f63-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:05:09.845: INFO: Pod client-containers-313ecaef-4f63-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:05:09.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "containers-5347" for this suite.
Mar 25 18:05:15.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:05:15.912: INFO: namespace containers-5347 deletion completed in 6.064696375s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:05:15.913: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating secret with name secret-test-3748a10c-4f63-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 25 18:05:15.949: INFO: Waiting up to 5m0s for pod "pod-secrets-374904fa-4f63-11e9-91ba-a08cfdecc127" in namespace "secrets-9827" to be "success or failure"
Mar 25 18:05:15.952: INFO: Pod "pod-secrets-374904fa-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.673863ms
Mar 25 18:05:17.956: INFO: Pod "pod-secrets-374904fa-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007542545s
Mar 25 18:05:19.960: INFO: Pod "pod-secrets-374904fa-4f63-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011544011s
[1mSTEP[0m: Saw pod success
Mar 25 18:05:19.960: INFO: Pod "pod-secrets-374904fa-4f63-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:05:19.964: INFO: Trying to get logs from node conformance-worker2 pod pod-secrets-374904fa-4f63-11e9-91ba-a08cfdecc127 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:05:19.983: INFO: Waiting for pod pod-secrets-374904fa-4f63-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:05:19.985: INFO: Pod pod-secrets-374904fa-4f63-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:05:19.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "secrets-9827" for this suite.
Mar 25 18:05:25.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:05:26.061: INFO: namespace secrets-9827 deletion completed in 6.07355355s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:05:26.061: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 18:05:26.094: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d55fa5e-4f63-11e9-91ba-a08cfdecc127" in namespace "downward-api-3233" to be "success or failure"
Mar 25 18:05:26.096: INFO: Pod "downwardapi-volume-3d55fa5e-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.558355ms
Mar 25 18:05:28.105: INFO: Pod "downwardapi-volume-3d55fa5e-4f63-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010946194s
[1mSTEP[0m: Saw pod success
Mar 25 18:05:28.105: INFO: Pod "downwardapi-volume-3d55fa5e-4f63-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:05:28.107: INFO: Trying to get logs from node conformance-worker pod downwardapi-volume-3d55fa5e-4f63-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:05:28.123: INFO: Waiting for pod downwardapi-volume-3d55fa5e-4f63-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:05:28.124: INFO: Pod downwardapi-volume-3d55fa5e-4f63-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:05:28.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-3233" for this suite.
Mar 25 18:05:34.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:05:34.206: INFO: namespace downward-api-3233 deletion completed in 6.079483694s
[32mâ€¢[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould set mode on item file [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:05:34.206: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 18:05:34.235: INFO: Waiting up to 5m0s for pod "downwardapi-volume-422fffcc-4f63-11e9-91ba-a08cfdecc127" in namespace "projected-300" to be "success or failure"
Mar 25 18:05:34.243: INFO: Pod "downwardapi-volume-422fffcc-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 7.928871ms
Mar 25 18:05:36.247: INFO: Pod "downwardapi-volume-422fffcc-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012125798s
Mar 25 18:05:38.250: INFO: Pod "downwardapi-volume-422fffcc-4f63-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014916751s
[1mSTEP[0m: Saw pod success
Mar 25 18:05:38.250: INFO: Pod "downwardapi-volume-422fffcc-4f63-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:05:38.252: INFO: Trying to get logs from node conformance-worker2 pod downwardapi-volume-422fffcc-4f63-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:05:38.268: INFO: Waiting for pod downwardapi-volume-422fffcc-4f63-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:05:38.269: INFO: Pod downwardapi-volume-422fffcc-4f63-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:05:38.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-300" for this suite.
Mar 25 18:05:44.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:05:44.338: INFO: namespace projected-300 deletion completed in 6.066761313s
[32mâ€¢[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mshould be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:05:44.338: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-map-483a457d-4f63-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 25 18:05:44.373: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-483a9282-4f63-11e9-91ba-a08cfdecc127" in namespace "projected-9147" to be "success or failure"
Mar 25 18:05:44.375: INFO: Pod "pod-projected-configmaps-483a9282-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011771ms
Mar 25 18:05:46.378: INFO: Pod "pod-projected-configmaps-483a9282-4f63-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005601286s
[1mSTEP[0m: Saw pod success
Mar 25 18:05:46.378: INFO: Pod "pod-projected-configmaps-483a9282-4f63-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:05:46.381: INFO: Trying to get logs from node conformance-worker pod pod-projected-configmaps-483a9282-4f63-11e9-91ba-a08cfdecc127 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:05:46.398: INFO: Waiting for pod pod-projected-configmaps-483a9282-4f63-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:05:46.400: INFO: Pod pod-projected-configmaps-483a9282-4f63-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:05:46.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-9147" for this suite.
Mar 25 18:05:52.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:05:52.467: INFO: namespace projected-9147 deletion completed in 6.064370289s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected secret
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:05:52.467: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-map-4d127a8c-4f63-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 25 18:05:52.500: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4d132c03-4f63-11e9-91ba-a08cfdecc127" in namespace "projected-285" to be "success or failure"
Mar 25 18:05:52.506: INFO: Pod "pod-projected-secrets-4d132c03-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 5.400603ms
Mar 25 18:05:54.509: INFO: Pod "pod-projected-secrets-4d132c03-4f63-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008446535s
[1mSTEP[0m: Saw pod success
Mar 25 18:05:54.509: INFO: Pod "pod-projected-secrets-4d132c03-4f63-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:05:54.512: INFO: Trying to get logs from node conformance-worker pod pod-projected-secrets-4d132c03-4f63-11e9-91ba-a08cfdecc127 container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:05:54.547: INFO: Waiting for pod pod-projected-secrets-4d132c03-4f63-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:05:54.551: INFO: Pod pod-projected-secrets-4d132c03-4f63-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected secret
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:05:54.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-285" for this suite.
Mar 25 18:06:00.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:06:00.633: INFO: namespace projected-285 deletion completed in 6.079395663s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicaSet[0m 
  [1mshould adopt matching pods on creation and release no longer matching pods [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] ReplicaSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:06:00.633: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename replicaset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Given a Pod with a 'name' label pod-adoption-release is created
[1mSTEP[0m: When a replicaset with a matching selector is created
[1mSTEP[0m: Then the orphan pod is adopted
[1mSTEP[0m: When the matched label of one of its pods change
Mar 25 18:06:03.683: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
[1mSTEP[0m: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:06:04.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "replicaset-68" for this suite.
Mar 25 18:06:26.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:06:26.775: INFO: namespace replicaset-68 deletion completed in 22.078626048s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Proxy[0m [90mversion v1[0m 
  [1mshould proxy through a service and a pod  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] version v1
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:06:26.775: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename proxy
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: starting an echo server on multiple ports
[1mSTEP[0m: creating replication controller proxy-service-slbtm in namespace proxy-427
I0325 18:06:26.812583   72333 runners.go:184] Created replication controller with name: proxy-service-slbtm, namespace: proxy-427, replica count: 1
I0325 18:06:27.862953   72333 runners.go:184] proxy-service-slbtm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0325 18:06:28.863081   72333 runners.go:184] proxy-service-slbtm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0325 18:06:29.863242   72333 runners.go:184] proxy-service-slbtm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0325 18:06:30.863395   72333 runners.go:184] proxy-service-slbtm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0325 18:06:31.863574   72333 runners.go:184] proxy-service-slbtm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0325 18:06:32.863747   72333 runners.go:184] proxy-service-slbtm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0325 18:06:33.863879   72333 runners.go:184] proxy-service-slbtm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0325 18:06:34.864038   72333 runners.go:184] proxy-service-slbtm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0325 18:06:35.864219   72333 runners.go:184] proxy-service-slbtm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0325 18:06:36.864385   72333 runners.go:184] proxy-service-slbtm Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 25 18:06:36.867: INFO: setup took 10.067232251s, starting test cases
[1mSTEP[0m: running 16 cases, 20 attempts per case, 320 total attempts
Mar 25 18:06:36.873: INFO: (0) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 6.03219ms)
Mar 25 18:06:36.873: INFO: (0) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 6.106449ms)
Mar 25 18:06:36.873: INFO: (0) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 6.197551ms)
Mar 25 18:06:36.873: INFO: (0) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 6.474607ms)
Mar 25 18:06:36.873: INFO: (0) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 6.53852ms)
Mar 25 18:06:36.873: INFO: (0) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 6.583185ms)
Mar 25 18:06:36.873: INFO: (0) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 6.504576ms)
Mar 25 18:06:36.874: INFO: (0) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 7.494402ms)
Mar 25 18:06:36.874: INFO: (0) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 7.615616ms)
Mar 25 18:06:36.875: INFO: (0) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 7.763958ms)
Mar 25 18:06:36.875: INFO: (0) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 8.021164ms)
Mar 25 18:06:36.883: INFO: (0) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 15.962375ms)
Mar 25 18:06:36.883: INFO: (0) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 16.061099ms)
Mar 25 18:06:36.883: INFO: (0) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 16.54672ms)
Mar 25 18:06:36.885: INFO: (0) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 18.400465ms)
Mar 25 18:06:36.886: INFO: (0) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 18.994289ms)
Mar 25 18:06:36.889: INFO: (1) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 2.689607ms)
Mar 25 18:06:36.889: INFO: (1) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 2.724134ms)
Mar 25 18:06:36.889: INFO: (1) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 3.136961ms)
Mar 25 18:06:36.889: INFO: (1) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 3.374858ms)
Mar 25 18:06:36.890: INFO: (1) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 4.029421ms)
Mar 25 18:06:36.890: INFO: (1) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 4.074996ms)
Mar 25 18:06:36.890: INFO: (1) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 4.113326ms)
Mar 25 18:06:36.890: INFO: (1) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 4.160144ms)
Mar 25 18:06:36.890: INFO: (1) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 4.11777ms)
Mar 25 18:06:36.890: INFO: (1) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 4.224546ms)
Mar 25 18:06:36.890: INFO: (1) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 4.267669ms)
Mar 25 18:06:36.890: INFO: (1) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 4.37419ms)
Mar 25 18:06:36.890: INFO: (1) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 4.449453ms)
Mar 25 18:06:36.890: INFO: (1) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 4.430268ms)
Mar 25 18:06:36.890: INFO: (1) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 4.387337ms)
Mar 25 18:06:36.890: INFO: (1) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 4.419337ms)
Mar 25 18:06:36.894: INFO: (2) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.133097ms)
Mar 25 18:06:36.894: INFO: (2) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 3.134095ms)
Mar 25 18:06:36.894: INFO: (2) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 3.393115ms)
Mar 25 18:06:36.894: INFO: (2) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 3.863733ms)
Mar 25 18:06:36.895: INFO: (2) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 4.275049ms)
Mar 25 18:06:36.895: INFO: (2) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 4.23277ms)
Mar 25 18:06:36.895: INFO: (2) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 4.269445ms)
Mar 25 18:06:36.895: INFO: (2) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 4.276981ms)
Mar 25 18:06:36.895: INFO: (2) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 4.336243ms)
Mar 25 18:06:36.895: INFO: (2) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 4.352789ms)
Mar 25 18:06:36.895: INFO: (2) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 4.414703ms)
Mar 25 18:06:36.895: INFO: (2) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 4.598972ms)
Mar 25 18:06:36.895: INFO: (2) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 4.634736ms)
Mar 25 18:06:36.896: INFO: (2) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 5.130411ms)
Mar 25 18:06:36.896: INFO: (2) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 5.606663ms)
Mar 25 18:06:36.896: INFO: (2) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 5.850655ms)
Mar 25 18:06:36.899: INFO: (3) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.093965ms)
Mar 25 18:06:36.900: INFO: (3) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 3.384776ms)
Mar 25 18:06:36.900: INFO: (3) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 3.841591ms)
Mar 25 18:06:36.900: INFO: (3) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.87979ms)
Mar 25 18:06:36.900: INFO: (3) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 3.995843ms)
Mar 25 18:06:36.900: INFO: (3) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 4.058249ms)
Mar 25 18:06:36.901: INFO: (3) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 4.527308ms)
Mar 25 18:06:36.901: INFO: (3) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 4.615446ms)
Mar 25 18:06:36.901: INFO: (3) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 4.678766ms)
Mar 25 18:06:36.901: INFO: (3) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 4.689696ms)
Mar 25 18:06:36.901: INFO: (3) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 4.761147ms)
Mar 25 18:06:36.901: INFO: (3) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 4.91612ms)
Mar 25 18:06:36.901: INFO: (3) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 4.976105ms)
Mar 25 18:06:36.901: INFO: (3) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 4.960305ms)
Mar 25 18:06:36.902: INFO: (3) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 5.405957ms)
Mar 25 18:06:36.902: INFO: (3) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 5.330184ms)
Mar 25 18:06:36.905: INFO: (4) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 2.671082ms)
Mar 25 18:06:36.905: INFO: (4) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 2.661152ms)
Mar 25 18:06:36.905: INFO: (4) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 2.873799ms)
Mar 25 18:06:36.905: INFO: (4) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 2.845872ms)
Mar 25 18:06:36.905: INFO: (4) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 3.312624ms)
Mar 25 18:06:36.905: INFO: (4) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.330389ms)
Mar 25 18:06:36.905: INFO: (4) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 3.618318ms)
Mar 25 18:06:36.906: INFO: (4) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 3.780356ms)
Mar 25 18:06:36.906: INFO: (4) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 3.863332ms)
Mar 25 18:06:36.906: INFO: (4) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 3.79703ms)
Mar 25 18:06:36.906: INFO: (4) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 3.8451ms)
Mar 25 18:06:36.906: INFO: (4) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 3.830852ms)
Mar 25 18:06:36.906: INFO: (4) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 3.89928ms)
Mar 25 18:06:36.906: INFO: (4) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 3.840015ms)
Mar 25 18:06:36.906: INFO: (4) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.840861ms)
Mar 25 18:06:36.906: INFO: (4) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 3.864375ms)
Mar 25 18:06:36.908: INFO: (5) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 2.025248ms)
Mar 25 18:06:36.908: INFO: (5) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 1.980638ms)
Mar 25 18:06:36.908: INFO: (5) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 1.949325ms)
Mar 25 18:06:36.908: INFO: (5) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 2.379388ms)
Mar 25 18:06:36.908: INFO: (5) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 1.943988ms)
Mar 25 18:06:36.909: INFO: (5) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 2.062663ms)
Mar 25 18:06:36.909: INFO: (5) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 2.107531ms)
Mar 25 18:06:36.909: INFO: (5) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 2.63199ms)
Mar 25 18:06:36.909: INFO: (5) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 2.710969ms)
Mar 25 18:06:36.909: INFO: (5) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 2.243533ms)
Mar 25 18:06:36.909: INFO: (5) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 2.664588ms)
Mar 25 18:06:36.912: INFO: (5) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 6.310545ms)
Mar 25 18:06:36.912: INFO: (5) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 5.920615ms)
Mar 25 18:06:36.912: INFO: (5) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 6.280062ms)
Mar 25 18:06:36.912: INFO: (5) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 5.88353ms)
Mar 25 18:06:36.912: INFO: (5) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 6.051005ms)
Mar 25 18:06:36.915: INFO: (6) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 2.91033ms)
Mar 25 18:06:36.917: INFO: (6) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 4.39371ms)
Mar 25 18:06:36.917: INFO: (6) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 4.714025ms)
Mar 25 18:06:36.917: INFO: (6) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 4.664084ms)
Mar 25 18:06:36.917: INFO: (6) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 4.634628ms)
Mar 25 18:06:36.917: INFO: (6) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 4.656165ms)
Mar 25 18:06:36.917: INFO: (6) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 4.758475ms)
Mar 25 18:06:36.917: INFO: (6) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 4.81614ms)
Mar 25 18:06:36.917: INFO: (6) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 4.817334ms)
Mar 25 18:06:36.917: INFO: (6) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 4.804802ms)
Mar 25 18:06:36.917: INFO: (6) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 4.793142ms)
Mar 25 18:06:36.917: INFO: (6) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 4.830524ms)
Mar 25 18:06:36.917: INFO: (6) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 4.848777ms)
Mar 25 18:06:36.917: INFO: (6) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 4.893283ms)
Mar 25 18:06:36.917: INFO: (6) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 4.935695ms)
Mar 25 18:06:36.918: INFO: (6) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 5.121742ms)
Mar 25 18:06:36.920: INFO: (7) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 2.566483ms)
Mar 25 18:06:36.920: INFO: (7) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 2.655971ms)
Mar 25 18:06:36.921: INFO: (7) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 3.070945ms)
Mar 25 18:06:36.921: INFO: (7) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 3.366877ms)
Mar 25 18:06:36.921: INFO: (7) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.407138ms)
Mar 25 18:06:36.921: INFO: (7) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.389721ms)
Mar 25 18:06:36.921: INFO: (7) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.492129ms)
Mar 25 18:06:36.921: INFO: (7) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 3.465116ms)
Mar 25 18:06:36.921: INFO: (7) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.415021ms)
Mar 25 18:06:36.921: INFO: (7) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 3.450925ms)
Mar 25 18:06:36.921: INFO: (7) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 3.485452ms)
Mar 25 18:06:36.922: INFO: (7) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 4.242621ms)
Mar 25 18:06:36.922: INFO: (7) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 4.309586ms)
Mar 25 18:06:36.922: INFO: (7) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 4.320041ms)
Mar 25 18:06:36.922: INFO: (7) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 4.366531ms)
Mar 25 18:06:36.922: INFO: (7) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 4.397677ms)
Mar 25 18:06:36.924: INFO: (8) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 2.056356ms)
Mar 25 18:06:36.925: INFO: (8) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 2.911624ms)
Mar 25 18:06:36.925: INFO: (8) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 2.947864ms)
Mar 25 18:06:36.925: INFO: (8) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 2.887542ms)
Mar 25 18:06:36.925: INFO: (8) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.039284ms)
Mar 25 18:06:36.925: INFO: (8) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 2.985411ms)
Mar 25 18:06:36.926: INFO: (8) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 3.581756ms)
Mar 25 18:06:36.926: INFO: (8) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 3.643319ms)
Mar 25 18:06:36.926: INFO: (8) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 3.622291ms)
Mar 25 18:06:36.926: INFO: (8) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.659424ms)
Mar 25 18:06:36.926: INFO: (8) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 3.824542ms)
Mar 25 18:06:36.926: INFO: (8) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 3.87052ms)
Mar 25 18:06:36.926: INFO: (8) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 4.012139ms)
Mar 25 18:06:36.926: INFO: (8) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 4.067864ms)
Mar 25 18:06:36.926: INFO: (8) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 4.057599ms)
Mar 25 18:06:36.927: INFO: (8) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 4.42459ms)
Mar 25 18:06:36.930: INFO: (9) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.533867ms)
Mar 25 18:06:36.930: INFO: (9) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 3.563633ms)
Mar 25 18:06:36.930: INFO: (9) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.497292ms)
Mar 25 18:06:36.930: INFO: (9) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 3.498122ms)
Mar 25 18:06:36.930: INFO: (9) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.54584ms)
Mar 25 18:06:36.930: INFO: (9) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 3.527541ms)
Mar 25 18:06:36.930: INFO: (9) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.535181ms)
Mar 25 18:06:36.930: INFO: (9) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 3.618647ms)
Mar 25 18:06:36.930: INFO: (9) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 3.541457ms)
Mar 25 18:06:36.930: INFO: (9) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 3.572874ms)
Mar 25 18:06:36.930: INFO: (9) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 3.544686ms)
Mar 25 18:06:36.931: INFO: (9) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 4.327314ms)
Mar 25 18:06:36.931: INFO: (9) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 4.39581ms)
Mar 25 18:06:36.931: INFO: (9) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 4.374056ms)
Mar 25 18:06:36.931: INFO: (9) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 4.317963ms)
Mar 25 18:06:36.932: INFO: (9) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 4.804622ms)
Mar 25 18:06:36.935: INFO: (10) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.788249ms)
Mar 25 18:06:36.935: INFO: (10) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 3.824388ms)
Mar 25 18:06:36.935: INFO: (10) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 3.828534ms)
Mar 25 18:06:36.935: INFO: (10) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.824086ms)
Mar 25 18:06:36.935: INFO: (10) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.911382ms)
Mar 25 18:06:36.936: INFO: (10) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 3.956182ms)
Mar 25 18:06:36.936: INFO: (10) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 3.884753ms)
Mar 25 18:06:36.936: INFO: (10) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 3.969733ms)
Mar 25 18:06:36.936: INFO: (10) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.89209ms)
Mar 25 18:06:36.936: INFO: (10) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 3.879427ms)
Mar 25 18:06:36.936: INFO: (10) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 4.286548ms)
Mar 25 18:06:36.936: INFO: (10) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 4.242387ms)
Mar 25 18:06:36.936: INFO: (10) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 4.235093ms)
Mar 25 18:06:36.936: INFO: (10) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 4.366279ms)
Mar 25 18:06:36.936: INFO: (10) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 4.294272ms)
Mar 25 18:06:36.936: INFO: (10) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 4.417316ms)
Mar 25 18:06:36.939: INFO: (11) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.076673ms)
Mar 25 18:06:36.939: INFO: (11) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.023039ms)
Mar 25 18:06:36.939: INFO: (11) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.033781ms)
Mar 25 18:06:36.939: INFO: (11) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 3.160186ms)
Mar 25 18:06:36.939: INFO: (11) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 3.201571ms)
Mar 25 18:06:36.940: INFO: (11) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 3.590448ms)
Mar 25 18:06:36.940: INFO: (11) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 3.671922ms)
Mar 25 18:06:36.940: INFO: (11) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 3.67577ms)
Mar 25 18:06:36.940: INFO: (11) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 3.666792ms)
Mar 25 18:06:36.940: INFO: (11) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.69855ms)
Mar 25 18:06:36.940: INFO: (11) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 3.950175ms)
Mar 25 18:06:36.940: INFO: (11) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 3.930196ms)
Mar 25 18:06:36.940: INFO: (11) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 4.073217ms)
Mar 25 18:06:36.940: INFO: (11) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 4.143787ms)
Mar 25 18:06:36.940: INFO: (11) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 4.161365ms)
Mar 25 18:06:36.940: INFO: (11) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 4.460158ms)
Mar 25 18:06:36.944: INFO: (12) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.397335ms)
Mar 25 18:06:36.944: INFO: (12) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 3.287155ms)
Mar 25 18:06:36.944: INFO: (12) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.284372ms)
Mar 25 18:06:36.944: INFO: (12) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 3.370872ms)
Mar 25 18:06:36.944: INFO: (12) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.27594ms)
Mar 25 18:06:36.944: INFO: (12) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 3.374021ms)
Mar 25 18:06:36.944: INFO: (12) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 3.563895ms)
Mar 25 18:06:36.944: INFO: (12) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 3.649548ms)
Mar 25 18:06:36.944: INFO: (12) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.8066ms)
Mar 25 18:06:36.944: INFO: (12) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 3.904266ms)
Mar 25 18:06:36.945: INFO: (12) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 4.568335ms)
Mar 25 18:06:36.945: INFO: (12) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 4.720527ms)
Mar 25 18:06:36.945: INFO: (12) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 4.805821ms)
Mar 25 18:06:36.945: INFO: (12) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 4.78542ms)
Mar 25 18:06:36.946: INFO: (12) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 5.269394ms)
Mar 25 18:06:36.946: INFO: (12) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 5.233939ms)
Mar 25 18:06:36.950: INFO: (13) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 3.352721ms)
Mar 25 18:06:36.951: INFO: (13) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 5.065156ms)
Mar 25 18:06:36.951: INFO: (13) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 4.669624ms)
Mar 25 18:06:36.951: INFO: (13) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 4.970812ms)
Mar 25 18:06:36.951: INFO: (13) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 4.91141ms)
Mar 25 18:06:36.951: INFO: (13) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 4.177129ms)
Mar 25 18:06:36.951: INFO: (13) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 4.471286ms)
Mar 25 18:06:36.951: INFO: (13) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 4.409826ms)
Mar 25 18:06:36.951: INFO: (13) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 4.595004ms)
Mar 25 18:06:36.951: INFO: (13) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 4.777696ms)
Mar 25 18:06:36.951: INFO: (13) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 4.663319ms)
Mar 25 18:06:36.951: INFO: (13) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 4.565431ms)
Mar 25 18:06:36.951: INFO: (13) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 4.60715ms)
Mar 25 18:06:36.951: INFO: (13) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 5.200373ms)
Mar 25 18:06:36.951: INFO: (13) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 4.579023ms)
Mar 25 18:06:36.951: INFO: (13) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 4.698792ms)
Mar 25 18:06:36.953: INFO: (14) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 1.813758ms)
Mar 25 18:06:36.956: INFO: (14) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 3.620761ms)
Mar 25 18:06:36.956: INFO: (14) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 3.976483ms)
Mar 25 18:06:36.956: INFO: (14) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 3.923909ms)
Mar 25 18:06:36.956: INFO: (14) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.469278ms)
Mar 25 18:06:36.956: INFO: (14) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 4.19245ms)
Mar 25 18:06:36.956: INFO: (14) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 4.344462ms)
Mar 25 18:06:36.956: INFO: (14) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 3.705166ms)
Mar 25 18:06:36.956: INFO: (14) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 3.664718ms)
Mar 25 18:06:36.956: INFO: (14) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 3.784792ms)
Mar 25 18:06:36.956: INFO: (14) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 4.038895ms)
Mar 25 18:06:36.956: INFO: (14) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 3.930987ms)
Mar 25 18:06:36.956: INFO: (14) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 4.502613ms)
Mar 25 18:06:36.956: INFO: (14) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.85746ms)
Mar 25 18:06:36.956: INFO: (14) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 4.377206ms)
Mar 25 18:06:36.957: INFO: (14) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 4.119462ms)
Mar 25 18:06:36.959: INFO: (15) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 2.069999ms)
Mar 25 18:06:36.960: INFO: (15) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 2.926255ms)
Mar 25 18:06:36.960: INFO: (15) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 3.108415ms)
Mar 25 18:06:36.960: INFO: (15) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 3.183039ms)
Mar 25 18:06:36.960: INFO: (15) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.337178ms)
Mar 25 18:06:36.960: INFO: (15) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 3.313366ms)
Mar 25 18:06:36.960: INFO: (15) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 3.500022ms)
Mar 25 18:06:36.960: INFO: (15) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.519911ms)
Mar 25 18:06:36.960: INFO: (15) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 3.556356ms)
Mar 25 18:06:36.960: INFO: (15) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 3.589416ms)
Mar 25 18:06:36.960: INFO: (15) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 3.640197ms)
Mar 25 18:06:36.960: INFO: (15) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 3.815826ms)
Mar 25 18:06:36.960: INFO: (15) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 3.76632ms)
Mar 25 18:06:36.960: INFO: (15) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 3.852774ms)
Mar 25 18:06:36.960: INFO: (15) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.77155ms)
Mar 25 18:06:36.961: INFO: (15) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 4.317607ms)
Mar 25 18:06:36.966: INFO: (16) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 4.931013ms)
Mar 25 18:06:36.966: INFO: (16) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 4.753473ms)
Mar 25 18:06:36.966: INFO: (16) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 4.814701ms)
Mar 25 18:06:36.966: INFO: (16) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 4.901257ms)
Mar 25 18:06:36.966: INFO: (16) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 4.839589ms)
Mar 25 18:06:36.966: INFO: (16) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 5.003221ms)
Mar 25 18:06:36.966: INFO: (16) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 4.88989ms)
Mar 25 18:06:36.966: INFO: (16) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 4.849942ms)
Mar 25 18:06:36.966: INFO: (16) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 4.917588ms)
Mar 25 18:06:36.966: INFO: (16) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 4.894077ms)
Mar 25 18:06:36.966: INFO: (16) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 4.961995ms)
Mar 25 18:06:36.966: INFO: (16) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 5.017908ms)
Mar 25 18:06:36.966: INFO: (16) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 5.036403ms)
Mar 25 18:06:36.966: INFO: (16) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 5.008823ms)
Mar 25 18:06:36.966: INFO: (16) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 5.01162ms)
Mar 25 18:06:36.966: INFO: (16) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 4.967812ms)
Mar 25 18:06:36.969: INFO: (17) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 2.817218ms)
Mar 25 18:06:36.969: INFO: (17) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 2.779721ms)
Mar 25 18:06:36.969: INFO: (17) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 2.373676ms)
Mar 25 18:06:36.969: INFO: (17) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 2.612157ms)
Mar 25 18:06:36.969: INFO: (17) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 2.666165ms)
Mar 25 18:06:36.969: INFO: (17) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 2.79008ms)
Mar 25 18:06:36.969: INFO: (17) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 3.281334ms)
Mar 25 18:06:36.969: INFO: (17) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 2.75229ms)
Mar 25 18:06:36.969: INFO: (17) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 3.177034ms)
Mar 25 18:06:36.970: INFO: (17) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 2.666065ms)
Mar 25 18:06:36.970: INFO: (17) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 3.63083ms)
Mar 25 18:06:36.971: INFO: (17) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 4.324319ms)
Mar 25 18:06:36.971: INFO: (17) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 3.827827ms)
Mar 25 18:06:36.971: INFO: (17) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 4.40293ms)
Mar 25 18:06:36.971: INFO: (17) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 3.894285ms)
Mar 25 18:06:36.971: INFO: (17) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 4.297697ms)
Mar 25 18:06:36.974: INFO: (18) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 2.793721ms)
Mar 25 18:06:36.974: INFO: (18) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 2.931887ms)
Mar 25 18:06:36.974: INFO: (18) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.404625ms)
Mar 25 18:06:36.974: INFO: (18) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.602094ms)
Mar 25 18:06:36.974: INFO: (18) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.647734ms)
Mar 25 18:06:36.975: INFO: (18) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 3.687761ms)
Mar 25 18:06:36.975: INFO: (18) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 3.827309ms)
Mar 25 18:06:36.975: INFO: (18) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.718481ms)
Mar 25 18:06:36.975: INFO: (18) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 3.862677ms)
Mar 25 18:06:36.975: INFO: (18) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 4.01745ms)
Mar 25 18:06:36.975: INFO: (18) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 4.12231ms)
Mar 25 18:06:36.975: INFO: (18) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 4.062503ms)
Mar 25 18:06:36.975: INFO: (18) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 4.085496ms)
Mar 25 18:06:36.975: INFO: (18) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 4.043201ms)
Mar 25 18:06:36.975: INFO: (18) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 4.080796ms)
Mar 25 18:06:36.975: INFO: (18) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 4.118615ms)
Mar 25 18:06:36.978: INFO: (19) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 3.377415ms)
Mar 25 18:06:36.978: INFO: (19) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt/proxy/rewriteme">test</a> (200; 3.384995ms)
Mar 25 18:06:36.978: INFO: (19) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 3.39975ms)
Mar 25 18:06:36.978: INFO: (19) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">test</... (200; 3.407251ms)
Mar 25 18:06:36.979: INFO: (19) /api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/http:proxy-service-slbtm-mb6nt:1080/proxy/rewriteme">t... (200; 3.500835ms)
Mar 25 18:06:36.979: INFO: (19) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:162/proxy/: bar (200; 4.220511ms)
Mar 25 18:06:36.979: INFO: (19) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/: <a href="/api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:443/proxy/tlsrewriteme... (200; 4.256072ms)
Mar 25 18:06:36.979: INFO: (19) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:460/proxy/: tls baz (200; 4.268896ms)
Mar 25 18:06:36.979: INFO: (19) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname2/proxy/: bar (200; 4.320981ms)
Mar 25 18:06:36.979: INFO: (19) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname2/proxy/: bar (200; 4.270876ms)
Mar 25 18:06:36.979: INFO: (19) /api/v1/namespaces/proxy-427/pods/proxy-service-slbtm-mb6nt:160/proxy/: foo (200; 4.313715ms)
Mar 25 18:06:36.979: INFO: (19) /api/v1/namespaces/proxy-427/services/proxy-service-slbtm:portname1/proxy/: foo (200; 4.308081ms)
Mar 25 18:06:36.979: INFO: (19) /api/v1/namespaces/proxy-427/pods/https:proxy-service-slbtm-mb6nt:462/proxy/: tls qux (200; 4.334789ms)
Mar 25 18:06:36.979: INFO: (19) /api/v1/namespaces/proxy-427/services/http:proxy-service-slbtm:portname1/proxy/: foo (200; 4.360384ms)
Mar 25 18:06:36.979: INFO: (19) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname1/proxy/: tls baz (200; 4.380117ms)
Mar 25 18:06:36.979: INFO: (19) /api/v1/namespaces/proxy-427/services/https:proxy-service-slbtm:tlsportname2/proxy/: tls qux (200; 4.422929ms)
[1mSTEP[0m: deleting ReplicationController proxy-service-slbtm in namespace proxy-427, will wait for the garbage collector to delete the pods
Mar 25 18:06:37.036: INFO: Deleting ReplicationController proxy-service-slbtm took: 4.625362ms
Mar 25 18:06:37.336: INFO: Terminating ReplicationController proxy-service-slbtm pods took: 300.195957ms
[AfterEach] version v1
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:06:48.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "proxy-427" for this suite.
Mar 25 18:06:54.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:06:54.615: INFO: namespace proxy-427 deletion completed in 6.076089106s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] Downward API[0m 
  [1mshould provide pod UID as env vars [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-node] Downward API
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:06:54.615: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward api env vars
Mar 25 18:06:54.649: INFO: Waiting up to 5m0s for pod "downward-api-721e64d8-4f63-11e9-91ba-a08cfdecc127" in namespace "downward-api-4429" to be "success or failure"
Mar 25 18:06:54.651: INFO: Pod "downward-api-721e64d8-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.610621ms
Mar 25 18:06:56.654: INFO: Pod "downward-api-721e64d8-4f63-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004524962s
[1mSTEP[0m: Saw pod success
Mar 25 18:06:56.654: INFO: Pod "downward-api-721e64d8-4f63-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:06:56.656: INFO: Trying to get logs from node conformance-worker2 pod downward-api-721e64d8-4f63-11e9-91ba-a08cfdecc127 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:06:56.672: INFO: Waiting for pod downward-api-721e64d8-4f63-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:06:56.675: INFO: Pod downward-api-721e64d8-4f63-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-node] Downward API
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:06:56.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-4429" for this suite.
Mar 25 18:07:02.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:07:02.754: INFO: namespace downward-api-4429 deletion completed in 6.076276447s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Lifecycle Hook[0m [90mwhen create a pod with lifecycle hook[0m 
  [1mshould execute prestop http hook properly [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:07:02.754: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename container-lifecycle-hook
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
[1mSTEP[0m: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: create the pod with lifecycle hook
[1mSTEP[0m: delete the pod with lifecycle hook
Mar 25 18:07:08.814: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 25 18:07:08.816: INFO: Pod pod-with-prestop-http-hook still exists
Mar 25 18:07:10.816: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 25 18:07:10.820: INFO: Pod pod-with-prestop-http-hook still exists
Mar 25 18:07:12.816: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 25 18:07:12.820: INFO: Pod pod-with-prestop-http-hook still exists
Mar 25 18:07:14.816: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 25 18:07:14.820: INFO: Pod pod-with-prestop-http-hook still exists
Mar 25 18:07:16.816: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 25 18:07:16.820: INFO: Pod pod-with-prestop-http-hook still exists
Mar 25 18:07:18.816: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 25 18:07:18.820: INFO: Pod pod-with-prestop-http-hook no longer exists
[1mSTEP[0m: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:07:18.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-lifecycle-hook-791" for this suite.
Mar 25 18:07:40.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:07:40.902: INFO: namespace container-lifecycle-hook-791 deletion completed in 22.06993922s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould be able to start watching from a specific resource version [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-api-machinery] Watchers
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:07:40.903: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename watch
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating a new configmap
[1mSTEP[0m: modifying the configmap once
[1mSTEP[0m: modifying the configmap a second time
[1mSTEP[0m: deleting the configmap
[1mSTEP[0m: creating a watch on configmaps from the resource version returned by the first update
[1mSTEP[0m: Expecting to observe notifications for all changes to the configmap after the first update
Mar 25 18:07:40.947: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7573,SelfLink:/api/v1/namespaces/watch-7573/configmaps/e2e-watch-test-resource-version,UID:8db56aef-4f63-11e9-8304-02427cbbc9a0,ResourceVersion:9237,Generation:0,CreationTimestamp:2019-03-25 18:07:40 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 25 18:07:40.947: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7573,SelfLink:/api/v1/namespaces/watch-7573/configmaps/e2e-watch-test-resource-version,UID:8db56aef-4f63-11e9-8304-02427cbbc9a0,ResourceVersion:9238,Generation:0,CreationTimestamp:2019-03-25 18:07:40 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:07:40.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "watch-7573" for this suite.
Mar 25 18:07:46.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:07:47.031: INFO: namespace watch-7573 deletion completed in 6.083024557s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Services[0m 
  [1mshould serve a basic endpoint from pods  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-network] Services
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:07:47.033: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename services
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating service endpoint-test2 in namespace services-4243
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace services-4243 to expose endpoints map[]
Mar 25 18:07:47.072: INFO: Get endpoints failed (1.835276ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Mar 25 18:07:48.076: INFO: successfully validated that service endpoint-test2 in namespace services-4243 exposes endpoints map[] (1.004971889s elapsed)
[1mSTEP[0m: Creating pod pod1 in namespace services-4243
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace services-4243 to expose endpoints map[pod1:[80]]
Mar 25 18:07:51.110: INFO: successfully validated that service endpoint-test2 in namespace services-4243 exposes endpoints map[pod1:[80]] (3.02789248s elapsed)
[1mSTEP[0m: Creating pod pod2 in namespace services-4243
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace services-4243 to expose endpoints map[pod1:[80] pod2:[80]]
Mar 25 18:07:53.143: INFO: successfully validated that service endpoint-test2 in namespace services-4243 exposes endpoints map[pod1:[80] pod2:[80]] (2.027472517s elapsed)
[1mSTEP[0m: Deleting pod pod1 in namespace services-4243
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace services-4243 to expose endpoints map[pod2:[80]]
Mar 25 18:07:53.164: INFO: successfully validated that service endpoint-test2 in namespace services-4243 exposes endpoints map[pod2:[80]] (16.33498ms elapsed)
[1mSTEP[0m: Deleting pod pod2 in namespace services-4243
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace services-4243 to expose endpoints map[]
Mar 25 18:07:54.172: INFO: successfully validated that service endpoint-test2 in namespace services-4243 exposes endpoints map[] (1.004894512s elapsed)
[AfterEach] [sig-network] Services
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:07:54.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "services-4243" for this suite.
Mar 25 18:08:00.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:08:00.271: INFO: namespace services-4243 deletion completed in 6.077863032s
[AfterEach] [sig-network] Services
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Secrets[0m 
  [1mshould be consumable via the environment [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-api-machinery] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:08:00.271: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating secret secrets-7085/secret-test-99405300-4f63-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 25 18:08:00.311: INFO: Waiting up to 5m0s for pod "pod-configmaps-9940bb19-4f63-11e9-91ba-a08cfdecc127" in namespace "secrets-7085" to be "success or failure"
Mar 25 18:08:00.313: INFO: Pod "pod-configmaps-9940bb19-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.068561ms
Mar 25 18:08:02.316: INFO: Pod "pod-configmaps-9940bb19-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004856247s
Mar 25 18:08:04.320: INFO: Pod "pod-configmaps-9940bb19-4f63-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008763521s
[1mSTEP[0m: Saw pod success
Mar 25 18:08:04.320: INFO: Pod "pod-configmaps-9940bb19-4f63-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:08:04.323: INFO: Trying to get logs from node conformance-worker pod pod-configmaps-9940bb19-4f63-11e9-91ba-a08cfdecc127 container env-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:08:04.340: INFO: Waiting for pod pod-configmaps-9940bb19-4f63-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:08:04.341: INFO: Pod pod-configmaps-9940bb19-4f63-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:08:04.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "secrets-7085" for this suite.
Mar 25 18:08:10.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:08:10.416: INFO: namespace secrets-7085 deletion completed in 6.072294558s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mBurst scaling should run to completion even with unhealthy pods [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:08:10.417: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace statefulset-5099
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating stateful set ss in namespace statefulset-5099
[1mSTEP[0m: Waiting until all stateful set ss replicas will be running in namespace statefulset-5099
Mar 25 18:08:10.458: INFO: Found 0 stateful pods, waiting for 1
Mar 25 18:08:20.462: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar 25 18:08:20.465: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-5099 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 18:08:20.724: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 18:08:20.724: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 18:08:20.724: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 18:08:20.726: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 25 18:08:30.731: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 25 18:08:30.731: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 18:08:30.743: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Mar 25 18:08:30.743: INFO: ss-0  conformance-worker2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:10 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:21 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:21 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:10 -0700 PDT  }]
Mar 25 18:08:30.743: INFO: 
Mar 25 18:08:30.743: INFO: StatefulSet ss has not reached scale 3, at 1
Mar 25 18:08:31.747: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99715912s
Mar 25 18:08:32.751: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993375177s
Mar 25 18:08:33.755: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989100919s
Mar 25 18:08:34.760: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.985097034s
Mar 25 18:08:35.766: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.98022325s
Mar 25 18:08:36.771: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973919933s
Mar 25 18:08:37.775: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.969570567s
Mar 25 18:08:38.780: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.964903577s
Mar 25 18:08:39.784: INFO: Verifying statefulset ss doesn't scale past 3 for another 960.659248ms
[1mSTEP[0m: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5099
Mar 25 18:08:40.788: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-5099 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 18:08:41.037: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar 25 18:08:41.037: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 18:08:41.037: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 18:08:41.037: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-5099 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 18:08:41.264: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Mar 25 18:08:41.264: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 18:08:41.264: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 18:08:41.264: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-5099 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 18:08:41.509: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Mar 25 18:08:41.509: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 18:08:41.509: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 18:08:41.512: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 18:08:41.512: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 18:08:41.512: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Scale down will not halt with unhealthy stateful pod
Mar 25 18:08:41.514: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-5099 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 18:08:41.743: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 18:08:41.743: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 18:08:41.743: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 18:08:41.744: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-5099 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 18:08:41.986: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 18:08:41.986: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 18:08:41.986: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 18:08:41.986: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-5099 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 18:08:42.235: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 18:08:42.235: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 18:08:42.235: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 18:08:42.235: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 18:08:42.238: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar 25 18:08:52.246: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 25 18:08:52.246: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 25 18:08:52.246: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 25 18:08:52.256: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Mar 25 18:08:52.256: INFO: ss-0  conformance-worker2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:10 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:10 -0700 PDT  }]
Mar 25 18:08:52.256: INFO: ss-1  conformance-worker   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  }]
Mar 25 18:08:52.256: INFO: ss-2  conformance-worker2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  }]
Mar 25 18:08:52.256: INFO: 
Mar 25 18:08:52.256: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 25 18:08:53.260: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Mar 25 18:08:53.260: INFO: ss-0  conformance-worker2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:10 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:10 -0700 PDT  }]
Mar 25 18:08:53.260: INFO: ss-1  conformance-worker   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  }]
Mar 25 18:08:53.260: INFO: ss-2  conformance-worker2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  }]
Mar 25 18:08:53.260: INFO: 
Mar 25 18:08:53.260: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 25 18:08:54.265: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Mar 25 18:08:54.265: INFO: ss-0  conformance-worker2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:10 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:10 -0700 PDT  }]
Mar 25 18:08:54.265: INFO: ss-1  conformance-worker   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  }]
Mar 25 18:08:54.265: INFO: ss-2  conformance-worker2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  }]
Mar 25 18:08:54.265: INFO: 
Mar 25 18:08:54.265: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 25 18:08:55.270: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Mar 25 18:08:55.270: INFO: ss-0  conformance-worker2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:10 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:10 -0700 PDT  }]
Mar 25 18:08:55.270: INFO: ss-1  conformance-worker   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  }]
Mar 25 18:08:55.270: INFO: ss-2  conformance-worker2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  }]
Mar 25 18:08:55.270: INFO: 
Mar 25 18:08:55.270: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 25 18:08:56.273: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Mar 25 18:08:56.274: INFO: ss-0  conformance-worker2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:10 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:10 -0700 PDT  }]
Mar 25 18:08:56.274: INFO: ss-1  conformance-worker   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  }]
Mar 25 18:08:56.274: INFO: ss-2  conformance-worker2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  }]
Mar 25 18:08:56.274: INFO: 
Mar 25 18:08:56.274: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 25 18:08:57.278: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Mar 25 18:08:57.278: INFO: ss-0  conformance-worker2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:10 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:10 -0700 PDT  }]
Mar 25 18:08:57.278: INFO: ss-1  conformance-worker   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  }]
Mar 25 18:08:57.278: INFO: ss-2  conformance-worker2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  }]
Mar 25 18:08:57.278: INFO: 
Mar 25 18:08:57.278: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 25 18:08:58.282: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Mar 25 18:08:58.282: INFO: ss-0  conformance-worker2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:10 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:10 -0700 PDT  }]
Mar 25 18:08:58.282: INFO: ss-1  conformance-worker   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  }]
Mar 25 18:08:58.282: INFO: ss-2  conformance-worker2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:42 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:08:30 -0700 PDT  }]
Mar 25 18:08:58.282: INFO: 
Mar 25 18:08:58.282: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 25 18:08:59.286: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.969789903s
Mar 25 18:09:00.290: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.96566913s
Mar 25 18:09:01.293: INFO: Verifying statefulset ss doesn't scale past 0 for another 962.078083ms
[1mSTEP[0m: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5099
Mar 25 18:09:02.296: INFO: Scaling statefulset ss to 0
Mar 25 18:09:02.304: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 25 18:09:02.307: INFO: Deleting all statefulset in ns statefulset-5099
Mar 25 18:09:02.309: INFO: Scaling statefulset ss to 0
Mar 25 18:09:02.314: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 18:09:02.316: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:09:02.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "statefulset-5099" for this suite.
Mar 25 18:09:08.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:09:08.393: INFO: namespace statefulset-5099 deletion completed in 6.068676591s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:09:08.393: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating secret with name secret-test-c1db185d-4f63-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 25 18:09:08.427: INFO: Waiting up to 5m0s for pod "pod-secrets-c1db60e6-4f63-11e9-91ba-a08cfdecc127" in namespace "secrets-720" to be "success or failure"
Mar 25 18:09:08.431: INFO: Pod "pod-secrets-c1db60e6-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.690181ms
Mar 25 18:09:10.435: INFO: Pod "pod-secrets-c1db60e6-4f63-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007591822s
[1mSTEP[0m: Saw pod success
Mar 25 18:09:10.435: INFO: Pod "pod-secrets-c1db60e6-4f63-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:09:10.438: INFO: Trying to get logs from node conformance-worker pod pod-secrets-c1db60e6-4f63-11e9-91ba-a08cfdecc127 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:09:10.456: INFO: Waiting for pod pod-secrets-c1db60e6-4f63-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:09:10.458: INFO: Pod pod-secrets-c1db60e6-4f63-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:09:10.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "secrets-720" for this suite.
Mar 25 18:09:16.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:09:16.531: INFO: namespace secrets-720 deletion completed in 6.071541361s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:09:16.532: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating secret with name secret-test-map-c6b5513f-4f63-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 25 18:09:16.569: INFO: Waiting up to 5m0s for pod "pod-secrets-c6b5a7fd-4f63-11e9-91ba-a08cfdecc127" in namespace "secrets-6079" to be "success or failure"
Mar 25 18:09:16.571: INFO: Pod "pod-secrets-c6b5a7fd-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.890813ms
Mar 25 18:09:18.574: INFO: Pod "pod-secrets-c6b5a7fd-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005068591s
Mar 25 18:09:20.578: INFO: Pod "pod-secrets-c6b5a7fd-4f63-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00904665s
[1mSTEP[0m: Saw pod success
Mar 25 18:09:20.578: INFO: Pod "pod-secrets-c6b5a7fd-4f63-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:09:20.581: INFO: Trying to get logs from node conformance-worker2 pod pod-secrets-c6b5a7fd-4f63-11e9-91ba-a08cfdecc127 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:09:20.599: INFO: Waiting for pod pod-secrets-c6b5a7fd-4f63-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:09:20.601: INFO: Pod pod-secrets-c6b5a7fd-4f63-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:09:20.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "secrets-6079" for this suite.
Mar 25 18:09:26.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:09:26.687: INFO: namespace secrets-6079 deletion completed in 6.076254737s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide container's cpu request [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:09:26.687: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 18:09:26.728: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ccc2c70b-4f63-11e9-91ba-a08cfdecc127" in namespace "projected-3849" to be "success or failure"
Mar 25 18:09:26.730: INFO: Pod "downwardapi-volume-ccc2c70b-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.474471ms
Mar 25 18:09:28.733: INFO: Pod "downwardapi-volume-ccc2c70b-4f63-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005246553s
[1mSTEP[0m: Saw pod success
Mar 25 18:09:28.733: INFO: Pod "downwardapi-volume-ccc2c70b-4f63-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:09:28.736: INFO: Trying to get logs from node conformance-worker pod downwardapi-volume-ccc2c70b-4f63-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:09:28.752: INFO: Waiting for pod downwardapi-volume-ccc2c70b-4f63-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:09:28.754: INFO: Pod downwardapi-volume-ccc2c70b-4f63-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:09:28.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-3849" for this suite.
Mar 25 18:09:34.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:09:34.823: INFO: namespace projected-3849 deletion completed in 6.067527926s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Service endpoints latency[0m 
  [1mshould not be very high  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-network] Service endpoints latency
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:09:34.823: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename svc-latency
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating replication controller svc-latency-rc in namespace svc-latency-8296
I0325 18:09:34.857415   72333 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8296, replica count: 1
I0325 18:09:35.907711   72333 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0325 18:09:36.907877   72333 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0325 18:09:37.908068   72333 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 25 18:09:38.019: INFO: Created: latency-svc-5lzmq
Mar 25 18:09:38.022: INFO: Got endpoints: latency-svc-5lzmq [14.078778ms]
Mar 25 18:09:38.036: INFO: Created: latency-svc-qfgqq
Mar 25 18:09:38.058: INFO: Got endpoints: latency-svc-qfgqq [36.454706ms]
Mar 25 18:09:38.059: INFO: Created: latency-svc-6q8xh
Mar 25 18:09:38.062: INFO: Got endpoints: latency-svc-6q8xh [40.197846ms]
Mar 25 18:09:38.078: INFO: Created: latency-svc-4dtgv
Mar 25 18:09:38.084: INFO: Got endpoints: latency-svc-4dtgv [61.582577ms]
Mar 25 18:09:38.092: INFO: Created: latency-svc-897m7
Mar 25 18:09:38.093: INFO: Got endpoints: latency-svc-897m7 [70.658522ms]
Mar 25 18:09:38.115: INFO: Created: latency-svc-6sjpv
Mar 25 18:09:38.118: INFO: Got endpoints: latency-svc-6sjpv [96.092413ms]
Mar 25 18:09:38.127: INFO: Created: latency-svc-mm2pj
Mar 25 18:09:38.132: INFO: Got endpoints: latency-svc-mm2pj [109.902961ms]
Mar 25 18:09:38.140: INFO: Created: latency-svc-dcmgq
Mar 25 18:09:38.148: INFO: Got endpoints: latency-svc-dcmgq [125.638847ms]
Mar 25 18:09:38.151: INFO: Created: latency-svc-j7cpf
Mar 25 18:09:38.157: INFO: Got endpoints: latency-svc-j7cpf [134.409946ms]
Mar 25 18:09:38.169: INFO: Created: latency-svc-bf9hk
Mar 25 18:09:38.172: INFO: Got endpoints: latency-svc-bf9hk [149.673397ms]
Mar 25 18:09:38.179: INFO: Created: latency-svc-25t7x
Mar 25 18:09:38.181: INFO: Got endpoints: latency-svc-25t7x [159.253653ms]
Mar 25 18:09:38.200: INFO: Created: latency-svc-g2xcq
Mar 25 18:09:38.206: INFO: Got endpoints: latency-svc-g2xcq [183.900126ms]
Mar 25 18:09:38.222: INFO: Created: latency-svc-wszs5
Mar 25 18:09:38.243: INFO: Got endpoints: latency-svc-wszs5 [221.342039ms]
Mar 25 18:09:38.245: INFO: Created: latency-svc-45whz
Mar 25 18:09:38.247: INFO: Got endpoints: latency-svc-45whz [224.980264ms]
Mar 25 18:09:38.259: INFO: Created: latency-svc-lz6x8
Mar 25 18:09:38.262: INFO: Got endpoints: latency-svc-lz6x8 [240.142952ms]
Mar 25 18:09:38.269: INFO: Created: latency-svc-pbbqn
Mar 25 18:09:38.271: INFO: Got endpoints: latency-svc-pbbqn [248.865354ms]
Mar 25 18:09:38.285: INFO: Created: latency-svc-r6lmt
Mar 25 18:09:38.289: INFO: Got endpoints: latency-svc-r6lmt [230.666441ms]
Mar 25 18:09:38.297: INFO: Created: latency-svc-q9xx9
Mar 25 18:09:38.303: INFO: Got endpoints: latency-svc-q9xx9 [240.557604ms]
Mar 25 18:09:38.312: INFO: Created: latency-svc-55dwk
Mar 25 18:09:38.318: INFO: Got endpoints: latency-svc-55dwk [234.088596ms]
Mar 25 18:09:38.326: INFO: Created: latency-svc-2bgqn
Mar 25 18:09:38.342: INFO: Got endpoints: latency-svc-2bgqn [248.88691ms]
Mar 25 18:09:38.342: INFO: Created: latency-svc-9bv2c
Mar 25 18:09:38.358: INFO: Got endpoints: latency-svc-9bv2c [239.986653ms]
Mar 25 18:09:38.360: INFO: Created: latency-svc-q64bp
Mar 25 18:09:38.364: INFO: Got endpoints: latency-svc-q64bp [232.043441ms]
Mar 25 18:09:38.370: INFO: Created: latency-svc-9ppn8
Mar 25 18:09:38.372: INFO: Got endpoints: latency-svc-9ppn8 [224.0022ms]
Mar 25 18:09:38.381: INFO: Created: latency-svc-qffvk
Mar 25 18:09:38.384: INFO: Got endpoints: latency-svc-qffvk [227.107756ms]
Mar 25 18:09:38.395: INFO: Created: latency-svc-hd546
Mar 25 18:09:38.404: INFO: Got endpoints: latency-svc-hd546 [232.555347ms]
Mar 25 18:09:38.407: INFO: Created: latency-svc-vkkss
Mar 25 18:09:38.407: INFO: Got endpoints: latency-svc-vkkss [225.4716ms]
Mar 25 18:09:38.414: INFO: Created: latency-svc-vwsxx
Mar 25 18:09:38.419: INFO: Got endpoints: latency-svc-vwsxx [212.451567ms]
Mar 25 18:09:38.428: INFO: Created: latency-svc-wdvg9
Mar 25 18:09:38.430: INFO: Got endpoints: latency-svc-wdvg9 [186.532967ms]
Mar 25 18:09:38.439: INFO: Created: latency-svc-fgrnr
Mar 25 18:09:38.442: INFO: Got endpoints: latency-svc-fgrnr [194.412427ms]
Mar 25 18:09:38.453: INFO: Created: latency-svc-9dss5
Mar 25 18:09:38.472: INFO: Got endpoints: latency-svc-9dss5 [209.905816ms]
Mar 25 18:09:38.473: INFO: Created: latency-svc-pxt6k
Mar 25 18:09:38.485: INFO: Got endpoints: latency-svc-pxt6k [214.169511ms]
Mar 25 18:09:38.486: INFO: Created: latency-svc-vd84p
Mar 25 18:09:38.494: INFO: Got endpoints: latency-svc-vd84p [204.666643ms]
Mar 25 18:09:38.506: INFO: Created: latency-svc-2vkwg
Mar 25 18:09:38.514: INFO: Got endpoints: latency-svc-2vkwg [210.95884ms]
Mar 25 18:09:38.523: INFO: Created: latency-svc-f8kbg
Mar 25 18:09:38.531: INFO: Got endpoints: latency-svc-f8kbg [213.70867ms]
Mar 25 18:09:38.532: INFO: Created: latency-svc-4xbhk
Mar 25 18:09:38.534: INFO: Got endpoints: latency-svc-4xbhk [192.207281ms]
Mar 25 18:09:38.541: INFO: Created: latency-svc-k9fzb
Mar 25 18:09:38.550: INFO: Got endpoints: latency-svc-k9fzb [192.019179ms]
Mar 25 18:09:38.558: INFO: Created: latency-svc-7m52x
Mar 25 18:09:38.561: INFO: Got endpoints: latency-svc-7m52x [197.175362ms]
Mar 25 18:09:38.569: INFO: Created: latency-svc-tqnxn
Mar 25 18:09:38.593: INFO: Got endpoints: latency-svc-tqnxn [220.728031ms]
Mar 25 18:09:38.595: INFO: Created: latency-svc-krwd2
Mar 25 18:09:38.599: INFO: Got endpoints: latency-svc-krwd2 [215.01634ms]
Mar 25 18:09:38.610: INFO: Created: latency-svc-xwdfm
Mar 25 18:09:38.621: INFO: Got endpoints: latency-svc-xwdfm [216.588138ms]
Mar 25 18:09:38.621: INFO: Created: latency-svc-kv9jt
Mar 25 18:09:38.623: INFO: Got endpoints: latency-svc-kv9jt [215.735006ms]
Mar 25 18:09:38.630: INFO: Created: latency-svc-z7h7g
Mar 25 18:09:38.634: INFO: Got endpoints: latency-svc-z7h7g [215.546174ms]
Mar 25 18:09:38.642: INFO: Created: latency-svc-fmvp7
Mar 25 18:09:38.661: INFO: Created: latency-svc-n92xv
Mar 25 18:09:38.671: INFO: Created: latency-svc-l5lfg
Mar 25 18:09:38.676: INFO: Got endpoints: latency-svc-fmvp7 [246.036927ms]
Mar 25 18:09:38.688: INFO: Created: latency-svc-n4l7z
Mar 25 18:09:38.713: INFO: Created: latency-svc-w9927
Mar 25 18:09:38.723: INFO: Got endpoints: latency-svc-n92xv [281.662219ms]
Mar 25 18:09:38.725: INFO: Created: latency-svc-9vv24
Mar 25 18:09:38.733: INFO: Created: latency-svc-65kwd
Mar 25 18:09:38.748: INFO: Created: latency-svc-8lw2p
Mar 25 18:09:38.757: INFO: Created: latency-svc-2hccc
Mar 25 18:09:38.764: INFO: Created: latency-svc-f4vck
Mar 25 18:09:38.771: INFO: Got endpoints: latency-svc-l5lfg [298.983074ms]
Mar 25 18:09:38.772: INFO: Created: latency-svc-22x4t
Mar 25 18:09:38.787: INFO: Created: latency-svc-f2fzz
Mar 25 18:09:38.796: INFO: Created: latency-svc-85nn6
Mar 25 18:09:38.807: INFO: Created: latency-svc-hbh5r
Mar 25 18:09:38.831: INFO: Got endpoints: latency-svc-n4l7z [345.539166ms]
Mar 25 18:09:38.834: INFO: Created: latency-svc-wn278
Mar 25 18:09:38.842: INFO: Created: latency-svc-7fnrc
Mar 25 18:09:38.854: INFO: Created: latency-svc-h2lct
Mar 25 18:09:38.861: INFO: Created: latency-svc-r5xxg
Mar 25 18:09:38.868: INFO: Created: latency-svc-h97pp
Mar 25 18:09:38.870: INFO: Got endpoints: latency-svc-w9927 [376.60604ms]
Mar 25 18:09:38.880: INFO: Created: latency-svc-qgd7c
Mar 25 18:09:38.920: INFO: Got endpoints: latency-svc-9vv24 [406.546054ms]
Mar 25 18:09:38.930: INFO: Created: latency-svc-79d5m
Mar 25 18:09:38.971: INFO: Got endpoints: latency-svc-65kwd [439.484292ms]
Mar 25 18:09:38.987: INFO: Created: latency-svc-5hpj6
Mar 25 18:09:39.022: INFO: Got endpoints: latency-svc-8lw2p [487.798453ms]
Mar 25 18:09:39.054: INFO: Created: latency-svc-nltvl
Mar 25 18:09:39.071: INFO: Got endpoints: latency-svc-2hccc [520.345326ms]
Mar 25 18:09:39.085: INFO: Created: latency-svc-bxlkg
Mar 25 18:09:39.121: INFO: Got endpoints: latency-svc-f4vck [559.75205ms]
Mar 25 18:09:39.134: INFO: Created: latency-svc-6thlx
Mar 25 18:09:39.171: INFO: Got endpoints: latency-svc-22x4t [578.042393ms]
Mar 25 18:09:39.183: INFO: Created: latency-svc-5nsj5
Mar 25 18:09:39.221: INFO: Got endpoints: latency-svc-f2fzz [622.628152ms]
Mar 25 18:09:39.232: INFO: Created: latency-svc-jn929
Mar 25 18:09:39.270: INFO: Got endpoints: latency-svc-85nn6 [649.502749ms]
Mar 25 18:09:39.286: INFO: Created: latency-svc-p8dkg
Mar 25 18:09:39.321: INFO: Got endpoints: latency-svc-hbh5r [698.145531ms]
Mar 25 18:09:39.338: INFO: Created: latency-svc-wg2qp
Mar 25 18:09:39.377: INFO: Got endpoints: latency-svc-wn278 [742.640521ms]
Mar 25 18:09:39.390: INFO: Created: latency-svc-r6thn
Mar 25 18:09:39.421: INFO: Got endpoints: latency-svc-7fnrc [744.74891ms]
Mar 25 18:09:39.432: INFO: Created: latency-svc-6jf62
Mar 25 18:09:39.471: INFO: Got endpoints: latency-svc-h2lct [747.650071ms]
Mar 25 18:09:39.491: INFO: Created: latency-svc-c5msj
Mar 25 18:09:39.521: INFO: Got endpoints: latency-svc-r5xxg [749.352236ms]
Mar 25 18:09:39.533: INFO: Created: latency-svc-dx667
Mar 25 18:09:39.571: INFO: Got endpoints: latency-svc-h97pp [740.084495ms]
Mar 25 18:09:39.582: INFO: Created: latency-svc-xmjdq
Mar 25 18:09:39.623: INFO: Got endpoints: latency-svc-qgd7c [752.667042ms]
Mar 25 18:09:39.635: INFO: Created: latency-svc-pp7w5
Mar 25 18:09:39.671: INFO: Got endpoints: latency-svc-79d5m [750.49249ms]
Mar 25 18:09:39.682: INFO: Created: latency-svc-x5qzf
Mar 25 18:09:39.720: INFO: Got endpoints: latency-svc-5hpj6 [749.533166ms]
Mar 25 18:09:39.739: INFO: Created: latency-svc-vlwpx
Mar 25 18:09:39.771: INFO: Got endpoints: latency-svc-nltvl [749.226808ms]
Mar 25 18:09:39.789: INFO: Created: latency-svc-85dtj
Mar 25 18:09:39.821: INFO: Got endpoints: latency-svc-bxlkg [750.078116ms]
Mar 25 18:09:39.835: INFO: Created: latency-svc-7qz9z
Mar 25 18:09:39.871: INFO: Got endpoints: latency-svc-6thlx [749.507711ms]
Mar 25 18:09:39.883: INFO: Created: latency-svc-qr4dz
Mar 25 18:09:39.927: INFO: Got endpoints: latency-svc-5nsj5 [756.504637ms]
Mar 25 18:09:39.939: INFO: Created: latency-svc-xdl72
Mar 25 18:09:39.971: INFO: Got endpoints: latency-svc-jn929 [749.022316ms]
Mar 25 18:09:39.983: INFO: Created: latency-svc-pj8n6
Mar 25 18:09:40.021: INFO: Got endpoints: latency-svc-p8dkg [750.192571ms]
Mar 25 18:09:40.041: INFO: Created: latency-svc-2j6bz
Mar 25 18:09:40.071: INFO: Got endpoints: latency-svc-wg2qp [750.011941ms]
Mar 25 18:09:40.081: INFO: Created: latency-svc-fhcch
Mar 25 18:09:40.121: INFO: Got endpoints: latency-svc-r6thn [743.986077ms]
Mar 25 18:09:40.132: INFO: Created: latency-svc-vwgkc
Mar 25 18:09:40.171: INFO: Got endpoints: latency-svc-6jf62 [749.852132ms]
Mar 25 18:09:40.181: INFO: Created: latency-svc-6n4kw
Mar 25 18:09:40.221: INFO: Got endpoints: latency-svc-c5msj [749.918887ms]
Mar 25 18:09:40.231: INFO: Created: latency-svc-tfv8x
Mar 25 18:09:40.271: INFO: Got endpoints: latency-svc-dx667 [750.147641ms]
Mar 25 18:09:40.282: INFO: Created: latency-svc-npqpl
Mar 25 18:09:40.321: INFO: Got endpoints: latency-svc-xmjdq [749.934299ms]
Mar 25 18:09:40.336: INFO: Created: latency-svc-f8kgn
Mar 25 18:09:40.377: INFO: Got endpoints: latency-svc-pp7w5 [753.862253ms]
Mar 25 18:09:40.398: INFO: Created: latency-svc-49wzg
Mar 25 18:09:40.421: INFO: Got endpoints: latency-svc-x5qzf [749.600387ms]
Mar 25 18:09:40.431: INFO: Created: latency-svc-4sjdn
Mar 25 18:09:40.470: INFO: Got endpoints: latency-svc-vlwpx [749.965877ms]
Mar 25 18:09:40.500: INFO: Created: latency-svc-mn9l6
Mar 25 18:09:40.521: INFO: Got endpoints: latency-svc-85dtj [749.75652ms]
Mar 25 18:09:40.534: INFO: Created: latency-svc-gzkgb
Mar 25 18:09:40.571: INFO: Got endpoints: latency-svc-7qz9z [749.856745ms]
Mar 25 18:09:40.583: INFO: Created: latency-svc-4786b
Mar 25 18:09:40.620: INFO: Got endpoints: latency-svc-qr4dz [749.896518ms]
Mar 25 18:09:40.632: INFO: Created: latency-svc-dl8rk
Mar 25 18:09:40.671: INFO: Got endpoints: latency-svc-xdl72 [743.479278ms]
Mar 25 18:09:40.683: INFO: Created: latency-svc-4njrc
Mar 25 18:09:40.721: INFO: Got endpoints: latency-svc-pj8n6 [750.100062ms]
Mar 25 18:09:40.732: INFO: Created: latency-svc-f5lg2
Mar 25 18:09:40.771: INFO: Got endpoints: latency-svc-2j6bz [749.986249ms]
Mar 25 18:09:40.786: INFO: Created: latency-svc-mmx7w
Mar 25 18:09:40.821: INFO: Got endpoints: latency-svc-fhcch [750.006107ms]
Mar 25 18:09:40.831: INFO: Created: latency-svc-znctq
Mar 25 18:09:40.871: INFO: Got endpoints: latency-svc-vwgkc [750.140677ms]
Mar 25 18:09:40.897: INFO: Created: latency-svc-8x2cg
Mar 25 18:09:40.928: INFO: Got endpoints: latency-svc-6n4kw [756.782674ms]
Mar 25 18:09:40.939: INFO: Created: latency-svc-jvktk
Mar 25 18:09:40.971: INFO: Got endpoints: latency-svc-tfv8x [750.015638ms]
Mar 25 18:09:40.982: INFO: Created: latency-svc-q4ld4
Mar 25 18:09:41.021: INFO: Got endpoints: latency-svc-npqpl [749.771894ms]
Mar 25 18:09:41.041: INFO: Created: latency-svc-csjwh
Mar 25 18:09:41.071: INFO: Got endpoints: latency-svc-f8kgn [750.163687ms]
Mar 25 18:09:41.081: INFO: Created: latency-svc-q8wsw
Mar 25 18:09:41.121: INFO: Got endpoints: latency-svc-49wzg [743.901415ms]
Mar 25 18:09:41.139: INFO: Created: latency-svc-grnfx
Mar 25 18:09:41.171: INFO: Got endpoints: latency-svc-4sjdn [750.081225ms]
Mar 25 18:09:41.180: INFO: Created: latency-svc-d96zt
Mar 25 18:09:41.229: INFO: Got endpoints: latency-svc-mn9l6 [758.497471ms]
Mar 25 18:09:41.241: INFO: Created: latency-svc-qrcwr
Mar 25 18:09:41.270: INFO: Got endpoints: latency-svc-gzkgb [749.584097ms]
Mar 25 18:09:41.281: INFO: Created: latency-svc-5sp67
Mar 25 18:09:41.321: INFO: Got endpoints: latency-svc-4786b [750.186199ms]
Mar 25 18:09:41.330: INFO: Created: latency-svc-v9flt
Mar 25 18:09:41.382: INFO: Got endpoints: latency-svc-dl8rk [761.130947ms]
Mar 25 18:09:41.400: INFO: Created: latency-svc-w8w6b
Mar 25 18:09:41.421: INFO: Got endpoints: latency-svc-4njrc [750.192804ms]
Mar 25 18:09:41.436: INFO: Created: latency-svc-8gsmz
Mar 25 18:09:41.471: INFO: Got endpoints: latency-svc-f5lg2 [750.199311ms]
Mar 25 18:09:41.490: INFO: Created: latency-svc-h5rqv
Mar 25 18:09:41.521: INFO: Got endpoints: latency-svc-mmx7w [750.353795ms]
Mar 25 18:09:41.536: INFO: Created: latency-svc-xz2kl
Mar 25 18:09:41.571: INFO: Got endpoints: latency-svc-znctq [749.776715ms]
Mar 25 18:09:41.582: INFO: Created: latency-svc-j7x2j
Mar 25 18:09:41.621: INFO: Got endpoints: latency-svc-8x2cg [749.651186ms]
Mar 25 18:09:41.635: INFO: Created: latency-svc-q7fzz
Mar 25 18:09:41.671: INFO: Got endpoints: latency-svc-jvktk [743.244146ms]
Mar 25 18:09:41.681: INFO: Created: latency-svc-z7bjk
Mar 25 18:09:41.720: INFO: Got endpoints: latency-svc-q4ld4 [749.39777ms]
Mar 25 18:09:41.732: INFO: Created: latency-svc-vjq7v
Mar 25 18:09:41.771: INFO: Got endpoints: latency-svc-csjwh [749.960409ms]
Mar 25 18:09:41.784: INFO: Created: latency-svc-6xmq4
Mar 25 18:09:41.820: INFO: Got endpoints: latency-svc-q8wsw [749.571749ms]
Mar 25 18:09:41.834: INFO: Created: latency-svc-h5kl8
Mar 25 18:09:41.871: INFO: Got endpoints: latency-svc-grnfx [750.167094ms]
Mar 25 18:09:41.884: INFO: Created: latency-svc-q6hdp
Mar 25 18:09:41.940: INFO: Got endpoints: latency-svc-d96zt [769.35673ms]
Mar 25 18:09:41.951: INFO: Created: latency-svc-fdf4v
Mar 25 18:09:41.971: INFO: Got endpoints: latency-svc-qrcwr [741.808407ms]
Mar 25 18:09:41.986: INFO: Created: latency-svc-7jqtl
Mar 25 18:09:42.021: INFO: Got endpoints: latency-svc-5sp67 [750.321781ms]
Mar 25 18:09:42.032: INFO: Created: latency-svc-p2v7p
Mar 25 18:09:42.071: INFO: Got endpoints: latency-svc-v9flt [749.792057ms]
Mar 25 18:09:42.085: INFO: Created: latency-svc-9fxrq
Mar 25 18:09:42.121: INFO: Got endpoints: latency-svc-w8w6b [739.053853ms]
Mar 25 18:09:42.131: INFO: Created: latency-svc-k8nfm
Mar 25 18:09:42.171: INFO: Got endpoints: latency-svc-8gsmz [749.647663ms]
Mar 25 18:09:42.187: INFO: Created: latency-svc-kf5vw
Mar 25 18:09:42.221: INFO: Got endpoints: latency-svc-h5rqv [749.749246ms]
Mar 25 18:09:42.233: INFO: Created: latency-svc-8j5n5
Mar 25 18:09:42.271: INFO: Got endpoints: latency-svc-xz2kl [749.458881ms]
Mar 25 18:09:42.281: INFO: Created: latency-svc-krm84
Mar 25 18:09:42.321: INFO: Got endpoints: latency-svc-j7x2j [750.346016ms]
Mar 25 18:09:42.331: INFO: Created: latency-svc-hlvnc
Mar 25 18:09:42.381: INFO: Got endpoints: latency-svc-q7fzz [760.188014ms]
Mar 25 18:09:42.392: INFO: Created: latency-svc-w9dst
Mar 25 18:09:42.421: INFO: Got endpoints: latency-svc-z7bjk [749.968227ms]
Mar 25 18:09:42.437: INFO: Created: latency-svc-7fqsw
Mar 25 18:09:42.472: INFO: Got endpoints: latency-svc-vjq7v [751.123688ms]
Mar 25 18:09:42.494: INFO: Created: latency-svc-wnxbt
Mar 25 18:09:42.522: INFO: Got endpoints: latency-svc-6xmq4 [751.314648ms]
Mar 25 18:09:42.532: INFO: Created: latency-svc-vrwbq
Mar 25 18:09:42.571: INFO: Got endpoints: latency-svc-h5kl8 [750.802609ms]
Mar 25 18:09:42.582: INFO: Created: latency-svc-rpttp
Mar 25 18:09:42.621: INFO: Got endpoints: latency-svc-q6hdp [750.091495ms]
Mar 25 18:09:42.636: INFO: Created: latency-svc-hlz7w
Mar 25 18:09:42.680: INFO: Got endpoints: latency-svc-fdf4v [739.940206ms]
Mar 25 18:09:42.693: INFO: Created: latency-svc-r4hxt
Mar 25 18:09:42.721: INFO: Got endpoints: latency-svc-7jqtl [750.315734ms]
Mar 25 18:09:42.732: INFO: Created: latency-svc-slscf
Mar 25 18:09:42.771: INFO: Got endpoints: latency-svc-p2v7p [749.917851ms]
Mar 25 18:09:42.781: INFO: Created: latency-svc-v4c7x
Mar 25 18:09:42.822: INFO: Got endpoints: latency-svc-9fxrq [751.444276ms]
Mar 25 18:09:42.831: INFO: Created: latency-svc-rnvsc
Mar 25 18:09:42.871: INFO: Got endpoints: latency-svc-k8nfm [749.805329ms]
Mar 25 18:09:42.882: INFO: Created: latency-svc-6p4lp
Mar 25 18:09:42.921: INFO: Got endpoints: latency-svc-kf5vw [750.223689ms]
Mar 25 18:09:42.941: INFO: Created: latency-svc-6dmqj
Mar 25 18:09:42.971: INFO: Got endpoints: latency-svc-8j5n5 [750.027035ms]
Mar 25 18:09:42.981: INFO: Created: latency-svc-hcqnk
Mar 25 18:09:43.021: INFO: Got endpoints: latency-svc-krm84 [750.815103ms]
Mar 25 18:09:43.043: INFO: Created: latency-svc-dhjz6
Mar 25 18:09:43.071: INFO: Got endpoints: latency-svc-hlvnc [749.695187ms]
Mar 25 18:09:43.081: INFO: Created: latency-svc-pchck
Mar 25 18:09:43.121: INFO: Got endpoints: latency-svc-w9dst [740.334904ms]
Mar 25 18:09:43.135: INFO: Created: latency-svc-6nd9p
Mar 25 18:09:43.172: INFO: Got endpoints: latency-svc-7fqsw [750.813919ms]
Mar 25 18:09:43.185: INFO: Created: latency-svc-7jk8d
Mar 25 18:09:43.221: INFO: Got endpoints: latency-svc-wnxbt [749.185507ms]
Mar 25 18:09:43.231: INFO: Created: latency-svc-m279v
Mar 25 18:09:43.270: INFO: Got endpoints: latency-svc-vrwbq [748.389742ms]
Mar 25 18:09:43.283: INFO: Created: latency-svc-nkwsb
Mar 25 18:09:43.321: INFO: Got endpoints: latency-svc-rpttp [749.328535ms]
Mar 25 18:09:43.340: INFO: Created: latency-svc-mz58f
Mar 25 18:09:43.375: INFO: Got endpoints: latency-svc-hlz7w [753.277624ms]
Mar 25 18:09:43.391: INFO: Created: latency-svc-jjchj
Mar 25 18:09:43.421: INFO: Got endpoints: latency-svc-r4hxt [740.554094ms]
Mar 25 18:09:43.432: INFO: Created: latency-svc-tkjc6
Mar 25 18:09:43.471: INFO: Got endpoints: latency-svc-slscf [749.465067ms]
Mar 25 18:09:43.486: INFO: Created: latency-svc-xtmww
Mar 25 18:09:43.521: INFO: Got endpoints: latency-svc-v4c7x [750.04683ms]
Mar 25 18:09:43.533: INFO: Created: latency-svc-lxmfz
Mar 25 18:09:43.571: INFO: Got endpoints: latency-svc-rnvsc [748.315346ms]
Mar 25 18:09:43.581: INFO: Created: latency-svc-qn52v
Mar 25 18:09:43.621: INFO: Got endpoints: latency-svc-6p4lp [749.966879ms]
Mar 25 18:09:43.632: INFO: Created: latency-svc-ggfgd
Mar 25 18:09:43.671: INFO: Got endpoints: latency-svc-6dmqj [749.801836ms]
Mar 25 18:09:43.684: INFO: Created: latency-svc-j84vp
Mar 25 18:09:43.721: INFO: Got endpoints: latency-svc-hcqnk [749.902765ms]
Mar 25 18:09:43.733: INFO: Created: latency-svc-8pv5d
Mar 25 18:09:43.771: INFO: Got endpoints: latency-svc-dhjz6 [749.120768ms]
Mar 25 18:09:43.782: INFO: Created: latency-svc-znkr5
Mar 25 18:09:43.821: INFO: Got endpoints: latency-svc-pchck [749.944435ms]
Mar 25 18:09:43.836: INFO: Created: latency-svc-2pdg6
Mar 25 18:09:43.871: INFO: Got endpoints: latency-svc-6nd9p [749.463763ms]
Mar 25 18:09:43.882: INFO: Created: latency-svc-hcc4q
Mar 25 18:09:43.930: INFO: Got endpoints: latency-svc-7jk8d [758.652309ms]
Mar 25 18:09:43.948: INFO: Created: latency-svc-2rnpq
Mar 25 18:09:43.972: INFO: Got endpoints: latency-svc-m279v [751.037347ms]
Mar 25 18:09:43.981: INFO: Created: latency-svc-dmm2b
Mar 25 18:09:44.021: INFO: Got endpoints: latency-svc-nkwsb [750.152022ms]
Mar 25 18:09:44.043: INFO: Created: latency-svc-gmwnd
Mar 25 18:09:44.071: INFO: Got endpoints: latency-svc-mz58f [750.130485ms]
Mar 25 18:09:44.087: INFO: Created: latency-svc-zqhfp
Mar 25 18:09:44.121: INFO: Got endpoints: latency-svc-jjchj [746.031955ms]
Mar 25 18:09:44.130: INFO: Created: latency-svc-nbjtw
Mar 25 18:09:44.171: INFO: Got endpoints: latency-svc-tkjc6 [749.965133ms]
Mar 25 18:09:44.182: INFO: Created: latency-svc-mp9fh
Mar 25 18:09:44.222: INFO: Got endpoints: latency-svc-xtmww [751.637483ms]
Mar 25 18:09:44.232: INFO: Created: latency-svc-jgmfk
Mar 25 18:09:44.271: INFO: Got endpoints: latency-svc-lxmfz [750.328659ms]
Mar 25 18:09:44.288: INFO: Created: latency-svc-x7lnp
Mar 25 18:09:44.320: INFO: Got endpoints: latency-svc-qn52v [749.834557ms]
Mar 25 18:09:44.332: INFO: Created: latency-svc-2r62p
Mar 25 18:09:44.371: INFO: Got endpoints: latency-svc-ggfgd [749.969871ms]
Mar 25 18:09:44.383: INFO: Created: latency-svc-gg4hd
Mar 25 18:09:44.421: INFO: Got endpoints: latency-svc-j84vp [750.146444ms]
Mar 25 18:09:44.431: INFO: Created: latency-svc-ssbs7
Mar 25 18:09:44.479: INFO: Got endpoints: latency-svc-8pv5d [757.971206ms]
Mar 25 18:09:44.495: INFO: Created: latency-svc-b2hql
Mar 25 18:09:44.521: INFO: Got endpoints: latency-svc-znkr5 [750.402334ms]
Mar 25 18:09:44.534: INFO: Created: latency-svc-h8br2
Mar 25 18:09:44.570: INFO: Got endpoints: latency-svc-2pdg6 [749.730787ms]
Mar 25 18:09:44.592: INFO: Created: latency-svc-pd7xp
Mar 25 18:09:44.621: INFO: Got endpoints: latency-svc-hcc4q [749.78474ms]
Mar 25 18:09:44.634: INFO: Created: latency-svc-b27kx
Mar 25 18:09:44.671: INFO: Got endpoints: latency-svc-2rnpq [740.237688ms]
Mar 25 18:09:44.686: INFO: Created: latency-svc-84t5j
Mar 25 18:09:44.721: INFO: Got endpoints: latency-svc-dmm2b [748.713299ms]
Mar 25 18:09:44.732: INFO: Created: latency-svc-pxv2n
Mar 25 18:09:44.771: INFO: Got endpoints: latency-svc-gmwnd [750.154213ms]
Mar 25 18:09:44.780: INFO: Created: latency-svc-5jtr5
Mar 25 18:09:44.821: INFO: Got endpoints: latency-svc-zqhfp [750.219001ms]
Mar 25 18:09:44.835: INFO: Created: latency-svc-8mknb
Mar 25 18:09:44.871: INFO: Got endpoints: latency-svc-nbjtw [750.038286ms]
Mar 25 18:09:44.884: INFO: Created: latency-svc-cfhsw
Mar 25 18:09:45.017: INFO: Got endpoints: latency-svc-mp9fh [846.150059ms]
Mar 25 18:09:45.020: INFO: Got endpoints: latency-svc-jgmfk [798.034194ms]
Mar 25 18:09:45.025: INFO: Got endpoints: latency-svc-x7lnp [753.413723ms]
Mar 25 18:09:45.056: INFO: Created: latency-svc-qvm7w
Mar 25 18:09:45.069: INFO: Created: latency-svc-44s6g
Mar 25 18:09:45.072: INFO: Got endpoints: latency-svc-2r62p [751.399046ms]
Mar 25 18:09:45.084: INFO: Created: latency-svc-nrxss
Mar 25 18:09:45.093: INFO: Created: latency-svc-mwkwx
Mar 25 18:09:45.126: INFO: Got endpoints: latency-svc-gg4hd [755.119159ms]
Mar 25 18:09:45.135: INFO: Created: latency-svc-x9rgh
Mar 25 18:09:45.171: INFO: Got endpoints: latency-svc-ssbs7 [749.860171ms]
Mar 25 18:09:45.180: INFO: Created: latency-svc-tl46n
Mar 25 18:09:45.221: INFO: Got endpoints: latency-svc-b2hql [741.996748ms]
Mar 25 18:09:45.243: INFO: Created: latency-svc-8pvqk
Mar 25 18:09:45.271: INFO: Got endpoints: latency-svc-h8br2 [749.59421ms]
Mar 25 18:09:45.281: INFO: Created: latency-svc-l4tld
Mar 25 18:09:45.321: INFO: Got endpoints: latency-svc-pd7xp [750.163997ms]
Mar 25 18:09:45.332: INFO: Created: latency-svc-9hkkf
Mar 25 18:09:45.371: INFO: Got endpoints: latency-svc-b27kx [750.255825ms]
Mar 25 18:09:45.391: INFO: Created: latency-svc-gdfkl
Mar 25 18:09:45.421: INFO: Got endpoints: latency-svc-84t5j [750.380818ms]
Mar 25 18:09:45.430: INFO: Created: latency-svc-kg76t
Mar 25 18:09:45.471: INFO: Got endpoints: latency-svc-pxv2n [750.397342ms]
Mar 25 18:09:45.484: INFO: Created: latency-svc-brpcn
Mar 25 18:09:45.521: INFO: Got endpoints: latency-svc-5jtr5 [749.665166ms]
Mar 25 18:09:45.530: INFO: Created: latency-svc-5m9mc
Mar 25 18:09:45.572: INFO: Got endpoints: latency-svc-8mknb [750.87219ms]
Mar 25 18:09:45.582: INFO: Created: latency-svc-vfhxv
Mar 25 18:09:45.621: INFO: Got endpoints: latency-svc-cfhsw [750.050858ms]
Mar 25 18:09:45.634: INFO: Created: latency-svc-ptlvg
Mar 25 18:09:45.672: INFO: Got endpoints: latency-svc-qvm7w [654.624012ms]
Mar 25 18:09:45.695: INFO: Created: latency-svc-9cmpz
Mar 25 18:09:45.721: INFO: Got endpoints: latency-svc-44s6g [700.249699ms]
Mar 25 18:09:45.731: INFO: Created: latency-svc-2b4j8
Mar 25 18:09:45.771: INFO: Got endpoints: latency-svc-nrxss [746.424231ms]
Mar 25 18:09:45.787: INFO: Created: latency-svc-j7zgx
Mar 25 18:09:45.821: INFO: Got endpoints: latency-svc-mwkwx [748.824533ms]
Mar 25 18:09:45.832: INFO: Created: latency-svc-6cn52
Mar 25 18:09:45.871: INFO: Got endpoints: latency-svc-x9rgh [744.846886ms]
Mar 25 18:09:45.921: INFO: Got endpoints: latency-svc-tl46n [749.772567ms]
Mar 25 18:09:45.970: INFO: Got endpoints: latency-svc-8pvqk [749.736182ms]
Mar 25 18:09:46.021: INFO: Got endpoints: latency-svc-l4tld [750.38694ms]
Mar 25 18:09:46.071: INFO: Got endpoints: latency-svc-9hkkf [750.582865ms]
Mar 25 18:09:46.120: INFO: Got endpoints: latency-svc-gdfkl [749.47703ms]
Mar 25 18:09:46.171: INFO: Got endpoints: latency-svc-kg76t [749.520511ms]
Mar 25 18:09:46.221: INFO: Got endpoints: latency-svc-brpcn [749.943649ms]
Mar 25 18:09:46.271: INFO: Got endpoints: latency-svc-5m9mc [750.269583ms]
Mar 25 18:09:46.324: INFO: Got endpoints: latency-svc-vfhxv [752.02388ms]
Mar 25 18:09:46.371: INFO: Got endpoints: latency-svc-ptlvg [749.958766ms]
Mar 25 18:09:46.421: INFO: Got endpoints: latency-svc-9cmpz [749.180443ms]
Mar 25 18:09:46.472: INFO: Got endpoints: latency-svc-2b4j8 [750.893232ms]
Mar 25 18:09:46.521: INFO: Got endpoints: latency-svc-j7zgx [749.798812ms]
Mar 25 18:09:46.571: INFO: Got endpoints: latency-svc-6cn52 [749.960276ms]
Mar 25 18:09:46.571: INFO: Latencies: [36.454706ms 40.197846ms 61.582577ms 70.658522ms 96.092413ms 109.902961ms 125.638847ms 134.409946ms 149.673397ms 159.253653ms 183.900126ms 186.532967ms 192.019179ms 192.207281ms 194.412427ms 197.175362ms 204.666643ms 209.905816ms 210.95884ms 212.451567ms 213.70867ms 214.169511ms 215.01634ms 215.546174ms 215.735006ms 216.588138ms 220.728031ms 221.342039ms 224.0022ms 224.980264ms 225.4716ms 227.107756ms 230.666441ms 232.043441ms 232.555347ms 234.088596ms 239.986653ms 240.142952ms 240.557604ms 246.036927ms 248.865354ms 248.88691ms 281.662219ms 298.983074ms 345.539166ms 376.60604ms 406.546054ms 439.484292ms 487.798453ms 520.345326ms 559.75205ms 578.042393ms 622.628152ms 649.502749ms 654.624012ms 698.145531ms 700.249699ms 739.053853ms 739.940206ms 740.084495ms 740.237688ms 740.334904ms 740.554094ms 741.808407ms 741.996748ms 742.640521ms 743.244146ms 743.479278ms 743.901415ms 743.986077ms 744.74891ms 744.846886ms 746.031955ms 746.424231ms 747.650071ms 748.315346ms 748.389742ms 748.713299ms 748.824533ms 749.022316ms 749.120768ms 749.180443ms 749.185507ms 749.226808ms 749.328535ms 749.352236ms 749.39777ms 749.458881ms 749.463763ms 749.465067ms 749.47703ms 749.507711ms 749.520511ms 749.533166ms 749.571749ms 749.584097ms 749.59421ms 749.600387ms 749.647663ms 749.651186ms 749.665166ms 749.695187ms 749.730787ms 749.736182ms 749.749246ms 749.75652ms 749.771894ms 749.772567ms 749.776715ms 749.78474ms 749.792057ms 749.798812ms 749.801836ms 749.805329ms 749.834557ms 749.852132ms 749.856745ms 749.860171ms 749.896518ms 749.902765ms 749.917851ms 749.918887ms 749.934299ms 749.943649ms 749.944435ms 749.958766ms 749.960276ms 749.960409ms 749.965133ms 749.965877ms 749.966879ms 749.968227ms 749.969871ms 749.986249ms 750.006107ms 750.011941ms 750.015638ms 750.027035ms 750.038286ms 750.04683ms 750.050858ms 750.078116ms 750.081225ms 750.091495ms 750.100062ms 750.130485ms 750.140677ms 750.146444ms 750.147641ms 750.152022ms 750.154213ms 750.163687ms 750.163997ms 750.167094ms 750.186199ms 750.192571ms 750.192804ms 750.199311ms 750.219001ms 750.223689ms 750.255825ms 750.269583ms 750.315734ms 750.321781ms 750.328659ms 750.346016ms 750.353795ms 750.380818ms 750.38694ms 750.397342ms 750.402334ms 750.49249ms 750.582865ms 750.802609ms 750.813919ms 750.815103ms 750.87219ms 750.893232ms 751.037347ms 751.123688ms 751.314648ms 751.399046ms 751.444276ms 751.637483ms 752.02388ms 752.667042ms 753.277624ms 753.413723ms 753.862253ms 755.119159ms 756.504637ms 756.782674ms 757.971206ms 758.497471ms 758.652309ms 760.188014ms 761.130947ms 769.35673ms 798.034194ms 846.150059ms]
Mar 25 18:09:46.571: INFO: 50 %ile: 749.665166ms
Mar 25 18:09:46.571: INFO: 90 %ile: 751.314648ms
Mar 25 18:09:46.571: INFO: 99 %ile: 798.034194ms
Mar 25 18:09:46.571: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:09:46.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "svc-latency-8296" for this suite.
Mar 25 18:09:58.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:09:58.643: INFO: namespace svc-latency-8296 deletion completed in 12.069236961s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:09:58.644: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test emptydir 0644 on node default medium
Mar 25 18:09:58.687: INFO: Waiting up to 5m0s for pod "pod-dfcffe82-4f63-11e9-91ba-a08cfdecc127" in namespace "emptydir-4707" to be "success or failure"
Mar 25 18:09:58.690: INFO: Pod "pod-dfcffe82-4f63-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.811561ms
Mar 25 18:10:00.694: INFO: Pod "pod-dfcffe82-4f63-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00606525s
[1mSTEP[0m: Saw pod success
Mar 25 18:10:00.694: INFO: Pod "pod-dfcffe82-4f63-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:10:00.696: INFO: Trying to get logs from node conformance-worker2 pod pod-dfcffe82-4f63-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:10:00.718: INFO: Waiting for pod pod-dfcffe82-4f63-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:10:00.720: INFO: Pod pod-dfcffe82-4f63-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:10:00.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-4707" for this suite.
Mar 25 18:10:06.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:10:06.799: INFO: namespace emptydir-4707 deletion completed in 6.075816803s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould observe add, update, and delete watch notifications on configmaps [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-api-machinery] Watchers
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:10:06.799: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename watch
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating a watch on configmaps with label A
[1mSTEP[0m: creating a watch on configmaps with label B
[1mSTEP[0m: creating a watch on configmaps with label A or B
[1mSTEP[0m: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar 25 18:10:06.835: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5429,SelfLink:/api/v1/namespaces/watch-5429/configmaps/e2e-watch-test-configmap-a,UID:e4abdf58-4f63-11e9-8304-02427cbbc9a0,ResourceVersion:11084,Generation:0,CreationTimestamp:2019-03-25 18:10:06 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 25 18:10:06.835: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5429,SelfLink:/api/v1/namespaces/watch-5429/configmaps/e2e-watch-test-configmap-a,UID:e4abdf58-4f63-11e9-8304-02427cbbc9a0,ResourceVersion:11084,Generation:0,CreationTimestamp:2019-03-25 18:10:06 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying configmap A and ensuring the correct watchers observe the notification
Mar 25 18:10:16.840: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5429,SelfLink:/api/v1/namespaces/watch-5429/configmaps/e2e-watch-test-configmap-a,UID:e4abdf58-4f63-11e9-8304-02427cbbc9a0,ResourceVersion:11100,Generation:0,CreationTimestamp:2019-03-25 18:10:06 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 25 18:10:16.840: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5429,SelfLink:/api/v1/namespaces/watch-5429/configmaps/e2e-watch-test-configmap-a,UID:e4abdf58-4f63-11e9-8304-02427cbbc9a0,ResourceVersion:11100,Generation:0,CreationTimestamp:2019-03-25 18:10:06 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying configmap A again and ensuring the correct watchers observe the notification
Mar 25 18:10:26.849: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5429,SelfLink:/api/v1/namespaces/watch-5429/configmaps/e2e-watch-test-configmap-a,UID:e4abdf58-4f63-11e9-8304-02427cbbc9a0,ResourceVersion:11115,Generation:0,CreationTimestamp:2019-03-25 18:10:06 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 25 18:10:26.849: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5429,SelfLink:/api/v1/namespaces/watch-5429/configmaps/e2e-watch-test-configmap-a,UID:e4abdf58-4f63-11e9-8304-02427cbbc9a0,ResourceVersion:11115,Generation:0,CreationTimestamp:2019-03-25 18:10:06 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: deleting configmap A and ensuring the correct watchers observe the notification
Mar 25 18:10:36.856: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5429,SelfLink:/api/v1/namespaces/watch-5429/configmaps/e2e-watch-test-configmap-a,UID:e4abdf58-4f63-11e9-8304-02427cbbc9a0,ResourceVersion:11131,Generation:0,CreationTimestamp:2019-03-25 18:10:06 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 25 18:10:36.856: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5429,SelfLink:/api/v1/namespaces/watch-5429/configmaps/e2e-watch-test-configmap-a,UID:e4abdf58-4f63-11e9-8304-02427cbbc9a0,ResourceVersion:11131,Generation:0,CreationTimestamp:2019-03-25 18:10:06 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar 25 18:10:46.861: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5429,SelfLink:/api/v1/namespaces/watch-5429/configmaps/e2e-watch-test-configmap-b,UID:fc870de7-4f63-11e9-8304-02427cbbc9a0,ResourceVersion:11146,Generation:0,CreationTimestamp:2019-03-25 18:10:46 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 25 18:10:46.861: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5429,SelfLink:/api/v1/namespaces/watch-5429/configmaps/e2e-watch-test-configmap-b,UID:fc870de7-4f63-11e9-8304-02427cbbc9a0,ResourceVersion:11146,Generation:0,CreationTimestamp:2019-03-25 18:10:46 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[1mSTEP[0m: deleting configmap B and ensuring the correct watchers observe the notification
Mar 25 18:10:56.866: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5429,SelfLink:/api/v1/namespaces/watch-5429/configmaps/e2e-watch-test-configmap-b,UID:fc870de7-4f63-11e9-8304-02427cbbc9a0,ResourceVersion:11161,Generation:0,CreationTimestamp:2019-03-25 18:10:46 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 25 18:10:56.866: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5429,SelfLink:/api/v1/namespaces/watch-5429/configmaps/e2e-watch-test-configmap-b,UID:fc870de7-4f63-11e9-8304-02427cbbc9a0,ResourceVersion:11161,Generation:0,CreationTimestamp:2019-03-25 18:10:46 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:11:06.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "watch-5429" for this suite.
Mar 25 18:11:12.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:11:12.955: INFO: namespace watch-5429 deletion completed in 6.084408335s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:11:12.955: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name configmap-test-volume-map-0c19ab8e-4f64-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 25 18:11:12.991: INFO: Waiting up to 5m0s for pod "pod-configmaps-0c1a04e9-4f64-11e9-91ba-a08cfdecc127" in namespace "configmap-7513" to be "success or failure"
Mar 25 18:11:12.994: INFO: Pod "pod-configmaps-0c1a04e9-4f64-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.3645ms
Mar 25 18:11:14.997: INFO: Pod "pod-configmaps-0c1a04e9-4f64-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006056328s
[1mSTEP[0m: Saw pod success
Mar 25 18:11:14.997: INFO: Pod "pod-configmaps-0c1a04e9-4f64-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:11:14.999: INFO: Trying to get logs from node conformance-worker2 pod pod-configmaps-0c1a04e9-4f64-11e9-91ba-a08cfdecc127 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:11:15.012: INFO: Waiting for pod pod-configmaps-0c1a04e9-4f64-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:11:15.014: INFO: Pod pod-configmaps-0c1a04e9-4f64-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:11:15.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-7513" for this suite.
Mar 25 18:11:21.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:11:21.091: INFO: namespace configmap-7513 deletion completed in 6.075601369s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:11:21.092: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: create the rc1
[1mSTEP[0m: create the rc2
[1mSTEP[0m: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
[1mSTEP[0m: delete the rc simpletest-rc-to-be-deleted
[1mSTEP[0m: wait for the rc to be deleted
[1mSTEP[0m: Gathering metrics
W0325 18:11:31.185756   72333 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 25 18:11:31.185: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:11:31.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "gc-9123" for this suite.
Mar 25 18:11:37.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:11:37.258: INFO: namespace gc-9123 deletion completed in 6.069599513s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:11:37.258: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 18:11:37.294: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1a96a09e-4f64-11e9-91ba-a08cfdecc127" in namespace "downward-api-3241" to be "success or failure"
Mar 25 18:11:37.296: INFO: Pod "downwardapi-volume-1a96a09e-4f64-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.535054ms
Mar 25 18:11:39.300: INFO: Pod "downwardapi-volume-1a96a09e-4f64-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005511688s
[1mSTEP[0m: Saw pod success
Mar 25 18:11:39.300: INFO: Pod "downwardapi-volume-1a96a09e-4f64-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:11:39.303: INFO: Trying to get logs from node conformance-worker pod downwardapi-volume-1a96a09e-4f64-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:11:39.320: INFO: Waiting for pod downwardapi-volume-1a96a09e-4f64-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:11:39.322: INFO: Pod downwardapi-volume-1a96a09e-4f64-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:11:39.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-3241" for this suite.
Mar 25 18:11:45.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:11:45.402: INFO: namespace downward-api-3241 deletion completed in 6.078003531s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould be able to override the image's default command and arguments [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Docker Containers
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:11:45.403: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename containers
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test override all
Mar 25 18:11:45.441: INFO: Waiting up to 5m0s for pod "client-containers-1f71c8dd-4f64-11e9-91ba-a08cfdecc127" in namespace "containers-6558" to be "success or failure"
Mar 25 18:11:45.443: INFO: Pod "client-containers-1f71c8dd-4f64-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.942314ms
Mar 25 18:11:47.447: INFO: Pod "client-containers-1f71c8dd-4f64-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005549992s
[1mSTEP[0m: Saw pod success
Mar 25 18:11:47.447: INFO: Pod "client-containers-1f71c8dd-4f64-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:11:47.449: INFO: Trying to get logs from node conformance-worker pod client-containers-1f71c8dd-4f64-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:11:47.470: INFO: Waiting for pod client-containers-1f71c8dd-4f64-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:11:47.473: INFO: Pod client-containers-1f71c8dd-4f64-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:11:47.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "containers-6558" for this suite.
Mar 25 18:11:53.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:11:53.552: INFO: namespace containers-6558 deletion completed in 6.077290791s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:11:53.553: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test emptydir 0666 on tmpfs
Mar 25 18:11:53.577: INFO: Waiting up to 5m0s for pod "pod-244b355c-4f64-11e9-91ba-a08cfdecc127" in namespace "emptydir-2839" to be "success or failure"
Mar 25 18:11:53.584: INFO: Pod "pod-244b355c-4f64-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 6.160556ms
Mar 25 18:11:55.588: INFO: Pod "pod-244b355c-4f64-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010311118s
[1mSTEP[0m: Saw pod success
Mar 25 18:11:55.588: INFO: Pod "pod-244b355c-4f64-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:11:55.591: INFO: Trying to get logs from node conformance-worker pod pod-244b355c-4f64-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:11:55.610: INFO: Waiting for pod pod-244b355c-4f64-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:11:55.617: INFO: Pod pod-244b355c-4f64-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:11:55.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-2839" for this suite.
Mar 25 18:12:01.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:12:01.690: INFO: namespace emptydir-2839 deletion completed in 6.070030594s
[32mâ€¢[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:12:01.690: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating pod liveness-http in namespace container-probe-3078
Mar 25 18:12:03.726: INFO: Started pod liveness-http in namespace container-probe-3078
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
Mar 25 18:12:03.729: INFO: Initial restart count of pod liveness-http is 0
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:16:04.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-probe-3078" for this suite.
Mar 25 18:16:10.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:16:10.260: INFO: namespace container-probe-3078 deletion completed in 6.085029227s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1mshould be consumable in multiple volumes in a pod [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected secret
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:16:10.261: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating secret with name projected-secret-test-bd5019dd-4f64-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 25 18:16:10.303: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bd50665e-4f64-11e9-91ba-a08cfdecc127" in namespace "projected-293" to be "success or failure"
Mar 25 18:16:10.307: INFO: Pod "pod-projected-secrets-bd50665e-4f64-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 4.081643ms
Mar 25 18:16:12.312: INFO: Pod "pod-projected-secrets-bd50665e-4f64-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008365511s
[1mSTEP[0m: Saw pod success
Mar 25 18:16:12.312: INFO: Pod "pod-projected-secrets-bd50665e-4f64-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:16:12.315: INFO: Trying to get logs from node conformance-worker pod pod-projected-secrets-bd50665e-4f64-11e9-91ba-a08cfdecc127 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:16:12.332: INFO: Waiting for pod pod-projected-secrets-bd50665e-4f64-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:16:12.334: INFO: Pod pod-projected-secrets-bd50665e-4f64-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected secret
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:16:12.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-293" for this suite.
Mar 25 18:16:18.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:16:18.418: INFO: namespace projected-293 deletion completed in 6.082365856s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:16:18.419: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name cm-test-opt-del-c22bc25a-4f64-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating configMap with name cm-test-opt-upd-c22bc291-4f64-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting configmap cm-test-opt-del-c22bc25a-4f64-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Updating configmap cm-test-opt-upd-c22bc291-4f64-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating configMap with name cm-test-opt-create-c22bc29e-4f64-11e9-91ba-a08cfdecc127
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:16:26.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-6409" for this suite.
Mar 25 18:16:48.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:16:48.616: INFO: namespace projected-6409 deletion completed in 22.069491812s
[32mâ€¢[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:16:48.616: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating pod liveness-exec in namespace container-probe-2953
Mar 25 18:16:50.662: INFO: Started pod liveness-exec in namespace container-probe-2953
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
Mar 25 18:16:50.665: INFO: Initial restart count of pod liveness-exec is 0
Mar 25 18:17:44.764: INFO: Restart count of pod container-probe-2953/liveness-exec is now 1 (54.099167891s elapsed)
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:17:44.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-probe-2953" for this suite.
Mar 25 18:17:50.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:17:50.848: INFO: namespace container-probe-2953 deletion completed in 6.069702944s
[32mâ€¢[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-network] Networking
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:17:50.848: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename pod-network-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Performing setup for networking test in namespace pod-network-test-7453
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
Mar 25 18:17:50.873: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[1mSTEP[0m: Creating test pods
Mar 25 18:18:12.930: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.32.0.2:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7453 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 18:18:12.930: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 18:18:13.128: INFO: Found all expected endpoints: [netserver-0]
Mar 25 18:18:13.131: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.38.0.1:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7453 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 18:18:13.131: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 18:18:13.294: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:18:13.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "pod-network-test-7453" for this suite.
Mar 25 18:18:35.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:18:35.365: INFO: namespace pod-network-test-7453 deletion completed in 22.068260518s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Aggregator[0m 
  [1mShould be able to support the 1.10 Sample API Server using the current Aggregator [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-api-machinery] Aggregator
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:18:35.365: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename aggregator
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Registering the sample API server.
Mar 25 18:18:35.981: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Mar 25 18:18:38.017: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689159915, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689159915, loc:(*time.Location)(0x89eb0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689159915, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689159915, loc:(*time.Location)(0x89eb0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 18:18:40.021: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689159915, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689159915, loc:(*time.Location)(0x89eb0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689159915, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689159915, loc:(*time.Location)(0x89eb0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 18:18:42.020: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689159915, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689159915, loc:(*time.Location)(0x89eb0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689159915, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689159915, loc:(*time.Location)(0x89eb0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 18:18:44.021: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689159915, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689159915, loc:(*time.Location)(0x89eb0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689159915, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689159915, loc:(*time.Location)(0x89eb0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 18:18:48.547: INFO: Waited 2.523207512s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:18:48.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "aggregator-1011" for this suite.
Mar 25 18:18:55.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:18:55.153: INFO: namespace aggregator-1011 deletion completed in 6.173378311s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's memory request [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:18:55.154: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 18:18:55.186: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1f97871f-4f65-11e9-91ba-a08cfdecc127" in namespace "downward-api-5449" to be "success or failure"
Mar 25 18:18:55.190: INFO: Pod "downwardapi-volume-1f97871f-4f65-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.686058ms
Mar 25 18:18:57.193: INFO: Pod "downwardapi-volume-1f97871f-4f65-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007182369s
Mar 25 18:18:59.197: INFO: Pod "downwardapi-volume-1f97871f-4f65-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011328499s
[1mSTEP[0m: Saw pod success
Mar 25 18:18:59.197: INFO: Pod "downwardapi-volume-1f97871f-4f65-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:18:59.201: INFO: Trying to get logs from node conformance-worker pod downwardapi-volume-1f97871f-4f65-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:18:59.219: INFO: Waiting for pod downwardapi-volume-1f97871f-4f65-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:18:59.221: INFO: Pod downwardapi-volume-1f97871f-4f65-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:18:59.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-5449" for this suite.
Mar 25 18:19:05.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:19:05.300: INFO: namespace downward-api-5449 deletion completed in 6.077228219s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Subpath[0m [90mAtomic writer volumes[0m 
  [1mshould support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Subpath
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:19:05.301: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename subpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
[1mSTEP[0m: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating pod pod-subpath-test-configmap-v6f5
[1mSTEP[0m: Creating a pod to test atomic-volume-subpath
Mar 25 18:19:05.339: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-v6f5" in namespace "subpath-1658" to be "success or failure"
Mar 25 18:19:05.341: INFO: Pod "pod-subpath-test-configmap-v6f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1.694505ms
Mar 25 18:19:07.345: INFO: Pod "pod-subpath-test-configmap-v6f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005749091s
Mar 25 18:19:09.349: INFO: Pod "pod-subpath-test-configmap-v6f5": Phase="Running", Reason="", readiness=true. Elapsed: 4.009736444s
Mar 25 18:19:11.353: INFO: Pod "pod-subpath-test-configmap-v6f5": Phase="Running", Reason="", readiness=true. Elapsed: 6.013859483s
Mar 25 18:19:13.356: INFO: Pod "pod-subpath-test-configmap-v6f5": Phase="Running", Reason="", readiness=true. Elapsed: 8.016697362s
Mar 25 18:19:15.359: INFO: Pod "pod-subpath-test-configmap-v6f5": Phase="Running", Reason="", readiness=true. Elapsed: 10.020054612s
Mar 25 18:19:17.362: INFO: Pod "pod-subpath-test-configmap-v6f5": Phase="Running", Reason="", readiness=true. Elapsed: 12.023004941s
Mar 25 18:19:19.365: INFO: Pod "pod-subpath-test-configmap-v6f5": Phase="Running", Reason="", readiness=true. Elapsed: 14.025963352s
Mar 25 18:19:21.369: INFO: Pod "pod-subpath-test-configmap-v6f5": Phase="Running", Reason="", readiness=true. Elapsed: 16.029510387s
Mar 25 18:19:23.372: INFO: Pod "pod-subpath-test-configmap-v6f5": Phase="Running", Reason="", readiness=true. Elapsed: 18.032802797s
Mar 25 18:19:25.376: INFO: Pod "pod-subpath-test-configmap-v6f5": Phase="Running", Reason="", readiness=true. Elapsed: 20.036458382s
Mar 25 18:19:27.380: INFO: Pod "pod-subpath-test-configmap-v6f5": Phase="Running", Reason="", readiness=true. Elapsed: 22.040411746s
Mar 25 18:19:29.384: INFO: Pod "pod-subpath-test-configmap-v6f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.044733436s
[1mSTEP[0m: Saw pod success
Mar 25 18:19:29.384: INFO: Pod "pod-subpath-test-configmap-v6f5" satisfied condition "success or failure"
Mar 25 18:19:29.387: INFO: Trying to get logs from node conformance-worker2 pod pod-subpath-test-configmap-v6f5 container test-container-subpath-configmap-v6f5: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:19:29.413: INFO: Waiting for pod pod-subpath-test-configmap-v6f5 to disappear
Mar 25 18:19:29.423: INFO: Pod pod-subpath-test-configmap-v6f5 no longer exists
[1mSTEP[0m: Deleting pod pod-subpath-test-configmap-v6f5
Mar 25 18:19:29.423: INFO: Deleting pod "pod-subpath-test-configmap-v6f5" in namespace "subpath-1658"
[AfterEach] [sig-storage] Subpath
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:19:29.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "subpath-1658" for this suite.
Mar 25 18:19:35.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:19:35.505: INFO: namespace subpath-1658 deletion completed in 6.0773402s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Kubelet[0m [90mwhen scheduling a busybox command in a pod[0m 
  [1mshould print the output to logs [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Kubelet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:19:35.505: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename kubelet-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:19:37.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubelet-test-9484" for this suite.
Mar 25 18:20:15.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:20:15.636: INFO: namespace kubelet-test-9484 deletion completed in 38.070907985s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:20:15.636: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test emptydir 0666 on node default medium
Mar 25 18:20:15.661: INFO: Waiting up to 5m0s for pod "pod-4f8ee217-4f65-11e9-91ba-a08cfdecc127" in namespace "emptydir-5201" to be "success or failure"
Mar 25 18:20:15.670: INFO: Pod "pod-4f8ee217-4f65-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 8.720257ms
Mar 25 18:20:17.673: INFO: Pod "pod-4f8ee217-4f65-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012573833s
[1mSTEP[0m: Saw pod success
Mar 25 18:20:17.673: INFO: Pod "pod-4f8ee217-4f65-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:20:17.676: INFO: Trying to get logs from node conformance-worker2 pod pod-4f8ee217-4f65-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:20:17.693: INFO: Waiting for pod pod-4f8ee217-4f65-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:20:17.696: INFO: Pod pod-4f8ee217-4f65-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:20:17.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-5201" for this suite.
Mar 25 18:20:23.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:20:23.774: INFO: namespace emptydir-5201 deletion completed in 6.075352131s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Docker Containers
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:20:23.774: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename containers
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test override command
Mar 25 18:20:23.806: INFO: Waiting up to 5m0s for pod "client-containers-5469b364-4f65-11e9-91ba-a08cfdecc127" in namespace "containers-1734" to be "success or failure"
Mar 25 18:20:23.811: INFO: Pod "client-containers-5469b364-4f65-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 5.416486ms
Mar 25 18:20:25.815: INFO: Pod "client-containers-5469b364-4f65-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009218352s
Mar 25 18:20:27.818: INFO: Pod "client-containers-5469b364-4f65-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011825515s
[1mSTEP[0m: Saw pod success
Mar 25 18:20:27.818: INFO: Pod "client-containers-5469b364-4f65-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:20:27.820: INFO: Trying to get logs from node conformance-worker pod client-containers-5469b364-4f65-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:20:27.839: INFO: Waiting for pod client-containers-5469b364-4f65-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:20:27.841: INFO: Pod client-containers-5469b364-4f65-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:20:27.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "containers-1734" for this suite.
Mar 25 18:20:33.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:20:33.917: INFO: namespace containers-1734 deletion completed in 6.07357396s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:20:33.917: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating secret with name secret-test-map-5a74fd54-4f65-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 25 18:20:33.948: INFO: Waiting up to 5m0s for pod "pod-secrets-5a754db9-4f65-11e9-91ba-a08cfdecc127" in namespace "secrets-3904" to be "success or failure"
Mar 25 18:20:33.951: INFO: Pod "pod-secrets-5a754db9-4f65-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.039548ms
Mar 25 18:20:35.954: INFO: Pod "pod-secrets-5a754db9-4f65-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005905773s
[1mSTEP[0m: Saw pod success
Mar 25 18:20:35.954: INFO: Pod "pod-secrets-5a754db9-4f65-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:20:35.956: INFO: Trying to get logs from node conformance-worker2 pod pod-secrets-5a754db9-4f65-11e9-91ba-a08cfdecc127 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:20:35.970: INFO: Waiting for pod pod-secrets-5a754db9-4f65-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:20:35.972: INFO: Pod pod-secrets-5a754db9-4f65-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:20:35.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "secrets-3904" for this suite.
Mar 25 18:20:41.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:20:42.032: INFO: namespace secrets-3904 deletion completed in 6.05880965s
[32mâ€¢[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] DNS[0m 
  [1mshould provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-network] DNS
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:20:42.032: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename dns
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4788.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-4788.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4788.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

[1mSTEP[0m: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4788.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-4788.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4788.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

[1mSTEP[0m: creating a pod to probe /etc/hosts
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: retrieving the pod
[1mSTEP[0m: looking for the results for each expected name from probers
Mar 25 18:20:58.087: INFO: Unable to read jessie_hosts@dns-querier-1.dns-test-service.dns-4788.svc.cluster.local from pod dns-4788/dns-test-5f4b0897-4f65-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-5f4b0897-4f65-11e9-91ba-a08cfdecc127)
Mar 25 18:20:58.090: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-4788/dns-test-5f4b0897-4f65-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-5f4b0897-4f65-11e9-91ba-a08cfdecc127)
Mar 25 18:20:58.092: INFO: Unable to read jessie_udp@PodARecord from pod dns-4788/dns-test-5f4b0897-4f65-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-5f4b0897-4f65-11e9-91ba-a08cfdecc127)
Mar 25 18:20:58.094: INFO: Unable to read jessie_tcp@PodARecord from pod dns-4788/dns-test-5f4b0897-4f65-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-5f4b0897-4f65-11e9-91ba-a08cfdecc127)
Mar 25 18:20:58.094: INFO: Lookups using dns-4788/dns-test-5f4b0897-4f65-11e9-91ba-a08cfdecc127 failed for: [jessie_hosts@dns-querier-1.dns-test-service.dns-4788.svc.cluster.local jessie_hosts@dns-querier-1 jessie_udp@PodARecord jessie_tcp@PodARecord]

Mar 25 18:21:03.119: INFO: DNS probes using dns-4788/dns-test-5f4b0897-4f65-11e9-91ba-a08cfdecc127 succeeded

[1mSTEP[0m: deleting the pod
[AfterEach] [sig-network] DNS
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:21:03.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "dns-4788" for this suite.
Mar 25 18:21:09.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:21:09.210: INFO: namespace dns-4788 deletion completed in 6.076742995s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-network] Networking
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:21:09.211: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename pod-network-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Performing setup for networking test in namespace pod-network-test-3423
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
Mar 25 18:21:09.240: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[1mSTEP[0m: Creating test pods
Mar 25 18:21:35.294: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.38.0.2:8080/dial?request=hostName&protocol=http&host=10.32.0.2&port=8080&tries=1'] Namespace:pod-network-test-3423 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 18:21:35.294: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 18:21:35.726: INFO: Waiting for endpoints: map[]
Mar 25 18:21:35.730: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.38.0.2:8080/dial?request=hostName&protocol=http&host=10.38.0.1&port=8080&tries=1'] Namespace:pod-network-test-3423 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 18:21:35.730: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 18:21:35.894: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:21:35.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "pod-network-test-3423" for this suite.
Mar 25 18:21:57.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:21:57.964: INFO: namespace pod-network-test-3423 deletion completed in 22.067597945s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mRollingUpdateDeployment should delete old pods and create new ones [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:21:57.965: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Mar 25 18:21:57.990: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar 25 18:21:57.995: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar 25 18:22:02.999: INFO: Pod name sample-pod: Found 1 pods out of 1
[1mSTEP[0m: ensuring each pod is running
Mar 25 18:22:02.999: INFO: Creating deployment "test-rolling-update-deployment"
Mar 25 18:22:03.003: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar 25 18:22:03.011: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar 25 18:22:05.017: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar 25 18:22:05.019: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160123, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160123, loc:(*time.Location)(0x89eb0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160123, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160123, loc:(*time.Location)(0x89eb0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67599b4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 18:22:07.022: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 25 18:22:07.030: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-5423,SelfLink:/apis/apps/v1/namespaces/deployment-5423/deployments/test-rolling-update-deployment,UID:8f8a366e-4f65-11e9-8304-02427cbbc9a0,ResourceVersion:13228,Generation:1,CreationTimestamp:2019-03-25 18:22:03 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-25 18:22:03 -0700 PDT 2019-03-25 18:22:03 -0700 PDT MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-25 18:22:05 -0700 PDT 2019-03-25 18:22:03 -0700 PDT NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 25 18:22:07.033: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-5423,SelfLink:/apis/apps/v1/namespaces/deployment-5423/replicasets/test-rolling-update-deployment-67599b4d9,UID:8f8cc65c-4f65-11e9-8304-02427cbbc9a0,ResourceVersion:13217,Generation:1,CreationTimestamp:2019-03-25 18:22:03 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 8f8a366e-4f65-11e9-8304-02427cbbc9a0 0xc0027f81c0 0xc0027f81c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 25 18:22:07.033: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar 25 18:22:07.033: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-5423,SelfLink:/apis/apps/v1/namespaces/deployment-5423/replicasets/test-rolling-update-controller,UID:8c8ddfaf-4f65-11e9-8304-02427cbbc9a0,ResourceVersion:13226,Generation:2,CreationTimestamp:2019-03-25 18:21:57 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 8f8a366e-4f65-11e9-8304-02427cbbc9a0 0xc0027f80f7 0xc0027f80f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 25 18:22:07.036: INFO: Pod "test-rolling-update-deployment-67599b4d9-267js" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-267js,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-5423,SelfLink:/api/v1/namespaces/deployment-5423/pods/test-rolling-update-deployment-67599b4d9-267js,UID:8f8d2729-4f65-11e9-8304-02427cbbc9a0,ResourceVersion:13216,Generation:0,CreationTimestamp:2019-03-25 18:22:03 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 8f8cc65c-4f65-11e9-8304-02427cbbc9a0 0xc0027f8b00 0xc0027f8b01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ff8bn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ff8bn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-ff8bn true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027f8b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027f8bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:22:03 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:22:05 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:22:05 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:22:03 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.2,PodIP:10.32.0.2,StartTime:2019-03-25 18:22:03 -0700 PDT,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-25 18:22:05 -0700 PDT,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://dcadf7500703ee1f2fb9e9a8aab025493ff001922b89ded2614ad81f5d48bf7b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:22:07.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "deployment-5423" for this suite.
Mar 25 18:22:13.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:22:13.113: INFO: namespace deployment-5423 deletion completed in 6.074594179s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mshould perform canary updates and phased rolling updates of template modifications [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:22:13.114: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace statefulset-7265
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a new StatefulSet
Mar 25 18:22:13.159: INFO: Found 0 stateful pods, waiting for 3
Mar 25 18:22:23.163: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 18:22:23.163: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 18:22:23.163: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 25 18:22:23.191: INFO: Updating stateful set ss2
[1mSTEP[0m: Creating a new revision
[1mSTEP[0m: Not applying an update when the partition is greater than the number of replicas
[1mSTEP[0m: Performing a canary update
Mar 25 18:22:33.227: INFO: Updating stateful set ss2
Mar 25 18:22:33.237: INFO: Waiting for Pod statefulset-7265/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
[1mSTEP[0m: Restoring Pods to the correct revision when they are deleted
Mar 25 18:22:43.283: INFO: Found 2 stateful pods, waiting for 3
Mar 25 18:22:53.287: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 18:22:53.287: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 18:22:53.287: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Performing a phased rolling update
Mar 25 18:22:53.308: INFO: Updating stateful set ss2
Mar 25 18:22:53.313: INFO: Waiting for Pod statefulset-7265/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 25 18:23:03.333: INFO: Updating stateful set ss2
Mar 25 18:23:03.343: INFO: Waiting for StatefulSet statefulset-7265/ss2 to complete update
Mar 25 18:23:03.343: INFO: Waiting for Pod statefulset-7265/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 25 18:23:13.348: INFO: Deleting all statefulset in ns statefulset-7265
Mar 25 18:23:13.350: INFO: Scaling statefulset ss2 to 0
Mar 25 18:23:33.365: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 18:23:33.368: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:23:33.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "statefulset-7265" for this suite.
Mar 25 18:23:39.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:23:39.480: INFO: namespace statefulset-7265 deletion completed in 6.095489208s
[32mâ€¢[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Proxy[0m [90mversion v1[0m 
  [1mshould proxy logs on node using proxy subresource  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] version v1
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:23:39.481: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename proxy
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Mar 25 18:23:39.526: INFO: (0) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.532535ms)
Mar 25 18:23:39.529: INFO: (1) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.375542ms)
Mar 25 18:23:39.531: INFO: (2) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.714607ms)
Mar 25 18:23:39.534: INFO: (3) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.809351ms)
Mar 25 18:23:39.537: INFO: (4) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.708962ms)
Mar 25 18:23:39.541: INFO: (5) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.657255ms)
Mar 25 18:23:39.543: INFO: (6) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.477083ms)
Mar 25 18:23:39.546: INFO: (7) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.825317ms)
Mar 25 18:23:39.548: INFO: (8) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.370766ms)
Mar 25 18:23:39.551: INFO: (9) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.577741ms)
Mar 25 18:23:39.554: INFO: (10) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.582677ms)
Mar 25 18:23:39.556: INFO: (11) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.954463ms)
Mar 25 18:23:39.558: INFO: (12) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.97786ms)
Mar 25 18:23:39.559: INFO: (13) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.764486ms)
Mar 25 18:23:39.561: INFO: (14) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.855163ms)
Mar 25 18:23:39.564: INFO: (15) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.20992ms)
Mar 25 18:23:39.565: INFO: (16) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.868676ms)
Mar 25 18:23:39.568: INFO: (17) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.273635ms)
Mar 25 18:23:39.570: INFO: (18) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.067243ms)
Mar 25 18:23:39.572: INFO: (19) /api/v1/nodes/conformance-worker/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.142396ms)
[AfterEach] version v1
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:23:39.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "proxy-7027" for this suite.
Mar 25 18:23:45.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:23:45.648: INFO: namespace proxy-7027 deletion completed in 6.074072173s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould be restarted with a /healthz http liveness probe [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:23:45.648: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating pod liveness-http in namespace container-probe-3157
Mar 25 18:23:49.683: INFO: Started pod liveness-http in namespace container-probe-3157
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
Mar 25 18:23:49.686: INFO: Initial restart count of pod liveness-http is 0
Mar 25 18:24:07.727: INFO: Restart count of pod container-probe-3157/liveness-http is now 1 (18.040242993s elapsed)
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:24:07.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-probe-3157" for this suite.
Mar 25 18:24:13.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:24:13.820: INFO: namespace container-probe-3157 deletion completed in 6.071471313s
[32mâ€¢[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mwith readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:24:13.820: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Mar 25 18:24:37.865: INFO: Container started at 2019-03-25 18:24:15 -0700 PDT, pod became ready at 2019-03-25 18:24:37 -0700 PDT
[AfterEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:24:37.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-probe-7494" for this suite.
Mar 25 18:24:59.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:24:59.933: INFO: namespace container-probe-7494 deletion completed in 22.065246257s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] ConfigMap[0m 
  [1mshould be consumable via environment variable [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-node] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:24:59.933: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap configmap-617/configmap-test-f904c79e-4f65-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 25 18:24:59.970: INFO: Waiting up to 5m0s for pod "pod-configmaps-f9052d7c-4f65-11e9-91ba-a08cfdecc127" in namespace "configmap-617" to be "success or failure"
Mar 25 18:24:59.973: INFO: Pod "pod-configmaps-f9052d7c-4f65-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.708441ms
Mar 25 18:25:01.977: INFO: Pod "pod-configmaps-f9052d7c-4f65-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006924877s
Mar 25 18:25:03.981: INFO: Pod "pod-configmaps-f9052d7c-4f65-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010571474s
[1mSTEP[0m: Saw pod success
Mar 25 18:25:03.981: INFO: Pod "pod-configmaps-f9052d7c-4f65-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:25:03.984: INFO: Trying to get logs from node conformance-worker2 pod pod-configmaps-f9052d7c-4f65-11e9-91ba-a08cfdecc127 container env-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:25:04.006: INFO: Waiting for pod pod-configmaps-f9052d7c-4f65-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:25:04.008: INFO: Pod pod-configmaps-f9052d7c-4f65-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-node] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:25:04.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-617" for this suite.
Mar 25 18:25:10.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:25:10.072: INFO: namespace configmap-617 deletion completed in 6.061614414s
[32mâ€¢[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mshould perform rolling updates and roll backs of template modifications [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:25:10.072: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace statefulset-5101
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a new StatefulSet
Mar 25 18:25:10.111: INFO: Found 0 stateful pods, waiting for 3
Mar 25 18:25:20.115: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 18:25:20.115: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 18:25:20.115: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar 25 18:25:20.125: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-5101 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 18:25:20.380: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 18:25:20.380: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 18:25:20.380: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

[1mSTEP[0m: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 25 18:25:30.413: INFO: Updating stateful set ss2
[1mSTEP[0m: Creating a new revision
[1mSTEP[0m: Updating Pods in reverse ordinal order
Mar 25 18:25:40.446: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-5101 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 18:25:40.704: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar 25 18:25:40.704: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 18:25:40.704: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 18:25:50.723: INFO: Waiting for StatefulSet statefulset-5101/ss2 to complete update
Mar 25 18:25:50.723: INFO: Waiting for Pod statefulset-5101/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 25 18:25:50.723: INFO: Waiting for Pod statefulset-5101/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 25 18:26:00.731: INFO: Waiting for StatefulSet statefulset-5101/ss2 to complete update
Mar 25 18:26:00.731: INFO: Waiting for Pod statefulset-5101/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 25 18:26:10.728: INFO: Waiting for StatefulSet statefulset-5101/ss2 to complete update
[1mSTEP[0m: Rolling back to a previous revision
Mar 25 18:26:20.731: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-5101 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 25 18:26:21.010: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar 25 18:26:21.010: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 25 18:26:21.010: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 25 18:26:31.038: INFO: Updating stateful set ss2
[1mSTEP[0m: Rolling back update in reverse ordinal order
Mar 25 18:26:41.055: INFO: Running '/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://localhost:34853 --kubeconfig=/usr/local/google/home/bentheelder/.kube/kind-config-conformance exec --namespace=statefulset-5101 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 25 18:26:41.322: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar 25 18:26:41.322: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 25 18:26:41.322: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 25 18:26:41.333: INFO: Waiting for StatefulSet statefulset-5101/ss2 to complete update
Mar 25 18:26:41.333: INFO: Waiting for Pod statefulset-5101/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar 25 18:26:41.333: INFO: Waiting for Pod statefulset-5101/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar 25 18:26:41.333: INFO: Waiting for Pod statefulset-5101/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar 25 18:26:51.340: INFO: Waiting for StatefulSet statefulset-5101/ss2 to complete update
Mar 25 18:26:51.340: INFO: Waiting for Pod statefulset-5101/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar 25 18:26:51.340: INFO: Waiting for Pod statefulset-5101/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar 25 18:27:01.341: INFO: Waiting for StatefulSet statefulset-5101/ss2 to complete update
Mar 25 18:27:01.341: INFO: Waiting for Pod statefulset-5101/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar 25 18:27:11.340: INFO: Waiting for StatefulSet statefulset-5101/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 25 18:27:21.341: INFO: Deleting all statefulset in ns statefulset-5101
Mar 25 18:27:21.343: INFO: Scaling statefulset ss2 to 0
Mar 25 18:27:41.362: INFO: Waiting for statefulset status.replicas updated to 0
Mar 25 18:27:41.363: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:27:41.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "statefulset-5101" for this suite.
Mar 25 18:27:47.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:27:47.450: INFO: namespace statefulset-5101 deletion completed in 6.078918834s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mwith readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:27:47.450: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:28:47.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-probe-7024" for this suite.
Mar 25 18:29:09.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:29:09.562: INFO: namespace container-probe-7024 deletion completed in 22.074175776s
[32mâ€¢[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:29:09.562: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 18:29:09.589: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8dcdcaee-4f66-11e9-91ba-a08cfdecc127" in namespace "projected-6000" to be "success or failure"
Mar 25 18:29:09.593: INFO: Pod "downwardapi-volume-8dcdcaee-4f66-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.661207ms
Mar 25 18:29:11.596: INFO: Pod "downwardapi-volume-8dcdcaee-4f66-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006750876s
[1mSTEP[0m: Saw pod success
Mar 25 18:29:11.596: INFO: Pod "downwardapi-volume-8dcdcaee-4f66-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:29:11.599: INFO: Trying to get logs from node conformance-worker pod downwardapi-volume-8dcdcaee-4f66-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:29:11.618: INFO: Waiting for pod downwardapi-volume-8dcdcaee-4f66-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:29:11.620: INFO: Pod downwardapi-volume-8dcdcaee-4f66-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:29:11.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-6000" for this suite.
Mar 25 18:29:17.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:29:17.700: INFO: namespace projected-6000 deletion completed in 6.076969226s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mdeployment should support rollover [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:29:17.700: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Mar 25 18:29:17.733: INFO: Pod name rollover-pod: Found 0 pods out of 1
Mar 25 18:29:22.736: INFO: Pod name rollover-pod: Found 1 pods out of 1
[1mSTEP[0m: ensuring each pod is running
Mar 25 18:29:22.736: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar 25 18:29:24.740: INFO: Creating deployment "test-rollover-deployment"
Mar 25 18:29:24.747: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar 25 18:29:26.754: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar 25 18:29:26.760: INFO: Ensure that both replica sets have 1 created replica
Mar 25 18:29:26.765: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar 25 18:29:26.771: INFO: Updating deployment test-rollover-deployment
Mar 25 18:29:26.771: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar 25 18:29:28.784: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar 25 18:29:28.789: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar 25 18:29:28.793: INFO: all replica sets need to contain the pod-template-hash label
Mar 25 18:29:28.793: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160566, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 18:29:30.800: INFO: all replica sets need to contain the pod-template-hash label
Mar 25 18:29:30.800: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160570, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 18:29:32.799: INFO: all replica sets need to contain the pod-template-hash label
Mar 25 18:29:32.799: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160570, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 18:29:34.799: INFO: all replica sets need to contain the pod-template-hash label
Mar 25 18:29:34.800: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160570, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 18:29:36.798: INFO: all replica sets need to contain the pod-template-hash label
Mar 25 18:29:36.798: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160570, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 18:29:38.801: INFO: all replica sets need to contain the pod-template-hash label
Mar 25 18:29:38.801: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160570, loc:(*time.Location)(0x89eb0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160564, loc:(*time.Location)(0x89eb0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 25 18:29:40.800: INFO: 
Mar 25 18:29:40.800: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 25 18:29:40.807: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-7830,SelfLink:/apis/apps/v1/namespaces/deployment-7830/deployments/test-rollover-deployment,UID:96d6a1bc-4f66-11e9-8304-02427cbbc9a0,ResourceVersion:14852,Generation:2,CreationTimestamp:2019-03-25 18:29:24 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-25 18:29:24 -0700 PDT 2019-03-25 18:29:24 -0700 PDT MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-25 18:29:40 -0700 PDT 2019-03-25 18:29:24 -0700 PDT NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 25 18:29:40.811: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-7830,SelfLink:/apis/apps/v1/namespaces/deployment-7830/replicasets/test-rollover-deployment-766b4d6c9d,UID:980c67e5-4f66-11e9-8304-02427cbbc9a0,ResourceVersion:14841,Generation:2,CreationTimestamp:2019-03-25 18:29:26 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 96d6a1bc-4f66-11e9-8304-02427cbbc9a0 0xc002265237 0xc002265238}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 25 18:29:40.811: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar 25 18:29:40.811: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-7830,SelfLink:/apis/apps/v1/namespaces/deployment-7830/replicasets/test-rollover-controller,UID:92a8b4ea-4f66-11e9-8304-02427cbbc9a0,ResourceVersion:14850,Generation:2,CreationTimestamp:2019-03-25 18:29:17 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 96d6a1bc-4f66-11e9-8304-02427cbbc9a0 0xc002265077 0xc002265078}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 25 18:29:40.811: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-7830,SelfLink:/apis/apps/v1/namespaces/deployment-7830/replicasets/test-rollover-deployment-6455657675,UID:96d85c22-4f66-11e9-8304-02427cbbc9a0,ResourceVersion:14803,Generation:2,CreationTimestamp:2019-03-25 18:29:24 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 96d6a1bc-4f66-11e9-8304-02427cbbc9a0 0xc002265157 0xc002265158}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 25 18:29:40.814: INFO: Pod "test-rollover-deployment-766b4d6c9d-vdt7d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-vdt7d,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-7830,SelfLink:/api/v1/namespaces/deployment-7830/pods/test-rollover-deployment-766b4d6c9d-vdt7d,UID:980fc275-4f66-11e9-8304-02427cbbc9a0,ResourceVersion:14822,Generation:0,CreationTimestamp:2019-03-25 18:29:26 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d 980c67e5-4f66-11e9-8304-02427cbbc9a0 0xc002265d47 0xc002265d48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2htbr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2htbr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-2htbr true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002265db0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002265dd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:29:26 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:29:30 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:29:30 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:29:26 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.3,PodIP:10.38.0.2,StartTime:2019-03-25 18:29:26 -0700 PDT,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-25 18:29:29 -0700 PDT,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://0abafe7f329ffae9fc15f57e63582ad3f2183381a54e522583aee55b34a8954b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:29:40.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "deployment-7830" for this suite.
Mar 25 18:29:46.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:29:46.878: INFO: namespace deployment-7830 deletion completed in 6.061150394s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mshould be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:29:46.878: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-map-a40c56b3-4f66-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 25 18:29:46.912: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a40ce9c6-4f66-11e9-91ba-a08cfdecc127" in namespace "projected-9976" to be "success or failure"
Mar 25 18:29:46.919: INFO: Pod "pod-projected-configmaps-a40ce9c6-4f66-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 6.841939ms
Mar 25 18:29:48.923: INFO: Pod "pod-projected-configmaps-a40ce9c6-4f66-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010572321s
[1mSTEP[0m: Saw pod success
Mar 25 18:29:48.923: INFO: Pod "pod-projected-configmaps-a40ce9c6-4f66-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:29:48.926: INFO: Trying to get logs from node conformance-worker pod pod-projected-configmaps-a40ce9c6-4f66-11e9-91ba-a08cfdecc127 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:29:48.944: INFO: Waiting for pod pod-projected-configmaps-a40ce9c6-4f66-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:29:48.947: INFO: Pod pod-projected-configmaps-a40ce9c6-4f66-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:29:48.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-9976" for this suite.
Mar 25 18:29:54.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:29:55.026: INFO: namespace projected-9976 deletion completed in 6.075832314s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Kubelet[0m [90mwhen scheduling a busybox command that always fails in a pod[0m 
  [1mshould have an terminated reason [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Kubelet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:29:55.026: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename kubelet-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:29:59.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubelet-test-5906" for this suite.
Mar 25 18:30:05.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:30:05.141: INFO: namespace kubelet-test-5906 deletion completed in 6.075733861s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] InitContainer [NodeConformance][0m 
  [1mshould not start app containers if init containers fail on a RestartAlways pod [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:30:05.141: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename init-container
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating the pod
Mar 25 18:30:05.171: INFO: PodSpec: initContainers in spec.initContainers
Mar 25 18:31:02.597: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-aeefc7e9-4f66-11e9-91ba-a08cfdecc127", GenerateName:"", Namespace:"init-container-1554", SelfLink:"/api/v1/namespaces/init-container-1554/pods/pod-init-aeefc7e9-4f66-11e9-91ba-a08cfdecc127", UID:"aef04cb2-4f66-11e9-8304-02427cbbc9a0", ResourceVersion:"15108", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63689160605, loc:(*time.Location)(0x89eb0e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"171919666"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fgb2j", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0020c7400), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fgb2j", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fgb2j", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fgb2j", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002bd5b58), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"conformance-worker", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002245e00), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002bd5be0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002bd5c00)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002bd5c08), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002bd5c0c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160605, loc:(*time.Location)(0x89eb0e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160605, loc:(*time.Location)(0x89eb0e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160605, loc:(*time.Location)(0x89eb0e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689160605, loc:(*time.Location)(0x89eb0e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.9.2", PodIP:"10.32.0.2", StartTime:(*v1.Time)(0xc0021442e0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000e4e3f0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000e4e460)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://617d0e2c7674dde61eb1f5ed9e461c9c1ce5e2480c73808490a9929712adc4d0"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002144320), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002144300), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:31:02.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "init-container-1554" for this suite.
Mar 25 18:31:24.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:31:24.676: INFO: namespace init-container-1554 deletion completed in 22.070844599s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:31:24.676: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test emptydir 0777 on tmpfs
Mar 25 18:31:24.712: INFO: Waiting up to 5m0s for pod "pod-de5808ce-4f66-11e9-91ba-a08cfdecc127" in namespace "emptydir-5883" to be "success or failure"
Mar 25 18:31:24.718: INFO: Pod "pod-de5808ce-4f66-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 6.285291ms
Mar 25 18:31:26.722: INFO: Pod "pod-de5808ce-4f66-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01015268s
Mar 25 18:31:28.725: INFO: Pod "pod-de5808ce-4f66-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013019082s
[1mSTEP[0m: Saw pod success
Mar 25 18:31:28.725: INFO: Pod "pod-de5808ce-4f66-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:31:28.728: INFO: Trying to get logs from node conformance-worker2 pod pod-de5808ce-4f66-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:31:28.744: INFO: Waiting for pod pod-de5808ce-4f66-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:31:28.747: INFO: Pod pod-de5808ce-4f66-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:31:28.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-5883" for this suite.
Mar 25 18:31:34.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:31:34.808: INFO: namespace emptydir-5883 deletion completed in 6.059088421s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Secrets[0m 
  [1mshould be consumable from pods in env vars [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-api-machinery] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:31:34.808: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating secret with name secret-test-e4615976-4f66-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 25 18:31:34.841: INFO: Waiting up to 5m0s for pod "pod-secrets-e461ad26-4f66-11e9-91ba-a08cfdecc127" in namespace "secrets-5074" to be "success or failure"
Mar 25 18:31:34.843: INFO: Pod "pod-secrets-e461ad26-4f66-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.63661ms
Mar 25 18:31:36.846: INFO: Pod "pod-secrets-e461ad26-4f66-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005303713s
[1mSTEP[0m: Saw pod success
Mar 25 18:31:36.846: INFO: Pod "pod-secrets-e461ad26-4f66-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:31:36.849: INFO: Trying to get logs from node conformance-worker pod pod-secrets-e461ad26-4f66-11e9-91ba-a08cfdecc127 container secret-env-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:31:36.864: INFO: Waiting for pod pod-secrets-e461ad26-4f66-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:31:36.866: INFO: Pod pod-secrets-e461ad26-4f66-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:31:36.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "secrets-5074" for this suite.
Mar 25 18:31:42.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:31:42.933: INFO: namespace secrets-5074 deletion completed in 6.065256224s
[32mâ€¢[0m
[90m------------------------------[0m
[0m[sig-network] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-network] Networking
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:31:42.933: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename pod-network-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Performing setup for networking test in namespace pod-network-test-3282
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
Mar 25 18:31:42.970: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[1mSTEP[0m: Creating test pods
Mar 25 18:32:07.034: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.32.0.3:8080/dial?request=hostName&protocol=udp&host=10.38.0.1&port=8081&tries=1'] Namespace:pod-network-test-3282 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 18:32:07.034: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 18:32:07.268: INFO: Waiting for endpoints: map[]
Mar 25 18:32:07.272: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.32.0.3:8080/dial?request=hostName&protocol=udp&host=10.32.0.2&port=8081&tries=1'] Namespace:pod-network-test-3282 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 25 18:32:07.272: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
Mar 25 18:32:07.433: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:32:07.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "pod-network-test-3282" for this suite.
Mar 25 18:32:29.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:32:29.501: INFO: namespace pod-network-test-3282 deletion completed in 22.064715629s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Kubelet[0m [90mwhen scheduling a busybox command that always fails in a pod[0m 
  [1mshould be possible to delete [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Kubelet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:32:29.501: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename kubelet-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:32:29.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubelet-test-4422" for this suite.
Mar 25 18:32:35.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:32:35.619: INFO: namespace kubelet-test-4422 deletion completed in 6.070202437s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:32:35.620: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: updating the pod
Mar 25 18:32:38.179: INFO: Successfully updated pod "pod-update-activedeadlineseconds-08a14702-4f67-11e9-91ba-a08cfdecc127"
Mar 25 18:32:38.180: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-08a14702-4f67-11e9-91ba-a08cfdecc127" in namespace "pods-2351" to be "terminated due to deadline exceeded"
Mar 25 18:32:38.182: INFO: Pod "pod-update-activedeadlineseconds-08a14702-4f67-11e9-91ba-a08cfdecc127": Phase="Running", Reason="", readiness=true. Elapsed: 2.380355ms
Mar 25 18:32:40.186: INFO: Pod "pod-update-activedeadlineseconds-08a14702-4f67-11e9-91ba-a08cfdecc127": Phase="Running", Reason="", readiness=true. Elapsed: 2.006468897s
Mar 25 18:32:42.190: INFO: Pod "pod-update-activedeadlineseconds-08a14702-4f67-11e9-91ba-a08cfdecc127": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.010669322s
Mar 25 18:32:42.190: INFO: Pod "pod-update-activedeadlineseconds-08a14702-4f67-11e9-91ba-a08cfdecc127" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:32:42.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-2351" for this suite.
Mar 25 18:32:48.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:32:48.260: INFO: namespace pods-2351 deletion completed in 6.065843647s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould set mode on item file [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:32:48.260: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 18:32:48.288: INFO: Waiting up to 5m0s for pod "downwardapi-volume-10286c22-4f67-11e9-91ba-a08cfdecc127" in namespace "downward-api-9481" to be "success or failure"
Mar 25 18:32:48.295: INFO: Pod "downwardapi-volume-10286c22-4f67-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 6.587714ms
Mar 25 18:32:50.299: INFO: Pod "downwardapi-volume-10286c22-4f67-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010403104s
Mar 25 18:32:52.302: INFO: Pod "downwardapi-volume-10286c22-4f67-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013791436s
[1mSTEP[0m: Saw pod success
Mar 25 18:32:52.302: INFO: Pod "downwardapi-volume-10286c22-4f67-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:32:52.305: INFO: Trying to get logs from node conformance-worker2 pod downwardapi-volume-10286c22-4f67-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:32:52.320: INFO: Waiting for pod downwardapi-volume-10286c22-4f67-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:32:52.323: INFO: Pod downwardapi-volume-10286c22-4f67-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:32:52.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-9481" for this suite.
Mar 25 18:32:58.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:32:58.398: INFO: namespace downward-api-9481 deletion completed in 6.072972884s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:32:58.398: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 18:32:58.427: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1633bdec-4f67-11e9-91ba-a08cfdecc127" in namespace "projected-4088" to be "success or failure"
Mar 25 18:32:58.429: INFO: Pod "downwardapi-volume-1633bdec-4f67-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100334ms
Mar 25 18:33:00.433: INFO: Pod "downwardapi-volume-1633bdec-4f67-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006051809s
Mar 25 18:33:02.437: INFO: Pod "downwardapi-volume-1633bdec-4f67-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010405091s
[1mSTEP[0m: Saw pod success
Mar 25 18:33:02.437: INFO: Pod "downwardapi-volume-1633bdec-4f67-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:33:02.441: INFO: Trying to get logs from node conformance-worker pod downwardapi-volume-1633bdec-4f67-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:33:02.471: INFO: Waiting for pod downwardapi-volume-1633bdec-4f67-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:33:02.474: INFO: Pod downwardapi-volume-1633bdec-4f67-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:33:02.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-4088" for this suite.
Mar 25 18:33:08.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:33:08.551: INFO: namespace projected-4088 deletion completed in 6.074219284s
[32mâ€¢[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould be able to restart watching from the last resource version observed by the previous watch [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-api-machinery] Watchers
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:33:08.551: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename watch
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating a watch on configmaps
[1mSTEP[0m: creating a new configmap
[1mSTEP[0m: modifying the configmap once
[1mSTEP[0m: closing the watch once it receives two notifications
Mar 25 18:33:08.593: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2651,SelfLink:/api/v1/namespaces/watch-2651/configmaps/e2e-watch-test-watch-closed,UID:1c422a6c-4f67-11e9-8304-02427cbbc9a0,ResourceVersion:15559,Generation:0,CreationTimestamp:2019-03-25 18:33:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 25 18:33:08.593: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2651,SelfLink:/api/v1/namespaces/watch-2651/configmaps/e2e-watch-test-watch-closed,UID:1c422a6c-4f67-11e9-8304-02427cbbc9a0,ResourceVersion:15560,Generation:0,CreationTimestamp:2019-03-25 18:33:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying the configmap a second time, while the watch is closed
[1mSTEP[0m: creating a new watch on configmaps from the last resource version observed by the first watch
[1mSTEP[0m: deleting the configmap
[1mSTEP[0m: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar 25 18:33:08.600: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2651,SelfLink:/api/v1/namespaces/watch-2651/configmaps/e2e-watch-test-watch-closed,UID:1c422a6c-4f67-11e9-8304-02427cbbc9a0,ResourceVersion:15561,Generation:0,CreationTimestamp:2019-03-25 18:33:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 25 18:33:08.600: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2651,SelfLink:/api/v1/namespaces/watch-2651/configmaps/e2e-watch-test-watch-closed,UID:1c422a6c-4f67-11e9-8304-02427cbbc9a0,ResourceVersion:15562,Generation:0,CreationTimestamp:2019-03-25 18:33:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:33:08.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "watch-2651" for this suite.
Mar 25 18:33:14.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:33:14.682: INFO: namespace watch-2651 deletion completed in 6.079318864s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir wrapper volumes[0m 
  [1mshould not conflict [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:33:14.683: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename emptydir-wrapper
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Cleaning up the secret
[1mSTEP[0m: Cleaning up the configmap
[1mSTEP[0m: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:33:18.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-wrapper-8713" for this suite.
Mar 25 18:33:24.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:33:24.825: INFO: namespace emptydir-wrapper-8713 deletion completed in 6.075708583s
[32mâ€¢[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Variable Expansion[0m 
  [1mshould allow composing env vars into new env vars [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Variable Expansion
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:33:24.825: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename var-expansion
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test env composition
Mar 25 18:33:24.862: INFO: Waiting up to 5m0s for pod "var-expansion-25f48b56-4f67-11e9-91ba-a08cfdecc127" in namespace "var-expansion-2338" to be "success or failure"
Mar 25 18:33:24.867: INFO: Pod "var-expansion-25f48b56-4f67-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 5.542377ms
Mar 25 18:33:26.870: INFO: Pod "var-expansion-25f48b56-4f67-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008239461s
Mar 25 18:33:28.873: INFO: Pod "var-expansion-25f48b56-4f67-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011065585s
[1mSTEP[0m: Saw pod success
Mar 25 18:33:28.873: INFO: Pod "var-expansion-25f48b56-4f67-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:33:28.875: INFO: Trying to get logs from node conformance-worker pod var-expansion-25f48b56-4f67-11e9-91ba-a08cfdecc127 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:33:28.890: INFO: Waiting for pod var-expansion-25f48b56-4f67-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:33:28.892: INFO: Pod var-expansion-25f48b56-4f67-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:33:28.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "var-expansion-2338" for this suite.
Mar 25 18:33:34.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:33:34.960: INFO: namespace var-expansion-2338 deletion completed in 6.066488768s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] ConfigMap[0m 
  [1mshould fail to create ConfigMap with empty key [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-node] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:33:34.960: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap that has name configmap-test-emptyKey-2bff84f6-4f67-11e9-91ba-a08cfdecc127
[AfterEach] [sig-node] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:33:34.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-7349" for this suite.
Mar 25 18:33:41.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:33:41.067: INFO: namespace configmap-7349 deletion completed in 6.074407853s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicationController[0m 
  [1mshould adopt matching pods on creation [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] ReplicationController
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:33:41.067: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename replication-controller
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Given a Pod with a 'name' label pod-adoption is created
[1mSTEP[0m: When a replication controller with a matching selector is created
[1mSTEP[0m: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:33:44.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "replication-controller-9291" for this suite.
Mar 25 18:34:06.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:34:06.200: INFO: namespace replication-controller-9291 deletion completed in 22.076876166s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould orphan pods created by rc if delete options say so [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:34:06.200: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: create the rc
[1mSTEP[0m: delete the rc
[1mSTEP[0m: wait for the rc to be deleted
[1mSTEP[0m: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
[1mSTEP[0m: Gathering metrics
W0325 18:34:46.268536   72333 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 25 18:34:46.268: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:34:46.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "gc-4053" for this suite.
Mar 25 18:34:52.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:34:52.349: INFO: namespace gc-4053 deletion completed in 6.077444886s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould rollback without unnecessary restarts [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:34:52.350: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename daemonsets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Mar 25 18:34:52.382: INFO: Create a RollingUpdate DaemonSet
Mar 25 18:34:52.384: INFO: Check that daemon pods launch on every node of the cluster
Mar 25 18:34:52.390: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:34:52.391: INFO: Number of nodes with available pods: 0
Mar 25 18:34:52.391: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:34:53.394: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:34:53.396: INFO: Number of nodes with available pods: 0
Mar 25 18:34:53.396: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:34:54.394: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:34:54.396: INFO: Number of nodes with available pods: 1
Mar 25 18:34:54.396: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:34:55.394: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:34:55.397: INFO: Number of nodes with available pods: 2
Mar 25 18:34:55.397: INFO: Number of running nodes: 2, number of available pods: 2
Mar 25 18:34:55.397: INFO: Update the DaemonSet to trigger a rollout
Mar 25 18:34:55.403: INFO: Updating DaemonSet daemon-set
Mar 25 18:35:09.415: INFO: Roll back the DaemonSet before rollout is complete
Mar 25 18:35:09.422: INFO: Updating DaemonSet daemon-set
Mar 25 18:35:09.422: INFO: Make sure DaemonSet rollback is complete
Mar 25 18:35:09.426: INFO: Wrong image for pod: daemon-set-hzf6w. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Mar 25 18:35:09.426: INFO: Pod daemon-set-hzf6w is not available
Mar 25 18:35:09.429: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:35:10.433: INFO: Wrong image for pod: daemon-set-hzf6w. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Mar 25 18:35:10.433: INFO: Pod daemon-set-hzf6w is not available
Mar 25 18:35:10.435: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:35:11.434: INFO: Wrong image for pod: daemon-set-hzf6w. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Mar 25 18:35:11.434: INFO: Pod daemon-set-hzf6w is not available
Mar 25 18:35:11.438: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:35:12.432: INFO: Pod daemon-set-wxg8x is not available
Mar 25 18:35:12.435: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1724, will wait for the garbage collector to delete the pods
Mar 25 18:35:12.503: INFO: Deleting DaemonSet.extensions daemon-set took: 12.141511ms
Mar 25 18:35:12.803: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.218729ms
Mar 25 18:36:28.705: INFO: Number of nodes with available pods: 0
Mar 25 18:36:28.705: INFO: Number of running nodes: 0, number of available pods: 0
Mar 25 18:36:28.708: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1724/daemonsets","resourceVersion":"16310"},"items":null}

Mar 25 18:36:28.710: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1724/pods","resourceVersion":"16310"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:36:28.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "daemonsets-1724" for this suite.
Mar 25 18:36:34.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:36:34.795: INFO: namespace daemonsets-1724 deletion completed in 6.075320639s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:36:34.795: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-972fddbf-4f67-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 25 18:36:34.830: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-973071a3-4f67-11e9-91ba-a08cfdecc127" in namespace "projected-6712" to be "success or failure"
Mar 25 18:36:34.832: INFO: Pod "pod-projected-configmaps-973071a3-4f67-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.898513ms
Mar 25 18:36:36.836: INFO: Pod "pod-projected-configmaps-973071a3-4f67-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005867499s
Mar 25 18:36:38.840: INFO: Pod "pod-projected-configmaps-973071a3-4f67-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009773671s
[1mSTEP[0m: Saw pod success
Mar 25 18:36:38.840: INFO: Pod "pod-projected-configmaps-973071a3-4f67-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:36:38.843: INFO: Trying to get logs from node conformance-worker pod pod-projected-configmaps-973071a3-4f67-11e9-91ba-a08cfdecc127 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:36:38.864: INFO: Waiting for pod pod-projected-configmaps-973071a3-4f67-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:36:38.867: INFO: Pod pod-projected-configmaps-973071a3-4f67-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:36:38.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-6712" for this suite.
Mar 25 18:36:44.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:36:44.941: INFO: namespace projected-6712 deletion completed in 6.071591779s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mupdates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:36:44.941: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name configmap-test-upd-9d3bce26-4f67-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Updating configmap configmap-test-upd-9d3bce26-4f67-11e9-91ba-a08cfdecc127
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:37:55.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-2652" for this suite.
Mar 25 18:38:17.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:38:17.422: INFO: namespace configmap-2652 deletion completed in 22.073256835s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Proxy[0m [90mversion v1[0m 
  [1mshould proxy logs on node with explicit kubelet port using proxy subresource  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] version v1
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:38:17.422: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename proxy
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Mar 25 18:38:17.458: INFO: (0) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.84513ms)
Mar 25 18:38:17.460: INFO: (1) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.18135ms)
Mar 25 18:38:17.462: INFO: (2) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.190254ms)
Mar 25 18:38:17.464: INFO: (3) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.790909ms)
Mar 25 18:38:17.466: INFO: (4) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.95801ms)
Mar 25 18:38:17.468: INFO: (5) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.91858ms)
Mar 25 18:38:17.470: INFO: (6) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.07414ms)
Mar 25 18:38:17.472: INFO: (7) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.825235ms)
Mar 25 18:38:17.474: INFO: (8) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.499526ms)
Mar 25 18:38:17.476: INFO: (9) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.200854ms)
Mar 25 18:38:17.479: INFO: (10) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.597397ms)
Mar 25 18:38:17.482: INFO: (11) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.041256ms)
Mar 25 18:38:17.485: INFO: (12) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.779914ms)
Mar 25 18:38:17.487: INFO: (13) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.385708ms)
Mar 25 18:38:17.489: INFO: (14) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.000073ms)
Mar 25 18:38:17.492: INFO: (15) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.192317ms)
Mar 25 18:38:17.494: INFO: (16) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.10681ms)
Mar 25 18:38:17.496: INFO: (17) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.201728ms)
Mar 25 18:38:17.498: INFO: (18) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.207437ms)
Mar 25 18:38:17.500: INFO: (19) /api/v1/nodes/conformance-worker:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.95702ms)
[AfterEach] version v1
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:38:17.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "proxy-3711" for this suite.
Mar 25 18:38:23.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:38:23.561: INFO: namespace proxy-3711 deletion completed in 6.058791707s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:38:23.561: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: create the deployment
[1mSTEP[0m: Wait for the Deployment to create new ReplicaSet
[1mSTEP[0m: delete the deployment
[1mSTEP[0m: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
[1mSTEP[0m: Gathering metrics
W0325 18:38:54.114337   72333 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 25 18:38:54.114: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:38:54.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "gc-2682" for this suite.
Mar 25 18:39:00.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:39:00.189: INFO: namespace gc-2682 deletion completed in 6.072072305s
[32mâ€¢[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] PreStop[0m 
  [1mshould call prestop when killing a pod  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] [sig-node] PreStop
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:39:00.189: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename prestop
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating server pod server in namespace prestop-2800
[1mSTEP[0m: Waiting for pods to come up.
[1mSTEP[0m: Creating tester pod tester in namespace prestop-2800
[1mSTEP[0m: Deleting pre-stop pod
Mar 25 18:39:15.261: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
[1mSTEP[0m: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:39:15.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "prestop-2800" for this suite.
Mar 25 18:39:47.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:39:47.350: INFO: namespace prestop-2800 deletion completed in 32.079564126s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicationController[0m 
  [1mshould release no longer matching pods [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] ReplicationController
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:39:47.351: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename replication-controller
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Given a ReplicationController is created
[1mSTEP[0m: When the matched label of one of its pods change
Mar 25 18:39:47.393: INFO: Pod name pod-release: Found 0 pods out of 1
Mar 25 18:39:52.397: INFO: Pod name pod-release: Found 1 pods out of 1
[1mSTEP[0m: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:39:53.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "replication-controller-6455" for this suite.
Mar 25 18:39:59.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:39:59.490: INFO: namespace replication-controller-6455 deletion completed in 6.073893265s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide container's memory request [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:39:59.490: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 18:39:59.523: INFO: Waiting up to 5m0s for pod "downwardapi-volume-11320421-4f68-11e9-91ba-a08cfdecc127" in namespace "projected-2535" to be "success or failure"
Mar 25 18:39:59.527: INFO: Pod "downwardapi-volume-11320421-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.752994ms
Mar 25 18:40:01.531: INFO: Pod "downwardapi-volume-11320421-4f68-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008029399s
[1mSTEP[0m: Saw pod success
Mar 25 18:40:01.531: INFO: Pod "downwardapi-volume-11320421-4f68-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:40:01.535: INFO: Trying to get logs from node conformance-worker pod downwardapi-volume-11320421-4f68-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:40:01.552: INFO: Waiting for pod downwardapi-volume-11320421-4f68-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:40:01.554: INFO: Pod downwardapi-volume-11320421-4f68-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:40:01.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-2535" for this suite.
Mar 25 18:40:07.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:40:07.635: INFO: namespace projected-2535 deletion completed in 6.079255413s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] Downward API[0m 
  [1mshould provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-node] Downward API
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:40:07.635: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward api env vars
Mar 25 18:40:07.673: INFO: Waiting up to 5m0s for pod "downward-api-160da4b2-4f68-11e9-91ba-a08cfdecc127" in namespace "downward-api-1865" to be "success or failure"
Mar 25 18:40:07.675: INFO: Pod "downward-api-160da4b2-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.967454ms
Mar 25 18:40:09.679: INFO: Pod "downward-api-160da4b2-4f68-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006037871s
[1mSTEP[0m: Saw pod success
Mar 25 18:40:09.679: INFO: Pod "downward-api-160da4b2-4f68-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:40:09.682: INFO: Trying to get logs from node conformance-worker2 pod downward-api-160da4b2-4f68-11e9-91ba-a08cfdecc127 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:40:09.700: INFO: Waiting for pod downward-api-160da4b2-4f68-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:40:09.702: INFO: Pod downward-api-160da4b2-4f68-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-node] Downward API
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:40:09.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-1865" for this suite.
Mar 25 18:40:15.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:40:15.783: INFO: namespace downward-api-1865 deletion completed in 6.078658933s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] HostPath[0m 
  [1mshould give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] HostPath
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:40:15.784: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename hostpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test hostPath mode
Mar 25 18:40:15.819: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-8362" to be "success or failure"
Mar 25 18:40:15.821: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 1.726142ms
Mar 25 18:40:17.824: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004600592s
Mar 25 18:40:19.827: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007772206s
[1mSTEP[0m: Saw pod success
Mar 25 18:40:19.827: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar 25 18:40:19.830: INFO: Trying to get logs from node conformance-worker pod pod-host-path-test container test-container-1: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:40:19.847: INFO: Waiting for pod pod-host-path-test to disappear
Mar 25 18:40:19.849: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:40:19.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "hostpath-8362" for this suite.
Mar 25 18:40:25.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:40:25.918: INFO: namespace hostpath-8362 deletion completed in 6.067058223s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Kubelet[0m [90mwhen scheduling a busybox Pod with hostAliases[0m 
  [1mshould write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Kubelet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:40:25.918: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename kubelet-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:40:27.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubelet-test-9269" for this suite.
Mar 25 18:41:05.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:41:06.061: INFO: namespace kubelet-test-9269 deletion completed in 38.079710587s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mshould be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:41:06.061: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-38dfb138-4f68-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 25 18:41:06.094: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-38e00a1f-4f68-11e9-91ba-a08cfdecc127" in namespace "projected-3365" to be "success or failure"
Mar 25 18:41:06.098: INFO: Pod "pod-projected-configmaps-38e00a1f-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.770378ms
Mar 25 18:41:08.102: INFO: Pod "pod-projected-configmaps-38e00a1f-4f68-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007541842s
[1mSTEP[0m: Saw pod success
Mar 25 18:41:08.102: INFO: Pod "pod-projected-configmaps-38e00a1f-4f68-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:41:08.105: INFO: Trying to get logs from node conformance-worker pod pod-projected-configmaps-38e00a1f-4f68-11e9-91ba-a08cfdecc127 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:41:08.129: INFO: Waiting for pod pod-projected-configmaps-38e00a1f-4f68-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:41:08.132: INFO: Pod pod-projected-configmaps-38e00a1f-4f68-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:41:08.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-3365" for this suite.
Mar 25 18:41:14.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:41:14.216: INFO: namespace projected-3365 deletion completed in 6.080405564s
[32mâ€¢[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] Downward API[0m 
  [1mshould provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-node] Downward API
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:41:14.216: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward api env vars
Mar 25 18:41:14.248: INFO: Waiting up to 5m0s for pod "downward-api-3dbc3392-4f68-11e9-91ba-a08cfdecc127" in namespace "downward-api-5105" to be "success or failure"
Mar 25 18:41:14.250: INFO: Pod "downward-api-3dbc3392-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.841786ms
Mar 25 18:41:16.253: INFO: Pod "downward-api-3dbc3392-4f68-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004350136s
[1mSTEP[0m: Saw pod success
Mar 25 18:41:16.253: INFO: Pod "downward-api-3dbc3392-4f68-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:41:16.254: INFO: Trying to get logs from node conformance-worker2 pod downward-api-3dbc3392-4f68-11e9-91ba-a08cfdecc127 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:41:16.267: INFO: Waiting for pod downward-api-3dbc3392-4f68-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:41:16.270: INFO: Pod downward-api-3dbc3392-4f68-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-node] Downward API
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:41:16.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-5105" for this suite.
Mar 25 18:41:22.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:41:22.336: INFO: namespace downward-api-5105 deletion completed in 6.063520439s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's memory limit [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:41:22.336: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 18:41:22.368: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4292e91b-4f68-11e9-91ba-a08cfdecc127" in namespace "downward-api-7663" to be "success or failure"
Mar 25 18:41:22.371: INFO: Pod "downwardapi-volume-4292e91b-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.616313ms
Mar 25 18:41:24.376: INFO: Pod "downwardapi-volume-4292e91b-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007882853s
Mar 25 18:41:26.380: INFO: Pod "downwardapi-volume-4292e91b-4f68-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012272914s
[1mSTEP[0m: Saw pod success
Mar 25 18:41:26.380: INFO: Pod "downwardapi-volume-4292e91b-4f68-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:41:26.383: INFO: Trying to get logs from node conformance-worker pod downwardapi-volume-4292e91b-4f68-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:41:26.405: INFO: Waiting for pod downwardapi-volume-4292e91b-4f68-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:41:26.406: INFO: Pod downwardapi-volume-4292e91b-4f68-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:41:26.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-7663" for this suite.
Mar 25 18:41:32.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:41:32.480: INFO: namespace downward-api-7663 deletion completed in 6.071959651s
[32mâ€¢[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mRecreateDeployment should delete old pods and create new ones [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:41:32.480: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Mar 25 18:41:32.528: INFO: Creating deployment "test-recreate-deployment"
Mar 25 18:41:32.531: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar 25 18:41:32.535: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Mar 25 18:41:34.542: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar 25 18:41:34.545: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar 25 18:41:34.551: INFO: Updating deployment test-recreate-deployment
Mar 25 18:41:34.551: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 25 18:41:34.626: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-9113,SelfLink:/apis/apps/v1/namespaces/deployment-9113/deployments/test-recreate-deployment,UID:48a23dbb-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:17300,Generation:2,CreationTimestamp:2019-03-25 18:41:32 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-03-25 18:41:34 -0700 PDT 2019-03-25 18:41:34 -0700 PDT MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-25 18:41:34 -0700 PDT 2019-03-25 18:41:32 -0700 PDT ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Mar 25 18:41:34.629: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-9113,SelfLink:/apis/apps/v1/namespaces/deployment-9113/replicasets/test-recreate-deployment-c9cbd8684,UID:49dac8fa-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:17298,Generation:1,CreationTimestamp:2019-03-25 18:41:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 48a23dbb-4f68-11e9-8304-02427cbbc9a0 0xc003526cb0 0xc003526cb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 25 18:41:34.629: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar 25 18:41:34.629: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-9113,SelfLink:/apis/apps/v1/namespaces/deployment-9113/replicasets/test-recreate-deployment-7d57d5ff7c,UID:48a2b1b9-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:17288,Generation:2,CreationTimestamp:2019-03-25 18:41:32 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 48a23dbb-4f68-11e9-8304-02427cbbc9a0 0xc003526be7 0xc003526be8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 25 18:41:34.630: INFO: Pod "test-recreate-deployment-c9cbd8684-c7nll" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-c7nll,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-9113,SelfLink:/api/v1/namespaces/deployment-9113/pods/test-recreate-deployment-c9cbd8684-c7nll,UID:49dbf895-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:17299,Generation:0,CreationTimestamp:2019-03-25 18:41:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 49dac8fa-4f68-11e9-8304-02427cbbc9a0 0xc00271bdd0 0xc00271bdd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-cn4mt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cn4mt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cn4mt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00271be30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00271be50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:41:34 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:41:34 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:41:34 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:41:34 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.2,PodIP:,StartTime:2019-03-25 18:41:34 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:41:34.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "deployment-9113" for this suite.
Mar 25 18:41:40.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:41:40.701: INFO: namespace deployment-9113 deletion completed in 6.068964725s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:41:40.702: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name configmap-test-volume-4d85edfb-4f68-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 25 18:41:40.739: INFO: Waiting up to 5m0s for pod "pod-configmaps-4d866d17-4f68-11e9-91ba-a08cfdecc127" in namespace "configmap-7504" to be "success or failure"
Mar 25 18:41:40.741: INFO: Pod "pod-configmaps-4d866d17-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.879808ms
Mar 25 18:41:42.744: INFO: Pod "pod-configmaps-4d866d17-4f68-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005252033s
[1mSTEP[0m: Saw pod success
Mar 25 18:41:42.744: INFO: Pod "pod-configmaps-4d866d17-4f68-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:41:42.747: INFO: Trying to get logs from node conformance-worker2 pod pod-configmaps-4d866d17-4f68-11e9-91ba-a08cfdecc127 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:41:42.762: INFO: Waiting for pod pod-configmaps-4d866d17-4f68-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:41:42.768: INFO: Pod pod-configmaps-4d866d17-4f68-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:41:42.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-7504" for this suite.
Mar 25 18:41:48.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:41:48.843: INFO: namespace configmap-7504 deletion completed in 6.072667012s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Services[0m 
  [1mshould provide secure master service  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-network] Services
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:41:48.843: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename services
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:41:48.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "services-9756" for this suite.
Mar 25 18:41:54.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:41:54.949: INFO: namespace services-9756 deletion completed in 6.074259321s
[AfterEach] [sig-network] Services
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:41:54.949: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: create the rc
[1mSTEP[0m: delete the rc
[1mSTEP[0m: wait for the rc to be deleted
[1mSTEP[0m: Gathering metrics
W0325 18:42:01.003036   72333 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 25 18:42:01.003: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:42:01.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "gc-3534" for this suite.
Mar 25 18:42:07.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:42:07.068: INFO: namespace gc-3534 deletion completed in 6.062041204s
[32mâ€¢[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:42:07.068: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 18:42:07.104: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5d3d1663-4f68-11e9-91ba-a08cfdecc127" in namespace "downward-api-8576" to be "success or failure"
Mar 25 18:42:07.108: INFO: Pod "downwardapi-volume-5d3d1663-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.876663ms
Mar 25 18:42:09.111: INFO: Pod "downwardapi-volume-5d3d1663-4f68-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006591305s
[1mSTEP[0m: Saw pod success
Mar 25 18:42:09.111: INFO: Pod "downwardapi-volume-5d3d1663-4f68-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:42:09.113: INFO: Trying to get logs from node conformance-worker pod downwardapi-volume-5d3d1663-4f68-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:42:09.131: INFO: Waiting for pod downwardapi-volume-5d3d1663-4f68-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:42:09.135: INFO: Pod downwardapi-volume-5d3d1663-4f68-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:42:09.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-8576" for this suite.
Mar 25 18:42:15.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:42:15.215: INFO: namespace downward-api-8576 deletion completed in 6.07531881s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable in multiple volumes in a pod [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:42:15.216: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating secret with name secret-test-6217c878-4f68-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 25 18:42:15.252: INFO: Waiting up to 5m0s for pod "pod-secrets-62182445-4f68-11e9-91ba-a08cfdecc127" in namespace "secrets-8949" to be "success or failure"
Mar 25 18:42:15.254: INFO: Pod "pod-secrets-62182445-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.95951ms
Mar 25 18:42:17.258: INFO: Pod "pod-secrets-62182445-4f68-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006177576s
[1mSTEP[0m: Saw pod success
Mar 25 18:42:17.258: INFO: Pod "pod-secrets-62182445-4f68-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:42:17.262: INFO: Trying to get logs from node conformance-worker2 pod pod-secrets-62182445-4f68-11e9-91ba-a08cfdecc127 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:42:17.281: INFO: Waiting for pod pod-secrets-62182445-4f68-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:42:17.283: INFO: Pod pod-secrets-62182445-4f68-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:42:17.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "secrets-8949" for this suite.
Mar 25 18:42:23.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:42:23.354: INFO: namespace secrets-8949 deletion completed in 6.069582874s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] DNS[0m 
  [1mshould provide DNS for the cluster  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-network] DNS
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:42:23.355: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename dns
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9687.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

[1mSTEP[0m: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9687.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

[1mSTEP[0m: creating a pod to probe DNS
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: retrieving the pod
[1mSTEP[0m: looking for the results for each expected name from probers
Mar 25 18:42:37.415: INFO: Unable to read jessie_udp@kubernetes.default.svc.cluster.local from pod dns-9687/dns-test-66f1e589-4f68-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-66f1e589-4f68-11e9-91ba-a08cfdecc127)
Mar 25 18:42:37.417: INFO: Unable to read jessie_tcp@kubernetes.default.svc.cluster.local from pod dns-9687/dns-test-66f1e589-4f68-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-66f1e589-4f68-11e9-91ba-a08cfdecc127)
Mar 25 18:42:37.419: INFO: Unable to read jessie_udp@PodARecord from pod dns-9687/dns-test-66f1e589-4f68-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-66f1e589-4f68-11e9-91ba-a08cfdecc127)
Mar 25 18:42:37.422: INFO: Unable to read jessie_tcp@PodARecord from pod dns-9687/dns-test-66f1e589-4f68-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-66f1e589-4f68-11e9-91ba-a08cfdecc127)
Mar 25 18:42:37.422: INFO: Lookups using dns-9687/dns-test-66f1e589-4f68-11e9-91ba-a08cfdecc127 failed for: [jessie_udp@kubernetes.default.svc.cluster.local jessie_tcp@kubernetes.default.svc.cluster.local jessie_udp@PodARecord jessie_tcp@PodARecord]

Mar 25 18:42:42.442: INFO: DNS probes using dns-9687/dns-test-66f1e589-4f68-11e9-91ba-a08cfdecc127 succeeded

[1mSTEP[0m: deleting the pod
[AfterEach] [sig-network] DNS
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:42:42.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "dns-9687" for this suite.
Mar 25 18:42:48.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:42:48.535: INFO: namespace dns-9687 deletion completed in 6.077777669s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's cpu limit [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:42:48.535: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 18:42:48.569: INFO: Waiting up to 5m0s for pod "downwardapi-volume-75f3a68c-4f68-11e9-91ba-a08cfdecc127" in namespace "downward-api-2777" to be "success or failure"
Mar 25 18:42:48.572: INFO: Pod "downwardapi-volume-75f3a68c-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.17617ms
Mar 25 18:42:50.576: INFO: Pod "downwardapi-volume-75f3a68c-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007211174s
Mar 25 18:42:52.580: INFO: Pod "downwardapi-volume-75f3a68c-4f68-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011326518s
[1mSTEP[0m: Saw pod success
Mar 25 18:42:52.580: INFO: Pod "downwardapi-volume-75f3a68c-4f68-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:42:52.583: INFO: Trying to get logs from node conformance-worker2 pod downwardapi-volume-75f3a68c-4f68-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:42:52.607: INFO: Waiting for pod downwardapi-volume-75f3a68c-4f68-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:42:52.611: INFO: Pod downwardapi-volume-75f3a68c-4f68-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:42:52.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-2777" for this suite.
Mar 25 18:42:58.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:42:58.689: INFO: namespace downward-api-2777 deletion completed in 6.075356337s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Kubelet[0m [90mwhen scheduling a read only busybox container[0m 
  [1mshould not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Kubelet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:42:58.689: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename kubelet-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:43:00.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubelet-test-5238" for this suite.
Mar 25 18:43:50.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:43:50.819: INFO: namespace kubelet-test-5238 deletion completed in 50.078681869s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1mshould be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected secret
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:43:50.819: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-9b16a3f5-4f68-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 25 18:43:50.872: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9b1712ce-4f68-11e9-91ba-a08cfdecc127" in namespace "projected-4952" to be "success or failure"
Mar 25 18:43:50.887: INFO: Pod "pod-projected-secrets-9b1712ce-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 14.825214ms
Mar 25 18:43:52.899: INFO: Pod "pod-projected-secrets-9b1712ce-4f68-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026944801s
[1mSTEP[0m: Saw pod success
Mar 25 18:43:52.899: INFO: Pod "pod-projected-secrets-9b1712ce-4f68-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:43:52.901: INFO: Trying to get logs from node conformance-worker pod pod-projected-secrets-9b1712ce-4f68-11e9-91ba-a08cfdecc127 container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:43:52.915: INFO: Waiting for pod pod-projected-secrets-9b1712ce-4f68-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:43:52.918: INFO: Pod pod-projected-secrets-9b1712ce-4f68-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected secret
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:43:52.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-4952" for this suite.
Mar 25 18:43:58.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:43:58.994: INFO: namespace projected-4952 deletion completed in 6.073675366s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:43:58.994: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test emptydir 0644 on tmpfs
Mar 25 18:43:59.021: INFO: Waiting up to 5m0s for pod "pod-9ff28ea7-4f68-11e9-91ba-a08cfdecc127" in namespace "emptydir-8245" to be "success or failure"
Mar 25 18:43:59.023: INFO: Pod "pod-9ff28ea7-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.278848ms
Mar 25 18:44:01.027: INFO: Pod "pod-9ff28ea7-4f68-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006022614s
[1mSTEP[0m: Saw pod success
Mar 25 18:44:01.027: INFO: Pod "pod-9ff28ea7-4f68-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:44:01.030: INFO: Trying to get logs from node conformance-worker pod pod-9ff28ea7-4f68-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:44:01.048: INFO: Waiting for pod pod-9ff28ea7-4f68-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:44:01.050: INFO: Pod pod-9ff28ea7-4f68-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:44:01.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-8245" for this suite.
Mar 25 18:44:07.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:44:07.114: INFO: namespace emptydir-8245 deletion completed in 6.061273007s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould retry creating failed daemon pods [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:44:07.114: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename daemonsets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a simple DaemonSet "daemon-set"
[1mSTEP[0m: Check that daemon pods launch on every node of the cluster.
Mar 25 18:44:07.152: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:44:07.157: INFO: Number of nodes with available pods: 0
Mar 25 18:44:07.157: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:44:08.160: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:44:08.162: INFO: Number of nodes with available pods: 0
Mar 25 18:44:08.162: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:44:09.161: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:44:09.163: INFO: Number of nodes with available pods: 1
Mar 25 18:44:09.163: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:44:10.160: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:44:10.163: INFO: Number of nodes with available pods: 2
Mar 25 18:44:10.163: INFO: Number of running nodes: 2, number of available pods: 2
[1mSTEP[0m: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar 25 18:44:10.175: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:44:10.185: INFO: Number of nodes with available pods: 1
Mar 25 18:44:10.185: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:44:11.188: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:44:11.191: INFO: Number of nodes with available pods: 1
Mar 25 18:44:11.191: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:44:12.189: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:44:12.193: INFO: Number of nodes with available pods: 2
Mar 25 18:44:12.193: INFO: Number of running nodes: 2, number of available pods: 2
[1mSTEP[0m: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4788, will wait for the garbage collector to delete the pods
Mar 25 18:44:12.254: INFO: Deleting DaemonSet.extensions daemon-set took: 5.380804ms
Mar 25 18:44:12.554: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.19481ms
Mar 25 18:44:18.757: INFO: Number of nodes with available pods: 0
Mar 25 18:44:18.757: INFO: Number of running nodes: 0, number of available pods: 0
Mar 25 18:44:18.759: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4788/daemonsets","resourceVersion":"18161"},"items":null}

Mar 25 18:44:18.761: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4788/pods","resourceVersion":"18161"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:44:18.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "daemonsets-4788" for this suite.
Mar 25 18:44:24.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:44:24.852: INFO: namespace daemonsets-4788 deletion completed in 6.08065773s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould not be blocked by dependency circle [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:44:24.852: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Mar 25 18:44:24.896: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"af5e303e-4f68-11e9-8304-02427cbbc9a0", Controller:(*bool)(0xc00237c876), BlockOwnerDeletion:(*bool)(0xc00237c877)}}
Mar 25 18:44:24.904: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"af5d1be3-4f68-11e9-8304-02427cbbc9a0", Controller:(*bool)(0xc002bd560a), BlockOwnerDeletion:(*bool)(0xc002bd560b)}}
Mar 25 18:44:24.910: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"af5d95db-4f68-11e9-8304-02427cbbc9a0", Controller:(*bool)(0xc00237ca26), BlockOwnerDeletion:(*bool)(0xc00237ca27)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:44:29.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "gc-2883" for this suite.
Mar 25 18:44:35.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:44:35.990: INFO: namespace gc-2883 deletion completed in 6.067777116s
[32mâ€¢[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mvolume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:44:35.990: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test emptydir volume type on node default medium
Mar 25 18:44:36.029: INFO: Waiting up to 5m0s for pod "pod-b60171ef-4f68-11e9-91ba-a08cfdecc127" in namespace "emptydir-21" to be "success or failure"
Mar 25 18:44:36.032: INFO: Pod "pod-b60171ef-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.027897ms
Mar 25 18:44:38.035: INFO: Pod "pod-b60171ef-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006284931s
Mar 25 18:44:40.038: INFO: Pod "pod-b60171ef-4f68-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008965739s
[1mSTEP[0m: Saw pod success
Mar 25 18:44:40.038: INFO: Pod "pod-b60171ef-4f68-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:44:40.040: INFO: Trying to get logs from node conformance-worker pod pod-b60171ef-4f68-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:44:40.052: INFO: Waiting for pod pod-b60171ef-4f68-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:44:40.053: INFO: Pod pod-b60171ef-4f68-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:44:40.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-21" for this suite.
Mar 25 18:44:46.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:44:46.120: INFO: namespace emptydir-21 deletion completed in 6.06506084s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mdeployment should support proportional scaling [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:44:46.120: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Mar 25 18:44:46.142: INFO: Creating deployment "nginx-deployment"
Mar 25 18:44:46.145: INFO: Waiting for observed generation 1
Mar 25 18:44:48.153: INFO: Waiting for all required pods to come up
Mar 25 18:44:48.156: INFO: Pod name nginx: Found 10 pods out of 10
[1mSTEP[0m: ensuring each pod is running
Mar 25 18:44:50.167: INFO: Waiting for deployment "nginx-deployment" to complete
Mar 25 18:44:50.172: INFO: Updating deployment "nginx-deployment" with a non-existent image
Mar 25 18:44:50.176: INFO: Updating deployment nginx-deployment
Mar 25 18:44:50.176: INFO: Waiting for observed generation 2
Mar 25 18:44:52.181: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar 25 18:44:52.185: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar 25 18:44:52.188: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 25 18:44:52.197: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar 25 18:44:52.197: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar 25 18:44:52.199: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 25 18:44:52.202: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Mar 25 18:44:52.202: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Mar 25 18:44:52.207: INFO: Updating deployment nginx-deployment
Mar 25 18:44:52.207: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Mar 25 18:44:52.223: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar 25 18:44:52.232: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 25 18:44:52.290: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-881,SelfLink:/apis/apps/v1/namespaces/deployment-881/deployments/nginx-deployment,UID:bc095350-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18547,Generation:3,CreationTimestamp:2019-03-25 18:44:46 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-03-25 18:44:50 -0700 PDT 2019-03-25 18:44:46 -0700 PDT ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.} {Available False 2019-03-25 18:44:52 -0700 PDT 2019-03-25 18:44:52 -0700 PDT MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Mar 25 18:44:52.304: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-881,SelfLink:/apis/apps/v1/namespaces/deployment-881/replicasets/nginx-deployment-5f9595f595,UID:be70df86-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18590,Generation:3,CreationTimestamp:2019-03-25 18:44:50 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bc095350-4f68-11e9-8304-02427cbbc9a0 0xc0027de3f7 0xc0027de3f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 25 18:44:52.304: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Mar 25 18:44:52.304: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-881,SelfLink:/apis/apps/v1/namespaces/deployment-881/replicasets/nginx-deployment-6f478d8d8,UID:bc09cc9f-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18591,Generation:3,CreationTimestamp:2019-03-25 18:44:46 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bc095350-4f68-11e9-8304-02427cbbc9a0 0xc0027de4c7 0xc0027de4c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Mar 25 18:44:52.339: INFO: Pod "nginx-deployment-5f9595f595-228fr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-228fr,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-5f9595f595-228fr,UID:bfaae670-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18581,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be70df86-4f68-11e9-8304-02427cbbc9a0 0xc002c442f7 0xc002c442f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c44370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c44390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.339: INFO: Pod "nginx-deployment-5f9595f595-4ggsm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-4ggsm,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-5f9595f595-4ggsm,UID:bfaadb7f-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18579,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be70df86-4f68-11e9-8304-02427cbbc9a0 0xc002c44410 0xc002c44411}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c44480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c444a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.339: INFO: Pod "nginx-deployment-5f9595f595-4x4l7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-4x4l7,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-5f9595f595-4x4l7,UID:be71381b-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18482,Generation:0,CreationTimestamp:2019-03-25 18:44:50 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be70df86-4f68-11e9-8304-02427cbbc9a0 0xc002c44520 0xc002c44521}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c44590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c445c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.3,PodIP:,StartTime:2019-03-25 18:44:50 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.339: INFO: Pod "nginx-deployment-5f9595f595-c4djq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-c4djq,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-5f9595f595-c4djq,UID:be77e922-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18508,Generation:0,CreationTimestamp:2019-03-25 18:44:50 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be70df86-4f68-11e9-8304-02427cbbc9a0 0xc002c446b0 0xc002c446b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c44720} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c44740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.2,PodIP:,StartTime:2019-03-25 18:44:50 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.339: INFO: Pod "nginx-deployment-5f9595f595-dnnjl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-dnnjl,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-5f9595f595-dnnjl,UID:be719767-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18483,Generation:0,CreationTimestamp:2019-03-25 18:44:50 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be70df86-4f68-11e9-8304-02427cbbc9a0 0xc002c44820 0xc002c44821}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c448c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c448f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.2,PodIP:,StartTime:2019-03-25 18:44:50 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.339: INFO: Pod "nginx-deployment-5f9595f595-jt46m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-jt46m,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-5f9595f595-jt46m,UID:bfa8759b-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18601,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be70df86-4f68-11e9-8304-02427cbbc9a0 0xc002c449c0 0xc002c449c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c44a30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c44a50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.3,PodIP:,StartTime:2019-03-25 18:44:52 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.339: INFO: Pod "nginx-deployment-5f9595f595-lhptb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-lhptb,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-5f9595f595-lhptb,UID:bfa7f48a-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18594,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be70df86-4f68-11e9-8304-02427cbbc9a0 0xc002c44b20 0xc002c44b21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c44b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c44bc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.2,PodIP:,StartTime:2019-03-25 18:44:52 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.339: INFO: Pod "nginx-deployment-5f9595f595-m8qpc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-m8qpc,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-5f9595f595-m8qpc,UID:bfaaabaf-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18577,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be70df86-4f68-11e9-8304-02427cbbc9a0 0xc002c44c90 0xc002c44c91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c44d00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c44d20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.339: INFO: Pod "nginx-deployment-5f9595f595-mfd4v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-mfd4v,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-5f9595f595-mfd4v,UID:be71bf46-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18492,Generation:0,CreationTimestamp:2019-03-25 18:44:50 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be70df86-4f68-11e9-8304-02427cbbc9a0 0xc002c44da0 0xc002c44da1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c44e10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c44e30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.3,PodIP:,StartTime:2019-03-25 18:44:50 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.339: INFO: Pod "nginx-deployment-5f9595f595-mpsrd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-mpsrd,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-5f9595f595-mpsrd,UID:bfaadb10-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18575,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be70df86-4f68-11e9-8304-02427cbbc9a0 0xc002c44f00 0xc002c44f01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c44f70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c44f90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.339: INFO: Pod "nginx-deployment-5f9595f595-n9qnt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-n9qnt,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-5f9595f595-n9qnt,UID:be7919b5-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18509,Generation:0,CreationTimestamp:2019-03-25 18:44:50 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be70df86-4f68-11e9-8304-02427cbbc9a0 0xc002c45010 0xc002c45011}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c45080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c450a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:50 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.3,PodIP:,StartTime:2019-03-25 18:44:50 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.340: INFO: Pod "nginx-deployment-5f9595f595-wdpgj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-wdpgj,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-5f9595f595-wdpgj,UID:bfa87af5-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18597,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be70df86-4f68-11e9-8304-02427cbbc9a0 0xc002c45170 0xc002c45171}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c451e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c45200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.2,PodIP:,StartTime:2019-03-25 18:44:52 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.340: INFO: Pod "nginx-deployment-5f9595f595-z9shz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-z9shz,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-5f9595f595-z9shz,UID:bfaca255-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18585,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be70df86-4f68-11e9-8304-02427cbbc9a0 0xc002c452e0 0xc002c452e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c45350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c45370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.340: INFO: Pod "nginx-deployment-6f478d8d8-22v6k" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-22v6k,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-22v6k,UID:bc0ae8b6-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18405,Generation:0,CreationTimestamp:2019-03-25 18:44:46 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002c453f0 0xc002c453f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c45450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c45470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:46 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:48 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:48 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:46 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.3,PodIP:10.38.0.1,StartTime:2019-03-25 18:44:46 -0700 PDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-25 18:44:48 -0700 PDT,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://d03b85c047a9b2ed34d21d14565d7e3a261f705e2fab2a981989045addb06d3b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.340: INFO: Pod "nginx-deployment-6f478d8d8-45sqs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-45sqs,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-45sqs,UID:bc0dbf35-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18425,Generation:0,CreationTimestamp:2019-03-25 18:44:46 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002c45540 0xc002c45541}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c455a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c455c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:46 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:48 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:48 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:46 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.2,PodIP:10.32.0.6,StartTime:2019-03-25 18:44:46 -0700 PDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-25 18:44:48 -0700 PDT,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://5f5248a0bfc8c424fc6873b085386d0216b622d42de6b993e0bc9b772937d94f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.340: INFO: Pod "nginx-deployment-6f478d8d8-4w7gq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-4w7gq,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-4w7gq,UID:bc0cbdad-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18422,Generation:0,CreationTimestamp:2019-03-25 18:44:46 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002c45690 0xc002c45691}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c456f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c45710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:46 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:48 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:48 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:46 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.2,PodIP:10.32.0.4,StartTime:2019-03-25 18:44:46 -0700 PDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-25 18:44:48 -0700 PDT,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://1bd6f1c959df9e172c43aecda5e001caafc346ac1c0d7e4c8fdf8a171bb32388}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.340: INFO: Pod "nginx-deployment-6f478d8d8-6vbgr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-6vbgr,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-6vbgr,UID:bfa9460a-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18560,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002c457e0 0xc002c457e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c45840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c45860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.340: INFO: Pod "nginx-deployment-6f478d8d8-7kfzl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-7kfzl,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-7kfzl,UID:bfa98213-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18570,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002c458e0 0xc002c458e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c45940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c45960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.340: INFO: Pod "nginx-deployment-6f478d8d8-bcscc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-bcscc,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-bcscc,UID:bc0cc95c-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18412,Generation:0,CreationTimestamp:2019-03-25 18:44:46 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002c459e0 0xc002c459e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c45a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c45a60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:46 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:48 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:48 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:46 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.3,PodIP:10.38.0.5,StartTime:2019-03-25 18:44:46 -0700 PDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-25 18:44:48 -0700 PDT,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://fe7a470854e3acefecc7a96279b22df750c392ff095aab995b7423762feb66e9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.340: INFO: Pod "nginx-deployment-6f478d8d8-cnjdh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-cnjdh,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-cnjdh,UID:bfa98004-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18569,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002c45b30 0xc002c45b31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c45b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c45bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.340: INFO: Pod "nginx-deployment-6f478d8d8-cslsm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-cslsm,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-cslsm,UID:bfa96e6a-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18568,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002c45c30 0xc002c45c31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c45c90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c45cb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.340: INFO: Pod "nginx-deployment-6f478d8d8-gxdxq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-gxdxq,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-gxdxq,UID:bc0cd7c8-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18428,Generation:0,CreationTimestamp:2019-03-25 18:44:46 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002c45d30 0xc002c45d31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c45d90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c45db0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:46 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:48 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:48 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:46 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.2,PodIP:10.32.0.3,StartTime:2019-03-25 18:44:46 -0700 PDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-25 18:44:48 -0700 PDT,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://e9a3a6c8ebb6a9772c40e1f5fe25015229fbcaa9a02bc0e98dafa440a1437e9e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.341: INFO: Pod "nginx-deployment-6f478d8d8-jcgzd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-jcgzd,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-jcgzd,UID:bfa73c4c-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18574,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002c45e90 0xc002c45e91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c45ef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c45f10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.2,PodIP:,StartTime:2019-03-25 18:44:52 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.341: INFO: Pod "nginx-deployment-6f478d8d8-ls94r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-ls94r,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-ls94r,UID:bfaaf221-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18578,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002c45fd0 0xc002c45fd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a5c030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a5c050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.341: INFO: Pod "nginx-deployment-6f478d8d8-m7nrc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-m7nrc,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-m7nrc,UID:bfaaffad-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18580,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002a5c0d0 0xc002a5c0d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a5c130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a5c150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.341: INFO: Pod "nginx-deployment-6f478d8d8-mxt87" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-mxt87,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-mxt87,UID:bfa803b2-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18587,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002a5c1d0 0xc002a5c1d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a5c230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a5c250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.3,PodIP:,StartTime:2019-03-25 18:44:52 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.341: INFO: Pod "nginx-deployment-6f478d8d8-ph8kw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-ph8kw,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-ph8kw,UID:bc0cd10d-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18415,Generation:0,CreationTimestamp:2019-03-25 18:44:46 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002a5c310 0xc002a5c311}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a5c370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a5c390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:46 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:48 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:48 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:46 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.3,PodIP:10.38.0.2,StartTime:2019-03-25 18:44:46 -0700 PDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-25 18:44:48 -0700 PDT,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://0d992c346946a083ef024c4143e7645297e16d4200808a316012ef250bd13d73}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.341: INFO: Pod "nginx-deployment-6f478d8d8-pwzd6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-pwzd6,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-pwzd6,UID:bc0db74a-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18409,Generation:0,CreationTimestamp:2019-03-25 18:44:46 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002a5c460 0xc002a5c461}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a5c4c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a5c4e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:46 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:48 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:48 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:46 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.3,PodIP:10.38.0.4,StartTime:2019-03-25 18:44:46 -0700 PDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-25 18:44:48 -0700 PDT,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://71e6f9aedee556c881a12f1f1429d032951740e4059035b3da6e523287d2c415}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.341: INFO: Pod "nginx-deployment-6f478d8d8-qgvk7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-qgvk7,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-qgvk7,UID:bfab3f10-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18584,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002a5c5b0 0xc002a5c5b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a5c610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a5c630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.341: INFO: Pod "nginx-deployment-6f478d8d8-qwjjm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-qwjjm,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-qwjjm,UID:bc0b4d0b-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18446,Generation:0,CreationTimestamp:2019-03-25 18:44:46 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002a5c6b0 0xc002a5c6b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a5c710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a5c730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:46 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:49 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:49 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:46 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.2,PodIP:10.32.0.2,StartTime:2019-03-25 18:44:46 -0700 PDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-25 18:44:48 -0700 PDT,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://1826e711bc2b32ee5784b903a1cf374fe041668f2fa9d3019467bd534dca61be}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.341: INFO: Pod "nginx-deployment-6f478d8d8-tmx4l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-tmx4l,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-tmx4l,UID:bfa80bc4-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18595,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002a5c810 0xc002a5c811}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a5c870} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a5c890}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.3,PodIP:,StartTime:2019-03-25 18:44:52 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.341: INFO: Pod "nginx-deployment-6f478d8d8-v9vfn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-v9vfn,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-v9vfn,UID:bfaafad6-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18583,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002a5c950 0xc002a5c951}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a5c9c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a5c9e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:44:52.341: INFO: Pod "nginx-deployment-6f478d8d8-xsf7r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-xsf7r,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-881,SelfLink:/api/v1/namespaces/deployment-881/pods/nginx-deployment-6f478d8d8-xsf7r,UID:bfaae837-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18582,Generation:0,CreationTimestamp:2019-03-25 18:44:52 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc09cc9f-4f68-11e9-8304-02427cbbc9a0 0xc002a5ca70 0xc002a5ca71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wr9qq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wr9qq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wr9qq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a5cad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a5caf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:44:52 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:44:52.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "deployment-881" for this suite.
Mar 25 18:44:58.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:44:58.428: INFO: namespace deployment-881 deletion completed in 6.081731142s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mshould be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:44:58.428: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-c364a33c-4f68-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 25 18:44:58.529: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c3675cd3-4f68-11e9-91ba-a08cfdecc127" in namespace "projected-1515" to be "success or failure"
Mar 25 18:44:58.541: INFO: Pod "pod-projected-configmaps-c3675cd3-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 11.819728ms
Mar 25 18:45:00.543: INFO: Pod "pod-projected-configmaps-c3675cd3-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014422064s
Mar 25 18:45:02.547: INFO: Pod "pod-projected-configmaps-c3675cd3-4f68-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017581834s
Mar 25 18:45:04.550: INFO: Pod "pod-projected-configmaps-c3675cd3-4f68-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021201664s
[1mSTEP[0m: Saw pod success
Mar 25 18:45:04.550: INFO: Pod "pod-projected-configmaps-c3675cd3-4f68-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:45:04.553: INFO: Trying to get logs from node conformance-worker pod pod-projected-configmaps-c3675cd3-4f68-11e9-91ba-a08cfdecc127 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:45:04.571: INFO: Waiting for pod pod-projected-configmaps-c3675cd3-4f68-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:45:04.573: INFO: Pod pod-projected-configmaps-c3675cd3-4f68-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:45:04.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-1515" for this suite.
Mar 25 18:45:10.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:45:10.638: INFO: namespace projected-1515 deletion completed in 6.062184147s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] InitContainer [NodeConformance][0m 
  [1mshould not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:45:10.638: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename init-container
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating the pod
Mar 25 18:45:10.658: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:45:19.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "init-container-9925" for this suite.
Mar 25 18:45:25.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:45:25.387: INFO: namespace init-container-9925 deletion completed in 6.06124294s
[32mâ€¢[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] Events[0m 
  [1mshould be sent by kubelets and the scheduler about pods scheduling and running  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] [sig-node] Events
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:45:25.387: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename events
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: retrieving the pod
Mar 25 18:45:29.439: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-d3724d71-4f68-11e9-91ba-a08cfdecc127,GenerateName:,Namespace:events-1854,SelfLink:/api/v1/namespaces/events-1854/pods/send-events-d3724d71-4f68-11e9-91ba-a08cfdecc127,UID:d372c9e3-4f68-11e9-8304-02427cbbc9a0,ResourceVersion:18959,Generation:0,CreationTimestamp:2019-03-25 18:45:25 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 418742645,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2gst9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2gst9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-2gst9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00221f5b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00221f5d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:45:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:45:29 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:45:29 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:45:25 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.2,PodIP:10.32.0.2,StartTime:2019-03-25 18:45:25 -0700 PDT,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-03-25 18:45:28 -0700 PDT,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://301fd5e88d029d8eb6281fc731fcf53fe0180ea43d29a58d5a60648e65cecae9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

[1mSTEP[0m: checking for scheduler event about the pod
Mar 25 18:45:31.443: INFO: Saw scheduler event for our pod.
[1mSTEP[0m: checking for kubelet event about the pod
Mar 25 18:45:33.446: INFO: Saw kubelet event for our pod.
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:45:33.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "events-1854" for this suite.
Mar 25 18:46:11.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:46:11.528: INFO: namespace events-1854 deletion completed in 38.074392663s
[32mâ€¢[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould run and stop simple daemon [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:46:11.528: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename daemonsets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating simple DaemonSet "daemon-set"
[1mSTEP[0m: Check that daemon pods launch on every node of the cluster.
Mar 25 18:46:11.576: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:11.577: INFO: Number of nodes with available pods: 0
Mar 25 18:46:11.577: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:46:12.579: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:12.582: INFO: Number of nodes with available pods: 0
Mar 25 18:46:12.582: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:46:13.580: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:13.583: INFO: Number of nodes with available pods: 0
Mar 25 18:46:13.583: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:46:14.579: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:14.582: INFO: Number of nodes with available pods: 2
Mar 25 18:46:14.582: INFO: Number of running nodes: 2, number of available pods: 2
[1mSTEP[0m: Stop a daemon pod, check that the daemon pod is revived.
Mar 25 18:46:14.594: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:14.596: INFO: Number of nodes with available pods: 1
Mar 25 18:46:14.596: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:46:15.600: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:15.604: INFO: Number of nodes with available pods: 1
Mar 25 18:46:15.604: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:46:16.599: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:16.601: INFO: Number of nodes with available pods: 1
Mar 25 18:46:16.601: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:46:17.601: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:17.604: INFO: Number of nodes with available pods: 1
Mar 25 18:46:17.604: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:46:18.599: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:18.601: INFO: Number of nodes with available pods: 1
Mar 25 18:46:18.601: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:46:19.600: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:19.602: INFO: Number of nodes with available pods: 1
Mar 25 18:46:19.602: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:46:20.599: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:20.602: INFO: Number of nodes with available pods: 1
Mar 25 18:46:20.602: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:46:21.600: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:21.603: INFO: Number of nodes with available pods: 1
Mar 25 18:46:21.603: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:46:22.600: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:22.603: INFO: Number of nodes with available pods: 1
Mar 25 18:46:22.603: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:46:23.601: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:23.604: INFO: Number of nodes with available pods: 1
Mar 25 18:46:23.604: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:46:24.600: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:24.602: INFO: Number of nodes with available pods: 1
Mar 25 18:46:24.602: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:46:25.601: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:25.604: INFO: Number of nodes with available pods: 1
Mar 25 18:46:25.604: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:46:26.607: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:26.610: INFO: Number of nodes with available pods: 1
Mar 25 18:46:26.610: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:46:27.600: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:27.603: INFO: Number of nodes with available pods: 1
Mar 25 18:46:27.603: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:46:28.602: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:28.604: INFO: Number of nodes with available pods: 1
Mar 25 18:46:28.604: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:46:29.599: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:29.601: INFO: Number of nodes with available pods: 1
Mar 25 18:46:29.601: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:46:30.599: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:46:30.603: INFO: Number of nodes with available pods: 2
Mar 25 18:46:30.603: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7275, will wait for the garbage collector to delete the pods
Mar 25 18:46:30.664: INFO: Deleting DaemonSet.extensions daemon-set took: 6.83113ms
Mar 25 18:46:30.964: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.207166ms
Mar 25 18:46:38.768: INFO: Number of nodes with available pods: 0
Mar 25 18:46:38.768: INFO: Number of running nodes: 0, number of available pods: 0
Mar 25 18:46:38.770: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7275/daemonsets","resourceVersion":"19149"},"items":null}

Mar 25 18:46:38.773: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7275/pods","resourceVersion":"19149"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:46:38.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "daemonsets-7275" for this suite.
Mar 25 18:46:44.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:46:44.854: INFO: namespace daemonsets-7275 deletion completed in 6.070326847s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] DNS[0m 
  [1mshould provide DNS for services  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-network] DNS
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:46:44.854: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename dns
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a test headless service
[1mSTEP[0m: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9526.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9526.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9526.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9526.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9526.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9526.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9526.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9526.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9526.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9526.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9526.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9526.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9526.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 155.113.98.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.98.113.155_udp@PTR;check="$$(dig +tcp +noall +answer +search 155.113.98.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.98.113.155_tcp@PTR;sleep 1; done

[1mSTEP[0m: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9526.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9526.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9526.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9526.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9526.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9526.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9526.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9526.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9526.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9526.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9526.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9526.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9526.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 155.113.98.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.98.113.155_udp@PTR;check="$$(dig +tcp +noall +answer +search 155.113.98.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.98.113.155_tcp@PTR;sleep 1; done

[1mSTEP[0m: creating a pod to probe DNS
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: retrieving the pod
[1mSTEP[0m: looking for the results for each expected name from probers
Mar 25 18:46:48.923: INFO: Unable to read wheezy_udp@dns-test-service.dns-9526.svc.cluster.local from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.925: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9526.svc.cluster.local from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.928: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9526.svc.cluster.local from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.931: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9526.svc.cluster.local from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.933: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.dns-9526.svc.cluster.local from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.935: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.dns-9526.svc.cluster.local from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.937: INFO: Unable to read wheezy_udp@PodARecord from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.939: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.942: INFO: Unable to read 10.98.113.155_udp@PTR from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.944: INFO: Unable to read 10.98.113.155_tcp@PTR from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.948: INFO: Unable to read jessie_udp@dns-test-service.dns-9526.svc.cluster.local from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.952: INFO: Unable to read jessie_tcp@dns-test-service.dns-9526.svc.cluster.local from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.955: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9526.svc.cluster.local from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.958: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9526.svc.cluster.local from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.960: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.dns-9526.svc.cluster.local from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.963: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.dns-9526.svc.cluster.local from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.968: INFO: Unable to read jessie_udp@PodARecord from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.970: INFO: Unable to read jessie_tcp@PodARecord from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.972: INFO: Unable to read 10.98.113.155_udp@PTR from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.973: INFO: Unable to read 10.98.113.155_tcp@PTR from pod dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127: the server could not find the requested resource (get pods dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127)
Mar 25 18:46:48.973: INFO: Lookups using dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127 failed for: [wheezy_udp@dns-test-service.dns-9526.svc.cluster.local wheezy_tcp@dns-test-service.dns-9526.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9526.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9526.svc.cluster.local wheezy_udp@_http._tcp.test-service-2.dns-9526.svc.cluster.local wheezy_tcp@_http._tcp.test-service-2.dns-9526.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord 10.98.113.155_udp@PTR 10.98.113.155_tcp@PTR jessie_udp@dns-test-service.dns-9526.svc.cluster.local jessie_tcp@dns-test-service.dns-9526.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9526.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9526.svc.cluster.local jessie_udp@_http._tcp.test-service-2.dns-9526.svc.cluster.local jessie_tcp@_http._tcp.test-service-2.dns-9526.svc.cluster.local jessie_udp@PodARecord jessie_tcp@PodARecord 10.98.113.155_udp@PTR 10.98.113.155_tcp@PTR]

Mar 25 18:46:54.017: INFO: DNS probes using dns-9526/dns-test-02d1cf03-4f69-11e9-91ba-a08cfdecc127 succeeded

[1mSTEP[0m: deleting the pod
[1mSTEP[0m: deleting the test service
[1mSTEP[0m: deleting the test headless service
[AfterEach] [sig-network] DNS
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:46:54.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "dns-9526" for this suite.
Mar 25 18:47:00.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:47:00.145: INFO: namespace dns-9526 deletion completed in 6.068063207s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould update pod when spec was updated and update strategy is RollingUpdate [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:47:00.145: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename daemonsets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Mar 25 18:47:00.184: INFO: Creating simple daemon set daemon-set
[1mSTEP[0m: Check that daemon pods launch on every node of the cluster.
Mar 25 18:47:00.189: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:47:00.190: INFO: Number of nodes with available pods: 0
Mar 25 18:47:00.190: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:47:01.194: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:47:01.195: INFO: Number of nodes with available pods: 0
Mar 25 18:47:01.195: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:47:02.194: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:47:02.196: INFO: Number of nodes with available pods: 1
Mar 25 18:47:02.196: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:47:03.195: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:47:03.197: INFO: Number of nodes with available pods: 2
Mar 25 18:47:03.197: INFO: Number of running nodes: 2, number of available pods: 2
[1mSTEP[0m: Update daemon pods image.
[1mSTEP[0m: Check that daemon pods images are updated.
Mar 25 18:47:03.217: INFO: Wrong image for pod: daemon-set-2pmrl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 18:47:03.217: INFO: Wrong image for pod: daemon-set-6b959. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 18:47:03.222: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:47:04.225: INFO: Wrong image for pod: daemon-set-2pmrl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 18:47:04.225: INFO: Wrong image for pod: daemon-set-6b959. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 18:47:04.227: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:47:05.225: INFO: Wrong image for pod: daemon-set-2pmrl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 18:47:05.225: INFO: Wrong image for pod: daemon-set-6b959. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 18:47:05.225: INFO: Pod daemon-set-6b959 is not available
Mar 25 18:47:05.227: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:47:06.226: INFO: Wrong image for pod: daemon-set-2pmrl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 18:47:06.226: INFO: Wrong image for pod: daemon-set-6b959. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 18:47:06.226: INFO: Pod daemon-set-6b959 is not available
Mar 25 18:47:06.230: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:47:07.225: INFO: Wrong image for pod: daemon-set-2pmrl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 18:47:07.225: INFO: Wrong image for pod: daemon-set-6b959. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 18:47:07.225: INFO: Pod daemon-set-6b959 is not available
Mar 25 18:47:07.228: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:47:08.225: INFO: Wrong image for pod: daemon-set-2pmrl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 18:47:08.225: INFO: Wrong image for pod: daemon-set-6b959. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 18:47:08.225: INFO: Pod daemon-set-6b959 is not available
Mar 25 18:47:08.228: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:47:09.226: INFO: Wrong image for pod: daemon-set-2pmrl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 18:47:09.226: INFO: Pod daemon-set-cbv9h is not available
Mar 25 18:47:09.229: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:47:10.225: INFO: Wrong image for pod: daemon-set-2pmrl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 18:47:10.225: INFO: Pod daemon-set-cbv9h is not available
Mar 25 18:47:10.228: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:47:11.224: INFO: Wrong image for pod: daemon-set-2pmrl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 18:47:11.227: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:47:12.225: INFO: Wrong image for pod: daemon-set-2pmrl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar 25 18:47:12.226: INFO: Pod daemon-set-2pmrl is not available
Mar 25 18:47:12.229: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:47:13.224: INFO: Pod daemon-set-fdqrj is not available
Mar 25 18:47:13.226: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[1mSTEP[0m: Check that daemon pods are still running on every node of the cluster.
Mar 25 18:47:13.228: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:47:13.230: INFO: Number of nodes with available pods: 1
Mar 25 18:47:13.230: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:47:14.234: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:47:14.237: INFO: Number of nodes with available pods: 1
Mar 25 18:47:14.237: INFO: Node conformance-worker2 is running more than one daemon pod
Mar 25 18:47:15.234: INFO: DaemonSet pods can't tolerate node conformance-control-plane with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 25 18:47:15.237: INFO: Number of nodes with available pods: 2
Mar 25 18:47:15.237: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8588, will wait for the garbage collector to delete the pods
Mar 25 18:47:15.303: INFO: Deleting DaemonSet.extensions daemon-set took: 5.002963ms
Mar 25 18:47:15.603: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.216577ms
Mar 25 18:47:28.606: INFO: Number of nodes with available pods: 0
Mar 25 18:47:28.606: INFO: Number of running nodes: 0, number of available pods: 0
Mar 25 18:47:28.607: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8588/daemonsets","resourceVersion":"19403"},"items":null}

Mar 25 18:47:28.609: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8588/pods","resourceVersion":"19403"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:47:28.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "daemonsets-8588" for this suite.
Mar 25 18:47:34.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:47:34.685: INFO: namespace daemonsets-8588 deletion completed in 6.068714223s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicaSet[0m 
  [1mshould serve a basic image on each replica with a public image  [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] ReplicaSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:47:34.685: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename replicaset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Mar 25 18:47:34.711: INFO: Creating ReplicaSet my-hostname-basic-2082de53-4f69-11e9-91ba-a08cfdecc127
Mar 25 18:47:34.722: INFO: Pod name my-hostname-basic-2082de53-4f69-11e9-91ba-a08cfdecc127: Found 1 pods out of 1
Mar 25 18:47:34.722: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-2082de53-4f69-11e9-91ba-a08cfdecc127" is running
Mar 25 18:47:36.732: INFO: Pod "my-hostname-basic-2082de53-4f69-11e9-91ba-a08cfdecc127-jtsz9" is running (conditions: [])
Mar 25 18:47:36.732: INFO: Trying to dial the pod
Mar 25 18:47:41.744: INFO: Controller my-hostname-basic-2082de53-4f69-11e9-91ba-a08cfdecc127: Got expected result from replica 1 [my-hostname-basic-2082de53-4f69-11e9-91ba-a08cfdecc127-jtsz9]: "my-hostname-basic-2082de53-4f69-11e9-91ba-a08cfdecc127-jtsz9", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:47:41.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "replicaset-5016" for this suite.
Mar 25 18:47:47.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:47:47.839: INFO: namespace replicaset-5016 deletion completed in 6.090712851s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:47:47.839: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name cm-test-opt-del-285d8f52-4f69-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating configMap with name cm-test-opt-upd-285d8f8b-4f69-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting configmap cm-test-opt-del-285d8f52-4f69-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Updating configmap cm-test-opt-upd-285d8f8b-4f69-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating configMap with name cm-test-opt-create-285d8f9e-4f69-11e9-91ba-a08cfdecc127
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:49:24.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-6232" for this suite.
Mar 25 18:49:46.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:49:46.558: INFO: namespace configmap-6232 deletion completed in 22.076870569s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide container's cpu limit [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:49:46.558: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 25 18:49:46.601: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6f1f0db0-4f69-11e9-91ba-a08cfdecc127" in namespace "projected-9949" to be "success or failure"
Mar 25 18:49:46.606: INFO: Pod "downwardapi-volume-6f1f0db0-4f69-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 4.801573ms
Mar 25 18:49:48.610: INFO: Pod "downwardapi-volume-6f1f0db0-4f69-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009036139s
[1mSTEP[0m: Saw pod success
Mar 25 18:49:48.610: INFO: Pod "downwardapi-volume-6f1f0db0-4f69-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:49:48.614: INFO: Trying to get logs from node conformance-worker pod downwardapi-volume-6f1f0db0-4f69-11e9-91ba-a08cfdecc127 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:49:48.630: INFO: Waiting for pod downwardapi-volume-6f1f0db0-4f69-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:49:48.632: INFO: Pod downwardapi-volume-6f1f0db0-4f69-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:49:48.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-9949" for this suite.
Mar 25 18:49:54.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:49:54.705: INFO: namespace projected-9949 deletion completed in 6.069599027s
[32mâ€¢[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mshould be consumable in multiple volumes in the same pod [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:49:54.705: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-73f83949-4f69-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 25 18:49:54.740: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-73f8dc18-4f69-11e9-91ba-a08cfdecc127" in namespace "projected-1140" to be "success or failure"
Mar 25 18:49:54.747: INFO: Pod "pod-projected-configmaps-73f8dc18-4f69-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 7.524516ms
Mar 25 18:49:56.751: INFO: Pod "pod-projected-configmaps-73f8dc18-4f69-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011156834s
[1mSTEP[0m: Saw pod success
Mar 25 18:49:56.751: INFO: Pod "pod-projected-configmaps-73f8dc18-4f69-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:49:56.754: INFO: Trying to get logs from node conformance-worker2 pod pod-projected-configmaps-73f8dc18-4f69-11e9-91ba-a08cfdecc127 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:49:56.768: INFO: Waiting for pod pod-projected-configmaps-73f8dc18-4f69-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:49:56.770: INFO: Pod pod-projected-configmaps-73f8dc18-4f69-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:49:56.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-1140" for this suite.
Mar 25 18:50:02.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:50:02.849: INFO: namespace projected-1140 deletion completed in 6.077105097s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:50:02.849: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating secret with name secret-test-78d40163-4f69-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 25 18:50:02.890: INFO: Waiting up to 5m0s for pod "pod-secrets-78d44e91-4f69-11e9-91ba-a08cfdecc127" in namespace "secrets-2434" to be "success or failure"
Mar 25 18:50:02.892: INFO: Pod "pod-secrets-78d44e91-4f69-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.653452ms
Mar 25 18:50:04.896: INFO: Pod "pod-secrets-78d44e91-4f69-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006490965s
[1mSTEP[0m: Saw pod success
Mar 25 18:50:04.896: INFO: Pod "pod-secrets-78d44e91-4f69-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:50:04.899: INFO: Trying to get logs from node conformance-worker2 pod pod-secrets-78d44e91-4f69-11e9-91ba-a08cfdecc127 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:50:04.919: INFO: Waiting for pod pod-secrets-78d44e91-4f69-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:50:04.921: INFO: Pod pod-secrets-78d44e91-4f69-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Secrets
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:50:04.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "secrets-2434" for this suite.
Mar 25 18:50:10.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:50:10.998: INFO: namespace secrets-2434 deletion completed in 6.074239993s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:50:10.998: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name configmap-test-volume-7daf062c-4f69-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 25 18:50:11.035: INFO: Waiting up to 5m0s for pod "pod-configmaps-7daf54e4-4f69-11e9-91ba-a08cfdecc127" in namespace "configmap-3469" to be "success or failure"
Mar 25 18:50:11.038: INFO: Pod "pod-configmaps-7daf54e4-4f69-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.148137ms
Mar 25 18:50:13.042: INFO: Pod "pod-configmaps-7daf54e4-4f69-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00725718s
[1mSTEP[0m: Saw pod success
Mar 25 18:50:13.042: INFO: Pod "pod-configmaps-7daf54e4-4f69-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:50:13.046: INFO: Trying to get logs from node conformance-worker2 pod pod-configmaps-7daf54e4-4f69-11e9-91ba-a08cfdecc127 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:50:13.065: INFO: Waiting for pod pod-configmaps-7daf54e4-4f69-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:50:13.067: INFO: Pod pod-configmaps-7daf54e4-4f69-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:50:13.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-3469" for this suite.
Mar 25 18:50:19.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:50:19.144: INFO: namespace configmap-3469 deletion completed in 6.074935926s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mdeployment should delete old replica sets [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:50:19.144: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Mar 25 18:50:19.176: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar 25 18:50:24.180: INFO: Pod name cleanup-pod: Found 1 pods out of 1
[1mSTEP[0m: ensuring each pod is running
Mar 25 18:50:24.181: INFO: Creating deployment test-cleanup-deployment
[1mSTEP[0m: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 25 18:50:24.200: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-5861,SelfLink:/apis/apps/v1/namespaces/deployment-5861/deployments/test-cleanup-deployment,UID:8586bb00-4f69-11e9-8304-02427cbbc9a0,ResourceVersion:19921,Generation:1,CreationTimestamp:2019-03-25 18:50:24 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Mar 25 18:50:24.205: INFO: New ReplicaSet "test-cleanup-deployment-55cbfbc8f5" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5,GenerateName:,Namespace:deployment-5861,SelfLink:/apis/apps/v1/namespaces/deployment-5861/replicasets/test-cleanup-deployment-55cbfbc8f5,UID:8588a903-4f69-11e9-8304-02427cbbc9a0,ResourceVersion:19923,Generation:1,CreationTimestamp:2019-03-25 18:50:24 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 8586bb00-4f69-11e9-8304-02427cbbc9a0 0xc002e860b7 0xc002e860b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 25 18:50:24.205: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Mar 25 18:50:24.206: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-5861,SelfLink:/apis/apps/v1/namespaces/deployment-5861/replicasets/test-cleanup-controller,UID:8289b652-4f69-11e9-8304-02427cbbc9a0,ResourceVersion:19922,Generation:1,CreationTimestamp:2019-03-25 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 8586bb00-4f69-11e9-8304-02427cbbc9a0 0xc00233ffe7 0xc00233ffe8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 25 18:50:24.210: INFO: Pod "test-cleanup-controller-47csq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-47csq,GenerateName:test-cleanup-controller-,Namespace:deployment-5861,SelfLink:/api/v1/namespaces/deployment-5861/pods/test-cleanup-controller-47csq,UID:828a501c-4f69-11e9-8304-02427cbbc9a0,ResourceVersion:19913,Generation:0,CreationTimestamp:2019-03-25 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 8289b652-4f69-11e9-8304-02427cbbc9a0 0xc002e86917 0xc002e86918}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-n2gqs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-n2gqs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-n2gqs true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e86980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e869a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:50:19 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:50:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:50:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:192.168.9.2,PodIP:10.32.0.2,StartTime:2019-03-25 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-25 18:50:20 -0700 PDT,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://9403b9160bd3e8169d0e147e47dac1229534478ecfd766d684f284d6508c328b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 25 18:50:24.210: INFO: Pod "test-cleanup-deployment-55cbfbc8f5-qsr44" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5-qsr44,GenerateName:test-cleanup-deployment-55cbfbc8f5-,Namespace:deployment-5861,SelfLink:/api/v1/namespaces/deployment-5861/pods/test-cleanup-deployment-55cbfbc8f5-qsr44,UID:85891166-4f69-11e9-8304-02427cbbc9a0,ResourceVersion:19928,Generation:0,CreationTimestamp:2019-03-25 18:50:24 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55cbfbc8f5 8588a903-4f69-11e9-8304-02427cbbc9a0 0xc002e86a77 0xc002e86a78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-n2gqs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-n2gqs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-n2gqs true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e86ae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e86b00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-25 18:50:24 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:50:24.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "deployment-5861" for this suite.
Mar 25 18:50:30.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:50:30.277: INFO: namespace deployment-5861 deletion completed in 6.062012479s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Docker Containers
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:50:30.277: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename containers
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test override arguments
Mar 25 18:50:30.305: INFO: Waiting up to 5m0s for pod "client-containers-892bafe9-4f69-11e9-91ba-a08cfdecc127" in namespace "containers-1690" to be "success or failure"
Mar 25 18:50:30.308: INFO: Pod "client-containers-892bafe9-4f69-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.354406ms
Mar 25 18:50:32.311: INFO: Pod "client-containers-892bafe9-4f69-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005543846s
[1mSTEP[0m: Saw pod success
Mar 25 18:50:32.311: INFO: Pod "client-containers-892bafe9-4f69-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:50:32.314: INFO: Trying to get logs from node conformance-worker pod client-containers-892bafe9-4f69-11e9-91ba-a08cfdecc127 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:50:32.331: INFO: Waiting for pod client-containers-892bafe9-4f69-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:50:32.333: INFO: Pod client-containers-892bafe9-4f69-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:50:32.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "containers-1690" for this suite.
Mar 25 18:50:38.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:50:38.406: INFO: namespace containers-1690 deletion completed in 6.070176004s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:50:38.406: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-map-8e044c49-4f69-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 25 18:50:38.442: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8e04aa2e-4f69-11e9-91ba-a08cfdecc127" in namespace "projected-6822" to be "success or failure"
Mar 25 18:50:38.444: INFO: Pod "pod-projected-configmaps-8e04aa2e-4f69-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 1.681916ms
Mar 25 18:50:40.447: INFO: Pod "pod-projected-configmaps-8e04aa2e-4f69-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005262182s
Mar 25 18:50:42.451: INFO: Pod "pod-projected-configmaps-8e04aa2e-4f69-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009065772s
[1mSTEP[0m: Saw pod success
Mar 25 18:50:42.451: INFO: Pod "pod-projected-configmaps-8e04aa2e-4f69-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:50:42.455: INFO: Trying to get logs from node conformance-worker pod pod-projected-configmaps-8e04aa2e-4f69-11e9-91ba-a08cfdecc127 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:50:42.485: INFO: Waiting for pod pod-projected-configmaps-8e04aa2e-4f69-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:50:42.487: INFO: Pod pod-projected-configmaps-8e04aa2e-4f69-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:50:42.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-6822" for this suite.
Mar 25 18:50:48.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:50:48.565: INFO: namespace projected-6822 deletion completed in 6.074273737s
[32mâ€¢[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1mshould be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-storage] Projected secret
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:50:48.565: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-map-94133550-4f69-11e9-91ba-a08cfdecc127
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 25 18:50:48.601: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-94137748-4f69-11e9-91ba-a08cfdecc127" in namespace "projected-2405" to be "success or failure"
Mar 25 18:50:48.604: INFO: Pod "pod-projected-secrets-94137748-4f69-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.626054ms
Mar 25 18:50:50.608: INFO: Pod "pod-projected-secrets-94137748-4f69-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007501366s
[1mSTEP[0m: Saw pod success
Mar 25 18:50:50.608: INFO: Pod "pod-projected-secrets-94137748-4f69-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:50:50.612: INFO: Trying to get logs from node conformance-worker pod pod-projected-secrets-94137748-4f69-11e9-91ba-a08cfdecc127 container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:50:50.633: INFO: Waiting for pod pod-projected-secrets-94137748-4f69-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:50:50.635: INFO: Pod pod-projected-secrets-94137748-4f69-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-storage] Projected secret
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:50:50.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-2405" for this suite.
Mar 25 18:50:56.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:50:56.716: INFO: namespace projected-2405 deletion completed in 6.078039531s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould run and stop complex daemon [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:50:56.716: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename daemonsets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Mar 25 18:50:56.768: INFO: Creating daemon "daemon-set" with a node selector
[1mSTEP[0m: Initially, daemon pods should not be running on any nodes.
Mar 25 18:50:56.775: INFO: Number of nodes with available pods: 0
Mar 25 18:50:56.775: INFO: Number of running nodes: 0, number of available pods: 0
[1mSTEP[0m: Change node label to blue, check that daemon pod is launched.
Mar 25 18:50:56.787: INFO: Number of nodes with available pods: 0
Mar 25 18:50:56.787: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:50:57.791: INFO: Number of nodes with available pods: 0
Mar 25 18:50:57.791: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:50:58.791: INFO: Number of nodes with available pods: 0
Mar 25 18:50:58.791: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:50:59.791: INFO: Number of nodes with available pods: 1
Mar 25 18:50:59.791: INFO: Number of running nodes: 1, number of available pods: 1
[1mSTEP[0m: Update the node label to green, and wait for daemons to be unscheduled
Mar 25 18:50:59.803: INFO: Number of nodes with available pods: 1
Mar 25 18:50:59.803: INFO: Number of running nodes: 0, number of available pods: 1
Mar 25 18:51:00.807: INFO: Number of nodes with available pods: 0
Mar 25 18:51:00.807: INFO: Number of running nodes: 0, number of available pods: 0
[1mSTEP[0m: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar 25 18:51:00.818: INFO: Number of nodes with available pods: 0
Mar 25 18:51:00.818: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:51:01.822: INFO: Number of nodes with available pods: 0
Mar 25 18:51:01.822: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:51:02.821: INFO: Number of nodes with available pods: 0
Mar 25 18:51:02.821: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:51:03.822: INFO: Number of nodes with available pods: 0
Mar 25 18:51:03.822: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:51:04.822: INFO: Number of nodes with available pods: 0
Mar 25 18:51:04.822: INFO: Node conformance-worker is running more than one daemon pod
Mar 25 18:51:05.821: INFO: Number of nodes with available pods: 1
Mar 25 18:51:05.821: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6139, will wait for the garbage collector to delete the pods
Mar 25 18:51:05.883: INFO: Deleting DaemonSet.extensions daemon-set took: 5.404743ms
Mar 25 18:51:06.183: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.192895ms
Mar 25 18:51:09.290: INFO: Number of nodes with available pods: 0
Mar 25 18:51:09.290: INFO: Number of running nodes: 0, number of available pods: 0
Mar 25 18:51:09.295: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6139/daemonsets","resourceVersion":"20180"},"items":null}

Mar 25 18:51:09.297: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6139/pods","resourceVersion":"20180"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:51:09.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "daemonsets-6139" for this suite.
Mar 25 18:51:15.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:51:15.384: INFO: namespace daemonsets-6139 deletion completed in 6.076883497s
[32mâ€¢[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould be submitted and removed [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:51:15.384: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating the pod
[1mSTEP[0m: setting up watch
[1mSTEP[0m: submitting the pod to kubernetes
Mar 25 18:51:15.416: INFO: observed the pod list
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: verifying pod creation was observed
[1mSTEP[0m: deleting the pod gracefully
[1mSTEP[0m: verifying the kubelet observed the termination notice
Mar 25 18:51:22.447: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[1mSTEP[0m: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:51:22.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-3441" for this suite.
Mar 25 18:51:28.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:51:28.530: INFO: namespace pods-3441 deletion completed in 6.076022513s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Lifecycle Hook[0m [90mwhen create a pod with lifecycle hook[0m 
  [1mshould execute poststart http hook properly [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:51:28.530: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename container-lifecycle-hook
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
[1mSTEP[0m: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: create the pod with lifecycle hook
[1mSTEP[0m: check poststart hook
[1mSTEP[0m: delete the pod with lifecycle hook
Mar 25 18:51:32.604: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 25 18:51:32.606: INFO: Pod pod-with-poststart-http-hook still exists
Mar 25 18:51:34.606: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 25 18:51:34.610: INFO: Pod pod-with-poststart-http-hook still exists
Mar 25 18:51:36.606: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 25 18:51:36.610: INFO: Pod pod-with-poststart-http-hook still exists
Mar 25 18:51:38.606: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 25 18:51:38.610: INFO: Pod pod-with-poststart-http-hook still exists
Mar 25 18:51:40.606: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 25 18:51:40.610: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:51:40.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-lifecycle-hook-6227" for this suite.
Mar 25 18:52:02.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:52:02.691: INFO: namespace container-lifecycle-hook-6227 deletion completed in 22.075985575s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould get a host IP [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:52:02.691: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: creating pod
Mar 25 18:52:04.736: INFO: Pod pod-hostip-c04220ea-4f69-11e9-91ba-a08cfdecc127 has hostIP: 192.168.9.2
[AfterEach] [k8s.io] Pods
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:52:04.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-3758" for this suite.
Mar 25 18:52:26.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:52:26.815: INFO: namespace pods-3758 deletion completed in 22.076725942s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] Downward API[0m 
  [1mshould provide host IP as an env var [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692[0m
[BeforeEach] [sig-node] Downward API
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
Mar 25 18:52:26.816: INFO: >>> kubeConfig: /usr/local/google/home/bentheelder/.kube/kind-config-conformance
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[1mSTEP[0m: Creating a pod to test downward api env vars
Mar 25 18:52:26.862: INFO: Waiting up to 5m0s for pod "downward-api-cea4963f-4f69-11e9-91ba-a08cfdecc127" in namespace "downward-api-9291" to be "success or failure"
Mar 25 18:52:26.865: INFO: Pod "downward-api-cea4963f-4f69-11e9-91ba-a08cfdecc127": Phase="Pending", Reason="", readiness=false. Elapsed: 3.047073ms
Mar 25 18:52:28.867: INFO: Pod "downward-api-cea4963f-4f69-11e9-91ba-a08cfdecc127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005626558s
[1mSTEP[0m: Saw pod success
Mar 25 18:52:28.867: INFO: Pod "downward-api-cea4963f-4f69-11e9-91ba-a08cfdecc127" satisfied condition "success or failure"
Mar 25 18:52:28.869: INFO: Trying to get logs from node conformance-worker2 pod downward-api-cea4963f-4f69-11e9-91ba-a08cfdecc127 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Mar 25 18:52:28.884: INFO: Waiting for pod downward-api-cea4963f-4f69-11e9-91ba-a08cfdecc127 to disappear
Mar 25 18:52:28.886: INFO: Pod downward-api-cea4963f-4f69-11e9-91ba-a08cfdecc127 no longer exists
[AfterEach] [sig-node] Downward API
  /usr/local/google/home/bentheelder/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Mar 25 18:52:28.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-9291" for this suite.
Mar 25 18:52:34.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 25 18:52:34.964: INFO: namespace downward-api-9291 deletion completed in 6.075911289s
[32mâ€¢[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0mMar 25 18:52:34.965: INFO: Running AfterSuite actions on all nodes
Mar 25 18:52:34.965: INFO: Running AfterSuite actions on node 1
Mar 25 18:52:34.965: INFO: Skipping dumping logs from cluster

[1m[32mRan 182 of 3584 Specs in 5094.052 seconds[0m
[1m[32mSUCCESS![0m -- [32m[1m182 Passed[0m | [91m[1m0 Failed[0m | [33m[1m0 Pending[0m | [36m[1m3402 Skipped[0m PASS

Ginkgo ran 1 suite in 1h24m54.960945995s
Test Suite Passed
