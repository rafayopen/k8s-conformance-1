I0906 15:24:44.873460      15 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-959664940
I0906 15:24:44.873575      15 e2e.go:240] Starting e2e run "73f276c1-d0ba-11e9-a08c-82ce3d77f2cb" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1567783483 - Will randomize all specs
Will run 204 of 3586 specs

Sep  6 15:24:45.024: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 15:24:45.026: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep  6 15:24:45.037: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep  6 15:24:45.058: INFO: 12 / 12 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep  6 15:24:45.058: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Sep  6 15:24:45.058: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep  6 15:24:45.062: INFO: e2e test version: v1.14.6
Sep  6 15:24:45.063: INFO: kube-apiserver version: v1.14.6
SS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:24:45.064: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename pods
Sep  6 15:24:45.084: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 15:24:45.085: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:24:47.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7318" for this suite.
Sep  6 15:25:37.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:25:37.270: INFO: namespace pods-7318 deletion completed in 50.075072193s

• [SLOW TEST:52.206 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:25:37.270: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-93c1155e-d0ba-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume configMaps
Sep  6 15:25:37.297: INFO: Waiting up to 5m0s for pod "pod-configmaps-93c16e4a-d0ba-11e9-a08c-82ce3d77f2cb" in namespace "configmap-7483" to be "success or failure"
Sep  6 15:25:37.299: INFO: Pod "pod-configmaps-93c16e4a-d0ba-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.94197ms
Sep  6 15:25:39.302: INFO: Pod "pod-configmaps-93c16e4a-d0ba-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004915196s
Sep  6 15:25:41.305: INFO: Pod "pod-configmaps-93c16e4a-d0ba-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00798364s
STEP: Saw pod success
Sep  6 15:25:41.305: INFO: Pod "pod-configmaps-93c16e4a-d0ba-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:25:41.307: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-configmaps-93c16e4a-d0ba-11e9-a08c-82ce3d77f2cb container configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 15:25:41.339: INFO: Waiting for pod pod-configmaps-93c16e4a-d0ba-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:25:41.341: INFO: Pod pod-configmaps-93c16e4a-d0ba-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:25:41.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7483" for this suite.
Sep  6 15:25:47.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:25:47.409: INFO: namespace configmap-7483 deletion completed in 6.066385643s

• [SLOW TEST:10.139 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:25:47.410: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-99cd36d2-d0ba-11e9-a08c-82ce3d77f2cb
STEP: Creating secret with name secret-projected-all-test-volume-99cd36b0-d0ba-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep  6 15:25:47.448: INFO: Waiting up to 5m0s for pod "projected-volume-99cd3675-d0ba-11e9-a08c-82ce3d77f2cb" in namespace "projected-8981" to be "success or failure"
Sep  6 15:25:47.452: INFO: Pod "projected-volume-99cd3675-d0ba-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.252028ms
Sep  6 15:25:49.455: INFO: Pod "projected-volume-99cd3675-d0ba-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006211525s
STEP: Saw pod success
Sep  6 15:25:49.455: INFO: Pod "projected-volume-99cd3675-d0ba-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:25:49.456: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod projected-volume-99cd3675-d0ba-11e9-a08c-82ce3d77f2cb container projected-all-volume-test: <nil>
STEP: delete the pod
Sep  6 15:25:49.476: INFO: Waiting for pod projected-volume-99cd3675-d0ba-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:25:49.478: INFO: Pod projected-volume-99cd3675-d0ba-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:25:49.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8981" for this suite.
Sep  6 15:25:55.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:25:55.542: INFO: namespace projected-8981 deletion completed in 6.06168764s

• [SLOW TEST:8.132 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:25:55.542: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 15:25:55.565: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9ea4ee44-d0ba-11e9-a08c-82ce3d77f2cb" in namespace "projected-6293" to be "success or failure"
Sep  6 15:25:55.568: INFO: Pod "downwardapi-volume-9ea4ee44-d0ba-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.842178ms
Sep  6 15:25:57.571: INFO: Pod "downwardapi-volume-9ea4ee44-d0ba-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005905598s
STEP: Saw pod success
Sep  6 15:25:57.571: INFO: Pod "downwardapi-volume-9ea4ee44-d0ba-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:25:57.572: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod downwardapi-volume-9ea4ee44-d0ba-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 15:25:57.583: INFO: Waiting for pod downwardapi-volume-9ea4ee44-d0ba-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:25:57.585: INFO: Pod downwardapi-volume-9ea4ee44-d0ba-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:25:57.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6293" for this suite.
Sep  6 15:26:03.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:26:03.652: INFO: namespace projected-6293 deletion completed in 6.064989386s

• [SLOW TEST:8.110 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:26:03.653: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep  6 15:26:03.687: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-9419,SelfLink:/api/v1/namespaces/watch-9419/configmaps/e2e-watch-test-resource-version,UID:a37a813c-d0ba-11e9-8afa-02e25174ea0a,ResourceVersion:856,Generation:0,CreationTimestamp:2019-09-06 15:26:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  6 15:26:03.687: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-9419,SelfLink:/api/v1/namespaces/watch-9419/configmaps/e2e-watch-test-resource-version,UID:a37a813c-d0ba-11e9-8afa-02e25174ea0a,ResourceVersion:857,Generation:0,CreationTimestamp:2019-09-06 15:26:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:26:03.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9419" for this suite.
Sep  6 15:26:09.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:26:09.757: INFO: namespace watch-9419 deletion completed in 6.066557729s

• [SLOW TEST:6.104 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:26:09.757: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-a71de582-d0ba-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume secrets
Sep  6 15:26:09.783: INFO: Waiting up to 5m0s for pod "pod-secrets-a71e39a2-d0ba-11e9-a08c-82ce3d77f2cb" in namespace "secrets-2145" to be "success or failure"
Sep  6 15:26:09.786: INFO: Pod "pod-secrets-a71e39a2-d0ba-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.759441ms
Sep  6 15:26:11.789: INFO: Pod "pod-secrets-a71e39a2-d0ba-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005404186s
Sep  6 15:26:13.792: INFO: Pod "pod-secrets-a71e39a2-d0ba-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008520891s
STEP: Saw pod success
Sep  6 15:26:13.792: INFO: Pod "pod-secrets-a71e39a2-d0ba-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:26:13.794: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-secrets-a71e39a2-d0ba-11e9-a08c-82ce3d77f2cb container secret-volume-test: <nil>
STEP: delete the pod
Sep  6 15:26:13.807: INFO: Waiting for pod pod-secrets-a71e39a2-d0ba-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:26:13.808: INFO: Pod pod-secrets-a71e39a2-d0ba-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:26:13.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2145" for this suite.
Sep  6 15:26:19.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:26:19.875: INFO: namespace secrets-2145 deletion completed in 6.064891089s

• [SLOW TEST:10.119 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:26:19.875: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1649
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  6 15:26:19.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-151'
Sep  6 15:26:20.119: INFO: stderr: ""
Sep  6 15:26:20.119: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1654
Sep  6 15:26:20.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 delete pods e2e-test-nginx-pod --namespace=kubectl-151'
Sep  6 15:26:23.407: INFO: stderr: ""
Sep  6 15:26:23.407: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:26:23.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-151" for this suite.
Sep  6 15:26:29.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:26:29.483: INFO: namespace kubectl-151 deletion completed in 6.073909638s

• [SLOW TEST:9.608 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:26:29.484: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:27:29.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-855" for this suite.
Sep  6 15:27:51.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:27:51.583: INFO: namespace container-probe-855 deletion completed in 22.070580965s

• [SLOW TEST:82.099 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:27:51.583: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-4109/secret-test-e3cf9aaa-d0ba-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume secrets
Sep  6 15:27:51.610: INFO: Waiting up to 5m0s for pod "pod-configmaps-e3cfeafb-d0ba-11e9-a08c-82ce3d77f2cb" in namespace "secrets-4109" to be "success or failure"
Sep  6 15:27:51.614: INFO: Pod "pod-configmaps-e3cfeafb-d0ba-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.284792ms
Sep  6 15:27:53.617: INFO: Pod "pod-configmaps-e3cfeafb-d0ba-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007258334s
Sep  6 15:27:55.620: INFO: Pod "pod-configmaps-e3cfeafb-d0ba-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010152139s
STEP: Saw pod success
Sep  6 15:27:55.620: INFO: Pod "pod-configmaps-e3cfeafb-d0ba-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:27:55.622: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-configmaps-e3cfeafb-d0ba-11e9-a08c-82ce3d77f2cb container env-test: <nil>
STEP: delete the pod
Sep  6 15:27:55.633: INFO: Waiting for pod pod-configmaps-e3cfeafb-d0ba-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:27:55.635: INFO: Pod pod-configmaps-e3cfeafb-d0ba-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:27:55.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4109" for this suite.
Sep  6 15:28:01.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:28:01.710: INFO: namespace secrets-4109 deletion completed in 6.072255438s

• [SLOW TEST:10.127 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:28:01.710: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1256
STEP: creating an rc
Sep  6 15:28:01.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 create -f - --namespace=kubectl-3025'
Sep  6 15:28:01.941: INFO: stderr: ""
Sep  6 15:28:01.941: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Sep  6 15:28:02.944: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 15:28:02.944: INFO: Found 0 / 1
Sep  6 15:28:03.943: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 15:28:03.943: INFO: Found 0 / 1
Sep  6 15:28:04.944: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 15:28:04.944: INFO: Found 1 / 1
Sep  6 15:28:04.944: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  6 15:28:04.946: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 15:28:04.946: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Sep  6 15:28:04.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 logs redis-master-f84cr redis-master --namespace=kubectl-3025'
Sep  6 15:28:05.024: INFO: stderr: ""
Sep  6 15:28:05.024: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 06 Sep 15:28:03.976 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Sep 15:28:03.976 # Server started, Redis version 3.2.12\n1:M 06 Sep 15:28:03.976 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Sep 15:28:03.976 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Sep  6 15:28:05.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 log redis-master-f84cr redis-master --namespace=kubectl-3025 --tail=1'
Sep  6 15:28:05.114: INFO: stderr: ""
Sep  6 15:28:05.114: INFO: stdout: "1:M 06 Sep 15:28:03.976 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Sep  6 15:28:05.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 log redis-master-f84cr redis-master --namespace=kubectl-3025 --limit-bytes=1'
Sep  6 15:28:05.194: INFO: stderr: ""
Sep  6 15:28:05.194: INFO: stdout: " "
STEP: exposing timestamps
Sep  6 15:28:05.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 log redis-master-f84cr redis-master --namespace=kubectl-3025 --tail=1 --timestamps'
Sep  6 15:28:05.271: INFO: stderr: ""
Sep  6 15:28:05.271: INFO: stdout: "2019-09-06T15:28:03.976375435Z 1:M 06 Sep 15:28:03.976 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Sep  6 15:28:07.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 log redis-master-f84cr redis-master --namespace=kubectl-3025 --since=1s'
Sep  6 15:28:07.851: INFO: stderr: ""
Sep  6 15:28:07.851: INFO: stdout: ""
Sep  6 15:28:07.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 log redis-master-f84cr redis-master --namespace=kubectl-3025 --since=24h'
Sep  6 15:28:07.928: INFO: stderr: ""
Sep  6 15:28:07.928: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 06 Sep 15:28:03.976 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Sep 15:28:03.976 # Server started, Redis version 3.2.12\n1:M 06 Sep 15:28:03.976 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Sep 15:28:03.976 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
STEP: using delete to clean up resources
Sep  6 15:28:07.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 delete --grace-period=0 --force -f - --namespace=kubectl-3025'
Sep  6 15:28:08.003: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 15:28:08.003: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Sep  6 15:28:08.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get rc,svc -l name=nginx --no-headers --namespace=kubectl-3025'
Sep  6 15:28:08.082: INFO: stderr: "No resources found.\n"
Sep  6 15:28:08.082: INFO: stdout: ""
Sep  6 15:28:08.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -l name=nginx --namespace=kubectl-3025 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  6 15:28:08.150: INFO: stderr: ""
Sep  6 15:28:08.150: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:28:08.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3025" for this suite.
Sep  6 15:28:30.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:28:30.254: INFO: namespace kubectl-3025 deletion completed in 22.101140963s

• [SLOW TEST:28.545 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:28:30.254: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep  6 15:28:32.801: INFO: Successfully updated pod "labelsupdatefadc36a4-d0ba-11e9-a08c-82ce3d77f2cb"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:28:36.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8683" for this suite.
Sep  6 15:28:58.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:28:58.903: INFO: namespace downward-api-8683 deletion completed in 22.067513273s

• [SLOW TEST:28.649 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:28:58.903: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  6 15:28:58.922: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  6 15:28:58.926: INFO: Waiting for terminating namespaces to be deleted...
Sep  6 15:28:58.928: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-60-162.us-east-2.compute.internal before test
Sep  6 15:28:58.932: INFO: kube-dns-autoscaler-6567f59ccb-gpkrr from kube-system started at 2019-09-06 15:22:51 +0000 UTC (1 container statuses recorded)
Sep  6 15:28:58.932: INFO: 	Container autoscaler ready: true, restart count 0
Sep  6 15:28:58.932: INFO: kube-dns-66d58c65d5-rt2hs from kube-system started at 2019-09-06 15:22:54 +0000 UTC (3 container statuses recorded)
Sep  6 15:28:58.932: INFO: 	Container dnsmasq ready: true, restart count 0
Sep  6 15:28:58.932: INFO: 	Container kubedns ready: true, restart count 0
Sep  6 15:28:58.932: INFO: 	Container sidecar ready: true, restart count 0
Sep  6 15:28:58.932: INFO: sonobuoy-systemd-logs-daemon-set-792ed0eef92d49d6-qsnlb from heptio-sonobuoy started at 2019-09-06 15:24:16 +0000 UTC (2 container statuses recorded)
Sep  6 15:28:58.932: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  6 15:28:58.932: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  6 15:28:58.932: INFO: kube-proxy-ip-172-20-60-162.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Sep  6 15:28:58.932: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-61-48.us-east-2.compute.internal before test
Sep  6 15:28:58.936: INFO: kube-proxy-ip-172-20-61-48.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Sep  6 15:28:58.936: INFO: kube-dns-66d58c65d5-6dppm from kube-system started at 2019-09-06 15:22:51 +0000 UTC (3 container statuses recorded)
Sep  6 15:28:58.936: INFO: 	Container dnsmasq ready: true, restart count 0
Sep  6 15:28:58.936: INFO: 	Container kubedns ready: true, restart count 0
Sep  6 15:28:58.936: INFO: 	Container sidecar ready: true, restart count 0
Sep  6 15:28:58.936: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-06 15:24:11 +0000 UTC (1 container statuses recorded)
Sep  6 15:28:58.936: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  6 15:28:58.936: INFO: sonobuoy-e2e-job-eb90599f41e04e4a from heptio-sonobuoy started at 2019-09-06 15:24:16 +0000 UTC (2 container statuses recorded)
Sep  6 15:28:58.936: INFO: 	Container e2e ready: true, restart count 0
Sep  6 15:28:58.936: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  6 15:28:58.936: INFO: sonobuoy-systemd-logs-daemon-set-792ed0eef92d49d6-m2qh6 from heptio-sonobuoy started at 2019-09-06 15:24:16 +0000 UTC (2 container statuses recorded)
Sep  6 15:28:58.936: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  6 15:28:58.936: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-0e56ff75-d0bb-11e9-a08c-82ce3d77f2cb 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-0e56ff75-d0bb-11e9-a08c-82ce3d77f2cb off the node ip-172-20-60-162.us-east-2.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-0e56ff75-d0bb-11e9-a08c-82ce3d77f2cb
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:29:04.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2233" for this suite.
Sep  6 15:29:16.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:29:17.043: INFO: namespace sched-pred-2233 deletion completed in 12.061979344s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:18.140 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:29:17.044: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0906 15:29:27.107516      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  6 15:29:27.107: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:29:27.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9303" for this suite.
Sep  6 15:29:33.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:29:33.173: INFO: namespace gc-9303 deletion completed in 6.06409335s

• [SLOW TEST:16.129 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:29:33.173: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 15:29:33.193: INFO: Creating ReplicaSet my-hostname-basic-205cea3f-d0bb-11e9-a08c-82ce3d77f2cb
Sep  6 15:29:33.198: INFO: Pod name my-hostname-basic-205cea3f-d0bb-11e9-a08c-82ce3d77f2cb: Found 0 pods out of 1
Sep  6 15:29:38.203: INFO: Pod name my-hostname-basic-205cea3f-d0bb-11e9-a08c-82ce3d77f2cb: Found 1 pods out of 1
Sep  6 15:29:38.203: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-205cea3f-d0bb-11e9-a08c-82ce3d77f2cb" is running
Sep  6 15:29:38.206: INFO: Pod "my-hostname-basic-205cea3f-d0bb-11e9-a08c-82ce3d77f2cb-sfzgn" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-06 15:29:33 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-06 15:29:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-06 15:29:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-06 15:29:33 +0000 UTC Reason: Message:}])
Sep  6 15:29:38.206: INFO: Trying to dial the pod
Sep  6 15:29:43.213: INFO: Controller my-hostname-basic-205cea3f-d0bb-11e9-a08c-82ce3d77f2cb: Got expected result from replica 1 [my-hostname-basic-205cea3f-d0bb-11e9-a08c-82ce3d77f2cb-sfzgn]: "my-hostname-basic-205cea3f-d0bb-11e9-a08c-82ce3d77f2cb-sfzgn", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:29:43.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2727" for this suite.
Sep  6 15:29:49.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:29:49.352: INFO: namespace replicaset-2727 deletion completed in 6.137120065s

• [SLOW TEST:16.179 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:29:49.353: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-5728
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5728
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5728
Sep  6 15:29:49.392: INFO: Found 0 stateful pods, waiting for 1
Sep  6 15:29:59.395: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep  6 15:29:59.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-5728 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 15:29:59.553: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  6 15:29:59.553: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 15:29:59.553: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 15:29:59.556: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  6 15:30:09.559: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  6 15:30:09.559: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 15:30:09.567: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998605s
Sep  6 15:30:10.570: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997647979s
Sep  6 15:30:11.574: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994648232s
Sep  6 15:30:12.577: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.99103767s
Sep  6 15:30:13.580: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.988038406s
Sep  6 15:30:14.583: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.984935886s
Sep  6 15:30:15.586: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.981885022s
Sep  6 15:30:16.589: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.978929045s
Sep  6 15:30:17.592: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.975747526s
Sep  6 15:30:18.595: INFO: Verifying statefulset ss doesn't scale past 1 for another 972.738322ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5728
Sep  6 15:30:19.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-5728 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 15:30:19.753: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  6 15:30:19.753: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  6 15:30:19.753: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  6 15:30:19.756: INFO: Found 1 stateful pods, waiting for 3
Sep  6 15:30:29.759: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 15:30:29.759: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 15:30:29.759: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep  6 15:30:29.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-5728 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 15:30:29.917: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  6 15:30:29.917: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 15:30:29.917: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 15:30:29.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-5728 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 15:30:30.081: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  6 15:30:30.081: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 15:30:30.081: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 15:30:30.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-5728 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 15:30:30.239: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  6 15:30:30.239: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 15:30:30.239: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 15:30:30.239: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 15:30:30.242: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Sep  6 15:30:40.248: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  6 15:30:40.248: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  6 15:30:40.248: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  6 15:30:40.256: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998622s
Sep  6 15:30:41.259: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996791095s
Sep  6 15:30:42.261: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993659927s
Sep  6 15:30:43.264: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991045889s
Sep  6 15:30:44.267: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.98801064s
Sep  6 15:30:45.270: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.985277895s
Sep  6 15:30:46.273: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.982093641s
Sep  6 15:30:47.276: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.979163546s
Sep  6 15:30:48.279: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.976185237s
Sep  6 15:30:49.282: INFO: Verifying statefulset ss doesn't scale past 3 for another 973.39467ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5728
Sep  6 15:30:50.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-5728 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 15:30:50.439: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  6 15:30:50.439: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  6 15:30:50.439: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  6 15:30:50.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-5728 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 15:30:50.603: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  6 15:30:50.603: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  6 15:30:50.603: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  6 15:30:50.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-5728 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 15:30:50.771: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  6 15:30:50.771: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  6 15:30:50.771: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  6 15:30:50.771: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  6 15:31:00.782: INFO: Deleting all statefulset in ns statefulset-5728
Sep  6 15:31:00.784: INFO: Scaling statefulset ss to 0
Sep  6 15:31:00.789: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 15:31:00.791: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:31:00.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5728" for this suite.
Sep  6 15:31:06.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:31:06.871: INFO: namespace statefulset-5728 deletion completed in 6.069072738s

• [SLOW TEST:77.519 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:31:06.871: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 15:31:06.918: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep  6 15:31:11.921: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  6 15:31:11.921: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  6 15:31:11.937: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-2147,SelfLink:/apis/apps/v1/namespaces/deployment-2147/deployments/test-cleanup-deployment,UID:5b350d54-d0bb-11e9-8afa-02e25174ea0a,ResourceVersion:1673,Generation:1,CreationTimestamp:2019-09-06 15:31:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Sep  6 15:31:11.945: INFO: New ReplicaSet "test-cleanup-deployment-6865c98b76" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76,GenerateName:,Namespace:deployment-2147,SelfLink:/apis/apps/v1/namespaces/deployment-2147/replicasets/test-cleanup-deployment-6865c98b76,UID:5b36d6c2-d0bb-11e9-8afa-02e25174ea0a,ResourceVersion:1675,Generation:1,CreationTimestamp:2019-09-06 15:31:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 5b350d54-d0bb-11e9-8afa-02e25174ea0a 0xc0023955f7 0xc0023955f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  6 15:31:11.946: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Sep  6 15:31:11.946: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-2147,SelfLink:/apis/apps/v1/namespaces/deployment-2147/replicasets/test-cleanup-controller,UID:58387b8f-d0bb-11e9-8afa-02e25174ea0a,ResourceVersion:1674,Generation:1,CreationTimestamp:2019-09-06 15:31:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 5b350d54-d0bb-11e9-8afa-02e25174ea0a 0xc00239551f 0xc002395530}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  6 15:31:11.956: INFO: Pod "test-cleanup-controller-s2skh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-s2skh,GenerateName:test-cleanup-controller-,Namespace:deployment-2147,SelfLink:/api/v1/namespaces/deployment-2147/pods/test-cleanup-controller-s2skh,UID:583957e8-d0bb-11e9-8afa-02e25174ea0a,ResourceVersion:1664,Generation:0,CreationTimestamp:2019-09-06 15:31:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 58387b8f-d0bb-11e9-8afa-02e25174ea0a 0xc0026de1df 0xc0026de1f0}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fhlr8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fhlr8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fhlr8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-61-48.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026de250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026de270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:31:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:31:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:31:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:31:06 +0000 UTC  }],Message:,Reason:,HostIP:172.20.61.48,PodIP:100.96.1.16,StartTime:2019-09-06 15:31:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 15:31:07 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c0ae85d0d34cf67466863922fde176466fad5bb819607a809500eafc07ca4705}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:31:11.956: INFO: Pod "test-cleanup-deployment-6865c98b76-pdzhw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76-pdzhw,GenerateName:test-cleanup-deployment-6865c98b76-,Namespace:deployment-2147,SelfLink:/api/v1/namespaces/deployment-2147/pods/test-cleanup-deployment-6865c98b76-pdzhw,UID:5b374bc8-d0bb-11e9-8afa-02e25174ea0a,ResourceVersion:1679,Generation:0,CreationTimestamp:2019-09-06 15:31:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-6865c98b76 5b36d6c2-d0bb-11e9-8afa-02e25174ea0a 0xc0026de467 0xc0026de468}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fhlr8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fhlr8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-fhlr8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-162.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026de630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026de650}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:31:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:31:11.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2147" for this suite.
Sep  6 15:31:17.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:31:18.045: INFO: namespace deployment-2147 deletion completed in 6.081715591s

• [SLOW TEST:11.174 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:31:18.046: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:31:22.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8549" for this suite.
Sep  6 15:31:28.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:31:28.148: INFO: namespace kubelet-test-8549 deletion completed in 6.072101686s

• [SLOW TEST:10.102 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:31:28.148: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-jr5j
STEP: Creating a pod to test atomic-volume-subpath
Sep  6 15:31:28.177: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-jr5j" in namespace "subpath-9899" to be "success or failure"
Sep  6 15:31:28.181: INFO: Pod "pod-subpath-test-configmap-jr5j": Phase="Pending", Reason="", readiness=false. Elapsed: 3.461799ms
Sep  6 15:31:30.184: INFO: Pod "pod-subpath-test-configmap-jr5j": Phase="Running", Reason="", readiness=true. Elapsed: 2.00655603s
Sep  6 15:31:32.187: INFO: Pod "pod-subpath-test-configmap-jr5j": Phase="Running", Reason="", readiness=true. Elapsed: 4.009499444s
Sep  6 15:31:34.190: INFO: Pod "pod-subpath-test-configmap-jr5j": Phase="Running", Reason="", readiness=true. Elapsed: 6.012632617s
Sep  6 15:31:36.193: INFO: Pod "pod-subpath-test-configmap-jr5j": Phase="Running", Reason="", readiness=true. Elapsed: 8.015761996s
Sep  6 15:31:38.196: INFO: Pod "pod-subpath-test-configmap-jr5j": Phase="Running", Reason="", readiness=true. Elapsed: 10.018716365s
Sep  6 15:31:40.199: INFO: Pod "pod-subpath-test-configmap-jr5j": Phase="Running", Reason="", readiness=true. Elapsed: 12.021568346s
Sep  6 15:31:42.201: INFO: Pod "pod-subpath-test-configmap-jr5j": Phase="Running", Reason="", readiness=true. Elapsed: 14.023864275s
Sep  6 15:31:44.204: INFO: Pod "pod-subpath-test-configmap-jr5j": Phase="Running", Reason="", readiness=true. Elapsed: 16.026985118s
Sep  6 15:31:46.207: INFO: Pod "pod-subpath-test-configmap-jr5j": Phase="Running", Reason="", readiness=true. Elapsed: 18.030069037s
Sep  6 15:31:48.211: INFO: Pod "pod-subpath-test-configmap-jr5j": Phase="Running", Reason="", readiness=true. Elapsed: 20.03329282s
Sep  6 15:31:50.214: INFO: Pod "pod-subpath-test-configmap-jr5j": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.036176027s
STEP: Saw pod success
Sep  6 15:31:50.214: INFO: Pod "pod-subpath-test-configmap-jr5j" satisfied condition "success or failure"
Sep  6 15:31:50.215: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-subpath-test-configmap-jr5j container test-container-subpath-configmap-jr5j: <nil>
STEP: delete the pod
Sep  6 15:31:50.230: INFO: Waiting for pod pod-subpath-test-configmap-jr5j to disappear
Sep  6 15:31:50.236: INFO: Pod pod-subpath-test-configmap-jr5j no longer exists
STEP: Deleting pod pod-subpath-test-configmap-jr5j
Sep  6 15:31:50.236: INFO: Deleting pod "pod-subpath-test-configmap-jr5j" in namespace "subpath-9899"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:31:50.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9899" for this suite.
Sep  6 15:31:56.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:31:56.311: INFO: namespace subpath-9899 deletion completed in 6.072021615s

• [SLOW TEST:28.163 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:31:56.312: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 15:31:56.334: INFO: Waiting up to 5m0s for pod "downwardapi-volume-75adfca8-d0bb-11e9-a08c-82ce3d77f2cb" in namespace "projected-7464" to be "success or failure"
Sep  6 15:31:56.337: INFO: Pod "downwardapi-volume-75adfca8-d0bb-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.179155ms
Sep  6 15:31:58.339: INFO: Pod "downwardapi-volume-75adfca8-d0bb-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005034053s
STEP: Saw pod success
Sep  6 15:31:58.339: INFO: Pod "downwardapi-volume-75adfca8-d0bb-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:31:58.341: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod downwardapi-volume-75adfca8-d0bb-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 15:31:58.355: INFO: Waiting for pod downwardapi-volume-75adfca8-d0bb-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:31:58.357: INFO: Pod downwardapi-volume-75adfca8-d0bb-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:31:58.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7464" for this suite.
Sep  6 15:32:04.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:32:04.429: INFO: namespace projected-7464 deletion completed in 6.069170025s

• [SLOW TEST:8.117 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:32:04.429: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep  6 15:32:04.452: INFO: Waiting up to 5m0s for pod "pod-7a84a823-d0bb-11e9-a08c-82ce3d77f2cb" in namespace "emptydir-1747" to be "success or failure"
Sep  6 15:32:04.455: INFO: Pod "pod-7a84a823-d0bb-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.425324ms
Sep  6 15:32:06.457: INFO: Pod "pod-7a84a823-d0bb-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005385718s
STEP: Saw pod success
Sep  6 15:32:06.458: INFO: Pod "pod-7a84a823-d0bb-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:32:06.459: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-7a84a823-d0bb-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 15:32:06.471: INFO: Waiting for pod pod-7a84a823-d0bb-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:32:06.473: INFO: Pod pod-7a84a823-d0bb-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:32:06.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1747" for this suite.
Sep  6 15:32:12.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:32:12.543: INFO: namespace emptydir-1747 deletion completed in 6.067824549s

• [SLOW TEST:8.114 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:32:12.543: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-8723
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-8723
STEP: Creating statefulset with conflicting port in namespace statefulset-8723
STEP: Waiting until pod test-pod will start running in namespace statefulset-8723
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-8723
Sep  6 15:32:14.590: INFO: Observed stateful pod in namespace: statefulset-8723, name: ss-0, uid: 8036898c-d0bb-11e9-8afa-02e25174ea0a, status phase: Pending. Waiting for statefulset controller to delete.
Sep  6 15:32:15.002: INFO: Observed stateful pod in namespace: statefulset-8723, name: ss-0, uid: 8036898c-d0bb-11e9-8afa-02e25174ea0a, status phase: Failed. Waiting for statefulset controller to delete.
Sep  6 15:32:15.006: INFO: Observed stateful pod in namespace: statefulset-8723, name: ss-0, uid: 8036898c-d0bb-11e9-8afa-02e25174ea0a, status phase: Failed. Waiting for statefulset controller to delete.
Sep  6 15:32:15.009: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-8723
STEP: Removing pod with conflicting port in namespace statefulset-8723
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-8723 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  6 15:32:19.029: INFO: Deleting all statefulset in ns statefulset-8723
Sep  6 15:32:19.031: INFO: Scaling statefulset ss to 0
Sep  6 15:32:29.041: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 15:32:29.043: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:32:29.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8723" for this suite.
Sep  6 15:32:35.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:32:35.155: INFO: namespace statefulset-8723 deletion completed in 6.09608662s

• [SLOW TEST:22.612 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:32:35.155: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Sep  6 15:32:35.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 api-versions'
Sep  6 15:32:35.249: INFO: stderr: ""
Sep  6 15:32:35.249: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:32:35.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1899" for this suite.
Sep  6 15:32:41.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:32:41.315: INFO: namespace kubectl-1899 deletion completed in 6.06304787s

• [SLOW TEST:6.159 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:32:41.315: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8046.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8046.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  6 15:32:51.363: INFO: DNS probes using dns-8046/dns-test-9080ffff-d0bb-11e9-a08c-82ce3d77f2cb succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:32:51.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8046" for this suite.
Sep  6 15:32:57.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:32:57.440: INFO: namespace dns-8046 deletion completed in 6.066356754s

• [SLOW TEST:16.125 seconds]
[sig-network] DNS
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:32:57.441: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:32:57.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2075" for this suite.
Sep  6 15:33:03.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:33:03.532: INFO: namespace services-2075 deletion completed in 6.068429872s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.092 seconds]
[sig-network] Services
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:33:03.532: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 15:33:03.603: INFO: Creating deployment "test-recreate-deployment"
Sep  6 15:33:03.606: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep  6 15:33:03.612: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Sep  6 15:33:05.616: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep  6 15:33:05.618: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep  6 15:33:05.623: INFO: Updating deployment test-recreate-deployment
Sep  6 15:33:05.623: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  6 15:33:05.685: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-624,SelfLink:/apis/apps/v1/namespaces/deployment-624/deployments/test-recreate-deployment,UID:9dc5796b-d0bb-11e9-8afa-02e25174ea0a,ResourceVersion:2069,Generation:2,CreationTimestamp:2019-09-06 15:33:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-09-06 15:33:05 +0000 UTC 2019-09-06 15:33:05 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-06 15:33:05 +0000 UTC 2019-09-06 15:33:03 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-745fb9c84c" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Sep  6 15:33:05.687: INFO: New ReplicaSet "test-recreate-deployment-745fb9c84c" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c,GenerateName:,Namespace:deployment-624,SelfLink:/apis/apps/v1/namespaces/deployment-624/replicasets/test-recreate-deployment-745fb9c84c,UID:9efd3739-d0bb-11e9-8afa-02e25174ea0a,ResourceVersion:2066,Generation:1,CreationTimestamp:2019-09-06 15:33:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 9dc5796b-d0bb-11e9-8afa-02e25174ea0a 0xc002860427 0xc002860428}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  6 15:33:05.687: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep  6 15:33:05.688: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6566d46b4b,GenerateName:,Namespace:deployment-624,SelfLink:/apis/apps/v1/namespaces/deployment-624/replicasets/test-recreate-deployment-6566d46b4b,UID:9dc5e87f-d0bb-11e9-8afa-02e25174ea0a,ResourceVersion:2060,Generation:2,CreationTimestamp:2019-09-06 15:33:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 9dc5796b-d0bb-11e9-8afa-02e25174ea0a 0xc002860367 0xc002860368}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  6 15:33:05.690: INFO: Pod "test-recreate-deployment-745fb9c84c-vl4kr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c-vl4kr,GenerateName:test-recreate-deployment-745fb9c84c-,Namespace:deployment-624,SelfLink:/api/v1/namespaces/deployment-624/pods/test-recreate-deployment-745fb9c84c-vl4kr,UID:9efdcdc2-d0bb-11e9-8afa-02e25174ea0a,ResourceVersion:2068,Generation:0,CreationTimestamp:2019-09-06 15:33:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-745fb9c84c 9efd3739-d0bb-11e9-8afa-02e25174ea0a 0xc002860cc7 0xc002860cc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wz8zz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wz8zz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wz8zz true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-61-48.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002860d30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002860d50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:33:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:33:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:33:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:33:05 +0000 UTC  }],Message:,Reason:,HostIP:172.20.61.48,PodIP:,StartTime:2019-09-06 15:33:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:33:05.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-624" for this suite.
Sep  6 15:33:11.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:33:11.758: INFO: namespace deployment-624 deletion completed in 6.065704914s

• [SLOW TEST:8.225 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:33:11.758: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-a2a6eed0-d0bb-11e9-a08c-82ce3d77f2cb
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:33:13.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-295" for this suite.
Sep  6 15:33:35.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:33:35.876: INFO: namespace configmap-295 deletion completed in 22.06812976s

• [SLOW TEST:24.118 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:33:35.878: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep  6 15:33:41.929: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  6 15:33:41.931: INFO: Pod pod-with-poststart-http-hook still exists
Sep  6 15:33:43.931: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  6 15:33:43.934: INFO: Pod pod-with-poststart-http-hook still exists
Sep  6 15:33:45.931: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  6 15:33:45.934: INFO: Pod pod-with-poststart-http-hook still exists
Sep  6 15:33:47.932: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  6 15:33:47.934: INFO: Pod pod-with-poststart-http-hook still exists
Sep  6 15:33:49.931: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  6 15:33:49.934: INFO: Pod pod-with-poststart-http-hook still exists
Sep  6 15:33:51.931: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  6 15:33:51.934: INFO: Pod pod-with-poststart-http-hook still exists
Sep  6 15:33:53.931: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  6 15:33:53.934: INFO: Pod pod-with-poststart-http-hook still exists
Sep  6 15:33:55.932: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  6 15:33:55.934: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:33:55.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6769" for this suite.
Sep  6 15:34:17.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:34:18.018: INFO: namespace container-lifecycle-hook-6769 deletion completed in 22.081197997s

• [SLOW TEST:42.140 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:34:18.019: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep  6 15:34:18.043: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:34:21.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6010" for this suite.
Sep  6 15:34:43.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:34:43.923: INFO: namespace init-container-6010 deletion completed in 22.061784352s

• [SLOW TEST:25.905 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:34:43.924: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 15:34:43.956: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:34:45.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6292" for this suite.
Sep  6 15:35:35.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:35:36.059: INFO: namespace pods-6292 deletion completed in 50.076030262s

• [SLOW TEST:52.135 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:35:36.059: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-f8a91b99-d0bb-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume configMaps
Sep  6 15:35:36.086: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f8a972b5-d0bb-11e9-a08c-82ce3d77f2cb" in namespace "projected-652" to be "success or failure"
Sep  6 15:35:36.089: INFO: Pod "pod-projected-configmaps-f8a972b5-d0bb-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.574747ms
Sep  6 15:35:38.092: INFO: Pod "pod-projected-configmaps-f8a972b5-d0bb-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005624734s
STEP: Saw pod success
Sep  6 15:35:38.092: INFO: Pod "pod-projected-configmaps-f8a972b5-d0bb-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:35:38.094: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-projected-configmaps-f8a972b5-d0bb-11e9-a08c-82ce3d77f2cb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 15:35:38.106: INFO: Waiting for pod pod-projected-configmaps-f8a972b5-d0bb-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:35:38.108: INFO: Pod pod-projected-configmaps-f8a972b5-d0bb-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:35:38.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-652" for this suite.
Sep  6 15:35:44.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:35:44.175: INFO: namespace projected-652 deletion completed in 6.065192518s

• [SLOW TEST:8.116 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:35:44.176: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep  6 15:35:48.212: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-fd7fdf18-d0bb-11e9-a08c-82ce3d77f2cb,GenerateName:,Namespace:events-9523,SelfLink:/api/v1/namespaces/events-9523/pods/send-events-fd7fdf18-d0bb-11e9-a08c-82ce3d77f2cb,UID:fd7df036-d0bb-11e9-8afa-02e25174ea0a,ResourceVersion:2425,Generation:0,CreationTimestamp:2019-09-06 15:35:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 198843080,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jzzpg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jzzpg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-jzzpg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-162.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00094dbd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00094dbf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:35:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:35:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:35:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:35:44 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.162,PodIP:100.96.2.31,StartTime:2019-09-06 15:35:44 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-09-06 15:35:46 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://d50b240e7373b2cd95aebf9da8273c7a882f0f79eb70399c59b13eff68a94f0d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Sep  6 15:35:50.216: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep  6 15:35:52.219: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:35:52.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9523" for this suite.
Sep  6 15:36:36.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:36:36.294: INFO: namespace events-9523 deletion completed in 44.067107733s

• [SLOW TEST:52.119 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:36:36.294: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-3613
Sep  6 15:36:38.335: INFO: Started pod liveness-http in namespace container-probe-3613
STEP: checking the pod's current state and verifying that restartCount is present
Sep  6 15:36:38.336: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:40:38.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3613" for this suite.
Sep  6 15:40:44.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:40:44.783: INFO: namespace container-probe-3613 deletion completed in 6.066763071s

• [SLOW TEST:248.488 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:40:44.783: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 15:40:44.807: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:40:45.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2862" for this suite.
Sep  6 15:40:51.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:40:51.916: INFO: namespace custom-resource-definition-2862 deletion completed in 6.069739893s

• [SLOW TEST:7.133 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:32
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:40:51.916: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep  6 15:40:51.936: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:40:55.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5372" for this suite.
Sep  6 15:41:01.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:41:01.116: INFO: namespace init-container-5372 deletion completed in 6.066159439s

• [SLOW TEST:9.200 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:41:01.116: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-wtr8
STEP: Creating a pod to test atomic-volume-subpath
Sep  6 15:41:01.145: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-wtr8" in namespace "subpath-9956" to be "success or failure"
Sep  6 15:41:01.149: INFO: Pod "pod-subpath-test-projected-wtr8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.898031ms
Sep  6 15:41:03.152: INFO: Pod "pod-subpath-test-projected-wtr8": Phase="Running", Reason="", readiness=true. Elapsed: 2.006806565s
Sep  6 15:41:05.155: INFO: Pod "pod-subpath-test-projected-wtr8": Phase="Running", Reason="", readiness=true. Elapsed: 4.009765229s
Sep  6 15:41:07.158: INFO: Pod "pod-subpath-test-projected-wtr8": Phase="Running", Reason="", readiness=true. Elapsed: 6.012820664s
Sep  6 15:41:09.161: INFO: Pod "pod-subpath-test-projected-wtr8": Phase="Running", Reason="", readiness=true. Elapsed: 8.015934792s
Sep  6 15:41:11.164: INFO: Pod "pod-subpath-test-projected-wtr8": Phase="Running", Reason="", readiness=true. Elapsed: 10.018940351s
Sep  6 15:41:13.167: INFO: Pod "pod-subpath-test-projected-wtr8": Phase="Running", Reason="", readiness=true. Elapsed: 12.022006465s
Sep  6 15:41:15.170: INFO: Pod "pod-subpath-test-projected-wtr8": Phase="Running", Reason="", readiness=true. Elapsed: 14.025141934s
Sep  6 15:41:17.174: INFO: Pod "pod-subpath-test-projected-wtr8": Phase="Running", Reason="", readiness=true. Elapsed: 16.028266597s
Sep  6 15:41:19.178: INFO: Pod "pod-subpath-test-projected-wtr8": Phase="Running", Reason="", readiness=true. Elapsed: 18.032952552s
Sep  6 15:41:21.181: INFO: Pod "pod-subpath-test-projected-wtr8": Phase="Running", Reason="", readiness=true. Elapsed: 20.036132652s
Sep  6 15:41:23.184: INFO: Pod "pod-subpath-test-projected-wtr8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.038868147s
STEP: Saw pod success
Sep  6 15:41:23.184: INFO: Pod "pod-subpath-test-projected-wtr8" satisfied condition "success or failure"
Sep  6 15:41:23.186: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-subpath-test-projected-wtr8 container test-container-subpath-projected-wtr8: <nil>
STEP: delete the pod
Sep  6 15:41:23.203: INFO: Waiting for pod pod-subpath-test-projected-wtr8 to disappear
Sep  6 15:41:23.214: INFO: Pod pod-subpath-test-projected-wtr8 no longer exists
STEP: Deleting pod pod-subpath-test-projected-wtr8
Sep  6 15:41:23.214: INFO: Deleting pod "pod-subpath-test-projected-wtr8" in namespace "subpath-9956"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:41:23.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9956" for this suite.
Sep  6 15:41:29.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:41:29.300: INFO: namespace subpath-9956 deletion completed in 6.07918254s

• [SLOW TEST:28.184 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:41:29.301: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:41:35.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3868" for this suite.
Sep  6 15:41:41.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:41:41.460: INFO: namespace namespaces-3868 deletion completed in 6.077134076s
STEP: Destroying namespace "nsdeletetest-8408" for this suite.
Sep  6 15:41:41.461: INFO: Namespace nsdeletetest-8408 was already deleted
STEP: Destroying namespace "nsdeletetest-1645" for this suite.
Sep  6 15:41:47.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:41:47.526: INFO: namespace nsdeletetest-1645 deletion completed in 6.064551885s

• [SLOW TEST:18.225 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:41:47.526: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-3540
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  6 15:41:47.547: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  6 15:42:05.607: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.2.33:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3540 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 15:42:05.607: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 15:42:05.701: INFO: Found all expected endpoints: [netserver-0]
Sep  6 15:42:05.704: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.1.25:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3540 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 15:42:05.704: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 15:42:05.793: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:42:05.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3540" for this suite.
Sep  6 15:42:21.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:42:21.859: INFO: namespace pod-network-test-3540 deletion completed in 16.062936918s

• [SLOW TEST:34.333 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:42:21.859: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep  6 15:42:21.883: INFO: Waiting up to 5m0s for pod "pod-ea891436-d0bc-11e9-a08c-82ce3d77f2cb" in namespace "emptydir-714" to be "success or failure"
Sep  6 15:42:21.886: INFO: Pod "pod-ea891436-d0bc-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.63379ms
Sep  6 15:42:23.889: INFO: Pod "pod-ea891436-d0bc-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006773518s
STEP: Saw pod success
Sep  6 15:42:23.889: INFO: Pod "pod-ea891436-d0bc-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:42:23.892: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-ea891436-d0bc-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 15:42:23.906: INFO: Waiting for pod pod-ea891436-d0bc-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:42:23.908: INFO: Pod pod-ea891436-d0bc-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:42:23.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-714" for this suite.
Sep  6 15:42:29.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:42:29.972: INFO: namespace emptydir-714 deletion completed in 6.061126926s

• [SLOW TEST:8.112 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:42:29.972: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-ef5ed873-d0bc-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume secrets
Sep  6 15:42:30.003: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ef5f3cdc-d0bc-11e9-a08c-82ce3d77f2cb" in namespace "projected-5578" to be "success or failure"
Sep  6 15:42:30.009: INFO: Pod "pod-projected-secrets-ef5f3cdc-d0bc-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.585805ms
Sep  6 15:42:32.012: INFO: Pod "pod-projected-secrets-ef5f3cdc-d0bc-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009663673s
STEP: Saw pod success
Sep  6 15:42:32.012: INFO: Pod "pod-projected-secrets-ef5f3cdc-d0bc-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:42:32.014: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-projected-secrets-ef5f3cdc-d0bc-11e9-a08c-82ce3d77f2cb container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  6 15:42:32.026: INFO: Waiting for pod pod-projected-secrets-ef5f3cdc-d0bc-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:42:32.029: INFO: Pod pod-projected-secrets-ef5f3cdc-d0bc-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:42:32.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5578" for this suite.
Sep  6 15:42:38.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:42:38.094: INFO: namespace projected-5578 deletion completed in 6.062922221s

• [SLOW TEST:8.122 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:42:38.094: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-f436d2a9-d0bc-11e9-a08c-82ce3d77f2cb
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-f436d2a9-d0bc-11e9-a08c-82ce3d77f2cb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:42:44.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6495" for this suite.
Sep  6 15:43:06.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:43:06.236: INFO: namespace projected-6495 deletion completed in 22.078296238s

• [SLOW TEST:28.143 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:43:06.237: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-04fc9cae-d0bd-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume configMaps
Sep  6 15:43:06.265: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-04fcfd95-d0bd-11e9-a08c-82ce3d77f2cb" in namespace "projected-3164" to be "success or failure"
Sep  6 15:43:06.269: INFO: Pod "pod-projected-configmaps-04fcfd95-d0bd-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.308289ms
Sep  6 15:43:08.272: INFO: Pod "pod-projected-configmaps-04fcfd95-d0bd-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007377471s
STEP: Saw pod success
Sep  6 15:43:08.272: INFO: Pod "pod-projected-configmaps-04fcfd95-d0bd-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:43:08.280: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-projected-configmaps-04fcfd95-d0bd-11e9-a08c-82ce3d77f2cb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 15:43:08.292: INFO: Waiting for pod pod-projected-configmaps-04fcfd95-d0bd-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:43:08.294: INFO: Pod pod-projected-configmaps-04fcfd95-d0bd-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:43:08.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3164" for this suite.
Sep  6 15:43:14.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:43:14.360: INFO: namespace projected-3164 deletion completed in 6.063776291s

• [SLOW TEST:8.124 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:43:14.361: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 15:43:14.385: INFO: (0) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.770612ms)
Sep  6 15:43:14.387: INFO: (1) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.667465ms)
Sep  6 15:43:14.390: INFO: (2) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.595673ms)
Sep  6 15:43:14.393: INFO: (3) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.492579ms)
Sep  6 15:43:14.397: INFO: (4) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.33769ms)
Sep  6 15:43:14.400: INFO: (5) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.845276ms)
Sep  6 15:43:14.402: INFO: (6) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.655183ms)
Sep  6 15:43:14.405: INFO: (7) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.286707ms)
Sep  6 15:43:14.408: INFO: (8) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.652667ms)
Sep  6 15:43:14.411: INFO: (9) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.333859ms)
Sep  6 15:43:14.413: INFO: (10) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.47623ms)
Sep  6 15:43:14.423: INFO: (11) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.767472ms)
Sep  6 15:43:14.432: INFO: (12) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.982641ms)
Sep  6 15:43:14.444: INFO: (13) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 11.736175ms)
Sep  6 15:43:14.447: INFO: (14) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.200155ms)
Sep  6 15:43:14.454: INFO: (15) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.590702ms)
Sep  6 15:43:14.460: INFO: (16) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.332996ms)
Sep  6 15:43:14.466: INFO: (17) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.339946ms)
Sep  6 15:43:14.469: INFO: (18) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.839137ms)
Sep  6 15:43:14.473: INFO: (19) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.631037ms)
[AfterEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:43:14.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2434" for this suite.
Sep  6 15:43:20.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:43:20.547: INFO: namespace proxy-2434 deletion completed in 6.071421174s

• [SLOW TEST:6.187 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:43:20.547: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-0d84456e-d0bd-11e9-a08c-82ce3d77f2cb
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:43:20.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9604" for this suite.
Sep  6 15:43:26.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:43:26.633: INFO: namespace configmap-9604 deletion completed in 6.062336032s

• [SLOW TEST:6.086 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:43:26.634: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep  6 15:43:29.174: INFO: Successfully updated pod "pod-update-11251d9c-d0bd-11e9-a08c-82ce3d77f2cb"
STEP: verifying the updated pod is in kubernetes
Sep  6 15:43:29.178: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:43:29.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4106" for this suite.
Sep  6 15:43:51.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:43:51.249: INFO: namespace pods-4106 deletion completed in 22.069037666s

• [SLOW TEST:24.615 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:43:51.249: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:43:53.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4862" for this suite.
Sep  6 15:44:43.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:44:43.352: INFO: namespace kubelet-test-4862 deletion completed in 50.063624963s

• [SLOW TEST:52.103 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:44:43.352: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-3edf3786-d0bd-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume secrets
Sep  6 15:44:43.378: INFO: Waiting up to 5m0s for pod "pod-secrets-3edf8a15-d0bd-11e9-a08c-82ce3d77f2cb" in namespace "secrets-2332" to be "success or failure"
Sep  6 15:44:43.381: INFO: Pod "pod-secrets-3edf8a15-d0bd-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.899133ms
Sep  6 15:44:45.385: INFO: Pod "pod-secrets-3edf8a15-d0bd-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006228861s
STEP: Saw pod success
Sep  6 15:44:45.385: INFO: Pod "pod-secrets-3edf8a15-d0bd-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:44:45.386: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-secrets-3edf8a15-d0bd-11e9-a08c-82ce3d77f2cb container secret-volume-test: <nil>
STEP: delete the pod
Sep  6 15:44:45.400: INFO: Waiting for pod pod-secrets-3edf8a15-d0bd-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:44:45.402: INFO: Pod pod-secrets-3edf8a15-d0bd-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:44:45.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2332" for this suite.
Sep  6 15:44:51.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:44:51.472: INFO: namespace secrets-2332 deletion completed in 6.067384597s

• [SLOW TEST:8.120 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:44:51.472: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-5j2kt in namespace proxy-8308
I0906 15:44:51.504152      15 runners.go:184] Created replication controller with name: proxy-service-5j2kt, namespace: proxy-8308, replica count: 1
I0906 15:44:52.554740      15 runners.go:184] proxy-service-5j2kt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0906 15:44:53.554996      15 runners.go:184] proxy-service-5j2kt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0906 15:44:54.555184      15 runners.go:184] proxy-service-5j2kt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0906 15:44:55.555505      15 runners.go:184] proxy-service-5j2kt Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  6 15:44:55.558: INFO: setup took 4.065754683s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep  6 15:44:55.578: INFO: (0) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 20.324517ms)
Sep  6 15:44:55.578: INFO: (0) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 20.753263ms)
Sep  6 15:44:55.578: INFO: (0) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 20.516458ms)
Sep  6 15:44:55.579: INFO: (0) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 20.578079ms)
Sep  6 15:44:55.583: INFO: (0) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 25.434721ms)
Sep  6 15:44:55.583: INFO: (0) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 25.337576ms)
Sep  6 15:44:55.583: INFO: (0) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 25.775548ms)
Sep  6 15:44:55.584: INFO: (0) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 25.855448ms)
Sep  6 15:44:55.587: INFO: (0) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 28.94118ms)
Sep  6 15:44:55.587: INFO: (0) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 29.313071ms)
Sep  6 15:44:55.587: INFO: (0) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 29.303841ms)
Sep  6 15:44:55.592: INFO: (0) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 34.160675ms)
Sep  6 15:44:55.596: INFO: (0) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 38.333708ms)
Sep  6 15:44:55.597: INFO: (0) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 38.739659ms)
Sep  6 15:44:55.597: INFO: (0) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 38.642463ms)
Sep  6 15:44:55.600: INFO: (0) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 42.11968ms)
Sep  6 15:44:55.607: INFO: (1) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 7.405209ms)
Sep  6 15:44:55.608: INFO: (1) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 7.773839ms)
Sep  6 15:44:55.608: INFO: (1) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 7.747194ms)
Sep  6 15:44:55.609: INFO: (1) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 9.043112ms)
Sep  6 15:44:55.610: INFO: (1) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 9.356267ms)
Sep  6 15:44:55.610: INFO: (1) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 9.713279ms)
Sep  6 15:44:55.610: INFO: (1) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 10.205879ms)
Sep  6 15:44:55.611: INFO: (1) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 10.53212ms)
Sep  6 15:44:55.611: INFO: (1) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 10.469115ms)
Sep  6 15:44:55.611: INFO: (1) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 10.623159ms)
Sep  6 15:44:55.612: INFO: (1) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 12.139924ms)
Sep  6 15:44:55.613: INFO: (1) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 12.395554ms)
Sep  6 15:44:55.613: INFO: (1) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 12.865272ms)
Sep  6 15:44:55.613: INFO: (1) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 12.979316ms)
Sep  6 15:44:55.614: INFO: (1) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 13.075356ms)
Sep  6 15:44:55.616: INFO: (1) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 15.479155ms)
Sep  6 15:44:55.623: INFO: (2) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 7.403766ms)
Sep  6 15:44:55.624: INFO: (2) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 7.376773ms)
Sep  6 15:44:55.624: INFO: (2) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 7.598921ms)
Sep  6 15:44:55.624: INFO: (2) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 8.495205ms)
Sep  6 15:44:55.624: INFO: (2) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 8.055911ms)
Sep  6 15:44:55.625: INFO: (2) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 9.268785ms)
Sep  6 15:44:55.626: INFO: (2) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 8.992619ms)
Sep  6 15:44:55.626: INFO: (2) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 10.344319ms)
Sep  6 15:44:55.627: INFO: (2) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 9.926114ms)
Sep  6 15:44:55.627: INFO: (2) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 11.011826ms)
Sep  6 15:44:55.627: INFO: (2) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 10.944785ms)
Sep  6 15:44:55.628: INFO: (2) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 10.956233ms)
Sep  6 15:44:55.629: INFO: (2) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 12.39144ms)
Sep  6 15:44:55.629: INFO: (2) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 13.158689ms)
Sep  6 15:44:55.629: INFO: (2) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 12.793925ms)
Sep  6 15:44:55.629: INFO: (2) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 13.389997ms)
Sep  6 15:44:55.638: INFO: (3) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 8.173094ms)
Sep  6 15:44:55.639: INFO: (3) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 9.257617ms)
Sep  6 15:44:55.640: INFO: (3) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 9.965623ms)
Sep  6 15:44:55.641: INFO: (3) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 11.076384ms)
Sep  6 15:44:55.641: INFO: (3) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 10.743328ms)
Sep  6 15:44:55.641: INFO: (3) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 11.017428ms)
Sep  6 15:44:55.641: INFO: (3) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 11.283185ms)
Sep  6 15:44:55.642: INFO: (3) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 11.398568ms)
Sep  6 15:44:55.642: INFO: (3) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 11.963061ms)
Sep  6 15:44:55.642: INFO: (3) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 12.085004ms)
Sep  6 15:44:55.642: INFO: (3) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 12.043042ms)
Sep  6 15:44:55.644: INFO: (3) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 13.99234ms)
Sep  6 15:44:55.644: INFO: (3) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 14.214389ms)
Sep  6 15:44:55.644: INFO: (3) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 14.551087ms)
Sep  6 15:44:55.644: INFO: (3) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 14.063401ms)
Sep  6 15:44:55.645: INFO: (3) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 14.253892ms)
Sep  6 15:44:55.653: INFO: (4) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 8.563409ms)
Sep  6 15:44:55.654: INFO: (4) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 8.734062ms)
Sep  6 15:44:55.654: INFO: (4) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 8.711688ms)
Sep  6 15:44:55.657: INFO: (4) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 12.042886ms)
Sep  6 15:44:55.657: INFO: (4) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 12.503169ms)
Sep  6 15:44:55.658: INFO: (4) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 12.56364ms)
Sep  6 15:44:55.658: INFO: (4) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 12.931721ms)
Sep  6 15:44:55.658: INFO: (4) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 13.080328ms)
Sep  6 15:44:55.658: INFO: (4) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 13.474488ms)
Sep  6 15:44:55.658: INFO: (4) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 13.321542ms)
Sep  6 15:44:55.658: INFO: (4) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 13.342215ms)
Sep  6 15:44:55.659: INFO: (4) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 13.905535ms)
Sep  6 15:44:55.659: INFO: (4) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 13.739305ms)
Sep  6 15:44:55.659: INFO: (4) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 13.764428ms)
Sep  6 15:44:55.659: INFO: (4) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 14.027339ms)
Sep  6 15:44:55.660: INFO: (4) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 14.520203ms)
Sep  6 15:44:55.665: INFO: (5) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 5.613718ms)
Sep  6 15:44:55.666: INFO: (5) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 5.786383ms)
Sep  6 15:44:55.670: INFO: (5) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 10.464364ms)
Sep  6 15:44:55.671: INFO: (5) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 10.933375ms)
Sep  6 15:44:55.672: INFO: (5) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 11.968328ms)
Sep  6 15:44:55.673: INFO: (5) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 12.297623ms)
Sep  6 15:44:55.673: INFO: (5) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 12.220719ms)
Sep  6 15:44:55.673: INFO: (5) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 13.008151ms)
Sep  6 15:44:55.673: INFO: (5) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 12.586215ms)
Sep  6 15:44:55.674: INFO: (5) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 13.099205ms)
Sep  6 15:44:55.674: INFO: (5) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 13.228833ms)
Sep  6 15:44:55.674: INFO: (5) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 14.431502ms)
Sep  6 15:44:55.674: INFO: (5) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 14.055497ms)
Sep  6 15:44:55.675: INFO: (5) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 14.528294ms)
Sep  6 15:44:55.675: INFO: (5) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 14.780633ms)
Sep  6 15:44:55.675: INFO: (5) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 14.20612ms)
Sep  6 15:44:55.683: INFO: (6) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 8.325027ms)
Sep  6 15:44:55.684: INFO: (6) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 8.135543ms)
Sep  6 15:44:55.684: INFO: (6) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 8.56444ms)
Sep  6 15:44:55.684: INFO: (6) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 8.971711ms)
Sep  6 15:44:55.684: INFO: (6) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 8.764361ms)
Sep  6 15:44:55.684: INFO: (6) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 9.080012ms)
Sep  6 15:44:55.685: INFO: (6) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 9.072326ms)
Sep  6 15:44:55.685: INFO: (6) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 9.108174ms)
Sep  6 15:44:55.687: INFO: (6) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 12.021809ms)
Sep  6 15:44:55.687: INFO: (6) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 12.11975ms)
Sep  6 15:44:55.688: INFO: (6) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 12.554398ms)
Sep  6 15:44:55.688: INFO: (6) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 12.265927ms)
Sep  6 15:44:55.688: INFO: (6) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 12.719928ms)
Sep  6 15:44:55.688: INFO: (6) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 12.992036ms)
Sep  6 15:44:55.689: INFO: (6) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 12.985946ms)
Sep  6 15:44:55.689: INFO: (6) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 14.086167ms)
Sep  6 15:44:55.696: INFO: (7) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 6.183107ms)
Sep  6 15:44:55.696: INFO: (7) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 6.209704ms)
Sep  6 15:44:55.699: INFO: (7) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 8.859837ms)
Sep  6 15:44:55.699: INFO: (7) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 9.11569ms)
Sep  6 15:44:55.699: INFO: (7) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 9.810238ms)
Sep  6 15:44:55.700: INFO: (7) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 9.866503ms)
Sep  6 15:44:55.700: INFO: (7) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 10.057473ms)
Sep  6 15:44:55.700: INFO: (7) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 10.055502ms)
Sep  6 15:44:55.701: INFO: (7) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 10.629097ms)
Sep  6 15:44:55.702: INFO: (7) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 11.370197ms)
Sep  6 15:44:55.702: INFO: (7) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 12.13778ms)
Sep  6 15:44:55.702: INFO: (7) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 12.1141ms)
Sep  6 15:44:55.702: INFO: (7) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 11.790098ms)
Sep  6 15:44:55.702: INFO: (7) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 12.035027ms)
Sep  6 15:44:55.703: INFO: (7) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 12.592199ms)
Sep  6 15:44:55.703: INFO: (7) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 12.979727ms)
Sep  6 15:44:55.708: INFO: (8) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 4.170618ms)
Sep  6 15:44:55.713: INFO: (8) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 8.909116ms)
Sep  6 15:44:55.715: INFO: (8) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 11.644285ms)
Sep  6 15:44:55.716: INFO: (8) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 11.801735ms)
Sep  6 15:44:55.716: INFO: (8) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 11.875027ms)
Sep  6 15:44:55.717: INFO: (8) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 12.840271ms)
Sep  6 15:44:55.717: INFO: (8) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 13.402531ms)
Sep  6 15:44:55.717: INFO: (8) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 13.496896ms)
Sep  6 15:44:55.717: INFO: (8) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 13.503546ms)
Sep  6 15:44:55.717: INFO: (8) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 13.517389ms)
Sep  6 15:44:55.718: INFO: (8) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 14.108003ms)
Sep  6 15:44:55.718: INFO: (8) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 14.35095ms)
Sep  6 15:44:55.718: INFO: (8) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 14.702333ms)
Sep  6 15:44:55.719: INFO: (8) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 15.02433ms)
Sep  6 15:44:55.719: INFO: (8) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 14.830873ms)
Sep  6 15:44:55.719: INFO: (8) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 15.03711ms)
Sep  6 15:44:55.724: INFO: (9) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 5.055397ms)
Sep  6 15:44:55.724: INFO: (9) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 5.335414ms)
Sep  6 15:44:55.726: INFO: (9) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 6.961525ms)
Sep  6 15:44:55.726: INFO: (9) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 7.50816ms)
Sep  6 15:44:55.727: INFO: (9) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 7.86587ms)
Sep  6 15:44:55.728: INFO: (9) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 8.646522ms)
Sep  6 15:44:55.728: INFO: (9) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 9.035595ms)
Sep  6 15:44:55.728: INFO: (9) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 8.788817ms)
Sep  6 15:44:55.728: INFO: (9) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 8.968509ms)
Sep  6 15:44:55.728: INFO: (9) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 9.30776ms)
Sep  6 15:44:55.731: INFO: (9) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 11.992734ms)
Sep  6 15:44:55.731: INFO: (9) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 12.005709ms)
Sep  6 15:44:55.731: INFO: (9) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 12.127595ms)
Sep  6 15:44:55.731: INFO: (9) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 12.177654ms)
Sep  6 15:44:55.731: INFO: (9) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 12.024235ms)
Sep  6 15:44:55.732: INFO: (9) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 12.622669ms)
Sep  6 15:44:55.737: INFO: (10) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 4.858236ms)
Sep  6 15:44:55.745: INFO: (10) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 12.308698ms)
Sep  6 15:44:55.745: INFO: (10) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 12.95279ms)
Sep  6 15:44:55.745: INFO: (10) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 13.307975ms)
Sep  6 15:44:55.746: INFO: (10) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 13.906313ms)
Sep  6 15:44:55.746: INFO: (10) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 13.585585ms)
Sep  6 15:44:55.746: INFO: (10) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 13.719843ms)
Sep  6 15:44:55.746: INFO: (10) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 14.193323ms)
Sep  6 15:44:55.746: INFO: (10) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 14.636081ms)
Sep  6 15:44:55.751: INFO: (10) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 18.920612ms)
Sep  6 15:44:55.751: INFO: (10) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 19.282543ms)
Sep  6 15:44:55.752: INFO: (10) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 19.438792ms)
Sep  6 15:44:55.752: INFO: (10) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 19.796237ms)
Sep  6 15:44:55.752: INFO: (10) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 19.540094ms)
Sep  6 15:44:55.753: INFO: (10) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 20.597057ms)
Sep  6 15:44:55.753: INFO: (10) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 20.655073ms)
Sep  6 15:44:55.758: INFO: (11) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 4.780562ms)
Sep  6 15:44:55.763: INFO: (11) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 10.049704ms)
Sep  6 15:44:55.764: INFO: (11) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 10.402904ms)
Sep  6 15:44:55.764: INFO: (11) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 10.585046ms)
Sep  6 15:44:55.764: INFO: (11) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 10.700646ms)
Sep  6 15:44:55.765: INFO: (11) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 11.517351ms)
Sep  6 15:44:55.765: INFO: (11) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 11.887357ms)
Sep  6 15:44:55.765: INFO: (11) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 11.856112ms)
Sep  6 15:44:55.766: INFO: (11) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 12.594349ms)
Sep  6 15:44:55.766: INFO: (11) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 12.600004ms)
Sep  6 15:44:55.766: INFO: (11) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 12.518016ms)
Sep  6 15:44:55.766: INFO: (11) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 12.940592ms)
Sep  6 15:44:55.766: INFO: (11) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 12.86766ms)
Sep  6 15:44:55.766: INFO: (11) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 12.974331ms)
Sep  6 15:44:55.766: INFO: (11) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 13.389622ms)
Sep  6 15:44:55.766: INFO: (11) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 13.215579ms)
Sep  6 15:44:55.773: INFO: (12) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 6.22943ms)
Sep  6 15:44:55.773: INFO: (12) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 6.645454ms)
Sep  6 15:44:55.774: INFO: (12) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 7.149502ms)
Sep  6 15:44:55.775: INFO: (12) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 7.931834ms)
Sep  6 15:44:55.775: INFO: (12) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 8.337116ms)
Sep  6 15:44:55.775: INFO: (12) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 8.50418ms)
Sep  6 15:44:55.777: INFO: (12) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 10.485869ms)
Sep  6 15:44:55.779: INFO: (12) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 12.048476ms)
Sep  6 15:44:55.779: INFO: (12) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 12.210427ms)
Sep  6 15:44:55.779: INFO: (12) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 12.896289ms)
Sep  6 15:44:55.779: INFO: (12) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 12.361999ms)
Sep  6 15:44:55.780: INFO: (12) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 12.987354ms)
Sep  6 15:44:55.780: INFO: (12) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 12.83553ms)
Sep  6 15:44:55.780: INFO: (12) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 12.854098ms)
Sep  6 15:44:55.780: INFO: (12) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 13.042944ms)
Sep  6 15:44:55.780: INFO: (12) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 13.007407ms)
Sep  6 15:44:55.789: INFO: (13) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 8.121905ms)
Sep  6 15:44:55.789: INFO: (13) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 8.342653ms)
Sep  6 15:44:55.789: INFO: (13) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 8.775173ms)
Sep  6 15:44:55.789: INFO: (13) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 8.718423ms)
Sep  6 15:44:55.789: INFO: (13) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 9.126992ms)
Sep  6 15:44:55.789: INFO: (13) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 9.258407ms)
Sep  6 15:44:55.790: INFO: (13) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 9.467888ms)
Sep  6 15:44:55.790: INFO: (13) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 9.160305ms)
Sep  6 15:44:55.790: INFO: (13) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 9.236629ms)
Sep  6 15:44:55.790: INFO: (13) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 9.616474ms)
Sep  6 15:44:55.792: INFO: (13) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 11.585824ms)
Sep  6 15:44:55.792: INFO: (13) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 11.735492ms)
Sep  6 15:44:55.792: INFO: (13) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 11.617168ms)
Sep  6 15:44:55.792: INFO: (13) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 12.179285ms)
Sep  6 15:44:55.793: INFO: (13) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 12.048147ms)
Sep  6 15:44:55.793: INFO: (13) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 12.362822ms)
Sep  6 15:44:55.798: INFO: (14) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 5.260026ms)
Sep  6 15:44:55.799: INFO: (14) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 6.282ms)
Sep  6 15:44:55.799: INFO: (14) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 6.415424ms)
Sep  6 15:44:55.800: INFO: (14) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 5.772458ms)
Sep  6 15:44:55.800: INFO: (14) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 6.315929ms)
Sep  6 15:44:55.800: INFO: (14) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 6.51188ms)
Sep  6 15:44:55.802: INFO: (14) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 8.468876ms)
Sep  6 15:44:55.802: INFO: (14) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 9.004692ms)
Sep  6 15:44:55.802: INFO: (14) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 9.064973ms)
Sep  6 15:44:55.802: INFO: (14) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 9.527062ms)
Sep  6 15:44:55.803: INFO: (14) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 9.592162ms)
Sep  6 15:44:55.805: INFO: (14) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 11.362969ms)
Sep  6 15:44:55.805: INFO: (14) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 11.514927ms)
Sep  6 15:44:55.806: INFO: (14) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 12.35725ms)
Sep  6 15:44:55.806: INFO: (14) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 12.967718ms)
Sep  6 15:44:55.806: INFO: (14) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 12.470339ms)
Sep  6 15:44:55.811: INFO: (15) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 4.602951ms)
Sep  6 15:44:55.811: INFO: (15) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 4.350562ms)
Sep  6 15:44:55.814: INFO: (15) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 6.356523ms)
Sep  6 15:44:55.814: INFO: (15) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 7.440947ms)
Sep  6 15:44:55.815: INFO: (15) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 8.087723ms)
Sep  6 15:44:55.815: INFO: (15) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 8.034546ms)
Sep  6 15:44:55.815: INFO: (15) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 9.11916ms)
Sep  6 15:44:55.816: INFO: (15) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 9.022474ms)
Sep  6 15:44:55.816: INFO: (15) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 9.723969ms)
Sep  6 15:44:55.816: INFO: (15) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 9.563242ms)
Sep  6 15:44:55.819: INFO: (15) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 11.770836ms)
Sep  6 15:44:55.820: INFO: (15) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 12.591527ms)
Sep  6 15:44:55.820: INFO: (15) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 12.613182ms)
Sep  6 15:44:55.820: INFO: (15) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 13.703051ms)
Sep  6 15:44:55.820: INFO: (15) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 13.560998ms)
Sep  6 15:44:55.820: INFO: (15) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 14.033563ms)
Sep  6 15:44:55.831: INFO: (16) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 9.834945ms)
Sep  6 15:44:55.831: INFO: (16) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 9.972141ms)
Sep  6 15:44:55.831: INFO: (16) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 9.954208ms)
Sep  6 15:44:55.832: INFO: (16) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 11.115059ms)
Sep  6 15:44:55.831: INFO: (16) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 10.759866ms)
Sep  6 15:44:55.831: INFO: (16) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 11.136968ms)
Sep  6 15:44:55.832: INFO: (16) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 11.279785ms)
Sep  6 15:44:55.832: INFO: (16) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 10.947566ms)
Sep  6 15:44:55.834: INFO: (16) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 13.098276ms)
Sep  6 15:44:55.835: INFO: (16) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 13.460946ms)
Sep  6 15:44:55.835: INFO: (16) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 14.229168ms)
Sep  6 15:44:55.835: INFO: (16) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 14.637947ms)
Sep  6 15:44:55.835: INFO: (16) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 14.414547ms)
Sep  6 15:44:55.835: INFO: (16) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 14.17842ms)
Sep  6 15:44:55.835: INFO: (16) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 13.84978ms)
Sep  6 15:44:55.836: INFO: (16) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 14.942292ms)
Sep  6 15:44:55.841: INFO: (17) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 4.749933ms)
Sep  6 15:44:55.842: INFO: (17) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 5.263954ms)
Sep  6 15:44:55.846: INFO: (17) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 8.637594ms)
Sep  6 15:44:55.846: INFO: (17) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 9.047699ms)
Sep  6 15:44:55.847: INFO: (17) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 9.437428ms)
Sep  6 15:44:55.847: INFO: (17) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 9.37288ms)
Sep  6 15:44:55.847: INFO: (17) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 9.436628ms)
Sep  6 15:44:55.847: INFO: (17) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 10.489421ms)
Sep  6 15:44:55.847: INFO: (17) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 10.707591ms)
Sep  6 15:44:55.847: INFO: (17) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 10.409528ms)
Sep  6 15:44:55.847: INFO: (17) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 10.308453ms)
Sep  6 15:44:55.847: INFO: (17) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 10.341915ms)
Sep  6 15:44:55.848: INFO: (17) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 11.249861ms)
Sep  6 15:44:55.849: INFO: (17) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 11.141367ms)
Sep  6 15:44:55.849: INFO: (17) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 11.830571ms)
Sep  6 15:44:55.849: INFO: (17) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 11.944927ms)
Sep  6 15:44:55.859: INFO: (18) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 9.466928ms)
Sep  6 15:44:55.859: INFO: (18) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 10.160852ms)
Sep  6 15:44:55.860: INFO: (18) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 10.558088ms)
Sep  6 15:44:55.860: INFO: (18) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 10.660757ms)
Sep  6 15:44:55.860: INFO: (18) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 10.289703ms)
Sep  6 15:44:55.860: INFO: (18) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 11.223646ms)
Sep  6 15:44:55.860: INFO: (18) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 10.061734ms)
Sep  6 15:44:55.860: INFO: (18) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 10.647733ms)
Sep  6 15:44:55.860: INFO: (18) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 11.215806ms)
Sep  6 15:44:55.861: INFO: (18) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 10.92634ms)
Sep  6 15:44:55.861: INFO: (18) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 11.134068ms)
Sep  6 15:44:55.862: INFO: (18) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 12.700267ms)
Sep  6 15:44:55.863: INFO: (18) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 13.20749ms)
Sep  6 15:44:55.863: INFO: (18) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 13.898667ms)
Sep  6 15:44:55.863: INFO: (18) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 13.742696ms)
Sep  6 15:44:55.863: INFO: (18) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 14.050072ms)
Sep  6 15:44:55.871: INFO: (19) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 7.171615ms)
Sep  6 15:44:55.871: INFO: (19) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:162/proxy/: bar (200; 7.577507ms)
Sep  6 15:44:55.871: INFO: (19) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 7.612321ms)
Sep  6 15:44:55.872: INFO: (19) /api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/http:proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">... (200; 8.065551ms)
Sep  6 15:44:55.872: INFO: (19) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:460/proxy/: tls baz (200; 8.612142ms)
Sep  6 15:44:55.872: INFO: (19) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:1080/proxy/rewriteme">test<... (200; 8.686547ms)
Sep  6 15:44:55.876: INFO: (19) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:462/proxy/: tls qux (200; 12.409406ms)
Sep  6 15:44:55.877: INFO: (19) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname2/proxy/: bar (200; 12.866608ms)
Sep  6 15:44:55.877: INFO: (19) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname1/proxy/: foo (200; 13.327981ms)
Sep  6 15:44:55.877: INFO: (19) /api/v1/namespaces/proxy-8308/services/http:proxy-service-5j2kt:portname1/proxy/: foo (200; 13.482704ms)
Sep  6 15:44:55.877: INFO: (19) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn/proxy/rewriteme">test</a> (200; 13.668277ms)
Sep  6 15:44:55.878: INFO: (19) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname1/proxy/: tls baz (200; 13.803326ms)
Sep  6 15:44:55.878: INFO: (19) /api/v1/namespaces/proxy-8308/services/https:proxy-service-5j2kt:tlsportname2/proxy/: tls qux (200; 14.113741ms)
Sep  6 15:44:55.878: INFO: (19) /api/v1/namespaces/proxy-8308/services/proxy-service-5j2kt:portname2/proxy/: bar (200; 13.931539ms)
Sep  6 15:44:55.878: INFO: (19) /api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/: <a href="/api/v1/namespaces/proxy-8308/pods/https:proxy-service-5j2kt-tdlkn:443/proxy/tlsrewritem... (200; 13.866527ms)
Sep  6 15:44:55.878: INFO: (19) /api/v1/namespaces/proxy-8308/pods/proxy-service-5j2kt-tdlkn:160/proxy/: foo (200; 14.137968ms)
STEP: deleting ReplicationController proxy-service-5j2kt in namespace proxy-8308, will wait for the garbage collector to delete the pods
Sep  6 15:44:55.934: INFO: Deleting ReplicationController proxy-service-5j2kt took: 3.749367ms
Sep  6 15:44:56.234: INFO: Terminating ReplicationController proxy-service-5j2kt pods took: 300.478132ms
[AfterEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:44:57.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8308" for this suite.
Sep  6 15:45:03.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:45:03.892: INFO: namespace proxy-8308 deletion completed in 6.254337945s

• [SLOW TEST:12.420 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:45:03.892: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 15:45:03.915: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep  6 15:45:03.922: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep  6 15:45:08.933: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  6 15:45:08.933: INFO: Creating deployment "test-rolling-update-deployment"
Sep  6 15:45:08.938: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep  6 15:45:08.949: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep  6 15:45:10.962: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep  6 15:45:10.968: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  6 15:45:10.973: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-7848,SelfLink:/apis/apps/v1/namespaces/deployment-7848/deployments/test-rolling-update-deployment,UID:4e19b99d-d0bd-11e9-8afa-02e25174ea0a,ResourceVersion:3608,Generation:1,CreationTimestamp:2019-09-06 15:45:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-06 15:45:08 +0000 UTC 2019-09-06 15:45:08 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-06 15:45:10 +0000 UTC 2019-09-06 15:45:08 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-57b6b5bb54" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  6 15:45:10.975: INFO: New ReplicaSet "test-rolling-update-deployment-57b6b5bb54" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54,GenerateName:,Namespace:deployment-7848,SelfLink:/apis/apps/v1/namespaces/deployment-7848/replicasets/test-rolling-update-deployment-57b6b5bb54,UID:4e1b2402-d0bd-11e9-8afa-02e25174ea0a,ResourceVersion:3601,Generation:1,CreationTimestamp:2019-09-06 15:45:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 4e19b99d-d0bd-11e9-8afa-02e25174ea0a 0xc0025a2dd7 0xc0025a2dd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  6 15:45:10.975: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep  6 15:45:10.975: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-7848,SelfLink:/apis/apps/v1/namespaces/deployment-7848/replicasets/test-rolling-update-controller,UID:4b1bc367-d0bd-11e9-8afa-02e25174ea0a,ResourceVersion:3607,Generation:2,CreationTimestamp:2019-09-06 15:45:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 4e19b99d-d0bd-11e9-8afa-02e25174ea0a 0xc0025a2d17 0xc0025a2d18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  6 15:45:10.978: INFO: Pod "test-rolling-update-deployment-57b6b5bb54-jvhpt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54-jvhpt,GenerateName:test-rolling-update-deployment-57b6b5bb54-,Namespace:deployment-7848,SelfLink:/api/v1/namespaces/deployment-7848/pods/test-rolling-update-deployment-57b6b5bb54-jvhpt,UID:4e1bc1cc-d0bd-11e9-8afa-02e25174ea0a,ResourceVersion:3600,Generation:0,CreationTimestamp:2019-09-06 15:45:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-57b6b5bb54 4e1b2402-d0bd-11e9-8afa-02e25174ea0a 0xc0025a3687 0xc0025a3688}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vw9db {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vw9db,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-vw9db true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-162.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025a36f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025a3710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:45:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:45:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:45:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:45:08 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.162,PodIP:100.96.2.40,StartTime:2019-09-06 15:45:08 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-06 15:45:09 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://80c822350050dfb3b8ff6170d4918543e50899e43a99b33ac70523f5da4867d4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:45:10.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7848" for this suite.
Sep  6 15:45:16.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:45:17.045: INFO: namespace deployment-7848 deletion completed in 6.06439849s

• [SLOW TEST:13.153 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:45:17.045: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Sep  6 15:45:17.065: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-959664940 proxy --unix-socket=/tmp/kubectl-proxy-unix435463323/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:45:17.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-438" for this suite.
Sep  6 15:45:23.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:45:23.183: INFO: namespace kubectl-438 deletion completed in 6.062905314s

• [SLOW TEST:6.137 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:45:23.183: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-569d2de9-d0bd-11e9-a08c-82ce3d77f2cb
STEP: Creating configMap with name cm-test-opt-upd-569d2e2c-d0bd-11e9-a08c-82ce3d77f2cb
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-569d2de9-d0bd-11e9-a08c-82ce3d77f2cb
STEP: Updating configmap cm-test-opt-upd-569d2e2c-d0bd-11e9-a08c-82ce3d77f2cb
STEP: Creating configMap with name cm-test-opt-create-569d2e4a-d0bd-11e9-a08c-82ce3d77f2cb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:45:29.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1371" for this suite.
Sep  6 15:45:51.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:45:51.355: INFO: namespace projected-1371 deletion completed in 22.071117022s

• [SLOW TEST:28.172 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:45:51.356: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep  6 15:45:55.397: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-524 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 15:45:55.397: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 15:45:55.484: INFO: Exec stderr: ""
Sep  6 15:45:55.484: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-524 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 15:45:55.484: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 15:45:55.570: INFO: Exec stderr: ""
Sep  6 15:45:55.570: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-524 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 15:45:55.570: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 15:45:55.666: INFO: Exec stderr: ""
Sep  6 15:45:55.666: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-524 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 15:45:55.666: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 15:45:55.753: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep  6 15:45:55.753: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-524 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 15:45:55.753: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 15:45:55.839: INFO: Exec stderr: ""
Sep  6 15:45:55.839: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-524 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 15:45:55.839: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 15:45:55.926: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep  6 15:45:55.926: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-524 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 15:45:55.926: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 15:45:56.007: INFO: Exec stderr: ""
Sep  6 15:45:56.007: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-524 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 15:45:56.007: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 15:45:56.100: INFO: Exec stderr: ""
Sep  6 15:45:56.100: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-524 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 15:45:56.100: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 15:45:56.198: INFO: Exec stderr: ""
Sep  6 15:45:56.198: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-524 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 15:45:56.198: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 15:45:56.286: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:45:56.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-524" for this suite.
Sep  6 15:46:46.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:46:46.359: INFO: namespace e2e-kubelet-etc-hosts-524 deletion completed in 50.069511823s

• [SLOW TEST:55.003 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:46:46.359: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-883087ce-d0bd-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume configMaps
Sep  6 15:46:46.386: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8830ff14-d0bd-11e9-a08c-82ce3d77f2cb" in namespace "projected-4216" to be "success or failure"
Sep  6 15:46:46.388: INFO: Pod "pod-projected-configmaps-8830ff14-d0bd-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.233637ms
Sep  6 15:46:48.391: INFO: Pod "pod-projected-configmaps-8830ff14-d0bd-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005191499s
STEP: Saw pod success
Sep  6 15:46:48.391: INFO: Pod "pod-projected-configmaps-8830ff14-d0bd-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:46:48.393: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-projected-configmaps-8830ff14-d0bd-11e9-a08c-82ce3d77f2cb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 15:46:48.405: INFO: Waiting for pod pod-projected-configmaps-8830ff14-d0bd-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:46:48.407: INFO: Pod pod-projected-configmaps-8830ff14-d0bd-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:46:48.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4216" for this suite.
Sep  6 15:46:54.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:46:54.475: INFO: namespace projected-4216 deletion completed in 6.064576757s

• [SLOW TEST:8.116 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:46:54.475: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-8d074e20-d0bd-11e9-a08c-82ce3d77f2cb
STEP: Creating secret with name s-test-opt-upd-8d074e72-d0bd-11e9-a08c-82ce3d77f2cb
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-8d074e20-d0bd-11e9-a08c-82ce3d77f2cb
STEP: Updating secret s-test-opt-upd-8d074e72-d0bd-11e9-a08c-82ce3d77f2cb
STEP: Creating secret with name s-test-opt-create-8d074e96-d0bd-11e9-a08c-82ce3d77f2cb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:46:58.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2934" for this suite.
Sep  6 15:47:20.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:47:20.626: INFO: namespace projected-2934 deletion completed in 22.064253676s

• [SLOW TEST:26.151 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:47:20.627: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 15:47:20.651: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9c9d65c4-d0bd-11e9-a08c-82ce3d77f2cb" in namespace "projected-3101" to be "success or failure"
Sep  6 15:47:20.655: INFO: Pod "downwardapi-volume-9c9d65c4-d0bd-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.656438ms
Sep  6 15:47:22.658: INFO: Pod "downwardapi-volume-9c9d65c4-d0bd-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006600814s
STEP: Saw pod success
Sep  6 15:47:22.658: INFO: Pod "downwardapi-volume-9c9d65c4-d0bd-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:47:22.659: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod downwardapi-volume-9c9d65c4-d0bd-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 15:47:22.671: INFO: Waiting for pod downwardapi-volume-9c9d65c4-d0bd-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:47:22.674: INFO: Pod downwardapi-volume-9c9d65c4-d0bd-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:47:22.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3101" for this suite.
Sep  6 15:47:28.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:47:28.739: INFO: namespace projected-3101 deletion completed in 6.062537901s

• [SLOW TEST:8.111 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:47:28.739: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-a1731fce-d0bd-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume configMaps
Sep  6 15:47:28.764: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a173710a-d0bd-11e9-a08c-82ce3d77f2cb" in namespace "projected-8706" to be "success or failure"
Sep  6 15:47:28.768: INFO: Pod "pod-projected-configmaps-a173710a-d0bd-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.555064ms
Sep  6 15:47:30.771: INFO: Pod "pod-projected-configmaps-a173710a-d0bd-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006534548s
STEP: Saw pod success
Sep  6 15:47:30.771: INFO: Pod "pod-projected-configmaps-a173710a-d0bd-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:47:30.773: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-projected-configmaps-a173710a-d0bd-11e9-a08c-82ce3d77f2cb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 15:47:30.785: INFO: Waiting for pod pod-projected-configmaps-a173710a-d0bd-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:47:30.791: INFO: Pod pod-projected-configmaps-a173710a-d0bd-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:47:30.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8706" for this suite.
Sep  6 15:47:36.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:47:36.862: INFO: namespace projected-8706 deletion completed in 6.06945959s

• [SLOW TEST:8.123 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:47:36.863: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep  6 15:47:39.907: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:47:40.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5379" for this suite.
Sep  6 15:48:02.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:48:02.984: INFO: namespace replicaset-5379 deletion completed in 22.063126895s

• [SLOW TEST:26.121 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:48:02.984: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Sep  6 15:48:03.004: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Sep  6 15:48:03.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 create -f - --namespace=kubectl-4292'
Sep  6 15:48:03.350: INFO: stderr: ""
Sep  6 15:48:03.350: INFO: stdout: "service/redis-slave created\n"
Sep  6 15:48:03.350: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Sep  6 15:48:03.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 create -f - --namespace=kubectl-4292'
Sep  6 15:48:03.532: INFO: stderr: ""
Sep  6 15:48:03.532: INFO: stdout: "service/redis-master created\n"
Sep  6 15:48:03.533: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep  6 15:48:03.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 create -f - --namespace=kubectl-4292'
Sep  6 15:48:03.721: INFO: stderr: ""
Sep  6 15:48:03.721: INFO: stdout: "service/frontend created\n"
Sep  6 15:48:03.721: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Sep  6 15:48:03.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 create -f - --namespace=kubectl-4292'
Sep  6 15:48:03.904: INFO: stderr: ""
Sep  6 15:48:03.904: INFO: stdout: "deployment.apps/frontend created\n"
Sep  6 15:48:03.904: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep  6 15:48:03.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 create -f - --namespace=kubectl-4292'
Sep  6 15:48:04.223: INFO: stderr: ""
Sep  6 15:48:04.223: INFO: stdout: "deployment.apps/redis-master created\n"
Sep  6 15:48:04.223: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Sep  6 15:48:04.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 create -f - --namespace=kubectl-4292'
Sep  6 15:48:04.423: INFO: stderr: ""
Sep  6 15:48:04.423: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Sep  6 15:48:04.423: INFO: Waiting for all frontend pods to be Running.
Sep  6 15:48:19.474: INFO: Waiting for frontend to serve content.
Sep  6 15:48:20.502: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Sep  6 15:48:25.514: INFO: Trying to add a new entry to the guestbook.
Sep  6 15:48:25.528: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Sep  6 15:48:25.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 delete --grace-period=0 --force -f - --namespace=kubectl-4292'
Sep  6 15:48:25.618: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 15:48:25.618: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep  6 15:48:25.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 delete --grace-period=0 --force -f - --namespace=kubectl-4292'
Sep  6 15:48:25.718: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 15:48:25.718: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep  6 15:48:25.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 delete --grace-period=0 --force -f - --namespace=kubectl-4292'
Sep  6 15:48:25.824: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 15:48:25.824: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep  6 15:48:25.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 delete --grace-period=0 --force -f - --namespace=kubectl-4292'
Sep  6 15:48:25.901: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 15:48:25.901: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep  6 15:48:25.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 delete --grace-period=0 --force -f - --namespace=kubectl-4292'
Sep  6 15:48:25.987: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 15:48:25.987: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep  6 15:48:25.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 delete --grace-period=0 --force -f - --namespace=kubectl-4292'
Sep  6 15:48:26.061: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 15:48:26.061: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:48:26.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4292" for this suite.
Sep  6 15:49:06.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:49:06.151: INFO: namespace kubectl-4292 deletion completed in 40.087916795s

• [SLOW TEST:63.167 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:49:06.152: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:49:09.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7256" for this suite.
Sep  6 15:49:31.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:49:31.258: INFO: namespace replication-controller-7256 deletion completed in 22.061023004s

• [SLOW TEST:25.106 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:49:31.258: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep  6 15:49:33.799: INFO: Successfully updated pod "pod-update-activedeadlineseconds-ea7a38de-d0bd-11e9-a08c-82ce3d77f2cb"
Sep  6 15:49:33.799: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-ea7a38de-d0bd-11e9-a08c-82ce3d77f2cb" in namespace "pods-467" to be "terminated due to deadline exceeded"
Sep  6 15:49:33.801: INFO: Pod "pod-update-activedeadlineseconds-ea7a38de-d0bd-11e9-a08c-82ce3d77f2cb": Phase="Running", Reason="", readiness=true. Elapsed: 2.064705ms
Sep  6 15:49:35.804: INFO: Pod "pod-update-activedeadlineseconds-ea7a38de-d0bd-11e9-a08c-82ce3d77f2cb": Phase="Running", Reason="", readiness=true. Elapsed: 2.004959553s
Sep  6 15:49:37.807: INFO: Pod "pod-update-activedeadlineseconds-ea7a38de-d0bd-11e9-a08c-82ce3d77f2cb": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.007916506s
Sep  6 15:49:37.807: INFO: Pod "pod-update-activedeadlineseconds-ea7a38de-d0bd-11e9-a08c-82ce3d77f2cb" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:49:37.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-467" for this suite.
Sep  6 15:49:43.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:49:43.873: INFO: namespace pods-467 deletion completed in 6.063503526s

• [SLOW TEST:12.614 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:49:43.873: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 15:49:43.923: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"f1ff51d0-d0bd-11e9-8afa-02e25174ea0a", Controller:(*bool)(0xc00094c066), BlockOwnerDeletion:(*bool)(0xc00094c067)}}
Sep  6 15:49:43.937: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"f1fdb3ec-d0bd-11e9-8afa-02e25174ea0a", Controller:(*bool)(0xc000382f6a), BlockOwnerDeletion:(*bool)(0xc000382f6b)}}
Sep  6 15:49:43.944: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"f1fe2d14-d0bd-11e9-8afa-02e25174ea0a", Controller:(*bool)(0xc00094c4b6), BlockOwnerDeletion:(*bool)(0xc00094c4b7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:49:48.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1275" for this suite.
Sep  6 15:49:54.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:49:55.019: INFO: namespace gc-1275 deletion completed in 6.065941511s

• [SLOW TEST:11.146 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:49:55.019: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-9746
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9746 to expose endpoints map[]
Sep  6 15:49:55.056: INFO: successfully validated that service endpoint-test2 in namespace services-9746 exposes endpoints map[] (7.518784ms elapsed)
STEP: Creating pod pod1 in namespace services-9746
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9746 to expose endpoints map[pod1:[80]]
Sep  6 15:49:57.085: INFO: successfully validated that service endpoint-test2 in namespace services-9746 exposes endpoints map[pod1:[80]] (2.023347799s elapsed)
STEP: Creating pod pod2 in namespace services-9746
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9746 to expose endpoints map[pod1:[80] pod2:[80]]
Sep  6 15:50:00.117: INFO: successfully validated that service endpoint-test2 in namespace services-9746 exposes endpoints map[pod1:[80] pod2:[80]] (3.029520991s elapsed)
STEP: Deleting pod pod1 in namespace services-9746
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9746 to expose endpoints map[pod2:[80]]
Sep  6 15:50:01.135: INFO: successfully validated that service endpoint-test2 in namespace services-9746 exposes endpoints map[pod2:[80]] (1.014096201s elapsed)
STEP: Deleting pod pod2 in namespace services-9746
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9746 to expose endpoints map[]
Sep  6 15:50:02.149: INFO: successfully validated that service endpoint-test2 in namespace services-9746 exposes endpoints map[] (1.009873237s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:50:02.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9746" for this suite.
Sep  6 15:50:24.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:50:24.263: INFO: namespace services-9746 deletion completed in 22.078971001s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:29.244 seconds]
[sig-network] Services
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:50:24.263: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-0a122174-d0be-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume secrets
Sep  6 15:50:24.290: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0a127add-d0be-11e9-a08c-82ce3d77f2cb" in namespace "projected-1425" to be "success or failure"
Sep  6 15:50:24.293: INFO: Pod "pod-projected-secrets-0a127add-d0be-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.074053ms
Sep  6 15:50:26.296: INFO: Pod "pod-projected-secrets-0a127add-d0be-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006283044s
STEP: Saw pod success
Sep  6 15:50:26.296: INFO: Pod "pod-projected-secrets-0a127add-d0be-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:50:26.298: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-projected-secrets-0a127add-d0be-11e9-a08c-82ce3d77f2cb container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  6 15:50:26.310: INFO: Waiting for pod pod-projected-secrets-0a127add-d0be-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:50:26.311: INFO: Pod pod-projected-secrets-0a127add-d0be-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:50:26.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1425" for this suite.
Sep  6 15:50:32.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:50:32.379: INFO: namespace projected-1425 deletion completed in 6.065457664s

• [SLOW TEST:8.117 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:50:32.380: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-2147/configmap-test-0ee8bced-d0be-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume configMaps
Sep  6 15:50:32.406: INFO: Waiting up to 5m0s for pod "pod-configmaps-0ee905fc-d0be-11e9-a08c-82ce3d77f2cb" in namespace "configmap-2147" to be "success or failure"
Sep  6 15:50:32.413: INFO: Pod "pod-configmaps-0ee905fc-d0be-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.971791ms
Sep  6 15:50:34.415: INFO: Pod "pod-configmaps-0ee905fc-d0be-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009551895s
STEP: Saw pod success
Sep  6 15:50:34.415: INFO: Pod "pod-configmaps-0ee905fc-d0be-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:50:34.417: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-configmaps-0ee905fc-d0be-11e9-a08c-82ce3d77f2cb container env-test: <nil>
STEP: delete the pod
Sep  6 15:50:34.431: INFO: Waiting for pod pod-configmaps-0ee905fc-d0be-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:50:34.434: INFO: Pod pod-configmaps-0ee905fc-d0be-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:50:34.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2147" for this suite.
Sep  6 15:50:40.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:50:40.503: INFO: namespace configmap-2147 deletion completed in 6.066464944s

• [SLOW TEST:8.123 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:50:40.503: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep  6 15:50:43.065: INFO: Successfully updated pod "labelsupdate13c237c9-d0be-11e9-a08c-82ce3d77f2cb"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:50:47.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7698" for this suite.
Sep  6 15:51:09.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:51:09.151: INFO: namespace projected-7698 deletion completed in 22.063326067s

• [SLOW TEST:28.647 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:51:09.151: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-dr24
STEP: Creating a pod to test atomic-volume-subpath
Sep  6 15:51:09.180: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-dr24" in namespace "subpath-702" to be "success or failure"
Sep  6 15:51:09.183: INFO: Pod "pod-subpath-test-configmap-dr24": Phase="Pending", Reason="", readiness=false. Elapsed: 3.534831ms
Sep  6 15:51:11.186: INFO: Pod "pod-subpath-test-configmap-dr24": Phase="Running", Reason="", readiness=true. Elapsed: 2.006551378s
Sep  6 15:51:13.189: INFO: Pod "pod-subpath-test-configmap-dr24": Phase="Running", Reason="", readiness=true. Elapsed: 4.009559626s
Sep  6 15:51:15.192: INFO: Pod "pod-subpath-test-configmap-dr24": Phase="Running", Reason="", readiness=true. Elapsed: 6.012579143s
Sep  6 15:51:17.195: INFO: Pod "pod-subpath-test-configmap-dr24": Phase="Running", Reason="", readiness=true. Elapsed: 8.015773879s
Sep  6 15:51:19.198: INFO: Pod "pod-subpath-test-configmap-dr24": Phase="Running", Reason="", readiness=true. Elapsed: 10.018632709s
Sep  6 15:51:21.201: INFO: Pod "pod-subpath-test-configmap-dr24": Phase="Running", Reason="", readiness=true. Elapsed: 12.021708205s
Sep  6 15:51:23.204: INFO: Pod "pod-subpath-test-configmap-dr24": Phase="Running", Reason="", readiness=true. Elapsed: 14.024764784s
Sep  6 15:51:25.207: INFO: Pod "pod-subpath-test-configmap-dr24": Phase="Running", Reason="", readiness=true. Elapsed: 16.027785595s
Sep  6 15:51:27.210: INFO: Pod "pod-subpath-test-configmap-dr24": Phase="Running", Reason="", readiness=true. Elapsed: 18.030614786s
Sep  6 15:51:29.215: INFO: Pod "pod-subpath-test-configmap-dr24": Phase="Running", Reason="", readiness=true. Elapsed: 20.035463237s
Sep  6 15:51:31.218: INFO: Pod "pod-subpath-test-configmap-dr24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.038449694s
STEP: Saw pod success
Sep  6 15:51:31.218: INFO: Pod "pod-subpath-test-configmap-dr24" satisfied condition "success or failure"
Sep  6 15:51:31.220: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-subpath-test-configmap-dr24 container test-container-subpath-configmap-dr24: <nil>
STEP: delete the pod
Sep  6 15:51:31.233: INFO: Waiting for pod pod-subpath-test-configmap-dr24 to disappear
Sep  6 15:51:31.236: INFO: Pod pod-subpath-test-configmap-dr24 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-dr24
Sep  6 15:51:31.236: INFO: Deleting pod "pod-subpath-test-configmap-dr24" in namespace "subpath-702"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:51:31.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-702" for this suite.
Sep  6 15:51:37.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:51:37.305: INFO: namespace subpath-702 deletion completed in 6.064432832s

• [SLOW TEST:28.154 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:51:37.305: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-359befa7-d0be-11e9-a08c-82ce3d77f2cb
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-359befa7-d0be-11e9-a08c-82ce3d77f2cb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:51:41.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5676" for this suite.
Sep  6 15:52:03.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:52:03.463: INFO: namespace configmap-5676 deletion completed in 22.100830274s

• [SLOW TEST:26.158 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:52:03.463: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep  6 15:52:03.490: INFO: Waiting up to 5m0s for pod "downward-api-45334b1a-d0be-11e9-a08c-82ce3d77f2cb" in namespace "downward-api-4708" to be "success or failure"
Sep  6 15:52:03.496: INFO: Pod "downward-api-45334b1a-d0be-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.429959ms
Sep  6 15:52:05.499: INFO: Pod "downward-api-45334b1a-d0be-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008582082s
STEP: Saw pod success
Sep  6 15:52:05.499: INFO: Pod "downward-api-45334b1a-d0be-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:52:05.501: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod downward-api-45334b1a-d0be-11e9-a08c-82ce3d77f2cb container dapi-container: <nil>
STEP: delete the pod
Sep  6 15:52:05.515: INFO: Waiting for pod downward-api-45334b1a-d0be-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:52:05.517: INFO: Pod downward-api-45334b1a-d0be-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:52:05.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4708" for this suite.
Sep  6 15:52:11.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:52:11.592: INFO: namespace downward-api-4708 deletion completed in 6.073101581s

• [SLOW TEST:8.129 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:52:11.593: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 15:52:11.612: INFO: Creating deployment "nginx-deployment"
Sep  6 15:52:11.615: INFO: Waiting for observed generation 1
Sep  6 15:52:13.620: INFO: Waiting for all required pods to come up
Sep  6 15:52:13.623: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep  6 15:52:15.634: INFO: Waiting for deployment "nginx-deployment" to complete
Sep  6 15:52:15.637: INFO: Updating deployment "nginx-deployment" with a non-existent image
Sep  6 15:52:15.642: INFO: Updating deployment nginx-deployment
Sep  6 15:52:15.642: INFO: Waiting for observed generation 2
Sep  6 15:52:17.647: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep  6 15:52:17.649: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep  6 15:52:17.651: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep  6 15:52:17.656: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep  6 15:52:17.656: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep  6 15:52:17.658: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep  6 15:52:17.661: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Sep  6 15:52:17.661: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Sep  6 15:52:17.667: INFO: Updating deployment nginx-deployment
Sep  6 15:52:17.667: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Sep  6 15:52:17.673: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep  6 15:52:17.683: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  6 15:52:17.706: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-6581,SelfLink:/apis/apps/v1/namespaces/deployment-6581/deployments/nginx-deployment,UID:4a09c89c-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4859,Generation:3,CreationTimestamp:2019-09-06 15:52:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-09-06 15:52:15 +0000 UTC 2019-09-06 15:52:11 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-b79c9d74d" is progressing.} {Available False 2019-09-06 15:52:17 +0000 UTC 2019-09-06 15:52:17 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Sep  6 15:52:17.714: INFO: New ReplicaSet "nginx-deployment-b79c9d74d" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d,GenerateName:,Namespace:deployment-6581,SelfLink:/apis/apps/v1/namespaces/deployment-6581/replicasets/nginx-deployment-b79c9d74d,UID:4c70dd51-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4853,Generation:3,CreationTimestamp:2019-09-06 15:52:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 4a09c89c-d0be-11e9-8afa-02e25174ea0a 0xc001dd2567 0xc001dd2568}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  6 15:52:17.714: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Sep  6 15:52:17.714: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5,GenerateName:,Namespace:deployment-6581,SelfLink:/apis/apps/v1/namespaces/deployment-6581/replicasets/nginx-deployment-85db8c99c5,UID:4a0a6ee9-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4852,Generation:3,CreationTimestamp:2019-09-06 15:52:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 4a09c89c-d0be-11e9-8afa-02e25174ea0a 0xc001dd2487 0xc001dd2488}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Sep  6 15:52:17.737: INFO: Pod "nginx-deployment-85db8c99c5-8f4nt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-8f4nt,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-85db8c99c5-8f4nt,UID:4a197a3d-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4803,Generation:0,CreationTimestamp:2019-09-06 15:52:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 4a0a6ee9-d0be-11e9-8afa-02e25174ea0a 0xc001dd3540 0xc001dd3541}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-162.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001dd35c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001dd3620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:11 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.162,PodIP:100.96.2.63,StartTime:2019-09-06 15:52:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 15:52:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f7becab41d203b413156b5ccc0414e217cb980b1750d1b63a2334bcaf2fae4d4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.737: INFO: Pod "nginx-deployment-85db8c99c5-9p55n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-9p55n,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-85db8c99c5-9p55n,UID:4da68bcd-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4857,Generation:0,CreationTimestamp:2019-09-06 15:52:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 4a0a6ee9-d0be-11e9-8afa-02e25174ea0a 0xc001dd37b0 0xc001dd37b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-162.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001dd3830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001dd3850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:17 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.737: INFO: Pod "nginx-deployment-85db8c99c5-br4rj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-br4rj,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-85db8c99c5-br4rj,UID:4a194a91-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4809,Generation:0,CreationTimestamp:2019-09-06 15:52:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 4a0a6ee9-d0be-11e9-8afa-02e25174ea0a 0xc001dd3930 0xc001dd3931}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-162.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001dd39d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001dd39f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:11 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.162,PodIP:100.96.2.60,StartTime:2019-09-06 15:52:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 15:52:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://6193624c588569c0dc0e090261692f1701f5befa55cfa3a5a60bf2bf2e4c81a5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.738: INFO: Pod "nginx-deployment-85db8c99c5-hpxhs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-hpxhs,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-85db8c99c5-hpxhs,UID:4a0ba0c1-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4781,Generation:0,CreationTimestamp:2019-09-06 15:52:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 4a0a6ee9-d0be-11e9-8afa-02e25174ea0a 0xc001dd3b30 0xc001dd3b31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-162.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001dd3c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001dd3c50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:11 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.162,PodIP:100.96.2.58,StartTime:2019-09-06 15:52:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 15:52:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8c21cc736cea7772c46f1ede18c82615f0f60936ff19668314c6cd723597ae70}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.738: INFO: Pod "nginx-deployment-85db8c99c5-j5nhs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-j5nhs,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-85db8c99c5-j5nhs,UID:4da7bab5-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4862,Generation:0,CreationTimestamp:2019-09-06 15:52:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 4a0a6ee9-d0be-11e9-8afa-02e25174ea0a 0xc001dd3dc0 0xc001dd3dc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-162.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001dd3e20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001dd3e40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:17 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.738: INFO: Pod "nginx-deployment-85db8c99c5-lfzgp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-lfzgp,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-85db8c99c5-lfzgp,UID:4a171e87-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4790,Generation:0,CreationTimestamp:2019-09-06 15:52:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 4a0a6ee9-d0be-11e9-8afa-02e25174ea0a 0xc001dd3ec0 0xc001dd3ec1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-61-48.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001dd3f20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001dd3f40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:11 +0000 UTC  }],Message:,Reason:,HostIP:172.20.61.48,PodIP:100.96.1.43,StartTime:2019-09-06 15:52:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 15:52:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://42383ecffed3e7bb9e345bc0ed81c0080602b9f00a3e810127c9d147bf60452d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.738: INFO: Pod "nginx-deployment-85db8c99c5-mr9sj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-mr9sj,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-85db8c99c5-mr9sj,UID:4a17ba86-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4797,Generation:0,CreationTimestamp:2019-09-06 15:52:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 4a0a6ee9-d0be-11e9-8afa-02e25174ea0a 0xc0026de020 0xc0026de021}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-162.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026de110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026de180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:11 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.162,PodIP:100.96.2.62,StartTime:2019-09-06 15:52:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 15:52:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7b213a7df0a6ad6e1a684ac52dc9e2b5f0bd83bd29a496610fdb6bf1cd7974b8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.738: INFO: Pod "nginx-deployment-85db8c99c5-p9hk2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-p9hk2,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-85db8c99c5-p9hk2,UID:4a0d30ee-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4786,Generation:0,CreationTimestamp:2019-09-06 15:52:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 4a0a6ee9-d0be-11e9-8afa-02e25174ea0a 0xc0026de260 0xc0026de261}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-61-48.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026de2f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026de3b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:11 +0000 UTC  }],Message:,Reason:,HostIP:172.20.61.48,PodIP:100.96.1.40,StartTime:2019-09-06 15:52:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 15:52:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://06d3a890395792f1dcbf8e65bf70655058c32ceb308ed76bc2bd665207db8826}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.738: INFO: Pod "nginx-deployment-85db8c99c5-pfcng" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-pfcng,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-85db8c99c5-pfcng,UID:4a196471-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4784,Generation:0,CreationTimestamp:2019-09-06 15:52:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 4a0a6ee9-d0be-11e9-8afa-02e25174ea0a 0xc0026de630 0xc0026de631}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-61-48.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026de6d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026de6f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:11 +0000 UTC  }],Message:,Reason:,HostIP:172.20.61.48,PodIP:100.96.1.41,StartTime:2019-09-06 15:52:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 15:52:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f7ea5ed757ff6b4c461de7053c147e80bfd669369f5cc01a3fc9207ba66b8829}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.738: INFO: Pod "nginx-deployment-85db8c99c5-pn769" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-pn769,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-85db8c99c5-pn769,UID:4da87d66-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4864,Generation:0,CreationTimestamp:2019-09-06 15:52:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 4a0a6ee9-d0be-11e9-8afa-02e25174ea0a 0xc0026de810 0xc0026de811}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-162.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026de900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026de920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:17 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.738: INFO: Pod "nginx-deployment-85db8c99c5-xdq68" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-xdq68,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-85db8c99c5-xdq68,UID:4a12b889-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4793,Generation:0,CreationTimestamp:2019-09-06 15:52:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 4a0a6ee9-d0be-11e9-8afa-02e25174ea0a 0xc0026deaf0 0xc0026deaf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-61-48.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026debc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026debe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:11 +0000 UTC  }],Message:,Reason:,HostIP:172.20.61.48,PodIP:100.96.1.42,StartTime:2019-09-06 15:52:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 15:52:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8cb5ad52bee2cecfbee40694841b58a63e69d1243259a4cdc5bf12d7d2579b08}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.738: INFO: Pod "nginx-deployment-b79c9d74d-4bl85" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-4bl85,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-b79c9d74d-4bl85,UID:4daa2e26-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4867,Generation:0,CreationTimestamp:2019-09-06 15:52:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 4c70dd51-d0be-11e9-8afa-02e25174ea0a 0xc0026dece0 0xc0026dece1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-61-48.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026ded50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026ded70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:17 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.738: INFO: Pod "nginx-deployment-b79c9d74d-4f5sq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-4f5sq,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-b79c9d74d-4f5sq,UID:4c7a081b-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4841,Generation:0,CreationTimestamp:2019-09-06 15:52:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 4c70dd51-d0be-11e9-8afa-02e25174ea0a 0xc0026df010 0xc0026df011}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-61-48.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026df080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026df0a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC  }],Message:,Reason:,HostIP:172.20.61.48,PodIP:,StartTime:2019-09-06 15:52:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.739: INFO: Pod "nginx-deployment-b79c9d74d-52ck4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-52ck4,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-b79c9d74d-52ck4,UID:4c7b63d3-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4849,Generation:0,CreationTimestamp:2019-09-06 15:52:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 4c70dd51-d0be-11e9-8afa-02e25174ea0a 0xc0026df300 0xc0026df301}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-162.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026df450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026df470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.162,PodIP:100.96.2.66,StartTime:2019-09-06 15:52:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.739: INFO: Pod "nginx-deployment-b79c9d74d-558zh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-558zh,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-b79c9d74d-558zh,UID:4c71a33d-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4850,Generation:0,CreationTimestamp:2019-09-06 15:52:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 4c70dd51-d0be-11e9-8afa-02e25174ea0a 0xc0026df600 0xc0026df601}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-162.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026df760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026df780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.162,PodIP:100.96.2.64,StartTime:2019-09-06 15:52:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.739: INFO: Pod "nginx-deployment-b79c9d74d-68bmc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-68bmc,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-b79c9d74d-68bmc,UID:4dac84d8-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4866,Generation:0,CreationTimestamp:2019-09-06 15:52:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 4c70dd51-d0be-11e9-8afa-02e25174ea0a 0xc0026df990 0xc0026df991}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026dfa00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026dfa20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.739: INFO: Pod "nginx-deployment-b79c9d74d-bh7vg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-bh7vg,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-b79c9d74d-bh7vg,UID:4c728974-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4845,Generation:0,CreationTimestamp:2019-09-06 15:52:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 4c70dd51-d0be-11e9-8afa-02e25174ea0a 0xc0026dfa87 0xc0026dfa88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-162.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026dfb00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026dfb20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.162,PodIP:,StartTime:2019-09-06 15:52:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.739: INFO: Pod "nginx-deployment-b79c9d74d-dtwgp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-dtwgp,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-b79c9d74d-dtwgp,UID:4da7a3d3-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4870,Generation:0,CreationTimestamp:2019-09-06 15:52:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 4c70dd51-d0be-11e9-8afa-02e25174ea0a 0xc0026dfce0 0xc0026dfce1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-61-48.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026dfd50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026dfd70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:17 +0000 UTC  }],Message:,Reason:,HostIP:172.20.61.48,PodIP:,StartTime:2019-09-06 15:52:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.739: INFO: Pod "nginx-deployment-b79c9d74d-jvfxl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-jvfxl,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-b79c9d74d-jvfxl,UID:4dab3edc-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4868,Generation:0,CreationTimestamp:2019-09-06 15:52:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 4c70dd51-d0be-11e9-8afa-02e25174ea0a 0xc0026dfe50 0xc0026dfe51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-162.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026dfec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026dfee0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:17 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.739: INFO: Pod "nginx-deployment-b79c9d74d-t7pzz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-t7pzz,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-b79c9d74d-t7pzz,UID:4dacfbbc-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4869,Generation:0,CreationTimestamp:2019-09-06 15:52:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 4c70dd51-d0be-11e9-8afa-02e25174ea0a 0xc0026dffa0 0xc0026dffa1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002718040} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002718060}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 15:52:17.739: INFO: Pod "nginx-deployment-b79c9d74d-xvql4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-xvql4,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-6581,SelfLink:/api/v1/namespaces/deployment-6581/pods/nginx-deployment-b79c9d74d-xvql4,UID:4c726f7f-d0be-11e9-8afa-02e25174ea0a,ResourceVersion:4824,Generation:0,CreationTimestamp:2019-09-06 15:52:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 4c70dd51-d0be-11e9-8afa-02e25174ea0a 0xc0027180c7 0xc0027180c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lnp4c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lnp4c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lnp4c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-61-48.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002718130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002718150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 15:52:15 +0000 UTC  }],Message:,Reason:,HostIP:172.20.61.48,PodIP:,StartTime:2019-09-06 15:52:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:52:17.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6581" for this suite.
Sep  6 15:52:23.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:52:23.859: INFO: namespace deployment-6581 deletion completed in 6.110399685s

• [SLOW TEST:12.266 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:52:23.859: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 15:52:23.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 version'
Sep  6 15:52:24.052: INFO: stderr: ""
Sep  6 15:52:24.052: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.6\", GitCommit:\"96fac5cd13a5dc064f7d9f4f23030a6aeface6cc\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:13:49Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.6\", GitCommit:\"96fac5cd13a5dc064f7d9f4f23030a6aeface6cc\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:05:16Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:52:24.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7795" for this suite.
Sep  6 15:52:30.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:52:30.128: INFO: namespace kubectl-7795 deletion completed in 6.069116674s

• [SLOW TEST:6.269 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:52:30.128: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep  6 15:52:30.164: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 15:52:30.167: INFO: Number of nodes with available pods: 0
Sep  6 15:52:30.167: INFO: Node ip-172-20-60-162.us-east-2.compute.internal is running more than one daemon pod
Sep  6 15:52:31.170: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 15:52:31.172: INFO: Number of nodes with available pods: 0
Sep  6 15:52:31.172: INFO: Node ip-172-20-60-162.us-east-2.compute.internal is running more than one daemon pod
Sep  6 15:52:32.170: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 15:52:32.172: INFO: Number of nodes with available pods: 2
Sep  6 15:52:32.172: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep  6 15:52:32.184: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 15:52:32.187: INFO: Number of nodes with available pods: 2
Sep  6 15:52:32.187: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-529, will wait for the garbage collector to delete the pods
Sep  6 15:52:33.254: INFO: Deleting DaemonSet.extensions daemon-set took: 6.084968ms
Sep  6 15:52:33.554: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.266985ms
Sep  6 15:52:44.657: INFO: Number of nodes with available pods: 0
Sep  6 15:52:44.657: INFO: Number of running nodes: 0, number of available pods: 0
Sep  6 15:52:44.660: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-529/daemonsets","resourceVersion":"5077"},"items":null}

Sep  6 15:52:44.661: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-529/pods","resourceVersion":"5077"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:52:44.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-529" for this suite.
Sep  6 15:52:50.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:52:50.735: INFO: namespace daemonsets-529 deletion completed in 6.06611944s

• [SLOW TEST:20.607 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:52:50.736: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep  6 15:52:50.765: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:52:51.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5499" for this suite.
Sep  6 15:52:57.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:52:57.875: INFO: namespace replication-controller-5499 deletion completed in 6.080248573s

• [SLOW TEST:7.139 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:52:57.875: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 15:52:57.899: INFO: Waiting up to 5m0s for pod "downwardapi-volume-65a169ef-d0be-11e9-a08c-82ce3d77f2cb" in namespace "downward-api-2942" to be "success or failure"
Sep  6 15:52:57.902: INFO: Pod "downwardapi-volume-65a169ef-d0be-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.659006ms
Sep  6 15:52:59.905: INFO: Pod "downwardapi-volume-65a169ef-d0be-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005487602s
STEP: Saw pod success
Sep  6 15:52:59.905: INFO: Pod "downwardapi-volume-65a169ef-d0be-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:52:59.907: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod downwardapi-volume-65a169ef-d0be-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 15:52:59.920: INFO: Waiting for pod downwardapi-volume-65a169ef-d0be-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:52:59.921: INFO: Pod downwardapi-volume-65a169ef-d0be-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:52:59.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2942" for this suite.
Sep  6 15:53:05.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:53:05.999: INFO: namespace downward-api-2942 deletion completed in 6.075867534s

• [SLOW TEST:8.124 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:53:06.000: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 15:53:06.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 create -f - --namespace=kubectl-761'
Sep  6 15:53:06.197: INFO: stderr: ""
Sep  6 15:53:06.197: INFO: stdout: "replicationcontroller/redis-master created\n"
Sep  6 15:53:06.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 create -f - --namespace=kubectl-761'
Sep  6 15:53:06.362: INFO: stderr: ""
Sep  6 15:53:06.362: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  6 15:53:07.365: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 15:53:07.365: INFO: Found 0 / 1
Sep  6 15:53:08.367: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 15:53:08.367: INFO: Found 1 / 1
Sep  6 15:53:08.367: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  6 15:53:08.369: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 15:53:08.369: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  6 15:53:08.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 describe pod redis-master-fzvsg --namespace=kubectl-761'
Sep  6 15:53:08.450: INFO: stderr: ""
Sep  6 15:53:08.450: INFO: stdout: "Name:               redis-master-fzvsg\nNamespace:          kubectl-761\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-172-20-60-162.us-east-2.compute.internal/172.20.60.162\nStart Time:         Fri, 06 Sep 2019 15:53:06 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 100.96.2.75\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://1f787e9bc6b8311a3df2fe979083724d9122b3d3f40095487a15558ebf464bf4\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 06 Sep 2019 15:53:06 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-jnhmd (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-jnhmd:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-jnhmd\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                  Message\n  ----    ------     ----  ----                                                  -------\n  Normal  Scheduled  2s    default-scheduler                                     Successfully assigned kubectl-761/redis-master-fzvsg to ip-172-20-60-162.us-east-2.compute.internal\n  Normal  Pulled     2s    kubelet, ip-172-20-60-162.us-east-2.compute.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, ip-172-20-60-162.us-east-2.compute.internal  Created container redis-master\n  Normal  Started    2s    kubelet, ip-172-20-60-162.us-east-2.compute.internal  Started container redis-master\n"
Sep  6 15:53:08.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 describe rc redis-master --namespace=kubectl-761'
Sep  6 15:53:08.546: INFO: stderr: ""
Sep  6 15:53:08.546: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-761\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-fzvsg\n"
Sep  6 15:53:08.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 describe service redis-master --namespace=kubectl-761'
Sep  6 15:53:08.621: INFO: stderr: ""
Sep  6 15:53:08.622: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-761\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.65.163.140\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.96.2.75:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep  6 15:53:08.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 describe node ip-172-20-50-224.us-east-2.compute.internal'
Sep  6 15:53:08.714: INFO: stderr: ""
Sep  6 15:53:08.714: INFO: stdout: "Name:               ip-172-20-50-224.us-east-2.compute.internal\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=c4.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east-2\n                    failure-domain.beta.kubernetes.io/zone=us-east-2a\n                    kops.k8s.io/instancegroup=master-us-east-2a\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-20-50-224.us-east-2.compute.internal\n                    kubernetes.io/os=linux\n                    kubernetes.io/role=master\n                    node-role.kubernetes.io/master=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 06 Sep 2019 15:22:18 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Fri, 06 Sep 2019 15:22:25 +0000   Fri, 06 Sep 2019 15:22:25 +0000   RouteCreated                 RouteController created a route\n  MemoryPressure       False   Fri, 06 Sep 2019 15:52:39 +0000   Fri, 06 Sep 2019 15:22:18 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Fri, 06 Sep 2019 15:52:39 +0000   Fri, 06 Sep 2019 15:22:18 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Fri, 06 Sep 2019 15:52:39 +0000   Fri, 06 Sep 2019 15:22:18 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Fri, 06 Sep 2019 15:52:39 +0000   Fri, 06 Sep 2019 15:22:18 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:   172.20.50.224\n  ExternalIP:   18.217.14.126\n  Hostname:     ip-172-20-50-224.us-east-2.compute.internal\n  InternalDNS:  ip-172-20-50-224.us-east-2.compute.internal\n  ExternalDNS:  ec2-18-217-14-126.us-east-2.compute.amazonaws.com\nCapacity:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           62843416Ki\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      3857008Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           57916492090\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      3754608Ki\n pods:                        110\nSystem Info:\n Machine ID:                 f04462d9aa3546f49cd7166a3c713ab1\n System UUID:                EC27578D-82C5-9264-7DE6-0C83BC92DA8C\n Boot ID:                    fadc92d7-35f9-417f-8533-52d5f3551202\n Kernel Version:             4.9.0-9-amd64\n OS Image:                   Debian GNU/Linux 9 (stretch)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.14.6\n Kube-Proxy Version:         v1.14.6\nPodCIDR:                     100.96.0.0/24\nProviderID:                  aws:///us-east-2a/i-0099bea464c7a9054\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                                   CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                                   ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-792ed0eef92d49d6-s82jc                0 (0%)        0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                dns-controller-7b47457bdd-v7glz                                        50m (2%)      0 (0%)      50Mi (1%)        0 (0%)         30m\n  kube-system                etcd-manager-events-ip-172-20-50-224.us-east-2.compute.internal        100m (5%)     0 (0%)      100Mi (2%)       0 (0%)         30m\n  kube-system                etcd-manager-main-ip-172-20-50-224.us-east-2.compute.internal          200m (10%)    0 (0%)      100Mi (2%)       0 (0%)         29m\n  kube-system                kube-apiserver-ip-172-20-50-224.us-east-2.compute.internal             150m (7%)     0 (0%)      0 (0%)           0 (0%)         30m\n  kube-system                kube-controller-manager-ip-172-20-50-224.us-east-2.compute.internal    100m (5%)     0 (0%)      0 (0%)           0 (0%)         30m\n  kube-system                kube-proxy-ip-172-20-50-224.us-east-2.compute.internal                 100m (5%)     0 (0%)      0 (0%)           0 (0%)         29m\n  kube-system                kube-scheduler-ip-172-20-50-224.us-east-2.compute.internal             100m (5%)     0 (0%)      0 (0%)           0 (0%)         29m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests    Limits\n  --------                    --------    ------\n  cpu                         800m (40%)  0 (0%)\n  memory                      250Mi (6%)  0 (0%)\n  ephemeral-storage           0 (0%)      0 (0%)\n  attachable-volumes-aws-ebs  0           0\nEvents:\n  Type    Reason    Age   From                                                     Message\n  ----    ------    ----  ----                                                     -------\n  Normal  Starting  32m   kube-proxy, ip-172-20-50-224.us-east-2.compute.internal  Starting kube-proxy.\n"
Sep  6 15:53:08.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 describe namespace kubectl-761'
Sep  6 15:53:08.789: INFO: stderr: ""
Sep  6 15:53:08.789: INFO: stdout: "Name:         kubectl-761\nLabels:       e2e-framework=kubectl\n              e2e-run=73f276c1-d0ba-11e9-a08c-82ce3d77f2cb\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:53:08.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-761" for this suite.
Sep  6 15:53:30.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:53:30.857: INFO: namespace kubectl-761 deletion completed in 22.065145333s

• [SLOW TEST:24.857 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:53:30.857: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-7949e835-d0be-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume secrets
Sep  6 15:53:30.882: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-794a3a29-d0be-11e9-a08c-82ce3d77f2cb" in namespace "projected-8415" to be "success or failure"
Sep  6 15:53:30.885: INFO: Pod "pod-projected-secrets-794a3a29-d0be-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.035982ms
Sep  6 15:53:32.888: INFO: Pod "pod-projected-secrets-794a3a29-d0be-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005944721s
STEP: Saw pod success
Sep  6 15:53:32.888: INFO: Pod "pod-projected-secrets-794a3a29-d0be-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:53:32.889: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-projected-secrets-794a3a29-d0be-11e9-a08c-82ce3d77f2cb container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  6 15:53:32.900: INFO: Waiting for pod pod-projected-secrets-794a3a29-d0be-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:53:32.903: INFO: Pod pod-projected-secrets-794a3a29-d0be-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:53:32.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8415" for this suite.
Sep  6 15:53:38.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:53:38.978: INFO: namespace projected-8415 deletion completed in 6.072906229s

• [SLOW TEST:8.121 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:53:38.978: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep  6 15:53:39.002: INFO: Waiting up to 5m0s for pod "pod-7e2122ba-d0be-11e9-a08c-82ce3d77f2cb" in namespace "emptydir-7436" to be "success or failure"
Sep  6 15:53:39.005: INFO: Pod "pod-7e2122ba-d0be-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.144521ms
Sep  6 15:53:41.008: INFO: Pod "pod-7e2122ba-d0be-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005906848s
STEP: Saw pod success
Sep  6 15:53:41.008: INFO: Pod "pod-7e2122ba-d0be-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:53:41.010: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-7e2122ba-d0be-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 15:53:41.025: INFO: Waiting for pod pod-7e2122ba-d0be-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:53:41.026: INFO: Pod pod-7e2122ba-d0be-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:53:41.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7436" for this suite.
Sep  6 15:53:47.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:53:47.091: INFO: namespace emptydir-7436 deletion completed in 6.063060033s

• [SLOW TEST:8.114 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:53:47.092: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep  6 15:53:51.146: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  6 15:53:51.148: INFO: Pod pod-with-prestop-http-hook still exists
Sep  6 15:53:53.149: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  6 15:53:53.151: INFO: Pod pod-with-prestop-http-hook still exists
Sep  6 15:53:55.149: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  6 15:53:55.151: INFO: Pod pod-with-prestop-http-hook still exists
Sep  6 15:53:57.149: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  6 15:53:57.152: INFO: Pod pod-with-prestop-http-hook still exists
Sep  6 15:53:59.149: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  6 15:53:59.152: INFO: Pod pod-with-prestop-http-hook still exists
Sep  6 15:54:01.149: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  6 15:54:01.152: INFO: Pod pod-with-prestop-http-hook still exists
Sep  6 15:54:03.149: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  6 15:54:03.151: INFO: Pod pod-with-prestop-http-hook still exists
Sep  6 15:54:05.149: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  6 15:54:05.151: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:54:05.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8865" for this suite.
Sep  6 15:54:27.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:54:27.228: INFO: namespace container-lifecycle-hook-8865 deletion completed in 22.068382691s

• [SLOW TEST:40.136 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:54:27.228: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0906 15:54:37.264777      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  6 15:54:37.264: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:54:37.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8619" for this suite.
Sep  6 15:54:43.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:54:43.329: INFO: namespace gc-8619 deletion completed in 6.06267598s

• [SLOW TEST:16.101 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:54:43.329: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-a47c99f8-d0be-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume secrets
Sep  6 15:54:43.356: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a47cecdc-d0be-11e9-a08c-82ce3d77f2cb" in namespace "projected-4523" to be "success or failure"
Sep  6 15:54:43.361: INFO: Pod "pod-projected-secrets-a47cecdc-d0be-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.594951ms
Sep  6 15:54:45.364: INFO: Pod "pod-projected-secrets-a47cecdc-d0be-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007454682s
STEP: Saw pod success
Sep  6 15:54:45.364: INFO: Pod "pod-projected-secrets-a47cecdc-d0be-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 15:54:45.365: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-projected-secrets-a47cecdc-d0be-11e9-a08c-82ce3d77f2cb container secret-volume-test: <nil>
STEP: delete the pod
Sep  6 15:54:45.379: INFO: Waiting for pod pod-projected-secrets-a47cecdc-d0be-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 15:54:45.380: INFO: Pod pod-projected-secrets-a47cecdc-d0be-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:54:45.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4523" for this suite.
Sep  6 15:54:51.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:54:51.448: INFO: namespace projected-4523 deletion completed in 6.065371414s

• [SLOW TEST:8.119 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:54:51.448: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-7914
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Sep  6 15:54:51.503: INFO: Found 0 stateful pods, waiting for 3
Sep  6 15:55:01.507: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 15:55:01.507: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 15:55:01.507: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 15:55:01.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-7914 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 15:55:01.672: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  6 15:55:01.672: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 15:55:01.672: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep  6 15:55:11.699: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep  6 15:55:21.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-7914 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 15:55:21.871: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  6 15:55:21.871: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  6 15:55:21.871: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

STEP: Rolling back to a previous revision
Sep  6 15:55:51.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-7914 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 15:55:52.039: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  6 15:55:52.039: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 15:55:52.039: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 15:56:02.064: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep  6 15:56:12.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-7914 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 15:56:12.280: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  6 15:56:12.280: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  6 15:56:12.280: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  6 15:56:22.294: INFO: Waiting for StatefulSet statefulset-7914/ss2 to complete update
Sep  6 15:56:22.294: INFO: Waiting for Pod statefulset-7914/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Sep  6 15:56:22.294: INFO: Waiting for Pod statefulset-7914/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Sep  6 15:56:22.294: INFO: Waiting for Pod statefulset-7914/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Sep  6 15:56:32.300: INFO: Waiting for StatefulSet statefulset-7914/ss2 to complete update
Sep  6 15:56:32.300: INFO: Waiting for Pod statefulset-7914/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Sep  6 15:56:42.300: INFO: Waiting for StatefulSet statefulset-7914/ss2 to complete update
Sep  6 15:56:42.300: INFO: Waiting for Pod statefulset-7914/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  6 15:56:52.308: INFO: Deleting all statefulset in ns statefulset-7914
Sep  6 15:56:52.310: INFO: Scaling statefulset ss2 to 0
Sep  6 15:57:32.324: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 15:57:32.326: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:57:32.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7914" for this suite.
Sep  6 15:57:38.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:57:38.430: INFO: namespace statefulset-7914 deletion completed in 6.086412158s

• [SLOW TEST:166.982 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:57:38.431: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep  6 15:57:38.468: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 15:57:38.471: INFO: Number of nodes with available pods: 0
Sep  6 15:57:38.471: INFO: Node ip-172-20-60-162.us-east-2.compute.internal is running more than one daemon pod
Sep  6 15:57:39.475: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 15:57:39.476: INFO: Number of nodes with available pods: 0
Sep  6 15:57:39.476: INFO: Node ip-172-20-60-162.us-east-2.compute.internal is running more than one daemon pod
Sep  6 15:57:40.475: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 15:57:40.477: INFO: Number of nodes with available pods: 2
Sep  6 15:57:40.477: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep  6 15:57:40.486: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 15:57:40.488: INFO: Number of nodes with available pods: 1
Sep  6 15:57:40.488: INFO: Node ip-172-20-61-48.us-east-2.compute.internal is running more than one daemon pod
Sep  6 15:57:41.491: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 15:57:41.493: INFO: Number of nodes with available pods: 1
Sep  6 15:57:41.493: INFO: Node ip-172-20-61-48.us-east-2.compute.internal is running more than one daemon pod
Sep  6 15:57:42.491: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 15:57:42.493: INFO: Number of nodes with available pods: 1
Sep  6 15:57:42.493: INFO: Node ip-172-20-61-48.us-east-2.compute.internal is running more than one daemon pod
Sep  6 15:57:43.491: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 15:57:43.493: INFO: Number of nodes with available pods: 1
Sep  6 15:57:43.493: INFO: Node ip-172-20-61-48.us-east-2.compute.internal is running more than one daemon pod
Sep  6 15:57:44.493: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 15:57:44.494: INFO: Number of nodes with available pods: 1
Sep  6 15:57:44.494: INFO: Node ip-172-20-61-48.us-east-2.compute.internal is running more than one daemon pod
Sep  6 15:57:45.491: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 15:57:45.493: INFO: Number of nodes with available pods: 2
Sep  6 15:57:45.493: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2758, will wait for the garbage collector to delete the pods
Sep  6 15:57:45.551: INFO: Deleting DaemonSet.extensions daemon-set took: 4.454653ms
Sep  6 15:57:45.651: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.278949ms
Sep  6 15:57:54.654: INFO: Number of nodes with available pods: 0
Sep  6 15:57:54.654: INFO: Number of running nodes: 0, number of available pods: 0
Sep  6 15:57:54.656: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2758/daemonsets","resourceVersion":"5931"},"items":null}

Sep  6 15:57:54.657: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2758/pods","resourceVersion":"5931"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:57:54.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2758" for this suite.
Sep  6 15:58:00.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:58:00.729: INFO: namespace daemonsets-2758 deletion completed in 6.064358349s

• [SLOW TEST:22.299 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:58:00.729: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1576
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  6 15:58:00.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-903'
Sep  6 15:58:00.828: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  6 15:58:00.828: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1581
Sep  6 15:58:00.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 delete jobs e2e-test-nginx-job --namespace=kubectl-903'
Sep  6 15:58:00.908: INFO: stderr: ""
Sep  6 15:58:00.908: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:58:00.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-903" for this suite.
Sep  6 15:58:06.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:58:06.998: INFO: namespace kubectl-903 deletion completed in 6.087077972s

• [SLOW TEST:6.269 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:58:06.999: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  6 15:58:07.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-247'
Sep  6 15:58:07.247: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  6 15:58:07.247: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Sep  6 15:58:07.254: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Sep  6 15:58:07.257: INFO: scanned /root for discovery docs: <nil>
Sep  6 15:58:07.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-247'
Sep  6 15:58:23.015: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  6 15:58:23.015: INFO: stdout: "Created e2e-test-nginx-rc-7bb947e7903a6b26e3d43d43451de3e3\nScaling up e2e-test-nginx-rc-7bb947e7903a6b26e3d43d43451de3e3 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-7bb947e7903a6b26e3d43d43451de3e3 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-7bb947e7903a6b26e3d43d43451de3e3 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Sep  6 15:58:23.015: INFO: stdout: "Created e2e-test-nginx-rc-7bb947e7903a6b26e3d43d43451de3e3\nScaling up e2e-test-nginx-rc-7bb947e7903a6b26e3d43d43451de3e3 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-7bb947e7903a6b26e3d43d43451de3e3 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-7bb947e7903a6b26e3d43d43451de3e3 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Sep  6 15:58:23.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-247'
Sep  6 15:58:23.087: INFO: stderr: ""
Sep  6 15:58:23.087: INFO: stdout: "e2e-test-nginx-rc-4zm9d e2e-test-nginx-rc-7bb947e7903a6b26e3d43d43451de3e3-q5ck8 "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Sep  6 15:58:28.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-247'
Sep  6 15:58:28.157: INFO: stderr: ""
Sep  6 15:58:28.157: INFO: stdout: "e2e-test-nginx-rc-7bb947e7903a6b26e3d43d43451de3e3-q5ck8 "
Sep  6 15:58:28.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods e2e-test-nginx-rc-7bb947e7903a6b26e3d43d43451de3e3-q5ck8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-247'
Sep  6 15:58:28.224: INFO: stderr: ""
Sep  6 15:58:28.224: INFO: stdout: "true"
Sep  6 15:58:28.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods e2e-test-nginx-rc-7bb947e7903a6b26e3d43d43451de3e3-q5ck8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-247'
Sep  6 15:58:28.290: INFO: stderr: ""
Sep  6 15:58:28.290: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Sep  6 15:58:28.290: INFO: e2e-test-nginx-rc-7bb947e7903a6b26e3d43d43451de3e3-q5ck8 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1486
Sep  6 15:58:28.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 delete rc e2e-test-nginx-rc --namespace=kubectl-247'
Sep  6 15:58:28.362: INFO: stderr: ""
Sep  6 15:58:28.362: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:58:28.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-247" for this suite.
Sep  6 15:58:50.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:58:50.434: INFO: namespace kubectl-247 deletion completed in 22.067248823s

• [SLOW TEST:43.436 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:58:50.435: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Sep  6 15:58:50.454: INFO: namespace kubectl-7532
Sep  6 15:58:50.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 create -f - --namespace=kubectl-7532'
Sep  6 15:58:50.614: INFO: stderr: ""
Sep  6 15:58:50.614: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  6 15:58:51.617: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 15:58:51.617: INFO: Found 0 / 1
Sep  6 15:58:52.618: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 15:58:52.618: INFO: Found 1 / 1
Sep  6 15:58:52.618: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  6 15:58:52.620: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 15:58:52.620: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  6 15:58:52.620: INFO: wait on redis-master startup in kubectl-7532 
Sep  6 15:58:52.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 logs redis-master-b4s9k redis-master --namespace=kubectl-7532'
Sep  6 15:58:52.699: INFO: stderr: ""
Sep  6 15:58:52.699: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 06 Sep 15:58:51.408 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Sep 15:58:51.408 # Server started, Redis version 3.2.12\n1:M 06 Sep 15:58:51.408 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Sep 15:58:51.408 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Sep  6 15:58:52.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-7532'
Sep  6 15:58:52.792: INFO: stderr: ""
Sep  6 15:58:52.792: INFO: stdout: "service/rm2 exposed\n"
Sep  6 15:58:52.796: INFO: Service rm2 in namespace kubectl-7532 found.
STEP: exposing service
Sep  6 15:58:54.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-7532'
Sep  6 15:58:54.878: INFO: stderr: ""
Sep  6 15:58:54.878: INFO: stdout: "service/rm3 exposed\n"
Sep  6 15:58:54.881: INFO: Service rm3 in namespace kubectl-7532 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:58:56.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7532" for this suite.
Sep  6 15:59:18.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:59:18.949: INFO: namespace kubectl-7532 deletion completed in 22.061509692s

• [SLOW TEST:28.514 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:59:18.949: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:59:41.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-528" for this suite.
Sep  6 15:59:47.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:59:47.168: INFO: namespace container-runtime-528 deletion completed in 6.063441091s

• [SLOW TEST:28.219 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:59:47.168: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2215.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2215.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2215.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2215.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2215.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2215.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  6 15:59:49.224: INFO: DNS probes using dns-2215/dns-test-5996d361-d0bf-11e9-a08c-82ce3d77f2cb succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:59:49.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2215" for this suite.
Sep  6 15:59:55.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 15:59:55.307: INFO: namespace dns-2215 deletion completed in 6.072322912s

• [SLOW TEST:8.139 seconds]
[sig-network] DNS
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 15:59:55.307: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 15:59:55.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9155" for this suite.
Sep  6 16:00:17.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:00:17.411: INFO: namespace pods-9155 deletion completed in 22.071076876s

• [SLOW TEST:22.104 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:00:17.411: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-6b9d32ff-d0bf-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume secrets
Sep  6 16:00:17.437: INFO: Waiting up to 5m0s for pod "pod-secrets-6b9d8485-d0bf-11e9-a08c-82ce3d77f2cb" in namespace "secrets-600" to be "success or failure"
Sep  6 16:00:17.439: INFO: Pod "pod-secrets-6b9d8485-d0bf-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.099315ms
Sep  6 16:00:19.442: INFO: Pod "pod-secrets-6b9d8485-d0bf-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005203885s
STEP: Saw pod success
Sep  6 16:00:19.442: INFO: Pod "pod-secrets-6b9d8485-d0bf-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:00:19.444: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-secrets-6b9d8485-d0bf-11e9-a08c-82ce3d77f2cb container secret-volume-test: <nil>
STEP: delete the pod
Sep  6 16:00:19.456: INFO: Waiting for pod pod-secrets-6b9d8485-d0bf-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:00:19.457: INFO: Pod pod-secrets-6b9d8485-d0bf-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:00:19.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-600" for this suite.
Sep  6 16:00:25.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:00:25.529: INFO: namespace secrets-600 deletion completed in 6.069076481s

• [SLOW TEST:8.118 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:00:25.529: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Sep  6 16:00:25.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 create -f - --namespace=kubectl-5636'
Sep  6 16:00:25.716: INFO: stderr: ""
Sep  6 16:00:25.716: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  6 16:00:25.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5636'
Sep  6 16:00:25.789: INFO: stderr: ""
Sep  6 16:00:25.789: INFO: stdout: "update-demo-nautilus-8b5ws update-demo-nautilus-sg2mq "
Sep  6 16:00:25.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-8b5ws -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5636'
Sep  6 16:00:25.860: INFO: stderr: ""
Sep  6 16:00:25.860: INFO: stdout: ""
Sep  6 16:00:25.860: INFO: update-demo-nautilus-8b5ws is created but not running
Sep  6 16:00:30.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5636'
Sep  6 16:00:30.930: INFO: stderr: ""
Sep  6 16:00:30.930: INFO: stdout: "update-demo-nautilus-8b5ws update-demo-nautilus-sg2mq "
Sep  6 16:00:30.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-8b5ws -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5636'
Sep  6 16:00:30.999: INFO: stderr: ""
Sep  6 16:00:30.999: INFO: stdout: "true"
Sep  6 16:00:30.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-8b5ws -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5636'
Sep  6 16:00:31.065: INFO: stderr: ""
Sep  6 16:00:31.065: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 16:00:31.065: INFO: validating pod update-demo-nautilus-8b5ws
Sep  6 16:00:31.070: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 16:00:31.070: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 16:00:31.070: INFO: update-demo-nautilus-8b5ws is verified up and running
Sep  6 16:00:31.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-sg2mq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5636'
Sep  6 16:00:31.137: INFO: stderr: ""
Sep  6 16:00:31.137: INFO: stdout: "true"
Sep  6 16:00:31.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-sg2mq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5636'
Sep  6 16:00:31.212: INFO: stderr: ""
Sep  6 16:00:31.212: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 16:00:31.212: INFO: validating pod update-demo-nautilus-sg2mq
Sep  6 16:00:31.216: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 16:00:31.216: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 16:00:31.216: INFO: update-demo-nautilus-sg2mq is verified up and running
STEP: rolling-update to new replication controller
Sep  6 16:00:31.217: INFO: scanned /root for discovery docs: <nil>
Sep  6 16:00:31.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-5636'
Sep  6 16:00:53.519: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  6 16:00:53.519: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  6 16:00:53.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5636'
Sep  6 16:00:53.589: INFO: stderr: ""
Sep  6 16:00:53.590: INFO: stdout: "update-demo-kitten-2xzg5 update-demo-kitten-h2gq4 "
Sep  6 16:00:53.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-kitten-2xzg5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5636'
Sep  6 16:00:53.660: INFO: stderr: ""
Sep  6 16:00:53.660: INFO: stdout: "true"
Sep  6 16:00:53.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-kitten-2xzg5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5636'
Sep  6 16:00:53.727: INFO: stderr: ""
Sep  6 16:00:53.727: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep  6 16:00:53.727: INFO: validating pod update-demo-kitten-2xzg5
Sep  6 16:00:53.731: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  6 16:00:53.731: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  6 16:00:53.731: INFO: update-demo-kitten-2xzg5 is verified up and running
Sep  6 16:00:53.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-kitten-h2gq4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5636'
Sep  6 16:00:53.797: INFO: stderr: ""
Sep  6 16:00:53.797: INFO: stdout: "true"
Sep  6 16:00:53.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-kitten-h2gq4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5636'
Sep  6 16:00:53.865: INFO: stderr: ""
Sep  6 16:00:53.865: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep  6 16:00:53.865: INFO: validating pod update-demo-kitten-h2gq4
Sep  6 16:00:53.868: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  6 16:00:53.868: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  6 16:00:53.868: INFO: update-demo-kitten-h2gq4 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:00:53.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5636" for this suite.
Sep  6 16:01:15.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:01:15.936: INFO: namespace kubectl-5636 deletion completed in 22.065548541s

• [SLOW TEST:50.407 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:01:15.936: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Sep  6 16:01:15.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 create -f - --namespace=kubectl-5081'
Sep  6 16:01:16.113: INFO: stderr: ""
Sep  6 16:01:16.113: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  6 16:01:16.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5081'
Sep  6 16:01:16.188: INFO: stderr: ""
Sep  6 16:01:16.188: INFO: stdout: "update-demo-nautilus-8l5x2 update-demo-nautilus-nrltg "
Sep  6 16:01:16.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-8l5x2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5081'
Sep  6 16:01:16.260: INFO: stderr: ""
Sep  6 16:01:16.260: INFO: stdout: ""
Sep  6 16:01:16.260: INFO: update-demo-nautilus-8l5x2 is created but not running
Sep  6 16:01:21.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5081'
Sep  6 16:01:21.339: INFO: stderr: ""
Sep  6 16:01:21.339: INFO: stdout: "update-demo-nautilus-8l5x2 update-demo-nautilus-nrltg "
Sep  6 16:01:21.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-8l5x2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5081'
Sep  6 16:01:21.409: INFO: stderr: ""
Sep  6 16:01:21.409: INFO: stdout: "true"
Sep  6 16:01:21.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-8l5x2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5081'
Sep  6 16:01:21.478: INFO: stderr: ""
Sep  6 16:01:21.478: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 16:01:21.478: INFO: validating pod update-demo-nautilus-8l5x2
Sep  6 16:01:21.484: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 16:01:21.484: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 16:01:21.484: INFO: update-demo-nautilus-8l5x2 is verified up and running
Sep  6 16:01:21.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-nrltg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5081'
Sep  6 16:01:21.555: INFO: stderr: ""
Sep  6 16:01:21.555: INFO: stdout: "true"
Sep  6 16:01:21.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-nrltg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5081'
Sep  6 16:01:21.622: INFO: stderr: ""
Sep  6 16:01:21.622: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 16:01:21.622: INFO: validating pod update-demo-nautilus-nrltg
Sep  6 16:01:21.625: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 16:01:21.625: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 16:01:21.625: INFO: update-demo-nautilus-nrltg is verified up and running
STEP: using delete to clean up resources
Sep  6 16:01:21.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 delete --grace-period=0 --force -f - --namespace=kubectl-5081'
Sep  6 16:01:21.694: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 16:01:21.694: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  6 16:01:21.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5081'
Sep  6 16:01:21.764: INFO: stderr: "No resources found.\n"
Sep  6 16:01:21.764: INFO: stdout: ""
Sep  6 16:01:21.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -l name=update-demo --namespace=kubectl-5081 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  6 16:01:21.836: INFO: stderr: ""
Sep  6 16:01:21.836: INFO: stdout: "update-demo-nautilus-8l5x2\nupdate-demo-nautilus-nrltg\n"
Sep  6 16:01:22.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5081'
Sep  6 16:01:22.424: INFO: stderr: "No resources found.\n"
Sep  6 16:01:22.424: INFO: stdout: ""
Sep  6 16:01:22.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -l name=update-demo --namespace=kubectl-5081 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  6 16:01:22.497: INFO: stderr: ""
Sep  6 16:01:22.497: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:01:22.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5081" for this suite.
Sep  6 16:01:44.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:01:44.571: INFO: namespace kubectl-5081 deletion completed in 22.071842325s

• [SLOW TEST:28.635 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:01:44.571: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep  6 16:01:48.617: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 16:01:48.619: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 16:01:50.619: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 16:01:50.622: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 16:01:52.619: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 16:01:52.622: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 16:01:54.619: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 16:01:54.622: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 16:01:56.619: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 16:01:56.622: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 16:01:58.619: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 16:01:58.622: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 16:02:00.619: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 16:02:00.622: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 16:02:02.619: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 16:02:02.625: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 16:02:04.619: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 16:02:04.622: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 16:02:06.619: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 16:02:06.622: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 16:02:08.620: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 16:02:08.622: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:02:08.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3531" for this suite.
Sep  6 16:02:20.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:02:20.702: INFO: namespace container-lifecycle-hook-3531 deletion completed in 12.070984055s

• [SLOW TEST:36.131 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:02:20.703: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Sep  6 16:02:22.786: INFO: Pod pod-hostip-b521f293-d0bf-11e9-a08c-82ce3d77f2cb has hostIP: 172.20.61.48
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:02:22.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8742" for this suite.
Sep  6 16:02:44.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:02:44.853: INFO: namespace pods-8742 deletion completed in 22.064394525s

• [SLOW TEST:24.150 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:02:44.853: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Sep  6 16:02:44.881: INFO: Waiting up to 5m0s for pod "var-expansion-c37fb974-d0bf-11e9-a08c-82ce3d77f2cb" in namespace "var-expansion-4875" to be "success or failure"
Sep  6 16:02:44.886: INFO: Pod "var-expansion-c37fb974-d0bf-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.292819ms
Sep  6 16:02:46.889: INFO: Pod "var-expansion-c37fb974-d0bf-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008412514s
STEP: Saw pod success
Sep  6 16:02:46.889: INFO: Pod "var-expansion-c37fb974-d0bf-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:02:46.891: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod var-expansion-c37fb974-d0bf-11e9-a08c-82ce3d77f2cb container dapi-container: <nil>
STEP: delete the pod
Sep  6 16:02:46.908: INFO: Waiting for pod var-expansion-c37fb974-d0bf-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:02:46.910: INFO: Pod var-expansion-c37fb974-d0bf-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:02:46.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4875" for this suite.
Sep  6 16:02:52.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:02:53.018: INFO: namespace var-expansion-4875 deletion completed in 6.105659116s

• [SLOW TEST:8.165 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:02:53.018: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-c863846b-d0bf-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume secrets
Sep  6 16:02:53.087: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c863efc2-d0bf-11e9-a08c-82ce3d77f2cb" in namespace "projected-5417" to be "success or failure"
Sep  6 16:02:53.091: INFO: Pod "pod-projected-secrets-c863efc2-d0bf-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.161994ms
Sep  6 16:02:55.095: INFO: Pod "pod-projected-secrets-c863efc2-d0bf-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007228268s
STEP: Saw pod success
Sep  6 16:02:55.095: INFO: Pod "pod-projected-secrets-c863efc2-d0bf-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:02:55.097: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-projected-secrets-c863efc2-d0bf-11e9-a08c-82ce3d77f2cb container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  6 16:02:55.109: INFO: Waiting for pod pod-projected-secrets-c863efc2-d0bf-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:02:55.111: INFO: Pod pod-projected-secrets-c863efc2-d0bf-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:02:55.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5417" for this suite.
Sep  6 16:03:01.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:03:01.177: INFO: namespace projected-5417 deletion completed in 6.064211675s

• [SLOW TEST:8.159 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:03:01.177: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-g6cj
STEP: Creating a pod to test atomic-volume-subpath
Sep  6 16:03:01.205: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-g6cj" in namespace "subpath-7683" to be "success or failure"
Sep  6 16:03:01.208: INFO: Pod "pod-subpath-test-secret-g6cj": Phase="Pending", Reason="", readiness=false. Elapsed: 3.171279ms
Sep  6 16:03:03.211: INFO: Pod "pod-subpath-test-secret-g6cj": Phase="Running", Reason="", readiness=true. Elapsed: 2.006030964s
Sep  6 16:03:05.214: INFO: Pod "pod-subpath-test-secret-g6cj": Phase="Running", Reason="", readiness=true. Elapsed: 4.009112457s
Sep  6 16:03:07.217: INFO: Pod "pod-subpath-test-secret-g6cj": Phase="Running", Reason="", readiness=true. Elapsed: 6.012006856s
Sep  6 16:03:09.220: INFO: Pod "pod-subpath-test-secret-g6cj": Phase="Running", Reason="", readiness=true. Elapsed: 8.015076332s
Sep  6 16:03:11.224: INFO: Pod "pod-subpath-test-secret-g6cj": Phase="Running", Reason="", readiness=true. Elapsed: 10.018637399s
Sep  6 16:03:13.227: INFO: Pod "pod-subpath-test-secret-g6cj": Phase="Running", Reason="", readiness=true. Elapsed: 12.021810333s
Sep  6 16:03:15.230: INFO: Pod "pod-subpath-test-secret-g6cj": Phase="Running", Reason="", readiness=true. Elapsed: 14.024765908s
Sep  6 16:03:17.233: INFO: Pod "pod-subpath-test-secret-g6cj": Phase="Running", Reason="", readiness=true. Elapsed: 16.027719534s
Sep  6 16:03:19.236: INFO: Pod "pod-subpath-test-secret-g6cj": Phase="Running", Reason="", readiness=true. Elapsed: 18.030681886s
Sep  6 16:03:21.239: INFO: Pod "pod-subpath-test-secret-g6cj": Phase="Running", Reason="", readiness=true. Elapsed: 20.033631662s
Sep  6 16:03:23.242: INFO: Pod "pod-subpath-test-secret-g6cj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.036615179s
STEP: Saw pod success
Sep  6 16:03:23.242: INFO: Pod "pod-subpath-test-secret-g6cj" satisfied condition "success or failure"
Sep  6 16:03:23.243: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-subpath-test-secret-g6cj container test-container-subpath-secret-g6cj: <nil>
STEP: delete the pod
Sep  6 16:03:23.256: INFO: Waiting for pod pod-subpath-test-secret-g6cj to disappear
Sep  6 16:03:23.258: INFO: Pod pod-subpath-test-secret-g6cj no longer exists
STEP: Deleting pod pod-subpath-test-secret-g6cj
Sep  6 16:03:23.258: INFO: Deleting pod "pod-subpath-test-secret-g6cj" in namespace "subpath-7683"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:03:23.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7683" for this suite.
Sep  6 16:03:29.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:03:29.340: INFO: namespace subpath-7683 deletion completed in 6.077098217s

• [SLOW TEST:28.163 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:03:29.340: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:03:31.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4378" for this suite.
Sep  6 16:04:13.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:04:13.445: INFO: namespace kubelet-test-4378 deletion completed in 42.066150315s

• [SLOW TEST:44.105 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:04:13.445: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Sep  6 16:04:13.468: INFO: Waiting up to 5m0s for pod "client-containers-f84d3048-d0bf-11e9-a08c-82ce3d77f2cb" in namespace "containers-1660" to be "success or failure"
Sep  6 16:04:13.471: INFO: Pod "client-containers-f84d3048-d0bf-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.759847ms
Sep  6 16:04:15.473: INFO: Pod "client-containers-f84d3048-d0bf-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005271302s
Sep  6 16:04:17.476: INFO: Pod "client-containers-f84d3048-d0bf-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008257654s
STEP: Saw pod success
Sep  6 16:04:17.476: INFO: Pod "client-containers-f84d3048-d0bf-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:04:17.478: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod client-containers-f84d3048-d0bf-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 16:04:17.490: INFO: Waiting for pod client-containers-f84d3048-d0bf-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:04:17.492: INFO: Pod client-containers-f84d3048-d0bf-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:04:17.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1660" for this suite.
Sep  6 16:04:23.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:04:23.561: INFO: namespace containers-1660 deletion completed in 6.066241273s

• [SLOW TEST:10.116 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:04:23.561: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-2593/configmap-test-fe54a2db-d0bf-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume configMaps
Sep  6 16:04:23.585: INFO: Waiting up to 5m0s for pod "pod-configmaps-fe54f508-d0bf-11e9-a08c-82ce3d77f2cb" in namespace "configmap-2593" to be "success or failure"
Sep  6 16:04:23.588: INFO: Pod "pod-configmaps-fe54f508-d0bf-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.434678ms
Sep  6 16:04:25.591: INFO: Pod "pod-configmaps-fe54f508-d0bf-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005360676s
STEP: Saw pod success
Sep  6 16:04:25.591: INFO: Pod "pod-configmaps-fe54f508-d0bf-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:04:25.592: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-configmaps-fe54f508-d0bf-11e9-a08c-82ce3d77f2cb container env-test: <nil>
STEP: delete the pod
Sep  6 16:04:25.605: INFO: Waiting for pod pod-configmaps-fe54f508-d0bf-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:04:25.607: INFO: Pod pod-configmaps-fe54f508-d0bf-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:04:25.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2593" for this suite.
Sep  6 16:04:31.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:04:31.682: INFO: namespace configmap-2593 deletion completed in 6.072194243s

• [SLOW TEST:8.121 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:04:31.682: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-810
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Sep  6 16:04:31.764: INFO: Found 0 stateful pods, waiting for 3
Sep  6 16:04:41.768: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 16:04:41.768: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 16:04:41.768: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep  6 16:04:41.789: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep  6 16:04:51.816: INFO: Updating stateful set ss2
Sep  6 16:04:51.828: INFO: Waiting for Pod statefulset-810/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep  6 16:05:01.833: INFO: Waiting for Pod statefulset-810/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Sep  6 16:05:11.882: INFO: Found 2 stateful pods, waiting for 3
Sep  6 16:05:21.885: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 16:05:21.885: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 16:05:21.885: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep  6 16:05:21.905: INFO: Updating stateful set ss2
Sep  6 16:05:21.913: INFO: Waiting for Pod statefulset-810/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep  6 16:05:31.932: INFO: Updating stateful set ss2
Sep  6 16:05:31.937: INFO: Waiting for StatefulSet statefulset-810/ss2 to complete update
Sep  6 16:05:31.937: INFO: Waiting for Pod statefulset-810/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep  6 16:05:41.941: INFO: Waiting for StatefulSet statefulset-810/ss2 to complete update
Sep  6 16:05:41.941: INFO: Waiting for Pod statefulset-810/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  6 16:05:51.944: INFO: Deleting all statefulset in ns statefulset-810
Sep  6 16:05:51.946: INFO: Scaling statefulset ss2 to 0
Sep  6 16:06:21.958: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 16:06:21.960: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:06:21.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-810" for this suite.
Sep  6 16:06:27.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:06:28.041: INFO: namespace statefulset-810 deletion completed in 6.071292051s

• [SLOW TEST:116.359 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:06:28.042: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 16:06:28.070: INFO: Create a RollingUpdate DaemonSet
Sep  6 16:06:28.074: INFO: Check that daemon pods launch on every node of the cluster
Sep  6 16:06:28.082: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:06:28.089: INFO: Number of nodes with available pods: 0
Sep  6 16:06:28.089: INFO: Node ip-172-20-60-162.us-east-2.compute.internal is running more than one daemon pod
Sep  6 16:06:29.092: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:06:29.094: INFO: Number of nodes with available pods: 0
Sep  6 16:06:29.094: INFO: Node ip-172-20-60-162.us-east-2.compute.internal is running more than one daemon pod
Sep  6 16:06:30.092: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:06:30.094: INFO: Number of nodes with available pods: 2
Sep  6 16:06:30.094: INFO: Number of running nodes: 2, number of available pods: 2
Sep  6 16:06:30.094: INFO: Update the DaemonSet to trigger a rollout
Sep  6 16:06:30.098: INFO: Updating DaemonSet daemon-set
Sep  6 16:06:34.105: INFO: Roll back the DaemonSet before rollout is complete
Sep  6 16:06:34.109: INFO: Updating DaemonSet daemon-set
Sep  6 16:06:34.109: INFO: Make sure DaemonSet rollback is complete
Sep  6 16:06:34.111: INFO: Wrong image for pod: daemon-set-fvcqz. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep  6 16:06:34.111: INFO: Pod daemon-set-fvcqz is not available
Sep  6 16:06:34.115: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:06:35.118: INFO: Wrong image for pod: daemon-set-fvcqz. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep  6 16:06:35.118: INFO: Pod daemon-set-fvcqz is not available
Sep  6 16:06:35.120: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:06:36.118: INFO: Pod daemon-set-c5mt7 is not available
Sep  6 16:06:36.120: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6273, will wait for the garbage collector to delete the pods
Sep  6 16:06:36.181: INFO: Deleting DaemonSet.extensions daemon-set took: 5.016542ms
Sep  6 16:06:36.481: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.338845ms
Sep  6 16:06:51.384: INFO: Number of nodes with available pods: 0
Sep  6 16:06:51.384: INFO: Number of running nodes: 0, number of available pods: 0
Sep  6 16:06:51.385: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6273/daemonsets","resourceVersion":"7373"},"items":null}

Sep  6 16:06:51.387: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6273/pods","resourceVersion":"7373"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:06:51.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6273" for this suite.
Sep  6 16:06:57.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:06:57.458: INFO: namespace daemonsets-6273 deletion completed in 6.062496435s

• [SLOW TEST:29.416 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:06:57.458: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-5a0f8244-d0c0-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume configMaps
Sep  6 16:06:57.483: INFO: Waiting up to 5m0s for pod "pod-configmaps-5a0fd5b2-d0c0-11e9-a08c-82ce3d77f2cb" in namespace "configmap-1835" to be "success or failure"
Sep  6 16:06:57.486: INFO: Pod "pod-configmaps-5a0fd5b2-d0c0-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.51996ms
Sep  6 16:06:59.489: INFO: Pod "pod-configmaps-5a0fd5b2-d0c0-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005117387s
STEP: Saw pod success
Sep  6 16:06:59.489: INFO: Pod "pod-configmaps-5a0fd5b2-d0c0-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:06:59.490: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-configmaps-5a0fd5b2-d0c0-11e9-a08c-82ce3d77f2cb container configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 16:06:59.503: INFO: Waiting for pod pod-configmaps-5a0fd5b2-d0c0-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:06:59.504: INFO: Pod pod-configmaps-5a0fd5b2-d0c0-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:06:59.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1835" for this suite.
Sep  6 16:07:05.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:07:05.570: INFO: namespace configmap-1835 deletion completed in 6.063639892s

• [SLOW TEST:8.112 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:07:05.570: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-5ee5b38b-d0c0-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume configMaps
Sep  6 16:07:05.597: INFO: Waiting up to 5m0s for pod "pod-configmaps-5ee6055f-d0c0-11e9-a08c-82ce3d77f2cb" in namespace "configmap-7433" to be "success or failure"
Sep  6 16:07:05.602: INFO: Pod "pod-configmaps-5ee6055f-d0c0-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.522331ms
Sep  6 16:07:07.605: INFO: Pod "pod-configmaps-5ee6055f-d0c0-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007562977s
STEP: Saw pod success
Sep  6 16:07:07.605: INFO: Pod "pod-configmaps-5ee6055f-d0c0-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:07:07.607: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-configmaps-5ee6055f-d0c0-11e9-a08c-82ce3d77f2cb container configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 16:07:07.620: INFO: Waiting for pod pod-configmaps-5ee6055f-d0c0-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:07:07.622: INFO: Pod pod-configmaps-5ee6055f-d0c0-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:07:07.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7433" for this suite.
Sep  6 16:07:13.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:07:13.686: INFO: namespace configmap-7433 deletion completed in 6.062123573s

• [SLOW TEST:8.116 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:07:13.686: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:07:13.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1518" for this suite.
Sep  6 16:07:19.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:07:19.799: INFO: namespace kubelet-test-1518 deletion completed in 6.070405688s

• [SLOW TEST:6.113 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:07:19.799: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  6 16:07:19.819: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  6 16:07:19.824: INFO: Waiting for terminating namespaces to be deleted...
Sep  6 16:07:19.825: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-60-162.us-east-2.compute.internal before test
Sep  6 16:07:19.829: INFO: kube-dns-66d58c65d5-rt2hs from kube-system started at 2019-09-06 15:22:54 +0000 UTC (3 container statuses recorded)
Sep  6 16:07:19.829: INFO: 	Container dnsmasq ready: true, restart count 0
Sep  6 16:07:19.829: INFO: 	Container kubedns ready: true, restart count 0
Sep  6 16:07:19.829: INFO: 	Container sidecar ready: true, restart count 0
Sep  6 16:07:19.829: INFO: kube-dns-autoscaler-6567f59ccb-gpkrr from kube-system started at 2019-09-06 15:22:51 +0000 UTC (1 container statuses recorded)
Sep  6 16:07:19.829: INFO: 	Container autoscaler ready: true, restart count 0
Sep  6 16:07:19.829: INFO: sonobuoy-systemd-logs-daemon-set-792ed0eef92d49d6-qsnlb from heptio-sonobuoy started at 2019-09-06 15:24:16 +0000 UTC (2 container statuses recorded)
Sep  6 16:07:19.829: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  6 16:07:19.829: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  6 16:07:19.829: INFO: kube-proxy-ip-172-20-60-162.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Sep  6 16:07:19.829: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-61-48.us-east-2.compute.internal before test
Sep  6 16:07:19.833: INFO: kube-dns-66d58c65d5-6dppm from kube-system started at 2019-09-06 15:22:51 +0000 UTC (3 container statuses recorded)
Sep  6 16:07:19.833: INFO: 	Container dnsmasq ready: true, restart count 0
Sep  6 16:07:19.833: INFO: 	Container kubedns ready: true, restart count 0
Sep  6 16:07:19.833: INFO: 	Container sidecar ready: true, restart count 0
Sep  6 16:07:19.833: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-06 15:24:11 +0000 UTC (1 container statuses recorded)
Sep  6 16:07:19.833: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  6 16:07:19.833: INFO: sonobuoy-systemd-logs-daemon-set-792ed0eef92d49d6-m2qh6 from heptio-sonobuoy started at 2019-09-06 15:24:16 +0000 UTC (2 container statuses recorded)
Sep  6 16:07:19.833: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  6 16:07:19.833: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  6 16:07:19.833: INFO: kube-proxy-ip-172-20-61-48.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Sep  6 16:07:19.833: INFO: sonobuoy-e2e-job-eb90599f41e04e4a from heptio-sonobuoy started at 2019-09-06 15:24:16 +0000 UTC (2 container statuses recorded)
Sep  6 16:07:19.833: INFO: 	Container e2e ready: true, restart count 0
Sep  6 16:07:19.833: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node ip-172-20-60-162.us-east-2.compute.internal
STEP: verifying the node has the label node ip-172-20-61-48.us-east-2.compute.internal
Sep  6 16:07:19.855: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-20-61-48.us-east-2.compute.internal
Sep  6 16:07:19.855: INFO: Pod sonobuoy-e2e-job-eb90599f41e04e4a requesting resource cpu=0m on Node ip-172-20-61-48.us-east-2.compute.internal
Sep  6 16:07:19.855: INFO: Pod sonobuoy-systemd-logs-daemon-set-792ed0eef92d49d6-m2qh6 requesting resource cpu=0m on Node ip-172-20-61-48.us-east-2.compute.internal
Sep  6 16:07:19.855: INFO: Pod sonobuoy-systemd-logs-daemon-set-792ed0eef92d49d6-qsnlb requesting resource cpu=0m on Node ip-172-20-60-162.us-east-2.compute.internal
Sep  6 16:07:19.855: INFO: Pod kube-dns-66d58c65d5-6dppm requesting resource cpu=260m on Node ip-172-20-61-48.us-east-2.compute.internal
Sep  6 16:07:19.855: INFO: Pod kube-dns-66d58c65d5-rt2hs requesting resource cpu=260m on Node ip-172-20-60-162.us-east-2.compute.internal
Sep  6 16:07:19.855: INFO: Pod kube-dns-autoscaler-6567f59ccb-gpkrr requesting resource cpu=20m on Node ip-172-20-60-162.us-east-2.compute.internal
Sep  6 16:07:19.855: INFO: Pod kube-proxy-ip-172-20-60-162.us-east-2.compute.internal requesting resource cpu=100m on Node ip-172-20-60-162.us-east-2.compute.internal
Sep  6 16:07:19.855: INFO: Pod kube-proxy-ip-172-20-61-48.us-east-2.compute.internal requesting resource cpu=100m on Node ip-172-20-61-48.us-east-2.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-67661505-d0c0-11e9-a08c-82ce3d77f2cb.15c1e518c523e801], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9596/filler-pod-67661505-d0c0-11e9-a08c-82ce3d77f2cb to ip-172-20-60-162.us-east-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-67661505-d0c0-11e9-a08c-82ce3d77f2cb.15c1e518f25e0dd0], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-67661505-d0c0-11e9-a08c-82ce3d77f2cb.15c1e518f514ad29], Reason = [Created], Message = [Created container filler-pod-67661505-d0c0-11e9-a08c-82ce3d77f2cb]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-67661505-d0c0-11e9-a08c-82ce3d77f2cb.15c1e518ff5b584a], Reason = [Started], Message = [Started container filler-pod-67661505-d0c0-11e9-a08c-82ce3d77f2cb]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6766c19d-d0c0-11e9-a08c-82ce3d77f2cb.15c1e518c590e64e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9596/filler-pod-6766c19d-d0c0-11e9-a08c-82ce3d77f2cb to ip-172-20-61-48.us-east-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6766c19d-d0c0-11e9-a08c-82ce3d77f2cb.15c1e518f0494602], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6766c19d-d0c0-11e9-a08c-82ce3d77f2cb.15c1e518f2fcd6aa], Reason = [Created], Message = [Created container filler-pod-6766c19d-d0c0-11e9-a08c-82ce3d77f2cb]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6766c19d-d0c0-11e9-a08c-82ce3d77f2cb.15c1e518ff2b9b44], Reason = [Started], Message = [Started container filler-pod-6766c19d-d0c0-11e9-a08c-82ce3d77f2cb]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c1e5193d4a3c5c], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node ip-172-20-60-162.us-east-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-20-61-48.us-east-2.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:07:22.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9596" for this suite.
Sep  6 16:07:28.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:07:28.972: INFO: namespace sched-pred-9596 deletion completed in 6.066646768s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.173 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:07:28.972: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep  6 16:07:28.996: INFO: Waiting up to 5m0s for pod "pod-6cd84544-d0c0-11e9-a08c-82ce3d77f2cb" in namespace "emptydir-9406" to be "success or failure"
Sep  6 16:07:28.999: INFO: Pod "pod-6cd84544-d0c0-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.242102ms
Sep  6 16:07:31.002: INFO: Pod "pod-6cd84544-d0c0-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006095783s
Sep  6 16:07:33.005: INFO: Pod "pod-6cd84544-d0c0-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009203986s
STEP: Saw pod success
Sep  6 16:07:33.005: INFO: Pod "pod-6cd84544-d0c0-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:07:33.007: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-6cd84544-d0c0-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 16:07:33.019: INFO: Waiting for pod pod-6cd84544-d0c0-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:07:33.021: INFO: Pod pod-6cd84544-d0c0-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:07:33.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9406" for this suite.
Sep  6 16:07:39.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:07:39.086: INFO: namespace emptydir-9406 deletion completed in 6.063433069s

• [SLOW TEST:10.114 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:07:39.087: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-2793
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  6 16:07:39.107: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  6 16:08:01.154: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.112:8080/dial?request=hostName&protocol=udp&host=100.96.2.111&port=8081&tries=1'] Namespace:pod-network-test-2793 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 16:08:01.154: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 16:08:01.244: INFO: Waiting for endpoints: map[]
Sep  6 16:08:01.246: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.112:8080/dial?request=hostName&protocol=udp&host=100.96.1.80&port=8081&tries=1'] Namespace:pod-network-test-2793 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 16:08:01.246: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 16:08:01.336: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:08:01.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2793" for this suite.
Sep  6 16:08:23.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:08:23.409: INFO: namespace pod-network-test-2793 deletion completed in 22.0707079s

• [SLOW TEST:44.323 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:08:23.410: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-8d4ae53a-d0c0-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume configMaps
Sep  6 16:08:23.436: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8d4b32be-d0c0-11e9-a08c-82ce3d77f2cb" in namespace "projected-6975" to be "success or failure"
Sep  6 16:08:23.439: INFO: Pod "pod-projected-configmaps-8d4b32be-d0c0-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.610489ms
Sep  6 16:08:25.442: INFO: Pod "pod-projected-configmaps-8d4b32be-d0c0-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005853431s
STEP: Saw pod success
Sep  6 16:08:25.442: INFO: Pod "pod-projected-configmaps-8d4b32be-d0c0-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:08:25.444: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-projected-configmaps-8d4b32be-d0c0-11e9-a08c-82ce3d77f2cb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 16:08:25.458: INFO: Waiting for pod pod-projected-configmaps-8d4b32be-d0c0-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:08:25.459: INFO: Pod pod-projected-configmaps-8d4b32be-d0c0-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:08:25.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6975" for this suite.
Sep  6 16:08:31.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:08:31.525: INFO: namespace projected-6975 deletion completed in 6.063220756s

• [SLOW TEST:8.115 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:08:31.525: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-92210d45-d0c0-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume secrets
Sep  6 16:08:31.567: INFO: Waiting up to 5m0s for pod "pod-secrets-9223debd-d0c0-11e9-a08c-82ce3d77f2cb" in namespace "secrets-4607" to be "success or failure"
Sep  6 16:08:31.570: INFO: Pod "pod-secrets-9223debd-d0c0-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.969141ms
Sep  6 16:08:33.572: INFO: Pod "pod-secrets-9223debd-d0c0-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005848905s
STEP: Saw pod success
Sep  6 16:08:33.573: INFO: Pod "pod-secrets-9223debd-d0c0-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:08:33.574: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-secrets-9223debd-d0c0-11e9-a08c-82ce3d77f2cb container secret-volume-test: <nil>
STEP: delete the pod
Sep  6 16:08:33.586: INFO: Waiting for pod pod-secrets-9223debd-d0c0-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:08:33.588: INFO: Pod pod-secrets-9223debd-d0c0-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:08:33.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4607" for this suite.
Sep  6 16:08:39.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:08:39.652: INFO: namespace secrets-4607 deletion completed in 6.061961965s
STEP: Destroying namespace "secret-namespace-3390" for this suite.
Sep  6 16:08:45.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:08:45.721: INFO: namespace secret-namespace-3390 deletion completed in 6.069417285s

• [SLOW TEST:14.196 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:08:45.722: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep  6 16:08:45.741: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:08:48.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5311" for this suite.
Sep  6 16:08:54.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:08:54.507: INFO: namespace init-container-5311 deletion completed in 6.062200802s

• [SLOW TEST:8.785 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:08:54.507: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep  6 16:08:54.537: INFO: Waiting up to 5m0s for pod "downward-api-9fd3caf1-d0c0-11e9-a08c-82ce3d77f2cb" in namespace "downward-api-1308" to be "success or failure"
Sep  6 16:08:54.543: INFO: Pod "downward-api-9fd3caf1-d0c0-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.348008ms
Sep  6 16:08:56.546: INFO: Pod "downward-api-9fd3caf1-d0c0-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009420994s
STEP: Saw pod success
Sep  6 16:08:56.546: INFO: Pod "downward-api-9fd3caf1-d0c0-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:08:56.548: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod downward-api-9fd3caf1-d0c0-11e9-a08c-82ce3d77f2cb container dapi-container: <nil>
STEP: delete the pod
Sep  6 16:08:56.560: INFO: Waiting for pod downward-api-9fd3caf1-d0c0-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:08:56.562: INFO: Pod downward-api-9fd3caf1-d0c0-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:08:56.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1308" for this suite.
Sep  6 16:09:02.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:09:02.630: INFO: namespace downward-api-1308 deletion completed in 6.06532744s

• [SLOW TEST:8.123 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:09:02.630: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0906 16:09:03.679376      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  6 16:09:03.679: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:09:03.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5027" for this suite.
Sep  6 16:09:09.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:09:09.747: INFO: namespace gc-5027 deletion completed in 6.065628607s

• [SLOW TEST:7.117 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:09:09.747: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-1886
Sep  6 16:09:13.777: INFO: Started pod liveness-http in namespace container-probe-1886
STEP: checking the pod's current state and verifying that restartCount is present
Sep  6 16:09:13.779: INFO: Initial restart count of pod liveness-http is 0
Sep  6 16:09:25.798: INFO: Restart count of pod container-probe-1886/liveness-http is now 1 (12.018581868s elapsed)
Sep  6 16:09:45.827: INFO: Restart count of pod container-probe-1886/liveness-http is now 2 (32.047689892s elapsed)
Sep  6 16:10:05.856: INFO: Restart count of pod container-probe-1886/liveness-http is now 3 (52.076712854s elapsed)
Sep  6 16:10:25.888: INFO: Restart count of pod container-probe-1886/liveness-http is now 4 (1m12.109017081s elapsed)
Sep  6 16:11:27.991: INFO: Restart count of pod container-probe-1886/liveness-http is now 5 (2m14.211913474s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:11:28.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1886" for this suite.
Sep  6 16:11:34.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:11:34.095: INFO: namespace container-probe-1886 deletion completed in 6.08840837s

• [SLOW TEST:144.348 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:11:34.096: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-fef37039-d0c0-11e9-a08c-82ce3d77f2cb
STEP: Creating secret with name s-test-opt-upd-fef3716b-d0c0-11e9-a08c-82ce3d77f2cb
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-fef37039-d0c0-11e9-a08c-82ce3d77f2cb
STEP: Updating secret s-test-opt-upd-fef3716b-d0c0-11e9-a08c-82ce3d77f2cb
STEP: Creating secret with name s-test-opt-create-fef371ab-d0c0-11e9-a08c-82ce3d77f2cb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:11:38.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3096" for this suite.
Sep  6 16:12:00.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:12:00.248: INFO: namespace secrets-3096 deletion completed in 22.066927152s

• [SLOW TEST:26.152 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:12:00.248: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-499
Sep  6 16:12:02.282: INFO: Started pod liveness-exec in namespace container-probe-499
STEP: checking the pod's current state and verifying that restartCount is present
Sep  6 16:12:02.284: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:16:02.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-499" for this suite.
Sep  6 16:16:08.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:16:08.754: INFO: namespace container-probe-499 deletion completed in 6.081561212s

• [SLOW TEST:248.506 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:16:08.755: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-6507
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-6507
STEP: Deleting pre-stop pod
Sep  6 16:16:19.800: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:16:19.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6507" for this suite.
Sep  6 16:16:57.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:16:57.877: INFO: namespace prestop-6507 deletion completed in 38.069619855s

• [SLOW TEST:49.122 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:16:57.877: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Sep  6 16:16:57.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 create -f - --namespace=kubectl-5164'
Sep  6 16:16:58.246: INFO: stderr: ""
Sep  6 16:16:58.246: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  6 16:16:58.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5164'
Sep  6 16:16:58.318: INFO: stderr: ""
Sep  6 16:16:58.318: INFO: stdout: "update-demo-nautilus-624f2 update-demo-nautilus-dfbd8 "
Sep  6 16:16:58.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-624f2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5164'
Sep  6 16:16:58.385: INFO: stderr: ""
Sep  6 16:16:58.385: INFO: stdout: ""
Sep  6 16:16:58.385: INFO: update-demo-nautilus-624f2 is created but not running
Sep  6 16:17:03.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5164'
Sep  6 16:17:03.454: INFO: stderr: ""
Sep  6 16:17:03.454: INFO: stdout: "update-demo-nautilus-624f2 update-demo-nautilus-dfbd8 "
Sep  6 16:17:03.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-624f2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5164'
Sep  6 16:17:03.521: INFO: stderr: ""
Sep  6 16:17:03.521: INFO: stdout: "true"
Sep  6 16:17:03.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-624f2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5164'
Sep  6 16:17:03.587: INFO: stderr: ""
Sep  6 16:17:03.587: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 16:17:03.587: INFO: validating pod update-demo-nautilus-624f2
Sep  6 16:17:03.591: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 16:17:03.591: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 16:17:03.591: INFO: update-demo-nautilus-624f2 is verified up and running
Sep  6 16:17:03.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-dfbd8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5164'
Sep  6 16:17:03.682: INFO: stderr: ""
Sep  6 16:17:03.682: INFO: stdout: "true"
Sep  6 16:17:03.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-dfbd8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5164'
Sep  6 16:17:03.754: INFO: stderr: ""
Sep  6 16:17:03.754: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 16:17:03.754: INFO: validating pod update-demo-nautilus-dfbd8
Sep  6 16:17:03.757: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 16:17:03.757: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 16:17:03.757: INFO: update-demo-nautilus-dfbd8 is verified up and running
STEP: scaling down the replication controller
Sep  6 16:17:03.759: INFO: scanned /root for discovery docs: <nil>
Sep  6 16:17:03.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-5164'
Sep  6 16:17:04.856: INFO: stderr: ""
Sep  6 16:17:04.856: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  6 16:17:04.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5164'
Sep  6 16:17:04.931: INFO: stderr: ""
Sep  6 16:17:04.931: INFO: stdout: "update-demo-nautilus-624f2 update-demo-nautilus-dfbd8 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep  6 16:17:09.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5164'
Sep  6 16:17:10.003: INFO: stderr: ""
Sep  6 16:17:10.003: INFO: stdout: "update-demo-nautilus-624f2 "
Sep  6 16:17:10.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-624f2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5164'
Sep  6 16:17:10.071: INFO: stderr: ""
Sep  6 16:17:10.071: INFO: stdout: "true"
Sep  6 16:17:10.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-624f2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5164'
Sep  6 16:17:10.139: INFO: stderr: ""
Sep  6 16:17:10.139: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 16:17:10.139: INFO: validating pod update-demo-nautilus-624f2
Sep  6 16:17:10.141: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 16:17:10.141: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 16:17:10.141: INFO: update-demo-nautilus-624f2 is verified up and running
STEP: scaling up the replication controller
Sep  6 16:17:10.143: INFO: scanned /root for discovery docs: <nil>
Sep  6 16:17:10.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-5164'
Sep  6 16:17:11.237: INFO: stderr: ""
Sep  6 16:17:11.237: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  6 16:17:11.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5164'
Sep  6 16:17:11.313: INFO: stderr: ""
Sep  6 16:17:11.313: INFO: stdout: "update-demo-nautilus-624f2 update-demo-nautilus-mzzbf "
Sep  6 16:17:11.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-624f2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5164'
Sep  6 16:17:11.380: INFO: stderr: ""
Sep  6 16:17:11.380: INFO: stdout: "true"
Sep  6 16:17:11.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-624f2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5164'
Sep  6 16:17:11.447: INFO: stderr: ""
Sep  6 16:17:11.447: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 16:17:11.447: INFO: validating pod update-demo-nautilus-624f2
Sep  6 16:17:11.449: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 16:17:11.449: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 16:17:11.449: INFO: update-demo-nautilus-624f2 is verified up and running
Sep  6 16:17:11.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-mzzbf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5164'
Sep  6 16:17:11.517: INFO: stderr: ""
Sep  6 16:17:11.517: INFO: stdout: ""
Sep  6 16:17:11.517: INFO: update-demo-nautilus-mzzbf is created but not running
Sep  6 16:17:16.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5164'
Sep  6 16:17:16.587: INFO: stderr: ""
Sep  6 16:17:16.587: INFO: stdout: "update-demo-nautilus-624f2 update-demo-nautilus-mzzbf "
Sep  6 16:17:16.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-624f2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5164'
Sep  6 16:17:16.654: INFO: stderr: ""
Sep  6 16:17:16.654: INFO: stdout: "true"
Sep  6 16:17:16.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-624f2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5164'
Sep  6 16:17:16.721: INFO: stderr: ""
Sep  6 16:17:16.721: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 16:17:16.721: INFO: validating pod update-demo-nautilus-624f2
Sep  6 16:17:16.724: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 16:17:16.724: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 16:17:16.724: INFO: update-demo-nautilus-624f2 is verified up and running
Sep  6 16:17:16.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-mzzbf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5164'
Sep  6 16:17:16.790: INFO: stderr: ""
Sep  6 16:17:16.790: INFO: stdout: "true"
Sep  6 16:17:16.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods update-demo-nautilus-mzzbf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5164'
Sep  6 16:17:16.858: INFO: stderr: ""
Sep  6 16:17:16.858: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 16:17:16.858: INFO: validating pod update-demo-nautilus-mzzbf
Sep  6 16:17:16.863: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 16:17:16.863: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 16:17:16.863: INFO: update-demo-nautilus-mzzbf is verified up and running
STEP: using delete to clean up resources
Sep  6 16:17:16.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 delete --grace-period=0 --force -f - --namespace=kubectl-5164'
Sep  6 16:17:16.944: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 16:17:16.944: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  6 16:17:16.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5164'
Sep  6 16:17:17.018: INFO: stderr: "No resources found.\n"
Sep  6 16:17:17.018: INFO: stdout: ""
Sep  6 16:17:17.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -l name=update-demo --namespace=kubectl-5164 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  6 16:17:17.090: INFO: stderr: ""
Sep  6 16:17:17.090: INFO: stdout: "update-demo-nautilus-624f2\nupdate-demo-nautilus-mzzbf\n"
Sep  6 16:17:17.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5164'
Sep  6 16:17:17.663: INFO: stderr: "No resources found.\n"
Sep  6 16:17:17.663: INFO: stdout: ""
Sep  6 16:17:17.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -l name=update-demo --namespace=kubectl-5164 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  6 16:17:17.736: INFO: stderr: ""
Sep  6 16:17:17.736: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:17:17.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5164" for this suite.
Sep  6 16:17:23.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:17:23.817: INFO: namespace kubectl-5164 deletion completed in 6.077669449s

• [SLOW TEST:25.940 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:17:23.818: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Sep  6 16:17:23.842: INFO: Waiting up to 5m0s for pod "var-expansion-cf669797-d0c1-11e9-a08c-82ce3d77f2cb" in namespace "var-expansion-2045" to be "success or failure"
Sep  6 16:17:23.844: INFO: Pod "var-expansion-cf669797-d0c1-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.225869ms
Sep  6 16:17:25.847: INFO: Pod "var-expansion-cf669797-d0c1-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005196823s
STEP: Saw pod success
Sep  6 16:17:25.847: INFO: Pod "var-expansion-cf669797-d0c1-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:17:25.849: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod var-expansion-cf669797-d0c1-11e9-a08c-82ce3d77f2cb container dapi-container: <nil>
STEP: delete the pod
Sep  6 16:17:25.863: INFO: Waiting for pod var-expansion-cf669797-d0c1-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:17:25.865: INFO: Pod var-expansion-cf669797-d0c1-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:17:25.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2045" for this suite.
Sep  6 16:17:31.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:17:31.932: INFO: namespace var-expansion-2045 deletion completed in 6.065012019s

• [SLOW TEST:8.114 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:17:31.932: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Sep  6 16:17:31.965: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:17:41.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4211" for this suite.
Sep  6 16:17:47.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:17:47.381: INFO: namespace pods-4211 deletion completed in 6.067365844s

• [SLOW TEST:15.449 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:17:47.382: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-l6j9
STEP: Creating a pod to test atomic-volume-subpath
Sep  6 16:17:47.411: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-l6j9" in namespace "subpath-4499" to be "success or failure"
Sep  6 16:17:47.412: INFO: Pod "pod-subpath-test-downwardapi-l6j9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.885161ms
Sep  6 16:17:49.416: INFO: Pod "pod-subpath-test-downwardapi-l6j9": Phase="Running", Reason="", readiness=true. Elapsed: 2.005049078s
Sep  6 16:17:51.418: INFO: Pod "pod-subpath-test-downwardapi-l6j9": Phase="Running", Reason="", readiness=true. Elapsed: 4.007496809s
Sep  6 16:17:53.421: INFO: Pod "pod-subpath-test-downwardapi-l6j9": Phase="Running", Reason="", readiness=true. Elapsed: 6.01044831s
Sep  6 16:17:55.424: INFO: Pod "pod-subpath-test-downwardapi-l6j9": Phase="Running", Reason="", readiness=true. Elapsed: 8.013586926s
Sep  6 16:17:57.427: INFO: Pod "pod-subpath-test-downwardapi-l6j9": Phase="Running", Reason="", readiness=true. Elapsed: 10.01650044s
Sep  6 16:17:59.430: INFO: Pod "pod-subpath-test-downwardapi-l6j9": Phase="Running", Reason="", readiness=true. Elapsed: 12.019517062s
Sep  6 16:18:01.433: INFO: Pod "pod-subpath-test-downwardapi-l6j9": Phase="Running", Reason="", readiness=true. Elapsed: 14.02254019s
Sep  6 16:18:03.436: INFO: Pod "pod-subpath-test-downwardapi-l6j9": Phase="Running", Reason="", readiness=true. Elapsed: 16.025538013s
Sep  6 16:18:05.439: INFO: Pod "pod-subpath-test-downwardapi-l6j9": Phase="Running", Reason="", readiness=true. Elapsed: 18.028476847s
Sep  6 16:18:07.442: INFO: Pod "pod-subpath-test-downwardapi-l6j9": Phase="Running", Reason="", readiness=true. Elapsed: 20.031542479s
Sep  6 16:18:09.445: INFO: Pod "pod-subpath-test-downwardapi-l6j9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.034781821s
STEP: Saw pod success
Sep  6 16:18:09.445: INFO: Pod "pod-subpath-test-downwardapi-l6j9" satisfied condition "success or failure"
Sep  6 16:18:09.447: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-subpath-test-downwardapi-l6j9 container test-container-subpath-downwardapi-l6j9: <nil>
STEP: delete the pod
Sep  6 16:18:09.460: INFO: Waiting for pod pod-subpath-test-downwardapi-l6j9 to disappear
Sep  6 16:18:09.462: INFO: Pod pod-subpath-test-downwardapi-l6j9 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-l6j9
Sep  6 16:18:09.462: INFO: Deleting pod "pod-subpath-test-downwardapi-l6j9" in namespace "subpath-4499"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:18:09.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4499" for this suite.
Sep  6 16:18:15.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:18:15.534: INFO: namespace subpath-4499 deletion completed in 6.067539526s

• [SLOW TEST:28.152 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:18:15.534: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-9200
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  6 16:18:15.555: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  6 16:18:33.604: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.125:8080/dial?request=hostName&protocol=http&host=100.96.1.87&port=8080&tries=1'] Namespace:pod-network-test-9200 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 16:18:33.604: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 16:18:33.696: INFO: Waiting for endpoints: map[]
Sep  6 16:18:33.699: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.125:8080/dial?request=hostName&protocol=http&host=100.96.2.124&port=8080&tries=1'] Namespace:pod-network-test-9200 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 16:18:33.699: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 16:18:33.819: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:18:33.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9200" for this suite.
Sep  6 16:18:55.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:18:55.900: INFO: namespace pod-network-test-9200 deletion completed in 22.077604785s

• [SLOW TEST:40.367 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:18:55.901: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 16:18:55.978: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0651502a-d0c2-11e9-a08c-82ce3d77f2cb" in namespace "downward-api-6541" to be "success or failure"
Sep  6 16:18:55.981: INFO: Pod "downwardapi-volume-0651502a-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.665403ms
Sep  6 16:18:57.984: INFO: Pod "downwardapi-volume-0651502a-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005780712s
STEP: Saw pod success
Sep  6 16:18:57.984: INFO: Pod "downwardapi-volume-0651502a-d0c2-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:18:57.986: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod downwardapi-volume-0651502a-d0c2-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 16:18:58.004: INFO: Waiting for pod downwardapi-volume-0651502a-d0c2-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:18:58.006: INFO: Pod downwardapi-volume-0651502a-d0c2-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:18:58.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6541" for this suite.
Sep  6 16:19:04.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:19:04.078: INFO: namespace downward-api-6541 deletion completed in 6.069939711s

• [SLOW TEST:8.178 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:19:04.079: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-0b2910f7-d0c2-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume secrets
Sep  6 16:19:04.116: INFO: Waiting up to 5m0s for pod "pod-secrets-0b2af175-d0c2-11e9-a08c-82ce3d77f2cb" in namespace "secrets-7921" to be "success or failure"
Sep  6 16:19:04.119: INFO: Pod "pod-secrets-0b2af175-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.216644ms
Sep  6 16:19:06.122: INFO: Pod "pod-secrets-0b2af175-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006560196s
STEP: Saw pod success
Sep  6 16:19:06.122: INFO: Pod "pod-secrets-0b2af175-d0c2-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:19:06.124: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-secrets-0b2af175-d0c2-11e9-a08c-82ce3d77f2cb container secret-volume-test: <nil>
STEP: delete the pod
Sep  6 16:19:06.140: INFO: Waiting for pod pod-secrets-0b2af175-d0c2-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:19:06.142: INFO: Pod pod-secrets-0b2af175-d0c2-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:19:06.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7921" for this suite.
Sep  6 16:19:12.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:19:12.228: INFO: namespace secrets-7921 deletion completed in 6.082671611s

• [SLOW TEST:8.149 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:19:12.228: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9307
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-9307
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9307
Sep  6 16:19:12.267: INFO: Found 0 stateful pods, waiting for 1
Sep  6 16:19:22.270: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep  6 16:19:22.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-9307 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 16:19:22.439: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  6 16:19:22.439: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 16:19:22.439: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 16:19:22.442: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  6 16:19:32.445: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  6 16:19:32.445: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 16:19:32.455: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Sep  6 16:19:32.455: INFO: ss-0  ip-172-20-61-48.us-east-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  }]
Sep  6 16:19:32.455: INFO: 
Sep  6 16:19:32.455: INFO: StatefulSet ss has not reached scale 3, at 1
Sep  6 16:19:33.458: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996829188s
Sep  6 16:19:34.461: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993588492s
Sep  6 16:19:35.464: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.990514093s
Sep  6 16:19:36.468: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.987495358s
Sep  6 16:19:37.471: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.984395856s
Sep  6 16:19:38.474: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.981256267s
Sep  6 16:19:39.478: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.978108943s
Sep  6 16:19:40.481: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.974356046s
Sep  6 16:19:41.484: INFO: Verifying statefulset ss doesn't scale past 3 for another 970.967072ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9307
Sep  6 16:19:42.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-9307 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 16:19:42.646: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  6 16:19:42.646: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  6 16:19:42.646: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  6 16:19:42.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-9307 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 16:19:42.810: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep  6 16:19:42.810: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  6 16:19:42.810: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  6 16:19:42.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-9307 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 16:19:42.967: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep  6 16:19:42.967: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  6 16:19:42.967: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  6 16:19:42.970: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Sep  6 16:19:52.973: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 16:19:52.973: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 16:19:52.973: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep  6 16:19:52.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-9307 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 16:19:53.149: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  6 16:19:53.149: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 16:19:53.149: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 16:19:53.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-9307 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 16:19:53.312: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  6 16:19:53.312: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 16:19:53.312: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 16:19:53.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 exec --namespace=statefulset-9307 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 16:19:53.489: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  6 16:19:53.489: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 16:19:53.489: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 16:19:53.490: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 16:19:53.492: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Sep  6 16:20:03.497: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  6 16:20:03.497: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  6 16:20:03.497: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  6 16:20:03.505: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Sep  6 16:20:03.505: INFO: ss-0  ip-172-20-61-48.us-east-2.compute.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  }]
Sep  6 16:20:03.505: INFO: ss-1  ip-172-20-60-162.us-east-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:32 +0000 UTC  }]
Sep  6 16:20:03.505: INFO: ss-2  ip-172-20-60-162.us-east-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:32 +0000 UTC  }]
Sep  6 16:20:03.505: INFO: 
Sep  6 16:20:03.505: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  6 16:20:04.509: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Sep  6 16:20:04.509: INFO: ss-0  ip-172-20-61-48.us-east-2.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  }]
Sep  6 16:20:04.509: INFO: ss-1  ip-172-20-60-162.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:32 +0000 UTC  }]
Sep  6 16:20:04.509: INFO: ss-2  ip-172-20-60-162.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:32 +0000 UTC  }]
Sep  6 16:20:04.509: INFO: 
Sep  6 16:20:04.509: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  6 16:20:05.512: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Sep  6 16:20:05.512: INFO: ss-0  ip-172-20-61-48.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  }]
Sep  6 16:20:05.512: INFO: 
Sep  6 16:20:05.512: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  6 16:20:06.515: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Sep  6 16:20:06.515: INFO: ss-0  ip-172-20-61-48.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  }]
Sep  6 16:20:06.515: INFO: 
Sep  6 16:20:06.515: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  6 16:20:07.518: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Sep  6 16:20:07.518: INFO: ss-0  ip-172-20-61-48.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  }]
Sep  6 16:20:07.518: INFO: 
Sep  6 16:20:07.518: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  6 16:20:08.521: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Sep  6 16:20:08.521: INFO: ss-0  ip-172-20-61-48.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  }]
Sep  6 16:20:08.521: INFO: 
Sep  6 16:20:08.521: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  6 16:20:09.524: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Sep  6 16:20:09.524: INFO: ss-0  ip-172-20-61-48.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  }]
Sep  6 16:20:09.524: INFO: 
Sep  6 16:20:09.524: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  6 16:20:10.528: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Sep  6 16:20:10.528: INFO: ss-0  ip-172-20-61-48.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:19:12 +0000 UTC  }]
Sep  6 16:20:10.528: INFO: 
Sep  6 16:20:10.528: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  6 16:20:11.531: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.973867423s
Sep  6 16:20:12.534: INFO: Verifying statefulset ss doesn't scale past 0 for another 971.062089ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9307
Sep  6 16:20:13.613: INFO: Scaling statefulset ss to 0
Sep  6 16:20:13.620: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  6 16:20:13.622: INFO: Deleting all statefulset in ns statefulset-9307
Sep  6 16:20:13.623: INFO: Scaling statefulset ss to 0
Sep  6 16:20:13.630: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 16:20:13.632: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:20:13.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9307" for this suite.
Sep  6 16:20:19.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:20:19.715: INFO: namespace statefulset-9307 deletion completed in 6.068890403s

• [SLOW TEST:67.487 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:20:19.715: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  6 16:20:19.735: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  6 16:20:19.740: INFO: Waiting for terminating namespaces to be deleted...
Sep  6 16:20:19.741: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-60-162.us-east-2.compute.internal before test
Sep  6 16:20:19.745: INFO: kube-dns-autoscaler-6567f59ccb-gpkrr from kube-system started at 2019-09-06 15:22:51 +0000 UTC (1 container statuses recorded)
Sep  6 16:20:19.745: INFO: 	Container autoscaler ready: true, restart count 0
Sep  6 16:20:19.745: INFO: kube-proxy-ip-172-20-60-162.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Sep  6 16:20:19.745: INFO: sonobuoy-systemd-logs-daemon-set-792ed0eef92d49d6-qsnlb from heptio-sonobuoy started at 2019-09-06 15:24:16 +0000 UTC (2 container statuses recorded)
Sep  6 16:20:19.745: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  6 16:20:19.745: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  6 16:20:19.745: INFO: kube-dns-66d58c65d5-rt2hs from kube-system started at 2019-09-06 15:22:54 +0000 UTC (3 container statuses recorded)
Sep  6 16:20:19.745: INFO: 	Container dnsmasq ready: true, restart count 0
Sep  6 16:20:19.745: INFO: 	Container kubedns ready: true, restart count 0
Sep  6 16:20:19.745: INFO: 	Container sidecar ready: true, restart count 0
Sep  6 16:20:19.745: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-61-48.us-east-2.compute.internal before test
Sep  6 16:20:19.750: INFO: kube-proxy-ip-172-20-61-48.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Sep  6 16:20:19.750: INFO: sonobuoy-e2e-job-eb90599f41e04e4a from heptio-sonobuoy started at 2019-09-06 15:24:16 +0000 UTC (2 container statuses recorded)
Sep  6 16:20:19.750: INFO: 	Container e2e ready: true, restart count 0
Sep  6 16:20:19.750: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  6 16:20:19.750: INFO: kube-dns-66d58c65d5-6dppm from kube-system started at 2019-09-06 15:22:51 +0000 UTC (3 container statuses recorded)
Sep  6 16:20:19.750: INFO: 	Container dnsmasq ready: true, restart count 0
Sep  6 16:20:19.750: INFO: 	Container kubedns ready: true, restart count 0
Sep  6 16:20:19.750: INFO: 	Container sidecar ready: true, restart count 0
Sep  6 16:20:19.750: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-06 15:24:11 +0000 UTC (1 container statuses recorded)
Sep  6 16:20:19.750: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  6 16:20:19.750: INFO: sonobuoy-systemd-logs-daemon-set-792ed0eef92d49d6-m2qh6 from heptio-sonobuoy started at 2019-09-06 15:24:16 +0000 UTC (2 container statuses recorded)
Sep  6 16:20:19.750: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  6 16:20:19.750: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c1e5ce5a9a828e], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:20:20.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2124" for this suite.
Sep  6 16:20:26.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:20:26.829: INFO: namespace sched-pred-2124 deletion completed in 6.062397458s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.114 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:20:26.829: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1521
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  6 16:20:26.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-1357'
Sep  6 16:20:26.937: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  6 16:20:26.937: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1526
Sep  6 16:20:28.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 delete deployment e2e-test-nginx-deployment --namespace=kubectl-1357'
Sep  6 16:20:29.031: INFO: stderr: ""
Sep  6 16:20:29.031: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:20:29.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1357" for this suite.
Sep  6 16:20:51.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:20:51.110: INFO: namespace kubectl-1357 deletion completed in 22.074805649s

• [SLOW TEST:24.281 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:20:51.111: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-4afed338-d0c2-11e9-a08c-82ce3d77f2cb
STEP: Creating configMap with name cm-test-opt-upd-4afed37c-d0c2-11e9-a08c-82ce3d77f2cb
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-4afed338-d0c2-11e9-a08c-82ce3d77f2cb
STEP: Updating configmap cm-test-opt-upd-4afed37c-d0c2-11e9-a08c-82ce3d77f2cb
STEP: Creating configMap with name cm-test-opt-create-4afed3a1-d0c2-11e9-a08c-82ce3d77f2cb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:20:55.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2325" for this suite.
Sep  6 16:21:17.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:21:17.333: INFO: namespace configmap-2325 deletion completed in 22.066265367s

• [SLOW TEST:26.222 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:21:17.333: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-5a962d1c-d0c2-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume secrets
Sep  6 16:21:17.360: INFO: Waiting up to 5m0s for pod "pod-secrets-5a96862d-d0c2-11e9-a08c-82ce3d77f2cb" in namespace "secrets-6426" to be "success or failure"
Sep  6 16:21:17.362: INFO: Pod "pod-secrets-5a96862d-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.318712ms
Sep  6 16:21:19.365: INFO: Pod "pod-secrets-5a96862d-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005389723s
STEP: Saw pod success
Sep  6 16:21:19.366: INFO: Pod "pod-secrets-5a96862d-d0c2-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:21:19.367: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-secrets-5a96862d-d0c2-11e9-a08c-82ce3d77f2cb container secret-env-test: <nil>
STEP: delete the pod
Sep  6 16:21:19.380: INFO: Waiting for pod pod-secrets-5a96862d-d0c2-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:21:19.381: INFO: Pod pod-secrets-5a96862d-d0c2-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:21:19.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6426" for this suite.
Sep  6 16:21:25.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:21:25.447: INFO: namespace secrets-6426 deletion completed in 6.063063649s

• [SLOW TEST:8.114 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:21:25.447: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep  6 16:21:28.004: INFO: Successfully updated pod "annotationupdate5f6c1f44-d0c2-11e9-a08c-82ce3d77f2cb"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:21:32.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2756" for this suite.
Sep  6 16:21:54.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:21:54.102: INFO: namespace projected-2756 deletion completed in 22.073971676s

• [SLOW TEST:28.655 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:21:54.102: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep  6 16:21:54.141: INFO: Waiting up to 5m0s for pod "pod-70825e70-d0c2-11e9-a08c-82ce3d77f2cb" in namespace "emptydir-8181" to be "success or failure"
Sep  6 16:21:54.142: INFO: Pod "pod-70825e70-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.81588ms
Sep  6 16:21:56.145: INFO: Pod "pod-70825e70-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004225229s
Sep  6 16:21:58.149: INFO: Pod "pod-70825e70-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00832737s
STEP: Saw pod success
Sep  6 16:21:58.149: INFO: Pod "pod-70825e70-d0c2-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:21:58.151: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-70825e70-d0c2-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 16:21:58.163: INFO: Waiting for pod pod-70825e70-d0c2-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:21:58.165: INFO: Pod pod-70825e70-d0c2-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:21:58.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8181" for this suite.
Sep  6 16:22:04.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:22:04.245: INFO: namespace emptydir-8181 deletion completed in 6.078413685s

• [SLOW TEST:10.143 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:22:04.245: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep  6 16:22:04.269: INFO: Waiting up to 5m0s for pod "pod-768c52c8-d0c2-11e9-a08c-82ce3d77f2cb" in namespace "emptydir-7471" to be "success or failure"
Sep  6 16:22:04.272: INFO: Pod "pod-768c52c8-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.991891ms
Sep  6 16:22:06.275: INFO: Pod "pod-768c52c8-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006072682s
STEP: Saw pod success
Sep  6 16:22:06.275: INFO: Pod "pod-768c52c8-d0c2-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:22:06.276: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-768c52c8-d0c2-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 16:22:06.289: INFO: Waiting for pod pod-768c52c8-d0c2-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:22:06.290: INFO: Pod pod-768c52c8-d0c2-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:22:06.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7471" for this suite.
Sep  6 16:22:12.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:22:12.363: INFO: namespace emptydir-7471 deletion completed in 6.070862228s

• [SLOW TEST:8.118 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:22:12.363: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Sep  6 16:22:12.386: INFO: Waiting up to 5m0s for pod "var-expansion-7b631212-d0c2-11e9-a08c-82ce3d77f2cb" in namespace "var-expansion-9174" to be "success or failure"
Sep  6 16:22:12.390: INFO: Pod "var-expansion-7b631212-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.682127ms
Sep  6 16:22:14.393: INFO: Pod "var-expansion-7b631212-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006641574s
STEP: Saw pod success
Sep  6 16:22:14.393: INFO: Pod "var-expansion-7b631212-d0c2-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:22:14.395: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod var-expansion-7b631212-d0c2-11e9-a08c-82ce3d77f2cb container dapi-container: <nil>
STEP: delete the pod
Sep  6 16:22:14.406: INFO: Waiting for pod var-expansion-7b631212-d0c2-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:22:14.408: INFO: Pod var-expansion-7b631212-d0c2-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:22:14.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9174" for this suite.
Sep  6 16:22:20.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:22:20.476: INFO: namespace var-expansion-9174 deletion completed in 6.065937918s

• [SLOW TEST:8.113 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:22:20.476: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep  6 16:22:20.499: INFO: Waiting up to 5m0s for pod "pod-8038f000-d0c2-11e9-a08c-82ce3d77f2cb" in namespace "emptydir-9143" to be "success or failure"
Sep  6 16:22:20.504: INFO: Pod "pod-8038f000-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.163147ms
Sep  6 16:22:22.507: INFO: Pod "pod-8038f000-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008201067s
STEP: Saw pod success
Sep  6 16:22:22.507: INFO: Pod "pod-8038f000-d0c2-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:22:22.509: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-8038f000-d0c2-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 16:22:22.523: INFO: Waiting for pod pod-8038f000-d0c2-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:22:22.525: INFO: Pod pod-8038f000-d0c2-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:22:22.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9143" for this suite.
Sep  6 16:22:28.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:22:28.592: INFO: namespace emptydir-9143 deletion completed in 6.065687204s

• [SLOW TEST:8.116 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:22:28.593: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-850f8050-d0c2-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume configMaps
Sep  6 16:22:28.619: INFO: Waiting up to 5m0s for pod "pod-configmaps-850ff826-d0c2-11e9-a08c-82ce3d77f2cb" in namespace "configmap-5529" to be "success or failure"
Sep  6 16:22:28.622: INFO: Pod "pod-configmaps-850ff826-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.854659ms
Sep  6 16:22:30.625: INFO: Pod "pod-configmaps-850ff826-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005812717s
STEP: Saw pod success
Sep  6 16:22:30.625: INFO: Pod "pod-configmaps-850ff826-d0c2-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:22:30.627: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-configmaps-850ff826-d0c2-11e9-a08c-82ce3d77f2cb container configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 16:22:30.639: INFO: Waiting for pod pod-configmaps-850ff826-d0c2-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:22:30.640: INFO: Pod pod-configmaps-850ff826-d0c2-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:22:30.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5529" for this suite.
Sep  6 16:22:36.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:22:36.710: INFO: namespace configmap-5529 deletion completed in 6.067644791s

• [SLOW TEST:8.118 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:22:36.710: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 16:22:36.734: INFO: Waiting up to 5m0s for pod "downwardapi-volume-89e61f2d-d0c2-11e9-a08c-82ce3d77f2cb" in namespace "downward-api-5166" to be "success or failure"
Sep  6 16:22:36.740: INFO: Pod "downwardapi-volume-89e61f2d-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.710742ms
Sep  6 16:22:38.743: INFO: Pod "downwardapi-volume-89e61f2d-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008832783s
STEP: Saw pod success
Sep  6 16:22:38.743: INFO: Pod "downwardapi-volume-89e61f2d-d0c2-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:22:38.745: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod downwardapi-volume-89e61f2d-d0c2-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 16:22:38.758: INFO: Waiting for pod downwardapi-volume-89e61f2d-d0c2-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:22:38.760: INFO: Pod downwardapi-volume-89e61f2d-d0c2-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:22:38.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5166" for this suite.
Sep  6 16:22:44.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:22:44.832: INFO: namespace downward-api-5166 deletion completed in 6.069524022s

• [SLOW TEST:8.121 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:22:44.832: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-8ebd52fe-d0c2-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume configMaps
Sep  6 16:22:44.857: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8ebda13e-d0c2-11e9-a08c-82ce3d77f2cb" in namespace "projected-3632" to be "success or failure"
Sep  6 16:22:44.859: INFO: Pod "pod-projected-configmaps-8ebda13e-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.294384ms
Sep  6 16:22:46.862: INFO: Pod "pod-projected-configmaps-8ebda13e-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005180632s
STEP: Saw pod success
Sep  6 16:22:46.862: INFO: Pod "pod-projected-configmaps-8ebda13e-d0c2-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:22:46.864: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-projected-configmaps-8ebda13e-d0c2-11e9-a08c-82ce3d77f2cb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 16:22:46.876: INFO: Waiting for pod pod-projected-configmaps-8ebda13e-d0c2-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:22:46.878: INFO: Pod pod-projected-configmaps-8ebda13e-d0c2-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:22:46.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3632" for this suite.
Sep  6 16:22:52.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:22:52.942: INFO: namespace projected-3632 deletion completed in 6.061244862s

• [SLOW TEST:8.110 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:22:52.942: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 16:22:52.965: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9392c9f6-d0c2-11e9-a08c-82ce3d77f2cb" in namespace "projected-7773" to be "success or failure"
Sep  6 16:22:52.967: INFO: Pod "downwardapi-volume-9392c9f6-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.145544ms
Sep  6 16:22:54.970: INFO: Pod "downwardapi-volume-9392c9f6-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005493669s
STEP: Saw pod success
Sep  6 16:22:54.970: INFO: Pod "downwardapi-volume-9392c9f6-d0c2-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:22:54.972: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod downwardapi-volume-9392c9f6-d0c2-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 16:22:54.993: INFO: Waiting for pod downwardapi-volume-9392c9f6-d0c2-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:22:54.994: INFO: Pod downwardapi-volume-9392c9f6-d0c2-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:22:54.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7773" for this suite.
Sep  6 16:23:01.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:23:01.058: INFO: namespace projected-7773 deletion completed in 6.061009401s

• [SLOW TEST:8.116 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:23:01.058: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 16:23:01.081: INFO: Waiting up to 5m0s for pod "downwardapi-volume-98693f66-d0c2-11e9-a08c-82ce3d77f2cb" in namespace "projected-9567" to be "success or failure"
Sep  6 16:23:01.084: INFO: Pod "downwardapi-volume-98693f66-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.337325ms
Sep  6 16:23:03.087: INFO: Pod "downwardapi-volume-98693f66-d0c2-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005347037s
STEP: Saw pod success
Sep  6 16:23:03.087: INFO: Pod "downwardapi-volume-98693f66-d0c2-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:23:03.088: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod downwardapi-volume-98693f66-d0c2-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 16:23:03.165: INFO: Waiting for pod downwardapi-volume-98693f66-d0c2-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:23:03.167: INFO: Pod downwardapi-volume-98693f66-d0c2-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:23:03.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9567" for this suite.
Sep  6 16:23:09.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:23:09.238: INFO: namespace projected-9567 deletion completed in 6.068815689s

• [SLOW TEST:8.180 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:23:09.239: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-9d499010-d0c2-11e9-a08c-82ce3d77f2cb
Sep  6 16:23:09.264: INFO: Pod name my-hostname-basic-9d499010-d0c2-11e9-a08c-82ce3d77f2cb: Found 0 pods out of 1
Sep  6 16:23:14.267: INFO: Pod name my-hostname-basic-9d499010-d0c2-11e9-a08c-82ce3d77f2cb: Found 1 pods out of 1
Sep  6 16:23:14.267: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-9d499010-d0c2-11e9-a08c-82ce3d77f2cb" are running
Sep  6 16:23:14.268: INFO: Pod "my-hostname-basic-9d499010-d0c2-11e9-a08c-82ce3d77f2cb-8bxgr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-06 16:23:09 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-06 16:23:10 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-06 16:23:10 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-06 16:23:09 +0000 UTC Reason: Message:}])
Sep  6 16:23:14.269: INFO: Trying to dial the pod
Sep  6 16:23:19.276: INFO: Controller my-hostname-basic-9d499010-d0c2-11e9-a08c-82ce3d77f2cb: Got expected result from replica 1 [my-hostname-basic-9d499010-d0c2-11e9-a08c-82ce3d77f2cb-8bxgr]: "my-hostname-basic-9d499010-d0c2-11e9-a08c-82ce3d77f2cb-8bxgr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:23:19.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1600" for this suite.
Sep  6 16:23:25.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:23:25.350: INFO: namespace replication-controller-1600 deletion completed in 6.071160744s

• [SLOW TEST:16.111 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:23:25.350: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-2077
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2077 to expose endpoints map[]
Sep  6 16:23:25.388: INFO: successfully validated that service multi-endpoint-test in namespace services-2077 exposes endpoints map[] (5.219601ms elapsed)
STEP: Creating pod pod1 in namespace services-2077
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2077 to expose endpoints map[pod1:[100]]
Sep  6 16:23:27.416: INFO: successfully validated that service multi-endpoint-test in namespace services-2077 exposes endpoints map[pod1:[100]] (2.021512151s elapsed)
STEP: Creating pod pod2 in namespace services-2077
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2077 to expose endpoints map[pod1:[100] pod2:[101]]
Sep  6 16:23:29.447: INFO: successfully validated that service multi-endpoint-test in namespace services-2077 exposes endpoints map[pod1:[100] pod2:[101]] (2.027261587s elapsed)
STEP: Deleting pod pod1 in namespace services-2077
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2077 to expose endpoints map[pod2:[101]]
Sep  6 16:23:30.463: INFO: successfully validated that service multi-endpoint-test in namespace services-2077 exposes endpoints map[pod2:[101]] (1.013406425s elapsed)
STEP: Deleting pod pod2 in namespace services-2077
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2077 to expose endpoints map[]
Sep  6 16:23:30.470: INFO: successfully validated that service multi-endpoint-test in namespace services-2077 exposes endpoints map[] (2.800541ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:23:30.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2077" for this suite.
Sep  6 16:23:52.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:23:52.556: INFO: namespace services-2077 deletion completed in 22.067986132s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:27.206 seconds]
[sig-network] Services
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:23:52.556: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 16:24:16.588: INFO: Container started at 2019-09-06 16:23:53 +0000 UTC, pod became ready at 2019-09-06 16:24:15 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:24:16.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2679" for this suite.
Sep  6 16:24:38.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:24:38.659: INFO: namespace container-probe-2679 deletion completed in 22.068517553s

• [SLOW TEST:46.103 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:24:38.659: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Sep  6 16:24:39.392: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Sep  6 16:24:41.446: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703383879, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703383879, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703383879, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703383879, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  6 16:24:43.449: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703383879, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703383879, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703383879, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703383879, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  6 16:24:46.170: INFO: Waited 717.456781ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:24:46.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5770" for this suite.
Sep  6 16:24:52.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:24:52.780: INFO: namespace aggregator-5770 deletion completed in 6.154995929s

• [SLOW TEST:14.121 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:24:52.780: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep  6 16:24:52.799: INFO: PodSpec: initContainers in spec.initContainers
Sep  6 16:25:38.228: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-db009913-d0c2-11e9-a08c-82ce3d77f2cb", GenerateName:"", Namespace:"init-container-1123", SelfLink:"/api/v1/namespaces/init-container-1123/pods/pod-init-db009913-d0c2-11e9-a08c-82ce3d77f2cb", UID:"dafef3d7-d0c2-11e9-8afa-02e25174ea0a", ResourceVersion:"9986", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63703383892, loc:(*time.Location)(0x8825120)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"799315784"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-hdm86", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002aa3c80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hdm86", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hdm86", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hdm86", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002719a18), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-20-60-162.us-east-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002aa8d20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002719a90)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002719ab0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002719ab8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002719abc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703383892, loc:(*time.Location)(0x8825120)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703383892, loc:(*time.Location)(0x8825120)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703383892, loc:(*time.Location)(0x8825120)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703383892, loc:(*time.Location)(0x8825120)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.20.60.162", PodIP:"100.96.2.143", StartTime:(*v1.Time)(0xc00261a260), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000881c00)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000881ce0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://8ec02ac51dd72739a0cc90cdc6725ba2c0b364cbb6a127ea2a4b1396fd128393"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00261a2a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00261a280), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:25:38.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1123" for this suite.
Sep  6 16:26:00.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:26:00.297: INFO: namespace init-container-1123 deletion completed in 22.06637312s

• [SLOW TEST:67.517 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:26:00.298: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Sep  6 16:26:00.323: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-3261" to be "success or failure"
Sep  6 16:26:00.326: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.767222ms
Sep  6 16:26:02.329: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005582089s
STEP: Saw pod success
Sep  6 16:26:02.329: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Sep  6 16:26:02.331: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep  6 16:26:02.348: INFO: Waiting for pod pod-host-path-test to disappear
Sep  6 16:26:02.350: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:26:02.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-3261" for this suite.
Sep  6 16:26:08.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:26:08.425: INFO: namespace hostpath-3261 deletion completed in 6.071691382s

• [SLOW TEST:8.127 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:26:08.425: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 16:26:08.480: INFO: Waiting up to 5m0s for pod "downwardapi-volume-081aa82a-d0c3-11e9-a08c-82ce3d77f2cb" in namespace "projected-8768" to be "success or failure"
Sep  6 16:26:08.487: INFO: Pod "downwardapi-volume-081aa82a-d0c3-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.487505ms
Sep  6 16:26:10.490: INFO: Pod "downwardapi-volume-081aa82a-d0c3-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009401922s
STEP: Saw pod success
Sep  6 16:26:10.490: INFO: Pod "downwardapi-volume-081aa82a-d0c3-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:26:10.491: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod downwardapi-volume-081aa82a-d0c3-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 16:26:10.504: INFO: Waiting for pod downwardapi-volume-081aa82a-d0c3-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:26:10.506: INFO: Pod downwardapi-volume-081aa82a-d0c3-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:26:10.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8768" for this suite.
Sep  6 16:26:16.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:26:16.574: INFO: namespace projected-8768 deletion completed in 6.065028307s

• [SLOW TEST:8.149 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:26:16.574: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:26:40.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9278" for this suite.
Sep  6 16:26:46.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:26:46.712: INFO: namespace namespaces-9278 deletion completed in 6.067504871s
STEP: Destroying namespace "nsdeletetest-1980" for this suite.
Sep  6 16:26:46.714: INFO: Namespace nsdeletetest-1980 was already deleted
STEP: Destroying namespace "nsdeletetest-5416" for this suite.
Sep  6 16:26:52.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:26:52.784: INFO: namespace nsdeletetest-5416 deletion completed in 6.069837392s

• [SLOW TEST:36.210 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:26:52.784: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Sep  6 16:26:52.810: INFO: Waiting up to 5m0s for pod "pod-22882f5b-d0c3-11e9-a08c-82ce3d77f2cb" in namespace "emptydir-8961" to be "success or failure"
Sep  6 16:26:52.814: INFO: Pod "pod-22882f5b-d0c3-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.760101ms
Sep  6 16:26:54.817: INFO: Pod "pod-22882f5b-d0c3-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00681113s
STEP: Saw pod success
Sep  6 16:26:54.817: INFO: Pod "pod-22882f5b-d0c3-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:26:54.819: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-22882f5b-d0c3-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 16:26:54.831: INFO: Waiting for pod pod-22882f5b-d0c3-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:26:54.833: INFO: Pod pod-22882f5b-d0c3-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:26:54.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8961" for this suite.
Sep  6 16:27:00.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:27:00.906: INFO: namespace emptydir-8961 deletion completed in 6.070420668s

• [SLOW TEST:8.121 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:27:00.906: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep  6 16:27:03.451: INFO: Successfully updated pod "annotationupdate275f20c9-d0c3-11e9-a08c-82ce3d77f2cb"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:27:07.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-354" for this suite.
Sep  6 16:27:21.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:27:21.546: INFO: namespace downward-api-354 deletion completed in 14.069690133s

• [SLOW TEST:20.640 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:27:21.546: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 16:27:23.640: INFO: Waiting up to 5m0s for pod "client-envvars-34e8999f-d0c3-11e9-a08c-82ce3d77f2cb" in namespace "pods-1719" to be "success or failure"
Sep  6 16:27:23.646: INFO: Pod "client-envvars-34e8999f-d0c3-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.2674ms
Sep  6 16:27:25.649: INFO: Pod "client-envvars-34e8999f-d0c3-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00916568s
STEP: Saw pod success
Sep  6 16:27:25.649: INFO: Pod "client-envvars-34e8999f-d0c3-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:27:25.651: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod client-envvars-34e8999f-d0c3-11e9-a08c-82ce3d77f2cb container env3cont: <nil>
STEP: delete the pod
Sep  6 16:27:25.663: INFO: Waiting for pod client-envvars-34e8999f-d0c3-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:27:25.665: INFO: Pod client-envvars-34e8999f-d0c3-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:27:25.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1719" for this suite.
Sep  6 16:28:05.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:28:05.742: INFO: namespace pods-1719 deletion completed in 40.074551071s

• [SLOW TEST:44.196 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:28:05.742: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Sep  6 16:28:05.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 create -f - --namespace=kubectl-4141'
Sep  6 16:28:06.121: INFO: stderr: ""
Sep  6 16:28:06.121: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  6 16:28:07.124: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 16:28:07.124: INFO: Found 0 / 1
Sep  6 16:28:08.124: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 16:28:08.124: INFO: Found 1 / 1
Sep  6 16:28:08.124: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep  6 16:28:08.126: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 16:28:08.126: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  6 16:28:08.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 patch pod redis-master-s57z8 --namespace=kubectl-4141 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep  6 16:28:08.199: INFO: stderr: ""
Sep  6 16:28:08.199: INFO: stdout: "pod/redis-master-s57z8 patched\n"
STEP: checking annotations
Sep  6 16:28:08.201: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 16:28:08.201: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:28:08.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4141" for this suite.
Sep  6 16:28:30.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:28:30.270: INFO: namespace kubectl-4141 deletion completed in 22.066575783s

• [SLOW TEST:24.528 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:28:30.271: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep  6 16:28:30.541: INFO: Pod name wrapped-volume-race-5cb28244-d0c3-11e9-a08c-82ce3d77f2cb: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-5cb28244-d0c3-11e9-a08c-82ce3d77f2cb in namespace emptydir-wrapper-8157, will wait for the garbage collector to delete the pods
Sep  6 16:28:46.654: INFO: Deleting ReplicationController wrapped-volume-race-5cb28244-d0c3-11e9-a08c-82ce3d77f2cb took: 6.145917ms
Sep  6 16:28:46.954: INFO: Terminating ReplicationController wrapped-volume-race-5cb28244-d0c3-11e9-a08c-82ce3d77f2cb pods took: 300.333859ms
STEP: Creating RC which spawns configmap-volume pods
Sep  6 16:29:24.667: INFO: Pod name wrapped-volume-race-7d0a85ca-d0c3-11e9-a08c-82ce3d77f2cb: Found 0 pods out of 5
Sep  6 16:29:29.672: INFO: Pod name wrapped-volume-race-7d0a85ca-d0c3-11e9-a08c-82ce3d77f2cb: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-7d0a85ca-d0c3-11e9-a08c-82ce3d77f2cb in namespace emptydir-wrapper-8157, will wait for the garbage collector to delete the pods
Sep  6 16:29:39.747: INFO: Deleting ReplicationController wrapped-volume-race-7d0a85ca-d0c3-11e9-a08c-82ce3d77f2cb took: 5.337965ms
Sep  6 16:29:40.047: INFO: Terminating ReplicationController wrapped-volume-race-7d0a85ca-d0c3-11e9-a08c-82ce3d77f2cb pods took: 300.309153ms
STEP: Creating RC which spawns configmap-volume pods
Sep  6 16:30:24.659: INFO: Pod name wrapped-volume-race-a0cca592-d0c3-11e9-a08c-82ce3d77f2cb: Found 0 pods out of 5
Sep  6 16:30:29.663: INFO: Pod name wrapped-volume-race-a0cca592-d0c3-11e9-a08c-82ce3d77f2cb: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-a0cca592-d0c3-11e9-a08c-82ce3d77f2cb in namespace emptydir-wrapper-8157, will wait for the garbage collector to delete the pods
Sep  6 16:30:39.741: INFO: Deleting ReplicationController wrapped-volume-race-a0cca592-d0c3-11e9-a08c-82ce3d77f2cb took: 5.455688ms
Sep  6 16:30:40.041: INFO: Terminating ReplicationController wrapped-volume-race-a0cca592-d0c3-11e9-a08c-82ce3d77f2cb pods took: 300.310436ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:31:24.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8157" for this suite.
Sep  6 16:31:30.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:31:30.871: INFO: namespace emptydir-wrapper-8157 deletion completed in 6.064403746s

• [SLOW TEST:180.600 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:31:30.871: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-5332
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  6 16:31:30.891: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  6 16:31:50.943: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.1.96 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5332 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 16:31:50.943: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 16:31:52.025: INFO: Found all expected endpoints: [netserver-0]
Sep  6 16:31:52.027: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.2.165 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5332 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 16:31:52.027: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
Sep  6 16:31:53.113: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:31:53.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5332" for this suite.
Sep  6 16:32:15.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:32:15.181: INFO: namespace pod-network-test-5332 deletion completed in 22.065198807s

• [SLOW TEST:44.310 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:32:15.181: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 16:32:15.208: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e2b2203f-d0c3-11e9-a08c-82ce3d77f2cb" in namespace "downward-api-9219" to be "success or failure"
Sep  6 16:32:15.215: INFO: Pod "downwardapi-volume-e2b2203f-d0c3-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.231191ms
Sep  6 16:32:17.217: INFO: Pod "downwardapi-volume-e2b2203f-d0c3-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009016736s
STEP: Saw pod success
Sep  6 16:32:17.217: INFO: Pod "downwardapi-volume-e2b2203f-d0c3-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:32:17.219: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod downwardapi-volume-e2b2203f-d0c3-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 16:32:17.230: INFO: Waiting for pod downwardapi-volume-e2b2203f-d0c3-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:32:17.232: INFO: Pod downwardapi-volume-e2b2203f-d0c3-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:32:17.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9219" for this suite.
Sep  6 16:32:23.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:32:23.312: INFO: namespace downward-api-9219 deletion completed in 6.077538507s

• [SLOW TEST:8.130 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:32:23.312: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep  6 16:32:23.345: INFO: Waiting up to 5m0s for pod "downward-api-e78bbd7d-d0c3-11e9-a08c-82ce3d77f2cb" in namespace "downward-api-4935" to be "success or failure"
Sep  6 16:32:23.350: INFO: Pod "downward-api-e78bbd7d-d0c3-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.010501ms
Sep  6 16:32:25.353: INFO: Pod "downward-api-e78bbd7d-d0c3-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008053059s
STEP: Saw pod success
Sep  6 16:32:25.353: INFO: Pod "downward-api-e78bbd7d-d0c3-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:32:25.355: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod downward-api-e78bbd7d-d0c3-11e9-a08c-82ce3d77f2cb container dapi-container: <nil>
STEP: delete the pod
Sep  6 16:32:25.368: INFO: Waiting for pod downward-api-e78bbd7d-d0c3-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:32:25.370: INFO: Pod downward-api-e78bbd7d-d0c3-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:32:25.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4935" for this suite.
Sep  6 16:32:31.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:32:31.438: INFO: namespace downward-api-4935 deletion completed in 6.065321995s

• [SLOW TEST:8.126 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:32:31.438: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-ec62ac93-d0c3-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume configMaps
Sep  6 16:32:31.466: INFO: Waiting up to 5m0s for pod "pod-configmaps-ec630137-d0c3-11e9-a08c-82ce3d77f2cb" in namespace "configmap-1695" to be "success or failure"
Sep  6 16:32:31.471: INFO: Pod "pod-configmaps-ec630137-d0c3-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.85115ms
Sep  6 16:32:33.474: INFO: Pod "pod-configmaps-ec630137-d0c3-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007870594s
STEP: Saw pod success
Sep  6 16:32:33.474: INFO: Pod "pod-configmaps-ec630137-d0c3-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:32:33.476: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-configmaps-ec630137-d0c3-11e9-a08c-82ce3d77f2cb container configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 16:32:33.489: INFO: Waiting for pod pod-configmaps-ec630137-d0c3-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:32:33.491: INFO: Pod pod-configmaps-ec630137-d0c3-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:32:33.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1695" for this suite.
Sep  6 16:32:39.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:32:39.564: INFO: namespace configmap-1695 deletion completed in 6.071109738s

• [SLOW TEST:8.126 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:32:39.564: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 16:32:39.589: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f13a5b8e-d0c3-11e9-a08c-82ce3d77f2cb" in namespace "projected-3785" to be "success or failure"
Sep  6 16:32:39.594: INFO: Pod "downwardapi-volume-f13a5b8e-d0c3-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.341806ms
Sep  6 16:32:41.597: INFO: Pod "downwardapi-volume-f13a5b8e-d0c3-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007439505s
STEP: Saw pod success
Sep  6 16:32:41.597: INFO: Pod "downwardapi-volume-f13a5b8e-d0c3-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:32:41.599: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod downwardapi-volume-f13a5b8e-d0c3-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 16:32:41.610: INFO: Waiting for pod downwardapi-volume-f13a5b8e-d0c3-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:32:41.612: INFO: Pod downwardapi-volume-f13a5b8e-d0c3-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:32:41.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3785" for this suite.
Sep  6 16:32:47.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:32:47.688: INFO: namespace projected-3785 deletion completed in 6.07398777s

• [SLOW TEST:8.124 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:32:47.688: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 16:32:47.711: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f611e52c-d0c3-11e9-a08c-82ce3d77f2cb" in namespace "projected-5156" to be "success or failure"
Sep  6 16:32:47.714: INFO: Pod "downwardapi-volume-f611e52c-d0c3-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.821505ms
Sep  6 16:32:49.720: INFO: Pod "downwardapi-volume-f611e52c-d0c3-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008354849s
STEP: Saw pod success
Sep  6 16:32:49.720: INFO: Pod "downwardapi-volume-f611e52c-d0c3-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:32:49.721: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod downwardapi-volume-f611e52c-d0c3-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 16:32:49.734: INFO: Waiting for pod downwardapi-volume-f611e52c-d0c3-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:32:49.736: INFO: Pod downwardapi-volume-f611e52c-d0c3-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:32:49.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5156" for this suite.
Sep  6 16:32:55.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:32:55.805: INFO: namespace projected-5156 deletion completed in 6.067425486s

• [SLOW TEST:8.117 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:32:55.805: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 16:32:55.835: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep  6 16:32:55.841: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:32:55.845: INFO: Number of nodes with available pods: 0
Sep  6 16:32:55.845: INFO: Node ip-172-20-60-162.us-east-2.compute.internal is running more than one daemon pod
Sep  6 16:32:56.848: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:32:56.849: INFO: Number of nodes with available pods: 0
Sep  6 16:32:56.849: INFO: Node ip-172-20-60-162.us-east-2.compute.internal is running more than one daemon pod
Sep  6 16:32:57.848: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:32:57.850: INFO: Number of nodes with available pods: 2
Sep  6 16:32:57.850: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep  6 16:32:57.872: INFO: Wrong image for pod: daemon-set-45skl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:32:57.872: INFO: Wrong image for pod: daemon-set-744l8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:32:57.877: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:32:58.880: INFO: Wrong image for pod: daemon-set-45skl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:32:58.880: INFO: Wrong image for pod: daemon-set-744l8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:32:58.883: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:32:59.880: INFO: Wrong image for pod: daemon-set-45skl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:32:59.880: INFO: Wrong image for pod: daemon-set-744l8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:32:59.883: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:33:00.882: INFO: Wrong image for pod: daemon-set-45skl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:33:00.882: INFO: Wrong image for pod: daemon-set-744l8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:33:00.882: INFO: Pod daemon-set-744l8 is not available
Sep  6 16:33:00.885: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:33:01.880: INFO: Wrong image for pod: daemon-set-45skl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:33:01.880: INFO: Pod daemon-set-5r8jg is not available
Sep  6 16:33:01.882: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:33:02.880: INFO: Wrong image for pod: daemon-set-45skl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:33:02.880: INFO: Pod daemon-set-5r8jg is not available
Sep  6 16:33:02.882: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:33:03.880: INFO: Wrong image for pod: daemon-set-45skl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:33:03.880: INFO: Pod daemon-set-5r8jg is not available
Sep  6 16:33:03.883: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:33:04.880: INFO: Wrong image for pod: daemon-set-45skl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:33:04.882: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:33:05.881: INFO: Wrong image for pod: daemon-set-45skl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:33:05.881: INFO: Pod daemon-set-45skl is not available
Sep  6 16:33:05.883: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:33:06.881: INFO: Wrong image for pod: daemon-set-45skl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:33:06.881: INFO: Pod daemon-set-45skl is not available
Sep  6 16:33:06.883: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:33:07.880: INFO: Wrong image for pod: daemon-set-45skl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:33:07.880: INFO: Pod daemon-set-45skl is not available
Sep  6 16:33:07.883: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:33:08.880: INFO: Wrong image for pod: daemon-set-45skl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:33:08.880: INFO: Pod daemon-set-45skl is not available
Sep  6 16:33:08.883: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:33:09.880: INFO: Wrong image for pod: daemon-set-45skl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:33:09.881: INFO: Pod daemon-set-45skl is not available
Sep  6 16:33:09.884: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:33:10.880: INFO: Wrong image for pod: daemon-set-45skl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:33:10.880: INFO: Pod daemon-set-45skl is not available
Sep  6 16:33:10.882: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:33:11.880: INFO: Wrong image for pod: daemon-set-45skl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:33:11.880: INFO: Pod daemon-set-45skl is not available
Sep  6 16:33:11.883: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:33:12.880: INFO: Wrong image for pod: daemon-set-45skl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:33:12.880: INFO: Pod daemon-set-45skl is not available
Sep  6 16:33:12.883: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:33:13.880: INFO: Wrong image for pod: daemon-set-45skl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  6 16:33:13.880: INFO: Pod daemon-set-45skl is not available
Sep  6 16:33:13.883: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:33:14.880: INFO: Pod daemon-set-djgwh is not available
Sep  6 16:33:14.883: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Sep  6 16:33:14.885: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:33:14.887: INFO: Number of nodes with available pods: 1
Sep  6 16:33:14.887: INFO: Node ip-172-20-60-162.us-east-2.compute.internal is running more than one daemon pod
Sep  6 16:33:15.890: INFO: DaemonSet pods can't tolerate node ip-172-20-50-224.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  6 16:33:15.892: INFO: Number of nodes with available pods: 2
Sep  6 16:33:15.892: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4445, will wait for the garbage collector to delete the pods
Sep  6 16:33:15.958: INFO: Deleting DaemonSet.extensions daemon-set took: 4.330873ms
Sep  6 16:33:16.259: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.33072ms
Sep  6 16:33:24.661: INFO: Number of nodes with available pods: 0
Sep  6 16:33:24.661: INFO: Number of running nodes: 0, number of available pods: 0
Sep  6 16:33:24.663: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4445/daemonsets","resourceVersion":"11265"},"items":null}

Sep  6 16:33:24.664: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4445/pods","resourceVersion":"11265"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:33:24.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4445" for this suite.
Sep  6 16:33:30.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:33:30.745: INFO: namespace daemonsets-4445 deletion completed in 6.071665639s

• [SLOW TEST:34.939 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:33:30.745: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 16:33:30.769: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0fbbda37-d0c4-11e9-a08c-82ce3d77f2cb" in namespace "projected-250" to be "success or failure"
Sep  6 16:33:30.772: INFO: Pod "downwardapi-volume-0fbbda37-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.811917ms
Sep  6 16:33:32.775: INFO: Pod "downwardapi-volume-0fbbda37-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005723833s
STEP: Saw pod success
Sep  6 16:33:32.775: INFO: Pod "downwardapi-volume-0fbbda37-d0c4-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:33:32.777: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod downwardapi-volume-0fbbda37-d0c4-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 16:33:32.792: INFO: Waiting for pod downwardapi-volume-0fbbda37-d0c4-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:33:32.793: INFO: Pod downwardapi-volume-0fbbda37-d0c4-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:33:32.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-250" for this suite.
Sep  6 16:33:38.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:33:38.860: INFO: namespace projected-250 deletion completed in 6.064243924s

• [SLOW TEST:8.115 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:33:38.860: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep  6 16:33:38.890: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1392,SelfLink:/api/v1/namespaces/watch-1392/configmaps/e2e-watch-test-label-changed,UID:148ff50e-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11309,Generation:0,CreationTimestamp:2019-09-06 16:33:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  6 16:33:38.890: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1392,SelfLink:/api/v1/namespaces/watch-1392/configmaps/e2e-watch-test-label-changed,UID:148ff50e-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11310,Generation:0,CreationTimestamp:2019-09-06 16:33:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  6 16:33:38.890: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1392,SelfLink:/api/v1/namespaces/watch-1392/configmaps/e2e-watch-test-label-changed,UID:148ff50e-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11311,Generation:0,CreationTimestamp:2019-09-06 16:33:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep  6 16:33:48.904: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1392,SelfLink:/api/v1/namespaces/watch-1392/configmaps/e2e-watch-test-label-changed,UID:148ff50e-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11328,Generation:0,CreationTimestamp:2019-09-06 16:33:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  6 16:33:48.904: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1392,SelfLink:/api/v1/namespaces/watch-1392/configmaps/e2e-watch-test-label-changed,UID:148ff50e-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11329,Generation:0,CreationTimestamp:2019-09-06 16:33:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Sep  6 16:33:48.904: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1392,SelfLink:/api/v1/namespaces/watch-1392/configmaps/e2e-watch-test-label-changed,UID:148ff50e-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11330,Generation:0,CreationTimestamp:2019-09-06 16:33:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:33:48.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1392" for this suite.
Sep  6 16:33:54.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:33:54.970: INFO: namespace watch-1392 deletion completed in 6.063432704s

• [SLOW TEST:16.110 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:33:54.970: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep  6 16:33:54.994: INFO: Waiting up to 5m0s for pod "pod-1e2c6d87-d0c4-11e9-a08c-82ce3d77f2cb" in namespace "emptydir-5622" to be "success or failure"
Sep  6 16:33:54.997: INFO: Pod "pod-1e2c6d87-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.817374ms
Sep  6 16:33:57.000: INFO: Pod "pod-1e2c6d87-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005954043s
STEP: Saw pod success
Sep  6 16:33:57.000: INFO: Pod "pod-1e2c6d87-d0c4-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:33:57.002: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-1e2c6d87-d0c4-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 16:33:57.014: INFO: Waiting for pod pod-1e2c6d87-d0c4-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:33:57.016: INFO: Pod pod-1e2c6d87-d0c4-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:33:57.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5622" for this suite.
Sep  6 16:34:03.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:34:03.102: INFO: namespace emptydir-5622 deletion completed in 6.084017582s

• [SLOW TEST:8.132 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:34:03.102: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-230d1847-d0c4-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume configMaps
Sep  6 16:34:03.180: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-230d701e-d0c4-11e9-a08c-82ce3d77f2cb" in namespace "projected-3077" to be "success or failure"
Sep  6 16:34:03.182: INFO: Pod "pod-projected-configmaps-230d701e-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.320283ms
Sep  6 16:34:05.185: INFO: Pod "pod-projected-configmaps-230d701e-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005225547s
STEP: Saw pod success
Sep  6 16:34:05.185: INFO: Pod "pod-projected-configmaps-230d701e-d0c4-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:34:05.187: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-projected-configmaps-230d701e-d0c4-11e9-a08c-82ce3d77f2cb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 16:34:05.199: INFO: Waiting for pod pod-projected-configmaps-230d701e-d0c4-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:34:05.201: INFO: Pod pod-projected-configmaps-230d701e-d0c4-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:34:05.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3077" for this suite.
Sep  6 16:34:11.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:34:11.270: INFO: namespace projected-3077 deletion completed in 6.066364402s

• [SLOW TEST:8.168 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:34:11.271: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep  6 16:34:11.295: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3817,SelfLink:/api/v1/namespaces/watch-3817/configmaps/e2e-watch-test-configmap-a,UID:27e1b4df-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11405,Generation:0,CreationTimestamp:2019-09-06 16:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  6 16:34:11.295: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3817,SelfLink:/api/v1/namespaces/watch-3817/configmaps/e2e-watch-test-configmap-a,UID:27e1b4df-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11405,Generation:0,CreationTimestamp:2019-09-06 16:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep  6 16:34:21.300: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3817,SelfLink:/api/v1/namespaces/watch-3817/configmaps/e2e-watch-test-configmap-a,UID:27e1b4df-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11422,Generation:0,CreationTimestamp:2019-09-06 16:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  6 16:34:21.300: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3817,SelfLink:/api/v1/namespaces/watch-3817/configmaps/e2e-watch-test-configmap-a,UID:27e1b4df-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11422,Generation:0,CreationTimestamp:2019-09-06 16:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep  6 16:34:31.305: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3817,SelfLink:/api/v1/namespaces/watch-3817/configmaps/e2e-watch-test-configmap-a,UID:27e1b4df-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11437,Generation:0,CreationTimestamp:2019-09-06 16:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  6 16:34:31.306: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3817,SelfLink:/api/v1/namespaces/watch-3817/configmaps/e2e-watch-test-configmap-a,UID:27e1b4df-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11437,Generation:0,CreationTimestamp:2019-09-06 16:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep  6 16:34:41.310: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3817,SelfLink:/api/v1/namespaces/watch-3817/configmaps/e2e-watch-test-configmap-a,UID:27e1b4df-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11452,Generation:0,CreationTimestamp:2019-09-06 16:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  6 16:34:41.310: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3817,SelfLink:/api/v1/namespaces/watch-3817/configmaps/e2e-watch-test-configmap-a,UID:27e1b4df-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11452,Generation:0,CreationTimestamp:2019-09-06 16:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep  6 16:34:51.315: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3817,SelfLink:/api/v1/namespaces/watch-3817/configmaps/e2e-watch-test-configmap-b,UID:3fbbf907-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11468,Generation:0,CreationTimestamp:2019-09-06 16:34:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  6 16:34:51.315: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3817,SelfLink:/api/v1/namespaces/watch-3817/configmaps/e2e-watch-test-configmap-b,UID:3fbbf907-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11468,Generation:0,CreationTimestamp:2019-09-06 16:34:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep  6 16:35:01.320: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3817,SelfLink:/api/v1/namespaces/watch-3817/configmaps/e2e-watch-test-configmap-b,UID:3fbbf907-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11483,Generation:0,CreationTimestamp:2019-09-06 16:34:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  6 16:35:01.320: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3817,SelfLink:/api/v1/namespaces/watch-3817/configmaps/e2e-watch-test-configmap-b,UID:3fbbf907-d0c4-11e9-8afa-02e25174ea0a,ResourceVersion:11483,Generation:0,CreationTimestamp:2019-09-06 16:34:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:35:11.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3817" for this suite.
Sep  6 16:35:17.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:35:17.390: INFO: namespace watch-3817 deletion completed in 6.066717527s

• [SLOW TEST:66.120 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:35:17.390: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 16:35:17.415: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4f4caf52-d0c4-11e9-a08c-82ce3d77f2cb" in namespace "downward-api-6975" to be "success or failure"
Sep  6 16:35:17.417: INFO: Pod "downwardapi-volume-4f4caf52-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.656206ms
Sep  6 16:35:19.420: INFO: Pod "downwardapi-volume-4f4caf52-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005811066s
STEP: Saw pod success
Sep  6 16:35:19.421: INFO: Pod "downwardapi-volume-4f4caf52-d0c4-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:35:19.422: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod downwardapi-volume-4f4caf52-d0c4-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 16:35:19.445: INFO: Waiting for pod downwardapi-volume-4f4caf52-d0c4-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:35:19.447: INFO: Pod downwardapi-volume-4f4caf52-d0c4-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:35:19.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6975" for this suite.
Sep  6 16:35:25.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:35:25.511: INFO: namespace downward-api-6975 deletion completed in 6.062032598s

• [SLOW TEST:8.121 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:35:25.511: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6720.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6720.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6720.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6720.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6720.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6720.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6720.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6720.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6720.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6720.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6720.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6720.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6720.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 17.115.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.115.17_udp@PTR;check="$$(dig +tcp +noall +answer +search 17.115.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.115.17_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6720.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6720.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6720.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6720.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6720.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6720.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6720.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6720.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6720.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6720.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6720.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6720.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6720.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 17.115.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.115.17_udp@PTR;check="$$(dig +tcp +noall +answer +search 17.115.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.115.17_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  6 16:35:27.569: INFO: Unable to read wheezy_udp@dns-test-service.dns-6720.svc.cluster.local from pod dns-6720/dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb: the server could not find the requested resource (get pods dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb)
Sep  6 16:35:27.572: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6720.svc.cluster.local from pod dns-6720/dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb: the server could not find the requested resource (get pods dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb)
Sep  6 16:35:27.574: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6720.svc.cluster.local from pod dns-6720/dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb: the server could not find the requested resource (get pods dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb)
Sep  6 16:35:27.576: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6720.svc.cluster.local from pod dns-6720/dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb: the server could not find the requested resource (get pods dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb)
Sep  6 16:35:27.594: INFO: Unable to read jessie_udp@dns-test-service.dns-6720.svc.cluster.local from pod dns-6720/dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb: the server could not find the requested resource (get pods dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb)
Sep  6 16:35:27.596: INFO: Unable to read jessie_tcp@dns-test-service.dns-6720.svc.cluster.local from pod dns-6720/dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb: the server could not find the requested resource (get pods dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb)
Sep  6 16:35:27.598: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6720.svc.cluster.local from pod dns-6720/dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb: the server could not find the requested resource (get pods dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb)
Sep  6 16:35:27.601: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6720.svc.cluster.local from pod dns-6720/dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb: the server could not find the requested resource (get pods dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb)
Sep  6 16:35:27.614: INFO: Lookups using dns-6720/dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb failed for: [wheezy_udp@dns-test-service.dns-6720.svc.cluster.local wheezy_tcp@dns-test-service.dns-6720.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6720.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6720.svc.cluster.local jessie_udp@dns-test-service.dns-6720.svc.cluster.local jessie_tcp@dns-test-service.dns-6720.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6720.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6720.svc.cluster.local]

Sep  6 16:35:32.659: INFO: DNS probes using dns-6720/dns-test-54260421-d0c4-11e9-a08c-82ce3d77f2cb succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:35:32.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6720" for this suite.
Sep  6 16:35:38.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:35:38.801: INFO: namespace dns-6720 deletion completed in 6.074857068s

• [SLOW TEST:13.290 seconds]
[sig-network] DNS
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:35:38.802: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1384
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  6 16:35:38.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4676'
Sep  6 16:35:38.906: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  6 16:35:38.906: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1390
Sep  6 16:35:38.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 delete deployment e2e-test-nginx-deployment --namespace=kubectl-4676'
Sep  6 16:35:38.989: INFO: stderr: ""
Sep  6 16:35:38.989: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:35:38.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4676" for this suite.
Sep  6 16:35:45.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:35:45.096: INFO: namespace kubectl-4676 deletion completed in 6.102341051s

• [SLOW TEST:6.295 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:35:45.096: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Sep  6 16:35:45.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 cluster-info'
Sep  6 16:35:45.197: INFO: stderr: ""
Sep  6 16:35:45.198: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:35:45.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1430" for this suite.
Sep  6 16:35:51.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:35:51.271: INFO: namespace kubectl-1430 deletion completed in 6.06994186s

• [SLOW TEST:6.175 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:35:51.272: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0906 16:35:57.317937      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  6 16:35:57.317: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:35:57.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7418" for this suite.
Sep  6 16:36:03.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:36:03.393: INFO: namespace gc-7418 deletion completed in 6.072718292s

• [SLOW TEST:12.121 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:36:03.393: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep  6 16:36:03.419: INFO: Waiting up to 5m0s for pod "downward-api-6ab86e02-d0c4-11e9-a08c-82ce3d77f2cb" in namespace "downward-api-8847" to be "success or failure"
Sep  6 16:36:03.422: INFO: Pod "downward-api-6ab86e02-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.740493ms
Sep  6 16:36:05.425: INFO: Pod "downward-api-6ab86e02-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006637343s
STEP: Saw pod success
Sep  6 16:36:05.425: INFO: Pod "downward-api-6ab86e02-d0c4-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:36:05.427: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod downward-api-6ab86e02-d0c4-11e9-a08c-82ce3d77f2cb container dapi-container: <nil>
STEP: delete the pod
Sep  6 16:36:05.445: INFO: Waiting for pod downward-api-6ab86e02-d0c4-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:36:05.447: INFO: Pod downward-api-6ab86e02-d0c4-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:36:05.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8847" for this suite.
Sep  6 16:36:11.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:36:11.513: INFO: namespace downward-api-8847 deletion completed in 6.063957872s

• [SLOW TEST:8.120 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:36:11.513: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep  6 16:36:11.536: INFO: Waiting up to 5m0s for pod "downward-api-6f8f19ac-d0c4-11e9-a08c-82ce3d77f2cb" in namespace "downward-api-4136" to be "success or failure"
Sep  6 16:36:11.539: INFO: Pod "downward-api-6f8f19ac-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.92503ms
Sep  6 16:36:13.543: INFO: Pod "downward-api-6f8f19ac-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006061299s
STEP: Saw pod success
Sep  6 16:36:13.543: INFO: Pod "downward-api-6f8f19ac-d0c4-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:36:13.545: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod downward-api-6f8f19ac-d0c4-11e9-a08c-82ce3d77f2cb container dapi-container: <nil>
STEP: delete the pod
Sep  6 16:36:13.557: INFO: Waiting for pod downward-api-6f8f19ac-d0c4-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:36:13.559: INFO: Pod downward-api-6f8f19ac-d0c4-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:36:13.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4136" for this suite.
Sep  6 16:36:19.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:36:19.630: INFO: namespace downward-api-4136 deletion completed in 6.068500771s

• [SLOW TEST:8.116 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:36:19.630: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 16:36:19.672: INFO: (0) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.549256ms)
Sep  6 16:36:19.674: INFO: (1) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.634358ms)
Sep  6 16:36:19.677: INFO: (2) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.409428ms)
Sep  6 16:36:19.679: INFO: (3) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.352519ms)
Sep  6 16:36:19.682: INFO: (4) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.324747ms)
Sep  6 16:36:19.684: INFO: (5) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.344474ms)
Sep  6 16:36:19.686: INFO: (6) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.343131ms)
Sep  6 16:36:19.689: INFO: (7) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.24005ms)
Sep  6 16:36:19.691: INFO: (8) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.279434ms)
Sep  6 16:36:19.694: INFO: (9) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.228143ms)
Sep  6 16:36:19.697: INFO: (10) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.273604ms)
Sep  6 16:36:19.699: INFO: (11) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.182333ms)
Sep  6 16:36:19.701: INFO: (12) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.288543ms)
Sep  6 16:36:19.703: INFO: (13) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.214932ms)
Sep  6 16:36:19.706: INFO: (14) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.334831ms)
Sep  6 16:36:19.708: INFO: (15) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.260909ms)
Sep  6 16:36:19.710: INFO: (16) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.269233ms)
Sep  6 16:36:19.713: INFO: (17) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.303535ms)
Sep  6 16:36:19.715: INFO: (18) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.160127ms)
Sep  6 16:36:19.717: INFO: (19) /api/v1/nodes/ip-172-20-60-162.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.348367ms)
[AfterEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:36:19.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8685" for this suite.
Sep  6 16:36:25.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:36:25.784: INFO: namespace proxy-8685 deletion completed in 6.063953897s

• [SLOW TEST:6.154 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:36:25.784: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  6 16:36:25.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-9869'
Sep  6 16:36:25.878: INFO: stderr: ""
Sep  6 16:36:25.878: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Sep  6 16:36:30.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pod e2e-test-nginx-pod --namespace=kubectl-9869 -o json'
Sep  6 16:36:30.996: INFO: stderr: ""
Sep  6 16:36:30.996: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-09-06T16:36:25Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-9869\",\n        \"resourceVersion\": \"11836\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-9869/pods/e2e-test-nginx-pod\",\n        \"uid\": \"78184b62-d0c4-11e9-8afa-02e25174ea0a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-5tlj6\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-20-60-162.us-east-2.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-5tlj6\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-5tlj6\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-06T16:36:25Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-06T16:36:27Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-06T16:36:27Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-06T16:36:25Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://08c8ed9acf5ea43dabe763a14f511309ea868acc6bbb36204c37560c90bbbbba\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-09-06T16:36:26Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.20.60.162\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.2.182\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-09-06T16:36:25Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep  6 16:36:30.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 replace -f - --namespace=kubectl-9869'
Sep  6 16:36:31.159: INFO: stderr: ""
Sep  6 16:36:31.159: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Sep  6 16:36:31.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 delete pods e2e-test-nginx-pod --namespace=kubectl-9869'
Sep  6 16:36:32.649: INFO: stderr: ""
Sep  6 16:36:32.649: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:36:32.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9869" for this suite.
Sep  6 16:36:38.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:36:38.718: INFO: namespace kubectl-9869 deletion completed in 6.065057049s

• [SLOW TEST:12.934 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:36:38.718: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:36:40.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-254" for this suite.
Sep  6 16:36:46.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:36:46.839: INFO: namespace emptydir-wrapper-254 deletion completed in 6.067348411s

• [SLOW TEST:8.122 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:36:46.840: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 16:36:46.863: INFO: Waiting up to 5m0s for pod "downwardapi-volume-849d75c1-d0c4-11e9-a08c-82ce3d77f2cb" in namespace "downward-api-3583" to be "success or failure"
Sep  6 16:36:46.870: INFO: Pod "downwardapi-volume-849d75c1-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.807364ms
Sep  6 16:36:48.873: INFO: Pod "downwardapi-volume-849d75c1-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009837016s
STEP: Saw pod success
Sep  6 16:36:48.873: INFO: Pod "downwardapi-volume-849d75c1-d0c4-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:36:48.875: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod downwardapi-volume-849d75c1-d0c4-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 16:36:48.887: INFO: Waiting for pod downwardapi-volume-849d75c1-d0c4-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:36:48.889: INFO: Pod downwardapi-volume-849d75c1-d0c4-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:36:48.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3583" for this suite.
Sep  6 16:36:54.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:36:54.956: INFO: namespace downward-api-3583 deletion completed in 6.064325325s

• [SLOW TEST:8.116 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:36:54.956: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Sep  6 16:36:54.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 --namespace=kubectl-2369 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Sep  6 16:36:56.931: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Sep  6 16:36:56.931: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:36:58.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2369" for this suite.
Sep  6 16:37:04.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:37:05.002: INFO: namespace kubectl-2369 deletion completed in 6.064755046s

• [SLOW TEST:10.046 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:37:05.003: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-9131
I0906 16:37:05.028956      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-9131, replica count: 1
I0906 16:37:06.079469      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  6 16:37:06.188: INFO: Created: latency-svc-967l5
Sep  6 16:37:06.191: INFO: Got endpoints: latency-svc-967l5 [12.10086ms]
Sep  6 16:37:06.211: INFO: Created: latency-svc-2t2k7
Sep  6 16:37:06.213: INFO: Created: latency-svc-6sq6f
Sep  6 16:37:06.216: INFO: Got endpoints: latency-svc-2t2k7 [24.767707ms]
Sep  6 16:37:06.223: INFO: Got endpoints: latency-svc-6sq6f [30.854611ms]
Sep  6 16:37:06.229: INFO: Created: latency-svc-2vlcv
Sep  6 16:37:06.278: INFO: Got endpoints: latency-svc-2vlcv [86.362487ms]
Sep  6 16:37:06.294: INFO: Created: latency-svc-5pthr
Sep  6 16:37:06.300: INFO: Got endpoints: latency-svc-5pthr [107.756663ms]
Sep  6 16:37:06.329: INFO: Created: latency-svc-dz2b4
Sep  6 16:37:06.333: INFO: Got endpoints: latency-svc-dz2b4 [140.576294ms]
Sep  6 16:37:06.367: INFO: Created: latency-svc-5czs8
Sep  6 16:37:06.380: INFO: Got endpoints: latency-svc-5czs8 [187.498799ms]
Sep  6 16:37:06.392: INFO: Created: latency-svc-7ccnz
Sep  6 16:37:06.425: INFO: Got endpoints: latency-svc-7ccnz [232.370558ms]
Sep  6 16:37:06.441: INFO: Created: latency-svc-8xwmx
Sep  6 16:37:06.459: INFO: Got endpoints: latency-svc-8xwmx [266.051125ms]
Sep  6 16:37:06.518: INFO: Created: latency-svc-dksqp
Sep  6 16:37:06.520: INFO: Created: latency-svc-t2q9v
Sep  6 16:37:06.523: INFO: Got endpoints: latency-svc-t2q9v [330.053181ms]
Sep  6 16:37:06.531: INFO: Got endpoints: latency-svc-dksqp [339.005748ms]
Sep  6 16:37:06.536: INFO: Created: latency-svc-sv4lh
Sep  6 16:37:06.546: INFO: Got endpoints: latency-svc-sv4lh [353.030839ms]
Sep  6 16:37:06.555: INFO: Created: latency-svc-qbr9w
Sep  6 16:37:06.568: INFO: Got endpoints: latency-svc-qbr9w [375.853593ms]
Sep  6 16:37:06.569: INFO: Created: latency-svc-4nztm
Sep  6 16:37:06.571: INFO: Got endpoints: latency-svc-4nztm [378.496205ms]
Sep  6 16:37:06.582: INFO: Created: latency-svc-h7pqp
Sep  6 16:37:06.593: INFO: Got endpoints: latency-svc-h7pqp [400.650279ms]
Sep  6 16:37:06.594: INFO: Created: latency-svc-c54cl
Sep  6 16:37:06.605: INFO: Created: latency-svc-2w8lz
Sep  6 16:37:06.605: INFO: Got endpoints: latency-svc-c54cl [412.462973ms]
Sep  6 16:37:06.617: INFO: Created: latency-svc-zxks4
Sep  6 16:37:06.618: INFO: Got endpoints: latency-svc-2w8lz [401.806779ms]
Sep  6 16:37:06.632: INFO: Got endpoints: latency-svc-zxks4 [408.440486ms]
Sep  6 16:37:06.642: INFO: Created: latency-svc-92dss
Sep  6 16:37:06.642: INFO: Got endpoints: latency-svc-92dss [363.359542ms]
Sep  6 16:37:06.647: INFO: Created: latency-svc-4rvjf
Sep  6 16:37:06.652: INFO: Got endpoints: latency-svc-4rvjf [351.274664ms]
Sep  6 16:37:06.658: INFO: Created: latency-svc-5pkr5
Sep  6 16:37:06.664: INFO: Created: latency-svc-q72fx
Sep  6 16:37:06.666: INFO: Got endpoints: latency-svc-5pkr5 [332.695577ms]
Sep  6 16:37:06.679: INFO: Got endpoints: latency-svc-q72fx [298.930042ms]
Sep  6 16:37:06.688: INFO: Created: latency-svc-785mr
Sep  6 16:37:06.697: INFO: Created: latency-svc-4g49s
Sep  6 16:37:06.697: INFO: Got endpoints: latency-svc-785mr [272.13117ms]
Sep  6 16:37:06.704: INFO: Got endpoints: latency-svc-4g49s [244.505769ms]
Sep  6 16:37:06.706: INFO: Created: latency-svc-b89c9
Sep  6 16:37:06.712: INFO: Got endpoints: latency-svc-b89c9 [189.049611ms]
Sep  6 16:37:06.719: INFO: Created: latency-svc-9dsxq
Sep  6 16:37:06.725: INFO: Got endpoints: latency-svc-9dsxq [193.74462ms]
Sep  6 16:37:06.732: INFO: Created: latency-svc-ctm4l
Sep  6 16:37:06.743: INFO: Created: latency-svc-27wh6
Sep  6 16:37:06.747: INFO: Got endpoints: latency-svc-ctm4l [201.32539ms]
Sep  6 16:37:06.750: INFO: Got endpoints: latency-svc-27wh6 [181.257224ms]
Sep  6 16:37:06.757: INFO: Created: latency-svc-fl45g
Sep  6 16:37:06.768: INFO: Got endpoints: latency-svc-fl45g [196.5322ms]
Sep  6 16:37:06.770: INFO: Created: latency-svc-s6wc2
Sep  6 16:37:06.788: INFO: Got endpoints: latency-svc-s6wc2 [194.289997ms]
Sep  6 16:37:06.788: INFO: Created: latency-svc-b2hwr
Sep  6 16:37:06.813: INFO: Created: latency-svc-m4tm4
Sep  6 16:37:06.814: INFO: Got endpoints: latency-svc-b2hwr [208.683547ms]
Sep  6 16:37:06.833: INFO: Got endpoints: latency-svc-m4tm4 [214.283736ms]
Sep  6 16:37:06.836: INFO: Created: latency-svc-z5p6q
Sep  6 16:37:06.840: INFO: Got endpoints: latency-svc-z5p6q [206.757195ms]
Sep  6 16:37:06.849: INFO: Created: latency-svc-tpkms
Sep  6 16:37:06.852: INFO: Got endpoints: latency-svc-tpkms [209.9513ms]
Sep  6 16:37:06.858: INFO: Created: latency-svc-74fbd
Sep  6 16:37:06.872: INFO: Got endpoints: latency-svc-74fbd [219.907148ms]
Sep  6 16:37:06.872: INFO: Created: latency-svc-84l8j
Sep  6 16:37:06.875: INFO: Got endpoints: latency-svc-84l8j [208.630746ms]
Sep  6 16:37:06.880: INFO: Created: latency-svc-888vq
Sep  6 16:37:06.891: INFO: Created: latency-svc-2trp5
Sep  6 16:37:06.892: INFO: Got endpoints: latency-svc-888vq [212.844394ms]
Sep  6 16:37:06.904: INFO: Created: latency-svc-7cp7v
Sep  6 16:37:06.905: INFO: Got endpoints: latency-svc-2trp5 [207.276161ms]
Sep  6 16:37:06.911: INFO: Created: latency-svc-chb7b
Sep  6 16:37:06.917: INFO: Got endpoints: latency-svc-7cp7v [213.51055ms]
Sep  6 16:37:06.922: INFO: Got endpoints: latency-svc-chb7b [209.850043ms]
Sep  6 16:37:06.928: INFO: Created: latency-svc-kkhmh
Sep  6 16:37:06.936: INFO: Got endpoints: latency-svc-kkhmh [210.208762ms]
Sep  6 16:37:06.940: INFO: Created: latency-svc-5hdbm
Sep  6 16:37:06.947: INFO: Created: latency-svc-mrlbp
Sep  6 16:37:06.949: INFO: Got endpoints: latency-svc-5hdbm [201.871701ms]
Sep  6 16:37:06.956: INFO: Created: latency-svc-pslls
Sep  6 16:37:06.956: INFO: Got endpoints: latency-svc-mrlbp [206.450066ms]
Sep  6 16:37:06.964: INFO: Created: latency-svc-bjkm9
Sep  6 16:37:06.969: INFO: Got endpoints: latency-svc-pslls [201.173908ms]
Sep  6 16:37:06.973: INFO: Got endpoints: latency-svc-bjkm9 [185.091981ms]
Sep  6 16:37:06.976: INFO: Created: latency-svc-txh6n
Sep  6 16:37:06.990: INFO: Created: latency-svc-nt29j
Sep  6 16:37:07.003: INFO: Created: latency-svc-8nm6v
Sep  6 16:37:07.004: INFO: Got endpoints: latency-svc-txh6n [190.504915ms]
Sep  6 16:37:07.014: INFO: Created: latency-svc-587jp
Sep  6 16:37:07.026: INFO: Created: latency-svc-h6tnj
Sep  6 16:37:07.033: INFO: Created: latency-svc-qkskl
Sep  6 16:37:07.041: INFO: Created: latency-svc-khbmq
Sep  6 16:37:07.054: INFO: Created: latency-svc-ldwmt
Sep  6 16:37:07.057: INFO: Got endpoints: latency-svc-nt29j [224.0776ms]
Sep  6 16:37:07.063: INFO: Created: latency-svc-fl2db
Sep  6 16:37:07.070: INFO: Created: latency-svc-2g4zv
Sep  6 16:37:07.079: INFO: Created: latency-svc-d2vhr
Sep  6 16:37:07.096: INFO: Created: latency-svc-xk6cf
Sep  6 16:37:07.097: INFO: Created: latency-svc-7hxxn
Sep  6 16:37:07.100: INFO: Got endpoints: latency-svc-8nm6v [259.863855ms]
Sep  6 16:37:07.119: INFO: Created: latency-svc-ckbvf
Sep  6 16:37:07.131: INFO: Created: latency-svc-fp5vw
Sep  6 16:37:07.143: INFO: Got endpoints: latency-svc-587jp [291.432208ms]
Sep  6 16:37:07.145: INFO: Created: latency-svc-sgxg4
Sep  6 16:37:07.156: INFO: Created: latency-svc-xwpt9
Sep  6 16:37:07.159: INFO: Created: latency-svc-lvqdk
Sep  6 16:37:07.173: INFO: Created: latency-svc-pfpmr
Sep  6 16:37:07.194: INFO: Got endpoints: latency-svc-h6tnj [321.826964ms]
Sep  6 16:37:07.208: INFO: Created: latency-svc-xbcrm
Sep  6 16:37:07.241: INFO: Got endpoints: latency-svc-qkskl [365.93854ms]
Sep  6 16:37:07.251: INFO: Created: latency-svc-dmfpc
Sep  6 16:37:07.297: INFO: Got endpoints: latency-svc-khbmq [405.503626ms]
Sep  6 16:37:07.310: INFO: Created: latency-svc-xb2f7
Sep  6 16:37:07.345: INFO: Got endpoints: latency-svc-ldwmt [439.952939ms]
Sep  6 16:37:07.359: INFO: Created: latency-svc-tgrqr
Sep  6 16:37:07.394: INFO: Got endpoints: latency-svc-fl2db [476.224615ms]
Sep  6 16:37:07.406: INFO: Created: latency-svc-7lqvp
Sep  6 16:37:07.443: INFO: Got endpoints: latency-svc-2g4zv [521.098194ms]
Sep  6 16:37:07.454: INFO: Created: latency-svc-9wwgr
Sep  6 16:37:07.491: INFO: Got endpoints: latency-svc-d2vhr [555.613838ms]
Sep  6 16:37:07.505: INFO: Created: latency-svc-7vvvc
Sep  6 16:37:07.542: INFO: Got endpoints: latency-svc-7hxxn [592.769885ms]
Sep  6 16:37:07.558: INFO: Created: latency-svc-4ftth
Sep  6 16:37:07.591: INFO: Got endpoints: latency-svc-xk6cf [634.834576ms]
Sep  6 16:37:07.602: INFO: Created: latency-svc-pzxh2
Sep  6 16:37:07.641: INFO: Got endpoints: latency-svc-ckbvf [671.942733ms]
Sep  6 16:37:07.653: INFO: Created: latency-svc-vthqb
Sep  6 16:37:07.690: INFO: Got endpoints: latency-svc-fp5vw [716.462104ms]
Sep  6 16:37:07.701: INFO: Created: latency-svc-cglsr
Sep  6 16:37:07.740: INFO: Got endpoints: latency-svc-sgxg4 [736.181ms]
Sep  6 16:37:07.751: INFO: Created: latency-svc-zcmss
Sep  6 16:37:07.791: INFO: Got endpoints: latency-svc-xwpt9 [734.086192ms]
Sep  6 16:37:07.802: INFO: Created: latency-svc-w6d6r
Sep  6 16:37:07.841: INFO: Got endpoints: latency-svc-lvqdk [740.417392ms]
Sep  6 16:37:07.857: INFO: Created: latency-svc-kklfg
Sep  6 16:37:07.890: INFO: Got endpoints: latency-svc-pfpmr [746.98567ms]
Sep  6 16:37:07.900: INFO: Created: latency-svc-f8wqn
Sep  6 16:37:07.943: INFO: Got endpoints: latency-svc-xbcrm [749.136366ms]
Sep  6 16:37:07.956: INFO: Created: latency-svc-twvfz
Sep  6 16:37:07.990: INFO: Got endpoints: latency-svc-dmfpc [749.176996ms]
Sep  6 16:37:08.011: INFO: Created: latency-svc-p6p8l
Sep  6 16:37:08.043: INFO: Got endpoints: latency-svc-xb2f7 [745.505606ms]
Sep  6 16:37:08.054: INFO: Created: latency-svc-gswf7
Sep  6 16:37:08.091: INFO: Got endpoints: latency-svc-tgrqr [746.821682ms]
Sep  6 16:37:08.102: INFO: Created: latency-svc-fpwfh
Sep  6 16:37:08.140: INFO: Got endpoints: latency-svc-7lqvp [746.101314ms]
Sep  6 16:37:08.151: INFO: Created: latency-svc-rjdbc
Sep  6 16:37:08.192: INFO: Got endpoints: latency-svc-9wwgr [749.216391ms]
Sep  6 16:37:08.207: INFO: Created: latency-svc-hmr5p
Sep  6 16:37:08.244: INFO: Got endpoints: latency-svc-7vvvc [751.902219ms]
Sep  6 16:37:08.255: INFO: Created: latency-svc-hpn5b
Sep  6 16:37:08.291: INFO: Got endpoints: latency-svc-4ftth [748.877612ms]
Sep  6 16:37:08.300: INFO: Created: latency-svc-n7jvf
Sep  6 16:37:08.341: INFO: Got endpoints: latency-svc-pzxh2 [749.61339ms]
Sep  6 16:37:08.354: INFO: Created: latency-svc-kdf7b
Sep  6 16:37:08.390: INFO: Got endpoints: latency-svc-vthqb [749.084452ms]
Sep  6 16:37:08.414: INFO: Created: latency-svc-zzc76
Sep  6 16:37:08.441: INFO: Got endpoints: latency-svc-cglsr [750.668279ms]
Sep  6 16:37:08.451: INFO: Created: latency-svc-gfb44
Sep  6 16:37:08.491: INFO: Got endpoints: latency-svc-zcmss [750.517571ms]
Sep  6 16:37:08.508: INFO: Created: latency-svc-fd8pr
Sep  6 16:37:08.542: INFO: Got endpoints: latency-svc-w6d6r [750.795329ms]
Sep  6 16:37:08.555: INFO: Created: latency-svc-t6z2l
Sep  6 16:37:08.594: INFO: Got endpoints: latency-svc-kklfg [753.586925ms]
Sep  6 16:37:08.604: INFO: Created: latency-svc-pnfqd
Sep  6 16:37:08.641: INFO: Got endpoints: latency-svc-f8wqn [750.840483ms]
Sep  6 16:37:08.651: INFO: Created: latency-svc-5fzr7
Sep  6 16:37:08.696: INFO: Got endpoints: latency-svc-twvfz [753.06791ms]
Sep  6 16:37:08.710: INFO: Created: latency-svc-m64zp
Sep  6 16:37:08.741: INFO: Got endpoints: latency-svc-p6p8l [749.981271ms]
Sep  6 16:37:08.752: INFO: Created: latency-svc-thgkn
Sep  6 16:37:08.792: INFO: Got endpoints: latency-svc-gswf7 [748.957774ms]
Sep  6 16:37:08.833: INFO: Created: latency-svc-kkf4c
Sep  6 16:37:08.840: INFO: Got endpoints: latency-svc-fpwfh [749.017736ms]
Sep  6 16:37:08.851: INFO: Created: latency-svc-97xg6
Sep  6 16:37:08.891: INFO: Got endpoints: latency-svc-rjdbc [750.928031ms]
Sep  6 16:37:08.902: INFO: Created: latency-svc-4gkmh
Sep  6 16:37:08.941: INFO: Got endpoints: latency-svc-hmr5p [749.138404ms]
Sep  6 16:37:08.951: INFO: Created: latency-svc-stx6n
Sep  6 16:37:08.990: INFO: Got endpoints: latency-svc-hpn5b [746.868107ms]
Sep  6 16:37:09.001: INFO: Created: latency-svc-dpf8v
Sep  6 16:37:09.042: INFO: Got endpoints: latency-svc-n7jvf [750.448051ms]
Sep  6 16:37:09.053: INFO: Created: latency-svc-xjmn5
Sep  6 16:37:09.091: INFO: Got endpoints: latency-svc-kdf7b [749.761842ms]
Sep  6 16:37:09.103: INFO: Created: latency-svc-bnx68
Sep  6 16:37:09.142: INFO: Got endpoints: latency-svc-zzc76 [751.291156ms]
Sep  6 16:37:09.156: INFO: Created: latency-svc-zb4rl
Sep  6 16:37:09.192: INFO: Got endpoints: latency-svc-gfb44 [751.070652ms]
Sep  6 16:37:09.205: INFO: Created: latency-svc-vzdkt
Sep  6 16:37:09.241: INFO: Got endpoints: latency-svc-fd8pr [749.425876ms]
Sep  6 16:37:09.250: INFO: Created: latency-svc-tfzg5
Sep  6 16:37:09.293: INFO: Got endpoints: latency-svc-t6z2l [750.830319ms]
Sep  6 16:37:09.306: INFO: Created: latency-svc-skbp6
Sep  6 16:37:09.341: INFO: Got endpoints: latency-svc-pnfqd [746.495753ms]
Sep  6 16:37:09.352: INFO: Created: latency-svc-4tk7m
Sep  6 16:37:09.390: INFO: Got endpoints: latency-svc-5fzr7 [749.062684ms]
Sep  6 16:37:09.404: INFO: Created: latency-svc-fbn9c
Sep  6 16:37:09.447: INFO: Got endpoints: latency-svc-m64zp [750.662486ms]
Sep  6 16:37:09.458: INFO: Created: latency-svc-mfkb9
Sep  6 16:37:09.497: INFO: Got endpoints: latency-svc-thgkn [755.936977ms]
Sep  6 16:37:09.508: INFO: Created: latency-svc-pc98b
Sep  6 16:37:09.544: INFO: Got endpoints: latency-svc-kkf4c [751.321966ms]
Sep  6 16:37:09.555: INFO: Created: latency-svc-tmwkr
Sep  6 16:37:09.590: INFO: Got endpoints: latency-svc-97xg6 [749.815653ms]
Sep  6 16:37:09.604: INFO: Created: latency-svc-wmmbz
Sep  6 16:37:09.642: INFO: Got endpoints: latency-svc-4gkmh [751.251221ms]
Sep  6 16:37:09.656: INFO: Created: latency-svc-5nrn2
Sep  6 16:37:09.693: INFO: Got endpoints: latency-svc-stx6n [751.208575ms]
Sep  6 16:37:09.706: INFO: Created: latency-svc-lzcnr
Sep  6 16:37:09.740: INFO: Got endpoints: latency-svc-dpf8v [749.605492ms]
Sep  6 16:37:09.757: INFO: Created: latency-svc-xrknv
Sep  6 16:37:09.796: INFO: Got endpoints: latency-svc-xjmn5 [754.041465ms]
Sep  6 16:37:09.828: INFO: Created: latency-svc-gtc9m
Sep  6 16:37:09.841: INFO: Got endpoints: latency-svc-bnx68 [749.589949ms]
Sep  6 16:37:09.850: INFO: Created: latency-svc-2mw8q
Sep  6 16:37:09.893: INFO: Got endpoints: latency-svc-zb4rl [750.62856ms]
Sep  6 16:37:09.903: INFO: Created: latency-svc-82qgj
Sep  6 16:37:09.941: INFO: Got endpoints: latency-svc-vzdkt [749.487103ms]
Sep  6 16:37:09.951: INFO: Created: latency-svc-pxvzn
Sep  6 16:37:09.993: INFO: Got endpoints: latency-svc-tfzg5 [752.092587ms]
Sep  6 16:37:10.003: INFO: Created: latency-svc-5qkqp
Sep  6 16:37:10.042: INFO: Got endpoints: latency-svc-skbp6 [748.824336ms]
Sep  6 16:37:10.057: INFO: Created: latency-svc-qcpn7
Sep  6 16:37:10.094: INFO: Got endpoints: latency-svc-4tk7m [752.61009ms]
Sep  6 16:37:10.105: INFO: Created: latency-svc-zztxf
Sep  6 16:37:10.142: INFO: Got endpoints: latency-svc-fbn9c [752.198778ms]
Sep  6 16:37:10.152: INFO: Created: latency-svc-k4fps
Sep  6 16:37:10.191: INFO: Got endpoints: latency-svc-mfkb9 [744.158965ms]
Sep  6 16:37:10.201: INFO: Created: latency-svc-g8zp7
Sep  6 16:37:10.254: INFO: Got endpoints: latency-svc-pc98b [756.967244ms]
Sep  6 16:37:10.270: INFO: Created: latency-svc-v9xjb
Sep  6 16:37:10.292: INFO: Got endpoints: latency-svc-tmwkr [748.048465ms]
Sep  6 16:37:10.302: INFO: Created: latency-svc-lddwc
Sep  6 16:37:10.340: INFO: Got endpoints: latency-svc-wmmbz [750.040886ms]
Sep  6 16:37:10.351: INFO: Created: latency-svc-cc8ws
Sep  6 16:37:10.392: INFO: Got endpoints: latency-svc-5nrn2 [749.41004ms]
Sep  6 16:37:10.407: INFO: Created: latency-svc-zmtjd
Sep  6 16:37:10.441: INFO: Got endpoints: latency-svc-lzcnr [748.267584ms]
Sep  6 16:37:10.481: INFO: Created: latency-svc-cznbg
Sep  6 16:37:10.496: INFO: Got endpoints: latency-svc-xrknv [755.613064ms]
Sep  6 16:37:10.519: INFO: Created: latency-svc-q5tvv
Sep  6 16:37:10.554: INFO: Got endpoints: latency-svc-gtc9m [757.889243ms]
Sep  6 16:37:10.569: INFO: Created: latency-svc-sxcm9
Sep  6 16:37:10.595: INFO: Got endpoints: latency-svc-2mw8q [754.747542ms]
Sep  6 16:37:10.626: INFO: Created: latency-svc-ns7fd
Sep  6 16:37:10.641: INFO: Got endpoints: latency-svc-82qgj [748.068427ms]
Sep  6 16:37:10.655: INFO: Created: latency-svc-k72z9
Sep  6 16:37:10.706: INFO: Got endpoints: latency-svc-pxvzn [764.899829ms]
Sep  6 16:37:10.725: INFO: Created: latency-svc-rrkg4
Sep  6 16:37:10.747: INFO: Got endpoints: latency-svc-5qkqp [753.812498ms]
Sep  6 16:37:10.777: INFO: Created: latency-svc-ncgdk
Sep  6 16:37:10.790: INFO: Got endpoints: latency-svc-qcpn7 [748.525114ms]
Sep  6 16:37:10.805: INFO: Created: latency-svc-xctvn
Sep  6 16:37:10.841: INFO: Got endpoints: latency-svc-zztxf [747.009721ms]
Sep  6 16:37:10.851: INFO: Created: latency-svc-qfksp
Sep  6 16:37:10.893: INFO: Got endpoints: latency-svc-k4fps [750.021949ms]
Sep  6 16:37:10.905: INFO: Created: latency-svc-k44bp
Sep  6 16:37:10.943: INFO: Got endpoints: latency-svc-g8zp7 [751.689329ms]
Sep  6 16:37:10.954: INFO: Created: latency-svc-52h5h
Sep  6 16:37:10.993: INFO: Got endpoints: latency-svc-v9xjb [738.835955ms]
Sep  6 16:37:11.007: INFO: Created: latency-svc-jbkcm
Sep  6 16:37:11.041: INFO: Got endpoints: latency-svc-lddwc [749.599496ms]
Sep  6 16:37:11.055: INFO: Created: latency-svc-2tn9j
Sep  6 16:37:11.093: INFO: Got endpoints: latency-svc-cc8ws [752.876361ms]
Sep  6 16:37:11.104: INFO: Created: latency-svc-tztxb
Sep  6 16:37:11.145: INFO: Got endpoints: latency-svc-zmtjd [752.577294ms]
Sep  6 16:37:11.157: INFO: Created: latency-svc-ss6rm
Sep  6 16:37:11.192: INFO: Got endpoints: latency-svc-cznbg [751.035538ms]
Sep  6 16:37:11.203: INFO: Created: latency-svc-vmvnk
Sep  6 16:37:11.241: INFO: Got endpoints: latency-svc-q5tvv [745.117143ms]
Sep  6 16:37:11.253: INFO: Created: latency-svc-rxptv
Sep  6 16:37:11.294: INFO: Got endpoints: latency-svc-sxcm9 [739.560048ms]
Sep  6 16:37:11.317: INFO: Created: latency-svc-jzmvm
Sep  6 16:37:11.341: INFO: Got endpoints: latency-svc-ns7fd [745.87853ms]
Sep  6 16:37:11.350: INFO: Created: latency-svc-v4jbh
Sep  6 16:37:11.392: INFO: Got endpoints: latency-svc-k72z9 [751.514047ms]
Sep  6 16:37:11.406: INFO: Created: latency-svc-4j2r9
Sep  6 16:37:11.449: INFO: Got endpoints: latency-svc-rrkg4 [742.375688ms]
Sep  6 16:37:11.461: INFO: Created: latency-svc-kpc4c
Sep  6 16:37:11.493: INFO: Got endpoints: latency-svc-ncgdk [743.551039ms]
Sep  6 16:37:11.505: INFO: Created: latency-svc-jfj74
Sep  6 16:37:11.551: INFO: Got endpoints: latency-svc-xctvn [760.3061ms]
Sep  6 16:37:11.571: INFO: Created: latency-svc-6hx24
Sep  6 16:37:11.591: INFO: Got endpoints: latency-svc-qfksp [749.771817ms]
Sep  6 16:37:11.607: INFO: Created: latency-svc-ctwj6
Sep  6 16:37:11.641: INFO: Got endpoints: latency-svc-k44bp [748.524319ms]
Sep  6 16:37:11.653: INFO: Created: latency-svc-7gbcc
Sep  6 16:37:11.691: INFO: Got endpoints: latency-svc-52h5h [747.739051ms]
Sep  6 16:37:11.701: INFO: Created: latency-svc-zhzwf
Sep  6 16:37:11.744: INFO: Got endpoints: latency-svc-jbkcm [750.506571ms]
Sep  6 16:37:11.756: INFO: Created: latency-svc-9qhkq
Sep  6 16:37:11.791: INFO: Got endpoints: latency-svc-2tn9j [749.043702ms]
Sep  6 16:37:11.802: INFO: Created: latency-svc-2fttw
Sep  6 16:37:11.841: INFO: Got endpoints: latency-svc-tztxb [747.299858ms]
Sep  6 16:37:11.855: INFO: Created: latency-svc-zj2wn
Sep  6 16:37:11.897: INFO: Got endpoints: latency-svc-ss6rm [751.768778ms]
Sep  6 16:37:11.917: INFO: Created: latency-svc-hfqfz
Sep  6 16:37:11.943: INFO: Got endpoints: latency-svc-vmvnk [749.930477ms]
Sep  6 16:37:11.955: INFO: Created: latency-svc-7fw2b
Sep  6 16:37:11.995: INFO: Got endpoints: latency-svc-rxptv [753.736586ms]
Sep  6 16:37:12.008: INFO: Created: latency-svc-9fpvc
Sep  6 16:37:12.043: INFO: Got endpoints: latency-svc-jzmvm [748.972688ms]
Sep  6 16:37:12.053: INFO: Created: latency-svc-nrfn8
Sep  6 16:37:12.094: INFO: Got endpoints: latency-svc-v4jbh [751.931504ms]
Sep  6 16:37:12.106: INFO: Created: latency-svc-qcv6m
Sep  6 16:37:12.141: INFO: Got endpoints: latency-svc-4j2r9 [748.98612ms]
Sep  6 16:37:12.153: INFO: Created: latency-svc-6spsq
Sep  6 16:37:12.197: INFO: Got endpoints: latency-svc-kpc4c [748.001149ms]
Sep  6 16:37:12.209: INFO: Created: latency-svc-bhgbd
Sep  6 16:37:12.241: INFO: Got endpoints: latency-svc-jfj74 [747.866071ms]
Sep  6 16:37:12.252: INFO: Created: latency-svc-mbgxx
Sep  6 16:37:12.291: INFO: Got endpoints: latency-svc-6hx24 [732.45198ms]
Sep  6 16:37:12.302: INFO: Created: latency-svc-j7qct
Sep  6 16:37:12.341: INFO: Got endpoints: latency-svc-ctwj6 [750.624143ms]
Sep  6 16:37:12.355: INFO: Created: latency-svc-rmpj5
Sep  6 16:37:12.397: INFO: Got endpoints: latency-svc-7gbcc [755.534863ms]
Sep  6 16:37:12.406: INFO: Created: latency-svc-h5294
Sep  6 16:37:12.442: INFO: Got endpoints: latency-svc-zhzwf [751.069975ms]
Sep  6 16:37:12.455: INFO: Created: latency-svc-f4l2z
Sep  6 16:37:12.491: INFO: Got endpoints: latency-svc-9qhkq [747.352094ms]
Sep  6 16:37:12.504: INFO: Created: latency-svc-l294d
Sep  6 16:37:12.541: INFO: Got endpoints: latency-svc-2fttw [749.950319ms]
Sep  6 16:37:12.557: INFO: Created: latency-svc-bd4s4
Sep  6 16:37:12.592: INFO: Got endpoints: latency-svc-zj2wn [751.680362ms]
Sep  6 16:37:12.608: INFO: Created: latency-svc-ktqz4
Sep  6 16:37:12.651: INFO: Got endpoints: latency-svc-hfqfz [754.225439ms]
Sep  6 16:37:12.662: INFO: Created: latency-svc-2m58j
Sep  6 16:37:12.690: INFO: Got endpoints: latency-svc-7fw2b [747.358616ms]
Sep  6 16:37:12.701: INFO: Created: latency-svc-4q8pq
Sep  6 16:37:12.741: INFO: Got endpoints: latency-svc-9fpvc [746.008396ms]
Sep  6 16:37:12.750: INFO: Created: latency-svc-k2zgm
Sep  6 16:37:12.794: INFO: Got endpoints: latency-svc-nrfn8 [751.61654ms]
Sep  6 16:37:12.803: INFO: Created: latency-svc-wfvjv
Sep  6 16:37:12.847: INFO: Got endpoints: latency-svc-qcv6m [753.832335ms]
Sep  6 16:37:12.859: INFO: Created: latency-svc-pgd9x
Sep  6 16:37:12.892: INFO: Got endpoints: latency-svc-6spsq [750.32702ms]
Sep  6 16:37:12.903: INFO: Created: latency-svc-ldds7
Sep  6 16:37:12.941: INFO: Got endpoints: latency-svc-bhgbd [743.682725ms]
Sep  6 16:37:12.966: INFO: Created: latency-svc-5d78c
Sep  6 16:37:12.990: INFO: Got endpoints: latency-svc-mbgxx [748.974436ms]
Sep  6 16:37:13.002: INFO: Created: latency-svc-sc6zt
Sep  6 16:37:13.040: INFO: Got endpoints: latency-svc-j7qct [748.753009ms]
Sep  6 16:37:13.052: INFO: Created: latency-svc-qmkpd
Sep  6 16:37:13.092: INFO: Got endpoints: latency-svc-rmpj5 [750.650455ms]
Sep  6 16:37:13.102: INFO: Created: latency-svc-4njkt
Sep  6 16:37:13.141: INFO: Got endpoints: latency-svc-h5294 [743.718974ms]
Sep  6 16:37:13.150: INFO: Created: latency-svc-5crzp
Sep  6 16:37:13.191: INFO: Got endpoints: latency-svc-f4l2z [749.128393ms]
Sep  6 16:37:13.201: INFO: Created: latency-svc-f4xrc
Sep  6 16:37:13.242: INFO: Got endpoints: latency-svc-l294d [750.5759ms]
Sep  6 16:37:13.253: INFO: Created: latency-svc-fqjfm
Sep  6 16:37:13.294: INFO: Got endpoints: latency-svc-bd4s4 [753.205621ms]
Sep  6 16:37:13.305: INFO: Created: latency-svc-cwqnq
Sep  6 16:37:13.340: INFO: Got endpoints: latency-svc-ktqz4 [747.625148ms]
Sep  6 16:37:13.349: INFO: Created: latency-svc-6v5pj
Sep  6 16:37:13.392: INFO: Got endpoints: latency-svc-2m58j [741.288642ms]
Sep  6 16:37:13.403: INFO: Created: latency-svc-flmfk
Sep  6 16:37:13.444: INFO: Got endpoints: latency-svc-4q8pq [754.096874ms]
Sep  6 16:37:13.456: INFO: Created: latency-svc-99htn
Sep  6 16:37:13.491: INFO: Got endpoints: latency-svc-k2zgm [749.852753ms]
Sep  6 16:37:13.501: INFO: Created: latency-svc-2s2s2
Sep  6 16:37:13.546: INFO: Got endpoints: latency-svc-wfvjv [751.955571ms]
Sep  6 16:37:13.558: INFO: Created: latency-svc-g7fmd
Sep  6 16:37:13.595: INFO: Got endpoints: latency-svc-pgd9x [747.348868ms]
Sep  6 16:37:13.611: INFO: Created: latency-svc-hc28s
Sep  6 16:37:13.644: INFO: Got endpoints: latency-svc-ldds7 [751.925911ms]
Sep  6 16:37:13.657: INFO: Created: latency-svc-2ngkp
Sep  6 16:37:13.691: INFO: Got endpoints: latency-svc-5d78c [750.655721ms]
Sep  6 16:37:13.707: INFO: Created: latency-svc-4qzlz
Sep  6 16:37:13.741: INFO: Got endpoints: latency-svc-sc6zt [750.915528ms]
Sep  6 16:37:13.767: INFO: Created: latency-svc-w6mc5
Sep  6 16:37:13.792: INFO: Got endpoints: latency-svc-qmkpd [751.823914ms]
Sep  6 16:37:13.807: INFO: Created: latency-svc-ljcg8
Sep  6 16:37:13.841: INFO: Got endpoints: latency-svc-4njkt [748.737159ms]
Sep  6 16:37:13.852: INFO: Created: latency-svc-4css8
Sep  6 16:37:13.892: INFO: Got endpoints: latency-svc-5crzp [750.864339ms]
Sep  6 16:37:13.907: INFO: Created: latency-svc-njv7d
Sep  6 16:37:13.943: INFO: Got endpoints: latency-svc-f4xrc [751.678901ms]
Sep  6 16:37:13.956: INFO: Created: latency-svc-9cdks
Sep  6 16:37:13.990: INFO: Got endpoints: latency-svc-fqjfm [748.245535ms]
Sep  6 16:37:14.006: INFO: Created: latency-svc-dfjmr
Sep  6 16:37:14.046: INFO: Got endpoints: latency-svc-cwqnq [751.206854ms]
Sep  6 16:37:14.091: INFO: Got endpoints: latency-svc-6v5pj [750.888902ms]
Sep  6 16:37:14.142: INFO: Got endpoints: latency-svc-flmfk [749.86862ms]
Sep  6 16:37:14.193: INFO: Got endpoints: latency-svc-99htn [748.910283ms]
Sep  6 16:37:14.244: INFO: Got endpoints: latency-svc-2s2s2 [753.102003ms]
Sep  6 16:37:14.295: INFO: Got endpoints: latency-svc-g7fmd [748.35182ms]
Sep  6 16:37:14.342: INFO: Got endpoints: latency-svc-hc28s [746.797405ms]
Sep  6 16:37:14.393: INFO: Got endpoints: latency-svc-2ngkp [748.972296ms]
Sep  6 16:37:14.442: INFO: Got endpoints: latency-svc-4qzlz [750.970198ms]
Sep  6 16:37:14.492: INFO: Got endpoints: latency-svc-w6mc5 [750.720985ms]
Sep  6 16:37:14.542: INFO: Got endpoints: latency-svc-ljcg8 [750.080455ms]
Sep  6 16:37:14.592: INFO: Got endpoints: latency-svc-4css8 [751.104279ms]
Sep  6 16:37:14.648: INFO: Got endpoints: latency-svc-njv7d [756.217591ms]
Sep  6 16:37:14.691: INFO: Got endpoints: latency-svc-9cdks [747.717087ms]
Sep  6 16:37:14.743: INFO: Got endpoints: latency-svc-dfjmr [752.449483ms]
Sep  6 16:37:14.743: INFO: Latencies: [24.767707ms 30.854611ms 86.362487ms 107.756663ms 140.576294ms 181.257224ms 185.091981ms 187.498799ms 189.049611ms 190.504915ms 193.74462ms 194.289997ms 196.5322ms 201.173908ms 201.32539ms 201.871701ms 206.450066ms 206.757195ms 207.276161ms 208.630746ms 208.683547ms 209.850043ms 209.9513ms 210.208762ms 212.844394ms 213.51055ms 214.283736ms 219.907148ms 224.0776ms 232.370558ms 244.505769ms 259.863855ms 266.051125ms 272.13117ms 291.432208ms 298.930042ms 321.826964ms 330.053181ms 332.695577ms 339.005748ms 351.274664ms 353.030839ms 363.359542ms 365.93854ms 375.853593ms 378.496205ms 400.650279ms 401.806779ms 405.503626ms 408.440486ms 412.462973ms 439.952939ms 476.224615ms 521.098194ms 555.613838ms 592.769885ms 634.834576ms 671.942733ms 716.462104ms 732.45198ms 734.086192ms 736.181ms 738.835955ms 739.560048ms 740.417392ms 741.288642ms 742.375688ms 743.551039ms 743.682725ms 743.718974ms 744.158965ms 745.117143ms 745.505606ms 745.87853ms 746.008396ms 746.101314ms 746.495753ms 746.797405ms 746.821682ms 746.868107ms 746.98567ms 747.009721ms 747.299858ms 747.348868ms 747.352094ms 747.358616ms 747.625148ms 747.717087ms 747.739051ms 747.866071ms 748.001149ms 748.048465ms 748.068427ms 748.245535ms 748.267584ms 748.35182ms 748.524319ms 748.525114ms 748.737159ms 748.753009ms 748.824336ms 748.877612ms 748.910283ms 748.957774ms 748.972296ms 748.972688ms 748.974436ms 748.98612ms 749.017736ms 749.043702ms 749.062684ms 749.084452ms 749.128393ms 749.136366ms 749.138404ms 749.176996ms 749.216391ms 749.41004ms 749.425876ms 749.487103ms 749.589949ms 749.599496ms 749.605492ms 749.61339ms 749.761842ms 749.771817ms 749.815653ms 749.852753ms 749.86862ms 749.930477ms 749.950319ms 749.981271ms 750.021949ms 750.040886ms 750.080455ms 750.32702ms 750.448051ms 750.506571ms 750.517571ms 750.5759ms 750.624143ms 750.62856ms 750.650455ms 750.655721ms 750.662486ms 750.668279ms 750.720985ms 750.795329ms 750.830319ms 750.840483ms 750.864339ms 750.888902ms 750.915528ms 750.928031ms 750.970198ms 751.035538ms 751.069975ms 751.070652ms 751.104279ms 751.206854ms 751.208575ms 751.251221ms 751.291156ms 751.321966ms 751.514047ms 751.61654ms 751.678901ms 751.680362ms 751.689329ms 751.768778ms 751.823914ms 751.902219ms 751.925911ms 751.931504ms 751.955571ms 752.092587ms 752.198778ms 752.449483ms 752.577294ms 752.61009ms 752.876361ms 753.06791ms 753.102003ms 753.205621ms 753.586925ms 753.736586ms 753.812498ms 753.832335ms 754.041465ms 754.096874ms 754.225439ms 754.747542ms 755.534863ms 755.613064ms 755.936977ms 756.217591ms 756.967244ms 757.889243ms 760.3061ms 764.899829ms]
Sep  6 16:37:14.744: INFO: 50 %ile: 748.824336ms
Sep  6 16:37:14.744: INFO: 90 %ile: 752.876361ms
Sep  6 16:37:14.744: INFO: 99 %ile: 760.3061ms
Sep  6 16:37:14.745: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:37:14.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-9131" for this suite.
Sep  6 16:37:26.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:37:26.813: INFO: namespace svc-latency-9131 deletion completed in 12.065479893s

• [SLOW TEST:21.811 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:37:26.814: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep  6 16:37:26.839: INFO: Waiting up to 5m0s for pod "pod-9c716a41-d0c4-11e9-a08c-82ce3d77f2cb" in namespace "emptydir-6458" to be "success or failure"
Sep  6 16:37:26.844: INFO: Pod "pod-9c716a41-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.660389ms
Sep  6 16:37:28.847: INFO: Pod "pod-9c716a41-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007583929s
STEP: Saw pod success
Sep  6 16:37:28.847: INFO: Pod "pod-9c716a41-d0c4-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:37:28.849: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-9c716a41-d0c4-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 16:37:28.862: INFO: Waiting for pod pod-9c716a41-d0c4-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:37:28.865: INFO: Pod pod-9c716a41-d0c4-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:37:28.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6458" for this suite.
Sep  6 16:37:34.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:37:34.932: INFO: namespace emptydir-6458 deletion completed in 6.065332235s

• [SLOW TEST:8.119 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:37:34.933: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-a1480919-d0c4-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume configMaps
Sep  6 16:37:34.959: INFO: Waiting up to 5m0s for pod "pod-configmaps-a1485ae4-d0c4-11e9-a08c-82ce3d77f2cb" in namespace "configmap-699" to be "success or failure"
Sep  6 16:37:34.961: INFO: Pod "pod-configmaps-a1485ae4-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.800122ms
Sep  6 16:37:36.964: INFO: Pod "pod-configmaps-a1485ae4-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004773109s
STEP: Saw pod success
Sep  6 16:37:36.964: INFO: Pod "pod-configmaps-a1485ae4-d0c4-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:37:36.966: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-configmaps-a1485ae4-d0c4-11e9-a08c-82ce3d77f2cb container configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 16:37:36.978: INFO: Waiting for pod pod-configmaps-a1485ae4-d0c4-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:37:36.980: INFO: Pod pod-configmaps-a1485ae4-d0c4-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:37:36.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-699" for this suite.
Sep  6 16:37:42.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:37:43.057: INFO: namespace configmap-699 deletion completed in 6.074923702s

• [SLOW TEST:8.125 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:37:43.058: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-a6225445-d0c4-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume secrets
Sep  6 16:37:43.100: INFO: Waiting up to 5m0s for pod "pod-secrets-a622ae64-d0c4-11e9-a08c-82ce3d77f2cb" in namespace "secrets-7014" to be "success or failure"
Sep  6 16:37:43.105: INFO: Pod "pod-secrets-a622ae64-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.226949ms
Sep  6 16:37:45.107: INFO: Pod "pod-secrets-a622ae64-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007109374s
STEP: Saw pod success
Sep  6 16:37:45.107: INFO: Pod "pod-secrets-a622ae64-d0c4-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:37:45.109: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-secrets-a622ae64-d0c4-11e9-a08c-82ce3d77f2cb container secret-volume-test: <nil>
STEP: delete the pod
Sep  6 16:37:45.122: INFO: Waiting for pod pod-secrets-a622ae64-d0c4-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:37:45.125: INFO: Pod pod-secrets-a622ae64-d0c4-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:37:45.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7014" for this suite.
Sep  6 16:37:51.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:37:51.195: INFO: namespace secrets-7014 deletion completed in 6.068280428s

• [SLOW TEST:8.138 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:37:51.196: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  6 16:37:51.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7868'
Sep  6 16:37:51.312: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  6 16:37:51.312: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Sep  6 16:37:51.316: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-jjrng]
Sep  6 16:37:51.316: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-jjrng" in namespace "kubectl-7868" to be "running and ready"
Sep  6 16:37:51.318: INFO: Pod "e2e-test-nginx-rc-jjrng": Phase="Pending", Reason="", readiness=false. Elapsed: 1.775976ms
Sep  6 16:37:53.321: INFO: Pod "e2e-test-nginx-rc-jjrng": Phase="Running", Reason="", readiness=true. Elapsed: 2.0048192s
Sep  6 16:37:53.321: INFO: Pod "e2e-test-nginx-rc-jjrng" satisfied condition "running and ready"
Sep  6 16:37:53.321: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-jjrng]
Sep  6 16:37:53.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 logs rc/e2e-test-nginx-rc --namespace=kubectl-7868'
Sep  6 16:37:53.402: INFO: stderr: ""
Sep  6 16:37:53.402: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1425
Sep  6 16:37:53.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 delete rc e2e-test-nginx-rc --namespace=kubectl-7868'
Sep  6 16:37:53.475: INFO: stderr: ""
Sep  6 16:37:53.475: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:37:53.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7868" for this suite.
Sep  6 16:38:15.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:38:15.542: INFO: namespace kubectl-7868 deletion completed in 22.064429725s

• [SLOW TEST:24.346 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:38:15.543: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Sep  6 16:38:15.570: INFO: Waiting up to 5m0s for pod "client-containers-b97c9970-d0c4-11e9-a08c-82ce3d77f2cb" in namespace "containers-917" to be "success or failure"
Sep  6 16:38:15.572: INFO: Pod "client-containers-b97c9970-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.840004ms
Sep  6 16:38:17.575: INFO: Pod "client-containers-b97c9970-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005321881s
Sep  6 16:38:19.578: INFO: Pod "client-containers-b97c9970-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008171545s
STEP: Saw pod success
Sep  6 16:38:19.578: INFO: Pod "client-containers-b97c9970-d0c4-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:38:19.580: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod client-containers-b97c9970-d0c4-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 16:38:19.592: INFO: Waiting for pod client-containers-b97c9970-d0c4-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:38:19.593: INFO: Pod client-containers-b97c9970-d0c4-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:38:19.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-917" for this suite.
Sep  6 16:38:25.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:38:25.660: INFO: namespace containers-917 deletion completed in 6.064915483s

• [SLOW TEST:10.118 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:38:25.660: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-bf848145-d0c4-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume secrets
Sep  6 16:38:25.689: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bf852ba6-d0c4-11e9-a08c-82ce3d77f2cb" in namespace "projected-2398" to be "success or failure"
Sep  6 16:38:25.691: INFO: Pod "pod-projected-secrets-bf852ba6-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.438679ms
Sep  6 16:38:27.694: INFO: Pod "pod-projected-secrets-bf852ba6-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005510641s
STEP: Saw pod success
Sep  6 16:38:27.694: INFO: Pod "pod-projected-secrets-bf852ba6-d0c4-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:38:27.696: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-projected-secrets-bf852ba6-d0c4-11e9-a08c-82ce3d77f2cb container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  6 16:38:27.709: INFO: Waiting for pod pod-projected-secrets-bf852ba6-d0c4-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:38:27.712: INFO: Pod pod-projected-secrets-bf852ba6-d0c4-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:38:27.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2398" for this suite.
Sep  6 16:38:33.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:38:33.783: INFO: namespace projected-2398 deletion completed in 6.068905536s

• [SLOW TEST:8.122 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:38:33.783: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0906 16:39:03.832955      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  6 16:39:03.832: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:39:03.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2493" for this suite.
Sep  6 16:39:09.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:39:09.910: INFO: namespace gc-2493 deletion completed in 6.075619644s

• [SLOW TEST:36.127 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:39:09.911: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep  6 16:39:09.934: INFO: Waiting up to 5m0s for pod "pod-d9e47eb2-d0c4-11e9-a08c-82ce3d77f2cb" in namespace "emptydir-2908" to be "success or failure"
Sep  6 16:39:09.937: INFO: Pod "pod-d9e47eb2-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.086903ms
Sep  6 16:39:11.941: INFO: Pod "pod-d9e47eb2-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006153652s
STEP: Saw pod success
Sep  6 16:39:11.941: INFO: Pod "pod-d9e47eb2-d0c4-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:39:11.942: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-d9e47eb2-d0c4-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 16:39:11.958: INFO: Waiting for pod pod-d9e47eb2-d0c4-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:39:11.960: INFO: Pod pod-d9e47eb2-d0c4-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:39:11.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2908" for this suite.
Sep  6 16:39:17.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:39:18.036: INFO: namespace emptydir-2908 deletion completed in 6.073188342s

• [SLOW TEST:8.125 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:39:18.036: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Sep  6 16:39:18.056: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-959664940 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:39:18.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-394" for this suite.
Sep  6 16:39:24.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:39:24.195: INFO: namespace kubectl-394 deletion completed in 6.075511922s

• [SLOW TEST:6.159 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:39:24.195: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0906 16:40:04.237161      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  6 16:40:04.237: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:40:04.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9624" for this suite.
Sep  6 16:40:10.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:40:10.311: INFO: namespace gc-9624 deletion completed in 6.072406033s

• [SLOW TEST:46.116 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:40:10.311: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-fde50b3b-d0c4-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume secrets
Sep  6 16:40:10.338: INFO: Waiting up to 5m0s for pod "pod-secrets-fde563ce-d0c4-11e9-a08c-82ce3d77f2cb" in namespace "secrets-2323" to be "success or failure"
Sep  6 16:40:10.342: INFO: Pod "pod-secrets-fde563ce-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.477955ms
Sep  6 16:40:12.345: INFO: Pod "pod-secrets-fde563ce-d0c4-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007574679s
STEP: Saw pod success
Sep  6 16:40:12.346: INFO: Pod "pod-secrets-fde563ce-d0c4-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:40:12.347: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-secrets-fde563ce-d0c4-11e9-a08c-82ce3d77f2cb container secret-volume-test: <nil>
STEP: delete the pod
Sep  6 16:40:12.359: INFO: Waiting for pod pod-secrets-fde563ce-d0c4-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:40:12.361: INFO: Pod pod-secrets-fde563ce-d0c4-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:40:12.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2323" for this suite.
Sep  6 16:40:18.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:40:18.427: INFO: namespace secrets-2323 deletion completed in 6.064514507s

• [SLOW TEST:8.116 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:40:18.428: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 16:40:18.466: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  6 16:40:20.477: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep  6 16:40:22.480: INFO: Creating deployment "test-rollover-deployment"
Sep  6 16:40:22.497: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep  6 16:40:24.504: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep  6 16:40:24.508: INFO: Ensure that both replica sets have 1 created replica
Sep  6 16:40:24.512: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep  6 16:40:24.517: INFO: Updating deployment test-rollover-deployment
Sep  6 16:40:24.517: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep  6 16:40:26.522: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep  6 16:40:26.527: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep  6 16:40:26.532: INFO: all replica sets need to contain the pod-template-hash label
Sep  6 16:40:26.532: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384822, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384822, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384826, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384822, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  6 16:40:28.537: INFO: all replica sets need to contain the pod-template-hash label
Sep  6 16:40:28.537: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384822, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384822, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384826, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384822, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  6 16:40:30.537: INFO: all replica sets need to contain the pod-template-hash label
Sep  6 16:40:30.537: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384822, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384822, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384826, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384822, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  6 16:40:32.537: INFO: all replica sets need to contain the pod-template-hash label
Sep  6 16:40:32.537: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384822, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384822, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384826, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384822, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  6 16:40:34.537: INFO: all replica sets need to contain the pod-template-hash label
Sep  6 16:40:34.537: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384822, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384822, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384826, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703384822, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  6 16:40:36.537: INFO: 
Sep  6 16:40:36.537: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  6 16:40:36.543: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-8105,SelfLink:/apis/apps/v1/namespaces/deployment-8105/deployments/test-rollover-deployment,UID:0521a0a2-d0c5-11e9-8afa-02e25174ea0a,ResourceVersion:13869,Generation:2,CreationTimestamp:2019-09-06 16:40:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-06 16:40:22 +0000 UTC 2019-09-06 16:40:22 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-06 16:40:36 +0000 UTC 2019-09-06 16:40:22 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-659c699649" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  6 16:40:36.545: INFO: New ReplicaSet "test-rollover-deployment-659c699649" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649,GenerateName:,Namespace:deployment-8105,SelfLink:/apis/apps/v1/namespaces/deployment-8105/replicasets/test-rollover-deployment-659c699649,UID:06575e04-d0c5-11e9-8afa-02e25174ea0a,ResourceVersion:13862,Generation:2,CreationTimestamp:2019-09-06 16:40:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 0521a0a2-d0c5-11e9-8afa-02e25174ea0a 0xc002718507 0xc002718508}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  6 16:40:36.545: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep  6 16:40:36.545: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-8105,SelfLink:/apis/apps/v1/namespaces/deployment-8105/replicasets/test-rollover-controller,UID:02b8ee53-d0c5-11e9-8afa-02e25174ea0a,ResourceVersion:13868,Generation:2,CreationTimestamp:2019-09-06 16:40:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 0521a0a2-d0c5-11e9-8afa-02e25174ea0a 0xc002718437 0xc002718438}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  6 16:40:36.545: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-7b45b6464,GenerateName:,Namespace:deployment-8105,SelfLink:/apis/apps/v1/namespaces/deployment-8105/replicasets/test-rollover-deployment-7b45b6464,UID:0523402c-d0c5-11e9-8afa-02e25174ea0a,ResourceVersion:13836,Generation:2,CreationTimestamp:2019-09-06 16:40:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 0521a0a2-d0c5-11e9-8afa-02e25174ea0a 0xc0027185d0 0xc0027185d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  6 16:40:36.547: INFO: Pod "test-rollover-deployment-659c699649-cwdvg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649-cwdvg,GenerateName:test-rollover-deployment-659c699649-,Namespace:deployment-8105,SelfLink:/api/v1/namespaces/deployment-8105/pods/test-rollover-deployment-659c699649-cwdvg,UID:065b7c26-d0c5-11e9-8afa-02e25174ea0a,ResourceVersion:13845,Generation:0,CreationTimestamp:2019-09-06 16:40:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-659c699649 06575e04-d0c5-11e9-8afa-02e25174ea0a 0xc002412397 0xc002412398}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-gwjvw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gwjvw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-gwjvw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-162.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002412400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002412420}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:40:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:40:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:40:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 16:40:24 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.162,PodIP:100.96.2.197,StartTime:2019-09-06 16:40:24 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-06 16:40:25 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://bb30a13cc02b432f641a9aa167823a7d1c23e824eba774dd0d0ee8e64be50b51}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:40:36.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8105" for this suite.
Sep  6 16:40:42.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:40:42.612: INFO: namespace deployment-8105 deletion completed in 6.062854578s

• [SLOW TEST:24.184 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:40:42.613: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep  6 16:40:42.637: INFO: Waiting up to 5m0s for pod "pod-1125ea1f-d0c5-11e9-a08c-82ce3d77f2cb" in namespace "emptydir-9919" to be "success or failure"
Sep  6 16:40:42.640: INFO: Pod "pod-1125ea1f-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.498436ms
Sep  6 16:40:44.643: INFO: Pod "pod-1125ea1f-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005440532s
STEP: Saw pod success
Sep  6 16:40:44.643: INFO: Pod "pod-1125ea1f-d0c5-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:40:44.645: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-1125ea1f-d0c5-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 16:40:44.658: INFO: Waiting for pod pod-1125ea1f-d0c5-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:40:44.660: INFO: Pod pod-1125ea1f-d0c5-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:40:44.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9919" for this suite.
Sep  6 16:40:50.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:40:50.739: INFO: namespace emptydir-9919 deletion completed in 6.076834529s

• [SLOW TEST:8.126 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:40:50.739: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-15fd8bf6-d0c5-11e9-a08c-82ce3d77f2cb
STEP: Creating a pod to test consume configMaps
Sep  6 16:40:50.764: INFO: Waiting up to 5m0s for pod "pod-configmaps-15fde120-d0c5-11e9-a08c-82ce3d77f2cb" in namespace "configmap-2998" to be "success or failure"
Sep  6 16:40:50.769: INFO: Pod "pod-configmaps-15fde120-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.177481ms
Sep  6 16:40:52.772: INFO: Pod "pod-configmaps-15fde120-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008224563s
STEP: Saw pod success
Sep  6 16:40:52.772: INFO: Pod "pod-configmaps-15fde120-d0c5-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:40:52.774: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod pod-configmaps-15fde120-d0c5-11e9-a08c-82ce3d77f2cb container configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 16:40:52.791: INFO: Waiting for pod pod-configmaps-15fde120-d0c5-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:40:52.794: INFO: Pod pod-configmaps-15fde120-d0c5-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:40:52.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2998" for this suite.
Sep  6 16:40:58.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:40:58.877: INFO: namespace configmap-2998 deletion completed in 6.079077255s

• [SLOW TEST:8.138 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:40:58.877: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 16:40:58.902: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1ad77a53-d0c5-11e9-a08c-82ce3d77f2cb" in namespace "downward-api-1075" to be "success or failure"
Sep  6 16:40:58.906: INFO: Pod "downwardapi-volume-1ad77a53-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.594865ms
Sep  6 16:41:00.909: INFO: Pod "downwardapi-volume-1ad77a53-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007579419s
STEP: Saw pod success
Sep  6 16:41:00.909: INFO: Pod "downwardapi-volume-1ad77a53-d0c5-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:41:00.911: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod downwardapi-volume-1ad77a53-d0c5-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 16:41:00.925: INFO: Waiting for pod downwardapi-volume-1ad77a53-d0c5-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:41:00.927: INFO: Pod downwardapi-volume-1ad77a53-d0c5-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:41:00.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1075" for this suite.
Sep  6 16:41:06.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:41:06.995: INFO: namespace downward-api-1075 deletion completed in 6.065130303s

• [SLOW TEST:8.118 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:41:06.995: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-8550
Sep  6 16:41:11.028: INFO: Started pod liveness-http in namespace container-probe-8550
STEP: checking the pod's current state and verifying that restartCount is present
Sep  6 16:41:11.029: INFO: Initial restart count of pod liveness-http is 0
Sep  6 16:41:29.061: INFO: Restart count of pod container-probe-8550/liveness-http is now 1 (18.031972718s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:41:29.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8550" for this suite.
Sep  6 16:41:35.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:41:35.139: INFO: namespace container-probe-8550 deletion completed in 6.067475241s

• [SLOW TEST:28.144 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:41:35.139: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1174
STEP: creating the pod
Sep  6 16:41:35.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 create -f - --namespace=kubectl-1741'
Sep  6 16:41:35.473: INFO: stderr: ""
Sep  6 16:41:35.473: INFO: stdout: "pod/pause created\n"
Sep  6 16:41:35.473: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep  6 16:41:35.473: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1741" to be "running and ready"
Sep  6 16:41:35.476: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.020153ms
Sep  6 16:41:37.479: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.005929841s
Sep  6 16:41:37.479: INFO: Pod "pause" satisfied condition "running and ready"
Sep  6 16:41:37.479: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Sep  6 16:41:37.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 label pods pause testing-label=testing-label-value --namespace=kubectl-1741'
Sep  6 16:41:37.554: INFO: stderr: ""
Sep  6 16:41:37.554: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep  6 16:41:37.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pod pause -L testing-label --namespace=kubectl-1741'
Sep  6 16:41:37.622: INFO: stderr: ""
Sep  6 16:41:37.622: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep  6 16:41:37.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 label pods pause testing-label- --namespace=kubectl-1741'
Sep  6 16:41:37.692: INFO: stderr: ""
Sep  6 16:41:37.692: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep  6 16:41:37.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pod pause -L testing-label --namespace=kubectl-1741'
Sep  6 16:41:37.758: INFO: stderr: ""
Sep  6 16:41:37.758: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1181
STEP: using delete to clean up resources
Sep  6 16:41:37.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 delete --grace-period=0 --force -f - --namespace=kubectl-1741'
Sep  6 16:41:37.880: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 16:41:37.880: INFO: stdout: "pod \"pause\" force deleted\n"
Sep  6 16:41:37.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get rc,svc -l name=pause --no-headers --namespace=kubectl-1741'
Sep  6 16:41:37.958: INFO: stderr: "No resources found.\n"
Sep  6 16:41:37.958: INFO: stdout: ""
Sep  6 16:41:37.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-959664940 get pods -l name=pause --namespace=kubectl-1741 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  6 16:41:38.025: INFO: stderr: ""
Sep  6 16:41:38.025: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:41:38.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1741" for this suite.
Sep  6 16:41:44.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:41:44.112: INFO: namespace kubectl-1741 deletion completed in 6.084238596s

• [SLOW TEST:8.973 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:41:44.112: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 16:41:44.138: INFO: Waiting up to 5m0s for pod "downwardapi-volume-35ce0ff7-d0c5-11e9-a08c-82ce3d77f2cb" in namespace "downward-api-4741" to be "success or failure"
Sep  6 16:41:44.142: INFO: Pod "downwardapi-volume-35ce0ff7-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.724017ms
Sep  6 16:41:46.144: INFO: Pod "downwardapi-volume-35ce0ff7-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006500274s
STEP: Saw pod success
Sep  6 16:41:46.144: INFO: Pod "downwardapi-volume-35ce0ff7-d0c5-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:41:46.146: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod downwardapi-volume-35ce0ff7-d0c5-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 16:41:46.159: INFO: Waiting for pod downwardapi-volume-35ce0ff7-d0c5-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:41:46.160: INFO: Pod downwardapi-volume-35ce0ff7-d0c5-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:41:46.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4741" for this suite.
Sep  6 16:41:52.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:41:52.276: INFO: namespace downward-api-4741 deletion completed in 6.113727052s

• [SLOW TEST:8.164 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:41:52.276: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep  6 16:41:52.319: INFO: Waiting up to 5m0s for pod "pod-3aae17d3-d0c5-11e9-a08c-82ce3d77f2cb" in namespace "emptydir-8127" to be "success or failure"
Sep  6 16:41:52.324: INFO: Pod "pod-3aae17d3-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.224426ms
Sep  6 16:41:54.327: INFO: Pod "pod-3aae17d3-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008312776s
STEP: Saw pod success
Sep  6 16:41:54.327: INFO: Pod "pod-3aae17d3-d0c5-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:41:54.329: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-3aae17d3-d0c5-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 16:41:54.341: INFO: Waiting for pod pod-3aae17d3-d0c5-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:41:54.343: INFO: Pod pod-3aae17d3-d0c5-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:41:54.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8127" for this suite.
Sep  6 16:42:00.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:42:00.413: INFO: namespace emptydir-8127 deletion completed in 6.068001535s

• [SLOW TEST:8.137 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:42:00.413: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:42:02.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4075" for this suite.
Sep  6 16:42:40.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:42:40.519: INFO: namespace kubelet-test-4075 deletion completed in 38.064185567s

• [SLOW TEST:40.106 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:42:40.519: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Sep  6 16:42:41.051: INFO: created pod pod-service-account-defaultsa
Sep  6 16:42:41.051: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep  6 16:42:41.055: INFO: created pod pod-service-account-mountsa
Sep  6 16:42:41.055: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep  6 16:42:41.062: INFO: created pod pod-service-account-nomountsa
Sep  6 16:42:41.062: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep  6 16:42:41.069: INFO: created pod pod-service-account-defaultsa-mountspec
Sep  6 16:42:41.069: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep  6 16:42:41.074: INFO: created pod pod-service-account-mountsa-mountspec
Sep  6 16:42:41.074: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep  6 16:42:41.082: INFO: created pod pod-service-account-nomountsa-mountspec
Sep  6 16:42:41.082: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep  6 16:42:41.091: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep  6 16:42:41.091: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep  6 16:42:41.099: INFO: created pod pod-service-account-mountsa-nomountspec
Sep  6 16:42:41.099: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep  6 16:42:41.109: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep  6 16:42:41.109: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:42:41.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7041" for this suite.
Sep  6 16:42:47.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:42:47.192: INFO: namespace svcaccounts-7041 deletion completed in 6.078925522s

• [SLOW TEST:6.673 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:42:47.192: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  6 16:42:47.268: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b6ecbdd-d0c5-11e9-a08c-82ce3d77f2cb" in namespace "downward-api-8224" to be "success or failure"
Sep  6 16:42:47.273: INFO: Pod "downwardapi-volume-5b6ecbdd-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.304307ms
Sep  6 16:42:49.276: INFO: Pod "downwardapi-volume-5b6ecbdd-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00746243s
STEP: Saw pod success
Sep  6 16:42:49.276: INFO: Pod "downwardapi-volume-5b6ecbdd-d0c5-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:42:49.278: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod downwardapi-volume-5b6ecbdd-d0c5-11e9-a08c-82ce3d77f2cb container client-container: <nil>
STEP: delete the pod
Sep  6 16:42:49.292: INFO: Waiting for pod downwardapi-volume-5b6ecbdd-d0c5-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:42:49.294: INFO: Pod downwardapi-volume-5b6ecbdd-d0c5-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:42:49.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8224" for this suite.
Sep  6 16:42:55.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:42:55.362: INFO: namespace downward-api-8224 deletion completed in 6.065284349s

• [SLOW TEST:8.170 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:42:55.362: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-8604
Sep  6 16:42:57.393: INFO: Started pod liveness-exec in namespace container-probe-8604
STEP: checking the pod's current state and verifying that restartCount is present
Sep  6 16:42:57.395: INFO: Initial restart count of pod liveness-exec is 0
Sep  6 16:43:49.475: INFO: Restart count of pod container-probe-8604/liveness-exec is now 1 (52.079729333s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:43:49.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8604" for this suite.
Sep  6 16:43:55.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:43:55.555: INFO: namespace container-probe-8604 deletion completed in 6.067059152s

• [SLOW TEST:60.193 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:43:55.555: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep  6 16:43:59.605: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 16:43:59.608: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 16:44:01.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 16:44:01.611: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 16:44:03.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 16:44:03.611: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 16:44:05.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 16:44:05.611: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 16:44:07.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 16:44:07.611: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 16:44:09.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 16:44:09.611: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 16:44:11.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 16:44:11.611: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 16:44:13.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 16:44:13.611: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 16:44:15.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 16:44:15.611: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 16:44:17.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 16:44:17.611: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 16:44:19.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 16:44:19.611: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 16:44:21.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 16:44:21.611: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 16:44:23.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 16:44:23.611: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 16:44:25.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 16:44:25.611: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:44:25.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8572" for this suite.
Sep  6 16:44:47.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:44:47.677: INFO: namespace container-lifecycle-hook-8572 deletion completed in 22.063590493s

• [SLOW TEST:52.122 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:44:47.677: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep  6 16:44:47.704: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2265,SelfLink:/api/v1/namespaces/watch-2265/configmaps/e2e-watch-test-watch-closed,UID:a3356158-d0c5-11e9-8afa-02e25174ea0a,ResourceVersion:14512,Generation:0,CreationTimestamp:2019-09-06 16:44:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  6 16:44:47.704: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2265,SelfLink:/api/v1/namespaces/watch-2265/configmaps/e2e-watch-test-watch-closed,UID:a3356158-d0c5-11e9-8afa-02e25174ea0a,ResourceVersion:14513,Generation:0,CreationTimestamp:2019-09-06 16:44:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep  6 16:44:47.711: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2265,SelfLink:/api/v1/namespaces/watch-2265/configmaps/e2e-watch-test-watch-closed,UID:a3356158-d0c5-11e9-8afa-02e25174ea0a,ResourceVersion:14514,Generation:0,CreationTimestamp:2019-09-06 16:44:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  6 16:44:47.712: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2265,SelfLink:/api/v1/namespaces/watch-2265/configmaps/e2e-watch-test-watch-closed,UID:a3356158-d0c5-11e9-8afa-02e25174ea0a,ResourceVersion:14515,Generation:0,CreationTimestamp:2019-09-06 16:44:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:44:47.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2265" for this suite.
Sep  6 16:44:53.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:44:53.776: INFO: namespace watch-2265 deletion completed in 6.062522951s

• [SLOW TEST:6.099 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:44:53.776: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Sep  6 16:44:53.804: INFO: Waiting up to 5m0s for pod "client-containers-a6dad608-d0c5-11e9-a08c-82ce3d77f2cb" in namespace "containers-2654" to be "success or failure"
Sep  6 16:44:53.807: INFO: Pod "client-containers-a6dad608-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.6993ms
Sep  6 16:44:55.811: INFO: Pod "client-containers-a6dad608-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007265813s
STEP: Saw pod success
Sep  6 16:44:55.811: INFO: Pod "client-containers-a6dad608-d0c5-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:44:55.814: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod client-containers-a6dad608-d0c5-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 16:44:55.830: INFO: Waiting for pod client-containers-a6dad608-d0c5-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:44:55.832: INFO: Pod client-containers-a6dad608-d0c5-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:44:55.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2654" for this suite.
Sep  6 16:45:01.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:45:01.913: INFO: namespace containers-2654 deletion completed in 6.076445479s

• [SLOW TEST:8.137 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:45:01.914: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  6 16:45:01.944: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep  6 16:45:01.950: INFO: Number of nodes with available pods: 0
Sep  6 16:45:01.950: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep  6 16:45:01.963: INFO: Number of nodes with available pods: 0
Sep  6 16:45:01.963: INFO: Node ip-172-20-60-162.us-east-2.compute.internal is running more than one daemon pod
Sep  6 16:45:02.966: INFO: Number of nodes with available pods: 1
Sep  6 16:45:02.966: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep  6 16:45:02.978: INFO: Number of nodes with available pods: 1
Sep  6 16:45:02.978: INFO: Number of running nodes: 0, number of available pods: 1
Sep  6 16:45:03.981: INFO: Number of nodes with available pods: 0
Sep  6 16:45:03.981: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep  6 16:45:03.987: INFO: Number of nodes with available pods: 0
Sep  6 16:45:03.987: INFO: Node ip-172-20-60-162.us-east-2.compute.internal is running more than one daemon pod
Sep  6 16:45:04.991: INFO: Number of nodes with available pods: 0
Sep  6 16:45:04.991: INFO: Node ip-172-20-60-162.us-east-2.compute.internal is running more than one daemon pod
Sep  6 16:45:05.990: INFO: Number of nodes with available pods: 0
Sep  6 16:45:05.990: INFO: Node ip-172-20-60-162.us-east-2.compute.internal is running more than one daemon pod
Sep  6 16:45:06.990: INFO: Number of nodes with available pods: 0
Sep  6 16:45:06.990: INFO: Node ip-172-20-60-162.us-east-2.compute.internal is running more than one daemon pod
Sep  6 16:45:07.990: INFO: Number of nodes with available pods: 1
Sep  6 16:45:07.990: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6529, will wait for the garbage collector to delete the pods
Sep  6 16:45:08.054: INFO: Deleting DaemonSet.extensions daemon-set took: 4.693753ms
Sep  6 16:45:08.354: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.30329ms
Sep  6 16:45:14.657: INFO: Number of nodes with available pods: 0
Sep  6 16:45:14.657: INFO: Number of running nodes: 0, number of available pods: 0
Sep  6 16:45:14.658: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6529/daemonsets","resourceVersion":"14614"},"items":null}

Sep  6 16:45:14.660: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6529/pods","resourceVersion":"14614"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:45:14.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6529" for this suite.
Sep  6 16:45:20.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:45:20.753: INFO: namespace daemonsets-6529 deletion completed in 6.077515464s

• [SLOW TEST:18.839 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:45:20.753: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep  6 16:45:20.828: INFO: Waiting up to 5m0s for pod "pod-b6f66b76-d0c5-11e9-a08c-82ce3d77f2cb" in namespace "emptydir-6985" to be "success or failure"
Sep  6 16:45:20.831: INFO: Pod "pod-b6f66b76-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.606184ms
Sep  6 16:45:22.834: INFO: Pod "pod-b6f66b76-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005441314s
STEP: Saw pod success
Sep  6 16:45:22.834: INFO: Pod "pod-b6f66b76-d0c5-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:45:22.835: INFO: Trying to get logs from node ip-172-20-60-162.us-east-2.compute.internal pod pod-b6f66b76-d0c5-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 16:45:22.847: INFO: Waiting for pod pod-b6f66b76-d0c5-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:45:22.849: INFO: Pod pod-b6f66b76-d0c5-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:45:22.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6985" for this suite.
Sep  6 16:45:28.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:45:28.917: INFO: namespace emptydir-6985 deletion completed in 6.065469231s

• [SLOW TEST:8.164 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:45:28.917: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Sep  6 16:45:28.941: INFO: Waiting up to 5m0s for pod "client-containers-bbcc36fe-d0c5-11e9-a08c-82ce3d77f2cb" in namespace "containers-689" to be "success or failure"
Sep  6 16:45:28.943: INFO: Pod "client-containers-bbcc36fe-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.1047ms
Sep  6 16:45:30.951: INFO: Pod "client-containers-bbcc36fe-d0c5-11e9-a08c-82ce3d77f2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010092309s
STEP: Saw pod success
Sep  6 16:45:30.951: INFO: Pod "client-containers-bbcc36fe-d0c5-11e9-a08c-82ce3d77f2cb" satisfied condition "success or failure"
Sep  6 16:45:30.953: INFO: Trying to get logs from node ip-172-20-61-48.us-east-2.compute.internal pod client-containers-bbcc36fe-d0c5-11e9-a08c-82ce3d77f2cb container test-container: <nil>
STEP: delete the pod
Sep  6 16:45:30.966: INFO: Waiting for pod client-containers-bbcc36fe-d0c5-11e9-a08c-82ce3d77f2cb to disappear
Sep  6 16:45:30.968: INFO: Pod client-containers-bbcc36fe-d0c5-11e9-a08c-82ce3d77f2cb no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:45:30.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-689" for this suite.
Sep  6 16:45:36.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:45:37.046: INFO: namespace containers-689 deletion completed in 6.076068065s

• [SLOW TEST:8.129 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  6 16:45:37.048: INFO: >>> kubeConfig: /tmp/kubeconfig-959664940
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Sep  6 16:45:39.585: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9480 pod-service-account-c0f26758-d0c5-11e9-a08c-82ce3d77f2cb -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Sep  6 16:45:39.742: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9480 pod-service-account-c0f26758-d0c5-11e9-a08c-82ce3d77f2cb -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Sep  6 16:45:39.892: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9480 pod-service-account-c0f26758-d0c5-11e9-a08c-82ce3d77f2cb -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  6 16:45:40.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9480" for this suite.
Sep  6 16:45:46.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 16:45:46.137: INFO: namespace svcaccounts-9480 deletion completed in 6.074818867s

• [SLOW TEST:9.089 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSep  6 16:45:46.137: INFO: Running AfterSuite actions on all nodes
Sep  6 16:45:46.137: INFO: Running AfterSuite actions on node 1
Sep  6 16:45:46.137: INFO: Skipping dumping logs from cluster

Ran 204 of 3586 Specs in 4861.114 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3382 Skipped PASS

Ginkgo ran 1 suite in 1h21m2.283326721s
Test Suite Passed
