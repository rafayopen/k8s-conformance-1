I1030 11:23:37.475004      18 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-984085711
I1030 11:23:37.475234      18 e2e.go:242] Starting e2e run "b6cf28fe-fb07-11e9-91af-623cf93d857c" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1572434616 - Will randomize all specs
Will run 204 of 3586 specs

Oct 30 11:23:37.692: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 11:23:37.696: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Oct 30 11:23:37.730: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct 30 11:23:37.833: INFO: 30 / 30 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct 30 11:23:37.833: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Oct 30 11:23:37.833: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct 30 11:23:37.858: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Oct 30 11:23:37.858: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Oct 30 11:23:37.858: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'openstack-cloud-controller-manager' (0 seconds elapsed)
Oct 30 11:23:37.858: INFO: e2e test version: v1.14.8
Oct 30 11:23:37.861: INFO: kube-apiserver version: v1.14.8
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:23:37.862: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename pod-network-test
Oct 30 11:23:37.962: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-6447
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 30 11:23:37.969: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 30 11:24:04.271: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.5.5 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6447 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:24:04.271: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 11:24:05.466: INFO: Found all expected endpoints: [netserver-0]
Oct 30 11:24:05.479: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.4.4 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6447 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:24:05.479: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 11:24:06.655: INFO: Found all expected endpoints: [netserver-1]
Oct 30 11:24:06.665: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.3.7 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6447 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:24:06.665: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 11:24:07.829: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:24:07.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6447" for this suite.
Oct 30 11:24:31.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:24:32.179: INFO: namespace pod-network-test-6447 deletion completed in 24.336124026s

â€¢ [SLOW TEST:54.317 seconds]
[sig-network] Networking
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:24:32.180: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct 30 11:24:32.283: INFO: PodSpec: initContainers in spec.initContainers
Oct 30 11:25:23.676: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-d83e8711-fb07-11e9-91af-623cf93d857c", GenerateName:"", Namespace:"init-container-6003", SelfLink:"/api/v1/namespaces/init-container-6003/pods/pod-init-d83e8711-fb07-11e9-91af-623cf93d857c", UID:"d8401e39-fb07-11e9-a053-fa163e61542c", ResourceVersion:"5309", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63708031472, loc:(*time.Location)(0x882f100)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"283030645"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.233.4.6/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-5q8r7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00160cb80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5q8r7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5q8r7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5q8r7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002ab2878), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"koris-pipeline-56683fb-92514359-node-1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002c72720), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002ab2a00)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002ab2a30)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002ab2a38), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002ab2a3c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031472, loc:(*time.Location)(0x882f100)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031472, loc:(*time.Location)(0x882f100)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031472, loc:(*time.Location)(0x882f100)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708031472, loc:(*time.Location)(0x882f100)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.0.39", PodIP:"10.233.4.6", StartTime:(*v1.Time)(0xc0028b1ae0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002444070)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0024440e0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://9744af2ee0d51317db5c56363cc410dfb8bc02398c85e37c9c255537e6c43d8d"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0028b1b20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0028b1b00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:25:23.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6003" for this suite.
Oct 30 11:25:51.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:25:52.013: INFO: namespace init-container-6003 deletion completed in 28.320402589s

â€¢ [SLOW TEST:79.833 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:25:52.016: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Oct 30 11:25:52.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 create -f - --namespace=kubectl-4493'
Oct 30 11:25:52.959: INFO: stderr: ""
Oct 30 11:25:52.959: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 30 11:25:52.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4493'
Oct 30 11:25:53.090: INFO: stderr: ""
Oct 30 11:25:53.090: INFO: stdout: "update-demo-nautilus-bz86c update-demo-nautilus-dgbct "
Oct 30 11:25:53.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-bz86c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4493'
Oct 30 11:25:53.224: INFO: stderr: ""
Oct 30 11:25:53.224: INFO: stdout: ""
Oct 30 11:25:53.224: INFO: update-demo-nautilus-bz86c is created but not running
Oct 30 11:25:58.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4493'
Oct 30 11:25:58.346: INFO: stderr: ""
Oct 30 11:25:58.346: INFO: stdout: "update-demo-nautilus-bz86c update-demo-nautilus-dgbct "
Oct 30 11:25:58.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-bz86c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4493'
Oct 30 11:25:58.477: INFO: stderr: ""
Oct 30 11:25:58.477: INFO: stdout: "true"
Oct 30 11:25:58.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-bz86c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4493'
Oct 30 11:25:58.604: INFO: stderr: ""
Oct 30 11:25:58.604: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:25:58.604: INFO: validating pod update-demo-nautilus-bz86c
Oct 30 11:25:58.620: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:25:58.620: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:25:58.620: INFO: update-demo-nautilus-bz86c is verified up and running
Oct 30 11:25:58.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-dgbct -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4493'
Oct 30 11:25:58.747: INFO: stderr: ""
Oct 30 11:25:58.747: INFO: stdout: "true"
Oct 30 11:25:58.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-dgbct -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4493'
Oct 30 11:25:58.869: INFO: stderr: ""
Oct 30 11:25:58.869: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:25:58.869: INFO: validating pod update-demo-nautilus-dgbct
Oct 30 11:25:58.879: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:25:58.879: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:25:58.879: INFO: update-demo-nautilus-dgbct is verified up and running
STEP: rolling-update to new replication controller
Oct 30 11:25:58.885: INFO: scanned /root for discovery docs: <nil>
Oct 30 11:25:58.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-4493'
Oct 30 11:26:22.668: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 30 11:26:22.668: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 30 11:26:22.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4493'
Oct 30 11:26:22.799: INFO: stderr: ""
Oct 30 11:26:22.799: INFO: stdout: "update-demo-kitten-dwnkm update-demo-kitten-ghcvk "
Oct 30 11:26:22.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-kitten-dwnkm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4493'
Oct 30 11:26:22.918: INFO: stderr: ""
Oct 30 11:26:22.918: INFO: stdout: "true"
Oct 30 11:26:22.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-kitten-dwnkm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4493'
Oct 30 11:26:23.048: INFO: stderr: ""
Oct 30 11:26:23.048: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 30 11:26:23.048: INFO: validating pod update-demo-kitten-dwnkm
Oct 30 11:26:23.063: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 30 11:26:23.063: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 30 11:26:23.063: INFO: update-demo-kitten-dwnkm is verified up and running
Oct 30 11:26:23.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-kitten-ghcvk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4493'
Oct 30 11:26:23.177: INFO: stderr: ""
Oct 30 11:26:23.177: INFO: stdout: "true"
Oct 30 11:26:23.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-kitten-ghcvk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4493'
Oct 30 11:26:23.306: INFO: stderr: ""
Oct 30 11:26:23.306: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 30 11:26:23.306: INFO: validating pod update-demo-kitten-ghcvk
Oct 30 11:26:23.316: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 30 11:26:23.316: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 30 11:26:23.316: INFO: update-demo-kitten-ghcvk is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:26:23.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4493" for this suite.
Oct 30 11:26:47.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:26:47.682: INFO: namespace kubectl-4493 deletion completed in 24.354687197s

â€¢ [SLOW TEST:55.667 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:26:47.684: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 30 11:26:47.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-8993'
Oct 30 11:26:47.969: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 30 11:26:47.969: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Oct 30 11:26:47.995: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Oct 30 11:26:48.013: INFO: scanned /root for discovery docs: <nil>
Oct 30 11:26:48.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-8993'
Oct 30 11:27:07.114: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 30 11:27:07.114: INFO: stdout: "Created e2e-test-nginx-rc-d88365320fb7231334e811e8a2c1e98b\nScaling up e2e-test-nginx-rc-d88365320fb7231334e811e8a2c1e98b from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d88365320fb7231334e811e8a2c1e98b up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d88365320fb7231334e811e8a2c1e98b to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Oct 30 11:27:07.114: INFO: stdout: "Created e2e-test-nginx-rc-d88365320fb7231334e811e8a2c1e98b\nScaling up e2e-test-nginx-rc-d88365320fb7231334e811e8a2c1e98b from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d88365320fb7231334e811e8a2c1e98b up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d88365320fb7231334e811e8a2c1e98b to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Oct 30 11:27:07.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-8993'
Oct 30 11:27:07.229: INFO: stderr: ""
Oct 30 11:27:07.229: INFO: stdout: "e2e-test-nginx-rc-d88365320fb7231334e811e8a2c1e98b-hb6mz "
Oct 30 11:27:07.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods e2e-test-nginx-rc-d88365320fb7231334e811e8a2c1e98b-hb6mz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8993'
Oct 30 11:27:07.349: INFO: stderr: ""
Oct 30 11:27:07.349: INFO: stdout: "true"
Oct 30 11:27:07.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods e2e-test-nginx-rc-d88365320fb7231334e811e8a2c1e98b-hb6mz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8993'
Oct 30 11:27:07.475: INFO: stderr: ""
Oct 30 11:27:07.475: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Oct 30 11:27:07.475: INFO: e2e-test-nginx-rc-d88365320fb7231334e811e8a2c1e98b-hb6mz is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1486
Oct 30 11:27:07.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 delete rc e2e-test-nginx-rc --namespace=kubectl-8993'
Oct 30 11:27:07.615: INFO: stderr: ""
Oct 30 11:27:07.615: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:27:07.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8993" for this suite.
Oct 30 11:27:31.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:27:31.948: INFO: namespace kubectl-8993 deletion completed in 24.314492936s

â€¢ [SLOW TEST:44.264 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:27:31.950: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Oct 30 11:27:32.077: INFO: Pod name pod-release: Found 0 pods out of 1
Oct 30 11:27:37.090: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:27:37.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6569" for this suite.
Oct 30 11:27:43.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:27:43.496: INFO: namespace replication-controller-6569 deletion completed in 6.345658316s

â€¢ [SLOW TEST:11.546 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:27:43.496: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:27:43.613: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4a4459c6-fb08-11e9-91af-623cf93d857c" in namespace "downward-api-6631" to be "success or failure"
Oct 30 11:27:43.634: INFO: Pod "downwardapi-volume-4a4459c6-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 20.33196ms
Oct 30 11:27:45.644: INFO: Pod "downwardapi-volume-4a4459c6-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030771313s
Oct 30 11:27:47.652: INFO: Pod "downwardapi-volume-4a4459c6-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038891314s
Oct 30 11:27:49.662: INFO: Pod "downwardapi-volume-4a4459c6-fb08-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04924149s
STEP: Saw pod success
Oct 30 11:27:49.663: INFO: Pod "downwardapi-volume-4a4459c6-fb08-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:27:49.670: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod downwardapi-volume-4a4459c6-fb08-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 11:27:49.755: INFO: Waiting for pod downwardapi-volume-4a4459c6-fb08-11e9-91af-623cf93d857c to disappear
Oct 30 11:27:49.763: INFO: Pod downwardapi-volume-4a4459c6-fb08-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:27:49.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6631" for this suite.
Oct 30 11:27:55.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:27:56.081: INFO: namespace downward-api-6631 deletion completed in 6.309807608s

â€¢ [SLOW TEST:12.585 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:27:56.083: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-8846
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 30 11:27:56.169: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 30 11:28:18.523: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.5.8:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8846 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:28:18.523: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 11:28:18.729: INFO: Found all expected endpoints: [netserver-0]
Oct 30 11:28:18.745: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.3.10:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8846 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:28:18.745: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 11:28:18.948: INFO: Found all expected endpoints: [netserver-1]
Oct 30 11:28:18.975: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.4.12:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8846 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 11:28:18.975: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 11:28:19.213: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:28:19.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8846" for this suite.
Oct 30 11:28:43.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:28:43.526: INFO: namespace pod-network-test-8846 deletion completed in 24.297178475s

â€¢ [SLOW TEST:47.444 seconds]
[sig-network] Networking
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:28:43.528: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-6e0df479-fb08-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume configMaps
Oct 30 11:28:43.668: INFO: Waiting up to 5m0s for pod "pod-configmaps-6e10bc4b-fb08-11e9-91af-623cf93d857c" in namespace "configmap-7880" to be "success or failure"
Oct 30 11:28:43.684: INFO: Pod "pod-configmaps-6e10bc4b-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.374141ms
Oct 30 11:28:45.694: INFO: Pod "pod-configmaps-6e10bc4b-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025603303s
Oct 30 11:28:47.702: INFO: Pod "pod-configmaps-6e10bc4b-fb08-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033822493s
STEP: Saw pod success
Oct 30 11:28:47.702: INFO: Pod "pod-configmaps-6e10bc4b-fb08-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:28:47.709: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-configmaps-6e10bc4b-fb08-11e9-91af-623cf93d857c container configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 11:28:47.769: INFO: Waiting for pod pod-configmaps-6e10bc4b-fb08-11e9-91af-623cf93d857c to disappear
Oct 30 11:28:47.784: INFO: Pod pod-configmaps-6e10bc4b-fb08-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:28:47.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7880" for this suite.
Oct 30 11:28:53.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:28:54.123: INFO: namespace configmap-7880 deletion completed in 6.325863629s

â€¢ [SLOW TEST:10.595 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:28:54.123: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct 30 11:28:54.239: INFO: Waiting up to 5m0s for pod "downward-api-745d2bee-fb08-11e9-91af-623cf93d857c" in namespace "downward-api-1248" to be "success or failure"
Oct 30 11:28:54.249: INFO: Pod "downward-api-745d2bee-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.023034ms
Oct 30 11:28:56.260: INFO: Pod "downward-api-745d2bee-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02028232s
Oct 30 11:28:58.270: INFO: Pod "downward-api-745d2bee-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030399207s
Oct 30 11:29:00.279: INFO: Pod "downward-api-745d2bee-fb08-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039412164s
STEP: Saw pod success
Oct 30 11:29:00.279: INFO: Pod "downward-api-745d2bee-fb08-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:29:00.286: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod downward-api-745d2bee-fb08-11e9-91af-623cf93d857c container dapi-container: <nil>
STEP: delete the pod
Oct 30 11:29:00.351: INFO: Waiting for pod downward-api-745d2bee-fb08-11e9-91af-623cf93d857c to disappear
Oct 30 11:29:00.357: INFO: Pod downward-api-745d2bee-fb08-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:29:00.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1248" for this suite.
Oct 30 11:29:06.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:29:06.659: INFO: namespace downward-api-1248 deletion completed in 6.292449777s

â€¢ [SLOW TEST:12.537 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:29:06.662: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-7bd7fa81-fb08-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume configMaps
Oct 30 11:29:06.797: INFO: Waiting up to 5m0s for pod "pod-configmaps-7bdb0a93-fb08-11e9-91af-623cf93d857c" in namespace "configmap-9662" to be "success or failure"
Oct 30 11:29:06.811: INFO: Pod "pod-configmaps-7bdb0a93-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.108055ms
Oct 30 11:29:08.821: INFO: Pod "pod-configmaps-7bdb0a93-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023469035s
Oct 30 11:29:10.831: INFO: Pod "pod-configmaps-7bdb0a93-fb08-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033836676s
STEP: Saw pod success
Oct 30 11:29:10.831: INFO: Pod "pod-configmaps-7bdb0a93-fb08-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:29:10.837: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-configmaps-7bdb0a93-fb08-11e9-91af-623cf93d857c container configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 11:29:10.906: INFO: Waiting for pod pod-configmaps-7bdb0a93-fb08-11e9-91af-623cf93d857c to disappear
Oct 30 11:29:10.912: INFO: Pod pod-configmaps-7bdb0a93-fb08-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:29:10.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9662" for this suite.
Oct 30 11:29:16.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:29:17.226: INFO: namespace configmap-9662 deletion completed in 6.303805438s

â€¢ [SLOW TEST:10.565 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:29:17.232: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct 30 11:29:17.331: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 30 11:29:17.366: INFO: Waiting for terminating namespaces to be deleted...
Oct 30 11:29:17.374: INFO: 
Logging pods the kubelet thinks is on node koris-pipeline-56683fb-92514359-node-1 before test
Oct 30 11:29:17.388: INFO: kube-proxy-246h7 from kube-system started at 2019-10-30 11:07:20 +0000 UTC (1 container statuses recorded)
Oct 30 11:29:17.388: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 30 11:29:17.388: INFO: calico-node-mt5gd from kube-system started at 2019-10-30 11:07:21 +0000 UTC (2 container statuses recorded)
Oct 30 11:29:17.388: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 11:29:17.388: INFO: 	Container install-cni ready: true, restart count 0
Oct 30 11:29:17.388: INFO: nginx-blue-7f86974c47-f726v from default started at 2019-10-30 11:08:16 +0000 UTC (1 container statuses recorded)
Oct 30 11:29:17.388: INFO: 	Container nginx ready: true, restart count 0
Oct 30 11:29:17.388: INFO: sonobuoy-e2e-job-18cfb8e951354e9a from sonobuoy started at 2019-10-30 11:23:03 +0000 UTC (2 container statuses recorded)
Oct 30 11:29:17.388: INFO: 	Container e2e ready: true, restart count 0
Oct 30 11:29:17.388: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 11:29:17.388: INFO: sonobuoy-systemd-logs-daemon-set-aac87c55e38d426f-w56kw from sonobuoy started at 2019-10-30 11:23:03 +0000 UTC (2 container statuses recorded)
Oct 30 11:29:17.388: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 11:29:17.388: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 11:29:17.388: INFO: 
Logging pods the kubelet thinks is on node koris-pipeline-56683fb-92514359-node-2 before test
Oct 30 11:29:17.436: INFO: external-http-nginx-deployment-56db997f77-klncq from default started at 2019-10-30 11:06:35 +0000 UTC (1 container statuses recorded)
Oct 30 11:29:17.436: INFO: 	Container nginx ready: true, restart count 0
Oct 30 11:29:17.436: INFO: external-http-nginx-deployment-56db997f77-jsv9j from default started at 2019-10-30 11:06:35 +0000 UTC (1 container statuses recorded)
Oct 30 11:29:17.436: INFO: 	Container nginx ready: true, restart count 0
Oct 30 11:29:17.436: INFO: nginx-ingress-controller-6cfd5b6544-pzmdd from ingress-nginx started at 2019-10-30 11:06:36 +0000 UTC (1 container statuses recorded)
Oct 30 11:29:17.436: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 30 11:29:17.436: INFO: kube-proxy-sms4r from kube-system started at 2019-10-30 11:06:15 +0000 UTC (1 container statuses recorded)
Oct 30 11:29:17.436: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 30 11:29:17.436: INFO: calico-node-cwjt4 from kube-system started at 2019-10-30 11:06:15 +0000 UTC (2 container statuses recorded)
Oct 30 11:29:17.436: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 11:29:17.436: INFO: 	Container install-cni ready: true, restart count 0
Oct 30 11:29:17.436: INFO: dnscheck from default started at 2019-10-30 11:06:35 +0000 UTC (1 container statuses recorded)
Oct 30 11:29:17.436: INFO: 	Container dnscheck ready: true, restart count 0
Oct 30 11:29:17.436: INFO: metrics-server-5845cc8fd4-w8vxn from kube-system started at 2019-10-30 11:06:35 +0000 UTC (1 container statuses recorded)
Oct 30 11:29:17.436: INFO: 	Container metrics-server ready: true, restart count 0
Oct 30 11:29:17.436: INFO: sonobuoy-systemd-logs-daemon-set-aac87c55e38d426f-vrllw from sonobuoy started at 2019-10-30 11:23:04 +0000 UTC (2 container statuses recorded)
Oct 30 11:29:17.436: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 11:29:17.436: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 11:29:17.436: INFO: 
Logging pods the kubelet thinks is on node koris-pipeline-56683fb-92514359-node-3 before test
Oct 30 11:29:17.451: INFO: kube-bench-node from default started at 2019-10-30 11:21:56 +0000 UTC (1 container statuses recorded)
Oct 30 11:29:17.451: INFO: 	Container kube-bench-node ready: false, restart count 0
Oct 30 11:29:17.451: INFO: sonobuoy from sonobuoy started at 2019-10-30 11:22:56 +0000 UTC (1 container statuses recorded)
Oct 30 11:29:17.451: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 30 11:29:17.451: INFO: sonobuoy-systemd-logs-daemon-set-aac87c55e38d426f-4ckdm from sonobuoy started at 2019-10-30 11:23:04 +0000 UTC (2 container statuses recorded)
Oct 30 11:29:17.451: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 11:29:17.451: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 11:29:17.451: INFO: kube-proxy-ds6hw from kube-system started at 2019-10-30 11:07:23 +0000 UTC (1 container statuses recorded)
Oct 30 11:29:17.451: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 30 11:29:17.451: INFO: calico-node-h9krs from kube-system started at 2019-10-30 11:07:23 +0000 UTC (2 container statuses recorded)
Oct 30 11:29:17.451: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 11:29:17.451: INFO: 	Container install-cni ready: true, restart count 0
Oct 30 11:29:17.451: INFO: nginx-green-56c79bbc4d-z8m7q from default started at 2019-10-30 11:08:16 +0000 UTC (1 container statuses recorded)
Oct 30 11:29:17.451: INFO: 	Container nginx ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d2694343bcd801], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:29:18.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9855" for this suite.
Oct 30 11:29:24.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:29:24.864: INFO: namespace sched-pred-9855 deletion completed in 6.305593449s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:7.633 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:29:24.872: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-86b235b1-fb08-11e9-91af-623cf93d857c
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-86b235b1-fb08-11e9-91af-623cf93d857c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:29:31.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3150" for this suite.
Oct 30 11:29:55.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:29:55.425: INFO: namespace configmap-3150 deletion completed in 24.287413725s

â€¢ [SLOW TEST:30.554 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:29:55.427: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 30 11:30:03.632: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 11:30:03.639: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 11:30:05.640: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 11:30:05.649: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 11:30:07.640: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 11:30:07.650: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 11:30:09.640: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 11:30:09.649: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 11:30:11.640: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 11:30:11.650: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 11:30:13.640: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 11:30:13.649: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 11:30:15.640: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 11:30:15.649: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 11:30:17.640: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 11:30:17.648: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 11:30:19.640: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 11:30:19.652: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 11:30:21.640: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 11:30:21.648: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 11:30:23.640: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 11:30:23.649: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 11:30:25.640: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 11:30:25.649: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 11:30:27.640: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 11:30:27.647: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 11:30:29.640: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 11:30:29.648: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 30 11:30:31.640: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 30 11:30:31.648: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:30:31.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2180" for this suite.
Oct 30 11:30:53.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:30:53.995: INFO: namespace container-lifecycle-hook-2180 deletion completed in 22.312394314s

â€¢ [SLOW TEST:58.569 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:30:53.998: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-bbd2835c-fb08-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume configMaps
Oct 30 11:30:54.137: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bbd52866-fb08-11e9-91af-623cf93d857c" in namespace "projected-2113" to be "success or failure"
Oct 30 11:30:54.154: INFO: Pod "pod-projected-configmaps-bbd52866-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.253752ms
Oct 30 11:30:56.163: INFO: Pod "pod-projected-configmaps-bbd52866-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02597462s
Oct 30 11:30:58.173: INFO: Pod "pod-projected-configmaps-bbd52866-fb08-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036129195s
STEP: Saw pod success
Oct 30 11:30:58.173: INFO: Pod "pod-projected-configmaps-bbd52866-fb08-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:30:58.181: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-projected-configmaps-bbd52866-fb08-11e9-91af-623cf93d857c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 11:30:58.238: INFO: Waiting for pod pod-projected-configmaps-bbd52866-fb08-11e9-91af-623cf93d857c to disappear
Oct 30 11:30:58.245: INFO: Pod pod-projected-configmaps-bbd52866-fb08-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:30:58.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2113" for this suite.
Oct 30 11:31:04.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:31:04.598: INFO: namespace projected-2113 deletion completed in 6.343104966s

â€¢ [SLOW TEST:10.601 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:31:04.600: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Oct 30 11:31:05.285: INFO: created pod pod-service-account-defaultsa
Oct 30 11:31:05.285: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct 30 11:31:05.314: INFO: created pod pod-service-account-mountsa
Oct 30 11:31:05.314: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct 30 11:31:05.330: INFO: created pod pod-service-account-nomountsa
Oct 30 11:31:05.331: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct 30 11:31:05.355: INFO: created pod pod-service-account-defaultsa-mountspec
Oct 30 11:31:05.355: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct 30 11:31:05.383: INFO: created pod pod-service-account-mountsa-mountspec
Oct 30 11:31:05.383: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct 30 11:31:05.412: INFO: created pod pod-service-account-nomountsa-mountspec
Oct 30 11:31:05.412: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct 30 11:31:05.436: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct 30 11:31:05.436: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct 30 11:31:05.492: INFO: created pod pod-service-account-mountsa-nomountspec
Oct 30 11:31:05.492: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct 30 11:31:05.518: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct 30 11:31:05.518: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:31:05.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9957" for this suite.
Oct 30 11:31:11.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:31:11.885: INFO: namespace svcaccounts-9957 deletion completed in 6.333008224s

â€¢ [SLOW TEST:7.285 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:31:11.887: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-c67a2403-fb08-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume secrets
Oct 30 11:31:12.012: INFO: Waiting up to 5m0s for pod "pod-secrets-c67d4bb8-fb08-11e9-91af-623cf93d857c" in namespace "secrets-2887" to be "success or failure"
Oct 30 11:31:12.023: INFO: Pod "pod-secrets-c67d4bb8-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.55354ms
Oct 30 11:31:14.034: INFO: Pod "pod-secrets-c67d4bb8-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021633132s
Oct 30 11:31:16.044: INFO: Pod "pod-secrets-c67d4bb8-fb08-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031833089s
STEP: Saw pod success
Oct 30 11:31:16.044: INFO: Pod "pod-secrets-c67d4bb8-fb08-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:31:16.051: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-secrets-c67d4bb8-fb08-11e9-91af-623cf93d857c container secret-volume-test: <nil>
STEP: delete the pod
Oct 30 11:31:16.103: INFO: Waiting for pod pod-secrets-c67d4bb8-fb08-11e9-91af-623cf93d857c to disappear
Oct 30 11:31:16.109: INFO: Pod pod-secrets-c67d4bb8-fb08-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:31:16.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2887" for this suite.
Oct 30 11:31:22.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:31:22.447: INFO: namespace secrets-2887 deletion completed in 6.327041985s

â€¢ [SLOW TEST:10.561 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:31:22.450: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Oct 30 11:31:22.583: INFO: Waiting up to 5m0s for pod "client-containers-ccc88700-fb08-11e9-91af-623cf93d857c" in namespace "containers-6503" to be "success or failure"
Oct 30 11:31:22.590: INFO: Pod "client-containers-ccc88700-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.160098ms
Oct 30 11:31:24.601: INFO: Pod "client-containers-ccc88700-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017945034s
Oct 30 11:31:26.611: INFO: Pod "client-containers-ccc88700-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028493318s
Oct 30 11:31:28.621: INFO: Pod "client-containers-ccc88700-fb08-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037893332s
STEP: Saw pod success
Oct 30 11:31:28.621: INFO: Pod "client-containers-ccc88700-fb08-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:31:28.632: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod client-containers-ccc88700-fb08-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 11:31:28.693: INFO: Waiting for pod client-containers-ccc88700-fb08-11e9-91af-623cf93d857c to disappear
Oct 30 11:31:28.706: INFO: Pod client-containers-ccc88700-fb08-11e9-91af-623cf93d857c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:31:28.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6503" for this suite.
Oct 30 11:31:34.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:31:35.040: INFO: namespace containers-6503 deletion completed in 6.324266675s

â€¢ [SLOW TEST:12.591 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:31:35.041: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 30 11:31:35.155: INFO: Waiting up to 5m0s for pod "pod-d446654c-fb08-11e9-91af-623cf93d857c" in namespace "emptydir-656" to be "success or failure"
Oct 30 11:31:35.180: INFO: Pod "pod-d446654c-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 24.391604ms
Oct 30 11:31:37.190: INFO: Pod "pod-d446654c-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034982342s
Oct 30 11:31:39.199: INFO: Pod "pod-d446654c-fb08-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04397029s
Oct 30 11:31:41.210: INFO: Pod "pod-d446654c-fb08-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.054010657s
STEP: Saw pod success
Oct 30 11:31:41.210: INFO: Pod "pod-d446654c-fb08-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:31:41.220: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-d446654c-fb08-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 11:31:41.280: INFO: Waiting for pod pod-d446654c-fb08-11e9-91af-623cf93d857c to disappear
Oct 30 11:31:41.288: INFO: Pod pod-d446654c-fb08-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:31:41.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-656" for this suite.
Oct 30 11:31:47.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:31:47.603: INFO: namespace emptydir-656 deletion completed in 6.298161063s

â€¢ [SLOW TEST:12.562 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:31:47.604: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Oct 30 11:31:47.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 create -f - --namespace=kubectl-7766'
Oct 30 11:31:48.117: INFO: stderr: ""
Oct 30 11:31:48.117: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 30 11:31:48.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7766'
Oct 30 11:31:48.246: INFO: stderr: ""
Oct 30 11:31:48.246: INFO: stdout: "update-demo-nautilus-kbp6m update-demo-nautilus-z9rvf "
Oct 30 11:31:48.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-kbp6m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7766'
Oct 30 11:31:48.365: INFO: stderr: ""
Oct 30 11:31:48.365: INFO: stdout: ""
Oct 30 11:31:48.365: INFO: update-demo-nautilus-kbp6m is created but not running
Oct 30 11:31:53.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7766'
Oct 30 11:31:53.486: INFO: stderr: ""
Oct 30 11:31:53.486: INFO: stdout: "update-demo-nautilus-kbp6m update-demo-nautilus-z9rvf "
Oct 30 11:31:53.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-kbp6m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7766'
Oct 30 11:31:53.611: INFO: stderr: ""
Oct 30 11:31:53.611: INFO: stdout: "true"
Oct 30 11:31:53.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-kbp6m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7766'
Oct 30 11:31:53.735: INFO: stderr: ""
Oct 30 11:31:53.735: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:31:53.735: INFO: validating pod update-demo-nautilus-kbp6m
Oct 30 11:31:53.750: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:31:53.750: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:31:53.750: INFO: update-demo-nautilus-kbp6m is verified up and running
Oct 30 11:31:53.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-z9rvf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7766'
Oct 30 11:31:53.886: INFO: stderr: ""
Oct 30 11:31:53.886: INFO: stdout: "true"
Oct 30 11:31:53.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-z9rvf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7766'
Oct 30 11:31:54.019: INFO: stderr: ""
Oct 30 11:31:54.019: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:31:54.019: INFO: validating pod update-demo-nautilus-z9rvf
Oct 30 11:31:54.033: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:31:54.033: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:31:54.033: INFO: update-demo-nautilus-z9rvf is verified up and running
STEP: scaling down the replication controller
Oct 30 11:31:54.039: INFO: scanned /root for discovery docs: <nil>
Oct 30 11:31:54.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-7766'
Oct 30 11:31:55.267: INFO: stderr: ""
Oct 30 11:31:55.267: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 30 11:31:55.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7766'
Oct 30 11:31:55.396: INFO: stderr: ""
Oct 30 11:31:55.396: INFO: stdout: "update-demo-nautilus-kbp6m update-demo-nautilus-z9rvf "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 30 11:32:00.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7766'
Oct 30 11:32:00.525: INFO: stderr: ""
Oct 30 11:32:00.525: INFO: stdout: "update-demo-nautilus-kbp6m "
Oct 30 11:32:00.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-kbp6m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7766'
Oct 30 11:32:00.646: INFO: stderr: ""
Oct 30 11:32:00.646: INFO: stdout: "true"
Oct 30 11:32:00.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-kbp6m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7766'
Oct 30 11:32:00.765: INFO: stderr: ""
Oct 30 11:32:00.765: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:32:00.765: INFO: validating pod update-demo-nautilus-kbp6m
Oct 30 11:32:00.775: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:32:00.775: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:32:00.775: INFO: update-demo-nautilus-kbp6m is verified up and running
STEP: scaling up the replication controller
Oct 30 11:32:00.779: INFO: scanned /root for discovery docs: <nil>
Oct 30 11:32:00.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-7766'
Oct 30 11:32:01.996: INFO: stderr: ""
Oct 30 11:32:01.996: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 30 11:32:01.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7766'
Oct 30 11:32:02.126: INFO: stderr: ""
Oct 30 11:32:02.126: INFO: stdout: "update-demo-nautilus-bdgxv update-demo-nautilus-kbp6m "
Oct 30 11:32:02.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-bdgxv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7766'
Oct 30 11:32:02.251: INFO: stderr: ""
Oct 30 11:32:02.251: INFO: stdout: ""
Oct 30 11:32:02.251: INFO: update-demo-nautilus-bdgxv is created but not running
Oct 30 11:32:07.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7766'
Oct 30 11:32:07.364: INFO: stderr: ""
Oct 30 11:32:07.364: INFO: stdout: "update-demo-nautilus-bdgxv update-demo-nautilus-kbp6m "
Oct 30 11:32:07.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-bdgxv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7766'
Oct 30 11:32:07.489: INFO: stderr: ""
Oct 30 11:32:07.489: INFO: stdout: "true"
Oct 30 11:32:07.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-bdgxv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7766'
Oct 30 11:32:07.614: INFO: stderr: ""
Oct 30 11:32:07.614: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:32:07.614: INFO: validating pod update-demo-nautilus-bdgxv
Oct 30 11:32:07.628: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:32:07.628: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:32:07.628: INFO: update-demo-nautilus-bdgxv is verified up and running
Oct 30 11:32:07.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-kbp6m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7766'
Oct 30 11:32:07.753: INFO: stderr: ""
Oct 30 11:32:07.753: INFO: stdout: "true"
Oct 30 11:32:07.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-kbp6m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7766'
Oct 30 11:32:07.868: INFO: stderr: ""
Oct 30 11:32:07.868: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:32:07.868: INFO: validating pod update-demo-nautilus-kbp6m
Oct 30 11:32:07.876: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:32:07.876: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:32:07.876: INFO: update-demo-nautilus-kbp6m is verified up and running
STEP: using delete to clean up resources
Oct 30 11:32:07.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 delete --grace-period=0 --force -f - --namespace=kubectl-7766'
Oct 30 11:32:08.010: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 11:32:08.010: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 30 11:32:08.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7766'
Oct 30 11:32:08.149: INFO: stderr: "No resources found.\n"
Oct 30 11:32:08.149: INFO: stdout: ""
Oct 30 11:32:08.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -l name=update-demo --namespace=kubectl-7766 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 30 11:32:08.291: INFO: stderr: ""
Oct 30 11:32:08.291: INFO: stdout: "update-demo-nautilus-bdgxv\nupdate-demo-nautilus-kbp6m\n"
Oct 30 11:32:08.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7766'
Oct 30 11:32:08.916: INFO: stderr: "No resources found.\n"
Oct 30 11:32:08.916: INFO: stdout: ""
Oct 30 11:32:08.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -l name=update-demo --namespace=kubectl-7766 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 30 11:32:09.037: INFO: stderr: ""
Oct 30 11:32:09.037: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:32:09.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7766" for this suite.
Oct 30 11:32:15.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:32:15.461: INFO: namespace kubectl-7766 deletion completed in 6.41232932s

â€¢ [SLOW TEST:27.858 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:32:15.462: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1649
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 30 11:32:15.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1842'
Oct 30 11:32:15.691: INFO: stderr: ""
Oct 30 11:32:15.691: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1654
Oct 30 11:32:15.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 delete pods e2e-test-nginx-pod --namespace=kubectl-1842'
Oct 30 11:32:18.928: INFO: stderr: ""
Oct 30 11:32:18.928: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:32:18.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1842" for this suite.
Oct 30 11:32:24.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:32:25.228: INFO: namespace kubectl-1842 deletion completed in 6.287816814s

â€¢ [SLOW TEST:9.766 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:32:25.230: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-j6wd
STEP: Creating a pod to test atomic-volume-subpath
Oct 30 11:32:25.379: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-j6wd" in namespace "subpath-9941" to be "success or failure"
Oct 30 11:32:25.390: INFO: Pod "pod-subpath-test-configmap-j6wd": Phase="Pending", Reason="", readiness=false. Elapsed: 11.518899ms
Oct 30 11:32:27.402: INFO: Pod "pod-subpath-test-configmap-j6wd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023174169s
Oct 30 11:32:29.417: INFO: Pod "pod-subpath-test-configmap-j6wd": Phase="Running", Reason="", readiness=true. Elapsed: 4.038213291s
Oct 30 11:32:31.431: INFO: Pod "pod-subpath-test-configmap-j6wd": Phase="Running", Reason="", readiness=true. Elapsed: 6.051767591s
Oct 30 11:32:33.443: INFO: Pod "pod-subpath-test-configmap-j6wd": Phase="Running", Reason="", readiness=true. Elapsed: 8.06375201s
Oct 30 11:32:35.454: INFO: Pod "pod-subpath-test-configmap-j6wd": Phase="Running", Reason="", readiness=true. Elapsed: 10.07551815s
Oct 30 11:32:37.464: INFO: Pod "pod-subpath-test-configmap-j6wd": Phase="Running", Reason="", readiness=true. Elapsed: 12.085557824s
Oct 30 11:32:39.473: INFO: Pod "pod-subpath-test-configmap-j6wd": Phase="Running", Reason="", readiness=true. Elapsed: 14.093869621s
Oct 30 11:32:41.482: INFO: Pod "pod-subpath-test-configmap-j6wd": Phase="Running", Reason="", readiness=true. Elapsed: 16.103293846s
Oct 30 11:32:43.492: INFO: Pod "pod-subpath-test-configmap-j6wd": Phase="Running", Reason="", readiness=true. Elapsed: 18.113619698s
Oct 30 11:32:45.499: INFO: Pod "pod-subpath-test-configmap-j6wd": Phase="Running", Reason="", readiness=true. Elapsed: 20.12048132s
Oct 30 11:32:47.509: INFO: Pod "pod-subpath-test-configmap-j6wd": Phase="Running", Reason="", readiness=true. Elapsed: 22.130481714s
Oct 30 11:32:49.520: INFO: Pod "pod-subpath-test-configmap-j6wd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.141250904s
STEP: Saw pod success
Oct 30 11:32:49.520: INFO: Pod "pod-subpath-test-configmap-j6wd" satisfied condition "success or failure"
Oct 30 11:32:49.527: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-subpath-test-configmap-j6wd container test-container-subpath-configmap-j6wd: <nil>
STEP: delete the pod
Oct 30 11:32:49.585: INFO: Waiting for pod pod-subpath-test-configmap-j6wd to disappear
Oct 30 11:32:49.596: INFO: Pod pod-subpath-test-configmap-j6wd no longer exists
STEP: Deleting pod pod-subpath-test-configmap-j6wd
Oct 30 11:32:49.596: INFO: Deleting pod "pod-subpath-test-configmap-j6wd" in namespace "subpath-9941"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:32:49.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9941" for this suite.
Oct 30 11:32:55.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:32:55.968: INFO: namespace subpath-9941 deletion completed in 6.350815594s

â€¢ [SLOW TEST:30.738 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:32:55.977: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-04847c1b-fb09-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume configMaps
Oct 30 11:32:56.101: INFO: Waiting up to 5m0s for pod "pod-configmaps-04878bdf-fb09-11e9-91af-623cf93d857c" in namespace "configmap-1253" to be "success or failure"
Oct 30 11:32:56.110: INFO: Pod "pod-configmaps-04878bdf-fb09-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.659826ms
Oct 30 11:32:58.127: INFO: Pod "pod-configmaps-04878bdf-fb09-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026369338s
Oct 30 11:33:00.140: INFO: Pod "pod-configmaps-04878bdf-fb09-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039167851s
STEP: Saw pod success
Oct 30 11:33:00.140: INFO: Pod "pod-configmaps-04878bdf-fb09-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:33:00.148: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-configmaps-04878bdf-fb09-11e9-91af-623cf93d857c container configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 11:33:00.224: INFO: Waiting for pod pod-configmaps-04878bdf-fb09-11e9-91af-623cf93d857c to disappear
Oct 30 11:33:00.233: INFO: Pod pod-configmaps-04878bdf-fb09-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:33:00.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1253" for this suite.
Oct 30 11:33:06.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:33:06.533: INFO: namespace configmap-1253 deletion completed in 6.288255813s

â€¢ [SLOW TEST:10.557 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:33:06.535: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct 30 11:33:11.250: INFO: Successfully updated pod "annotationupdate0ad0fead-fb09-11e9-91af-623cf93d857c"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:33:13.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7631" for this suite.
Oct 30 11:33:35.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:33:35.657: INFO: namespace projected-7631 deletion completed in 22.336387782s

â€¢ [SLOW TEST:29.122 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:33:35.660: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-1c2aa46a-fb09-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume secrets
Oct 30 11:33:35.777: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1c2d6b92-fb09-11e9-91af-623cf93d857c" in namespace "projected-1603" to be "success or failure"
Oct 30 11:33:35.795: INFO: Pod "pod-projected-secrets-1c2d6b92-fb09-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.822216ms
Oct 30 11:33:37.806: INFO: Pod "pod-projected-secrets-1c2d6b92-fb09-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028585398s
Oct 30 11:33:39.815: INFO: Pod "pod-projected-secrets-1c2d6b92-fb09-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038233635s
STEP: Saw pod success
Oct 30 11:33:39.815: INFO: Pod "pod-projected-secrets-1c2d6b92-fb09-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:33:39.823: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-projected-secrets-1c2d6b92-fb09-11e9-91af-623cf93d857c container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 30 11:33:39.880: INFO: Waiting for pod pod-projected-secrets-1c2d6b92-fb09-11e9-91af-623cf93d857c to disappear
Oct 30 11:33:39.885: INFO: Pod pod-projected-secrets-1c2d6b92-fb09-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:33:39.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1603" for this suite.
Oct 30 11:33:45.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:33:46.230: INFO: namespace projected-1603 deletion completed in 6.336295808s

â€¢ [SLOW TEST:10.571 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:33:46.234: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct 30 11:33:51.001: INFO: Successfully updated pod "annotationupdate227d9f13-fb09-11e9-91af-623cf93d857c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:33:53.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3483" for this suite.
Oct 30 11:34:15.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:34:15.481: INFO: namespace downward-api-3483 deletion completed in 22.415856067s

â€¢ [SLOW TEST:29.247 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:34:15.482: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1256
STEP: creating an rc
Oct 30 11:34:15.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 create -f - --namespace=kubectl-530'
Oct 30 11:34:15.973: INFO: stderr: ""
Oct 30 11:34:15.973: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Oct 30 11:34:16.982: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 11:34:16.982: INFO: Found 0 / 1
Oct 30 11:34:17.982: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 11:34:17.982: INFO: Found 0 / 1
Oct 30 11:34:18.982: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 11:34:18.982: INFO: Found 0 / 1
Oct 30 11:34:19.984: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 11:34:19.984: INFO: Found 0 / 1
Oct 30 11:34:20.981: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 11:34:20.981: INFO: Found 1 / 1
Oct 30 11:34:20.981: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 30 11:34:20.989: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 11:34:20.989: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Oct 30 11:34:20.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 logs redis-master-ckwr4 redis-master --namespace=kubectl-530'
Oct 30 11:34:21.149: INFO: stderr: ""
Oct 30 11:34:21.149: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 30 Oct 11:34:19.553 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 30 Oct 11:34:19.553 # Server started, Redis version 3.2.12\n1:M 30 Oct 11:34:19.553 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 30 Oct 11:34:19.553 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Oct 30 11:34:21.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 log redis-master-ckwr4 redis-master --namespace=kubectl-530 --tail=1'
Oct 30 11:34:21.283: INFO: stderr: ""
Oct 30 11:34:21.283: INFO: stdout: "1:M 30 Oct 11:34:19.553 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Oct 30 11:34:21.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 log redis-master-ckwr4 redis-master --namespace=kubectl-530 --limit-bytes=1'
Oct 30 11:34:21.422: INFO: stderr: ""
Oct 30 11:34:21.422: INFO: stdout: " "
STEP: exposing timestamps
Oct 30 11:34:21.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 log redis-master-ckwr4 redis-master --namespace=kubectl-530 --tail=1 --timestamps'
Oct 30 11:34:21.586: INFO: stderr: ""
Oct 30 11:34:21.586: INFO: stdout: "2019-10-30T11:34:19.553377967Z 1:M 30 Oct 11:34:19.553 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Oct 30 11:34:24.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 log redis-master-ckwr4 redis-master --namespace=kubectl-530 --since=1s'
Oct 30 11:34:24.258: INFO: stderr: ""
Oct 30 11:34:24.258: INFO: stdout: ""
Oct 30 11:34:24.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 log redis-master-ckwr4 redis-master --namespace=kubectl-530 --since=24h'
Oct 30 11:34:24.403: INFO: stderr: ""
Oct 30 11:34:24.403: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 30 Oct 11:34:19.553 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 30 Oct 11:34:19.553 # Server started, Redis version 3.2.12\n1:M 30 Oct 11:34:19.553 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 30 Oct 11:34:19.553 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
STEP: using delete to clean up resources
Oct 30 11:34:24.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 delete --grace-period=0 --force -f - --namespace=kubectl-530'
Oct 30 11:34:24.534: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 11:34:24.534: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Oct 30 11:34:24.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get rc,svc -l name=nginx --no-headers --namespace=kubectl-530'
Oct 30 11:34:24.655: INFO: stderr: "No resources found.\n"
Oct 30 11:34:24.655: INFO: stdout: ""
Oct 30 11:34:24.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -l name=nginx --namespace=kubectl-530 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 30 11:34:24.768: INFO: stderr: ""
Oct 30 11:34:24.768: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:34:24.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-530" for this suite.
Oct 30 11:34:46.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:34:47.140: INFO: namespace kubectl-530 deletion completed in 22.359600237s

â€¢ [SLOW TEST:31.658 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:34:47.145: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-46ca09da-fb09-11e9-91af-623cf93d857c
STEP: Creating secret with name secret-projected-all-test-volume-46ca09ad-fb09-11e9-91af-623cf93d857c
STEP: Creating a pod to test Check all projections for projected volume plugin
Oct 30 11:34:47.314: INFO: Waiting up to 5m0s for pod "projected-volume-46ca0920-fb09-11e9-91af-623cf93d857c" in namespace "projected-2930" to be "success or failure"
Oct 30 11:34:47.326: INFO: Pod "projected-volume-46ca0920-fb09-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.618562ms
Oct 30 11:34:49.338: INFO: Pod "projected-volume-46ca0920-fb09-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023735608s
Oct 30 11:34:51.348: INFO: Pod "projected-volume-46ca0920-fb09-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034132528s
STEP: Saw pod success
Oct 30 11:34:51.348: INFO: Pod "projected-volume-46ca0920-fb09-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:34:51.359: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod projected-volume-46ca0920-fb09-11e9-91af-623cf93d857c container projected-all-volume-test: <nil>
STEP: delete the pod
Oct 30 11:34:51.428: INFO: Waiting for pod projected-volume-46ca0920-fb09-11e9-91af-623cf93d857c to disappear
Oct 30 11:34:51.445: INFO: Pod projected-volume-46ca0920-fb09-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:34:51.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2930" for this suite.
Oct 30 11:34:57.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:34:57.782: INFO: namespace projected-2930 deletion completed in 6.323756991s

â€¢ [SLOW TEST:10.638 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:34:57.784: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:34:57.905: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4d20c7da-fb09-11e9-91af-623cf93d857c" in namespace "downward-api-4519" to be "success or failure"
Oct 30 11:34:57.913: INFO: Pod "downwardapi-volume-4d20c7da-fb09-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.498301ms
Oct 30 11:34:59.921: INFO: Pod "downwardapi-volume-4d20c7da-fb09-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015492501s
Oct 30 11:35:01.932: INFO: Pod "downwardapi-volume-4d20c7da-fb09-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026275133s
STEP: Saw pod success
Oct 30 11:35:01.932: INFO: Pod "downwardapi-volume-4d20c7da-fb09-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:35:01.940: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod downwardapi-volume-4d20c7da-fb09-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 11:35:01.994: INFO: Waiting for pod downwardapi-volume-4d20c7da-fb09-11e9-91af-623cf93d857c to disappear
Oct 30 11:35:02.000: INFO: Pod downwardapi-volume-4d20c7da-fb09-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:35:02.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4519" for this suite.
Oct 30 11:35:08.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:35:08.313: INFO: namespace downward-api-4519 deletion completed in 6.304199106s

â€¢ [SLOW TEST:10.530 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:35:08.314: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Oct 30 11:35:08.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 api-versions'
Oct 30 11:35:08.581: INFO: stderr: ""
Oct 30 11:35:08.581: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:35:08.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2457" for this suite.
Oct 30 11:35:14.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:35:14.878: INFO: namespace kubectl-2457 deletion completed in 6.288058171s

â€¢ [SLOW TEST:6.563 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:35:14.878: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-57518f64-fb09-11e9-91af-623cf93d857c
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-57518f64-fb09-11e9-91af-623cf93d857c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:36:36.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7753" for this suite.
Oct 30 11:37:00.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:37:00.320: INFO: namespace projected-7753 deletion completed in 24.302285959s

â€¢ [SLOW TEST:105.442 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:37:00.324: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 11:37:00.443: INFO: (0) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 18.222779ms)
Oct 30 11:37:00.456: INFO: (1) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 13.726935ms)
Oct 30 11:37:00.474: INFO: (2) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 17.600956ms)
Oct 30 11:37:00.486: INFO: (3) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 11.378042ms)
Oct 30 11:37:00.494: INFO: (4) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 8.517685ms)
Oct 30 11:37:00.502: INFO: (5) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 8.027008ms)
Oct 30 11:37:00.512: INFO: (6) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 9.479566ms)
Oct 30 11:37:00.522: INFO: (7) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 9.886146ms)
Oct 30 11:37:00.531: INFO: (8) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 9.191259ms)
Oct 30 11:37:00.542: INFO: (9) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 11.128491ms)
Oct 30 11:37:00.556: INFO: (10) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 14.128971ms)
Oct 30 11:37:00.566: INFO: (11) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 9.877232ms)
Oct 30 11:37:00.577: INFO: (12) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 10.300179ms)
Oct 30 11:37:00.587: INFO: (13) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 9.921136ms)
Oct 30 11:37:00.597: INFO: (14) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 9.917685ms)
Oct 30 11:37:00.606: INFO: (15) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 8.970018ms)
Oct 30 11:37:00.616: INFO: (16) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 10.156985ms)
Oct 30 11:37:00.629: INFO: (17) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 13.08102ms)
Oct 30 11:37:00.640: INFO: (18) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 10.833313ms)
Oct 30 11:37:00.649: INFO: (19) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 8.697313ms)
[AfterEach] version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:37:00.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6384" for this suite.
Oct 30 11:37:06.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:37:06.939: INFO: namespace proxy-6384 deletion completed in 6.278160775s

â€¢ [SLOW TEST:6.615 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:37:06.941: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:37:07.057: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9a1b8b02-fb09-11e9-91af-623cf93d857c" in namespace "downward-api-1027" to be "success or failure"
Oct 30 11:37:07.074: INFO: Pod "downwardapi-volume-9a1b8b02-fb09-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.974029ms
Oct 30 11:37:09.082: INFO: Pod "downwardapi-volume-9a1b8b02-fb09-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024964008s
Oct 30 11:37:11.091: INFO: Pod "downwardapi-volume-9a1b8b02-fb09-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033922688s
STEP: Saw pod success
Oct 30 11:37:11.091: INFO: Pod "downwardapi-volume-9a1b8b02-fb09-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:37:11.098: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod downwardapi-volume-9a1b8b02-fb09-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 11:37:11.154: INFO: Waiting for pod downwardapi-volume-9a1b8b02-fb09-11e9-91af-623cf93d857c to disappear
Oct 30 11:37:11.161: INFO: Pod downwardapi-volume-9a1b8b02-fb09-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:37:11.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1027" for this suite.
Oct 30 11:37:17.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:37:17.450: INFO: namespace downward-api-1027 deletion completed in 6.281850678s

â€¢ [SLOW TEST:10.510 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:37:17.452: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-a05e00e2-fb09-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume configMaps
Oct 30 11:37:17.574: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a0608ea4-fb09-11e9-91af-623cf93d857c" in namespace "projected-4395" to be "success or failure"
Oct 30 11:37:17.590: INFO: Pod "pod-projected-configmaps-a0608ea4-fb09-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 15.909764ms
Oct 30 11:37:19.603: INFO: Pod "pod-projected-configmaps-a0608ea4-fb09-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028582713s
Oct 30 11:37:21.612: INFO: Pod "pod-projected-configmaps-a0608ea4-fb09-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03806844s
STEP: Saw pod success
Oct 30 11:37:21.613: INFO: Pod "pod-projected-configmaps-a0608ea4-fb09-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:37:21.620: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-projected-configmaps-a0608ea4-fb09-11e9-91af-623cf93d857c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 11:37:21.684: INFO: Waiting for pod pod-projected-configmaps-a0608ea4-fb09-11e9-91af-623cf93d857c to disappear
Oct 30 11:37:21.691: INFO: Pod pod-projected-configmaps-a0608ea4-fb09-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:37:21.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4395" for this suite.
Oct 30 11:37:27.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:37:28.017: INFO: namespace projected-4395 deletion completed in 6.314024641s

â€¢ [SLOW TEST:10.565 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:37:28.021: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Oct 30 11:37:28.196: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8372,SelfLink:/api/v1/namespaces/watch-8372/configmaps/e2e-watch-test-label-changed,UID:a6ae793c-fb09-11e9-a053-fa163e61542c,ResourceVersion:8436,Generation:0,CreationTimestamp:2019-10-30 11:37:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 30 11:37:28.197: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8372,SelfLink:/api/v1/namespaces/watch-8372/configmaps/e2e-watch-test-label-changed,UID:a6ae793c-fb09-11e9-a053-fa163e61542c,ResourceVersion:8437,Generation:0,CreationTimestamp:2019-10-30 11:37:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 30 11:37:28.197: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8372,SelfLink:/api/v1/namespaces/watch-8372/configmaps/e2e-watch-test-label-changed,UID:a6ae793c-fb09-11e9-a053-fa163e61542c,ResourceVersion:8438,Generation:0,CreationTimestamp:2019-10-30 11:37:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Oct 30 11:37:38.297: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8372,SelfLink:/api/v1/namespaces/watch-8372/configmaps/e2e-watch-test-label-changed,UID:a6ae793c-fb09-11e9-a053-fa163e61542c,ResourceVersion:8467,Generation:0,CreationTimestamp:2019-10-30 11:37:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 30 11:37:38.297: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8372,SelfLink:/api/v1/namespaces/watch-8372/configmaps/e2e-watch-test-label-changed,UID:a6ae793c-fb09-11e9-a053-fa163e61542c,ResourceVersion:8468,Generation:0,CreationTimestamp:2019-10-30 11:37:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Oct 30 11:37:38.297: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8372,SelfLink:/api/v1/namespaces/watch-8372/configmaps/e2e-watch-test-label-changed,UID:a6ae793c-fb09-11e9-a053-fa163e61542c,ResourceVersion:8469,Generation:0,CreationTimestamp:2019-10-30 11:37:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:37:38.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8372" for this suite.
Oct 30 11:37:44.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:37:44.649: INFO: namespace watch-8372 deletion completed in 6.335301913s

â€¢ [SLOW TEST:16.628 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:37:44.650: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 11:37:44.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 version'
Oct 30 11:37:44.871: INFO: stderr: ""
Oct 30 11:37:44.872: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.8\", GitCommit:\"211047e9a1922595eaa3a1127ed365e9299a6c23\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T12:11:03Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.8\", GitCommit:\"211047e9a1922595eaa3a1127ed365e9299a6c23\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T12:02:12Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:37:44.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3428" for this suite.
Oct 30 11:37:50.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:37:51.180: INFO: namespace kubectl-3428 deletion completed in 6.295738471s

â€¢ [SLOW TEST:6.531 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:37:51.183: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 11:37:51.373: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"b481d929-fb09-11e9-a053-fa163e61542c", Controller:(*bool)(0xc0030234ce), BlockOwnerDeletion:(*bool)(0xc0030234cf)}}
Oct 30 11:37:51.408: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b47bde48-fb09-11e9-a053-fa163e61542c", Controller:(*bool)(0xc00314d4b6), BlockOwnerDeletion:(*bool)(0xc00314d4b7)}}
Oct 30 11:37:51.431: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b47ee661-fb09-11e9-a053-fa163e61542c", Controller:(*bool)(0xc0025d98ee), BlockOwnerDeletion:(*bool)(0xc0025d98ef)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:37:56.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3706" for this suite.
Oct 30 11:38:02.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:38:02.796: INFO: namespace gc-3706 deletion completed in 6.295062824s

â€¢ [SLOW TEST:11.614 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:38:02.799: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 11:38:09.069: INFO: Waiting up to 5m0s for pod "client-envvars-bf11ecac-fb09-11e9-91af-623cf93d857c" in namespace "pods-5970" to be "success or failure"
Oct 30 11:38:09.081: INFO: Pod "client-envvars-bf11ecac-fb09-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.938455ms
Oct 30 11:38:11.089: INFO: Pod "client-envvars-bf11ecac-fb09-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01982129s
Oct 30 11:38:13.105: INFO: Pod "client-envvars-bf11ecac-fb09-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036116184s
STEP: Saw pod success
Oct 30 11:38:13.105: INFO: Pod "client-envvars-bf11ecac-fb09-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:38:13.114: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod client-envvars-bf11ecac-fb09-11e9-91af-623cf93d857c container env3cont: <nil>
STEP: delete the pod
Oct 30 11:38:13.213: INFO: Waiting for pod client-envvars-bf11ecac-fb09-11e9-91af-623cf93d857c to disappear
Oct 30 11:38:13.224: INFO: Pod client-envvars-bf11ecac-fb09-11e9-91af-623cf93d857c no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:38:13.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5970" for this suite.
Oct 30 11:39:03.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:39:03.583: INFO: namespace pods-5970 deletion completed in 50.337860228s

â€¢ [SLOW TEST:60.784 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:39:03.583: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Oct 30 11:39:03.773: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-5607,SelfLink:/api/v1/namespaces/watch-5607/configmaps/e2e-watch-test-resource-version,UID:dfa2361b-fb09-11e9-a053-fa163e61542c,ResourceVersion:8808,Generation:0,CreationTimestamp:2019-10-30 11:39:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 30 11:39:03.773: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-5607,SelfLink:/api/v1/namespaces/watch-5607/configmaps/e2e-watch-test-resource-version,UID:dfa2361b-fb09-11e9-a053-fa163e61542c,ResourceVersion:8809,Generation:0,CreationTimestamp:2019-10-30 11:39:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:39:03.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5607" for this suite.
Oct 30 11:39:09.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:39:10.137: INFO: namespace watch-5607 deletion completed in 6.35354783s

â€¢ [SLOW TEST:6.554 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:39:10.140: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-e38b4a09-fb09-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume configMaps
Oct 30 11:39:10.283: INFO: Waiting up to 5m0s for pod "pod-configmaps-e38e32fa-fb09-11e9-91af-623cf93d857c" in namespace "configmap-2558" to be "success or failure"
Oct 30 11:39:10.293: INFO: Pod "pod-configmaps-e38e32fa-fb09-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.038624ms
Oct 30 11:39:12.304: INFO: Pod "pod-configmaps-e38e32fa-fb09-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021512681s
Oct 30 11:39:14.314: INFO: Pod "pod-configmaps-e38e32fa-fb09-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031490416s
STEP: Saw pod success
Oct 30 11:39:14.315: INFO: Pod "pod-configmaps-e38e32fa-fb09-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:39:14.323: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-configmaps-e38e32fa-fb09-11e9-91af-623cf93d857c container configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 11:39:14.379: INFO: Waiting for pod pod-configmaps-e38e32fa-fb09-11e9-91af-623cf93d857c to disappear
Oct 30 11:39:14.388: INFO: Pod pod-configmaps-e38e32fa-fb09-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:39:14.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2558" for this suite.
Oct 30 11:39:20.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:39:20.728: INFO: namespace configmap-2558 deletion completed in 6.328450447s

â€¢ [SLOW TEST:10.589 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:39:20.730: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1521
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 30 11:39:20.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-285'
Oct 30 11:39:21.457: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 30 11:39:21.457: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1526
Oct 30 11:39:23.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 delete deployment e2e-test-nginx-deployment --namespace=kubectl-285'
Oct 30 11:39:23.662: INFO: stderr: ""
Oct 30 11:39:23.662: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:39:23.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-285" for this suite.
Oct 30 11:39:45.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:39:46.055: INFO: namespace kubectl-285 deletion completed in 22.381212248s

â€¢ [SLOW TEST:25.325 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:39:46.057: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-kq4v2 in namespace proxy-4434
I1030 11:39:46.253872      18 runners.go:184] Created replication controller with name: proxy-service-kq4v2, namespace: proxy-4434, replica count: 1
I1030 11:39:47.304882      18 runners.go:184] proxy-service-kq4v2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1030 11:39:48.305242      18 runners.go:184] proxy-service-kq4v2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1030 11:39:49.305595      18 runners.go:184] proxy-service-kq4v2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1030 11:39:50.305872      18 runners.go:184] proxy-service-kq4v2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1030 11:39:51.306264      18 runners.go:184] proxy-service-kq4v2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1030 11:39:52.306766      18 runners.go:184] proxy-service-kq4v2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1030 11:39:53.307148      18 runners.go:184] proxy-service-kq4v2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1030 11:39:54.307453      18 runners.go:184] proxy-service-kq4v2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1030 11:39:55.307746      18 runners.go:184] proxy-service-kq4v2 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 30 11:39:55.317: INFO: setup took 9.163852322s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Oct 30 11:39:55.337: INFO: (0) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 20.288005ms)
Oct 30 11:39:55.338: INFO: (0) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 21.140487ms)
Oct 30 11:39:55.341: INFO: (0) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 23.407257ms)
Oct 30 11:39:55.342: INFO: (0) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 24.232652ms)
Oct 30 11:39:55.342: INFO: (0) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 24.435514ms)
Oct 30 11:39:55.342: INFO: (0) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 25.086013ms)
Oct 30 11:39:55.346: INFO: (0) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 28.365032ms)
Oct 30 11:39:55.346: INFO: (0) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 28.862864ms)
Oct 30 11:39:55.346: INFO: (0) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 29.033843ms)
Oct 30 11:39:55.349: INFO: (0) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 31.879724ms)
Oct 30 11:39:55.355: INFO: (0) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 37.951234ms)
Oct 30 11:39:55.356: INFO: (0) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 38.323936ms)
Oct 30 11:39:55.357: INFO: (0) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 39.668384ms)
Oct 30 11:39:55.358: INFO: (0) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 41.632706ms)
Oct 30 11:39:55.362: INFO: (0) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 44.654032ms)
Oct 30 11:39:55.363: INFO: (0) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 46.190441ms)
Oct 30 11:39:55.381: INFO: (1) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 16.755226ms)
Oct 30 11:39:55.387: INFO: (1) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 22.870778ms)
Oct 30 11:39:55.388: INFO: (1) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 24.262495ms)
Oct 30 11:39:55.389: INFO: (1) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 24.364624ms)
Oct 30 11:39:55.389: INFO: (1) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 25.398849ms)
Oct 30 11:39:55.389: INFO: (1) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 25.223933ms)
Oct 30 11:39:55.392: INFO: (1) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 27.428212ms)
Oct 30 11:39:55.392: INFO: (1) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 28.515302ms)
Oct 30 11:39:55.394: INFO: (1) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 30.622329ms)
Oct 30 11:39:55.395: INFO: (1) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 30.549913ms)
Oct 30 11:39:55.397: INFO: (1) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 33.45977ms)
Oct 30 11:39:55.401: INFO: (1) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 36.43134ms)
Oct 30 11:39:55.402: INFO: (1) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 37.385893ms)
Oct 30 11:39:55.402: INFO: (1) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 37.77988ms)
Oct 30 11:39:55.402: INFO: (1) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 37.761782ms)
Oct 30 11:39:55.405: INFO: (1) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 40.379003ms)
Oct 30 11:39:55.429: INFO: (2) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 23.629723ms)
Oct 30 11:39:55.429: INFO: (2) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 23.691694ms)
Oct 30 11:39:55.429: INFO: (2) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 23.785162ms)
Oct 30 11:39:55.429: INFO: (2) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 24.047538ms)
Oct 30 11:39:55.432: INFO: (2) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 27.22611ms)
Oct 30 11:39:55.432: INFO: (2) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 27.706132ms)
Oct 30 11:39:55.434: INFO: (2) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 29.392328ms)
Oct 30 11:39:55.434: INFO: (2) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 29.204044ms)
Oct 30 11:39:55.434: INFO: (2) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 29.583057ms)
Oct 30 11:39:55.436: INFO: (2) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 30.686826ms)
Oct 30 11:39:55.436: INFO: (2) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 31.534854ms)
Oct 30 11:39:55.445: INFO: (2) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 39.765501ms)
Oct 30 11:39:55.445: INFO: (2) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 40.309187ms)
Oct 30 11:39:55.445: INFO: (2) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 40.713214ms)
Oct 30 11:39:55.446: INFO: (2) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 40.882734ms)
Oct 30 11:39:55.446: INFO: (2) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 41.096539ms)
Oct 30 11:39:55.467: INFO: (3) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 20.144925ms)
Oct 30 11:39:55.468: INFO: (3) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 20.68223ms)
Oct 30 11:39:55.469: INFO: (3) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 22.42558ms)
Oct 30 11:39:55.470: INFO: (3) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 22.939342ms)
Oct 30 11:39:55.470: INFO: (3) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 23.400766ms)
Oct 30 11:39:55.472: INFO: (3) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 25.264035ms)
Oct 30 11:39:55.473: INFO: (3) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 26.180149ms)
Oct 30 11:39:55.474: INFO: (3) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 26.959861ms)
Oct 30 11:39:55.475: INFO: (3) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 27.593266ms)
Oct 30 11:39:55.477: INFO: (3) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 30.518244ms)
Oct 30 11:39:55.514: INFO: (3) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 67.583957ms)
Oct 30 11:39:55.515: INFO: (3) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 68.399354ms)
Oct 30 11:39:55.516: INFO: (3) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 69.257548ms)
Oct 30 11:39:55.516: INFO: (3) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 69.484361ms)
Oct 30 11:39:55.516: INFO: (3) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 69.596465ms)
Oct 30 11:39:55.517: INFO: (3) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 70.043106ms)
Oct 30 11:39:55.536: INFO: (4) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 19.176076ms)
Oct 30 11:39:55.537: INFO: (4) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 19.616546ms)
Oct 30 11:39:55.540: INFO: (4) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 23.253132ms)
Oct 30 11:39:55.543: INFO: (4) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 25.725808ms)
Oct 30 11:39:55.549: INFO: (4) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 31.980373ms)
Oct 30 11:39:55.550: INFO: (4) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 33.830639ms)
Oct 30 11:39:55.551: INFO: (4) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 34.233635ms)
Oct 30 11:39:55.551: INFO: (4) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 34.052256ms)
Oct 30 11:39:55.551: INFO: (4) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 33.975557ms)
Oct 30 11:39:55.551: INFO: (4) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 34.263977ms)
Oct 30 11:39:55.551: INFO: (4) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 34.5151ms)
Oct 30 11:39:55.552: INFO: (4) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 34.854946ms)
Oct 30 11:39:55.552: INFO: (4) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 34.902012ms)
Oct 30 11:39:55.553: INFO: (4) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 36.467269ms)
Oct 30 11:39:55.553: INFO: (4) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 36.616093ms)
Oct 30 11:39:55.554: INFO: (4) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 36.76208ms)
Oct 30 11:39:55.566: INFO: (5) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 11.916184ms)
Oct 30 11:39:55.572: INFO: (5) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 18.104326ms)
Oct 30 11:39:55.576: INFO: (5) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 21.587171ms)
Oct 30 11:39:55.576: INFO: (5) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 22.544174ms)
Oct 30 11:39:55.578: INFO: (5) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 24.125925ms)
Oct 30 11:39:55.578: INFO: (5) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 24.195401ms)
Oct 30 11:39:55.579: INFO: (5) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 25.028647ms)
Oct 30 11:39:55.581: INFO: (5) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 27.247989ms)
Oct 30 11:39:55.582: INFO: (5) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 27.951883ms)
Oct 30 11:39:55.583: INFO: (5) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 29.809736ms)
Oct 30 11:39:55.584: INFO: (5) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 29.773554ms)
Oct 30 11:39:55.585: INFO: (5) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 31.421495ms)
Oct 30 11:39:55.585: INFO: (5) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 31.266971ms)
Oct 30 11:39:55.587: INFO: (5) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 33.107474ms)
Oct 30 11:39:55.588: INFO: (5) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 33.399308ms)
Oct 30 11:39:55.589: INFO: (5) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 35.090298ms)
Oct 30 11:39:55.612: INFO: (6) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 22.19317ms)
Oct 30 11:39:55.618: INFO: (6) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 28.155192ms)
Oct 30 11:39:55.620: INFO: (6) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 29.477115ms)
Oct 30 11:39:55.620: INFO: (6) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 29.764866ms)
Oct 30 11:39:55.621: INFO: (6) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 30.188295ms)
Oct 30 11:39:55.621: INFO: (6) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 31.009019ms)
Oct 30 11:39:55.622: INFO: (6) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 31.356421ms)
Oct 30 11:39:55.622: INFO: (6) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 31.71116ms)
Oct 30 11:39:55.622: INFO: (6) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 31.406109ms)
Oct 30 11:39:55.623: INFO: (6) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 32.55356ms)
Oct 30 11:39:55.630: INFO: (6) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 39.793702ms)
Oct 30 11:39:55.632: INFO: (6) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 42.645339ms)
Oct 30 11:39:55.634: INFO: (6) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 43.838874ms)
Oct 30 11:39:55.634: INFO: (6) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 44.095714ms)
Oct 30 11:39:55.634: INFO: (6) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 44.344036ms)
Oct 30 11:39:55.635: INFO: (6) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 44.900234ms)
Oct 30 11:39:55.654: INFO: (7) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 18.765329ms)
Oct 30 11:39:55.656: INFO: (7) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 20.831025ms)
Oct 30 11:39:55.656: INFO: (7) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 20.827465ms)
Oct 30 11:39:55.656: INFO: (7) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 20.860262ms)
Oct 30 11:39:55.657: INFO: (7) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 21.573267ms)
Oct 30 11:39:55.657: INFO: (7) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 21.604472ms)
Oct 30 11:39:55.657: INFO: (7) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 21.647291ms)
Oct 30 11:39:55.657: INFO: (7) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 22.095326ms)
Oct 30 11:39:55.658: INFO: (7) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 22.420685ms)
Oct 30 11:39:55.658: INFO: (7) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 22.71711ms)
Oct 30 11:39:55.658: INFO: (7) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 22.459692ms)
Oct 30 11:39:55.663: INFO: (7) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 27.689602ms)
Oct 30 11:39:55.663: INFO: (7) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 27.6762ms)
Oct 30 11:39:55.663: INFO: (7) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 27.703929ms)
Oct 30 11:39:55.663: INFO: (7) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 28.026417ms)
Oct 30 11:39:55.663: INFO: (7) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 27.439248ms)
Oct 30 11:39:55.687: INFO: (8) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 22.804243ms)
Oct 30 11:39:55.688: INFO: (8) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 23.596467ms)
Oct 30 11:39:55.690: INFO: (8) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 25.358152ms)
Oct 30 11:39:55.693: INFO: (8) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 28.238464ms)
Oct 30 11:39:55.694: INFO: (8) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 29.796522ms)
Oct 30 11:39:55.695: INFO: (8) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 30.347984ms)
Oct 30 11:39:55.695: INFO: (8) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 30.602921ms)
Oct 30 11:39:55.698: INFO: (8) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 34.428847ms)
Oct 30 11:39:55.700: INFO: (8) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 35.816139ms)
Oct 30 11:39:55.700: INFO: (8) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 35.931331ms)
Oct 30 11:39:55.701: INFO: (8) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 36.728247ms)
Oct 30 11:39:55.701: INFO: (8) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 37.128625ms)
Oct 30 11:39:55.701: INFO: (8) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 37.480065ms)
Oct 30 11:39:55.702: INFO: (8) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 37.342182ms)
Oct 30 11:39:55.702: INFO: (8) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 37.673789ms)
Oct 30 11:39:55.702: INFO: (8) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 37.571667ms)
Oct 30 11:39:55.722: INFO: (9) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 19.367289ms)
Oct 30 11:39:55.722: INFO: (9) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 19.969746ms)
Oct 30 11:39:55.724: INFO: (9) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 21.762969ms)
Oct 30 11:39:55.725: INFO: (9) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 22.349484ms)
Oct 30 11:39:55.730: INFO: (9) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 27.904594ms)
Oct 30 11:39:55.730: INFO: (9) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 26.76142ms)
Oct 30 11:39:55.730: INFO: (9) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 28.006929ms)
Oct 30 11:39:55.731: INFO: (9) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 28.178442ms)
Oct 30 11:39:55.731: INFO: (9) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 28.446785ms)
Oct 30 11:39:55.731: INFO: (9) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 28.53906ms)
Oct 30 11:39:55.733: INFO: (9) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 30.763972ms)
Oct 30 11:39:55.737: INFO: (9) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 35.335399ms)
Oct 30 11:39:55.737: INFO: (9) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 35.005178ms)
Oct 30 11:39:55.743: INFO: (9) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 40.055451ms)
Oct 30 11:39:55.744: INFO: (9) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 41.027016ms)
Oct 30 11:39:55.753: INFO: (9) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 50.183745ms)
Oct 30 11:39:55.778: INFO: (10) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 25.789542ms)
Oct 30 11:39:55.785: INFO: (10) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 32.221963ms)
Oct 30 11:39:55.786: INFO: (10) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 33.209524ms)
Oct 30 11:39:55.787: INFO: (10) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 33.770265ms)
Oct 30 11:39:55.788: INFO: (10) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 34.458791ms)
Oct 30 11:39:55.788: INFO: (10) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 34.630054ms)
Oct 30 11:39:55.789: INFO: (10) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 35.297215ms)
Oct 30 11:39:55.789: INFO: (10) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 35.745615ms)
Oct 30 11:39:55.789: INFO: (10) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 36.264414ms)
Oct 30 11:39:55.789: INFO: (10) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 36.253248ms)
Oct 30 11:39:55.801: INFO: (10) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 48.354568ms)
Oct 30 11:39:55.806: INFO: (10) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 52.450816ms)
Oct 30 11:39:55.807: INFO: (10) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 54.104661ms)
Oct 30 11:39:55.808: INFO: (10) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 54.896034ms)
Oct 30 11:39:55.809: INFO: (10) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 55.708917ms)
Oct 30 11:39:55.809: INFO: (10) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 56.027364ms)
Oct 30 11:39:55.833: INFO: (11) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 23.771454ms)
Oct 30 11:39:55.834: INFO: (11) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 24.499584ms)
Oct 30 11:39:55.834: INFO: (11) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 24.640147ms)
Oct 30 11:39:55.834: INFO: (11) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 24.96402ms)
Oct 30 11:39:55.835: INFO: (11) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 25.131268ms)
Oct 30 11:39:55.835: INFO: (11) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 25.409163ms)
Oct 30 11:39:55.835: INFO: (11) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 25.3076ms)
Oct 30 11:39:55.835: INFO: (11) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 25.910996ms)
Oct 30 11:39:55.837: INFO: (11) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 27.730541ms)
Oct 30 11:39:55.839: INFO: (11) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 29.531529ms)
Oct 30 11:39:55.839: INFO: (11) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 30.062233ms)
Oct 30 11:39:55.840: INFO: (11) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 30.578211ms)
Oct 30 11:39:55.840: INFO: (11) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 30.740072ms)
Oct 30 11:39:55.847: INFO: (11) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 36.839937ms)
Oct 30 11:39:55.847: INFO: (11) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 37.70647ms)
Oct 30 11:39:55.848: INFO: (11) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 38.560642ms)
Oct 30 11:39:55.861: INFO: (12) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 12.782116ms)
Oct 30 11:39:55.868: INFO: (12) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 19.295735ms)
Oct 30 11:39:55.869: INFO: (12) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 19.833835ms)
Oct 30 11:39:55.869: INFO: (12) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 20.14941ms)
Oct 30 11:39:55.870: INFO: (12) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 21.020469ms)
Oct 30 11:39:55.872: INFO: (12) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 23.841742ms)
Oct 30 11:39:55.873: INFO: (12) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 25.075423ms)
Oct 30 11:39:55.878: INFO: (12) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 29.06584ms)
Oct 30 11:39:55.878: INFO: (12) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 29.507947ms)
Oct 30 11:39:55.880: INFO: (12) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 30.963827ms)
Oct 30 11:39:55.880: INFO: (12) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 31.899871ms)
Oct 30 11:39:55.881: INFO: (12) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 32.656964ms)
Oct 30 11:39:55.884: INFO: (12) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 34.863074ms)
Oct 30 11:39:55.887: INFO: (12) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 37.980741ms)
Oct 30 11:39:55.888: INFO: (12) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 39.184667ms)
Oct 30 11:39:55.888: INFO: (12) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 39.393074ms)
Oct 30 11:39:55.908: INFO: (13) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 19.090612ms)
Oct 30 11:39:55.908: INFO: (13) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 18.664838ms)
Oct 30 11:39:55.909: INFO: (13) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 19.822174ms)
Oct 30 11:39:55.910: INFO: (13) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 20.913926ms)
Oct 30 11:39:55.910: INFO: (13) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 21.261966ms)
Oct 30 11:39:55.911: INFO: (13) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 21.828615ms)
Oct 30 11:39:55.911: INFO: (13) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 21.731354ms)
Oct 30 11:39:55.911: INFO: (13) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 21.559546ms)
Oct 30 11:39:55.911: INFO: (13) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 21.549491ms)
Oct 30 11:39:55.912: INFO: (13) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 23.24504ms)
Oct 30 11:39:55.912: INFO: (13) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 23.851963ms)
Oct 30 11:39:55.915: INFO: (13) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 25.491442ms)
Oct 30 11:39:55.921: INFO: (13) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 31.394882ms)
Oct 30 11:39:55.921: INFO: (13) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 31.275133ms)
Oct 30 11:39:55.921: INFO: (13) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 31.37929ms)
Oct 30 11:39:55.922: INFO: (13) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 32.647338ms)
Oct 30 11:39:55.944: INFO: (14) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 22.080893ms)
Oct 30 11:39:55.944: INFO: (14) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 21.965398ms)
Oct 30 11:39:55.948: INFO: (14) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 25.313528ms)
Oct 30 11:39:55.948: INFO: (14) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 25.886474ms)
Oct 30 11:39:55.950: INFO: (14) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 27.476253ms)
Oct 30 11:39:55.950: INFO: (14) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 28.085703ms)
Oct 30 11:39:55.951: INFO: (14) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 28.75107ms)
Oct 30 11:39:55.952: INFO: (14) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 29.310299ms)
Oct 30 11:39:55.952: INFO: (14) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 29.637591ms)
Oct 30 11:39:55.952: INFO: (14) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 30.097375ms)
Oct 30 11:39:55.953: INFO: (14) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 30.28035ms)
Oct 30 11:39:55.958: INFO: (14) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 35.651528ms)
Oct 30 11:39:55.960: INFO: (14) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 37.729774ms)
Oct 30 11:39:55.960: INFO: (14) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 37.964359ms)
Oct 30 11:39:55.961: INFO: (14) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 38.85145ms)
Oct 30 11:39:55.961: INFO: (14) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 39.086222ms)
Oct 30 11:39:55.980: INFO: (15) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 17.532161ms)
Oct 30 11:39:55.984: INFO: (15) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 21.945669ms)
Oct 30 11:39:55.984: INFO: (15) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 22.076981ms)
Oct 30 11:39:55.985: INFO: (15) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 22.627232ms)
Oct 30 11:39:55.986: INFO: (15) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 23.81703ms)
Oct 30 11:39:55.986: INFO: (15) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 24.747416ms)
Oct 30 11:39:55.988: INFO: (15) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 26.020569ms)
Oct 30 11:39:55.988: INFO: (15) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 26.245612ms)
Oct 30 11:39:55.989: INFO: (15) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 27.275934ms)
Oct 30 11:39:55.990: INFO: (15) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 28.180794ms)
Oct 30 11:39:55.995: INFO: (15) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 33.254479ms)
Oct 30 11:39:56.000: INFO: (15) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 37.485931ms)
Oct 30 11:39:56.015: INFO: (15) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 52.810894ms)
Oct 30 11:39:56.015: INFO: (15) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 53.123004ms)
Oct 30 11:39:56.015: INFO: (15) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 52.914824ms)
Oct 30 11:39:56.016: INFO: (15) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 53.687771ms)
Oct 30 11:39:56.035: INFO: (16) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 17.488407ms)
Oct 30 11:39:56.035: INFO: (16) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 19.197743ms)
Oct 30 11:39:56.037: INFO: (16) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 20.443614ms)
Oct 30 11:39:56.042: INFO: (16) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 25.875995ms)
Oct 30 11:39:56.042: INFO: (16) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 25.576016ms)
Oct 30 11:39:56.043: INFO: (16) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 26.413811ms)
Oct 30 11:39:56.044: INFO: (16) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 26.699836ms)
Oct 30 11:39:56.044: INFO: (16) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 27.565766ms)
Oct 30 11:39:56.044: INFO: (16) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 27.554567ms)
Oct 30 11:39:56.044: INFO: (16) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 27.068164ms)
Oct 30 11:39:56.047: INFO: (16) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 30.256306ms)
Oct 30 11:39:56.049: INFO: (16) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 32.512633ms)
Oct 30 11:39:56.050: INFO: (16) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 33.285601ms)
Oct 30 11:39:56.052: INFO: (16) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 35.861336ms)
Oct 30 11:39:56.053: INFO: (16) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 36.564368ms)
Oct 30 11:39:56.054: INFO: (16) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 37.430371ms)
Oct 30 11:39:56.072: INFO: (17) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 18.121135ms)
Oct 30 11:39:56.085: INFO: (17) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 30.921622ms)
Oct 30 11:39:56.085: INFO: (17) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 31.269916ms)
Oct 30 11:39:56.086: INFO: (17) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 31.9775ms)
Oct 30 11:39:56.086: INFO: (17) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 31.948609ms)
Oct 30 11:39:56.086: INFO: (17) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 32.105703ms)
Oct 30 11:39:56.086: INFO: (17) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 32.361833ms)
Oct 30 11:39:56.086: INFO: (17) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 31.95604ms)
Oct 30 11:39:56.086: INFO: (17) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 32.545571ms)
Oct 30 11:39:56.086: INFO: (17) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 32.185813ms)
Oct 30 11:39:56.086: INFO: (17) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 32.52139ms)
Oct 30 11:39:56.089: INFO: (17) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 35.290705ms)
Oct 30 11:39:56.094: INFO: (17) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 39.519532ms)
Oct 30 11:39:56.095: INFO: (17) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 41.087414ms)
Oct 30 11:39:56.095: INFO: (17) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 41.403123ms)
Oct 30 11:39:56.096: INFO: (17) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 42.076759ms)
Oct 30 11:39:56.118: INFO: (18) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 21.417448ms)
Oct 30 11:39:56.118: INFO: (18) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 21.856972ms)
Oct 30 11:39:56.119: INFO: (18) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 22.900738ms)
Oct 30 11:39:56.120: INFO: (18) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 23.369541ms)
Oct 30 11:39:56.121: INFO: (18) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 25.032339ms)
Oct 30 11:39:56.122: INFO: (18) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 25.464654ms)
Oct 30 11:39:56.127: INFO: (18) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 30.745446ms)
Oct 30 11:39:56.127: INFO: (18) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 30.82807ms)
Oct 30 11:39:56.127: INFO: (18) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 30.98502ms)
Oct 30 11:39:56.128: INFO: (18) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 31.793739ms)
Oct 30 11:39:56.129: INFO: (18) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 32.568897ms)
Oct 30 11:39:56.134: INFO: (18) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 38.382739ms)
Oct 30 11:39:56.139: INFO: (18) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 42.924026ms)
Oct 30 11:39:56.139: INFO: (18) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 43.341948ms)
Oct 30 11:39:56.141: INFO: (18) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 44.438588ms)
Oct 30 11:39:56.141: INFO: (18) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 44.991417ms)
Oct 30 11:39:56.165: INFO: (19) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 23.673668ms)
Oct 30 11:39:56.166: INFO: (19) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:162/proxy/: bar (200; 24.518283ms)
Oct 30 11:39:56.168: INFO: (19) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 25.907309ms)
Oct 30 11:39:56.170: INFO: (19) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:160/proxy/: foo (200; 27.531304ms)
Oct 30 11:39:56.170: INFO: (19) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz/proxy/rewriteme">test</a> (200; 27.918783ms)
Oct 30 11:39:56.170: INFO: (19) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:462/proxy/: tls qux (200; 28.626639ms)
Oct 30 11:39:56.171: INFO: (19) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:443/proxy/tlsrewritem... (200; 28.621628ms)
Oct 30 11:39:56.171: INFO: (19) /api/v1/namespaces/proxy-4434/pods/https:proxy-service-kq4v2-drfbz:460/proxy/: tls baz (200; 29.242468ms)
Oct 30 11:39:56.171: INFO: (19) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname1/proxy/: foo (200; 29.15711ms)
Oct 30 11:39:56.171: INFO: (19) /api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/http:proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">... (200; 28.797099ms)
Oct 30 11:39:56.173: INFO: (19) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname2/proxy/: bar (200; 30.61147ms)
Oct 30 11:39:56.174: INFO: (19) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname1/proxy/: tls baz (200; 32.085758ms)
Oct 30 11:39:56.174: INFO: (19) /api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4434/pods/proxy-service-kq4v2-drfbz:1080/proxy/rewriteme">test<... (200; 32.299913ms)
Oct 30 11:39:56.175: INFO: (19) /api/v1/namespaces/proxy-4434/services/proxy-service-kq4v2:portname1/proxy/: foo (200; 33.365642ms)
Oct 30 11:39:56.179: INFO: (19) /api/v1/namespaces/proxy-4434/services/http:proxy-service-kq4v2:portname2/proxy/: bar (200; 37.251957ms)
Oct 30 11:39:56.181: INFO: (19) /api/v1/namespaces/proxy-4434/services/https:proxy-service-kq4v2:tlsportname2/proxy/: tls qux (200; 39.179335ms)
STEP: deleting ReplicationController proxy-service-kq4v2 in namespace proxy-4434, will wait for the garbage collector to delete the pods
Oct 30 11:39:56.267: INFO: Deleting ReplicationController proxy-service-kq4v2 took: 24.194482ms
Oct 30 11:39:56.667: INFO: Terminating ReplicationController proxy-service-kq4v2 pods took: 400.360412ms
[AfterEach] version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:40:00.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4434" for this suite.
Oct 30 11:40:06.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:40:06.572: INFO: namespace proxy-4434 deletion completed in 6.29148121s

â€¢ [SLOW TEST:20.516 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:40:06.574: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-052fd147-fb0a-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume configMaps
Oct 30 11:40:06.726: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-05340eef-fb0a-11e9-91af-623cf93d857c" in namespace "projected-3772" to be "success or failure"
Oct 30 11:40:06.774: INFO: Pod "pod-projected-configmaps-05340eef-fb0a-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 47.897782ms
Oct 30 11:40:08.784: INFO: Pod "pod-projected-configmaps-05340eef-fb0a-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057736591s
Oct 30 11:40:10.795: INFO: Pod "pod-projected-configmaps-05340eef-fb0a-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.068275089s
STEP: Saw pod success
Oct 30 11:40:10.795: INFO: Pod "pod-projected-configmaps-05340eef-fb0a-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:40:10.804: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-projected-configmaps-05340eef-fb0a-11e9-91af-623cf93d857c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 11:40:10.887: INFO: Waiting for pod pod-projected-configmaps-05340eef-fb0a-11e9-91af-623cf93d857c to disappear
Oct 30 11:40:10.893: INFO: Pod pod-projected-configmaps-05340eef-fb0a-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:40:10.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3772" for this suite.
Oct 30 11:40:16.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:40:17.184: INFO: namespace projected-3772 deletion completed in 6.282538491s

â€¢ [SLOW TEST:10.610 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:40:17.185: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 30 11:40:17.302: INFO: Waiting up to 5m0s for pod "pod-0b807603-fb0a-11e9-91af-623cf93d857c" in namespace "emptydir-4949" to be "success or failure"
Oct 30 11:40:17.320: INFO: Pod "pod-0b807603-fb0a-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 18.654505ms
Oct 30 11:40:19.329: INFO: Pod "pod-0b807603-fb0a-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027640349s
Oct 30 11:40:21.341: INFO: Pod "pod-0b807603-fb0a-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039015502s
STEP: Saw pod success
Oct 30 11:40:21.341: INFO: Pod "pod-0b807603-fb0a-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:40:21.349: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-0b807603-fb0a-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 11:40:21.430: INFO: Waiting for pod pod-0b807603-fb0a-11e9-91af-623cf93d857c to disappear
Oct 30 11:40:21.440: INFO: Pod pod-0b807603-fb0a-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:40:21.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4949" for this suite.
Oct 30 11:40:27.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:40:27.794: INFO: namespace emptydir-4949 deletion completed in 6.343240017s

â€¢ [SLOW TEST:10.609 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:40:27.794: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 30 11:40:27.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-6692'
Oct 30 11:40:28.070: INFO: stderr: ""
Oct 30 11:40:28.070: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Oct 30 11:40:33.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pod e2e-test-nginx-pod --namespace=kubectl-6692 -o json'
Oct 30 11:40:33.251: INFO: stderr: ""
Oct 30 11:40:33.251: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.233.4.30/32\"\n        },\n        \"creationTimestamp\": \"2019-10-30T11:40:28Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-6692\",\n        \"resourceVersion\": \"9221\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-6692/pods/e2e-test-nginx-pod\",\n        \"uid\": \"11eace9d-fb0a-11e9-a053-fa163e61542c\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-jr84l\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"koris-pipeline-56683fb-92514359-node-1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-jr84l\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-jr84l\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-30T11:40:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-30T11:40:30Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-30T11:40:30Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-30T11:40:28Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://ad15a20225cb525e81d96a7e649f072df599d051b0ee29546f34e55a0ac7a863\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-10-30T11:40:29Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.0.39\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.4.30\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-10-30T11:40:28Z\"\n    }\n}\n"
STEP: replace the image in the pod
Oct 30 11:40:33.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 replace -f - --namespace=kubectl-6692'
Oct 30 11:40:33.578: INFO: stderr: ""
Oct 30 11:40:33.578: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Oct 30 11:40:33.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 delete pods e2e-test-nginx-pod --namespace=kubectl-6692'
Oct 30 11:40:38.010: INFO: stderr: ""
Oct 30 11:40:38.010: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:40:38.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6692" for this suite.
Oct 30 11:40:44.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:40:44.355: INFO: namespace kubectl-6692 deletion completed in 6.330199276s

â€¢ [SLOW TEST:16.560 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:40:44.355: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct 30 11:40:44.505: INFO: Waiting up to 5m0s for pod "downward-api-1bb507e5-fb0a-11e9-91af-623cf93d857c" in namespace "downward-api-8650" to be "success or failure"
Oct 30 11:40:44.514: INFO: Pod "downward-api-1bb507e5-fb0a-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.779696ms
Oct 30 11:40:46.522: INFO: Pod "downward-api-1bb507e5-fb0a-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01707838s
Oct 30 11:40:48.531: INFO: Pod "downward-api-1bb507e5-fb0a-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02611578s
STEP: Saw pod success
Oct 30 11:40:48.531: INFO: Pod "downward-api-1bb507e5-fb0a-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:40:48.539: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod downward-api-1bb507e5-fb0a-11e9-91af-623cf93d857c container dapi-container: <nil>
STEP: delete the pod
Oct 30 11:40:48.618: INFO: Waiting for pod downward-api-1bb507e5-fb0a-11e9-91af-623cf93d857c to disappear
Oct 30 11:40:48.633: INFO: Pod downward-api-1bb507e5-fb0a-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:40:48.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8650" for this suite.
Oct 30 11:40:54.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:40:54.948: INFO: namespace downward-api-8650 deletion completed in 6.304388632s

â€¢ [SLOW TEST:10.593 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:40:54.951: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Oct 30 11:40:55.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 create -f - --namespace=kubectl-9870'
Oct 30 11:40:55.354: INFO: stderr: ""
Oct 30 11:40:55.354: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 30 11:40:55.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9870'
Oct 30 11:40:55.489: INFO: stderr: ""
Oct 30 11:40:55.489: INFO: stdout: "update-demo-nautilus-dcr4c update-demo-nautilus-rthlq "
Oct 30 11:40:55.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-dcr4c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9870'
Oct 30 11:40:55.621: INFO: stderr: ""
Oct 30 11:40:55.621: INFO: stdout: ""
Oct 30 11:40:55.621: INFO: update-demo-nautilus-dcr4c is created but not running
Oct 30 11:41:00.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9870'
Oct 30 11:41:00.769: INFO: stderr: ""
Oct 30 11:41:00.769: INFO: stdout: "update-demo-nautilus-dcr4c update-demo-nautilus-rthlq "
Oct 30 11:41:00.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-dcr4c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9870'
Oct 30 11:41:00.908: INFO: stderr: ""
Oct 30 11:41:00.908: INFO: stdout: "true"
Oct 30 11:41:00.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-dcr4c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9870'
Oct 30 11:41:01.034: INFO: stderr: ""
Oct 30 11:41:01.034: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:41:01.034: INFO: validating pod update-demo-nautilus-dcr4c
Oct 30 11:41:01.047: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:41:01.048: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:41:01.048: INFO: update-demo-nautilus-dcr4c is verified up and running
Oct 30 11:41:01.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-rthlq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9870'
Oct 30 11:41:01.178: INFO: stderr: ""
Oct 30 11:41:01.178: INFO: stdout: "true"
Oct 30 11:41:01.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods update-demo-nautilus-rthlq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9870'
Oct 30 11:41:01.298: INFO: stderr: ""
Oct 30 11:41:01.298: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 30 11:41:01.298: INFO: validating pod update-demo-nautilus-rthlq
Oct 30 11:41:01.310: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 30 11:41:01.310: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 30 11:41:01.310: INFO: update-demo-nautilus-rthlq is verified up and running
STEP: using delete to clean up resources
Oct 30 11:41:01.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 delete --grace-period=0 --force -f - --namespace=kubectl-9870'
Oct 30 11:41:01.455: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 11:41:01.455: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 30 11:41:01.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9870'
Oct 30 11:41:01.664: INFO: stderr: "No resources found.\n"
Oct 30 11:41:01.664: INFO: stdout: ""
Oct 30 11:41:01.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -l name=update-demo --namespace=kubectl-9870 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 30 11:41:01.804: INFO: stderr: ""
Oct 30 11:41:01.804: INFO: stdout: "update-demo-nautilus-rthlq\n"
Oct 30 11:41:02.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9870'
Oct 30 11:41:02.442: INFO: stderr: "No resources found.\n"
Oct 30 11:41:02.442: INFO: stdout: ""
Oct 30 11:41:02.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -l name=update-demo --namespace=kubectl-9870 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 30 11:41:02.581: INFO: stderr: ""
Oct 30 11:41:02.581: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:41:02.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9870" for this suite.
Oct 30 11:41:26.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:41:26.975: INFO: namespace kubectl-9870 deletion completed in 24.382927717s

â€¢ [SLOW TEST:32.024 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:41:26.976: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 30 11:41:27.102: INFO: Waiting up to 5m0s for pod "pod-35194a7b-fb0a-11e9-91af-623cf93d857c" in namespace "emptydir-4186" to be "success or failure"
Oct 30 11:41:27.117: INFO: Pod "pod-35194a7b-fb0a-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 15.564771ms
Oct 30 11:41:29.125: INFO: Pod "pod-35194a7b-fb0a-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023282489s
Oct 30 11:41:31.141: INFO: Pod "pod-35194a7b-fb0a-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039123056s
STEP: Saw pod success
Oct 30 11:41:31.141: INFO: Pod "pod-35194a7b-fb0a-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:41:31.148: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-35194a7b-fb0a-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 11:41:31.207: INFO: Waiting for pod pod-35194a7b-fb0a-11e9-91af-623cf93d857c to disappear
Oct 30 11:41:31.215: INFO: Pod pod-35194a7b-fb0a-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:41:31.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4186" for this suite.
Oct 30 11:41:37.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:41:37.519: INFO: namespace emptydir-4186 deletion completed in 6.289936852s

â€¢ [SLOW TEST:10.544 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:41:37.520: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Oct 30 11:41:37.656: INFO: Waiting up to 5m0s for pod "pod-3b622f0e-fb0a-11e9-91af-623cf93d857c" in namespace "emptydir-2099" to be "success or failure"
Oct 30 11:41:37.670: INFO: Pod "pod-3b622f0e-fb0a-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.697066ms
Oct 30 11:41:39.679: INFO: Pod "pod-3b622f0e-fb0a-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022800446s
Oct 30 11:41:41.687: INFO: Pod "pod-3b622f0e-fb0a-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030669783s
STEP: Saw pod success
Oct 30 11:41:41.687: INFO: Pod "pod-3b622f0e-fb0a-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:41:41.695: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-3b622f0e-fb0a-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 11:41:41.754: INFO: Waiting for pod pod-3b622f0e-fb0a-11e9-91af-623cf93d857c to disappear
Oct 30 11:41:41.768: INFO: Pod pod-3b622f0e-fb0a-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:41:41.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2099" for this suite.
Oct 30 11:41:47.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:41:48.108: INFO: namespace emptydir-2099 deletion completed in 6.331743396s

â€¢ [SLOW TEST:10.588 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:41:48.112: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:41:48.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1250" for this suite.
Oct 30 11:42:10.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:42:10.663: INFO: namespace pods-1250 deletion completed in 22.369676958s

â€¢ [SLOW TEST:22.551 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:42:10.665: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-4f257693-fb0a-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume secrets
Oct 30 11:42:10.800: INFO: Waiting up to 5m0s for pod "pod-secrets-4f27e05b-fb0a-11e9-91af-623cf93d857c" in namespace "secrets-5365" to be "success or failure"
Oct 30 11:42:10.833: INFO: Pod "pod-secrets-4f27e05b-fb0a-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 32.347723ms
Oct 30 11:42:12.843: INFO: Pod "pod-secrets-4f27e05b-fb0a-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042135248s
Oct 30 11:42:14.851: INFO: Pod "pod-secrets-4f27e05b-fb0a-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0506115s
STEP: Saw pod success
Oct 30 11:42:14.852: INFO: Pod "pod-secrets-4f27e05b-fb0a-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:42:14.859: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-secrets-4f27e05b-fb0a-11e9-91af-623cf93d857c container secret-volume-test: <nil>
STEP: delete the pod
Oct 30 11:42:14.941: INFO: Waiting for pod pod-secrets-4f27e05b-fb0a-11e9-91af-623cf93d857c to disappear
Oct 30 11:42:14.968: INFO: Pod pod-secrets-4f27e05b-fb0a-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:42:14.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5365" for this suite.
Oct 30 11:42:21.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:42:21.305: INFO: namespace secrets-5365 deletion completed in 6.324737599s

â€¢ [SLOW TEST:10.640 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:42:21.307: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 11:42:21.500: INFO: Create a RollingUpdate DaemonSet
Oct 30 11:42:21.522: INFO: Check that daemon pods launch on every node of the cluster
Oct 30 11:42:21.541: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:21.542: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:21.542: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:21.550: INFO: Number of nodes with available pods: 0
Oct 30 11:42:21.550: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 11:42:22.560: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:22.561: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:22.561: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:22.567: INFO: Number of nodes with available pods: 0
Oct 30 11:42:22.567: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 11:42:23.561: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:23.561: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:23.562: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:23.572: INFO: Number of nodes with available pods: 0
Oct 30 11:42:23.572: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 11:42:24.565: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:24.565: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:24.565: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:24.572: INFO: Number of nodes with available pods: 2
Oct 30 11:42:24.572: INFO: Node koris-pipeline-56683fb-92514359-node-2 is running more than one daemon pod
Oct 30 11:42:25.563: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:25.563: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:25.563: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:25.583: INFO: Number of nodes with available pods: 2
Oct 30 11:42:25.583: INFO: Node koris-pipeline-56683fb-92514359-node-2 is running more than one daemon pod
Oct 30 11:42:26.561: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:26.562: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:26.562: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:26.568: INFO: Number of nodes with available pods: 2
Oct 30 11:42:26.568: INFO: Node koris-pipeline-56683fb-92514359-node-2 is running more than one daemon pod
Oct 30 11:42:27.561: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:27.561: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:27.561: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:27.569: INFO: Number of nodes with available pods: 3
Oct 30 11:42:27.569: INFO: Number of running nodes: 3, number of available pods: 3
Oct 30 11:42:27.569: INFO: Update the DaemonSet to trigger a rollout
Oct 30 11:42:27.602: INFO: Updating DaemonSet daemon-set
Oct 30 11:42:31.641: INFO: Roll back the DaemonSet before rollout is complete
Oct 30 11:42:31.668: INFO: Updating DaemonSet daemon-set
Oct 30 11:42:31.668: INFO: Make sure DaemonSet rollback is complete
Oct 30 11:42:31.679: INFO: Wrong image for pod: daemon-set-rq5l9. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 30 11:42:31.679: INFO: Pod daemon-set-rq5l9 is not available
Oct 30 11:42:31.695: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:31.695: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:31.695: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:32.715: INFO: Wrong image for pod: daemon-set-rq5l9. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 30 11:42:32.715: INFO: Pod daemon-set-rq5l9 is not available
Oct 30 11:42:32.725: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:32.725: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:32.725: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:33.705: INFO: Pod daemon-set-wd8k7 is not available
Oct 30 11:42:33.714: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:33.714: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:42:33.715: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4986, will wait for the garbage collector to delete the pods
Oct 30 11:42:33.819: INFO: Deleting DaemonSet.extensions daemon-set took: 30.351423ms
Oct 30 11:42:34.220: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.356288ms
Oct 30 11:42:42.828: INFO: Number of nodes with available pods: 0
Oct 30 11:42:42.828: INFO: Number of running nodes: 0, number of available pods: 0
Oct 30 11:42:42.840: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4986/daemonsets","resourceVersion":"9869"},"items":null}

Oct 30 11:42:42.847: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4986/pods","resourceVersion":"9869"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:42:42.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4986" for this suite.
Oct 30 11:42:48.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:42:49.191: INFO: namespace daemonsets-4986 deletion completed in 6.300364764s

â€¢ [SLOW TEST:27.884 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:42:49.194: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 11:42:49.278: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct 30 11:42:49.335: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 30 11:42:53.362: INFO: Creating deployment "test-rolling-update-deployment"
Oct 30 11:42:53.377: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct 30 11:42:53.415: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
Oct 30 11:42:55.433: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct 30 11:42:55.440: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708032573, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708032573, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708032573, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708032573, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-57b6b5bb54\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 11:42:57.450: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708032573, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708032573, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708032573, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708032573, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-57b6b5bb54\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 11:42:59.448: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 30 11:42:59.468: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-8370,SelfLink:/apis/apps/v1/namespaces/deployment-8370/deployments/test-rolling-update-deployment,UID:6889f8d3-fb0a-11e9-a053-fa163e61542c,ResourceVersion:9993,Generation:1,CreationTimestamp:2019-10-30 11:42:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-30 11:42:53 +0000 UTC 2019-10-30 11:42:53 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-30 11:42:57 +0000 UTC 2019-10-30 11:42:53 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-57b6b5bb54" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 30 11:42:59.478: INFO: New ReplicaSet "test-rolling-update-deployment-57b6b5bb54" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54,GenerateName:,Namespace:deployment-8370,SelfLink:/apis/apps/v1/namespaces/deployment-8370/replicasets/test-rolling-update-deployment-57b6b5bb54,UID:688fc555-fb0a-11e9-ad48-fa163ee0935a,ResourceVersion:9983,Generation:1,CreationTimestamp:2019-10-30 11:42:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 6889f8d3-fb0a-11e9-a053-fa163e61542c 0xc00215f2a7 0xc00215f2a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 30 11:42:59.478: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct 30 11:42:59.478: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-8370,SelfLink:/apis/apps/v1/namespaces/deployment-8370/replicasets/test-rolling-update-controller,UID:661bb95b-fb0a-11e9-a053-fa163e61542c,ResourceVersion:9992,Generation:2,CreationTimestamp:2019-10-30 11:42:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 6889f8d3-fb0a-11e9-a053-fa163e61542c 0xc00215f1cf 0xc00215f1e0}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 30 11:42:59.484: INFO: Pod "test-rolling-update-deployment-57b6b5bb54-hc6ds" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54-hc6ds,GenerateName:test-rolling-update-deployment-57b6b5bb54-,Namespace:deployment-8370,SelfLink:/api/v1/namespaces/deployment-8370/pods/test-rolling-update-deployment-57b6b5bb54-hc6ds,UID:6891b929-fb0a-11e9-ad48-fa163ee0935a,ResourceVersion:9982,Generation:0,CreationTimestamp:2019-10-30 11:42:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.5.33/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-57b6b5bb54 688fc555-fb0a-11e9-ad48-fa163ee0935a 0xc00215fb77 0xc00215fb78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pmq65 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pmq65,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-pmq65 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00215fbe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00215fc00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:42:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:42:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:42:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:42:53 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.32,PodIP:10.233.5.33,StartTime:2019-10-30 11:42:53 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-30 11:42:56 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://99f5e319e599e30742d305575d6e2996473c82810e17287a21d221ae23426f9e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:42:59.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8370" for this suite.
Oct 30 11:43:05.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:43:05.830: INFO: namespace deployment-8370 deletion completed in 6.336263228s

â€¢ [SLOW TEST:16.636 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:43:05.832: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-8676
Oct 30 11:43:11.983: INFO: Started pod liveness-http in namespace container-probe-8676
STEP: checking the pod's current state and verifying that restartCount is present
Oct 30 11:43:11.990: INFO: Initial restart count of pod liveness-http is 0
Oct 30 11:43:26.073: INFO: Restart count of pod container-probe-8676/liveness-http is now 1 (14.083341741s elapsed)
Oct 30 11:43:46.198: INFO: Restart count of pod container-probe-8676/liveness-http is now 2 (34.207836768s elapsed)
Oct 30 11:44:06.301: INFO: Restart count of pod container-probe-8676/liveness-http is now 3 (54.310937572s elapsed)
Oct 30 11:44:26.409: INFO: Restart count of pod container-probe-8676/liveness-http is now 4 (1m14.419443892s elapsed)
Oct 30 11:45:26.712: INFO: Restart count of pod container-probe-8676/liveness-http is now 5 (2m14.721615487s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:45:26.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8676" for this suite.
Oct 30 11:45:32.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:45:33.109: INFO: namespace container-probe-8676 deletion completed in 6.318205874s

â€¢ [SLOW TEST:147.277 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:45:33.110: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:45:38.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1860" for this suite.
Oct 30 11:46:00.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:46:00.798: INFO: namespace replication-controller-1860 deletion completed in 22.474322795s

â€¢ [SLOW TEST:27.688 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:46:00.801: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Oct 30 11:46:06.002: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:46:07.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9303" for this suite.
Oct 30 11:46:31.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:46:31.346: INFO: namespace replicaset-9303 deletion completed in 24.286583835s

â€¢ [SLOW TEST:30.545 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:46:31.346: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Oct 30 11:46:31.494: INFO: Waiting up to 5m0s for pod "client-containers-ea87f8d5-fb0a-11e9-91af-623cf93d857c" in namespace "containers-6043" to be "success or failure"
Oct 30 11:46:31.503: INFO: Pod "client-containers-ea87f8d5-fb0a-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.581797ms
Oct 30 11:46:33.512: INFO: Pod "client-containers-ea87f8d5-fb0a-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017303367s
Oct 30 11:46:35.521: INFO: Pod "client-containers-ea87f8d5-fb0a-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026552138s
STEP: Saw pod success
Oct 30 11:46:35.521: INFO: Pod "client-containers-ea87f8d5-fb0a-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:46:35.541: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod client-containers-ea87f8d5-fb0a-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 11:46:35.604: INFO: Waiting for pod client-containers-ea87f8d5-fb0a-11e9-91af-623cf93d857c to disappear
Oct 30 11:46:35.612: INFO: Pod client-containers-ea87f8d5-fb0a-11e9-91af-623cf93d857c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:46:35.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6043" for this suite.
Oct 30 11:46:41.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:46:41.944: INFO: namespace containers-6043 deletion completed in 6.315484079s

â€¢ [SLOW TEST:10.598 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:46:41.946: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-5849
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-5849
STEP: Creating statefulset with conflicting port in namespace statefulset-5849
STEP: Waiting until pod test-pod will start running in namespace statefulset-5849
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-5849
Oct 30 11:46:46.159: INFO: Observed stateful pod in namespace: statefulset-5849, name: ss-0, uid: f30c31b8-fb0a-11e9-ad48-fa163ee0935a, status phase: Pending. Waiting for statefulset controller to delete.
Oct 30 11:46:46.314: INFO: Observed stateful pod in namespace: statefulset-5849, name: ss-0, uid: f30c31b8-fb0a-11e9-ad48-fa163ee0935a, status phase: Failed. Waiting for statefulset controller to delete.
Oct 30 11:46:46.327: INFO: Observed stateful pod in namespace: statefulset-5849, name: ss-0, uid: f30c31b8-fb0a-11e9-ad48-fa163ee0935a, status phase: Failed. Waiting for statefulset controller to delete.
Oct 30 11:46:46.337: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-5849
STEP: Removing pod with conflicting port in namespace statefulset-5849
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-5849 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 30 11:46:50.432: INFO: Deleting all statefulset in ns statefulset-5849
Oct 30 11:46:50.439: INFO: Scaling statefulset ss to 0
Oct 30 11:47:00.493: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 11:47:00.501: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:47:00.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5849" for this suite.
Oct 30 11:47:06.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:47:06.858: INFO: namespace statefulset-5849 deletion completed in 6.30421227s

â€¢ [SLOW TEST:24.912 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:47:06.862: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:47:06.984: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ffb08560-fb0a-11e9-91af-623cf93d857c" in namespace "projected-4674" to be "success or failure"
Oct 30 11:47:06.996: INFO: Pod "downwardapi-volume-ffb08560-fb0a-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.416531ms
Oct 30 11:47:09.007: INFO: Pod "downwardapi-volume-ffb08560-fb0a-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023099206s
Oct 30 11:47:11.017: INFO: Pod "downwardapi-volume-ffb08560-fb0a-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033274569s
STEP: Saw pod success
Oct 30 11:47:11.017: INFO: Pod "downwardapi-volume-ffb08560-fb0a-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:47:11.024: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod downwardapi-volume-ffb08560-fb0a-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 11:47:11.090: INFO: Waiting for pod downwardapi-volume-ffb08560-fb0a-11e9-91af-623cf93d857c to disappear
Oct 30 11:47:11.103: INFO: Pod downwardapi-volume-ffb08560-fb0a-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:47:11.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4674" for this suite.
Oct 30 11:47:17.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:47:17.443: INFO: namespace projected-4674 deletion completed in 6.327163789s

â€¢ [SLOW TEST:10.581 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:47:17.446: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-05fe4a0e-fb0b-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume secrets
Oct 30 11:47:17.566: INFO: Waiting up to 5m0s for pod "pod-secrets-060151bf-fb0b-11e9-91af-623cf93d857c" in namespace "secrets-5067" to be "success or failure"
Oct 30 11:47:17.578: INFO: Pod "pod-secrets-060151bf-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.19102ms
Oct 30 11:47:19.588: INFO: Pod "pod-secrets-060151bf-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022431607s
Oct 30 11:47:21.597: INFO: Pod "pod-secrets-060151bf-fb0b-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030942771s
STEP: Saw pod success
Oct 30 11:47:21.597: INFO: Pod "pod-secrets-060151bf-fb0b-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:47:21.604: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-secrets-060151bf-fb0b-11e9-91af-623cf93d857c container secret-env-test: <nil>
STEP: delete the pod
Oct 30 11:47:21.680: INFO: Waiting for pod pod-secrets-060151bf-fb0b-11e9-91af-623cf93d857c to disappear
Oct 30 11:47:21.686: INFO: Pod pod-secrets-060151bf-fb0b-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:47:21.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5067" for this suite.
Oct 30 11:47:27.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:47:27.996: INFO: namespace secrets-5067 deletion completed in 6.299319937s

â€¢ [SLOW TEST:10.551 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:47:28.000: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-1632/secret-test-0c491d25-fb0b-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume secrets
Oct 30 11:47:28.136: INFO: Waiting up to 5m0s for pod "pod-configmaps-0c4d0716-fb0b-11e9-91af-623cf93d857c" in namespace "secrets-1632" to be "success or failure"
Oct 30 11:47:28.144: INFO: Pod "pod-configmaps-0c4d0716-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.380677ms
Oct 30 11:47:30.154: INFO: Pod "pod-configmaps-0c4d0716-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018479791s
Oct 30 11:47:32.165: INFO: Pod "pod-configmaps-0c4d0716-fb0b-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029399378s
STEP: Saw pod success
Oct 30 11:47:32.166: INFO: Pod "pod-configmaps-0c4d0716-fb0b-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:47:32.174: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-configmaps-0c4d0716-fb0b-11e9-91af-623cf93d857c container env-test: <nil>
STEP: delete the pod
Oct 30 11:47:32.274: INFO: Waiting for pod pod-configmaps-0c4d0716-fb0b-11e9-91af-623cf93d857c to disappear
Oct 30 11:47:32.282: INFO: Pod pod-configmaps-0c4d0716-fb0b-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:47:32.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1632" for this suite.
Oct 30 11:47:38.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:47:38.684: INFO: namespace secrets-1632 deletion completed in 6.390035144s

â€¢ [SLOW TEST:10.684 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:47:38.685: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-12ab3603-fb0b-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume configMaps
Oct 30 11:47:38.834: INFO: Waiting up to 5m0s for pod "pod-configmaps-12ae50f1-fb0b-11e9-91af-623cf93d857c" in namespace "configmap-5448" to be "success or failure"
Oct 30 11:47:38.847: INFO: Pod "pod-configmaps-12ae50f1-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.852567ms
Oct 30 11:47:40.856: INFO: Pod "pod-configmaps-12ae50f1-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02181279s
Oct 30 11:47:42.867: INFO: Pod "pod-configmaps-12ae50f1-fb0b-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032705669s
STEP: Saw pod success
Oct 30 11:47:42.867: INFO: Pod "pod-configmaps-12ae50f1-fb0b-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:47:42.875: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-configmaps-12ae50f1-fb0b-11e9-91af-623cf93d857c container configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 11:47:42.935: INFO: Waiting for pod pod-configmaps-12ae50f1-fb0b-11e9-91af-623cf93d857c to disappear
Oct 30 11:47:42.942: INFO: Pod pod-configmaps-12ae50f1-fb0b-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:47:42.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5448" for this suite.
Oct 30 11:47:48.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:47:49.257: INFO: namespace configmap-5448 deletion completed in 6.302534839s

â€¢ [SLOW TEST:10.572 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:47:49.258: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:47:49.387: INFO: Waiting up to 5m0s for pod "downwardapi-volume-18f5b7af-fb0b-11e9-91af-623cf93d857c" in namespace "downward-api-4386" to be "success or failure"
Oct 30 11:47:49.404: INFO: Pod "downwardapi-volume-18f5b7af-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.353275ms
Oct 30 11:47:51.423: INFO: Pod "downwardapi-volume-18f5b7af-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036042677s
Oct 30 11:47:53.433: INFO: Pod "downwardapi-volume-18f5b7af-fb0b-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045404636s
STEP: Saw pod success
Oct 30 11:47:53.433: INFO: Pod "downwardapi-volume-18f5b7af-fb0b-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:47:53.440: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod downwardapi-volume-18f5b7af-fb0b-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 11:47:53.499: INFO: Waiting for pod downwardapi-volume-18f5b7af-fb0b-11e9-91af-623cf93d857c to disappear
Oct 30 11:47:53.504: INFO: Pod downwardapi-volume-18f5b7af-fb0b-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:47:53.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4386" for this suite.
Oct 30 11:47:59.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:47:59.808: INFO: namespace downward-api-4386 deletion completed in 6.295240529s

â€¢ [SLOW TEST:10.550 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:47:59.809: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:47:59.919: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1f3f37d5-fb0b-11e9-91af-623cf93d857c" in namespace "downward-api-4268" to be "success or failure"
Oct 30 11:47:59.934: INFO: Pod "downwardapi-volume-1f3f37d5-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.888582ms
Oct 30 11:48:01.944: INFO: Pod "downwardapi-volume-1f3f37d5-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024975147s
Oct 30 11:48:03.953: INFO: Pod "downwardapi-volume-1f3f37d5-fb0b-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033155336s
STEP: Saw pod success
Oct 30 11:48:03.953: INFO: Pod "downwardapi-volume-1f3f37d5-fb0b-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:48:03.965: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod downwardapi-volume-1f3f37d5-fb0b-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 11:48:04.073: INFO: Waiting for pod downwardapi-volume-1f3f37d5-fb0b-11e9-91af-623cf93d857c to disappear
Oct 30 11:48:04.080: INFO: Pod downwardapi-volume-1f3f37d5-fb0b-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:48:04.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4268" for this suite.
Oct 30 11:48:10.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:48:10.398: INFO: namespace downward-api-4268 deletion completed in 6.307073398s

â€¢ [SLOW TEST:10.589 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:48:10.399: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-2591484f-fb0b-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume configMaps
Oct 30 11:48:10.557: INFO: Waiting up to 5m0s for pod "pod-configmaps-25947571-fb0b-11e9-91af-623cf93d857c" in namespace "configmap-8345" to be "success or failure"
Oct 30 11:48:10.572: INFO: Pod "pod-configmaps-25947571-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.700972ms
Oct 30 11:48:12.580: INFO: Pod "pod-configmaps-25947571-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022410633s
Oct 30 11:48:14.590: INFO: Pod "pod-configmaps-25947571-fb0b-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032592165s
STEP: Saw pod success
Oct 30 11:48:14.590: INFO: Pod "pod-configmaps-25947571-fb0b-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:48:14.597: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-configmaps-25947571-fb0b-11e9-91af-623cf93d857c container configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 11:48:14.655: INFO: Waiting for pod pod-configmaps-25947571-fb0b-11e9-91af-623cf93d857c to disappear
Oct 30 11:48:14.662: INFO: Pod pod-configmaps-25947571-fb0b-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:48:14.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8345" for this suite.
Oct 30 11:48:20.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:48:21.002: INFO: namespace configmap-8345 deletion completed in 6.330403906s

â€¢ [SLOW TEST:10.603 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:48:21.002: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 30 11:48:29.352: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 30 11:48:29.372: INFO: Pod pod-with-poststart-http-hook still exists
Oct 30 11:48:31.372: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 30 11:48:31.382: INFO: Pod pod-with-poststart-http-hook still exists
Oct 30 11:48:33.372: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 30 11:48:33.381: INFO: Pod pod-with-poststart-http-hook still exists
Oct 30 11:48:35.372: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 30 11:48:35.381: INFO: Pod pod-with-poststart-http-hook still exists
Oct 30 11:48:37.372: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 30 11:48:37.382: INFO: Pod pod-with-poststart-http-hook still exists
Oct 30 11:48:39.372: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 30 11:48:39.380: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:48:39.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9021" for this suite.
Oct 30 11:49:03.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:49:03.718: INFO: namespace container-lifecycle-hook-9021 deletion completed in 24.324810966s

â€¢ [SLOW TEST:42.716 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:49:03.720: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Oct 30 11:49:03.935: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1594,SelfLink:/api/v1/namespaces/watch-1594/configmaps/e2e-watch-test-watch-closed,UID:455a99f1-fb0b-11e9-a053-fa163e61542c,ResourceVersion:11517,Generation:0,CreationTimestamp:2019-10-30 11:49:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 30 11:49:03.936: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1594,SelfLink:/api/v1/namespaces/watch-1594/configmaps/e2e-watch-test-watch-closed,UID:455a99f1-fb0b-11e9-a053-fa163e61542c,ResourceVersion:11518,Generation:0,CreationTimestamp:2019-10-30 11:49:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Oct 30 11:49:03.999: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1594,SelfLink:/api/v1/namespaces/watch-1594/configmaps/e2e-watch-test-watch-closed,UID:455a99f1-fb0b-11e9-a053-fa163e61542c,ResourceVersion:11519,Generation:0,CreationTimestamp:2019-10-30 11:49:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 30 11:49:03.999: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1594,SelfLink:/api/v1/namespaces/watch-1594/configmaps/e2e-watch-test-watch-closed,UID:455a99f1-fb0b-11e9-a053-fa163e61542c,ResourceVersion:11520,Generation:0,CreationTimestamp:2019-10-30 11:49:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:49:03.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1594" for this suite.
Oct 30 11:49:10.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:49:10.345: INFO: namespace watch-1594 deletion completed in 6.33219299s

â€¢ [SLOW TEST:6.625 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:49:10.348: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct 30 11:49:10.450: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:49:16.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4350" for this suite.
Oct 30 11:49:40.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:49:40.471: INFO: namespace init-container-4350 deletion completed in 24.334233617s

â€¢ [SLOW TEST:30.123 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:49:40.472: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Oct 30 11:49:44.629: INFO: Pod pod-hostip-5b3ef160-fb0b-11e9-91af-623cf93d857c has hostIP: 10.0.0.39
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:49:44.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8957" for this suite.
Oct 30 11:50:08.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:50:08.967: INFO: namespace pods-8957 deletion completed in 24.327484184s

â€¢ [SLOW TEST:28.495 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:50:08.967: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 30 11:50:09.082: INFO: Waiting up to 5m0s for pod "pod-6c3a6050-fb0b-11e9-91af-623cf93d857c" in namespace "emptydir-4396" to be "success or failure"
Oct 30 11:50:09.095: INFO: Pod "pod-6c3a6050-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.739301ms
Oct 30 11:50:11.105: INFO: Pod "pod-6c3a6050-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022954039s
Oct 30 11:50:13.114: INFO: Pod "pod-6c3a6050-fb0b-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031364971s
STEP: Saw pod success
Oct 30 11:50:13.114: INFO: Pod "pod-6c3a6050-fb0b-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:50:13.120: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-6c3a6050-fb0b-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 11:50:13.185: INFO: Waiting for pod pod-6c3a6050-fb0b-11e9-91af-623cf93d857c to disappear
Oct 30 11:50:13.217: INFO: Pod pod-6c3a6050-fb0b-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:50:13.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4396" for this suite.
Oct 30 11:50:19.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:50:19.548: INFO: namespace emptydir-4396 deletion completed in 6.305521839s

â€¢ [SLOW TEST:10.581 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:50:19.552: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct 30 11:50:19.644: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 30 11:50:19.680: INFO: Waiting for terminating namespaces to be deleted...
Oct 30 11:50:19.686: INFO: 
Logging pods the kubelet thinks is on node koris-pipeline-56683fb-92514359-node-1 before test
Oct 30 11:50:19.699: INFO: kube-proxy-246h7 from kube-system started at 2019-10-30 11:07:20 +0000 UTC (1 container statuses recorded)
Oct 30 11:50:19.700: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 30 11:50:19.700: INFO: calico-node-mt5gd from kube-system started at 2019-10-30 11:07:21 +0000 UTC (2 container statuses recorded)
Oct 30 11:50:19.700: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 11:50:19.700: INFO: 	Container install-cni ready: true, restart count 0
Oct 30 11:50:19.700: INFO: nginx-blue-7f86974c47-f726v from default started at 2019-10-30 11:08:16 +0000 UTC (1 container statuses recorded)
Oct 30 11:50:19.700: INFO: 	Container nginx ready: true, restart count 0
Oct 30 11:50:19.700: INFO: sonobuoy-e2e-job-18cfb8e951354e9a from sonobuoy started at 2019-10-30 11:23:03 +0000 UTC (2 container statuses recorded)
Oct 30 11:50:19.700: INFO: 	Container e2e ready: true, restart count 0
Oct 30 11:50:19.700: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 11:50:19.700: INFO: sonobuoy-systemd-logs-daemon-set-aac87c55e38d426f-w56kw from sonobuoy started at 2019-10-30 11:23:03 +0000 UTC (2 container statuses recorded)
Oct 30 11:50:19.700: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 11:50:19.700: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 11:50:19.700: INFO: 
Logging pods the kubelet thinks is on node koris-pipeline-56683fb-92514359-node-2 before test
Oct 30 11:50:19.721: INFO: kube-proxy-sms4r from kube-system started at 2019-10-30 11:06:15 +0000 UTC (1 container statuses recorded)
Oct 30 11:50:19.721: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 30 11:50:19.721: INFO: calico-node-cwjt4 from kube-system started at 2019-10-30 11:06:15 +0000 UTC (2 container statuses recorded)
Oct 30 11:50:19.721: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 11:50:19.721: INFO: 	Container install-cni ready: true, restart count 0
Oct 30 11:50:19.721: INFO: dnscheck from default started at 2019-10-30 11:06:35 +0000 UTC (1 container statuses recorded)
Oct 30 11:50:19.721: INFO: 	Container dnscheck ready: true, restart count 0
Oct 30 11:50:19.721: INFO: external-http-nginx-deployment-56db997f77-klncq from default started at 2019-10-30 11:06:35 +0000 UTC (1 container statuses recorded)
Oct 30 11:50:19.721: INFO: 	Container nginx ready: true, restart count 0
Oct 30 11:50:19.721: INFO: external-http-nginx-deployment-56db997f77-jsv9j from default started at 2019-10-30 11:06:35 +0000 UTC (1 container statuses recorded)
Oct 30 11:50:19.721: INFO: 	Container nginx ready: true, restart count 0
Oct 30 11:50:19.721: INFO: nginx-ingress-controller-6cfd5b6544-pzmdd from ingress-nginx started at 2019-10-30 11:06:36 +0000 UTC (1 container statuses recorded)
Oct 30 11:50:19.721: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 30 11:50:19.721: INFO: metrics-server-5845cc8fd4-w8vxn from kube-system started at 2019-10-30 11:06:35 +0000 UTC (1 container statuses recorded)
Oct 30 11:50:19.721: INFO: 	Container metrics-server ready: true, restart count 0
Oct 30 11:50:19.721: INFO: sonobuoy-systemd-logs-daemon-set-aac87c55e38d426f-vrllw from sonobuoy started at 2019-10-30 11:23:04 +0000 UTC (2 container statuses recorded)
Oct 30 11:50:19.721: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 11:50:19.721: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 11:50:19.721: INFO: 
Logging pods the kubelet thinks is on node koris-pipeline-56683fb-92514359-node-3 before test
Oct 30 11:50:19.738: INFO: kube-proxy-ds6hw from kube-system started at 2019-10-30 11:07:23 +0000 UTC (1 container statuses recorded)
Oct 30 11:50:19.738: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 30 11:50:19.738: INFO: nginx-green-56c79bbc4d-z8m7q from default started at 2019-10-30 11:08:16 +0000 UTC (1 container statuses recorded)
Oct 30 11:50:19.738: INFO: 	Container nginx ready: true, restart count 0
Oct 30 11:50:19.738: INFO: sonobuoy from sonobuoy started at 2019-10-30 11:22:56 +0000 UTC (1 container statuses recorded)
Oct 30 11:50:19.738: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 30 11:50:19.738: INFO: sonobuoy-systemd-logs-daemon-set-aac87c55e38d426f-4ckdm from sonobuoy started at 2019-10-30 11:23:04 +0000 UTC (2 container statuses recorded)
Oct 30 11:50:19.738: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 11:50:19.738: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 11:50:19.738: INFO: calico-node-h9krs from kube-system started at 2019-10-30 11:07:23 +0000 UTC (2 container statuses recorded)
Oct 30 11:50:19.738: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 11:50:19.739: INFO: 	Container install-cni ready: true, restart count 0
Oct 30 11:50:19.739: INFO: kube-bench-node from default started at 2019-10-30 11:21:56 +0000 UTC (1 container statuses recorded)
Oct 30 11:50:19.739: INFO: 	Container kube-bench-node ready: false, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node koris-pipeline-56683fb-92514359-node-1
STEP: verifying the node has the label node koris-pipeline-56683fb-92514359-node-2
STEP: verifying the node has the label node koris-pipeline-56683fb-92514359-node-3
Oct 30 11:50:19.918: INFO: Pod dnscheck requesting resource cpu=0m on Node koris-pipeline-56683fb-92514359-node-2
Oct 30 11:50:19.918: INFO: Pod external-http-nginx-deployment-56db997f77-jsv9j requesting resource cpu=0m on Node koris-pipeline-56683fb-92514359-node-2
Oct 30 11:50:19.918: INFO: Pod external-http-nginx-deployment-56db997f77-klncq requesting resource cpu=0m on Node koris-pipeline-56683fb-92514359-node-2
Oct 30 11:50:19.918: INFO: Pod nginx-blue-7f86974c47-f726v requesting resource cpu=0m on Node koris-pipeline-56683fb-92514359-node-1
Oct 30 11:50:19.918: INFO: Pod nginx-green-56c79bbc4d-z8m7q requesting resource cpu=0m on Node koris-pipeline-56683fb-92514359-node-3
Oct 30 11:50:19.919: INFO: Pod nginx-ingress-controller-6cfd5b6544-pzmdd requesting resource cpu=0m on Node koris-pipeline-56683fb-92514359-node-2
Oct 30 11:50:19.919: INFO: Pod calico-node-cwjt4 requesting resource cpu=250m on Node koris-pipeline-56683fb-92514359-node-2
Oct 30 11:50:19.919: INFO: Pod calico-node-h9krs requesting resource cpu=250m on Node koris-pipeline-56683fb-92514359-node-3
Oct 30 11:50:19.919: INFO: Pod calico-node-mt5gd requesting resource cpu=250m on Node koris-pipeline-56683fb-92514359-node-1
Oct 30 11:50:19.919: INFO: Pod kube-proxy-246h7 requesting resource cpu=0m on Node koris-pipeline-56683fb-92514359-node-1
Oct 30 11:50:19.919: INFO: Pod kube-proxy-ds6hw requesting resource cpu=0m on Node koris-pipeline-56683fb-92514359-node-3
Oct 30 11:50:19.919: INFO: Pod kube-proxy-sms4r requesting resource cpu=0m on Node koris-pipeline-56683fb-92514359-node-2
Oct 30 11:50:19.920: INFO: Pod metrics-server-5845cc8fd4-w8vxn requesting resource cpu=0m on Node koris-pipeline-56683fb-92514359-node-2
Oct 30 11:50:19.920: INFO: Pod sonobuoy requesting resource cpu=0m on Node koris-pipeline-56683fb-92514359-node-3
Oct 30 11:50:19.920: INFO: Pod sonobuoy-e2e-job-18cfb8e951354e9a requesting resource cpu=0m on Node koris-pipeline-56683fb-92514359-node-1
Oct 30 11:50:19.920: INFO: Pod sonobuoy-systemd-logs-daemon-set-aac87c55e38d426f-4ckdm requesting resource cpu=0m on Node koris-pipeline-56683fb-92514359-node-3
Oct 30 11:50:19.920: INFO: Pod sonobuoy-systemd-logs-daemon-set-aac87c55e38d426f-vrllw requesting resource cpu=0m on Node koris-pipeline-56683fb-92514359-node-2
Oct 30 11:50:19.920: INFO: Pod sonobuoy-systemd-logs-daemon-set-aac87c55e38d426f-w56kw requesting resource cpu=0m on Node koris-pipeline-56683fb-92514359-node-1
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72b566c1-fb0b-11e9-91af-623cf93d857c.15d26a6933ca0290], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5777/filler-pod-72b566c1-fb0b-11e9-91af-623cf93d857c to koris-pipeline-56683fb-92514359-node-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72b566c1-fb0b-11e9-91af-623cf93d857c.15d26a697d8ea466], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72b566c1-fb0b-11e9-91af-623cf93d857c.15d26a6986171928], Reason = [Created], Message = [Created container filler-pod-72b566c1-fb0b-11e9-91af-623cf93d857c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72b566c1-fb0b-11e9-91af-623cf93d857c.15d26a699353f957], Reason = [Started], Message = [Started container filler-pod-72b566c1-fb0b-11e9-91af-623cf93d857c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72ba4018-fb0b-11e9-91af-623cf93d857c.15d26a6933e34d87], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5777/filler-pod-72ba4018-fb0b-11e9-91af-623cf93d857c to koris-pipeline-56683fb-92514359-node-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72ba4018-fb0b-11e9-91af-623cf93d857c.15d26a6982319c9c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72ba4018-fb0b-11e9-91af-623cf93d857c.15d26a698cb08727], Reason = [Created], Message = [Created container filler-pod-72ba4018-fb0b-11e9-91af-623cf93d857c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72ba4018-fb0b-11e9-91af-623cf93d857c.15d26a699985a498], Reason = [Started], Message = [Started container filler-pod-72ba4018-fb0b-11e9-91af-623cf93d857c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72bd6497-fb0b-11e9-91af-623cf93d857c.15d26a6935df1a20], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5777/filler-pod-72bd6497-fb0b-11e9-91af-623cf93d857c to koris-pipeline-56683fb-92514359-node-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72bd6497-fb0b-11e9-91af-623cf93d857c.15d26a6985504899], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72bd6497-fb0b-11e9-91af-623cf93d857c.15d26a698ceab246], Reason = [Created], Message = [Created container filler-pod-72bd6497-fb0b-11e9-91af-623cf93d857c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72bd6497-fb0b-11e9-91af-623cf93d857c.15d26a699a4ae289], Reason = [Started], Message = [Started container filler-pod-72bd6497-fb0b-11e9-91af-623cf93d857c]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15d26a6a27b8332c], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 Insufficient cpu.]
STEP: removing the label node off the node koris-pipeline-56683fb-92514359-node-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node koris-pipeline-56683fb-92514359-node-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node koris-pipeline-56683fb-92514359-node-3
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:50:25.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5777" for this suite.
Oct 30 11:50:31.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:50:31.647: INFO: namespace sched-pred-5777 deletion completed in 6.38805968s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:12.096 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:50:31.648: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:50:31.796: INFO: Waiting up to 5m0s for pod "downwardapi-volume-79c30600-fb0b-11e9-91af-623cf93d857c" in namespace "projected-1689" to be "success or failure"
Oct 30 11:50:31.814: INFO: Pod "downwardapi-volume-79c30600-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 18.641046ms
Oct 30 11:50:33.826: INFO: Pod "downwardapi-volume-79c30600-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030249036s
Oct 30 11:50:35.837: INFO: Pod "downwardapi-volume-79c30600-fb0b-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040957489s
STEP: Saw pod success
Oct 30 11:50:35.837: INFO: Pod "downwardapi-volume-79c30600-fb0b-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:50:35.846: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod downwardapi-volume-79c30600-fb0b-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 11:50:35.917: INFO: Waiting for pod downwardapi-volume-79c30600-fb0b-11e9-91af-623cf93d857c to disappear
Oct 30 11:50:35.923: INFO: Pod downwardapi-volume-79c30600-fb0b-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:50:35.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1689" for this suite.
Oct 30 11:50:41.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:50:42.251: INFO: namespace projected-1689 deletion completed in 6.31516928s

â€¢ [SLOW TEST:10.604 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:50:42.252: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:50:42.377: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8012d329-fb0b-11e9-91af-623cf93d857c" in namespace "projected-3637" to be "success or failure"
Oct 30 11:50:42.394: INFO: Pod "downwardapi-volume-8012d329-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.471156ms
Oct 30 11:50:44.403: INFO: Pod "downwardapi-volume-8012d329-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026706745s
Oct 30 11:50:46.414: INFO: Pod "downwardapi-volume-8012d329-fb0b-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037807242s
STEP: Saw pod success
Oct 30 11:50:46.415: INFO: Pod "downwardapi-volume-8012d329-fb0b-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:50:46.423: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod downwardapi-volume-8012d329-fb0b-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 11:50:46.477: INFO: Waiting for pod downwardapi-volume-8012d329-fb0b-11e9-91af-623cf93d857c to disappear
Oct 30 11:50:46.489: INFO: Pod downwardapi-volume-8012d329-fb0b-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:50:46.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3637" for this suite.
Oct 30 11:50:52.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:50:52.863: INFO: namespace projected-3637 deletion completed in 6.351762449s

â€¢ [SLOW TEST:10.611 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:50:52.866: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:50:52.985: INFO: Waiting up to 5m0s for pod "downwardapi-volume-86658a12-fb0b-11e9-91af-623cf93d857c" in namespace "downward-api-1893" to be "success or failure"
Oct 30 11:50:53.005: INFO: Pod "downwardapi-volume-86658a12-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 20.509512ms
Oct 30 11:50:55.016: INFO: Pod "downwardapi-volume-86658a12-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0307825s
Oct 30 11:50:57.032: INFO: Pod "downwardapi-volume-86658a12-fb0b-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04675932s
STEP: Saw pod success
Oct 30 11:50:57.032: INFO: Pod "downwardapi-volume-86658a12-fb0b-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:50:57.040: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod downwardapi-volume-86658a12-fb0b-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 11:50:57.098: INFO: Waiting for pod downwardapi-volume-86658a12-fb0b-11e9-91af-623cf93d857c to disappear
Oct 30 11:50:57.104: INFO: Pod downwardapi-volume-86658a12-fb0b-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:50:57.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1893" for this suite.
Oct 30 11:51:03.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:51:03.474: INFO: namespace downward-api-1893 deletion completed in 6.357658214s

â€¢ [SLOW TEST:10.608 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:51:03.477: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Oct 30 11:51:03.590: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2945" to be "success or failure"
Oct 30 11:51:03.605: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 14.248304ms
Oct 30 11:51:05.616: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025625688s
Oct 30 11:51:07.625: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034259161s
STEP: Saw pod success
Oct 30 11:51:07.625: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Oct 30 11:51:07.630: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Oct 30 11:51:07.699: INFO: Waiting for pod pod-host-path-test to disappear
Oct 30 11:51:07.713: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:51:07.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2945" for this suite.
Oct 30 11:51:13.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:51:14.050: INFO: namespace hostpath-2945 deletion completed in 6.325187234s

â€¢ [SLOW TEST:10.574 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:51:14.052: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:51:14.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7137" for this suite.
Oct 30 11:51:20.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:51:20.513: INFO: namespace kubelet-test-7137 deletion completed in 6.286982768s

â€¢ [SLOW TEST:6.462 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:51:20.520: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-96e20464-fb0b-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume configMaps
Oct 30 11:51:20.648: INFO: Waiting up to 5m0s for pod "pod-configmaps-96e4be59-fb0b-11e9-91af-623cf93d857c" in namespace "configmap-864" to be "success or failure"
Oct 30 11:51:20.707: INFO: Pod "pod-configmaps-96e4be59-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 58.474087ms
Oct 30 11:51:22.716: INFO: Pod "pod-configmaps-96e4be59-fb0b-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.06842264s
Oct 30 11:51:24.726: INFO: Pod "pod-configmaps-96e4be59-fb0b-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.077676032s
STEP: Saw pod success
Oct 30 11:51:24.726: INFO: Pod "pod-configmaps-96e4be59-fb0b-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:51:24.736: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-configmaps-96e4be59-fb0b-11e9-91af-623cf93d857c container configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 11:51:24.798: INFO: Waiting for pod pod-configmaps-96e4be59-fb0b-11e9-91af-623cf93d857c to disappear
Oct 30 11:51:24.807: INFO: Pod pod-configmaps-96e4be59-fb0b-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:51:24.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-864" for this suite.
Oct 30 11:51:30.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:51:31.168: INFO: namespace configmap-864 deletion completed in 6.349583051s

â€¢ [SLOW TEST:10.648 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:51:31.168: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-9d3739d8-fb0b-11e9-91af-623cf93d857c
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:51:31.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8301" for this suite.
Oct 30 11:51:37.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:51:37.592: INFO: namespace configmap-8301 deletion completed in 6.339162617s

â€¢ [SLOW TEST:6.423 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:51:37.593: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 11:51:37.665: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:51:41.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5009" for this suite.
Oct 30 11:52:31.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:52:32.079: INFO: namespace pods-5009 deletion completed in 50.297656988s

â€¢ [SLOW TEST:54.486 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:52:32.081: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-c18db709-fb0b-11e9-91af-623cf93d857c
Oct 30 11:52:32.249: INFO: Pod name my-hostname-basic-c18db709-fb0b-11e9-91af-623cf93d857c: Found 0 pods out of 1
Oct 30 11:52:37.256: INFO: Pod name my-hostname-basic-c18db709-fb0b-11e9-91af-623cf93d857c: Found 1 pods out of 1
Oct 30 11:52:37.256: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-c18db709-fb0b-11e9-91af-623cf93d857c" are running
Oct 30 11:52:37.263: INFO: Pod "my-hostname-basic-c18db709-fb0b-11e9-91af-623cf93d857c-j6lq4" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-30 11:52:32 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-30 11:52:36 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-30 11:52:36 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-30 11:52:32 +0000 UTC Reason: Message:}])
Oct 30 11:52:37.263: INFO: Trying to dial the pod
Oct 30 11:52:42.291: INFO: Controller my-hostname-basic-c18db709-fb0b-11e9-91af-623cf93d857c: Got expected result from replica 1 [my-hostname-basic-c18db709-fb0b-11e9-91af-623cf93d857c-j6lq4]: "my-hostname-basic-c18db709-fb0b-11e9-91af-623cf93d857c-j6lq4", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:52:42.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7399" for this suite.
Oct 30 11:52:48.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:52:48.635: INFO: namespace replication-controller-7399 deletion completed in 6.328799845s

â€¢ [SLOW TEST:16.554 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:52:48.637: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Oct 30 11:52:48.738: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-984085711 proxy --unix-socket=/tmp/kubectl-proxy-unix388356066/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:52:48.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9727" for this suite.
Oct 30 11:52:54.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:52:55.122: INFO: namespace kubectl-9727 deletion completed in 6.281452216s

â€¢ [SLOW TEST:6.485 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:52:55.125: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Oct 30 11:52:55.217: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Oct 30 11:52:55.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 create -f - --namespace=kubectl-6915'
Oct 30 11:52:56.217: INFO: stderr: ""
Oct 30 11:52:56.217: INFO: stdout: "service/redis-slave created\n"
Oct 30 11:52:56.218: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Oct 30 11:52:56.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 create -f - --namespace=kubectl-6915'
Oct 30 11:52:56.568: INFO: stderr: ""
Oct 30 11:52:56.568: INFO: stdout: "service/redis-master created\n"
Oct 30 11:52:56.568: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct 30 11:52:56.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 create -f - --namespace=kubectl-6915'
Oct 30 11:52:57.001: INFO: stderr: ""
Oct 30 11:52:57.001: INFO: stdout: "service/frontend created\n"
Oct 30 11:52:57.002: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Oct 30 11:52:57.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 create -f - --namespace=kubectl-6915'
Oct 30 11:52:57.388: INFO: stderr: ""
Oct 30 11:52:57.388: INFO: stdout: "deployment.apps/frontend created\n"
Oct 30 11:52:57.389: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct 30 11:52:57.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 create -f - --namespace=kubectl-6915'
Oct 30 11:52:57.791: INFO: stderr: ""
Oct 30 11:52:57.791: INFO: stdout: "deployment.apps/redis-master created\n"
Oct 30 11:52:57.791: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Oct 30 11:52:57.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 create -f - --namespace=kubectl-6915'
Oct 30 11:52:58.277: INFO: stderr: ""
Oct 30 11:52:58.278: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Oct 30 11:52:58.278: INFO: Waiting for all frontend pods to be Running.
Oct 30 11:53:18.329: INFO: Waiting for frontend to serve content.
Oct 30 11:53:18.366: INFO: Trying to add a new entry to the guestbook.
Oct 30 11:53:18.404: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Oct 30 11:53:18.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 delete --grace-period=0 --force -f - --namespace=kubectl-6915'
Oct 30 11:53:18.612: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 11:53:18.612: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Oct 30 11:53:18.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 delete --grace-period=0 --force -f - --namespace=kubectl-6915'
Oct 30 11:53:18.802: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 11:53:18.802: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 30 11:53:18.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 delete --grace-period=0 --force -f - --namespace=kubectl-6915'
Oct 30 11:53:19.007: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 11:53:19.007: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 30 11:53:19.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 delete --grace-period=0 --force -f - --namespace=kubectl-6915'
Oct 30 11:53:19.146: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 11:53:19.146: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 30 11:53:19.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 delete --grace-period=0 --force -f - --namespace=kubectl-6915'
Oct 30 11:53:19.296: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 11:53:19.296: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 30 11:53:19.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 delete --grace-period=0 --force -f - --namespace=kubectl-6915'
Oct 30 11:53:19.432: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 11:53:19.432: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:53:19.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6915" for this suite.
Oct 30 11:54:03.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:54:03.797: INFO: namespace kubectl-6915 deletion completed in 44.355094501s

â€¢ [SLOW TEST:68.673 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:54:03.802: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Oct 30 11:54:04.359: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Oct 30 11:54:06.534: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708033244, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708033244, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708033244, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708033244, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 11:54:08.543: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708033244, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708033244, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708033244, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708033244, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 11:54:10.549: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708033244, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708033244, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708033244, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708033244, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 11:54:12.546: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708033244, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708033244, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708033244, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708033244, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 11:54:15.727: INFO: Waited 1.151125575s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:54:16.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1535" for this suite.
Oct 30 11:54:22.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:54:22.993: INFO: namespace aggregator-1535 deletion completed in 6.325612925s

â€¢ [SLOW TEST:19.192 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:54:22.998: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:54:23.143: INFO: Waiting up to 5m0s for pod "downwardapi-volume-03a98d80-fb0c-11e9-91af-623cf93d857c" in namespace "projected-696" to be "success or failure"
Oct 30 11:54:23.161: INFO: Pod "downwardapi-volume-03a98d80-fb0c-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.711771ms
Oct 30 11:54:25.196: INFO: Pod "downwardapi-volume-03a98d80-fb0c-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052979952s
Oct 30 11:54:27.205: INFO: Pod "downwardapi-volume-03a98d80-fb0c-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062372054s
STEP: Saw pod success
Oct 30 11:54:27.205: INFO: Pod "downwardapi-volume-03a98d80-fb0c-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:54:27.213: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod downwardapi-volume-03a98d80-fb0c-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 11:54:27.272: INFO: Waiting for pod downwardapi-volume-03a98d80-fb0c-11e9-91af-623cf93d857c to disappear
Oct 30 11:54:27.280: INFO: Pod downwardapi-volume-03a98d80-fb0c-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:54:27.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-696" for this suite.
Oct 30 11:54:33.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:54:33.568: INFO: namespace projected-696 deletion completed in 6.278375613s

â€¢ [SLOW TEST:10.571 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:54:33.569: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9493.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9493.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9493.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9493.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9493.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9493.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 30 11:54:49.832: INFO: DNS probes using dns-9493/dns-test-09f39893-fb0c-11e9-91af-623cf93d857c succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:54:49.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9493" for this suite.
Oct 30 11:54:55.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:54:56.210: INFO: namespace dns-9493 deletion completed in 6.31995171s

â€¢ [SLOW TEST:22.641 seconds]
[sig-network] DNS
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:54:56.212: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct 30 11:54:56.308: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:55:00.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8094" for this suite.
Oct 30 11:55:06.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:55:06.965: INFO: namespace init-container-8094 deletion completed in 6.328404895s

â€¢ [SLOW TEST:10.754 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:55:06.967: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-8374
I1030 11:55:07.065706      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8374, replica count: 1
I1030 11:55:08.116786      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1030 11:55:09.117168      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1030 11:55:10.117556      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 30 11:55:10.263: INFO: Created: latency-svc-d9dlk
Oct 30 11:55:10.272: INFO: Got endpoints: latency-svc-d9dlk [54.791438ms]
Oct 30 11:55:10.323: INFO: Created: latency-svc-thg6g
Oct 30 11:55:10.348: INFO: Got endpoints: latency-svc-thg6g [75.155764ms]
Oct 30 11:55:10.374: INFO: Created: latency-svc-s9gnh
Oct 30 11:55:10.376: INFO: Got endpoints: latency-svc-s9gnh [102.959613ms]
Oct 30 11:55:10.414: INFO: Created: latency-svc-s8rkq
Oct 30 11:55:10.425: INFO: Got endpoints: latency-svc-s8rkq [152.196478ms]
Oct 30 11:55:10.468: INFO: Created: latency-svc-7zfj7
Oct 30 11:55:10.495: INFO: Got endpoints: latency-svc-7zfj7 [221.580982ms]
Oct 30 11:55:10.530: INFO: Created: latency-svc-w94xw
Oct 30 11:55:10.540: INFO: Got endpoints: latency-svc-w94xw [266.471828ms]
Oct 30 11:55:10.588: INFO: Created: latency-svc-8hh5m
Oct 30 11:55:10.607: INFO: Got endpoints: latency-svc-8hh5m [333.203641ms]
Oct 30 11:55:10.665: INFO: Created: latency-svc-4ttpt
Oct 30 11:55:10.671: INFO: Got endpoints: latency-svc-4ttpt [396.968639ms]
Oct 30 11:55:10.732: INFO: Created: latency-svc-vs9ck
Oct 30 11:55:10.757: INFO: Got endpoints: latency-svc-vs9ck [483.503587ms]
Oct 30 11:55:10.823: INFO: Created: latency-svc-cn684
Oct 30 11:55:10.837: INFO: Got endpoints: latency-svc-cn684 [564.048818ms]
Oct 30 11:55:10.880: INFO: Created: latency-svc-98g6w
Oct 30 11:55:10.904: INFO: Got endpoints: latency-svc-98g6w [630.014678ms]
Oct 30 11:55:10.966: INFO: Created: latency-svc-djgt9
Oct 30 11:55:10.979: INFO: Got endpoints: latency-svc-djgt9 [705.125332ms]
Oct 30 11:55:11.038: INFO: Created: latency-svc-h2wkg
Oct 30 11:55:11.115: INFO: Got endpoints: latency-svc-h2wkg [841.451586ms]
Oct 30 11:55:11.142: INFO: Created: latency-svc-p2spw
Oct 30 11:55:11.147: INFO: Got endpoints: latency-svc-p2spw [872.768989ms]
Oct 30 11:55:11.343: INFO: Created: latency-svc-99qpf
Oct 30 11:55:11.378: INFO: Got endpoints: latency-svc-99qpf [1.104369788s]
Oct 30 11:55:11.392: INFO: Created: latency-svc-lpmt6
Oct 30 11:55:11.439: INFO: Got endpoints: latency-svc-lpmt6 [1.165723417s]
Oct 30 11:55:11.467: INFO: Created: latency-svc-xdgvz
Oct 30 11:55:11.473: INFO: Got endpoints: latency-svc-xdgvz [1.125544207s]
Oct 30 11:55:11.533: INFO: Created: latency-svc-k7tzt
Oct 30 11:55:11.555: INFO: Got endpoints: latency-svc-k7tzt [1.179759394s]
Oct 30 11:55:11.614: INFO: Created: latency-svc-g9wv2
Oct 30 11:55:11.641: INFO: Got endpoints: latency-svc-g9wv2 [1.215315714s]
Oct 30 11:55:11.653: INFO: Created: latency-svc-qhxcd
Oct 30 11:55:11.718: INFO: Got endpoints: latency-svc-qhxcd [1.222717666s]
Oct 30 11:55:11.753: INFO: Created: latency-svc-b6x4p
Oct 30 11:55:11.785: INFO: Got endpoints: latency-svc-b6x4p [1.245433293s]
Oct 30 11:55:11.790: INFO: Created: latency-svc-5nb9l
Oct 30 11:55:11.841: INFO: Got endpoints: latency-svc-5nb9l [1.23445437s]
Oct 30 11:55:11.865: INFO: Created: latency-svc-gkbtz
Oct 30 11:55:11.887: INFO: Got endpoints: latency-svc-gkbtz [1.216571415s]
Oct 30 11:55:11.912: INFO: Created: latency-svc-8ttjl
Oct 30 11:55:11.939: INFO: Got endpoints: latency-svc-8ttjl [1.181169255s]
Oct 30 11:55:11.966: INFO: Created: latency-svc-xvlb4
Oct 30 11:55:11.996: INFO: Got endpoints: latency-svc-xvlb4 [1.158564745s]
Oct 30 11:55:12.076: INFO: Created: latency-svc-jg5r9
Oct 30 11:55:12.080: INFO: Got endpoints: latency-svc-jg5r9 [1.17652059s]
Oct 30 11:55:12.122: INFO: Created: latency-svc-h8xw2
Oct 30 11:55:12.158: INFO: Got endpoints: latency-svc-h8xw2 [1.179090146s]
Oct 30 11:55:12.173: INFO: Created: latency-svc-xgq9v
Oct 30 11:55:12.291: INFO: Got endpoints: latency-svc-xgq9v [1.174920811s]
Oct 30 11:55:12.357: INFO: Created: latency-svc-sd4tz
Oct 30 11:55:12.373: INFO: Got endpoints: latency-svc-sd4tz [1.225821386s]
Oct 30 11:55:12.414: INFO: Created: latency-svc-4czf4
Oct 30 11:55:12.414: INFO: Got endpoints: latency-svc-4czf4 [1.035396363s]
Oct 30 11:55:12.444: INFO: Created: latency-svc-wmbfz
Oct 30 11:55:12.460: INFO: Got endpoints: latency-svc-wmbfz [1.020527871s]
Oct 30 11:55:12.493: INFO: Created: latency-svc-nwtv5
Oct 30 11:55:12.503: INFO: Got endpoints: latency-svc-nwtv5 [1.029858942s]
Oct 30 11:55:12.565: INFO: Created: latency-svc-dsd9v
Oct 30 11:55:12.565: INFO: Got endpoints: latency-svc-dsd9v [1.009610976s]
Oct 30 11:55:12.597: INFO: Created: latency-svc-9sk5t
Oct 30 11:55:12.601: INFO: Got endpoints: latency-svc-9sk5t [959.803976ms]
Oct 30 11:55:12.673: INFO: Created: latency-svc-hwh2s
Oct 30 11:55:12.674: INFO: Got endpoints: latency-svc-hwh2s [955.841808ms]
Oct 30 11:55:12.719: INFO: Created: latency-svc-kn7pc
Oct 30 11:55:12.735: INFO: Got endpoints: latency-svc-kn7pc [949.279906ms]
Oct 30 11:55:12.786: INFO: Created: latency-svc-996gb
Oct 30 11:55:12.794: INFO: Got endpoints: latency-svc-996gb [952.936323ms]
Oct 30 11:55:12.843: INFO: Created: latency-svc-6rvww
Oct 30 11:55:12.881: INFO: Got endpoints: latency-svc-6rvww [993.62313ms]
Oct 30 11:55:12.910: INFO: Created: latency-svc-m79zk
Oct 30 11:55:12.929: INFO: Got endpoints: latency-svc-m79zk [990.814101ms]
Oct 30 11:55:12.984: INFO: Created: latency-svc-nmhzf
Oct 30 11:55:12.984: INFO: Got endpoints: latency-svc-nmhzf [988.209485ms]
Oct 30 11:55:13.028: INFO: Created: latency-svc-ccfgt
Oct 30 11:55:13.066: INFO: Got endpoints: latency-svc-ccfgt [985.190043ms]
Oct 30 11:55:13.096: INFO: Created: latency-svc-z8fwd
Oct 30 11:55:13.096: INFO: Got endpoints: latency-svc-z8fwd [937.310443ms]
Oct 30 11:55:13.165: INFO: Created: latency-svc-bgjsh
Oct 30 11:55:13.175: INFO: Got endpoints: latency-svc-bgjsh [884.224485ms]
Oct 30 11:55:13.232: INFO: Created: latency-svc-f49m6
Oct 30 11:55:13.294: INFO: Got endpoints: latency-svc-f49m6 [921.324483ms]
Oct 30 11:55:13.335: INFO: Created: latency-svc-xk6hb
Oct 30 11:55:13.359: INFO: Got endpoints: latency-svc-xk6hb [944.394191ms]
Oct 30 11:55:13.416: INFO: Created: latency-svc-dz28p
Oct 30 11:55:13.417: INFO: Got endpoints: latency-svc-dz28p [956.380088ms]
Oct 30 11:55:13.460: INFO: Created: latency-svc-mbbht
Oct 30 11:55:13.472: INFO: Got endpoints: latency-svc-mbbht [968.401848ms]
Oct 30 11:55:13.551: INFO: Created: latency-svc-7rcq5
Oct 30 11:55:13.596: INFO: Got endpoints: latency-svc-7rcq5 [1.030586283s]
Oct 30 11:55:13.636: INFO: Created: latency-svc-nndmh
Oct 30 11:55:13.636: INFO: Got endpoints: latency-svc-nndmh [1.03534188s]
Oct 30 11:55:13.661: INFO: Created: latency-svc-wgfhc
Oct 30 11:55:13.692: INFO: Got endpoints: latency-svc-wgfhc [1.017996123s]
Oct 30 11:55:13.783: INFO: Created: latency-svc-p4tdn
Oct 30 11:55:13.790: INFO: Got endpoints: latency-svc-p4tdn [1.055627835s]
Oct 30 11:55:13.874: INFO: Created: latency-svc-qvtss
Oct 30 11:55:13.883: INFO: Got endpoints: latency-svc-qvtss [1.088984288s]
Oct 30 11:55:13.964: INFO: Created: latency-svc-snmwn
Oct 30 11:55:13.969: INFO: Got endpoints: latency-svc-snmwn [1.08782278s]
Oct 30 11:55:14.044: INFO: Created: latency-svc-429jc
Oct 30 11:55:14.044: INFO: Got endpoints: latency-svc-429jc [1.114199713s]
Oct 30 11:55:14.083: INFO: Created: latency-svc-7vzgg
Oct 30 11:55:14.123: INFO: Got endpoints: latency-svc-7vzgg [1.138641495s]
Oct 30 11:55:14.149: INFO: Created: latency-svc-58v2c
Oct 30 11:55:14.159: INFO: Got endpoints: latency-svc-58v2c [1.09371483s]
Oct 30 11:55:14.206: INFO: Created: latency-svc-52nvm
Oct 30 11:55:14.227: INFO: Got endpoints: latency-svc-52nvm [1.13089973s]
Oct 30 11:55:14.328: INFO: Created: latency-svc-mtsvh
Oct 30 11:55:14.343: INFO: Got endpoints: latency-svc-mtsvh [1.168349102s]
Oct 30 11:55:14.354: INFO: Created: latency-svc-gm2vb
Oct 30 11:55:14.363: INFO: Got endpoints: latency-svc-gm2vb [1.069094747s]
Oct 30 11:55:14.407: INFO: Created: latency-svc-47fn5
Oct 30 11:55:14.418: INFO: Got endpoints: latency-svc-47fn5 [1.05909156s]
Oct 30 11:55:14.490: INFO: Created: latency-svc-9d7nx
Oct 30 11:55:14.496: INFO: Got endpoints: latency-svc-9d7nx [1.079414633s]
Oct 30 11:55:14.577: INFO: Created: latency-svc-wg9mn
Oct 30 11:55:14.607: INFO: Got endpoints: latency-svc-wg9mn [1.135218178s]
Oct 30 11:55:14.636: INFO: Created: latency-svc-s7l6h
Oct 30 11:55:14.643: INFO: Got endpoints: latency-svc-s7l6h [1.046896336s]
Oct 30 11:55:14.696: INFO: Created: latency-svc-2knb4
Oct 30 11:55:14.697: INFO: Got endpoints: latency-svc-2knb4 [1.060565588s]
Oct 30 11:55:14.814: INFO: Created: latency-svc-5mqg7
Oct 30 11:55:14.822: INFO: Got endpoints: latency-svc-5mqg7 [1.130446653s]
Oct 30 11:55:14.882: INFO: Created: latency-svc-b2v2r
Oct 30 11:55:14.915: INFO: Got endpoints: latency-svc-b2v2r [1.124052709s]
Oct 30 11:55:14.924: INFO: Created: latency-svc-4t4t7
Oct 30 11:55:14.924: INFO: Got endpoints: latency-svc-4t4t7 [1.04035865s]
Oct 30 11:55:14.957: INFO: Created: latency-svc-22btt
Oct 30 11:55:14.978: INFO: Got endpoints: latency-svc-22btt [1.008483337s]
Oct 30 11:55:15.020: INFO: Created: latency-svc-jcdnn
Oct 30 11:55:15.125: INFO: Got endpoints: latency-svc-jcdnn [1.080737615s]
Oct 30 11:55:15.183: INFO: Created: latency-svc-srdgm
Oct 30 11:55:15.190: INFO: Got endpoints: latency-svc-srdgm [1.067414561s]
Oct 30 11:55:15.237: INFO: Created: latency-svc-jmjfk
Oct 30 11:55:15.266: INFO: Got endpoints: latency-svc-jmjfk [140.438487ms]
Oct 30 11:55:15.287: INFO: Created: latency-svc-t9drn
Oct 30 11:55:15.292: INFO: Got endpoints: latency-svc-t9drn [1.132888742s]
Oct 30 11:55:15.353: INFO: Created: latency-svc-wfldn
Oct 30 11:55:15.353: INFO: Got endpoints: latency-svc-wfldn [1.126693828s]
Oct 30 11:55:15.431: INFO: Created: latency-svc-8jxgb
Oct 30 11:55:15.438: INFO: Got endpoints: latency-svc-8jxgb [1.094349932s]
Oct 30 11:55:15.491: INFO: Created: latency-svc-hhsfg
Oct 30 11:55:15.494: INFO: Got endpoints: latency-svc-hhsfg [1.130553975s]
Oct 30 11:55:15.560: INFO: Created: latency-svc-5tqjq
Oct 30 11:55:15.629: INFO: Got endpoints: latency-svc-5tqjq [1.21046445s]
Oct 30 11:55:15.636: INFO: Created: latency-svc-bn8wj
Oct 30 11:55:15.650: INFO: Got endpoints: latency-svc-bn8wj [1.153398725s]
Oct 30 11:55:15.734: INFO: Created: latency-svc-z5sqt
Oct 30 11:55:15.798: INFO: Got endpoints: latency-svc-z5sqt [1.190840296s]
Oct 30 11:55:15.804: INFO: Created: latency-svc-smb25
Oct 30 11:55:15.846: INFO: Got endpoints: latency-svc-smb25 [1.202334413s]
Oct 30 11:55:15.935: INFO: Created: latency-svc-vv5k5
Oct 30 11:55:15.955: INFO: Got endpoints: latency-svc-vv5k5 [1.258718785s]
Oct 30 11:55:15.969: INFO: Created: latency-svc-75dkx
Oct 30 11:55:15.986: INFO: Got endpoints: latency-svc-75dkx [1.163259352s]
Oct 30 11:55:16.019: INFO: Created: latency-svc-5b7xj
Oct 30 11:55:16.153: INFO: Created: latency-svc-774bb
Oct 30 11:55:16.165: INFO: Got endpoints: latency-svc-5b7xj [1.250346619s]
Oct 30 11:55:16.195: INFO: Got endpoints: latency-svc-774bb [1.271733158s]
Oct 30 11:55:16.217: INFO: Created: latency-svc-6grrr
Oct 30 11:55:16.225: INFO: Got endpoints: latency-svc-6grrr [1.246771744s]
Oct 30 11:55:16.358: INFO: Created: latency-svc-lcfkd
Oct 30 11:55:16.358: INFO: Got endpoints: latency-svc-lcfkd [1.167500645s]
Oct 30 11:55:16.467: INFO: Created: latency-svc-lhkt4
Oct 30 11:55:16.487: INFO: Got endpoints: latency-svc-lhkt4 [1.221709673s]
Oct 30 11:55:16.519: INFO: Created: latency-svc-j4sgx
Oct 30 11:55:16.522: INFO: Got endpoints: latency-svc-j4sgx [1.229735684s]
Oct 30 11:55:16.581: INFO: Created: latency-svc-z2r5p
Oct 30 11:55:16.633: INFO: Got endpoints: latency-svc-z2r5p [1.279344479s]
Oct 30 11:55:16.671: INFO: Created: latency-svc-bfzpk
Oct 30 11:55:16.675: INFO: Got endpoints: latency-svc-bfzpk [1.237514594s]
Oct 30 11:55:16.732: INFO: Created: latency-svc-6jkkb
Oct 30 11:55:16.753: INFO: Got endpoints: latency-svc-6jkkb [1.258976576s]
Oct 30 11:55:16.794: INFO: Created: latency-svc-fw2wv
Oct 30 11:55:16.794: INFO: Got endpoints: latency-svc-fw2wv [1.16531705s]
Oct 30 11:55:16.833: INFO: Created: latency-svc-6rp2t
Oct 30 11:55:16.877: INFO: Got endpoints: latency-svc-6rp2t [1.22725051s]
Oct 30 11:55:16.921: INFO: Created: latency-svc-dc8kg
Oct 30 11:55:16.921: INFO: Got endpoints: latency-svc-dc8kg [1.123107401s]
Oct 30 11:55:16.961: INFO: Created: latency-svc-sgqqs
Oct 30 11:55:16.978: INFO: Got endpoints: latency-svc-sgqqs [1.131673239s]
Oct 30 11:55:17.018: INFO: Created: latency-svc-rbb2l
Oct 30 11:55:17.043: INFO: Got endpoints: latency-svc-rbb2l [1.088096138s]
Oct 30 11:55:17.059: INFO: Created: latency-svc-jfm68
Oct 30 11:55:17.081: INFO: Got endpoints: latency-svc-jfm68 [1.095614565s]
Oct 30 11:55:17.092: INFO: Created: latency-svc-9pmg6
Oct 30 11:55:17.103: INFO: Got endpoints: latency-svc-9pmg6 [937.581215ms]
Oct 30 11:55:17.134: INFO: Created: latency-svc-dkv8g
Oct 30 11:55:17.178: INFO: Got endpoints: latency-svc-dkv8g [982.561115ms]
Oct 30 11:55:17.194: INFO: Created: latency-svc-bzsw9
Oct 30 11:55:17.209: INFO: Got endpoints: latency-svc-bzsw9 [984.028633ms]
Oct 30 11:55:17.262: INFO: Created: latency-svc-ct84w
Oct 30 11:55:17.272: INFO: Got endpoints: latency-svc-ct84w [914.606288ms]
Oct 30 11:55:17.325: INFO: Created: latency-svc-w4wbl
Oct 30 11:55:17.343: INFO: Got endpoints: latency-svc-w4wbl [855.067964ms]
Oct 30 11:55:17.358: INFO: Created: latency-svc-jkhhf
Oct 30 11:55:17.370: INFO: Got endpoints: latency-svc-jkhhf [847.685178ms]
Oct 30 11:55:17.407: INFO: Created: latency-svc-2n6s8
Oct 30 11:55:17.408: INFO: Got endpoints: latency-svc-2n6s8 [774.604567ms]
Oct 30 11:55:17.460: INFO: Created: latency-svc-4prp8
Oct 30 11:55:17.470: INFO: Got endpoints: latency-svc-4prp8 [794.463129ms]
Oct 30 11:55:17.505: INFO: Created: latency-svc-vt79g
Oct 30 11:55:17.511: INFO: Got endpoints: latency-svc-vt79g [757.8597ms]
Oct 30 11:55:17.584: INFO: Created: latency-svc-nnlh6
Oct 30 11:55:17.592: INFO: Got endpoints: latency-svc-nnlh6 [797.827704ms]
Oct 30 11:55:17.654: INFO: Created: latency-svc-6w2hk
Oct 30 11:55:17.710: INFO: Got endpoints: latency-svc-6w2hk [832.468397ms]
Oct 30 11:55:17.736: INFO: Created: latency-svc-m5jnn
Oct 30 11:55:17.743: INFO: Got endpoints: latency-svc-m5jnn [821.587041ms]
Oct 30 11:55:17.797: INFO: Created: latency-svc-bpxkl
Oct 30 11:55:17.807: INFO: Got endpoints: latency-svc-bpxkl [829.55626ms]
Oct 30 11:55:17.967: INFO: Created: latency-svc-mp42k
Oct 30 11:55:17.983: INFO: Got endpoints: latency-svc-mp42k [939.016429ms]
Oct 30 11:55:18.004: INFO: Created: latency-svc-425zp
Oct 30 11:55:18.013: INFO: Got endpoints: latency-svc-425zp [931.188574ms]
Oct 30 11:55:18.161: INFO: Created: latency-svc-c758s
Oct 30 11:55:18.166: INFO: Got endpoints: latency-svc-c758s [1.062961846s]
Oct 30 11:55:18.230: INFO: Created: latency-svc-h9kpg
Oct 30 11:55:18.230: INFO: Got endpoints: latency-svc-h9kpg [1.052019905s]
Oct 30 11:55:18.302: INFO: Created: latency-svc-l5zzz
Oct 30 11:55:18.314: INFO: Got endpoints: latency-svc-l5zzz [1.105136633s]
Oct 30 11:55:18.354: INFO: Created: latency-svc-dbzs8
Oct 30 11:55:18.358: INFO: Got endpoints: latency-svc-dbzs8 [1.085933411s]
Oct 30 11:55:18.400: INFO: Created: latency-svc-4qfv9
Oct 30 11:55:18.418: INFO: Got endpoints: latency-svc-4qfv9 [1.075032811s]
Oct 30 11:55:18.456: INFO: Created: latency-svc-j652m
Oct 30 11:55:18.456: INFO: Got endpoints: latency-svc-j652m [1.086405424s]
Oct 30 11:55:18.485: INFO: Created: latency-svc-84484
Oct 30 11:55:18.495: INFO: Got endpoints: latency-svc-84484 [1.087125925s]
Oct 30 11:55:18.528: INFO: Created: latency-svc-lgsqb
Oct 30 11:55:18.565: INFO: Got endpoints: latency-svc-lgsqb [1.094319948s]
Oct 30 11:55:18.592: INFO: Created: latency-svc-ghwxk
Oct 30 11:55:18.636: INFO: Got endpoints: latency-svc-ghwxk [1.124413704s]
Oct 30 11:55:18.660: INFO: Created: latency-svc-sxkdt
Oct 30 11:55:18.683: INFO: Got endpoints: latency-svc-sxkdt [1.09067964s]
Oct 30 11:55:18.701: INFO: Created: latency-svc-ng9r9
Oct 30 11:55:18.711: INFO: Got endpoints: latency-svc-ng9r9 [1.000639266s]
Oct 30 11:55:18.755: INFO: Created: latency-svc-m2v97
Oct 30 11:55:18.776: INFO: Got endpoints: latency-svc-m2v97 [1.032345763s]
Oct 30 11:55:18.804: INFO: Created: latency-svc-fzmpz
Oct 30 11:55:18.816: INFO: Got endpoints: latency-svc-fzmpz [1.008957523s]
Oct 30 11:55:18.854: INFO: Created: latency-svc-srk2h
Oct 30 11:55:18.888: INFO: Got endpoints: latency-svc-srk2h [905.852831ms]
Oct 30 11:55:19.025: INFO: Created: latency-svc-ts67w
Oct 30 11:55:19.060: INFO: Got endpoints: latency-svc-ts67w [1.046836772s]
Oct 30 11:55:19.078: INFO: Created: latency-svc-r289m
Oct 30 11:55:19.087: INFO: Got endpoints: latency-svc-r289m [921.477102ms]
Oct 30 11:55:19.132: INFO: Created: latency-svc-jt774
Oct 30 11:55:19.141: INFO: Got endpoints: latency-svc-jt774 [910.099011ms]
Oct 30 11:55:19.183: INFO: Created: latency-svc-2n64z
Oct 30 11:55:19.281: INFO: Got endpoints: latency-svc-2n64z [966.899812ms]
Oct 30 11:55:19.289: INFO: Created: latency-svc-5lbn4
Oct 30 11:55:19.296: INFO: Got endpoints: latency-svc-5lbn4 [937.642552ms]
Oct 30 11:55:19.338: INFO: Created: latency-svc-94c69
Oct 30 11:55:19.366: INFO: Got endpoints: latency-svc-94c69 [948.205817ms]
Oct 30 11:55:19.392: INFO: Created: latency-svc-dqn46
Oct 30 11:55:19.406: INFO: Got endpoints: latency-svc-dqn46 [949.62707ms]
Oct 30 11:55:19.475: INFO: Created: latency-svc-bgt47
Oct 30 11:55:19.491: INFO: Got endpoints: latency-svc-bgt47 [995.524922ms]
Oct 30 11:55:19.555: INFO: Created: latency-svc-cfbf7
Oct 30 11:55:19.562: INFO: Got endpoints: latency-svc-cfbf7 [996.756711ms]
Oct 30 11:55:19.620: INFO: Created: latency-svc-cht2t
Oct 30 11:55:19.628: INFO: Got endpoints: latency-svc-cht2t [991.898746ms]
Oct 30 11:55:19.669: INFO: Created: latency-svc-ckwlh
Oct 30 11:55:19.670: INFO: Got endpoints: latency-svc-ckwlh [987.358135ms]
Oct 30 11:55:19.757: INFO: Created: latency-svc-pbbtd
Oct 30 11:55:19.758: INFO: Got endpoints: latency-svc-pbbtd [1.047755379s]
Oct 30 11:55:19.818: INFO: Created: latency-svc-w45fc
Oct 30 11:55:19.882: INFO: Got endpoints: latency-svc-w45fc [1.105949021s]
Oct 30 11:55:19.930: INFO: Created: latency-svc-6pgt6
Oct 30 11:55:19.935: INFO: Got endpoints: latency-svc-6pgt6 [1.117781641s]
Oct 30 11:55:20.013: INFO: Created: latency-svc-drxkj
Oct 30 11:55:20.070: INFO: Created: latency-svc-kpz8k
Oct 30 11:55:20.071: INFO: Got endpoints: latency-svc-drxkj [1.182778688s]
Oct 30 11:55:20.076: INFO: Got endpoints: latency-svc-kpz8k [1.015794765s]
Oct 30 11:55:20.133: INFO: Created: latency-svc-8kdc2
Oct 30 11:55:20.155: INFO: Got endpoints: latency-svc-8kdc2 [1.067104644s]
Oct 30 11:55:20.178: INFO: Created: latency-svc-whr6f
Oct 30 11:55:20.201: INFO: Got endpoints: latency-svc-whr6f [1.060134646s]
Oct 30 11:55:20.254: INFO: Created: latency-svc-cbwzr
Oct 30 11:55:20.278: INFO: Got endpoints: latency-svc-cbwzr [996.029574ms]
Oct 30 11:55:20.321: INFO: Created: latency-svc-qdw42
Oct 30 11:55:20.367: INFO: Got endpoints: latency-svc-qdw42 [1.07037988s]
Oct 30 11:55:20.387: INFO: Created: latency-svc-fkdbn
Oct 30 11:55:20.390: INFO: Got endpoints: latency-svc-fkdbn [1.023938538s]
Oct 30 11:55:20.425: INFO: Created: latency-svc-8ngmk
Oct 30 11:55:20.429: INFO: Got endpoints: latency-svc-8ngmk [1.022179834s]
Oct 30 11:55:20.469: INFO: Created: latency-svc-9969f
Oct 30 11:55:20.474: INFO: Got endpoints: latency-svc-9969f [983.372885ms]
Oct 30 11:55:20.501: INFO: Created: latency-svc-2c8bv
Oct 30 11:55:20.527: INFO: Got endpoints: latency-svc-2c8bv [965.649139ms]
Oct 30 11:55:20.546: INFO: Created: latency-svc-f9p84
Oct 30 11:55:20.549: INFO: Got endpoints: latency-svc-f9p84 [920.698444ms]
Oct 30 11:55:20.606: INFO: Created: latency-svc-r746p
Oct 30 11:55:20.625: INFO: Got endpoints: latency-svc-r746p [954.143ms]
Oct 30 11:55:20.644: INFO: Created: latency-svc-4gdwq
Oct 30 11:55:20.659: INFO: Got endpoints: latency-svc-4gdwq [900.624678ms]
Oct 30 11:55:20.707: INFO: Created: latency-svc-c588m
Oct 30 11:55:20.715: INFO: Got endpoints: latency-svc-c588m [832.977197ms]
Oct 30 11:55:20.750: INFO: Created: latency-svc-45mrz
Oct 30 11:55:20.792: INFO: Got endpoints: latency-svc-45mrz [857.076295ms]
Oct 30 11:55:20.828: INFO: Created: latency-svc-pcstc
Oct 30 11:55:20.854: INFO: Got endpoints: latency-svc-pcstc [782.730224ms]
Oct 30 11:55:20.888: INFO: Created: latency-svc-gskpp
Oct 30 11:55:20.895: INFO: Got endpoints: latency-svc-gskpp [818.924932ms]
Oct 30 11:55:20.971: INFO: Created: latency-svc-bvb7l
Oct 30 11:55:20.990: INFO: Got endpoints: latency-svc-bvb7l [835.215658ms]
Oct 30 11:55:21.032: INFO: Created: latency-svc-fq9zm
Oct 30 11:55:21.054: INFO: Got endpoints: latency-svc-fq9zm [852.165354ms]
Oct 30 11:55:21.087: INFO: Created: latency-svc-jqhzp
Oct 30 11:55:21.106: INFO: Got endpoints: latency-svc-jqhzp [827.651067ms]
Oct 30 11:55:21.125: INFO: Created: latency-svc-bgthz
Oct 30 11:55:21.137: INFO: Got endpoints: latency-svc-bgthz [769.582369ms]
Oct 30 11:55:21.216: INFO: Created: latency-svc-ljrvz
Oct 30 11:55:21.255: INFO: Got endpoints: latency-svc-ljrvz [864.853855ms]
Oct 30 11:55:21.276: INFO: Created: latency-svc-qjqsz
Oct 30 11:55:21.277: INFO: Got endpoints: latency-svc-qjqsz [848.619263ms]
Oct 30 11:55:21.325: INFO: Created: latency-svc-qtx79
Oct 30 11:55:21.360: INFO: Got endpoints: latency-svc-qtx79 [885.815571ms]
Oct 30 11:55:21.376: INFO: Created: latency-svc-ldqm7
Oct 30 11:55:21.383: INFO: Got endpoints: latency-svc-ldqm7 [856.044053ms]
Oct 30 11:55:21.432: INFO: Created: latency-svc-hpf9z
Oct 30 11:55:21.530: INFO: Got endpoints: latency-svc-hpf9z [979.978655ms]
Oct 30 11:55:21.548: INFO: Created: latency-svc-jdl2v
Oct 30 11:55:21.580: INFO: Got endpoints: latency-svc-jdl2v [955.014913ms]
Oct 30 11:55:21.590: INFO: Created: latency-svc-vvzkm
Oct 30 11:55:21.596: INFO: Got endpoints: latency-svc-vvzkm [936.533574ms]
Oct 30 11:55:21.644: INFO: Created: latency-svc-8wbn6
Oct 30 11:55:21.678: INFO: Got endpoints: latency-svc-8wbn6 [963.438581ms]
Oct 30 11:55:21.719: INFO: Created: latency-svc-j4hqg
Oct 30 11:55:21.723: INFO: Got endpoints: latency-svc-j4hqg [931.113246ms]
Oct 30 11:55:21.779: INFO: Created: latency-svc-jgzns
Oct 30 11:55:21.779: INFO: Got endpoints: latency-svc-jgzns [924.968486ms]
Oct 30 11:55:21.843: INFO: Created: latency-svc-9rfjb
Oct 30 11:55:21.865: INFO: Got endpoints: latency-svc-9rfjb [969.368877ms]
Oct 30 11:55:21.908: INFO: Created: latency-svc-6v5gj
Oct 30 11:55:21.917: INFO: Got endpoints: latency-svc-6v5gj [926.625746ms]
Oct 30 11:55:21.978: INFO: Created: latency-svc-77ft9
Oct 30 11:55:21.990: INFO: Got endpoints: latency-svc-77ft9 [936.154769ms]
Oct 30 11:55:22.046: INFO: Created: latency-svc-9vwld
Oct 30 11:55:22.084: INFO: Got endpoints: latency-svc-9vwld [978.223449ms]
Oct 30 11:55:22.129: INFO: Created: latency-svc-hgsp9
Oct 30 11:55:22.167: INFO: Got endpoints: latency-svc-hgsp9 [1.030109978s]
Oct 30 11:55:22.194: INFO: Created: latency-svc-88cfz
Oct 30 11:55:22.201: INFO: Got endpoints: latency-svc-88cfz [945.629572ms]
Oct 30 11:55:22.239: INFO: Created: latency-svc-qbbxw
Oct 30 11:55:22.290: INFO: Got endpoints: latency-svc-qbbxw [1.013151272s]
Oct 30 11:55:22.303: INFO: Created: latency-svc-x8p25
Oct 30 11:55:22.312: INFO: Got endpoints: latency-svc-x8p25 [951.398445ms]
Oct 30 11:55:22.342: INFO: Created: latency-svc-b4g9k
Oct 30 11:55:22.355: INFO: Got endpoints: latency-svc-b4g9k [971.706916ms]
Oct 30 11:55:22.384: INFO: Created: latency-svc-f9kwj
Oct 30 11:55:22.418: INFO: Got endpoints: latency-svc-f9kwj [887.780278ms]
Oct 30 11:55:22.436: INFO: Created: latency-svc-mglqt
Oct 30 11:55:22.449: INFO: Got endpoints: latency-svc-mglqt [868.963104ms]
Oct 30 11:55:22.474: INFO: Created: latency-svc-fdpqz
Oct 30 11:55:22.505: INFO: Got endpoints: latency-svc-fdpqz [908.644307ms]
Oct 30 11:55:22.669: INFO: Created: latency-svc-wkpkn
Oct 30 11:55:22.713: INFO: Got endpoints: latency-svc-wkpkn [1.03418073s]
Oct 30 11:55:22.798: INFO: Created: latency-svc-2fz87
Oct 30 11:55:22.798: INFO: Got endpoints: latency-svc-2fz87 [1.074736611s]
Oct 30 11:55:22.824: INFO: Created: latency-svc-jqcsb
Oct 30 11:55:22.833: INFO: Got endpoints: latency-svc-jqcsb [1.053358097s]
Oct 30 11:55:22.904: INFO: Created: latency-svc-wvcn7
Oct 30 11:55:22.934: INFO: Got endpoints: latency-svc-wvcn7 [1.069262553s]
Oct 30 11:55:22.948: INFO: Created: latency-svc-jqnd6
Oct 30 11:55:22.972: INFO: Got endpoints: latency-svc-jqnd6 [1.054750074s]
Oct 30 11:55:22.982: INFO: Created: latency-svc-9t4pw
Oct 30 11:55:23.020: INFO: Got endpoints: latency-svc-9t4pw [1.029560889s]
Oct 30 11:55:23.054: INFO: Created: latency-svc-m6cmv
Oct 30 11:55:23.072: INFO: Got endpoints: latency-svc-m6cmv [987.436687ms]
Oct 30 11:55:23.083: INFO: Created: latency-svc-dldgr
Oct 30 11:55:23.089: INFO: Got endpoints: latency-svc-dldgr [922.116032ms]
Oct 30 11:55:23.153: INFO: Created: latency-svc-gd29r
Oct 30 11:55:23.158: INFO: Got endpoints: latency-svc-gd29r [957.418879ms]
Oct 30 11:55:23.296: INFO: Created: latency-svc-w2gmf
Oct 30 11:55:23.297: INFO: Got endpoints: latency-svc-w2gmf [1.006107348s]
Oct 30 11:55:23.341: INFO: Created: latency-svc-7g2th
Oct 30 11:55:23.351: INFO: Got endpoints: latency-svc-7g2th [1.039287401s]
Oct 30 11:55:23.405: INFO: Created: latency-svc-c7g9f
Oct 30 11:55:23.405: INFO: Got endpoints: latency-svc-c7g9f [1.049713761s]
Oct 30 11:55:23.457: INFO: Created: latency-svc-s8xs9
Oct 30 11:55:23.478: INFO: Got endpoints: latency-svc-s8xs9 [1.060199523s]
Oct 30 11:55:23.538: INFO: Created: latency-svc-x7br4
Oct 30 11:55:23.544: INFO: Got endpoints: latency-svc-x7br4 [1.094678461s]
Oct 30 11:55:23.573: INFO: Created: latency-svc-vvnmx
Oct 30 11:55:23.577: INFO: Got endpoints: latency-svc-vvnmx [1.072277894s]
Oct 30 11:55:23.608: INFO: Created: latency-svc-8g4w2
Oct 30 11:55:23.622: INFO: Got endpoints: latency-svc-8g4w2 [909.6495ms]
Oct 30 11:55:23.663: INFO: Created: latency-svc-8jpxb
Oct 30 11:55:23.688: INFO: Got endpoints: latency-svc-8jpxb [889.640394ms]
Oct 30 11:55:23.724: INFO: Created: latency-svc-zgrbc
Oct 30 11:55:23.726: INFO: Got endpoints: latency-svc-zgrbc [893.177358ms]
Oct 30 11:55:23.789: INFO: Created: latency-svc-mmtxj
Oct 30 11:55:23.838: INFO: Got endpoints: latency-svc-mmtxj [903.25901ms]
Oct 30 11:55:23.838: INFO: Latencies: [75.155764ms 102.959613ms 140.438487ms 152.196478ms 221.580982ms 266.471828ms 333.203641ms 396.968639ms 483.503587ms 564.048818ms 630.014678ms 705.125332ms 757.8597ms 769.582369ms 774.604567ms 782.730224ms 794.463129ms 797.827704ms 818.924932ms 821.587041ms 827.651067ms 829.55626ms 832.468397ms 832.977197ms 835.215658ms 841.451586ms 847.685178ms 848.619263ms 852.165354ms 855.067964ms 856.044053ms 857.076295ms 864.853855ms 868.963104ms 872.768989ms 884.224485ms 885.815571ms 887.780278ms 889.640394ms 893.177358ms 900.624678ms 903.25901ms 905.852831ms 908.644307ms 909.6495ms 910.099011ms 914.606288ms 920.698444ms 921.324483ms 921.477102ms 922.116032ms 924.968486ms 926.625746ms 931.113246ms 931.188574ms 936.154769ms 936.533574ms 937.310443ms 937.581215ms 937.642552ms 939.016429ms 944.394191ms 945.629572ms 948.205817ms 949.279906ms 949.62707ms 951.398445ms 952.936323ms 954.143ms 955.014913ms 955.841808ms 956.380088ms 957.418879ms 959.803976ms 963.438581ms 965.649139ms 966.899812ms 968.401848ms 969.368877ms 971.706916ms 978.223449ms 979.978655ms 982.561115ms 983.372885ms 984.028633ms 985.190043ms 987.358135ms 987.436687ms 988.209485ms 990.814101ms 991.898746ms 993.62313ms 995.524922ms 996.029574ms 996.756711ms 1.000639266s 1.006107348s 1.008483337s 1.008957523s 1.009610976s 1.013151272s 1.015794765s 1.017996123s 1.020527871s 1.022179834s 1.023938538s 1.029560889s 1.029858942s 1.030109978s 1.030586283s 1.032345763s 1.03418073s 1.03534188s 1.035396363s 1.039287401s 1.04035865s 1.046836772s 1.046896336s 1.047755379s 1.049713761s 1.052019905s 1.053358097s 1.054750074s 1.055627835s 1.05909156s 1.060134646s 1.060199523s 1.060565588s 1.062961846s 1.067104644s 1.067414561s 1.069094747s 1.069262553s 1.07037988s 1.072277894s 1.074736611s 1.075032811s 1.079414633s 1.080737615s 1.085933411s 1.086405424s 1.087125925s 1.08782278s 1.088096138s 1.088984288s 1.09067964s 1.09371483s 1.094319948s 1.094349932s 1.094678461s 1.095614565s 1.104369788s 1.105136633s 1.105949021s 1.114199713s 1.117781641s 1.123107401s 1.124052709s 1.124413704s 1.125544207s 1.126693828s 1.130446653s 1.130553975s 1.13089973s 1.131673239s 1.132888742s 1.135218178s 1.138641495s 1.153398725s 1.158564745s 1.163259352s 1.16531705s 1.165723417s 1.167500645s 1.168349102s 1.174920811s 1.17652059s 1.179090146s 1.179759394s 1.181169255s 1.182778688s 1.190840296s 1.202334413s 1.21046445s 1.215315714s 1.216571415s 1.221709673s 1.222717666s 1.225821386s 1.22725051s 1.229735684s 1.23445437s 1.237514594s 1.245433293s 1.246771744s 1.250346619s 1.258718785s 1.258976576s 1.271733158s 1.279344479s]
Oct 30 11:55:23.838: INFO: 50 %ile: 1.013151272s
Oct 30 11:55:23.838: INFO: 90 %ile: 1.182778688s
Oct 30 11:55:23.838: INFO: 99 %ile: 1.271733158s
Oct 30 11:55:23.838: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:55:23.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-8374" for this suite.
Oct 30 11:55:53.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:55:54.203: INFO: namespace svc-latency-8374 deletion completed in 30.348357777s

â€¢ [SLOW TEST:47.236 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:55:54.208: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 30 11:55:54.426: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:54.426: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:54.426: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:54.433: INFO: Number of nodes with available pods: 0
Oct 30 11:55:54.433: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 11:55:55.450: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:55.450: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:55.451: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:55.459: INFO: Number of nodes with available pods: 0
Oct 30 11:55:55.459: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 11:55:56.527: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:56.527: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:56.527: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:56.536: INFO: Number of nodes with available pods: 0
Oct 30 11:55:56.537: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 11:55:57.455: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:57.455: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:57.456: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:57.464: INFO: Number of nodes with available pods: 3
Oct 30 11:55:57.464: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Oct 30 11:55:57.588: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:57.589: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:57.589: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:57.613: INFO: Number of nodes with available pods: 2
Oct 30 11:55:57.613: INFO: Node koris-pipeline-56683fb-92514359-node-2 is running more than one daemon pod
Oct 30 11:55:58.639: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:58.639: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:58.639: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:58.651: INFO: Number of nodes with available pods: 2
Oct 30 11:55:58.651: INFO: Node koris-pipeline-56683fb-92514359-node-2 is running more than one daemon pod
Oct 30 11:55:59.626: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:59.626: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:59.626: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:55:59.642: INFO: Number of nodes with available pods: 2
Oct 30 11:55:59.642: INFO: Node koris-pipeline-56683fb-92514359-node-2 is running more than one daemon pod
Oct 30 11:56:00.675: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:56:00.675: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:56:00.675: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 11:56:00.692: INFO: Number of nodes with available pods: 3
Oct 30 11:56:00.692: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7962, will wait for the garbage collector to delete the pods
Oct 30 11:56:00.792: INFO: Deleting DaemonSet.extensions daemon-set took: 22.869301ms
Oct 30 11:56:01.192: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.391512ms
Oct 30 11:56:12.903: INFO: Number of nodes with available pods: 0
Oct 30 11:56:12.904: INFO: Number of running nodes: 0, number of available pods: 0
Oct 30 11:56:12.911: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7962/daemonsets","resourceVersion":"15017"},"items":null}

Oct 30 11:56:12.916: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7962/pods","resourceVersion":"15017"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:56:12.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7962" for this suite.
Oct 30 11:56:19.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:56:19.300: INFO: namespace daemonsets-7962 deletion completed in 6.340922586s

â€¢ [SLOW TEST:25.092 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:56:19.302: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 11:56:19.408: INFO: Creating ReplicaSet my-hostname-basic-48fac7cf-fb0c-11e9-91af-623cf93d857c
Oct 30 11:56:19.439: INFO: Pod name my-hostname-basic-48fac7cf-fb0c-11e9-91af-623cf93d857c: Found 0 pods out of 1
Oct 30 11:56:24.448: INFO: Pod name my-hostname-basic-48fac7cf-fb0c-11e9-91af-623cf93d857c: Found 1 pods out of 1
Oct 30 11:56:24.448: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-48fac7cf-fb0c-11e9-91af-623cf93d857c" is running
Oct 30 11:56:24.457: INFO: Pod "my-hostname-basic-48fac7cf-fb0c-11e9-91af-623cf93d857c-sj787" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-30 11:56:19 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-30 11:56:21 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-30 11:56:21 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-30 11:56:19 +0000 UTC Reason: Message:}])
Oct 30 11:56:24.457: INFO: Trying to dial the pod
Oct 30 11:56:29.484: INFO: Controller my-hostname-basic-48fac7cf-fb0c-11e9-91af-623cf93d857c: Got expected result from replica 1 [my-hostname-basic-48fac7cf-fb0c-11e9-91af-623cf93d857c-sj787]: "my-hostname-basic-48fac7cf-fb0c-11e9-91af-623cf93d857c-sj787", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:56:29.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1878" for this suite.
Oct 30 11:56:35.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:56:35.785: INFO: namespace replicaset-1878 deletion completed in 6.29191858s

â€¢ [SLOW TEST:16.483 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:56:35.787: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 11:56:35.899: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52caff06-fb0c-11e9-91af-623cf93d857c" in namespace "projected-7795" to be "success or failure"
Oct 30 11:56:35.914: INFO: Pod "downwardapi-volume-52caff06-fb0c-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 15.271125ms
Oct 30 11:56:37.923: INFO: Pod "downwardapi-volume-52caff06-fb0c-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023899727s
Oct 30 11:56:39.934: INFO: Pod "downwardapi-volume-52caff06-fb0c-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035243493s
STEP: Saw pod success
Oct 30 11:56:39.934: INFO: Pod "downwardapi-volume-52caff06-fb0c-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 11:56:39.946: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod downwardapi-volume-52caff06-fb0c-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 11:56:40.034: INFO: Waiting for pod downwardapi-volume-52caff06-fb0c-11e9-91af-623cf93d857c to disappear
Oct 30 11:56:40.045: INFO: Pod downwardapi-volume-52caff06-fb0c-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 11:56:40.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7795" for this suite.
Oct 30 11:56:46.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 11:56:46.350: INFO: namespace projected-7795 deletion completed in 6.295101266s

â€¢ [SLOW TEST:10.564 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 11:56:46.357: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6463
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-6463
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6463
Oct 30 11:56:46.491: INFO: Found 0 stateful pods, waiting for 1
Oct 30 11:56:56.500: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Oct 30 11:56:56.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 11:56:56.835: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 11:56:56.835: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 11:56:56.835: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 11:56:56.843: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 30 11:57:06.853: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 30 11:57:06.854: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 11:57:06.907: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Oct 30 11:57:06.907: INFO: ss-0  koris-pipeline-56683fb-92514359-node-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  }]
Oct 30 11:57:06.907: INFO: 
Oct 30 11:57:06.907: INFO: StatefulSet ss has not reached scale 3, at 1
Oct 30 11:57:07.922: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.976877837s
Oct 30 11:57:08.934: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.961802432s
Oct 30 11:57:09.945: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.950682281s
Oct 30 11:57:10.955: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.939572587s
Oct 30 11:57:11.967: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.929723282s
Oct 30 11:57:12.978: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.917686099s
Oct 30 11:57:13.989: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.906021493s
Oct 30 11:57:14.997: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.894931396s
Oct 30 11:57:16.019: INFO: Verifying statefulset ss doesn't scale past 3 for another 886.824853ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6463
Oct 30 11:57:17.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:57:17.327: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 30 11:57:17.327: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 11:57:17.327: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 11:57:17.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:57:17.669: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 30 11:57:17.669: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 11:57:17.669: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 11:57:17.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:57:17.978: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 30 11:57:17.978: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 11:57:17.978: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 11:57:17.989: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 11:57:17.989: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 11:57:17.989: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Oct 30 11:57:17.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 11:57:18.299: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 11:57:18.299: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 11:57:18.299: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 11:57:18.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 11:57:18.584: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 11:57:18.584: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 11:57:18.584: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 11:57:18.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 11:57:18.913: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 11:57:18.913: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 11:57:18.913: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 11:57:18.913: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 11:57:18.924: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct 30 11:57:28.945: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 30 11:57:28.945: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 30 11:57:28.945: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 30 11:57:28.975: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Oct 30 11:57:28.975: INFO: ss-0  koris-pipeline-56683fb-92514359-node-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  }]
Oct 30 11:57:28.975: INFO: ss-1  koris-pipeline-56683fb-92514359-node-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  }]
Oct 30 11:57:28.975: INFO: ss-2  koris-pipeline-56683fb-92514359-node-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  }]
Oct 30 11:57:28.975: INFO: 
Oct 30 11:57:28.975: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 30 11:57:29.984: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Oct 30 11:57:29.984: INFO: ss-0  koris-pipeline-56683fb-92514359-node-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  }]
Oct 30 11:57:29.984: INFO: ss-1  koris-pipeline-56683fb-92514359-node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  }]
Oct 30 11:57:29.984: INFO: ss-2  koris-pipeline-56683fb-92514359-node-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  }]
Oct 30 11:57:29.984: INFO: 
Oct 30 11:57:29.984: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 30 11:57:30.997: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Oct 30 11:57:30.997: INFO: ss-0  koris-pipeline-56683fb-92514359-node-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  }]
Oct 30 11:57:30.997: INFO: ss-1  koris-pipeline-56683fb-92514359-node-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  }]
Oct 30 11:57:30.997: INFO: ss-2  koris-pipeline-56683fb-92514359-node-3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  }]
Oct 30 11:57:30.997: INFO: 
Oct 30 11:57:30.997: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 30 11:57:32.011: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Oct 30 11:57:32.011: INFO: ss-0  koris-pipeline-56683fb-92514359-node-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  }]
Oct 30 11:57:32.011: INFO: ss-2  koris-pipeline-56683fb-92514359-node-3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  }]
Oct 30 11:57:32.011: INFO: 
Oct 30 11:57:32.011: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 30 11:57:33.022: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Oct 30 11:57:33.022: INFO: ss-0  koris-pipeline-56683fb-92514359-node-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  }]
Oct 30 11:57:33.022: INFO: ss-2  koris-pipeline-56683fb-92514359-node-3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  }]
Oct 30 11:57:33.022: INFO: 
Oct 30 11:57:33.022: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 30 11:57:34.031: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Oct 30 11:57:34.031: INFO: ss-0  koris-pipeline-56683fb-92514359-node-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  }]
Oct 30 11:57:34.031: INFO: ss-2  koris-pipeline-56683fb-92514359-node-3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  }]
Oct 30 11:57:34.032: INFO: 
Oct 30 11:57:34.032: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 30 11:57:35.041: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Oct 30 11:57:35.041: INFO: ss-0  koris-pipeline-56683fb-92514359-node-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  }]
Oct 30 11:57:35.041: INFO: ss-2  koris-pipeline-56683fb-92514359-node-3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  }]
Oct 30 11:57:35.041: INFO: 
Oct 30 11:57:35.041: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 30 11:57:36.051: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Oct 30 11:57:36.051: INFO: ss-0  koris-pipeline-56683fb-92514359-node-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  }]
Oct 30 11:57:36.051: INFO: ss-2  koris-pipeline-56683fb-92514359-node-3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  }]
Oct 30 11:57:36.051: INFO: 
Oct 30 11:57:36.051: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 30 11:57:37.062: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Oct 30 11:57:37.062: INFO: ss-0  koris-pipeline-56683fb-92514359-node-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:56:46 +0000 UTC  }]
Oct 30 11:57:37.062: INFO: ss-2  koris-pipeline-56683fb-92514359-node-3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  }]
Oct 30 11:57:37.062: INFO: 
Oct 30 11:57:37.062: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 30 11:57:38.072: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Oct 30 11:57:38.073: INFO: ss-2  koris-pipeline-56683fb-92514359-node-3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 11:57:06 +0000 UTC  }]
Oct 30 11:57:38.073: INFO: 
Oct 30 11:57:38.073: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6463
Oct 30 11:57:39.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:57:39.276: INFO: rc: 1
Oct 30 11:57:39.277: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc0020f8db0 exit status 1 <nil> <nil> true [0xc00242a1e0 0xc00242a1f8 0xc00242a210] [0xc00242a1e0 0xc00242a1f8 0xc00242a210] [0xc00242a1f0 0xc00242a208] [0xb916c0 0xb916c0] 0xc001d9e4e0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Oct 30 11:57:49.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:57:49.386: INFO: rc: 1
Oct 30 11:57:49.387: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0020f9140 exit status 1 <nil> <nil> true [0xc00242a218 0xc00242a230 0xc00242a248] [0xc00242a218 0xc00242a230 0xc00242a248] [0xc00242a228 0xc00242a240] [0xb916c0 0xb916c0] 0xc001d9eba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 11:57:59.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:57:59.501: INFO: rc: 1
Oct 30 11:57:59.502: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0020f94a0 exit status 1 <nil> <nil> true [0xc00242a250 0xc00242a268 0xc00242a280] [0xc00242a250 0xc00242a268 0xc00242a280] [0xc00242a260 0xc00242a278] [0xb916c0 0xb916c0] 0xc001d9f260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 11:58:09.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:58:09.609: INFO: rc: 1
Oct 30 11:58:09.609: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002fbc5a0 exit status 1 <nil> <nil> true [0xc001388b68 0xc001388c60 0xc001388d18] [0xc001388b68 0xc001388c60 0xc001388d18] [0xc001388be8 0xc001388ce0] [0xb916c0 0xb916c0] 0xc00217d8c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 11:58:19.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:58:19.724: INFO: rc: 1
Oct 30 11:58:19.724: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002fbc930 exit status 1 <nil> <nil> true [0xc001388d38 0xc001388db8 0xc001388ea8] [0xc001388d38 0xc001388db8 0xc001388ea8] [0xc001388da8 0xc001388e70] [0xb916c0 0xb916c0] 0xc00217df20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 11:58:29.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:58:29.841: INFO: rc: 1
Oct 30 11:58:29.842: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0022a51d0 exit status 1 <nil> <nil> true [0xc000011820 0xc000011898 0xc000011b68] [0xc000011820 0xc000011898 0xc000011b68] [0xc000011860 0xc000011900] [0xb916c0 0xb916c0] 0xc002121e60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 11:58:39.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:58:39.957: INFO: rc: 1
Oct 30 11:58:39.958: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001364ea0 exit status 1 <nil> <nil> true [0xc00018f8a0 0xc00018f950 0xc00018fb48] [0xc00018f8a0 0xc00018f950 0xc00018fb48] [0xc00018f8d0 0xc00018fb20] [0xb916c0 0xb916c0] 0xc001dcd260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 11:58:49.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:58:50.081: INFO: rc: 1
Oct 30 11:58:50.081: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001365230 exit status 1 <nil> <nil> true [0xc0009c6040 0xc0009c62a0 0xc0009c64f8] [0xc0009c6040 0xc0009c62a0 0xc0009c64f8] [0xc0009c61d0 0xc0009c6380] [0xb916c0 0xb916c0] 0xc001dcdb60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 11:59:00.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:59:00.197: INFO: rc: 1
Oct 30 11:59:00.197: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002fbccc0 exit status 1 <nil> <nil> true [0xc001388ef0 0xc001389030 0xc0013890e8] [0xc001388ef0 0xc001389030 0xc0013890e8] [0xc001388f90 0xc0013890a8] [0xb916c0 0xb916c0] 0xc002c4ce40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 11:59:10.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:59:10.308: INFO: rc: 1
Oct 30 11:59:10.308: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0022a5560 exit status 1 <nil> <nil> true [0xc000011bd0 0xc000011cd0 0xc000011d50] [0xc000011bd0 0xc000011cd0 0xc000011d50] [0xc000011c60 0xc000011d40] [0xb916c0 0xb916c0] 0xc0028c2300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 11:59:20.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:59:20.418: INFO: rc: 1
Oct 30 11:59:20.418: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001bf83c0 exit status 1 <nil> <nil> true [0xc00018e2f0 0xc00018f850 0xc00018f8b0] [0xc00018e2f0 0xc00018f850 0xc00018f8b0] [0xc00018f820 0xc00018f8a0] [0xb916c0 0xb916c0] 0xc00217c4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 11:59:30.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:59:30.544: INFO: rc: 1
Oct 30 11:59:30.544: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001bf8750 exit status 1 <nil> <nil> true [0xc00018f8d0 0xc00018fb20 0xc001388000] [0xc00018f8d0 0xc00018fb20 0xc001388000] [0xc00018fa60 0xc0000cc5b8] [0xb916c0 0xb916c0] 0xc00217cba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 11:59:40.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:59:40.650: INFO: rc: 1
Oct 30 11:59:40.651: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001bf8ae0 exit status 1 <nil> <nil> true [0xc001388230 0xc001388378 0xc0013884a8] [0xc001388230 0xc001388378 0xc0013884a8] [0xc001388310 0xc001388450] [0xb916c0 0xb916c0] 0xc00217d260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 11:59:50.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 11:59:50.768: INFO: rc: 1
Oct 30 11:59:50.769: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00330c330 exit status 1 <nil> <nil> true [0xc0009c6040 0xc0009c62a0 0xc0009c64f8] [0xc0009c6040 0xc0009c62a0 0xc0009c64f8] [0xc0009c61d0 0xc0009c6380] [0xb916c0 0xb916c0] 0xc0029aa2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 12:00:00.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:00:00.877: INFO: rc: 1
Oct 30 12:00:00.877: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001bf8e70 exit status 1 <nil> <nil> true [0xc001388548 0xc001388860 0xc0013888a0] [0xc001388548 0xc001388860 0xc0013888a0] [0xc001388800 0xc001388880] [0xb916c0 0xb916c0] 0xc00217d980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 12:00:10.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:00:10.994: INFO: rc: 1
Oct 30 12:00:10.994: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00330c6f0 exit status 1 <nil> <nil> true [0xc0009c6528 0xc0009c6608 0xc0009c67b8] [0xc0009c6528 0xc0009c6608 0xc0009c67b8] [0xc0009c6588 0xc0009c66e0] [0xb916c0 0xb916c0] 0xc0029aa600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 12:00:20.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:00:21.109: INFO: rc: 1
Oct 30 12:00:21.109: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0029503f0 exit status 1 <nil> <nil> true [0xc000010330 0xc0000106b0 0xc0000108c0] [0xc000010330 0xc0000106b0 0xc0000108c0] [0xc000010648 0xc000010870] [0xb916c0 0xb916c0] 0xc0021204e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 12:00:31.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:00:31.225: INFO: rc: 1
Oct 30 12:00:31.225: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001bf91d0 exit status 1 <nil> <nil> true [0xc0013888b8 0xc001388998 0xc001388a78] [0xc0013888b8 0xc001388998 0xc001388a78] [0xc001388938 0xc001388a20] [0xb916c0 0xb916c0] 0xc002c4c300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 12:00:41.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:00:41.341: INFO: rc: 1
Oct 30 12:00:41.341: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002af0360 exit status 1 <nil> <nil> true [0xc00242a000 0xc00242a018 0xc00242a030] [0xc00242a000 0xc00242a018 0xc00242a030] [0xc00242a010 0xc00242a028] [0xb916c0 0xb916c0] 0xc001dcc420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 12:00:51.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:00:51.458: INFO: rc: 1
Oct 30 12:00:51.458: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00330cc00 exit status 1 <nil> <nil> true [0xc0009c6878 0xc0009c6950 0xc0009c6a28] [0xc0009c6878 0xc0009c6950 0xc0009c6a28] [0xc0009c68d0 0xc0009c69f8] [0xb916c0 0xb916c0] 0xc0029aaa20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 12:01:01.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:01:01.574: INFO: rc: 1
Oct 30 12:01:01.574: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002af0720 exit status 1 <nil> <nil> true [0xc00242a038 0xc00242a050 0xc00242a068] [0xc00242a038 0xc00242a050 0xc00242a068] [0xc00242a048 0xc00242a060] [0xb916c0 0xb916c0] 0xc001dcccc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 12:01:11.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:01:11.689: INFO: rc: 1
Oct 30 12:01:11.689: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0029507b0 exit status 1 <nil> <nil> true [0xc000010918 0xc0000109d0 0xc000010c60] [0xc000010918 0xc0000109d0 0xc000010c60] [0xc0000109a0 0xc000010b70] [0xb916c0 0xb916c0] 0xc002120b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 12:01:21.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:01:21.796: INFO: rc: 1
Oct 30 12:01:21.797: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001bf83f0 exit status 1 <nil> <nil> true [0xc00018e000 0xc00018f820 0xc00018f8a0] [0xc00018e000 0xc00018f820 0xc00018f8a0] [0xc00018e3f0 0xc00018f880] [0xb916c0 0xb916c0] 0xc00217c4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 12:01:31.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:01:31.922: INFO: rc: 1
Oct 30 12:01:31.922: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002950360 exit status 1 <nil> <nil> true [0xc001388000 0xc001388310 0xc001388450] [0xc001388000 0xc001388310 0xc001388450] [0xc001388278 0xc0013883e0] [0xb916c0 0xb916c0] 0xc002c4cde0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 12:01:41.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:01:42.038: INFO: rc: 1
Oct 30 12:01:42.039: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0029506f0 exit status 1 <nil> <nil> true [0xc0013884a8 0xc001388800 0xc001388880] [0xc0013884a8 0xc001388800 0xc001388880] [0xc0013887e0 0xc001388868] [0xb916c0 0xb916c0] 0xc002c4d2c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 12:01:52.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:01:52.152: INFO: rc: 1
Oct 30 12:01:52.152: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001bf87e0 exit status 1 <nil> <nil> true [0xc00018f8b0 0xc00018fa60 0xc000010330] [0xc00018f8b0 0xc00018fa60 0xc000010330] [0xc00018f950 0xc00018fb48] [0xb916c0 0xb916c0] 0xc00217cba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 12:02:02.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:02:02.273: INFO: rc: 1
Oct 30 12:02:02.273: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00330c390 exit status 1 <nil> <nil> true [0xc0009c6040 0xc0009c62a0 0xc0009c64f8] [0xc0009c6040 0xc0009c62a0 0xc0009c64f8] [0xc0009c61d0 0xc0009c6380] [0xb916c0 0xb916c0] 0xc0021204e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 12:02:12.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:02:12.388: INFO: rc: 1
Oct 30 12:02:12.388: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002af03f0 exit status 1 <nil> <nil> true [0xc00242a000 0xc00242a018 0xc00242a030] [0xc00242a000 0xc00242a018 0xc00242a030] [0xc00242a010 0xc00242a028] [0xb916c0 0xb916c0] 0xc0029aa2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 12:02:22.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:02:22.491: INFO: rc: 1
Oct 30 12:02:22.491: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002af07b0 exit status 1 <nil> <nil> true [0xc00242a038 0xc00242a050 0xc00242a068] [0xc00242a038 0xc00242a050 0xc00242a068] [0xc00242a048 0xc00242a060] [0xb916c0 0xb916c0] 0xc0029aa600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 12:02:32.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:02:32.608: INFO: rc: 1
Oct 30 12:02:32.608: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001bf8b70 exit status 1 <nil> <nil> true [0xc000010560 0xc000010708 0xc000010918] [0xc000010560 0xc000010708 0xc000010918] [0xc0000106b0 0xc0000108c0] [0xb916c0 0xb916c0] 0xc00217d260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 30 12:02:42.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6463 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:02:42.722: INFO: rc: 1
Oct 30 12:02:42.723: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Oct 30 12:02:42.723: INFO: Scaling statefulset ss to 0
Oct 30 12:02:42.770: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 30 12:02:42.776: INFO: Deleting all statefulset in ns statefulset-6463
Oct 30 12:02:42.786: INFO: Scaling statefulset ss to 0
Oct 30 12:02:42.808: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 12:02:42.820: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:02:42.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6463" for this suite.
Oct 30 12:02:48.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:02:49.173: INFO: namespace statefulset-6463 deletion completed in 6.304371187s

â€¢ [SLOW TEST:362.816 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:02:49.178: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-3044
Oct 30 12:02:53.305: INFO: Started pod liveness-exec in namespace container-probe-3044
STEP: checking the pod's current state and verifying that restartCount is present
Oct 30 12:02:53.312: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:06:54.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3044" for this suite.
Oct 30 12:07:00.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:07:00.867: INFO: namespace container-probe-3044 deletion completed in 6.320326178s

â€¢ [SLOW TEST:251.689 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:07:00.872: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1030 12:07:07.056578      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 30 12:07:07.056: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:07:07.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2120" for this suite.
Oct 30 12:07:15.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:07:15.370: INFO: namespace gc-2120 deletion completed in 8.303746018s

â€¢ [SLOW TEST:14.498 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:07:15.371: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Oct 30 12:07:15.489: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:07:18.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9088" for this suite.
Oct 30 12:07:25.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:07:25.279: INFO: namespace init-container-9088 deletion completed in 6.294699496s

â€¢ [SLOW TEST:9.908 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:07:25.281: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1576
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 30 12:07:25.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-553'
Oct 30 12:07:26.117: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 30 12:07:26.117: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1581
Oct 30 12:07:26.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 delete jobs e2e-test-nginx-job --namespace=kubectl-553'
Oct 30 12:07:26.302: INFO: stderr: ""
Oct 30 12:07:26.302: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:07:26.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-553" for this suite.
Oct 30 12:07:32.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:07:32.609: INFO: namespace kubectl-553 deletion completed in 6.293731726s

â€¢ [SLOW TEST:7.328 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:07:32.611: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-da509db6-fb0d-11e9-91af-623cf93d857c
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:07:36.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9404" for this suite.
Oct 30 12:08:00.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:08:01.195: INFO: namespace configmap-9404 deletion completed in 24.330281273s

â€¢ [SLOW TEST:28.584 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:08:01.197: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:08:01.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9763" for this suite.
Oct 30 12:08:07.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:08:07.641: INFO: namespace services-9763 deletion completed in 6.322117201s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

â€¢ [SLOW TEST:6.444 seconds]
[sig-network] Services
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:08:07.641: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 30 12:08:07.806: INFO: Waiting up to 5m0s for pod "pod-ef2c8f4c-fb0d-11e9-91af-623cf93d857c" in namespace "emptydir-5175" to be "success or failure"
Oct 30 12:08:07.817: INFO: Pod "pod-ef2c8f4c-fb0d-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.981916ms
Oct 30 12:08:09.826: INFO: Pod "pod-ef2c8f4c-fb0d-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020128847s
Oct 30 12:08:11.836: INFO: Pod "pod-ef2c8f4c-fb0d-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03012788s
STEP: Saw pod success
Oct 30 12:08:11.836: INFO: Pod "pod-ef2c8f4c-fb0d-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:08:11.843: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-ef2c8f4c-fb0d-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 12:08:11.895: INFO: Waiting for pod pod-ef2c8f4c-fb0d-11e9-91af-623cf93d857c to disappear
Oct 30 12:08:11.900: INFO: Pod pod-ef2c8f4c-fb0d-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:08:11.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5175" for this suite.
Oct 30 12:08:17.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:08:18.320: INFO: namespace emptydir-5175 deletion completed in 6.398506702s

â€¢ [SLOW TEST:10.678 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:08:18.321: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Oct 30 12:08:24.565: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1175 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 12:08:24.565: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 12:08:24.747: INFO: Exec stderr: ""
Oct 30 12:08:24.747: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1175 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 12:08:24.748: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 12:08:24.906: INFO: Exec stderr: ""
Oct 30 12:08:24.906: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1175 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 12:08:24.906: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 12:08:25.084: INFO: Exec stderr: ""
Oct 30 12:08:25.084: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1175 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 12:08:25.084: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 12:08:25.235: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Oct 30 12:08:25.235: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1175 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 12:08:25.235: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 12:08:25.396: INFO: Exec stderr: ""
Oct 30 12:08:25.396: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1175 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 12:08:25.396: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 12:08:25.549: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Oct 30 12:08:25.550: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1175 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 12:08:25.550: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 12:08:25.708: INFO: Exec stderr: ""
Oct 30 12:08:25.708: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1175 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 12:08:25.708: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 12:08:25.868: INFO: Exec stderr: ""
Oct 30 12:08:25.868: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1175 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 12:08:25.869: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 12:08:26.042: INFO: Exec stderr: ""
Oct 30 12:08:26.042: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1175 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 12:08:26.042: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 12:08:26.209: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:08:26.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-1175" for this suite.
Oct 30 12:09:10.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:09:10.526: INFO: namespace e2e-kubelet-etc-hosts-1175 deletion completed in 44.30185111s

â€¢ [SLOW TEST:52.205 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:09:10.527: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:09:38.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5301" for this suite.
Oct 30 12:09:44.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:09:44.341: INFO: namespace namespaces-5301 deletion completed in 6.30416533s
STEP: Destroying namespace "nsdeletetest-4101" for this suite.
Oct 30 12:09:44.348: INFO: Namespace nsdeletetest-4101 was already deleted
STEP: Destroying namespace "nsdeletetest-3234" for this suite.
Oct 30 12:09:50.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:09:50.665: INFO: namespace nsdeletetest-3234 deletion completed in 6.316275993s

â€¢ [SLOW TEST:40.137 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:09:50.666: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Oct 30 12:09:50.747: INFO: namespace kubectl-5583
Oct 30 12:09:50.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 create -f - --namespace=kubectl-5583'
Oct 30 12:09:51.155: INFO: stderr: ""
Oct 30 12:09:51.155: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 30 12:09:52.165: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 12:09:52.165: INFO: Found 0 / 1
Oct 30 12:09:53.163: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 12:09:53.163: INFO: Found 0 / 1
Oct 30 12:09:54.167: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 12:09:54.167: INFO: Found 1 / 1
Oct 30 12:09:54.167: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 30 12:09:54.175: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 12:09:54.175: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 30 12:09:54.175: INFO: wait on redis-master startup in kubectl-5583 
Oct 30 12:09:54.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 logs redis-master-ntfns redis-master --namespace=kubectl-5583'
Oct 30 12:09:54.333: INFO: stderr: ""
Oct 30 12:09:54.333: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 30 Oct 12:09:52.822 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 30 Oct 12:09:52.822 # Server started, Redis version 3.2.12\n1:M 30 Oct 12:09:52.823 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 30 Oct 12:09:52.823 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Oct 30 12:09:54.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-5583'
Oct 30 12:09:54.518: INFO: stderr: ""
Oct 30 12:09:54.518: INFO: stdout: "service/rm2 exposed\n"
Oct 30 12:09:54.529: INFO: Service rm2 in namespace kubectl-5583 found.
STEP: exposing service
Oct 30 12:09:56.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-5583'
Oct 30 12:09:56.716: INFO: stderr: ""
Oct 30 12:09:56.716: INFO: stdout: "service/rm3 exposed\n"
Oct 30 12:09:56.731: INFO: Service rm3 in namespace kubectl-5583 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:09:58.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5583" for this suite.
Oct 30 12:10:22.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:10:23.067: INFO: namespace kubectl-5583 deletion completed in 24.307475016s

â€¢ [SLOW TEST:32.401 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:10:23.068: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-vn28
STEP: Creating a pod to test atomic-volume-subpath
Oct 30 12:10:23.281: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-vn28" in namespace "subpath-1155" to be "success or failure"
Oct 30 12:10:23.294: INFO: Pod "pod-subpath-test-secret-vn28": Phase="Pending", Reason="", readiness=false. Elapsed: 12.76712ms
Oct 30 12:10:25.305: INFO: Pod "pod-subpath-test-secret-vn28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02369545s
Oct 30 12:10:27.314: INFO: Pod "pod-subpath-test-secret-vn28": Phase="Running", Reason="", readiness=true. Elapsed: 4.032634728s
Oct 30 12:10:29.324: INFO: Pod "pod-subpath-test-secret-vn28": Phase="Running", Reason="", readiness=true. Elapsed: 6.043021258s
Oct 30 12:10:31.334: INFO: Pod "pod-subpath-test-secret-vn28": Phase="Running", Reason="", readiness=true. Elapsed: 8.053184764s
Oct 30 12:10:33.343: INFO: Pod "pod-subpath-test-secret-vn28": Phase="Running", Reason="", readiness=true. Elapsed: 10.06213211s
Oct 30 12:10:35.354: INFO: Pod "pod-subpath-test-secret-vn28": Phase="Running", Reason="", readiness=true. Elapsed: 12.073249895s
Oct 30 12:10:37.363: INFO: Pod "pod-subpath-test-secret-vn28": Phase="Running", Reason="", readiness=true. Elapsed: 14.081950025s
Oct 30 12:10:39.372: INFO: Pod "pod-subpath-test-secret-vn28": Phase="Running", Reason="", readiness=true. Elapsed: 16.091028844s
Oct 30 12:10:41.380: INFO: Pod "pod-subpath-test-secret-vn28": Phase="Running", Reason="", readiness=true. Elapsed: 18.098696272s
Oct 30 12:10:43.389: INFO: Pod "pod-subpath-test-secret-vn28": Phase="Running", Reason="", readiness=true. Elapsed: 20.10786208s
Oct 30 12:10:45.399: INFO: Pod "pod-subpath-test-secret-vn28": Phase="Running", Reason="", readiness=true. Elapsed: 22.117355462s
Oct 30 12:10:47.409: INFO: Pod "pod-subpath-test-secret-vn28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.128092109s
STEP: Saw pod success
Oct 30 12:10:47.409: INFO: Pod "pod-subpath-test-secret-vn28" satisfied condition "success or failure"
Oct 30 12:10:47.419: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-subpath-test-secret-vn28 container test-container-subpath-secret-vn28: <nil>
STEP: delete the pod
Oct 30 12:10:47.474: INFO: Waiting for pod pod-subpath-test-secret-vn28 to disappear
Oct 30 12:10:47.481: INFO: Pod pod-subpath-test-secret-vn28 no longer exists
STEP: Deleting pod pod-subpath-test-secret-vn28
Oct 30 12:10:47.481: INFO: Deleting pod "pod-subpath-test-secret-vn28" in namespace "subpath-1155"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:10:47.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1155" for this suite.
Oct 30 12:10:53.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:10:53.808: INFO: namespace subpath-1155 deletion completed in 6.310991967s

â€¢ [SLOW TEST:30.740 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:10:53.814: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Oct 30 12:10:53.929: INFO: Waiting up to 5m0s for pod "client-containers-5238b68c-fb0e-11e9-91af-623cf93d857c" in namespace "containers-7809" to be "success or failure"
Oct 30 12:10:53.937: INFO: Pod "client-containers-5238b68c-fb0e-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.388265ms
Oct 30 12:10:55.952: INFO: Pod "client-containers-5238b68c-fb0e-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022237648s
Oct 30 12:10:57.963: INFO: Pod "client-containers-5238b68c-fb0e-11e9-91af-623cf93d857c": Phase="Running", Reason="", readiness=true. Elapsed: 4.033947906s
Oct 30 12:10:59.974: INFO: Pod "client-containers-5238b68c-fb0e-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044797798s
STEP: Saw pod success
Oct 30 12:10:59.975: INFO: Pod "client-containers-5238b68c-fb0e-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:10:59.981: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod client-containers-5238b68c-fb0e-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 12:11:00.056: INFO: Waiting for pod client-containers-5238b68c-fb0e-11e9-91af-623cf93d857c to disappear
Oct 30 12:11:00.063: INFO: Pod client-containers-5238b68c-fb0e-11e9-91af-623cf93d857c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:11:00.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7809" for this suite.
Oct 30 12:11:06.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:11:06.420: INFO: namespace containers-7809 deletion completed in 6.345098637s

â€¢ [SLOW TEST:12.607 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:11:06.421: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct 30 12:11:06.504: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 30 12:11:06.524: INFO: Waiting for terminating namespaces to be deleted...
Oct 30 12:11:06.533: INFO: 
Logging pods the kubelet thinks is on node koris-pipeline-56683fb-92514359-node-1 before test
Oct 30 12:11:06.555: INFO: calico-node-mt5gd from kube-system started at 2019-10-30 11:07:21 +0000 UTC (2 container statuses recorded)
Oct 30 12:11:06.555: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 12:11:06.555: INFO: 	Container install-cni ready: true, restart count 0
Oct 30 12:11:06.555: INFO: nginx-blue-7f86974c47-f726v from default started at 2019-10-30 11:08:16 +0000 UTC (1 container statuses recorded)
Oct 30 12:11:06.555: INFO: 	Container nginx ready: true, restart count 0
Oct 30 12:11:06.555: INFO: sonobuoy-e2e-job-18cfb8e951354e9a from sonobuoy started at 2019-10-30 11:23:03 +0000 UTC (2 container statuses recorded)
Oct 30 12:11:06.555: INFO: 	Container e2e ready: true, restart count 0
Oct 30 12:11:06.555: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 12:11:06.555: INFO: sonobuoy-systemd-logs-daemon-set-aac87c55e38d426f-w56kw from sonobuoy started at 2019-10-30 11:23:03 +0000 UTC (2 container statuses recorded)
Oct 30 12:11:06.555: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 12:11:06.555: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 12:11:06.555: INFO: kube-proxy-246h7 from kube-system started at 2019-10-30 11:07:20 +0000 UTC (1 container statuses recorded)
Oct 30 12:11:06.555: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 30 12:11:06.555: INFO: 
Logging pods the kubelet thinks is on node koris-pipeline-56683fb-92514359-node-2 before test
Oct 30 12:11:06.573: INFO: nginx-ingress-controller-6cfd5b6544-pzmdd from ingress-nginx started at 2019-10-30 11:06:36 +0000 UTC (1 container statuses recorded)
Oct 30 12:11:06.574: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 30 12:11:06.574: INFO: kube-proxy-sms4r from kube-system started at 2019-10-30 11:06:15 +0000 UTC (1 container statuses recorded)
Oct 30 12:11:06.574: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 30 12:11:06.574: INFO: calico-node-cwjt4 from kube-system started at 2019-10-30 11:06:15 +0000 UTC (2 container statuses recorded)
Oct 30 12:11:06.574: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 12:11:06.574: INFO: 	Container install-cni ready: true, restart count 0
Oct 30 12:11:06.574: INFO: dnscheck from default started at 2019-10-30 11:06:35 +0000 UTC (1 container statuses recorded)
Oct 30 12:11:06.574: INFO: 	Container dnscheck ready: true, restart count 0
Oct 30 12:11:06.574: INFO: external-http-nginx-deployment-56db997f77-klncq from default started at 2019-10-30 11:06:35 +0000 UTC (1 container statuses recorded)
Oct 30 12:11:06.574: INFO: 	Container nginx ready: true, restart count 0
Oct 30 12:11:06.574: INFO: external-http-nginx-deployment-56db997f77-jsv9j from default started at 2019-10-30 11:06:35 +0000 UTC (1 container statuses recorded)
Oct 30 12:11:06.574: INFO: 	Container nginx ready: true, restart count 0
Oct 30 12:11:06.574: INFO: metrics-server-5845cc8fd4-w8vxn from kube-system started at 2019-10-30 11:06:35 +0000 UTC (1 container statuses recorded)
Oct 30 12:11:06.574: INFO: 	Container metrics-server ready: true, restart count 0
Oct 30 12:11:06.574: INFO: sonobuoy-systemd-logs-daemon-set-aac87c55e38d426f-vrllw from sonobuoy started at 2019-10-30 11:23:04 +0000 UTC (2 container statuses recorded)
Oct 30 12:11:06.574: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 12:11:06.574: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 12:11:06.574: INFO: 
Logging pods the kubelet thinks is on node koris-pipeline-56683fb-92514359-node-3 before test
Oct 30 12:11:06.586: INFO: kube-proxy-ds6hw from kube-system started at 2019-10-30 11:07:23 +0000 UTC (1 container statuses recorded)
Oct 30 12:11:06.587: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 30 12:11:06.587: INFO: nginx-green-56c79bbc4d-z8m7q from default started at 2019-10-30 11:08:16 +0000 UTC (1 container statuses recorded)
Oct 30 12:11:06.587: INFO: 	Container nginx ready: true, restart count 0
Oct 30 12:11:06.587: INFO: sonobuoy from sonobuoy started at 2019-10-30 11:22:56 +0000 UTC (1 container statuses recorded)
Oct 30 12:11:06.587: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 30 12:11:06.587: INFO: sonobuoy-systemd-logs-daemon-set-aac87c55e38d426f-4ckdm from sonobuoy started at 2019-10-30 11:23:04 +0000 UTC (2 container statuses recorded)
Oct 30 12:11:06.587: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 30 12:11:06.587: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 30 12:11:06.587: INFO: calico-node-h9krs from kube-system started at 2019-10-30 11:07:23 +0000 UTC (2 container statuses recorded)
Oct 30 12:11:06.588: INFO: 	Container calico-node ready: true, restart count 0
Oct 30 12:11:06.588: INFO: 	Container install-cni ready: true, restart count 0
Oct 30 12:11:06.588: INFO: kube-bench-node from default started at 2019-10-30 11:21:56 +0000 UTC (1 container statuses recorded)
Oct 30 12:11:06.588: INFO: 	Container kube-bench-node ready: false, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-5c3bf37d-fb0e-11e9-91af-623cf93d857c 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-5c3bf37d-fb0e-11e9-91af-623cf93d857c off the node koris-pipeline-56683fb-92514359-node-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-5c3bf37d-fb0e-11e9-91af-623cf93d857c
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:11:14.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8298" for this suite.
Oct 30 12:11:22.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:11:23.148: INFO: namespace sched-pred-8298 deletion completed in 8.305774578s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:16.727 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:11:23.150: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 12:11:23.322: INFO: Waiting up to 5m0s for pod "downwardapi-volume-63b5c46e-fb0e-11e9-91af-623cf93d857c" in namespace "projected-3622" to be "success or failure"
Oct 30 12:11:23.337: INFO: Pod "downwardapi-volume-63b5c46e-fb0e-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.864409ms
Oct 30 12:11:25.347: INFO: Pod "downwardapi-volume-63b5c46e-fb0e-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025255449s
Oct 30 12:11:27.355: INFO: Pod "downwardapi-volume-63b5c46e-fb0e-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033665187s
STEP: Saw pod success
Oct 30 12:11:27.355: INFO: Pod "downwardapi-volume-63b5c46e-fb0e-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:11:27.364: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod downwardapi-volume-63b5c46e-fb0e-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 12:11:27.423: INFO: Waiting for pod downwardapi-volume-63b5c46e-fb0e-11e9-91af-623cf93d857c to disappear
Oct 30 12:11:27.429: INFO: Pod downwardapi-volume-63b5c46e-fb0e-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:11:27.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3622" for this suite.
Oct 30 12:11:33.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:11:33.726: INFO: namespace projected-3622 deletion completed in 6.288794322s

â€¢ [SLOW TEST:10.576 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:11:33.733: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 12:11:33.835: INFO: Creating deployment "nginx-deployment"
Oct 30 12:11:33.856: INFO: Waiting for observed generation 1
Oct 30 12:11:35.876: INFO: Waiting for all required pods to come up
Oct 30 12:11:35.886: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Oct 30 12:11:37.923: INFO: Waiting for deployment "nginx-deployment" to complete
Oct 30 12:11:37.937: INFO: Updating deployment "nginx-deployment" with a non-existent image
Oct 30 12:11:37.960: INFO: Updating deployment nginx-deployment
Oct 30 12:11:37.960: INFO: Waiting for observed generation 2
Oct 30 12:11:39.986: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct 30 12:11:39.997: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct 30 12:11:40.006: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 30 12:11:40.030: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct 30 12:11:40.030: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct 30 12:11:40.036: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 30 12:11:40.057: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Oct 30 12:11:40.057: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Oct 30 12:11:40.078: INFO: Updating deployment nginx-deployment
Oct 30 12:11:40.078: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Oct 30 12:11:40.119: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct 30 12:11:40.154: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 30 12:11:40.254: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-9808,SelfLink:/apis/apps/v1/namespaces/deployment-9808/deployments/nginx-deployment,UID:6a059ffe-fb0e-11e9-a053-fa163e61542c,ResourceVersion:18572,Generation:3,CreationTimestamp:2019-10-30 12:11:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-10-30 12:11:38 +0000 UTC 2019-10-30 12:11:33 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-b79c9d74d" is progressing.} {Available False 2019-10-30 12:11:40 +0000 UTC 2019-10-30 12:11:40 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Oct 30 12:11:40.323: INFO: New ReplicaSet "nginx-deployment-b79c9d74d" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d,GenerateName:,Namespace:deployment-9808,SelfLink:/apis/apps/v1/namespaces/deployment-9808/replicasets/nginx-deployment-b79c9d74d,UID:6c7b2317-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18553,Generation:3,CreationTimestamp:2019-10-30 12:11:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 6a059ffe-fb0e-11e9-a053-fa163e61542c 0xc0005505e7 0xc0005505e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 30 12:11:40.323: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Oct 30 12:11:40.324: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5,GenerateName:,Namespace:deployment-9808,SelfLink:/apis/apps/v1/namespaces/deployment-9808/replicasets/nginx-deployment-85db8c99c5,UID:6a08a1a7-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18593,Generation:3,CreationTimestamp:2019-10-30 12:11:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 6a059ffe-fb0e-11e9-a053-fa163e61542c 0xc000550507 0xc000550508}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Oct 30 12:11:40.376: INFO: Pod "nginx-deployment-85db8c99c5-2qpnc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-2qpnc,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-2qpnc,UID:6a25e61c-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18468,Generation:0,CreationTimestamp:2019-10-30 12:11:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.4.76/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc002412c87 0xc002412c88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002412cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002412d10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:34 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.39,PodIP:10.233.4.76,StartTime:2019-10-30 12:11:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-30 12:11:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0adaffdc556b354140cec5011a0fb2734757d96bd60903ff92612208b6badaab}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.377: INFO: Pod "nginx-deployment-85db8c99c5-4flz7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-4flz7,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-4flz7,UID:6a0d5e57-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18478,Generation:0,CreationTimestamp:2019-10-30 12:11:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.4.74/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc002412e10 0xc002412e11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002412e70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002412e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.39,PodIP:10.233.4.74,StartTime:2019-10-30 12:11:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-30 12:11:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f0d16dd7298af21ce5eceb5d7ee5e3c6eb663f564468756fdbc904e368d1a4c0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.377: INFO: Pod "nginx-deployment-85db8c99c5-57kkm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-57kkm,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-57kkm,UID:6dd1b5fc-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18606,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc002412f70 0xc002412f71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002412fd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002412ff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.377: INFO: Pod "nginx-deployment-85db8c99c5-6vj4q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-6vj4q,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-6vj4q,UID:6dc9bc9d-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18583,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc002413070 0xc002413071}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024130e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002413110}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.378: INFO: Pod "nginx-deployment-85db8c99c5-7gxgn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-7gxgn,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-7gxgn,UID:6a1feaa3-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18458,Generation:0,CreationTimestamp:2019-10-30 12:11:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.3.31/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc0024131c0 0xc0024131c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002413220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002413240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:34 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.41,PodIP:10.233.3.31,StartTime:2019-10-30 12:11:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-30 12:11:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://663afa0a8f701f6ca9d3f43844effa53ea37dd6bfa33e11de34a70d4907c5e9f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.378: INFO: Pod "nginx-deployment-85db8c99c5-997kl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-997kl,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-997kl,UID:6a20271e-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18466,Generation:0,CreationTimestamp:2019-10-30 12:11:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.5.61/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc002413320 0xc002413321}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002413380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024133a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:34 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.32,PodIP:10.233.5.61,StartTime:2019-10-30 12:11:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-30 12:11:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://64ceb211554e5e13a981cda52d8109aa77939f7e04450df8f37a19d3cf0006bf}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.378: INFO: Pod "nginx-deployment-85db8c99c5-bfs5t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-bfs5t,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-bfs5t,UID:6dc9de5b-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18588,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc002413470 0xc002413471}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024134e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002413500}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.379: INFO: Pod "nginx-deployment-85db8c99c5-bxwdt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-bxwdt,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-bxwdt,UID:6dc9a3e1-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18580,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc002413580 0xc002413581}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024135e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002413600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.379: INFO: Pod "nginx-deployment-85db8c99c5-cpbf9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-cpbf9,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-cpbf9,UID:6a0feffb-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18423,Generation:0,CreationTimestamp:2019-10-30 12:11:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.3.28/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc002413690 0xc002413691}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024136f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002413710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:34 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.41,PodIP:10.233.3.28,StartTime:2019-10-30 12:11:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-30 12:11:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7fd6e45507b01b91c0abeb577e9febdcf369a1ef5bea35c54c135436f2c88822}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.379: INFO: Pod "nginx-deployment-85db8c99c5-f6qpl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-f6qpl,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-f6qpl,UID:6dd1f887-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18605,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc0024137e0 0xc0024137e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002413860} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002413880}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.379: INFO: Pod "nginx-deployment-85db8c99c5-gcjf8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-gcjf8,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-gcjf8,UID:6dd20514-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18597,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc002413900 0xc002413901}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002413970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002413990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.380: INFO: Pod "nginx-deployment-85db8c99c5-gdc2w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-gdc2w,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-gdc2w,UID:6dc394b2-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18594,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc002413a20 0xc002413a21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002413a90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002413ab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.32,PodIP:,StartTime:2019-10-30 12:11:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.380: INFO: Pod "nginx-deployment-85db8c99c5-jljwm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-jljwm,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-jljwm,UID:6dd2431b-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18601,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc002413b90 0xc002413b91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002413c20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002413c40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.380: INFO: Pod "nginx-deployment-85db8c99c5-l9xnk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-l9xnk,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-l9xnk,UID:6a2015b2-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18455,Generation:0,CreationTimestamp:2019-10-30 12:11:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.3.29/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc002413cd0 0xc002413cd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002413d40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002413d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:34 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.41,PodIP:10.233.3.29,StartTime:2019-10-30 12:11:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-30 12:11:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8885070a558ae1b5946c3f2703632cfd20e0e47710021acbb08ea3904b0abf1f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.381: INFO: Pod "nginx-deployment-85db8c99c5-tp4t7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-tp4t7,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-tp4t7,UID:6dc3cff5-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18595,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc002413e60 0xc002413e61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002413ec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002413ee0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.41,PodIP:,StartTime:2019-10-30 12:11:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.381: INFO: Pod "nginx-deployment-85db8c99c5-v9x2s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-v9x2s,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-v9x2s,UID:6dbf83e2-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18574,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc002413fa0 0xc002413fa1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000394100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0003941e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.41,PodIP:,StartTime:2019-10-30 12:11:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.381: INFO: Pod "nginx-deployment-85db8c99c5-vgrkq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-vgrkq,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-vgrkq,UID:6dc9801b-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18579,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc000394590 0xc000394591}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000394630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000394660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.381: INFO: Pod "nginx-deployment-85db8c99c5-w69lk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-w69lk,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-w69lk,UID:6dd1e1fd-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18599,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc0003946f0 0xc0003946f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0003947d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000394820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.382: INFO: Pod "nginx-deployment-85db8c99c5-wwp7m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-wwp7m,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-wwp7m,UID:6a0fad76-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18460,Generation:0,CreationTimestamp:2019-10-30 12:11:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.5.60/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc000394c50 0xc000394c51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000394dd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000394e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:34 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.32,PodIP:10.233.5.60,StartTime:2019-10-30 12:11:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-30 12:11:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b828bb030725a1b1e343497f3d0d8ec7d47067b95f1700a898f2d7cdc2ea80a0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.382: INFO: Pod "nginx-deployment-85db8c99c5-zzb6g" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-zzb6g,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-85db8c99c5-zzb6g,UID:6a2035c5-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18474,Generation:0,CreationTimestamp:2019-10-30 12:11:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.4.75/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 6a08a1a7-fb0e-11e9-ad48-fa163ee0935a 0xc000395070 0xc000395071}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000395160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000395180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:34 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.39,PodIP:10.233.4.75,StartTime:2019-10-30 12:11:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-30 12:11:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e984de5f11059fdea9b1c808f7025965f5eb4a73705761cc4c1298bac0373da6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.383: INFO: Pod "nginx-deployment-b79c9d74d-7xl6r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-7xl6r,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-b79c9d74d-7xl6r,UID:6dc29ffc-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18567,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 6c7b2317-fb0e-11e9-ad48-fa163ee0935a 0xc0003953a0 0xc0003953a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000395550} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000395fe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.384: INFO: Pod "nginx-deployment-b79c9d74d-bnclq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-bnclq,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-b79c9d74d-bnclq,UID:6dd0c4e3-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18607,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 6c7b2317-fb0e-11e9-ad48-fa163ee0935a 0xc0004d2780 0xc0004d2781}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0004d3440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0004d3480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.384: INFO: Pod "nginx-deployment-b79c9d74d-c9lfq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-c9lfq,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-b79c9d74d-c9lfq,UID:6c7ca427-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18541,Generation:0,CreationTimestamp:2019-10-30 12:11:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.4.77/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 6c7b2317-fb0e-11e9-ad48-fa163ee0935a 0xc0004d3910 0xc0004d3911}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0004d3af0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0004d3b20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:37 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.39,PodIP:,StartTime:2019-10-30 12:11:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.385: INFO: Pod "nginx-deployment-b79c9d74d-hx8fq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-hx8fq,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-b79c9d74d-hx8fq,UID:6c80cee2-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18539,Generation:0,CreationTimestamp:2019-10-30 12:11:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.3.32/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 6c7b2317-fb0e-11e9-ad48-fa163ee0935a 0xc000485ff0 0xc000485ff1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0000c8d60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0000c9210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.41,PodIP:,StartTime:2019-10-30 12:11:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.385: INFO: Pod "nginx-deployment-b79c9d74d-jrjvv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-jrjvv,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-b79c9d74d-jrjvv,UID:6c8100ca-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18543,Generation:0,CreationTimestamp:2019-10-30 12:11:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.5.63/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 6c7b2317-fb0e-11e9-ad48-fa163ee0935a 0xc0000c97e0 0xc0000c97e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0000c9870} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0000c9930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.32,PodIP:,StartTime:2019-10-30 12:11:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.385: INFO: Pod "nginx-deployment-b79c9d74d-q9q2w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-q9q2w,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-b79c9d74d-q9q2w,UID:6ddb51bb-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18614,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 6c7b2317-fb0e-11e9-ad48-fa163ee0935a 0xc0000c9c10 0xc0000c9c11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0000c9d40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0000c9d80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.386: INFO: Pod "nginx-deployment-b79c9d74d-sppxl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-sppxl,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-b79c9d74d-sppxl,UID:6dc8ed7e-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18609,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 6c7b2317-fb0e-11e9-ad48-fa163ee0935a 0xc0000c9e40 0xc0000c9e41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0000c9f20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0000c9f40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.39,PodIP:,StartTime:2019-10-30 12:11:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.386: INFO: Pod "nginx-deployment-b79c9d74d-stpgh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-stpgh,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-b79c9d74d-stpgh,UID:6dd0eda8-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18608,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 6c7b2317-fb0e-11e9-ad48-fa163ee0935a 0xc00033c0c0 0xc00033c0c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00033c1d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00033c3b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.386: INFO: Pod "nginx-deployment-b79c9d74d-wl2vf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-wl2vf,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-b79c9d74d-wl2vf,UID:6dd0d5a0-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18604,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 6c7b2317-fb0e-11e9-ad48-fa163ee0935a 0xc00033c500 0xc00033c501}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00033c720} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00033c770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.386: INFO: Pod "nginx-deployment-b79c9d74d-x4jtg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-x4jtg,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-b79c9d74d-x4jtg,UID:6c9f9665-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18547,Generation:0,CreationTimestamp:2019-10-30 12:11:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.4.78/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 6c7b2317-fb0e-11e9-ad48-fa163ee0935a 0xc00033c930 0xc00033c931}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00033ca90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00033cb20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.39,PodIP:,StartTime:2019-10-30 12:11:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.387: INFO: Pod "nginx-deployment-b79c9d74d-x6tpq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-x6tpq,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-b79c9d74d-x6tpq,UID:6dc8c93e-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18576,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 6c7b2317-fb0e-11e9-ad48-fa163ee0935a 0xc00033cff0 0xc00033cff1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00033d0f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00033d150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.387: INFO: Pod "nginx-deployment-b79c9d74d-xmxjj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-xmxjj,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-b79c9d74d-xmxjj,UID:6c9c3228-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18546,Generation:0,CreationTimestamp:2019-10-30 12:11:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.3.33/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 6c7b2317-fb0e-11e9-ad48-fa163ee0935a 0xc00033dae0 0xc00033dae1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0000549b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000054eb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:38 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.41,PodIP:,StartTime:2019-10-30 12:11:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 30 12:11:40.387: INFO: Pod "nginx-deployment-b79c9d74d-zrm8n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-zrm8n,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-9808,SelfLink:/api/v1/namespaces/deployment-9808/pods/nginx-deployment-b79c9d74d-zrm8n,UID:6dd0a4af-fb0e-11e9-ad48-fa163ee0935a,ResourceVersion:18603,Generation:0,CreationTimestamp:2019-10-30 12:11:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 6c7b2317-fb0e-11e9-ad48-fa163ee0935a 0xc00064a0e0 0xc00064a0e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-djs2h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-djs2h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-djs2h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00064a1f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00064a2d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:11:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:11:40.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9808" for this suite.
Oct 30 12:11:48.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:11:48.859: INFO: namespace deployment-9808 deletion completed in 8.43474359s

â€¢ [SLOW TEST:15.126 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:11:48.860: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 30 12:11:53.593: INFO: Successfully updated pod "pod-update-activedeadlineseconds-7308c7ad-fb0e-11e9-91af-623cf93d857c"
Oct 30 12:11:53.593: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-7308c7ad-fb0e-11e9-91af-623cf93d857c" in namespace "pods-1402" to be "terminated due to deadline exceeded"
Oct 30 12:11:53.599: INFO: Pod "pod-update-activedeadlineseconds-7308c7ad-fb0e-11e9-91af-623cf93d857c": Phase="Running", Reason="", readiness=true. Elapsed: 5.515252ms
Oct 30 12:11:55.610: INFO: Pod "pod-update-activedeadlineseconds-7308c7ad-fb0e-11e9-91af-623cf93d857c": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.017015264s
Oct 30 12:11:55.611: INFO: Pod "pod-update-activedeadlineseconds-7308c7ad-fb0e-11e9-91af-623cf93d857c" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:11:55.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1402" for this suite.
Oct 30 12:12:01.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:12:02.133: INFO: namespace pods-1402 deletion completed in 6.505118166s

â€¢ [SLOW TEST:13.273 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:12:02.137: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Oct 30 12:12:02.567: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:12:18.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8611" for this suite.
Oct 30 12:12:24.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:12:24.386: INFO: namespace pods-8611 deletion completed in 6.332355405s

â€¢ [SLOW TEST:22.249 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:12:24.389: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 12:12:24.550: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Oct 30 12:12:24.577: INFO: Number of nodes with available pods: 0
Oct 30 12:12:24.577: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Oct 30 12:12:24.689: INFO: Number of nodes with available pods: 0
Oct 30 12:12:24.689: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:12:25.698: INFO: Number of nodes with available pods: 0
Oct 30 12:12:25.698: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:12:26.707: INFO: Number of nodes with available pods: 0
Oct 30 12:12:26.707: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:12:27.697: INFO: Number of nodes with available pods: 1
Oct 30 12:12:27.698: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Oct 30 12:12:27.766: INFO: Number of nodes with available pods: 0
Oct 30 12:12:27.766: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Oct 30 12:12:27.826: INFO: Number of nodes with available pods: 0
Oct 30 12:12:27.826: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:12:28.835: INFO: Number of nodes with available pods: 0
Oct 30 12:12:28.835: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:12:29.836: INFO: Number of nodes with available pods: 0
Oct 30 12:12:29.836: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:12:30.835: INFO: Number of nodes with available pods: 0
Oct 30 12:12:30.835: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:12:31.834: INFO: Number of nodes with available pods: 0
Oct 30 12:12:31.834: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:12:32.834: INFO: Number of nodes with available pods: 0
Oct 30 12:12:32.834: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:12:33.839: INFO: Number of nodes with available pods: 0
Oct 30 12:12:33.839: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:12:34.836: INFO: Number of nodes with available pods: 0
Oct 30 12:12:34.836: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:12:35.836: INFO: Number of nodes with available pods: 0
Oct 30 12:12:35.836: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:12:36.840: INFO: Number of nodes with available pods: 0
Oct 30 12:12:36.840: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:12:37.838: INFO: Number of nodes with available pods: 0
Oct 30 12:12:37.838: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:12:38.837: INFO: Number of nodes with available pods: 0
Oct 30 12:12:38.837: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:12:39.835: INFO: Number of nodes with available pods: 0
Oct 30 12:12:39.835: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:12:40.835: INFO: Number of nodes with available pods: 1
Oct 30 12:12:40.835: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3069, will wait for the garbage collector to delete the pods
Oct 30 12:12:40.930: INFO: Deleting DaemonSet.extensions daemon-set took: 21.593912ms
Oct 30 12:12:41.330: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.358984ms
Oct 30 12:12:44.439: INFO: Number of nodes with available pods: 0
Oct 30 12:12:44.439: INFO: Number of running nodes: 0, number of available pods: 0
Oct 30 12:12:44.446: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3069/daemonsets","resourceVersion":"19183"},"items":null}

Oct 30 12:12:44.454: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3069/pods","resourceVersion":"19183"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:12:44.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3069" for this suite.
Oct 30 12:12:50.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:12:50.870: INFO: namespace daemonsets-3069 deletion completed in 6.333776838s

â€¢ [SLOW TEST:26.481 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:12:50.871: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 12:12:50.998: INFO: (0) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 21.021148ms)
Oct 30 12:12:51.011: INFO: (1) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 13.199397ms)
Oct 30 12:12:51.023: INFO: (2) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 12.535333ms)
Oct 30 12:12:51.036: INFO: (3) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 11.705687ms)
Oct 30 12:12:51.045: INFO: (4) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 8.986663ms)
Oct 30 12:12:51.061: INFO: (5) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 15.914451ms)
Oct 30 12:12:51.070: INFO: (6) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 9.371532ms)
Oct 30 12:12:51.082: INFO: (7) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 11.30032ms)
Oct 30 12:12:51.093: INFO: (8) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 11.334196ms)
Oct 30 12:12:51.104: INFO: (9) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 10.567999ms)
Oct 30 12:12:51.114: INFO: (10) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 10.388701ms)
Oct 30 12:12:51.125: INFO: (11) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 10.908406ms)
Oct 30 12:12:51.135: INFO: (12) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 9.564675ms)
Oct 30 12:12:51.145: INFO: (13) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 10.011639ms)
Oct 30 12:12:51.154: INFO: (14) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 8.949434ms)
Oct 30 12:12:51.162: INFO: (15) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 8.281684ms)
Oct 30 12:12:51.175: INFO: (16) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 12.258394ms)
Oct 30 12:12:51.237: INFO: (17) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 62.171934ms)
Oct 30 12:12:51.249: INFO: (18) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 12.09666ms)
Oct 30 12:12:51.259: INFO: (19) /api/v1/nodes/koris-pipeline-56683fb-92514359-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 9.251466ms)
[AfterEach] version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:12:51.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7550" for this suite.
Oct 30 12:12:57.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:12:57.573: INFO: namespace proxy-7550 deletion completed in 6.305015111s

â€¢ [SLOW TEST:6.703 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:12:57.575: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-2106/configmap-test-9bfebd3f-fb0e-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume configMaps
Oct 30 12:12:57.729: INFO: Waiting up to 5m0s for pod "pod-configmaps-9c014e7f-fb0e-11e9-91af-623cf93d857c" in namespace "configmap-2106" to be "success or failure"
Oct 30 12:12:57.758: INFO: Pod "pod-configmaps-9c014e7f-fb0e-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 28.74972ms
Oct 30 12:12:59.768: INFO: Pod "pod-configmaps-9c014e7f-fb0e-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038670088s
Oct 30 12:13:01.776: INFO: Pod "pod-configmaps-9c014e7f-fb0e-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046386709s
STEP: Saw pod success
Oct 30 12:13:01.776: INFO: Pod "pod-configmaps-9c014e7f-fb0e-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:13:01.783: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-configmaps-9c014e7f-fb0e-11e9-91af-623cf93d857c container env-test: <nil>
STEP: delete the pod
Oct 30 12:13:01.837: INFO: Waiting for pod pod-configmaps-9c014e7f-fb0e-11e9-91af-623cf93d857c to disappear
Oct 30 12:13:01.844: INFO: Pod pod-configmaps-9c014e7f-fb0e-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:13:01.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2106" for this suite.
Oct 30 12:13:07.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:13:08.204: INFO: namespace configmap-2106 deletion completed in 6.351177192s

â€¢ [SLOW TEST:10.629 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:13:08.207: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6152
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Oct 30 12:13:08.450: INFO: Found 0 stateful pods, waiting for 3
Oct 30 12:13:18.464: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 12:13:18.465: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 12:13:18.465: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 30 12:13:18.523: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Oct 30 12:13:28.630: INFO: Updating stateful set ss2
Oct 30 12:13:28.689: INFO: Waiting for Pod statefulset-6152/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Oct 30 12:13:38.929: INFO: Found 2 stateful pods, waiting for 3
Oct 30 12:13:48.939: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 12:13:48.939: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 12:13:48.939: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Oct 30 12:13:48.993: INFO: Updating stateful set ss2
Oct 30 12:13:49.043: INFO: Waiting for Pod statefulset-6152/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 30 12:13:59.064: INFO: Waiting for Pod statefulset-6152/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 30 12:14:09.204: INFO: Updating stateful set ss2
Oct 30 12:14:09.241: INFO: Waiting for StatefulSet statefulset-6152/ss2 to complete update
Oct 30 12:14:09.241: INFO: Waiting for Pod statefulset-6152/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 30 12:14:19.257: INFO: Waiting for StatefulSet statefulset-6152/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 30 12:14:29.265: INFO: Deleting all statefulset in ns statefulset-6152
Oct 30 12:14:29.271: INFO: Scaling statefulset ss2 to 0
Oct 30 12:14:59.315: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 12:14:59.323: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:14:59.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6152" for this suite.
Oct 30 12:15:07.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:15:07.782: INFO: namespace statefulset-6152 deletion completed in 8.40647025s

â€¢ [SLOW TEST:119.576 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:15:07.788: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1174
STEP: creating the pod
Oct 30 12:15:07.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 create -f - --namespace=kubectl-6252'
Oct 30 12:15:08.349: INFO: stderr: ""
Oct 30 12:15:08.349: INFO: stdout: "pod/pause created\n"
Oct 30 12:15:08.350: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct 30 12:15:08.350: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6252" to be "running and ready"
Oct 30 12:15:08.368: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 18.130232ms
Oct 30 12:15:10.379: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02947797s
Oct 30 12:15:12.390: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.039847033s
Oct 30 12:15:12.390: INFO: Pod "pause" satisfied condition "running and ready"
Oct 30 12:15:12.390: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Oct 30 12:15:12.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 label pods pause testing-label=testing-label-value --namespace=kubectl-6252'
Oct 30 12:15:12.552: INFO: stderr: ""
Oct 30 12:15:12.552: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Oct 30 12:15:12.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pod pause -L testing-label --namespace=kubectl-6252'
Oct 30 12:15:12.680: INFO: stderr: ""
Oct 30 12:15:12.680: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Oct 30 12:15:12.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 label pods pause testing-label- --namespace=kubectl-6252'
Oct 30 12:15:12.839: INFO: stderr: ""
Oct 30 12:15:12.839: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Oct 30 12:15:12.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pod pause -L testing-label --namespace=kubectl-6252'
Oct 30 12:15:12.957: INFO: stderr: ""
Oct 30 12:15:12.957: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1181
STEP: using delete to clean up resources
Oct 30 12:15:12.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 delete --grace-period=0 --force -f - --namespace=kubectl-6252'
Oct 30 12:15:13.126: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 30 12:15:13.126: INFO: stdout: "pod \"pause\" force deleted\n"
Oct 30 12:15:13.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get rc,svc -l name=pause --no-headers --namespace=kubectl-6252'
Oct 30 12:15:13.270: INFO: stderr: "No resources found.\n"
Oct 30 12:15:13.270: INFO: stdout: ""
Oct 30 12:15:13.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 get pods -l name=pause --namespace=kubectl-6252 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 30 12:15:13.379: INFO: stderr: ""
Oct 30 12:15:13.379: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:15:13.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6252" for this suite.
Oct 30 12:15:19.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:15:19.694: INFO: namespace kubectl-6252 deletion completed in 6.301602339s

â€¢ [SLOW TEST:11.907 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:15:19.695: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 30 12:15:19.799: INFO: Waiting up to 5m0s for pod "pod-f0b07ebc-fb0e-11e9-91af-623cf93d857c" in namespace "emptydir-7428" to be "success or failure"
Oct 30 12:15:19.806: INFO: Pod "pod-f0b07ebc-fb0e-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.951223ms
Oct 30 12:15:21.817: INFO: Pod "pod-f0b07ebc-fb0e-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017509149s
Oct 30 12:15:23.828: INFO: Pod "pod-f0b07ebc-fb0e-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028821566s
STEP: Saw pod success
Oct 30 12:15:23.828: INFO: Pod "pod-f0b07ebc-fb0e-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:15:23.845: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-f0b07ebc-fb0e-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 12:15:23.908: INFO: Waiting for pod pod-f0b07ebc-fb0e-11e9-91af-623cf93d857c to disappear
Oct 30 12:15:23.918: INFO: Pod pod-f0b07ebc-fb0e-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:15:23.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7428" for this suite.
Oct 30 12:15:29.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:15:30.251: INFO: namespace emptydir-7428 deletion completed in 6.321628787s

â€¢ [SLOW TEST:10.557 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:15:30.256: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Oct 30 12:15:30.382: INFO: Waiting up to 5m0s for pod "var-expansion-f6fdade5-fb0e-11e9-91af-623cf93d857c" in namespace "var-expansion-550" to be "success or failure"
Oct 30 12:15:30.389: INFO: Pod "var-expansion-f6fdade5-fb0e-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.441054ms
Oct 30 12:15:32.399: INFO: Pod "var-expansion-f6fdade5-fb0e-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017407292s
Oct 30 12:15:34.409: INFO: Pod "var-expansion-f6fdade5-fb0e-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027459295s
STEP: Saw pod success
Oct 30 12:15:34.409: INFO: Pod "var-expansion-f6fdade5-fb0e-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:15:34.417: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod var-expansion-f6fdade5-fb0e-11e9-91af-623cf93d857c container dapi-container: <nil>
STEP: delete the pod
Oct 30 12:15:34.484: INFO: Waiting for pod var-expansion-f6fdade5-fb0e-11e9-91af-623cf93d857c to disappear
Oct 30 12:15:34.490: INFO: Pod var-expansion-f6fdade5-fb0e-11e9-91af-623cf93d857c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:15:34.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-550" for this suite.
Oct 30 12:15:40.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:15:40.799: INFO: namespace var-expansion-550 deletion completed in 6.297484573s

â€¢ [SLOW TEST:10.543 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:15:40.799: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 30 12:15:40.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7882'
Oct 30 12:15:41.007: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 30 12:15:41.007: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Oct 30 12:15:41.035: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-4bz8l]
Oct 30 12:15:41.035: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-4bz8l" in namespace "kubectl-7882" to be "running and ready"
Oct 30 12:15:41.058: INFO: Pod "e2e-test-nginx-rc-4bz8l": Phase="Pending", Reason="", readiness=false. Elapsed: 22.411124ms
Oct 30 12:15:43.066: INFO: Pod "e2e-test-nginx-rc-4bz8l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030726514s
Oct 30 12:15:45.076: INFO: Pod "e2e-test-nginx-rc-4bz8l": Phase="Running", Reason="", readiness=true. Elapsed: 4.040316158s
Oct 30 12:15:45.076: INFO: Pod "e2e-test-nginx-rc-4bz8l" satisfied condition "running and ready"
Oct 30 12:15:45.076: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-4bz8l]
Oct 30 12:15:45.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 logs rc/e2e-test-nginx-rc --namespace=kubectl-7882'
Oct 30 12:15:45.257: INFO: stderr: ""
Oct 30 12:15:45.257: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1425
Oct 30 12:15:45.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 delete rc e2e-test-nginx-rc --namespace=kubectl-7882'
Oct 30 12:15:45.400: INFO: stderr: ""
Oct 30 12:15:45.400: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:15:45.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7882" for this suite.
Oct 30 12:15:51.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:15:51.717: INFO: namespace kubectl-7882 deletion completed in 6.305899149s

â€¢ [SLOW TEST:10.918 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:15:51.719: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1030 12:16:22.006833      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 30 12:16:22.007: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:16:22.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8614" for this suite.
Oct 30 12:16:28.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:16:28.328: INFO: namespace gc-8614 deletion completed in 6.310561861s

â€¢ [SLOW TEST:36.609 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:16:28.329: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-199ca71d-fb0f-11e9-91af-623cf93d857c
STEP: Creating secret with name s-test-opt-upd-199ca7ca-fb0f-11e9-91af-623cf93d857c
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-199ca71d-fb0f-11e9-91af-623cf93d857c
STEP: Updating secret s-test-opt-upd-199ca7ca-fb0f-11e9-91af-623cf93d857c
STEP: Creating secret with name s-test-opt-create-199ca7f6-fb0f-11e9-91af-623cf93d857c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:16:34.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2230" for this suite.
Oct 30 12:16:58.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:16:59.120: INFO: namespace secrets-2230 deletion completed in 24.323589861s

â€¢ [SLOW TEST:30.791 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:16:59.121: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-2bf8d6a3-fb0f-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume configMaps
Oct 30 12:16:59.275: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2bfba3c3-fb0f-11e9-91af-623cf93d857c" in namespace "projected-9831" to be "success or failure"
Oct 30 12:16:59.297: INFO: Pod "pod-projected-configmaps-2bfba3c3-fb0f-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 21.841993ms
Oct 30 12:17:01.308: INFO: Pod "pod-projected-configmaps-2bfba3c3-fb0f-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032737338s
Oct 30 12:17:03.316: INFO: Pod "pod-projected-configmaps-2bfba3c3-fb0f-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04087609s
STEP: Saw pod success
Oct 30 12:17:03.316: INFO: Pod "pod-projected-configmaps-2bfba3c3-fb0f-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:17:03.323: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-projected-configmaps-2bfba3c3-fb0f-11e9-91af-623cf93d857c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 12:17:03.397: INFO: Waiting for pod pod-projected-configmaps-2bfba3c3-fb0f-11e9-91af-623cf93d857c to disappear
Oct 30 12:17:03.404: INFO: Pod pod-projected-configmaps-2bfba3c3-fb0f-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:17:03.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9831" for this suite.
Oct 30 12:17:09.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:17:09.722: INFO: namespace projected-9831 deletion completed in 6.305921442s

â€¢ [SLOW TEST:10.601 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:17:09.723: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-32463dbd-fb0f-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume secrets
Oct 30 12:17:09.848: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-32497ad7-fb0f-11e9-91af-623cf93d857c" in namespace "projected-3307" to be "success or failure"
Oct 30 12:17:09.864: INFO: Pod "pod-projected-secrets-32497ad7-fb0f-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.935014ms
Oct 30 12:17:11.875: INFO: Pod "pod-projected-secrets-32497ad7-fb0f-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027697614s
Oct 30 12:17:13.884: INFO: Pod "pod-projected-secrets-32497ad7-fb0f-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0364146s
STEP: Saw pod success
Oct 30 12:17:13.884: INFO: Pod "pod-projected-secrets-32497ad7-fb0f-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:17:13.891: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-projected-secrets-32497ad7-fb0f-11e9-91af-623cf93d857c container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 30 12:17:13.974: INFO: Waiting for pod pod-projected-secrets-32497ad7-fb0f-11e9-91af-623cf93d857c to disappear
Oct 30 12:17:13.981: INFO: Pod pod-projected-secrets-32497ad7-fb0f-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:17:13.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3307" for this suite.
Oct 30 12:17:20.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:17:20.315: INFO: namespace projected-3307 deletion completed in 6.325706656s

â€¢ [SLOW TEST:10.592 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:17:20.319: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-4659
Oct 30 12:17:24.458: INFO: Started pod liveness-exec in namespace container-probe-4659
STEP: checking the pod's current state and verifying that restartCount is present
Oct 30 12:17:24.465: INFO: Initial restart count of pod liveness-exec is 0
Oct 30 12:18:16.764: INFO: Restart count of pod container-probe-4659/liveness-exec is now 1 (52.298842679s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:18:16.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4659" for this suite.
Oct 30 12:18:22.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:18:23.119: INFO: namespace container-probe-4659 deletion completed in 6.293603244s

â€¢ [SLOW TEST:62.800 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:18:23.120: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 12:18:51.303: INFO: Container started at 2019-10-30 12:18:26 +0000 UTC, pod became ready at 2019-10-30 12:18:50 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:18:51.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-364" for this suite.
Oct 30 12:19:13.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:19:13.655: INFO: namespace container-probe-364 deletion completed in 22.342440226s

â€¢ [SLOW TEST:50.536 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:19:13.659: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
W1030 12:19:14.636098      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 30 12:19:14.636: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:19:14.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5877" for this suite.
Oct 30 12:19:20.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:19:21.125: INFO: namespace gc-5877 deletion completed in 6.478376159s

â€¢ [SLOW TEST:7.466 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:19:21.127: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6984
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-6984
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6984
Oct 30 12:19:21.409: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Oct 30 12:19:31.434: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Oct 30 12:19:31.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6984 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 12:19:31.758: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 12:19:31.758: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 12:19:31.758: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 12:19:31.768: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 30 12:19:41.791: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 30 12:19:41.791: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 12:19:41.848: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999303s
Oct 30 12:19:42.862: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.985677762s
Oct 30 12:19:43.872: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.97125732s
Oct 30 12:19:44.883: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.961379726s
Oct 30 12:19:45.894: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.950233254s
Oct 30 12:19:47.015: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.93934803s
Oct 30 12:19:48.036: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.818701637s
Oct 30 12:19:49.047: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.797665836s
Oct 30 12:19:50.056: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.785782442s
Oct 30 12:19:51.069: INFO: Verifying statefulset ss doesn't scale past 1 for another 776.943193ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6984
Oct 30 12:19:52.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6984 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:19:52.373: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 30 12:19:52.373: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 12:19:52.373: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 12:19:52.384: INFO: Found 1 stateful pods, waiting for 3
Oct 30 12:20:02.454: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 12:20:02.454: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 12:20:02.454: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Oct 30 12:20:02.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6984 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 12:20:02.869: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 12:20:02.869: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 12:20:02.869: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 12:20:02.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6984 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 12:20:03.177: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 12:20:03.177: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 12:20:03.177: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 12:20:03.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6984 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 12:20:03.488: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 12:20:03.488: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 12:20:03.488: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 12:20:03.488: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 12:20:03.500: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Oct 30 12:20:13.518: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 30 12:20:13.518: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 30 12:20:13.518: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 30 12:20:13.567: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.9999991s
Oct 30 12:20:14.574: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.976612116s
Oct 30 12:20:15.588: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.969190808s
Oct 30 12:20:16.597: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.955463117s
Oct 30 12:20:17.607: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.946575451s
Oct 30 12:20:18.621: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.935741158s
Oct 30 12:20:19.631: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.922427566s
Oct 30 12:20:20.642: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.911957071s
Oct 30 12:20:21.652: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.901395431s
Oct 30 12:20:22.666: INFO: Verifying statefulset ss doesn't scale past 3 for another 890.618419ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6984
Oct 30 12:20:23.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6984 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:20:23.997: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 30 12:20:23.997: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 12:20:23.997: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 12:20:23.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6984 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:20:24.265: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 30 12:20:24.265: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 12:20:24.265: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 12:20:24.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-6984 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:20:24.565: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 30 12:20:24.565: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 12:20:24.565: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 12:20:24.565: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 30 12:20:54.603: INFO: Deleting all statefulset in ns statefulset-6984
Oct 30 12:20:54.612: INFO: Scaling statefulset ss to 0
Oct 30 12:20:54.636: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 12:20:54.643: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:20:54.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6984" for this suite.
Oct 30 12:21:00.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:21:01.088: INFO: namespace statefulset-6984 deletion completed in 6.389699181s

â€¢ [SLOW TEST:99.962 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:21:01.093: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Oct 30 12:21:01.178: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-984085711 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:21:01.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3869" for this suite.
Oct 30 12:21:07.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:21:07.665: INFO: namespace kubectl-3869 deletion completed in 6.360257533s

â€¢ [SLOW TEST:6.572 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:21:07.669: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 12:21:07.861: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c023a12d-fb0f-11e9-91af-623cf93d857c" in namespace "downward-api-4926" to be "success or failure"
Oct 30 12:21:07.896: INFO: Pod "downwardapi-volume-c023a12d-fb0f-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 35.064127ms
Oct 30 12:21:09.907: INFO: Pod "downwardapi-volume-c023a12d-fb0f-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045622363s
Oct 30 12:21:11.917: INFO: Pod "downwardapi-volume-c023a12d-fb0f-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055364966s
STEP: Saw pod success
Oct 30 12:21:11.917: INFO: Pod "downwardapi-volume-c023a12d-fb0f-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:21:11.927: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod downwardapi-volume-c023a12d-fb0f-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 12:21:12.047: INFO: Waiting for pod downwardapi-volume-c023a12d-fb0f-11e9-91af-623cf93d857c to disappear
Oct 30 12:21:12.054: INFO: Pod downwardapi-volume-c023a12d-fb0f-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:21:12.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4926" for this suite.
Oct 30 12:21:18.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:21:18.500: INFO: namespace downward-api-4926 deletion completed in 6.416840231s

â€¢ [SLOW TEST:10.832 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:21:18.501: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Oct 30 12:21:23.277: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4117 pod-service-account-c6eceadb-fb0f-11e9-91af-623cf93d857c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Oct 30 12:21:23.593: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4117 pod-service-account-c6eceadb-fb0f-11e9-91af-623cf93d857c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Oct 30 12:21:23.897: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4117 pod-service-account-c6eceadb-fb0f-11e9-91af-623cf93d857c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:21:24.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4117" for this suite.
Oct 30 12:21:30.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:21:30.570: INFO: namespace svcaccounts-4117 deletion completed in 6.347050012s

â€¢ [SLOW TEST:12.069 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:21:30.572: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:21:42.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9548" for this suite.
Oct 30 12:21:48.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:21:48.666: INFO: namespace namespaces-9548 deletion completed in 6.506783123s
STEP: Destroying namespace "nsdeletetest-7023" for this suite.
Oct 30 12:21:48.672: INFO: Namespace nsdeletetest-7023 was already deleted
STEP: Destroying namespace "nsdeletetest-3384" for this suite.
Oct 30 12:21:54.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:21:55.248: INFO: namespace nsdeletetest-3384 deletion completed in 6.576137484s

â€¢ [SLOW TEST:24.676 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:21:55.249: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Oct 30 12:21:55.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 create -f - --namespace=kubectl-3863'
Oct 30 12:21:56.278: INFO: stderr: ""
Oct 30 12:21:56.279: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 30 12:21:57.291: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 12:21:57.291: INFO: Found 0 / 1
Oct 30 12:21:58.289: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 12:21:58.289: INFO: Found 0 / 1
Oct 30 12:21:59.291: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 12:21:59.291: INFO: Found 1 / 1
Oct 30 12:21:59.291: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Oct 30 12:21:59.300: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 12:21:59.300: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 30 12:21:59.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 patch pod redis-master-k4dfg --namespace=kubectl-3863 -p {"metadata":{"annotations":{"x":"y"}}}'
Oct 30 12:21:59.445: INFO: stderr: ""
Oct 30 12:21:59.445: INFO: stdout: "pod/redis-master-k4dfg patched\n"
STEP: checking annotations
Oct 30 12:21:59.455: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 12:21:59.455: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:21:59.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3863" for this suite.
Oct 30 12:22:23.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:22:23.803: INFO: namespace kubectl-3863 deletion completed in 24.334806271s

â€¢ [SLOW TEST:28.554 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:22:23.805: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 12:22:23.918: INFO: Creating deployment "test-recreate-deployment"
Oct 30 12:22:23.948: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct 30 12:22:23.969: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Oct 30 12:22:26.164: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct 30 12:22:26.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708034944, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708034944, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708034944, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708034943, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6566d46b4b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 12:22:28.184: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct 30 12:22:28.209: INFO: Updating deployment test-recreate-deployment
Oct 30 12:22:28.209: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 30 12:22:28.434: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-6109,SelfLink:/apis/apps/v1/namespaces/deployment-6109/deployments/test-recreate-deployment,UID:ed8054fc-fb0f-11e9-a053-fa163e61542c,ResourceVersion:21778,Generation:2,CreationTimestamp:2019-10-30 12:22:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-10-30 12:22:28 +0000 UTC 2019-10-30 12:22:28 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-10-30 12:22:28 +0000 UTC 2019-10-30 12:22:23 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-745fb9c84c" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Oct 30 12:22:28.448: INFO: New ReplicaSet "test-recreate-deployment-745fb9c84c" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c,GenerateName:,Namespace:deployment-6109,SelfLink:/apis/apps/v1/namespaces/deployment-6109/replicasets/test-recreate-deployment-745fb9c84c,UID:f020ec2a-fb0f-11e9-ad48-fa163ee0935a,ResourceVersion:21776,Generation:1,CreationTimestamp:2019-10-30 12:22:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment ed8054fc-fb0f-11e9-a053-fa163e61542c 0xc002bf61f7 0xc002bf61f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 30 12:22:28.448: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct 30 12:22:28.448: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6566d46b4b,GenerateName:,Namespace:deployment-6109,SelfLink:/apis/apps/v1/namespaces/deployment-6109/replicasets/test-recreate-deployment-6566d46b4b,UID:ed83d3c7-fb0f-11e9-ad48-fa163ee0935a,ResourceVersion:21766,Generation:2,CreationTimestamp:2019-10-30 12:22:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment ed8054fc-fb0f-11e9-a053-fa163e61542c 0xc002bf6127 0xc002bf6128}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 30 12:22:28.459: INFO: Pod "test-recreate-deployment-745fb9c84c-ffqbk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c-ffqbk,GenerateName:test-recreate-deployment-745fb9c84c-,Namespace:deployment-6109,SelfLink:/api/v1/namespaces/deployment-6109/pods/test-recreate-deployment-745fb9c84c-ffqbk,UID:f022932f-fb0f-11e9-ad48-fa163ee0935a,ResourceVersion:21777,Generation:0,CreationTimestamp:2019-10-30 12:22:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-745fb9c84c f020ec2a-fb0f-11e9-ad48-fa163ee0935a 0xc002bf6b27 0xc002bf6b28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bsgnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bsgnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bsgnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bf6b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bf6bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:22:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:22:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:22:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:22:28 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.39,PodIP:,StartTime:2019-10-30 12:22:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:22:28.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6109" for this suite.
Oct 30 12:22:36.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:22:36.778: INFO: namespace deployment-6109 deletion completed in 8.308260981s

â€¢ [SLOW TEST:12.973 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:22:36.779: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 30 12:22:36.922: INFO: Waiting up to 5m0s for pod "pod-f53b0d16-fb0f-11e9-91af-623cf93d857c" in namespace "emptydir-6857" to be "success or failure"
Oct 30 12:22:36.936: INFO: Pod "pod-f53b0d16-fb0f-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.791709ms
Oct 30 12:22:38.945: INFO: Pod "pod-f53b0d16-fb0f-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023112761s
Oct 30 12:22:40.955: INFO: Pod "pod-f53b0d16-fb0f-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032805938s
STEP: Saw pod success
Oct 30 12:22:40.955: INFO: Pod "pod-f53b0d16-fb0f-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:22:40.983: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-f53b0d16-fb0f-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 12:22:41.158: INFO: Waiting for pod pod-f53b0d16-fb0f-11e9-91af-623cf93d857c to disappear
Oct 30 12:22:41.191: INFO: Pod pod-f53b0d16-fb0f-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:22:41.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6857" for this suite.
Oct 30 12:22:47.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:22:47.592: INFO: namespace emptydir-6857 deletion completed in 6.386338099s

â€¢ [SLOW TEST:10.813 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:22:47.593: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct 30 12:22:47.715: INFO: Waiting up to 5m0s for pod "downward-api-fbab7a64-fb0f-11e9-91af-623cf93d857c" in namespace "downward-api-5614" to be "success or failure"
Oct 30 12:22:47.731: INFO: Pod "downward-api-fbab7a64-fb0f-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.222611ms
Oct 30 12:22:49.742: INFO: Pod "downward-api-fbab7a64-fb0f-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026446607s
Oct 30 12:22:51.761: INFO: Pod "downward-api-fbab7a64-fb0f-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04589178s
STEP: Saw pod success
Oct 30 12:22:51.761: INFO: Pod "downward-api-fbab7a64-fb0f-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:22:51.769: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod downward-api-fbab7a64-fb0f-11e9-91af-623cf93d857c container dapi-container: <nil>
STEP: delete the pod
Oct 30 12:22:51.837: INFO: Waiting for pod downward-api-fbab7a64-fb0f-11e9-91af-623cf93d857c to disappear
Oct 30 12:22:51.842: INFO: Pod downward-api-fbab7a64-fb0f-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:22:51.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5614" for this suite.
Oct 30 12:22:57.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:22:58.186: INFO: namespace downward-api-5614 deletion completed in 6.334453733s

â€¢ [SLOW TEST:10.593 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:22:58.187: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct 30 12:22:58.329: INFO: Waiting up to 5m0s for pod "downward-api-01fda4ee-fb10-11e9-91af-623cf93d857c" in namespace "downward-api-3768" to be "success or failure"
Oct 30 12:22:58.423: INFO: Pod "downward-api-01fda4ee-fb10-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 94.312245ms
Oct 30 12:23:00.434: INFO: Pod "downward-api-01fda4ee-fb10-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.105179793s
Oct 30 12:23:02.444: INFO: Pod "downward-api-01fda4ee-fb10-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.115362768s
STEP: Saw pod success
Oct 30 12:23:02.444: INFO: Pod "downward-api-01fda4ee-fb10-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:23:02.451: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod downward-api-01fda4ee-fb10-11e9-91af-623cf93d857c container dapi-container: <nil>
STEP: delete the pod
Oct 30 12:23:02.547: INFO: Waiting for pod downward-api-01fda4ee-fb10-11e9-91af-623cf93d857c to disappear
Oct 30 12:23:02.553: INFO: Pod downward-api-01fda4ee-fb10-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:23:02.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3768" for this suite.
Oct 30 12:23:08.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:23:08.883: INFO: namespace downward-api-3768 deletion completed in 6.322275634s

â€¢ [SLOW TEST:10.697 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:23:08.884: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:23:13.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7873" for this suite.
Oct 30 12:23:19.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:23:19.565: INFO: namespace emptydir-wrapper-7873 deletion completed in 6.355595341s

â€¢ [SLOW TEST:10.681 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:23:19.567: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Oct 30 12:23:19.693: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-27,SelfLink:/api/v1/namespaces/watch-27/configmaps/e2e-watch-test-configmap-a,UID:0ebb7ab0-fb10-11e9-a053-fa163e61542c,ResourceVersion:22061,Generation:0,CreationTimestamp:2019-10-30 12:23:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 30 12:23:19.693: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-27,SelfLink:/api/v1/namespaces/watch-27/configmaps/e2e-watch-test-configmap-a,UID:0ebb7ab0-fb10-11e9-a053-fa163e61542c,ResourceVersion:22061,Generation:0,CreationTimestamp:2019-10-30 12:23:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Oct 30 12:23:29.721: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-27,SelfLink:/api/v1/namespaces/watch-27/configmaps/e2e-watch-test-configmap-a,UID:0ebb7ab0-fb10-11e9-a053-fa163e61542c,ResourceVersion:22149,Generation:0,CreationTimestamp:2019-10-30 12:23:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 30 12:23:29.722: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-27,SelfLink:/api/v1/namespaces/watch-27/configmaps/e2e-watch-test-configmap-a,UID:0ebb7ab0-fb10-11e9-a053-fa163e61542c,ResourceVersion:22149,Generation:0,CreationTimestamp:2019-10-30 12:23:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Oct 30 12:23:39.762: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-27,SelfLink:/api/v1/namespaces/watch-27/configmaps/e2e-watch-test-configmap-a,UID:0ebb7ab0-fb10-11e9-a053-fa163e61542c,ResourceVersion:22191,Generation:0,CreationTimestamp:2019-10-30 12:23:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 30 12:23:39.762: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-27,SelfLink:/api/v1/namespaces/watch-27/configmaps/e2e-watch-test-configmap-a,UID:0ebb7ab0-fb10-11e9-a053-fa163e61542c,ResourceVersion:22191,Generation:0,CreationTimestamp:2019-10-30 12:23:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Oct 30 12:23:49.789: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-27,SelfLink:/api/v1/namespaces/watch-27/configmaps/e2e-watch-test-configmap-a,UID:0ebb7ab0-fb10-11e9-a053-fa163e61542c,ResourceVersion:22223,Generation:0,CreationTimestamp:2019-10-30 12:23:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 30 12:23:49.790: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-27,SelfLink:/api/v1/namespaces/watch-27/configmaps/e2e-watch-test-configmap-a,UID:0ebb7ab0-fb10-11e9-a053-fa163e61542c,ResourceVersion:22223,Generation:0,CreationTimestamp:2019-10-30 12:23:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Oct 30 12:23:59.813: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-27,SelfLink:/api/v1/namespaces/watch-27/configmaps/e2e-watch-test-configmap-b,UID:26a52aa8-fb10-11e9-a053-fa163e61542c,ResourceVersion:22252,Generation:0,CreationTimestamp:2019-10-30 12:23:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 30 12:23:59.813: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-27,SelfLink:/api/v1/namespaces/watch-27/configmaps/e2e-watch-test-configmap-b,UID:26a52aa8-fb10-11e9-a053-fa163e61542c,ResourceVersion:22252,Generation:0,CreationTimestamp:2019-10-30 12:23:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Oct 30 12:24:09.831: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-27,SelfLink:/api/v1/namespaces/watch-27/configmaps/e2e-watch-test-configmap-b,UID:26a52aa8-fb10-11e9-a053-fa163e61542c,ResourceVersion:22278,Generation:0,CreationTimestamp:2019-10-30 12:23:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 30 12:24:09.831: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-27,SelfLink:/api/v1/namespaces/watch-27/configmaps/e2e-watch-test-configmap-b,UID:26a52aa8-fb10-11e9-a053-fa163e61542c,ResourceVersion:22278,Generation:0,CreationTimestamp:2019-10-30 12:23:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:24:19.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-27" for this suite.
Oct 30 12:24:25.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:24:26.195: INFO: namespace watch-27 deletion completed in 6.34989958s

â€¢ [SLOW TEST:66.629 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:24:26.201: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-777.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-777.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-777.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-777.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-777.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-777.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-777.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-777.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-777.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-777.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-777.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-777.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-777.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 113.37.108.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.108.37.113_udp@PTR;check="$$(dig +tcp +noall +answer +search 113.37.108.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.108.37.113_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-777.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-777.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-777.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-777.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-777.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-777.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-777.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-777.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-777.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-777.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-777.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-777.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-777.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 113.37.108.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.108.37.113_udp@PTR;check="$$(dig +tcp +noall +answer +search 113.37.108.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.108.37.113_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 30 12:24:30.594: INFO: Unable to read wheezy_udp@dns-test-service.dns-777.svc.cluster.local from pod dns-777/dns-test-368db874-fb10-11e9-91af-623cf93d857c: the server could not find the requested resource (get pods dns-test-368db874-fb10-11e9-91af-623cf93d857c)
Oct 30 12:24:30.603: INFO: Unable to read wheezy_tcp@dns-test-service.dns-777.svc.cluster.local from pod dns-777/dns-test-368db874-fb10-11e9-91af-623cf93d857c: the server could not find the requested resource (get pods dns-test-368db874-fb10-11e9-91af-623cf93d857c)
Oct 30 12:24:30.612: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-777.svc.cluster.local from pod dns-777/dns-test-368db874-fb10-11e9-91af-623cf93d857c: the server could not find the requested resource (get pods dns-test-368db874-fb10-11e9-91af-623cf93d857c)
Oct 30 12:24:30.623: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-777.svc.cluster.local from pod dns-777/dns-test-368db874-fb10-11e9-91af-623cf93d857c: the server could not find the requested resource (get pods dns-test-368db874-fb10-11e9-91af-623cf93d857c)
Oct 30 12:24:30.702: INFO: Unable to read jessie_udp@dns-test-service.dns-777.svc.cluster.local from pod dns-777/dns-test-368db874-fb10-11e9-91af-623cf93d857c: the server could not find the requested resource (get pods dns-test-368db874-fb10-11e9-91af-623cf93d857c)
Oct 30 12:24:30.713: INFO: Unable to read jessie_tcp@dns-test-service.dns-777.svc.cluster.local from pod dns-777/dns-test-368db874-fb10-11e9-91af-623cf93d857c: the server could not find the requested resource (get pods dns-test-368db874-fb10-11e9-91af-623cf93d857c)
Oct 30 12:24:30.722: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-777.svc.cluster.local from pod dns-777/dns-test-368db874-fb10-11e9-91af-623cf93d857c: the server could not find the requested resource (get pods dns-test-368db874-fb10-11e9-91af-623cf93d857c)
Oct 30 12:24:30.737: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-777.svc.cluster.local from pod dns-777/dns-test-368db874-fb10-11e9-91af-623cf93d857c: the server could not find the requested resource (get pods dns-test-368db874-fb10-11e9-91af-623cf93d857c)
Oct 30 12:24:30.793: INFO: Lookups using dns-777/dns-test-368db874-fb10-11e9-91af-623cf93d857c failed for: [wheezy_udp@dns-test-service.dns-777.svc.cluster.local wheezy_tcp@dns-test-service.dns-777.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-777.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-777.svc.cluster.local jessie_udp@dns-test-service.dns-777.svc.cluster.local jessie_tcp@dns-test-service.dns-777.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-777.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-777.svc.cluster.local]

Oct 30 12:24:36.009: INFO: DNS probes using dns-777/dns-test-368db874-fb10-11e9-91af-623cf93d857c succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:24:36.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-777" for this suite.
Oct 30 12:24:42.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:24:42.843: INFO: namespace dns-777 deletion completed in 6.531507474s

â€¢ [SLOW TEST:16.642 seconds]
[sig-network] DNS
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:24:42.855: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 30 12:24:43.007: INFO: Waiting up to 5m0s for pod "pod-4061eada-fb10-11e9-91af-623cf93d857c" in namespace "emptydir-3635" to be "success or failure"
Oct 30 12:24:43.015: INFO: Pod "pod-4061eada-fb10-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.028372ms
Oct 30 12:24:45.023: INFO: Pod "pod-4061eada-fb10-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016023093s
Oct 30 12:24:47.031: INFO: Pod "pod-4061eada-fb10-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024004268s
STEP: Saw pod success
Oct 30 12:24:47.031: INFO: Pod "pod-4061eada-fb10-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:24:47.039: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-4061eada-fb10-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 12:24:47.091: INFO: Waiting for pod pod-4061eada-fb10-11e9-91af-623cf93d857c to disappear
Oct 30 12:24:47.098: INFO: Pod pod-4061eada-fb10-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:24:47.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3635" for this suite.
Oct 30 12:24:53.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:24:53.508: INFO: namespace emptydir-3635 deletion completed in 6.400102118s

â€¢ [SLOW TEST:10.653 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:24:53.508: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 12:24:53.661: INFO: Waiting up to 5m0s for pod "downwardapi-volume-46bd0cc1-fb10-11e9-91af-623cf93d857c" in namespace "projected-5097" to be "success or failure"
Oct 30 12:24:53.670: INFO: Pod "downwardapi-volume-46bd0cc1-fb10-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.169955ms
Oct 30 12:24:55.682: INFO: Pod "downwardapi-volume-46bd0cc1-fb10-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021174912s
Oct 30 12:24:57.692: INFO: Pod "downwardapi-volume-46bd0cc1-fb10-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03063448s
STEP: Saw pod success
Oct 30 12:24:57.692: INFO: Pod "downwardapi-volume-46bd0cc1-fb10-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:24:57.697: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod downwardapi-volume-46bd0cc1-fb10-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 12:24:57.781: INFO: Waiting for pod downwardapi-volume-46bd0cc1-fb10-11e9-91af-623cf93d857c to disappear
Oct 30 12:24:57.787: INFO: Pod downwardapi-volume-46bd0cc1-fb10-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:24:57.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5097" for this suite.
Oct 30 12:25:03.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:25:04.159: INFO: namespace projected-5097 deletion completed in 6.362606831s

â€¢ [SLOW TEST:10.651 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:25:04.163: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-4d13242d-fb10-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume secrets
Oct 30 12:25:04.307: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4d1601cf-fb10-11e9-91af-623cf93d857c" in namespace "projected-5242" to be "success or failure"
Oct 30 12:25:04.315: INFO: Pod "pod-projected-secrets-4d1601cf-fb10-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.135029ms
Oct 30 12:25:06.335: INFO: Pod "pod-projected-secrets-4d1601cf-fb10-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027482404s
Oct 30 12:25:08.347: INFO: Pod "pod-projected-secrets-4d1601cf-fb10-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039362281s
STEP: Saw pod success
Oct 30 12:25:08.347: INFO: Pod "pod-projected-secrets-4d1601cf-fb10-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:25:08.354: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-projected-secrets-4d1601cf-fb10-11e9-91af-623cf93d857c container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 30 12:25:08.410: INFO: Waiting for pod pod-projected-secrets-4d1601cf-fb10-11e9-91af-623cf93d857c to disappear
Oct 30 12:25:08.417: INFO: Pod pod-projected-secrets-4d1601cf-fb10-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:25:08.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5242" for this suite.
Oct 30 12:25:14.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:25:14.763: INFO: namespace projected-5242 deletion completed in 6.335041967s

â€¢ [SLOW TEST:10.601 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:25:14.765: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:25:43.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3976" for this suite.
Oct 30 12:25:49.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:25:50.070: INFO: namespace container-runtime-3976 deletion completed in 6.379617479s

â€¢ [SLOW TEST:35.306 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:25:50.071: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:25:54.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5835" for this suite.
Oct 30 12:26:34.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:26:34.911: INFO: namespace kubelet-test-5835 deletion completed in 40.325750635s

â€¢ [SLOW TEST:44.840 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:26:34.916: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1030 12:26:45.332024      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 30 12:26:45.332: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:26:45.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2789" for this suite.
Oct 30 12:26:53.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:26:53.646: INFO: namespace gc-2789 deletion completed in 8.304946314s

â€¢ [SLOW TEST:18.731 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:26:53.647: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct 30 12:26:58.362: INFO: Successfully updated pod "labelsupdate8e523595-fb10-11e9-91af-623cf93d857c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:27:00.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7347" for this suite.
Oct 30 12:27:24.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:27:24.773: INFO: namespace downward-api-7347 deletion completed in 24.356699605s

â€¢ [SLOW TEST:31.125 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:27:24.775: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 12:27:24.881: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:27:29.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6505" for this suite.
Oct 30 12:28:19.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:28:19.493: INFO: namespace pods-6505 deletion completed in 50.354643224s

â€¢ [SLOW TEST:54.718 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:28:19.495: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Oct 30 12:28:19.629: INFO: Waiting up to 5m0s for pod "downward-api-c18118f1-fb10-11e9-91af-623cf93d857c" in namespace "downward-api-5544" to be "success or failure"
Oct 30 12:28:19.639: INFO: Pod "downward-api-c18118f1-fb10-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.844323ms
Oct 30 12:28:21.647: INFO: Pod "downward-api-c18118f1-fb10-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017177398s
Oct 30 12:28:23.655: INFO: Pod "downward-api-c18118f1-fb10-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025432979s
STEP: Saw pod success
Oct 30 12:28:23.655: INFO: Pod "downward-api-c18118f1-fb10-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:28:23.667: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod downward-api-c18118f1-fb10-11e9-91af-623cf93d857c container dapi-container: <nil>
STEP: delete the pod
Oct 30 12:28:23.734: INFO: Waiting for pod downward-api-c18118f1-fb10-11e9-91af-623cf93d857c to disappear
Oct 30 12:28:23.741: INFO: Pod downward-api-c18118f1-fb10-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:28:23.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5544" for this suite.
Oct 30 12:28:29.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:28:30.114: INFO: namespace downward-api-5544 deletion completed in 6.364189686s

â€¢ [SLOW TEST:10.619 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:28:30.115: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-c7d6db41-fb10-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume secrets
Oct 30 12:28:30.328: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c7dd5b7b-fb10-11e9-91af-623cf93d857c" in namespace "projected-419" to be "success or failure"
Oct 30 12:28:30.348: INFO: Pod "pod-projected-secrets-c7dd5b7b-fb10-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 20.081747ms
Oct 30 12:28:32.362: INFO: Pod "pod-projected-secrets-c7dd5b7b-fb10-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034409755s
Oct 30 12:28:34.372: INFO: Pod "pod-projected-secrets-c7dd5b7b-fb10-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044517893s
STEP: Saw pod success
Oct 30 12:28:34.372: INFO: Pod "pod-projected-secrets-c7dd5b7b-fb10-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:28:34.379: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-projected-secrets-c7dd5b7b-fb10-11e9-91af-623cf93d857c container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 30 12:28:34.502: INFO: Waiting for pod pod-projected-secrets-c7dd5b7b-fb10-11e9-91af-623cf93d857c to disappear
Oct 30 12:28:34.514: INFO: Pod pod-projected-secrets-c7dd5b7b-fb10-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:28:34.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-419" for this suite.
Oct 30 12:28:42.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:28:43.273: INFO: namespace projected-419 deletion completed in 8.748774309s

â€¢ [SLOW TEST:13.158 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:28:43.276: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 30 12:28:48.062: INFO: Successfully updated pod "pod-update-cfbbca1e-fb10-11e9-91af-623cf93d857c"
STEP: verifying the updated pod is in kubernetes
Oct 30 12:28:48.079: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:28:48.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3536" for this suite.
Oct 30 12:29:12.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:29:12.408: INFO: namespace pods-3536 deletion completed in 24.318225334s

â€¢ [SLOW TEST:29.132 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:29:12.410: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-e11b53ec-fb10-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume configMaps
Oct 30 12:29:12.892: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e1254234-fb10-11e9-91af-623cf93d857c" in namespace "projected-2983" to be "success or failure"
Oct 30 12:29:12.905: INFO: Pod "pod-projected-configmaps-e1254234-fb10-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.608649ms
Oct 30 12:29:14.915: INFO: Pod "pod-projected-configmaps-e1254234-fb10-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022999977s
Oct 30 12:29:16.928: INFO: Pod "pod-projected-configmaps-e1254234-fb10-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03515965s
STEP: Saw pod success
Oct 30 12:29:16.928: INFO: Pod "pod-projected-configmaps-e1254234-fb10-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:29:16.935: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-projected-configmaps-e1254234-fb10-11e9-91af-623cf93d857c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 12:29:17.012: INFO: Waiting for pod pod-projected-configmaps-e1254234-fb10-11e9-91af-623cf93d857c to disappear
Oct 30 12:29:17.019: INFO: Pod pod-projected-configmaps-e1254234-fb10-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:29:17.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2983" for this suite.
Oct 30 12:29:23.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:29:23.413: INFO: namespace projected-2983 deletion completed in 6.382650911s

â€¢ [SLOW TEST:11.004 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:29:23.419: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-8759/configmap-test-e79c94a7-fb10-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume configMaps
Oct 30 12:29:23.612: INFO: Waiting up to 5m0s for pod "pod-configmaps-e7a13d07-fb10-11e9-91af-623cf93d857c" in namespace "configmap-8759" to be "success or failure"
Oct 30 12:29:23.650: INFO: Pod "pod-configmaps-e7a13d07-fb10-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 37.885125ms
Oct 30 12:29:25.659: INFO: Pod "pod-configmaps-e7a13d07-fb10-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046842753s
Oct 30 12:29:27.669: INFO: Pod "pod-configmaps-e7a13d07-fb10-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056482719s
STEP: Saw pod success
Oct 30 12:29:27.669: INFO: Pod "pod-configmaps-e7a13d07-fb10-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:29:27.676: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-configmaps-e7a13d07-fb10-11e9-91af-623cf93d857c container env-test: <nil>
STEP: delete the pod
Oct 30 12:29:27.797: INFO: Waiting for pod pod-configmaps-e7a13d07-fb10-11e9-91af-623cf93d857c to disappear
Oct 30 12:29:27.805: INFO: Pod pod-configmaps-e7a13d07-fb10-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:29:27.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8759" for this suite.
Oct 30 12:29:33.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:29:34.260: INFO: namespace configmap-8759 deletion completed in 6.447386998s

â€¢ [SLOW TEST:10.842 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:29:34.261: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-1145
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1145 to expose endpoints map[]
Oct 30 12:29:34.500: INFO: successfully validated that service endpoint-test2 in namespace services-1145 exposes endpoints map[] (12.510226ms elapsed)
STEP: Creating pod pod1 in namespace services-1145
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1145 to expose endpoints map[pod1:[80]]
Oct 30 12:29:38.650: INFO: successfully validated that service endpoint-test2 in namespace services-1145 exposes endpoints map[pod1:[80]] (4.10244726s elapsed)
STEP: Creating pod pod2 in namespace services-1145
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1145 to expose endpoints map[pod1:[80] pod2:[80]]
Oct 30 12:29:41.965: INFO: successfully validated that service endpoint-test2 in namespace services-1145 exposes endpoints map[pod1:[80] pod2:[80]] (3.123750266s elapsed)
STEP: Deleting pod pod1 in namespace services-1145
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1145 to expose endpoints map[pod2:[80]]
Oct 30 12:29:42.253: INFO: successfully validated that service endpoint-test2 in namespace services-1145 exposes endpoints map[pod2:[80]] (267.598757ms elapsed)
STEP: Deleting pod pod2 in namespace services-1145
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1145 to expose endpoints map[]
Oct 30 12:29:43.399: INFO: successfully validated that service endpoint-test2 in namespace services-1145 exposes endpoints map[] (1.102364469s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:29:43.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1145" for this suite.
Oct 30 12:29:49.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:29:50.183: INFO: namespace services-1145 deletion completed in 6.386745386s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

â€¢ [SLOW TEST:15.923 seconds]
[sig-network] Services
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:29:50.186: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Oct 30 12:29:50.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 cluster-info'
Oct 30 12:29:50.413: INFO: stderr: ""
Oct 30 12:29:50.413: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:29:50.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3550" for this suite.
Oct 30 12:29:56.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:29:56.750: INFO: namespace kubectl-3550 deletion completed in 6.32346064s

â€¢ [SLOW TEST:6.565 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:29:56.752: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:30:01.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6362" for this suite.
Oct 30 12:30:41.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:30:41.427: INFO: namespace kubelet-test-6362 deletion completed in 40.339508985s

â€¢ [SLOW TEST:44.675 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:30:41.429: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Oct 30 12:30:41.655: INFO: Waiting up to 5m0s for pod "pod-161ff110-fb11-11e9-91af-623cf93d857c" in namespace "emptydir-4579" to be "success or failure"
Oct 30 12:30:41.663: INFO: Pod "pod-161ff110-fb11-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.878049ms
Oct 30 12:30:43.804: INFO: Pod "pod-161ff110-fb11-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.149265648s
Oct 30 12:30:45.815: INFO: Pod "pod-161ff110-fb11-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.159797737s
STEP: Saw pod success
Oct 30 12:30:45.815: INFO: Pod "pod-161ff110-fb11-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:30:45.826: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-161ff110-fb11-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 12:30:45.919: INFO: Waiting for pod pod-161ff110-fb11-11e9-91af-623cf93d857c to disappear
Oct 30 12:30:45.927: INFO: Pod pod-161ff110-fb11-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:30:45.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4579" for this suite.
Oct 30 12:30:52.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:30:52.430: INFO: namespace emptydir-4579 deletion completed in 6.457402741s

â€¢ [SLOW TEST:11.001 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:30:52.432: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1030 12:31:32.697377      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 30 12:31:32.697: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:31:32.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6444" for this suite.
Oct 30 12:31:41.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:31:42.424: INFO: namespace gc-6444 deletion completed in 9.716597241s

â€¢ [SLOW TEST:49.992 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:31:42.427: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 12:31:42.597: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct 30 12:31:47.609: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 30 12:31:47.609: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct 30 12:31:49.618: INFO: Creating deployment "test-rollover-deployment"
Oct 30 12:31:49.644: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct 30 12:31:51.672: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct 30 12:31:51.689: INFO: Ensure that both replica sets have 1 created replica
Oct 30 12:31:51.704: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct 30 12:31:51.752: INFO: Updating deployment test-rollover-deployment
Oct 30 12:31:51.752: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct 30 12:31:53.851: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct 30 12:31:53.868: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct 30 12:31:53.886: INFO: all replica sets need to contain the pod-template-hash label
Oct 30 12:31:53.886: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035513, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 12:31:55.906: INFO: all replica sets need to contain the pod-template-hash label
Oct 30 12:31:55.906: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035513, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 12:31:57.905: INFO: all replica sets need to contain the pod-template-hash label
Oct 30 12:31:57.905: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035515, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 12:31:59.906: INFO: all replica sets need to contain the pod-template-hash label
Oct 30 12:31:59.906: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035515, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 12:32:01.905: INFO: all replica sets need to contain the pod-template-hash label
Oct 30 12:32:01.905: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035515, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 12:32:03.905: INFO: all replica sets need to contain the pod-template-hash label
Oct 30 12:32:03.905: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035515, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 12:32:05.903: INFO: all replica sets need to contain the pod-template-hash label
Oct 30 12:32:05.903: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035515, loc:(*time.Location)(0x882f100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708035509, loc:(*time.Location)(0x882f100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 30 12:32:07.903: INFO: 
Oct 30 12:32:07.903: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 30 12:32:07.931: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-7778,SelfLink:/apis/apps/v1/namespaces/deployment-7778/deployments/test-rollover-deployment,UID:3eaf5c4e-fb11-11e9-a053-fa163e61542c,ResourceVersion:24582,Generation:2,CreationTimestamp:2019-10-30 12:31:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-30 12:31:49 +0000 UTC 2019-10-30 12:31:49 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-30 12:32:06 +0000 UTC 2019-10-30 12:31:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-659c699649" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 30 12:32:07.938: INFO: New ReplicaSet "test-rollover-deployment-659c699649" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649,GenerateName:,Namespace:deployment-7778,SelfLink:/apis/apps/v1/namespaces/deployment-7778/replicasets/test-rollover-deployment-659c699649,UID:3ff44a04-fb11-11e9-ad48-fa163ee0935a,ResourceVersion:24571,Generation:2,CreationTimestamp:2019-10-30 12:31:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 3eaf5c4e-fb11-11e9-a053-fa163e61542c 0xc00349dc27 0xc00349dc28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 30 12:32:07.938: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct 30 12:32:07.939: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-7778,SelfLink:/apis/apps/v1/namespaces/deployment-7778/replicasets/test-rollover-controller,UID:3a79a2d9-fb11-11e9-a053-fa163e61542c,ResourceVersion:24581,Generation:2,CreationTimestamp:2019-10-30 12:31:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 3eaf5c4e-fb11-11e9-a053-fa163e61542c 0xc00349db57 0xc00349db58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 30 12:32:07.939: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-7b45b6464,GenerateName:,Namespace:deployment-7778,SelfLink:/apis/apps/v1/namespaces/deployment-7778/replicasets/test-rollover-deployment-7b45b6464,UID:3eb4ca73-fb11-11e9-ad48-fa163ee0935a,ResourceVersion:24528,Generation:2,CreationTimestamp:2019-10-30 12:31:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 3eaf5c4e-fb11-11e9-a053-fa163e61542c 0xc00349dcf0 0xc00349dcf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 30 12:32:07.946: INFO: Pod "test-rollover-deployment-659c699649-ntpzc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649-ntpzc,GenerateName:test-rollover-deployment-659c699649-,Namespace:deployment-7778,SelfLink:/api/v1/namespaces/deployment-7778/pods/test-rollover-deployment-659c699649-ntpzc,UID:408940ef-fb11-11e9-ad48-fa163ee0935a,ResourceVersion:24542,Generation:0,CreationTimestamp:2019-10-30 12:31:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.4.118/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-659c699649 3ff44a04-fb11-11e9-ad48-fa163ee0935a 0xc00301a977 0xc00301a978}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-b8vzk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-b8vzk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-b8vzk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00301a9e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00301aa00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:31:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:31:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:31:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:31:52 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.39,PodIP:10.233.4.118,StartTime:2019-10-30 12:31:52 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-30 12:31:55 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://f34f81fd1c0162f84e63bf3b08e01225b6dff72f11f2992d48988075c9d11d44}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:32:07.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7778" for this suite.
Oct 30 12:32:15.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:32:16.269: INFO: namespace deployment-7778 deletion completed in 8.307921065s

â€¢ [SLOW TEST:33.842 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:32:16.271: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 30 12:32:16.439: INFO: Waiting up to 5m0s for pod "pod-4ea44598-fb11-11e9-91af-623cf93d857c" in namespace "emptydir-6534" to be "success or failure"
Oct 30 12:32:16.448: INFO: Pod "pod-4ea44598-fb11-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.088198ms
Oct 30 12:32:18.457: INFO: Pod "pod-4ea44598-fb11-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018315525s
Oct 30 12:32:20.467: INFO: Pod "pod-4ea44598-fb11-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027722105s
STEP: Saw pod success
Oct 30 12:32:20.467: INFO: Pod "pod-4ea44598-fb11-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:32:20.473: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-4ea44598-fb11-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 12:32:20.562: INFO: Waiting for pod pod-4ea44598-fb11-11e9-91af-623cf93d857c to disappear
Oct 30 12:32:20.570: INFO: Pod pod-4ea44598-fb11-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:32:20.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6534" for this suite.
Oct 30 12:32:26.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:32:26.899: INFO: namespace emptydir-6534 deletion completed in 6.318892849s

â€¢ [SLOW TEST:10.628 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:32:26.899: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-54ffae71-fb11-11e9-91af-623cf93d857c
STEP: Creating configMap with name cm-test-opt-upd-54ffafc9-fb11-11e9-91af-623cf93d857c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-54ffae71-fb11-11e9-91af-623cf93d857c
STEP: Updating configmap cm-test-opt-upd-54ffafc9-fb11-11e9-91af-623cf93d857c
STEP: Creating configMap with name cm-test-opt-create-54ffb0ad-fb11-11e9-91af-623cf93d857c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:32:33.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-844" for this suite.
Oct 30 12:32:57.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:32:57.852: INFO: namespace projected-844 deletion completed in 24.398016517s

â€¢ [SLOW TEST:30.952 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:32:57.852: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 30 12:33:06.152: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 12:33:06.159: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 12:33:08.160: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 12:33:08.168: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 12:33:10.160: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 12:33:10.168: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 12:33:12.160: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 12:33:12.171: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 12:33:14.160: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 12:33:14.168: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 12:33:16.160: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 12:33:16.168: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 12:33:18.160: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 12:33:18.170: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 12:33:20.160: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 12:33:20.168: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 12:33:22.160: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 12:33:22.184: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 12:33:24.160: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 12:33:24.167: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 12:33:26.160: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 12:33:26.178: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 30 12:33:28.160: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 30 12:33:28.170: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:33:28.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2086" for this suite.
Oct 30 12:33:52.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:33:52.514: INFO: namespace container-lifecycle-hook-2086 deletion completed in 24.33296139s

â€¢ [SLOW TEST:54.662 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:33:52.514: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Oct 30 12:33:52.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 --namespace=kubectl-9032 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Oct 30 12:33:55.805: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Oct 30 12:33:55.805: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:33:57.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9032" for this suite.
Oct 30 12:34:03.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:34:04.337: INFO: namespace kubectl-9032 deletion completed in 6.508903596s

â€¢ [SLOW TEST:11.823 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:34:04.339: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-9260
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 30 12:34:04.475: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 30 12:34:28.735: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.4.121:8080/dial?request=hostName&protocol=udp&host=10.233.3.55&port=8081&tries=1'] Namespace:pod-network-test-9260 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 12:34:28.735: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 12:34:28.931: INFO: Waiting for endpoints: map[]
Oct 30 12:34:28.939: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.4.121:8080/dial?request=hostName&protocol=udp&host=10.233.5.105&port=8081&tries=1'] Namespace:pod-network-test-9260 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 12:34:28.939: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 12:34:29.117: INFO: Waiting for endpoints: map[]
Oct 30 12:34:29.128: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.4.121:8080/dial?request=hostName&protocol=udp&host=10.233.4.120&port=8081&tries=1'] Namespace:pod-network-test-9260 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 12:34:29.128: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 12:34:29.307: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:34:29.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9260" for this suite.
Oct 30 12:34:53.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:34:53.666: INFO: namespace pod-network-test-9260 deletion completed in 24.338130018s

â€¢ [SLOW TEST:49.327 seconds]
[sig-network] Networking
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:34:53.670: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Oct 30 12:34:53.873: INFO: Waiting up to 5m0s for pod "client-containers-ac7a5442-fb11-11e9-91af-623cf93d857c" in namespace "containers-7941" to be "success or failure"
Oct 30 12:34:53.915: INFO: Pod "client-containers-ac7a5442-fb11-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 41.123757ms
Oct 30 12:34:55.947: INFO: Pod "client-containers-ac7a5442-fb11-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073649235s
Oct 30 12:34:57.956: INFO: Pod "client-containers-ac7a5442-fb11-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.082972396s
STEP: Saw pod success
Oct 30 12:34:57.957: INFO: Pod "client-containers-ac7a5442-fb11-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:34:57.964: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod client-containers-ac7a5442-fb11-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 12:34:58.023: INFO: Waiting for pod client-containers-ac7a5442-fb11-11e9-91af-623cf93d857c to disappear
Oct 30 12:34:58.031: INFO: Pod client-containers-ac7a5442-fb11-11e9-91af-623cf93d857c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:34:58.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7941" for this suite.
Oct 30 12:35:04.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:35:04.403: INFO: namespace containers-7941 deletion completed in 6.36057125s

â€¢ [SLOW TEST:10.734 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:35:04.404: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-b2e1d3f9-fb11-11e9-91af-623cf93d857c
STEP: Creating secret with name s-test-opt-upd-b2e1d5a7-fb11-11e9-91af-623cf93d857c
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b2e1d3f9-fb11-11e9-91af-623cf93d857c
STEP: Updating secret s-test-opt-upd-b2e1d5a7-fb11-11e9-91af-623cf93d857c
STEP: Creating secret with name s-test-opt-create-b2e1d5de-fb11-11e9-91af-623cf93d857c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:35:10.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8761" for this suite.
Oct 30 12:35:34.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:35:35.207: INFO: namespace projected-8761 deletion completed in 24.337859391s

â€¢ [SLOW TEST:30.803 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:35:35.209: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-7880
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7880 to expose endpoints map[]
Oct 30 12:35:35.650: INFO: successfully validated that service multi-endpoint-test in namespace services-7880 exposes endpoints map[] (10.978134ms elapsed)
STEP: Creating pod pod1 in namespace services-7880
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7880 to expose endpoints map[pod1:[100]]
Oct 30 12:35:38.765: INFO: successfully validated that service multi-endpoint-test in namespace services-7880 exposes endpoints map[pod1:[100]] (3.078079316s elapsed)
STEP: Creating pod pod2 in namespace services-7880
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7880 to expose endpoints map[pod1:[100] pod2:[101]]
Oct 30 12:35:41.964: INFO: successfully validated that service multi-endpoint-test in namespace services-7880 exposes endpoints map[pod1:[100] pod2:[101]] (3.18365264s elapsed)
STEP: Deleting pod pod1 in namespace services-7880
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7880 to expose endpoints map[pod2:[101]]
Oct 30 12:35:43.022: INFO: successfully validated that service multi-endpoint-test in namespace services-7880 exposes endpoints map[pod2:[101]] (1.042283852s elapsed)
STEP: Deleting pod pod2 in namespace services-7880
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7880 to expose endpoints map[]
Oct 30 12:35:43.086: INFO: successfully validated that service multi-endpoint-test in namespace services-7880 exposes endpoints map[] (15.013318ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:35:43.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7880" for this suite.
Oct 30 12:36:07.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:36:07.554: INFO: namespace services-7880 deletion completed in 24.341089643s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

â€¢ [SLOW TEST:32.345 seconds]
[sig-network] Services
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:36:07.555: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 12:36:07.694: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d87ce898-fb11-11e9-91af-623cf93d857c" in namespace "downward-api-3030" to be "success or failure"
Oct 30 12:36:07.702: INFO: Pod "downwardapi-volume-d87ce898-fb11-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.89288ms
Oct 30 12:36:09.713: INFO: Pod "downwardapi-volume-d87ce898-fb11-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018826888s
Oct 30 12:36:11.724: INFO: Pod "downwardapi-volume-d87ce898-fb11-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030012921s
STEP: Saw pod success
Oct 30 12:36:11.724: INFO: Pod "downwardapi-volume-d87ce898-fb11-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:36:11.731: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod downwardapi-volume-d87ce898-fb11-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 12:36:11.789: INFO: Waiting for pod downwardapi-volume-d87ce898-fb11-11e9-91af-623cf93d857c to disappear
Oct 30 12:36:11.798: INFO: Pod downwardapi-volume-d87ce898-fb11-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:36:11.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3030" for this suite.
Oct 30 12:36:17.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:36:18.117: INFO: namespace downward-api-3030 deletion completed in 6.309433609s

â€¢ [SLOW TEST:10.563 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:36:18.123: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-dec99b5a-fb11-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume configMaps
Oct 30 12:36:18.273: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-decc3df4-fb11-11e9-91af-623cf93d857c" in namespace "projected-935" to be "success or failure"
Oct 30 12:36:18.286: INFO: Pod "pod-projected-configmaps-decc3df4-fb11-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.331209ms
Oct 30 12:36:20.295: INFO: Pod "pod-projected-configmaps-decc3df4-fb11-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021641618s
Oct 30 12:36:22.305: INFO: Pod "pod-projected-configmaps-decc3df4-fb11-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031557976s
STEP: Saw pod success
Oct 30 12:36:22.305: INFO: Pod "pod-projected-configmaps-decc3df4-fb11-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:36:22.316: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-projected-configmaps-decc3df4-fb11-11e9-91af-623cf93d857c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 12:36:22.364: INFO: Waiting for pod pod-projected-configmaps-decc3df4-fb11-11e9-91af-623cf93d857c to disappear
Oct 30 12:36:22.374: INFO: Pod pod-projected-configmaps-decc3df4-fb11-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:36:22.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-935" for this suite.
Oct 30 12:36:28.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:36:28.786: INFO: namespace projected-935 deletion completed in 6.398216442s

â€¢ [SLOW TEST:10.663 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:36:28.789: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 12:36:28.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 create -f - --namespace=kubectl-586'
Oct 30 12:36:29.310: INFO: stderr: ""
Oct 30 12:36:29.310: INFO: stdout: "replicationcontroller/redis-master created\n"
Oct 30 12:36:29.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 create -f - --namespace=kubectl-586'
Oct 30 12:36:29.610: INFO: stderr: ""
Oct 30 12:36:29.610: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 30 12:36:30.619: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 12:36:30.619: INFO: Found 0 / 1
Oct 30 12:36:31.620: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 12:36:31.620: INFO: Found 1 / 1
Oct 30 12:36:31.620: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 30 12:36:31.630: INFO: Selector matched 1 pods for map[app:redis]
Oct 30 12:36:31.630: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 30 12:36:31.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 describe pod redis-master-52bwr --namespace=kubectl-586'
Oct 30 12:36:31.780: INFO: stderr: ""
Oct 30 12:36:31.780: INFO: stdout: "Name:               redis-master-52bwr\nNamespace:          kubectl-586\nPriority:           0\nPriorityClassName:  <none>\nNode:               koris-pipeline-56683fb-92514359-node-1/10.0.0.39\nStart Time:         Wed, 30 Oct 2019 12:36:29 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.233.4.123/32\nStatus:             Running\nIP:                 10.233.4.123\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://903e4c7ed51c249e1e690f39079a6be5749ff80bbdcb493eab93a9ca74ad1426\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 30 Oct 2019 12:36:30 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-htsrk (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-htsrk:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-htsrk\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                             Message\n  ----    ------     ----  ----                                             -------\n  Normal  Scheduled  2s    default-scheduler                                Successfully assigned kubectl-586/redis-master-52bwr to koris-pipeline-56683fb-92514359-node-1\n  Normal  Pulled     1s    kubelet, koris-pipeline-56683fb-92514359-node-1  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, koris-pipeline-56683fb-92514359-node-1  Created container redis-master\n  Normal  Started    1s    kubelet, koris-pipeline-56683fb-92514359-node-1  Started container redis-master\n"
Oct 30 12:36:31.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 describe rc redis-master --namespace=kubectl-586'
Oct 30 12:36:31.972: INFO: stderr: ""
Oct 30 12:36:31.972: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-586\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-52bwr\n"
Oct 30 12:36:31.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 describe service redis-master --namespace=kubectl-586'
Oct 30 12:36:32.140: INFO: stderr: ""
Oct 30 12:36:32.140: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-586\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.97.102.87\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.233.4.123:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct 30 12:36:32.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 describe node koris-pipeline-56683fb-92514359-master-1'
Oct 30 12:36:32.356: INFO: stderr: ""
Oct 30 12:36:32.356: INFO: stdout: "Name:               koris-pipeline-56683fb-92514359-master-1\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=koris-pipeline-56683fb-92514359-master-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.0.0.12/24\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 30 Oct 2019 11:02:40 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 30 Oct 2019 12:35:51 +0000   Wed, 30 Oct 2019 11:02:40 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 30 Oct 2019 12:35:51 +0000   Wed, 30 Oct 2019 11:02:40 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 30 Oct 2019 12:35:51 +0000   Wed, 30 Oct 2019 11:02:40 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 30 Oct 2019 12:35:51 +0000   Wed, 30 Oct 2019 11:04:20 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.0.0.12\n  Hostname:    koris-pipeline-56683fb-92514359-master-1\nCapacity:\n cpu:                2\n ephemeral-storage:  25346088Ki\n hugepages-2Mi:      0\n memory:             8168296Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  23358954663\n hugepages-2Mi:      0\n memory:             8065896Ki\n pods:               110\nSystem Info:\n Machine ID:                 c3fd4b929df145ba8fc081eb76adeb3c\n System UUID:                941F5011-5579-422D-BC4C-EA7AC54FD18B\n Boot ID:                    2f115c70-62f1-4873-8236-7834f65d4d6f\n Kernel Version:             4.15.0-66-generic\n OS Image:                   Ubuntu 16.04.6 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.14.8\n Kube-Proxy Version:         v1.14.8\nPodCIDR:                     10.233.0.0/24\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                                ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-node-j6tsx                                                   250m (12%)    0 (0%)      0 (0%)           0 (0%)         92m\n  kube-system                coredns-6dcc67dcbc-dzvt5                                            100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     93m\n  kube-system                coredns-6dcc67dcbc-wzplc                                            100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     93m\n  kube-system                etcd-koris-pipeline-56683fb-92514359-master-1                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         92m\n  kube-system                kube-apiserver-koris-pipeline-56683fb-92514359-master-1             250m (12%)    0 (0%)      0 (0%)           0 (0%)         93m\n  kube-system                kube-controller-manager-koris-pipeline-56683fb-92514359-master-1    200m (10%)    0 (0%)      0 (0%)           0 (0%)         92m\n  kube-system                kube-proxy-qlh5r                                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         93m\n  kube-system                kube-scheduler-koris-pipeline-56683fb-92514359-master-1             100m (5%)     0 (0%)      0 (0%)           0 (0%)         93m\n  kube-system                openstack-cloud-controller-manager-gwc5n                            200m (10%)    0 (0%)      0 (0%)           0 (0%)         92m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-aac87c55e38d426f-2zvlw             0 (0%)        0 (0%)      0 (0%)           0 (0%)         73m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                1200m (60%)  0 (0%)\n  memory             140Mi (1%)   340Mi (4%)\n  ephemeral-storage  0 (0%)       0 (0%)\nEvents:\n  Type    Reason                   Age                From                                                  Message\n  ----    ------                   ----               ----                                                  -------\n  Normal  Starting                 94m                kubelet, koris-pipeline-56683fb-92514359-master-1     Starting kubelet.\n  Normal  NodeAllocatableEnforced  94m                kubelet, koris-pipeline-56683fb-92514359-master-1     Updated Node Allocatable limit across pods\n  Normal  NodeHasSufficientMemory  94m (x8 over 94m)  kubelet, koris-pipeline-56683fb-92514359-master-1     Node koris-pipeline-56683fb-92514359-master-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    94m (x8 over 94m)  kubelet, koris-pipeline-56683fb-92514359-master-1     Node koris-pipeline-56683fb-92514359-master-1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     94m (x7 over 94m)  kubelet, koris-pipeline-56683fb-92514359-master-1     Node koris-pipeline-56683fb-92514359-master-1 status is now: NodeHasSufficientPID\n  Normal  Starting                 93m                kube-proxy, koris-pipeline-56683fb-92514359-master-1  Starting kube-proxy.\n"
Oct 30 12:36:32.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 describe namespace kubectl-586'
Oct 30 12:36:32.515: INFO: stderr: ""
Oct 30 12:36:32.515: INFO: stdout: "Name:         kubectl-586\nLabels:       e2e-framework=kubectl\n              e2e-run=b6cf28fe-fb07-11e9-91af-623cf93d857c\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:36:32.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-586" for this suite.
Oct 30 12:36:56.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:36:56.848: INFO: namespace kubectl-586 deletion completed in 24.314523387s

â€¢ [SLOW TEST:28.059 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:36:56.849: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 12:36:56.987: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:36:58.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9626" for this suite.
Oct 30 12:37:04.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:37:04.450: INFO: namespace custom-resource-definition-9626 deletion completed in 6.332398123s

â€¢ [SLOW TEST:7.601 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:32
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:37:04.452: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-5379
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-5379
STEP: Deleting pre-stop pod
Oct 30 12:37:19.822: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:37:19.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-5379" for this suite.
Oct 30 12:38:00.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:38:00.426: INFO: namespace prestop-5379 deletion completed in 40.412462046s

â€¢ [SLOW TEST:55.975 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:38:00.429: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-gp94
STEP: Creating a pod to test atomic-volume-subpath
Oct 30 12:38:00.668: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-gp94" in namespace "subpath-1625" to be "success or failure"
Oct 30 12:38:00.681: INFO: Pod "pod-subpath-test-downwardapi-gp94": Phase="Pending", Reason="", readiness=false. Elapsed: 12.921966ms
Oct 30 12:38:02.689: INFO: Pod "pod-subpath-test-downwardapi-gp94": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021754766s
Oct 30 12:38:04.707: INFO: Pod "pod-subpath-test-downwardapi-gp94": Phase="Running", Reason="", readiness=true. Elapsed: 4.039122262s
Oct 30 12:38:06.717: INFO: Pod "pod-subpath-test-downwardapi-gp94": Phase="Running", Reason="", readiness=true. Elapsed: 6.049209105s
Oct 30 12:38:08.728: INFO: Pod "pod-subpath-test-downwardapi-gp94": Phase="Running", Reason="", readiness=true. Elapsed: 8.060167962s
Oct 30 12:38:10.737: INFO: Pod "pod-subpath-test-downwardapi-gp94": Phase="Running", Reason="", readiness=true. Elapsed: 10.069775526s
Oct 30 12:38:12.746: INFO: Pod "pod-subpath-test-downwardapi-gp94": Phase="Running", Reason="", readiness=true. Elapsed: 12.078350453s
Oct 30 12:38:14.755: INFO: Pod "pod-subpath-test-downwardapi-gp94": Phase="Running", Reason="", readiness=true. Elapsed: 14.086842156s
Oct 30 12:38:16.764: INFO: Pod "pod-subpath-test-downwardapi-gp94": Phase="Running", Reason="", readiness=true. Elapsed: 16.096079818s
Oct 30 12:38:18.775: INFO: Pod "pod-subpath-test-downwardapi-gp94": Phase="Running", Reason="", readiness=true. Elapsed: 18.107279961s
Oct 30 12:38:20.785: INFO: Pod "pod-subpath-test-downwardapi-gp94": Phase="Running", Reason="", readiness=true. Elapsed: 20.116868362s
Oct 30 12:38:22.793: INFO: Pod "pod-subpath-test-downwardapi-gp94": Phase="Running", Reason="", readiness=true. Elapsed: 22.124923207s
Oct 30 12:38:24.806: INFO: Pod "pod-subpath-test-downwardapi-gp94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.137841147s
STEP: Saw pod success
Oct 30 12:38:24.806: INFO: Pod "pod-subpath-test-downwardapi-gp94" satisfied condition "success or failure"
Oct 30 12:38:24.813: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-subpath-test-downwardapi-gp94 container test-container-subpath-downwardapi-gp94: <nil>
STEP: delete the pod
Oct 30 12:38:24.874: INFO: Waiting for pod pod-subpath-test-downwardapi-gp94 to disappear
Oct 30 12:38:24.885: INFO: Pod pod-subpath-test-downwardapi-gp94 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-gp94
Oct 30 12:38:24.885: INFO: Deleting pod "pod-subpath-test-downwardapi-gp94" in namespace "subpath-1625"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:38:24.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1625" for this suite.
Oct 30 12:38:30.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:38:31.273: INFO: namespace subpath-1625 deletion completed in 6.358971697s

â€¢ [SLOW TEST:30.843 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:38:31.273: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Oct 30 12:38:35.458: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-2e28ab7a-fb12-11e9-91af-623cf93d857c,GenerateName:,Namespace:events-5668,SelfLink:/api/v1/namespaces/events-5668/pods/send-events-2e28ab7a-fb12-11e9-91af-623cf93d857c,UID:2e29daa3-fb12-11e9-a053-fa163e61542c,ResourceVersion:26203,Generation:0,CreationTimestamp:2019-10-30 12:38:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 391150412,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.4.126/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8nh69 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8nh69,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-8nh69 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00033c870} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00033c8e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:38:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:38:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:38:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 12:38:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.39,PodIP:10.233.4.126,StartTime:2019-10-30 12:38:31 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-10-30 12:38:33 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://a53e9d2e7853e785073c5992e88e4800f72aeef9f7cd8ced6c31125b825190d9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Oct 30 12:38:37.469: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Oct 30 12:38:39.478: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:38:39.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5668" for this suite.
Oct 30 12:39:19.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:39:19.895: INFO: namespace events-5668 deletion completed in 40.326227378s

â€¢ [SLOW TEST:48.622 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:39:19.902: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-333.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-333.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 30 12:39:24.144: INFO: DNS probes using dns-333/dns-test-4b22f14f-fb12-11e9-91af-623cf93d857c succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:39:24.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-333" for this suite.
Oct 30 12:39:30.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:39:30.519: INFO: namespace dns-333 deletion completed in 6.315783811s

â€¢ [SLOW TEST:10.617 seconds]
[sig-network] DNS
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:39:30.519: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1384
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 30 12:39:30.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4077'
Oct 30 12:39:30.804: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 30 12:39:30.804: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1390
Oct 30 12:39:32.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 delete deployment e2e-test-nginx-deployment --namespace=kubectl-4077'
Oct 30 12:39:32.966: INFO: stderr: ""
Oct 30 12:39:32.966: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:39:32.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4077" for this suite.
Oct 30 12:39:57.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:39:57.295: INFO: namespace kubectl-4077 deletion completed in 24.319797614s

â€¢ [SLOW TEST:26.776 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:39:57.298: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-616cf7de-fb12-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume secrets
Oct 30 12:39:57.474: INFO: Waiting up to 5m0s for pod "pod-secrets-61703e01-fb12-11e9-91af-623cf93d857c" in namespace "secrets-3712" to be "success or failure"
Oct 30 12:39:57.492: INFO: Pod "pod-secrets-61703e01-fb12-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 18.075264ms
Oct 30 12:39:59.503: INFO: Pod "pod-secrets-61703e01-fb12-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028375141s
Oct 30 12:40:01.513: INFO: Pod "pod-secrets-61703e01-fb12-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038645434s
STEP: Saw pod success
Oct 30 12:40:01.513: INFO: Pod "pod-secrets-61703e01-fb12-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:40:01.521: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-secrets-61703e01-fb12-11e9-91af-623cf93d857c container secret-volume-test: <nil>
STEP: delete the pod
Oct 30 12:40:01.572: INFO: Waiting for pod pod-secrets-61703e01-fb12-11e9-91af-623cf93d857c to disappear
Oct 30 12:40:01.580: INFO: Pod pod-secrets-61703e01-fb12-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:40:01.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3712" for this suite.
Oct 30 12:40:07.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:40:07.904: INFO: namespace secrets-3712 deletion completed in 6.313540993s

â€¢ [SLOW TEST:10.606 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:40:07.907: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Oct 30 12:40:12.664: INFO: Successfully updated pod "labelsupdate67c30ec0-fb12-11e9-91af-623cf93d857c"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:40:14.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7430" for this suite.
Oct 30 12:40:36.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:40:37.025: INFO: namespace projected-7430 deletion completed in 22.30951208s

â€¢ [SLOW TEST:29.119 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:40:37.027: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 30 12:40:37.221: INFO: Waiting up to 5m0s for pod "pod-7924643e-fb12-11e9-91af-623cf93d857c" in namespace "emptydir-6596" to be "success or failure"
Oct 30 12:40:37.234: INFO: Pod "pod-7924643e-fb12-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.048538ms
Oct 30 12:40:39.243: INFO: Pod "pod-7924643e-fb12-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021855584s
Oct 30 12:40:41.252: INFO: Pod "pod-7924643e-fb12-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03032258s
STEP: Saw pod success
Oct 30 12:40:41.252: INFO: Pod "pod-7924643e-fb12-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:40:41.258: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-7924643e-fb12-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 12:40:41.315: INFO: Waiting for pod pod-7924643e-fb12-11e9-91af-623cf93d857c to disappear
Oct 30 12:40:41.322: INFO: Pod pod-7924643e-fb12-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:40:41.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6596" for this suite.
Oct 30 12:40:47.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:40:47.698: INFO: namespace emptydir-6596 deletion completed in 6.360147917s

â€¢ [SLOW TEST:10.671 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:40:47.699: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1030 12:40:57.885905      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 30 12:40:57.886: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:40:57.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3101" for this suite.
Oct 30 12:41:03.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:41:04.243: INFO: namespace gc-3101 deletion completed in 6.345046841s

â€¢ [SLOW TEST:16.544 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:41:04.245: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 30 12:41:04.448: INFO: Waiting up to 5m0s for pod "pod-89582a2a-fb12-11e9-91af-623cf93d857c" in namespace "emptydir-3271" to be "success or failure"
Oct 30 12:41:04.457: INFO: Pod "pod-89582a2a-fb12-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.471136ms
Oct 30 12:41:06.471: INFO: Pod "pod-89582a2a-fb12-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023110963s
Oct 30 12:41:08.486: INFO: Pod "pod-89582a2a-fb12-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03768972s
STEP: Saw pod success
Oct 30 12:41:08.486: INFO: Pod "pod-89582a2a-fb12-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:41:08.494: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-89582a2a-fb12-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 12:41:08.551: INFO: Waiting for pod pod-89582a2a-fb12-11e9-91af-623cf93d857c to disappear
Oct 30 12:41:08.561: INFO: Pod pod-89582a2a-fb12-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:41:08.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3271" for this suite.
Oct 30 12:41:14.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:41:14.852: INFO: namespace emptydir-3271 deletion completed in 6.281530385s

â€¢ [SLOW TEST:10.607 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:41:14.853: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 12:41:15.023: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Oct 30 12:41:15.055: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:15.055: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:15.055: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:15.071: INFO: Number of nodes with available pods: 0
Oct 30 12:41:15.071: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:41:16.083: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:16.083: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:16.083: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:16.095: INFO: Number of nodes with available pods: 0
Oct 30 12:41:16.095: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:41:17.084: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:17.084: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:17.084: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:17.093: INFO: Number of nodes with available pods: 0
Oct 30 12:41:17.093: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 12:41:18.082: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:18.082: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:18.082: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:18.090: INFO: Number of nodes with available pods: 3
Oct 30 12:41:18.090: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Oct 30 12:41:18.161: INFO: Wrong image for pod: daemon-set-7wmm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:18.161: INFO: Wrong image for pod: daemon-set-f92px. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:18.161: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:18.177: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:18.177: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:18.177: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:19.187: INFO: Wrong image for pod: daemon-set-7wmm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:19.187: INFO: Wrong image for pod: daemon-set-f92px. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:19.187: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:19.196: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:19.196: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:19.196: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:20.187: INFO: Wrong image for pod: daemon-set-7wmm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:20.187: INFO: Wrong image for pod: daemon-set-f92px. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:20.187: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:20.197: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:20.197: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:20.197: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:21.186: INFO: Wrong image for pod: daemon-set-7wmm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:21.186: INFO: Wrong image for pod: daemon-set-f92px. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:21.186: INFO: Pod daemon-set-f92px is not available
Oct 30 12:41:21.186: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:21.199: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:21.200: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:21.200: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:22.187: INFO: Wrong image for pod: daemon-set-7wmm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:22.187: INFO: Wrong image for pod: daemon-set-f92px. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:22.187: INFO: Pod daemon-set-f92px is not available
Oct 30 12:41:22.187: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:22.196: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:22.197: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:22.197: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:23.190: INFO: Wrong image for pod: daemon-set-7wmm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:23.190: INFO: Wrong image for pod: daemon-set-f92px. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:23.190: INFO: Pod daemon-set-f92px is not available
Oct 30 12:41:23.190: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:23.200: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:23.200: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:23.200: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:24.186: INFO: Wrong image for pod: daemon-set-7wmm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:24.186: INFO: Wrong image for pod: daemon-set-f92px. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:24.186: INFO: Pod daemon-set-f92px is not available
Oct 30 12:41:24.186: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:24.199: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:24.199: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:24.199: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:25.186: INFO: Wrong image for pod: daemon-set-7wmm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:25.186: INFO: Wrong image for pod: daemon-set-f92px. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:25.186: INFO: Pod daemon-set-f92px is not available
Oct 30 12:41:25.186: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:25.195: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:25.195: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:25.195: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:26.188: INFO: Wrong image for pod: daemon-set-7wmm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:26.188: INFO: Wrong image for pod: daemon-set-f92px. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:26.188: INFO: Pod daemon-set-f92px is not available
Oct 30 12:41:26.188: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:26.202: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:26.202: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:26.202: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:27.187: INFO: Wrong image for pod: daemon-set-7wmm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:27.187: INFO: Wrong image for pod: daemon-set-f92px. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:27.187: INFO: Pod daemon-set-f92px is not available
Oct 30 12:41:27.187: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:27.200: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:27.200: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:27.200: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:28.186: INFO: Wrong image for pod: daemon-set-7wmm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:28.187: INFO: Pod daemon-set-hbzxv is not available
Oct 30 12:41:28.187: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:28.195: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:28.196: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:28.196: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:29.190: INFO: Wrong image for pod: daemon-set-7wmm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:29.190: INFO: Pod daemon-set-hbzxv is not available
Oct 30 12:41:29.190: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:29.201: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:29.201: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:29.201: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:30.220: INFO: Wrong image for pod: daemon-set-7wmm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:30.220: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:30.233: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:30.233: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:30.234: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:31.191: INFO: Wrong image for pod: daemon-set-7wmm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:31.191: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:31.203: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:31.203: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:31.203: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:32.187: INFO: Wrong image for pod: daemon-set-7wmm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:32.187: INFO: Pod daemon-set-7wmm5 is not available
Oct 30 12:41:32.187: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:32.227: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:32.227: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:32.227: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:33.190: INFO: Pod daemon-set-ffj7s is not available
Oct 30 12:41:33.190: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:33.201: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:33.201: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:33.201: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:34.187: INFO: Pod daemon-set-ffj7s is not available
Oct 30 12:41:34.187: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:34.206: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:34.206: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:34.206: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:35.186: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:35.196: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:35.196: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:35.196: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:36.186: INFO: Wrong image for pod: daemon-set-tkqfz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 30 12:41:36.186: INFO: Pod daemon-set-tkqfz is not available
Oct 30 12:41:36.194: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:36.194: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:36.194: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:37.188: INFO: Pod daemon-set-7mnv4 is not available
Oct 30 12:41:37.199: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:37.199: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:37.199: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Oct 30 12:41:37.208: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:37.208: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:37.208: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:37.217: INFO: Number of nodes with available pods: 2
Oct 30 12:41:37.217: INFO: Node koris-pipeline-56683fb-92514359-node-2 is running more than one daemon pod
Oct 30 12:41:38.238: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:38.238: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:38.238: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:38.247: INFO: Number of nodes with available pods: 2
Oct 30 12:41:38.247: INFO: Node koris-pipeline-56683fb-92514359-node-2 is running more than one daemon pod
Oct 30 12:41:39.230: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:39.230: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:39.230: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:39.239: INFO: Number of nodes with available pods: 2
Oct 30 12:41:39.239: INFO: Node koris-pipeline-56683fb-92514359-node-2 is running more than one daemon pod
Oct 30 12:41:40.228: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:40.228: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:40.228: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:40.237: INFO: Number of nodes with available pods: 2
Oct 30 12:41:40.238: INFO: Node koris-pipeline-56683fb-92514359-node-2 is running more than one daemon pod
Oct 30 12:41:41.229: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:41.229: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:41.229: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 12:41:41.237: INFO: Number of nodes with available pods: 3
Oct 30 12:41:41.237: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1906, will wait for the garbage collector to delete the pods
Oct 30 12:41:41.358: INFO: Deleting DaemonSet.extensions daemon-set took: 20.239302ms
Oct 30 12:41:41.759: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.513908ms
Oct 30 12:41:45.167: INFO: Number of nodes with available pods: 0
Oct 30 12:41:45.167: INFO: Number of running nodes: 0, number of available pods: 0
Oct 30 12:41:45.175: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1906/daemonsets","resourceVersion":"27087"},"items":null}

Oct 30 12:41:45.183: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1906/pods","resourceVersion":"27087"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:41:45.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1906" for this suite.
Oct 30 12:41:53.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:41:53.538: INFO: namespace daemonsets-1906 deletion completed in 8.307236071s

â€¢ [SLOW TEST:38.685 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:41:53.538: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 30 12:42:01.800: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 30 12:42:01.806: INFO: Pod pod-with-prestop-http-hook still exists
Oct 30 12:42:03.807: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 30 12:42:03.815: INFO: Pod pod-with-prestop-http-hook still exists
Oct 30 12:42:05.807: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 30 12:42:05.817: INFO: Pod pod-with-prestop-http-hook still exists
Oct 30 12:42:07.807: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 30 12:42:07.816: INFO: Pod pod-with-prestop-http-hook still exists
Oct 30 12:42:09.807: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 30 12:42:09.815: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:42:09.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5109" for this suite.
Oct 30 12:42:33.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:42:34.167: INFO: namespace container-lifecycle-hook-5109 deletion completed in 24.325992191s

â€¢ [SLOW TEST:40.629 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:42:34.168: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-beed1038-fb12-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume secrets
Oct 30 12:42:34.315: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bef0744e-fb12-11e9-91af-623cf93d857c" in namespace "projected-5213" to be "success or failure"
Oct 30 12:42:34.322: INFO: Pod "pod-projected-secrets-bef0744e-fb12-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.819507ms
Oct 30 12:42:36.333: INFO: Pod "pod-projected-secrets-bef0744e-fb12-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017280675s
Oct 30 12:42:38.347: INFO: Pod "pod-projected-secrets-bef0744e-fb12-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031479982s
STEP: Saw pod success
Oct 30 12:42:38.347: INFO: Pod "pod-projected-secrets-bef0744e-fb12-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:42:38.354: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-projected-secrets-bef0744e-fb12-11e9-91af-623cf93d857c container secret-volume-test: <nil>
STEP: delete the pod
Oct 30 12:42:38.411: INFO: Waiting for pod pod-projected-secrets-bef0744e-fb12-11e9-91af-623cf93d857c to disappear
Oct 30 12:42:38.417: INFO: Pod pod-projected-secrets-bef0744e-fb12-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:42:38.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5213" for this suite.
Oct 30 12:42:44.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:42:44.820: INFO: namespace projected-5213 deletion completed in 6.385622488s

â€¢ [SLOW TEST:10.652 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:42:44.825: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-c545c2a9-fb12-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume configMaps
Oct 30 12:42:44.977: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c548df6c-fb12-11e9-91af-623cf93d857c" in namespace "projected-4887" to be "success or failure"
Oct 30 12:42:44.991: INFO: Pod "pod-projected-configmaps-c548df6c-fb12-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.790215ms
Oct 30 12:42:47.002: INFO: Pod "pod-projected-configmaps-c548df6c-fb12-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025029692s
Oct 30 12:42:49.012: INFO: Pod "pod-projected-configmaps-c548df6c-fb12-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035078586s
STEP: Saw pod success
Oct 30 12:42:49.012: INFO: Pod "pod-projected-configmaps-c548df6c-fb12-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:42:49.019: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-projected-configmaps-c548df6c-fb12-11e9-91af-623cf93d857c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 30 12:42:49.074: INFO: Waiting for pod pod-projected-configmaps-c548df6c-fb12-11e9-91af-623cf93d857c to disappear
Oct 30 12:42:49.080: INFO: Pod pod-projected-configmaps-c548df6c-fb12-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:42:49.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4887" for this suite.
Oct 30 12:42:55.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:42:55.420: INFO: namespace projected-4887 deletion completed in 6.32973033s

â€¢ [SLOW TEST:10.596 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:42:55.424: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:42:59.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9844" for this suite.
Oct 30 12:43:45.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:43:45.998: INFO: namespace kubelet-test-9844 deletion completed in 46.359991213s

â€¢ [SLOW TEST:50.574 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:43:45.999: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-w2fl
STEP: Creating a pod to test atomic-volume-subpath
Oct 30 12:43:46.143: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-w2fl" in namespace "subpath-417" to be "success or failure"
Oct 30 12:43:46.149: INFO: Pod "pod-subpath-test-configmap-w2fl": Phase="Pending", Reason="", readiness=false. Elapsed: 5.66843ms
Oct 30 12:43:48.160: INFO: Pod "pod-subpath-test-configmap-w2fl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017107214s
Oct 30 12:43:50.170: INFO: Pod "pod-subpath-test-configmap-w2fl": Phase="Running", Reason="", readiness=true. Elapsed: 4.026616645s
Oct 30 12:43:52.178: INFO: Pod "pod-subpath-test-configmap-w2fl": Phase="Running", Reason="", readiness=true. Elapsed: 6.03498689s
Oct 30 12:43:54.187: INFO: Pod "pod-subpath-test-configmap-w2fl": Phase="Running", Reason="", readiness=true. Elapsed: 8.044277315s
Oct 30 12:43:56.195: INFO: Pod "pod-subpath-test-configmap-w2fl": Phase="Running", Reason="", readiness=true. Elapsed: 10.052277919s
Oct 30 12:43:58.208: INFO: Pod "pod-subpath-test-configmap-w2fl": Phase="Running", Reason="", readiness=true. Elapsed: 12.064589493s
Oct 30 12:44:00.216: INFO: Pod "pod-subpath-test-configmap-w2fl": Phase="Running", Reason="", readiness=true. Elapsed: 14.073358659s
Oct 30 12:44:02.226: INFO: Pod "pod-subpath-test-configmap-w2fl": Phase="Running", Reason="", readiness=true. Elapsed: 16.083102134s
Oct 30 12:44:04.236: INFO: Pod "pod-subpath-test-configmap-w2fl": Phase="Running", Reason="", readiness=true. Elapsed: 18.09246478s
Oct 30 12:44:06.245: INFO: Pod "pod-subpath-test-configmap-w2fl": Phase="Running", Reason="", readiness=true. Elapsed: 20.101600894s
Oct 30 12:44:08.254: INFO: Pod "pod-subpath-test-configmap-w2fl": Phase="Running", Reason="", readiness=true. Elapsed: 22.110820965s
Oct 30 12:44:10.263: INFO: Pod "pod-subpath-test-configmap-w2fl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.120180159s
STEP: Saw pod success
Oct 30 12:44:10.263: INFO: Pod "pod-subpath-test-configmap-w2fl" satisfied condition "success or failure"
Oct 30 12:44:10.269: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-subpath-test-configmap-w2fl container test-container-subpath-configmap-w2fl: <nil>
STEP: delete the pod
Oct 30 12:44:10.329: INFO: Waiting for pod pod-subpath-test-configmap-w2fl to disappear
Oct 30 12:44:10.335: INFO: Pod pod-subpath-test-configmap-w2fl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-w2fl
Oct 30 12:44:10.335: INFO: Deleting pod "pod-subpath-test-configmap-w2fl" in namespace "subpath-417"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:44:10.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-417" for this suite.
Oct 30 12:44:16.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:44:16.697: INFO: namespace subpath-417 deletion completed in 6.344220126s

â€¢ [SLOW TEST:30.697 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:44:16.697: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-fc099cc3-fb12-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume secrets
Oct 30 12:44:16.833: INFO: Waiting up to 5m0s for pod "pod-secrets-fc0c2403-fb12-11e9-91af-623cf93d857c" in namespace "secrets-7521" to be "success or failure"
Oct 30 12:44:16.863: INFO: Pod "pod-secrets-fc0c2403-fb12-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 30.053663ms
Oct 30 12:44:18.875: INFO: Pod "pod-secrets-fc0c2403-fb12-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041471908s
Oct 30 12:44:20.886: INFO: Pod "pod-secrets-fc0c2403-fb12-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052248322s
STEP: Saw pod success
Oct 30 12:44:20.886: INFO: Pod "pod-secrets-fc0c2403-fb12-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:44:20.894: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-secrets-fc0c2403-fb12-11e9-91af-623cf93d857c container secret-volume-test: <nil>
STEP: delete the pod
Oct 30 12:44:20.953: INFO: Waiting for pod pod-secrets-fc0c2403-fb12-11e9-91af-623cf93d857c to disappear
Oct 30 12:44:20.974: INFO: Pod pod-secrets-fc0c2403-fb12-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:44:20.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7521" for this suite.
Oct 30 12:44:27.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:44:27.342: INFO: namespace secrets-7521 deletion completed in 6.354674292s

â€¢ [SLOW TEST:10.645 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:44:27.343: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 12:44:27.454: INFO: Waiting up to 5m0s for pod "downwardapi-volume-025efab9-fb13-11e9-91af-623cf93d857c" in namespace "projected-694" to be "success or failure"
Oct 30 12:44:27.465: INFO: Pod "downwardapi-volume-025efab9-fb13-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.235096ms
Oct 30 12:44:29.474: INFO: Pod "downwardapi-volume-025efab9-fb13-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020258383s
Oct 30 12:44:31.485: INFO: Pod "downwardapi-volume-025efab9-fb13-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031319256s
STEP: Saw pod success
Oct 30 12:44:31.485: INFO: Pod "downwardapi-volume-025efab9-fb13-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:44:31.493: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod downwardapi-volume-025efab9-fb13-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 12:44:31.559: INFO: Waiting for pod downwardapi-volume-025efab9-fb13-11e9-91af-623cf93d857c to disappear
Oct 30 12:44:31.564: INFO: Pod downwardapi-volume-025efab9-fb13-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:44:31.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-694" for this suite.
Oct 30 12:44:37.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:44:37.911: INFO: namespace projected-694 deletion completed in 6.337088603s

â€¢ [SLOW TEST:10.569 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:44:37.915: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-8486
Oct 30 12:44:42.075: INFO: Started pod liveness-http in namespace container-probe-8486
STEP: checking the pod's current state and verifying that restartCount is present
Oct 30 12:44:42.083: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:48:43.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8486" for this suite.
Oct 30 12:48:49.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:48:49.824: INFO: namespace container-probe-8486 deletion completed in 6.355079826s

â€¢ [SLOW TEST:251.909 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:48:49.827: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-2541
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 30 12:48:49.989: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 30 12:49:16.381: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.4.138:8080/dial?request=hostName&protocol=http&host=10.233.4.137&port=8080&tries=1'] Namespace:pod-network-test-2541 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 12:49:16.381: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 12:49:16.555: INFO: Waiting for endpoints: map[]
Oct 30 12:49:16.563: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.4.138:8080/dial?request=hostName&protocol=http&host=10.233.5.121&port=8080&tries=1'] Namespace:pod-network-test-2541 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 12:49:16.563: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 12:49:16.741: INFO: Waiting for endpoints: map[]
Oct 30 12:49:16.749: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.4.138:8080/dial?request=hostName&protocol=http&host=10.233.3.60&port=8080&tries=1'] Namespace:pod-network-test-2541 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 30 12:49:16.749: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
Oct 30 12:49:16.917: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:49:16.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2541" for this suite.
Oct 30 12:49:40.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:49:41.254: INFO: namespace pod-network-test-2541 deletion completed in 24.318397307s

â€¢ [SLOW TEST:51.427 seconds]
[sig-network] Networking
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:49:41.256: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 30 12:49:41.370: INFO: Waiting up to 5m0s for pod "pod-bd7c0096-fb13-11e9-91af-623cf93d857c" in namespace "emptydir-6599" to be "success or failure"
Oct 30 12:49:41.377: INFO: Pod "pod-bd7c0096-fb13-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.241845ms
Oct 30 12:49:43.390: INFO: Pod "pod-bd7c0096-fb13-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019489147s
Oct 30 12:49:45.400: INFO: Pod "pod-bd7c0096-fb13-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029603112s
STEP: Saw pod success
Oct 30 12:49:45.400: INFO: Pod "pod-bd7c0096-fb13-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:49:45.413: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-bd7c0096-fb13-11e9-91af-623cf93d857c container test-container: <nil>
STEP: delete the pod
Oct 30 12:49:45.499: INFO: Waiting for pod pod-bd7c0096-fb13-11e9-91af-623cf93d857c to disappear
Oct 30 12:49:45.511: INFO: Pod pod-bd7c0096-fb13-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:49:45.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6599" for this suite.
Oct 30 12:49:51.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:49:51.825: INFO: namespace emptydir-6599 deletion completed in 6.301127425s

â€¢ [SLOW TEST:10.570 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:49:51.829: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 12:49:52.053: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c3d898f1-fb13-11e9-91af-623cf93d857c" in namespace "downward-api-35" to be "success or failure"
Oct 30 12:49:52.076: INFO: Pod "downwardapi-volume-c3d898f1-fb13-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 23.241203ms
Oct 30 12:49:54.086: INFO: Pod "downwardapi-volume-c3d898f1-fb13-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033556496s
Oct 30 12:49:56.097: INFO: Pod "downwardapi-volume-c3d898f1-fb13-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044473606s
STEP: Saw pod success
Oct 30 12:49:56.097: INFO: Pod "downwardapi-volume-c3d898f1-fb13-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:49:56.106: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod downwardapi-volume-c3d898f1-fb13-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 12:49:56.165: INFO: Waiting for pod downwardapi-volume-c3d898f1-fb13-11e9-91af-623cf93d857c to disappear
Oct 30 12:49:56.170: INFO: Pod downwardapi-volume-c3d898f1-fb13-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:49:56.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-35" for this suite.
Oct 30 12:50:02.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:50:02.508: INFO: namespace downward-api-35 deletion completed in 6.326404325s

â€¢ [SLOW TEST:10.680 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:50:02.513: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Oct 30 12:50:03.523: INFO: Pod name wrapped-volume-race-caab9f54-fb13-11e9-91af-623cf93d857c: Found 0 pods out of 5
Oct 30 12:50:08.540: INFO: Pod name wrapped-volume-race-caab9f54-fb13-11e9-91af-623cf93d857c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-caab9f54-fb13-11e9-91af-623cf93d857c in namespace emptydir-wrapper-1991, will wait for the garbage collector to delete the pods
Oct 30 12:50:20.714: INFO: Deleting ReplicationController wrapped-volume-race-caab9f54-fb13-11e9-91af-623cf93d857c took: 37.723745ms
Oct 30 12:50:21.214: INFO: Terminating ReplicationController wrapped-volume-race-caab9f54-fb13-11e9-91af-623cf93d857c pods took: 500.363072ms
STEP: Creating RC which spawns configmap-volume pods
Oct 30 12:51:08.376: INFO: Pod name wrapped-volume-race-f15221a8-fb13-11e9-91af-623cf93d857c: Found 0 pods out of 5
Oct 30 12:51:13.390: INFO: Pod name wrapped-volume-race-f15221a8-fb13-11e9-91af-623cf93d857c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f15221a8-fb13-11e9-91af-623cf93d857c in namespace emptydir-wrapper-1991, will wait for the garbage collector to delete the pods
Oct 30 12:51:25.544: INFO: Deleting ReplicationController wrapped-volume-race-f15221a8-fb13-11e9-91af-623cf93d857c took: 24.110903ms
Oct 30 12:51:26.044: INFO: Terminating ReplicationController wrapped-volume-race-f15221a8-fb13-11e9-91af-623cf93d857c pods took: 500.65408ms
STEP: Creating RC which spawns configmap-volume pods
Oct 30 12:52:03.399: INFO: Pod name wrapped-volume-race-121f08af-fb14-11e9-91af-623cf93d857c: Found 0 pods out of 5
Oct 30 12:52:08.413: INFO: Pod name wrapped-volume-race-121f08af-fb14-11e9-91af-623cf93d857c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-121f08af-fb14-11e9-91af-623cf93d857c in namespace emptydir-wrapper-1991, will wait for the garbage collector to delete the pods
Oct 30 12:52:20.567: INFO: Deleting ReplicationController wrapped-volume-race-121f08af-fb14-11e9-91af-623cf93d857c took: 18.753963ms
Oct 30 12:52:21.068: INFO: Terminating ReplicationController wrapped-volume-race-121f08af-fb14-11e9-91af-623cf93d857c pods took: 500.464065ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:52:59.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1991" for this suite.
Oct 30 12:53:09.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:53:10.185: INFO: namespace emptydir-wrapper-1991 deletion completed in 10.335347411s

â€¢ [SLOW TEST:187.672 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:53:10.186: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Oct 30 12:53:10.307: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3a043228-fb14-11e9-91af-623cf93d857c" in namespace "projected-565" to be "success or failure"
Oct 30 12:53:10.316: INFO: Pod "downwardapi-volume-3a043228-fb14-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.364112ms
Oct 30 12:53:12.327: INFO: Pod "downwardapi-volume-3a043228-fb14-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020199536s
Oct 30 12:53:14.337: INFO: Pod "downwardapi-volume-3a043228-fb14-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030334273s
STEP: Saw pod success
Oct 30 12:53:14.337: INFO: Pod "downwardapi-volume-3a043228-fb14-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:53:14.345: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod downwardapi-volume-3a043228-fb14-11e9-91af-623cf93d857c container client-container: <nil>
STEP: delete the pod
Oct 30 12:53:14.439: INFO: Waiting for pod downwardapi-volume-3a043228-fb14-11e9-91af-623cf93d857c to disappear
Oct 30 12:53:14.448: INFO: Pod downwardapi-volume-3a043228-fb14-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:53:14.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-565" for this suite.
Oct 30 12:53:20.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:53:20.832: INFO: namespace projected-565 deletion completed in 6.374860865s

â€¢ [SLOW TEST:10.647 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:53:20.836: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:53:24.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7754" for this suite.
Oct 30 12:53:31.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:53:31.281: INFO: namespace kubelet-test-7754 deletion completed in 6.28121848s

â€¢ [SLOW TEST:10.446 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:53:31.282: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Oct 30 12:53:31.424: INFO: Waiting up to 5m0s for pod "var-expansion-469babe6-fb14-11e9-91af-623cf93d857c" in namespace "var-expansion-1245" to be "success or failure"
Oct 30 12:53:31.434: INFO: Pod "var-expansion-469babe6-fb14-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.326783ms
Oct 30 12:53:33.443: INFO: Pod "var-expansion-469babe6-fb14-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018394915s
Oct 30 12:53:35.452: INFO: Pod "var-expansion-469babe6-fb14-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027589941s
STEP: Saw pod success
Oct 30 12:53:35.452: INFO: Pod "var-expansion-469babe6-fb14-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:53:35.460: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod var-expansion-469babe6-fb14-11e9-91af-623cf93d857c container dapi-container: <nil>
STEP: delete the pod
Oct 30 12:53:35.531: INFO: Waiting for pod var-expansion-469babe6-fb14-11e9-91af-623cf93d857c to disappear
Oct 30 12:53:35.537: INFO: Pod var-expansion-469babe6-fb14-11e9-91af-623cf93d857c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:53:35.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1245" for this suite.
Oct 30 12:53:41.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:53:41.850: INFO: namespace var-expansion-1245 deletion completed in 6.3016256s

â€¢ [SLOW TEST:10.568 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:53:41.851: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:54:42.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2751" for this suite.
Oct 30 12:55:06.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:55:06.398: INFO: namespace container-probe-2751 deletion completed in 24.357291307s

â€¢ [SLOW TEST:84.547 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:55:06.399: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-wmft
STEP: Creating a pod to test atomic-volume-subpath
Oct 30 12:55:06.696: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-wmft" in namespace "subpath-5052" to be "success or failure"
Oct 30 12:55:06.706: INFO: Pod "pod-subpath-test-projected-wmft": Phase="Pending", Reason="", readiness=false. Elapsed: 10.197472ms
Oct 30 12:55:08.716: INFO: Pod "pod-subpath-test-projected-wmft": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020511501s
Oct 30 12:55:10.726: INFO: Pod "pod-subpath-test-projected-wmft": Phase="Running", Reason="", readiness=true. Elapsed: 4.030498917s
Oct 30 12:55:12.735: INFO: Pod "pod-subpath-test-projected-wmft": Phase="Running", Reason="", readiness=true. Elapsed: 6.039393581s
Oct 30 12:55:14.745: INFO: Pod "pod-subpath-test-projected-wmft": Phase="Running", Reason="", readiness=true. Elapsed: 8.048909404s
Oct 30 12:55:16.755: INFO: Pod "pod-subpath-test-projected-wmft": Phase="Running", Reason="", readiness=true. Elapsed: 10.059137592s
Oct 30 12:55:18.766: INFO: Pod "pod-subpath-test-projected-wmft": Phase="Running", Reason="", readiness=true. Elapsed: 12.070767753s
Oct 30 12:55:20.777: INFO: Pod "pod-subpath-test-projected-wmft": Phase="Running", Reason="", readiness=true. Elapsed: 14.081661484s
Oct 30 12:55:22.788: INFO: Pod "pod-subpath-test-projected-wmft": Phase="Running", Reason="", readiness=true. Elapsed: 16.091960771s
Oct 30 12:55:24.797: INFO: Pod "pod-subpath-test-projected-wmft": Phase="Running", Reason="", readiness=true. Elapsed: 18.10143138s
Oct 30 12:55:26.810: INFO: Pod "pod-subpath-test-projected-wmft": Phase="Running", Reason="", readiness=true. Elapsed: 20.114744578s
Oct 30 12:55:28.820: INFO: Pod "pod-subpath-test-projected-wmft": Phase="Running", Reason="", readiness=true. Elapsed: 22.124246549s
Oct 30 12:55:30.831: INFO: Pod "pod-subpath-test-projected-wmft": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.135453604s
STEP: Saw pod success
Oct 30 12:55:30.831: INFO: Pod "pod-subpath-test-projected-wmft" satisfied condition "success or failure"
Oct 30 12:55:30.839: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-subpath-test-projected-wmft container test-container-subpath-projected-wmft: <nil>
STEP: delete the pod
Oct 30 12:55:30.914: INFO: Waiting for pod pod-subpath-test-projected-wmft to disappear
Oct 30 12:55:30.930: INFO: Pod pod-subpath-test-projected-wmft no longer exists
STEP: Deleting pod pod-subpath-test-projected-wmft
Oct 30 12:55:30.930: INFO: Deleting pod "pod-subpath-test-projected-wmft" in namespace "subpath-5052"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:55:30.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5052" for this suite.
Oct 30 12:55:36.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:55:37.298: INFO: namespace subpath-5052 deletion completed in 6.338776472s

â€¢ [SLOW TEST:30.899 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:55:37.299: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-91b68202-fb14-11e9-91af-623cf93d857c
STEP: Creating configMap with name cm-test-opt-upd-91b68293-fb14-11e9-91af-623cf93d857c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-91b68202-fb14-11e9-91af-623cf93d857c
STEP: Updating configmap cm-test-opt-upd-91b68293-fb14-11e9-91af-623cf93d857c
STEP: Creating configMap with name cm-test-opt-create-91b682d7-fb14-11e9-91af-623cf93d857c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:56:46.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9534" for this suite.
Oct 30 12:57:10.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:57:10.782: INFO: namespace configmap-9534 deletion completed in 24.347149977s

â€¢ [SLOW TEST:93.483 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:57:10.792: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-4842
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Oct 30 12:57:10.954: INFO: Found 0 stateful pods, waiting for 3
Oct 30 12:57:20.971: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 12:57:20.971: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 12:57:20.971: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct 30 12:57:21.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-4842 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 12:57:21.316: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 12:57:21.316: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 12:57:21.316: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 30 12:57:31.392: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Oct 30 12:57:41.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-4842 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:57:41.706: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 30 12:57:41.706: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 12:57:41.706: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 12:58:01.767: INFO: Waiting for StatefulSet statefulset-4842/ss2 to complete update
STEP: Rolling back to a previous revision
Oct 30 12:58:11.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-4842 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 30 12:58:12.072: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 30 12:58:12.072: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 30 12:58:12.072: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 30 12:58:22.152: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Oct 30 12:58:32.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-984085711 exec --namespace=statefulset-4842 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 30 12:58:32.456: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 30 12:58:32.456: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 30 12:58:32.456: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 30 12:59:02.527: INFO: Waiting for StatefulSet statefulset-4842/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 30 12:59:12.553: INFO: Deleting all statefulset in ns statefulset-4842
Oct 30 12:59:12.564: INFO: Scaling statefulset ss2 to 0
Oct 30 12:59:32.604: INFO: Waiting for statefulset status.replicas updated to 0
Oct 30 12:59:32.611: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:59:32.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4842" for this suite.
Oct 30 12:59:40.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:59:40.975: INFO: namespace statefulset-4842 deletion completed in 8.293978932s

â€¢ [SLOW TEST:150.183 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:59:40.975: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-22f4a01d-fb15-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume secrets
Oct 30 12:59:41.234: INFO: Waiting up to 5m0s for pod "pod-secrets-23074bbd-fb15-11e9-91af-623cf93d857c" in namespace "secrets-7841" to be "success or failure"
Oct 30 12:59:41.247: INFO: Pod "pod-secrets-23074bbd-fb15-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.321434ms
Oct 30 12:59:43.259: INFO: Pod "pod-secrets-23074bbd-fb15-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024540321s
Oct 30 12:59:45.269: INFO: Pod "pod-secrets-23074bbd-fb15-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034146145s
STEP: Saw pod success
Oct 30 12:59:45.269: INFO: Pod "pod-secrets-23074bbd-fb15-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 12:59:45.276: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-secrets-23074bbd-fb15-11e9-91af-623cf93d857c container secret-volume-test: <nil>
STEP: delete the pod
Oct 30 12:59:45.340: INFO: Waiting for pod pod-secrets-23074bbd-fb15-11e9-91af-623cf93d857c to disappear
Oct 30 12:59:45.347: INFO: Pod pod-secrets-23074bbd-fb15-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 12:59:45.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7841" for this suite.
Oct 30 12:59:51.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:59:51.689: INFO: namespace secrets-7841 deletion completed in 6.332439848s
STEP: Destroying namespace "secret-namespace-9806" for this suite.
Oct 30 12:59:57.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 12:59:58.027: INFO: namespace secret-namespace-9806 deletion completed in 6.337359108s

â€¢ [SLOW TEST:17.052 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 12:59:58.028: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Oct 30 12:59:58.189: INFO: Waiting up to 5m0s for pod "var-expansion-2d1d39f9-fb15-11e9-91af-623cf93d857c" in namespace "var-expansion-5053" to be "success or failure"
Oct 30 12:59:58.202: INFO: Pod "var-expansion-2d1d39f9-fb15-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.615443ms
Oct 30 13:00:00.212: INFO: Pod "var-expansion-2d1d39f9-fb15-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022807483s
Oct 30 13:00:02.221: INFO: Pod "var-expansion-2d1d39f9-fb15-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032057892s
STEP: Saw pod success
Oct 30 13:00:02.221: INFO: Pod "var-expansion-2d1d39f9-fb15-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 13:00:02.228: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod var-expansion-2d1d39f9-fb15-11e9-91af-623cf93d857c container dapi-container: <nil>
STEP: delete the pod
Oct 30 13:00:02.289: INFO: Waiting for pod var-expansion-2d1d39f9-fb15-11e9-91af-623cf93d857c to disappear
Oct 30 13:00:02.295: INFO: Pod var-expansion-2d1d39f9-fb15-11e9-91af-623cf93d857c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 13:00:02.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5053" for this suite.
Oct 30 13:00:08.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 13:00:08.673: INFO: namespace var-expansion-5053 deletion completed in 6.348853246s

â€¢ [SLOW TEST:10.645 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 13:00:08.674: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-107
Oct 30 13:00:12.893: INFO: Started pod liveness-http in namespace container-probe-107
STEP: checking the pod's current state and verifying that restartCount is present
Oct 30 13:00:12.903: INFO: Initial restart count of pod liveness-http is 0
Oct 30 13:00:33.034: INFO: Restart count of pod container-probe-107/liveness-http is now 1 (20.131235464s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 13:00:33.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-107" for this suite.
Oct 30 13:00:39.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 13:00:39.463: INFO: namespace container-probe-107 deletion completed in 6.354574884s

â€¢ [SLOW TEST:30.790 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 13:00:39.464: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-45cf3b50-fb15-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume secrets
Oct 30 13:00:39.616: INFO: Waiting up to 5m0s for pod "pod-secrets-45d37b75-fb15-11e9-91af-623cf93d857c" in namespace "secrets-3162" to be "success or failure"
Oct 30 13:00:39.632: INFO: Pod "pod-secrets-45d37b75-fb15-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.524096ms
Oct 30 13:00:41.641: INFO: Pod "pod-secrets-45d37b75-fb15-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025071171s
Oct 30 13:00:43.650: INFO: Pod "pod-secrets-45d37b75-fb15-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034197856s
STEP: Saw pod success
Oct 30 13:00:43.650: INFO: Pod "pod-secrets-45d37b75-fb15-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 13:00:43.659: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-secrets-45d37b75-fb15-11e9-91af-623cf93d857c container secret-volume-test: <nil>
STEP: delete the pod
Oct 30 13:00:43.720: INFO: Waiting for pod pod-secrets-45d37b75-fb15-11e9-91af-623cf93d857c to disappear
Oct 30 13:00:43.725: INFO: Pod pod-secrets-45d37b75-fb15-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 13:00:43.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3162" for this suite.
Oct 30 13:00:49.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 13:00:50.070: INFO: namespace secrets-3162 deletion completed in 6.324990442s

â€¢ [SLOW TEST:10.606 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 13:00:50.071: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 30 13:00:50.271: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:50.271: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:50.271: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:50.277: INFO: Number of nodes with available pods: 0
Oct 30 13:00:50.277: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 13:00:51.292: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:51.292: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:51.292: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:51.301: INFO: Number of nodes with available pods: 0
Oct 30 13:00:51.301: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 13:00:52.296: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:52.296: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:52.296: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:52.306: INFO: Number of nodes with available pods: 0
Oct 30 13:00:52.306: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 13:00:53.296: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:53.296: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:53.296: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:53.304: INFO: Number of nodes with available pods: 3
Oct 30 13:00:53.304: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Oct 30 13:00:53.354: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:53.355: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:53.355: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:53.364: INFO: Number of nodes with available pods: 2
Oct 30 13:00:53.365: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 13:00:54.379: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:54.379: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:54.380: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:54.390: INFO: Number of nodes with available pods: 2
Oct 30 13:00:54.390: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 13:00:55.376: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:55.376: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:55.376: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:55.384: INFO: Number of nodes with available pods: 2
Oct 30 13:00:55.384: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 13:00:56.377: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:56.377: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:56.377: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:56.386: INFO: Number of nodes with available pods: 2
Oct 30 13:00:56.386: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 13:00:57.379: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:57.380: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:57.380: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:57.387: INFO: Number of nodes with available pods: 2
Oct 30 13:00:57.387: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 13:00:58.378: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:58.378: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:58.378: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:58.387: INFO: Number of nodes with available pods: 2
Oct 30 13:00:58.387: INFO: Node koris-pipeline-56683fb-92514359-node-1 is running more than one daemon pod
Oct 30 13:00:59.380: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:59.381: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:59.381: INFO: DaemonSet pods can't tolerate node koris-pipeline-56683fb-92514359-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 30 13:00:59.389: INFO: Number of nodes with available pods: 3
Oct 30 13:00:59.390: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3161, will wait for the garbage collector to delete the pods
Oct 30 13:00:59.482: INFO: Deleting DaemonSet.extensions daemon-set took: 24.518242ms
Oct 30 13:00:59.882: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.620068ms
Oct 30 13:01:13.003: INFO: Number of nodes with available pods: 0
Oct 30 13:01:13.004: INFO: Number of running nodes: 0, number of available pods: 0
Oct 30 13:01:13.010: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3161/daemonsets","resourceVersion":"32164"},"items":null}

Oct 30 13:01:13.017: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3161/pods","resourceVersion":"32164"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 13:01:13.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3161" for this suite.
Oct 30 13:01:19.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 13:01:19.418: INFO: namespace daemonsets-3161 deletion completed in 6.355689568s

â€¢ [SLOW TEST:29.348 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 13:01:19.421: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-5da0ffe8-fb15-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume secrets
Oct 30 13:01:19.568: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5da41dca-fb15-11e9-91af-623cf93d857c" in namespace "projected-390" to be "success or failure"
Oct 30 13:01:19.646: INFO: Pod "pod-projected-secrets-5da41dca-fb15-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 77.557029ms
Oct 30 13:01:21.657: INFO: Pod "pod-projected-secrets-5da41dca-fb15-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088593708s
Oct 30 13:01:23.667: INFO: Pod "pod-projected-secrets-5da41dca-fb15-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.098558083s
STEP: Saw pod success
Oct 30 13:01:23.667: INFO: Pod "pod-projected-secrets-5da41dca-fb15-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 13:01:23.673: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-3 pod pod-projected-secrets-5da41dca-fb15-11e9-91af-623cf93d857c container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 30 13:01:23.741: INFO: Waiting for pod pod-projected-secrets-5da41dca-fb15-11e9-91af-623cf93d857c to disappear
Oct 30 13:01:23.748: INFO: Pod pod-projected-secrets-5da41dca-fb15-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 13:01:23.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-390" for this suite.
Oct 30 13:01:29.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 13:01:30.081: INFO: namespace projected-390 deletion completed in 6.320179343s

â€¢ [SLOW TEST:10.661 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 13:01:30.087: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Oct 30 13:01:30.210: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct 30 13:01:35.219: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 30 13:01:35.220: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 30 13:01:39.293: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-7705,SelfLink:/apis/apps/v1/namespaces/deployment-7705/deployments/test-cleanup-deployment,UID:66fdba3a-fb15-11e9-a053-fa163e61542c,ResourceVersion:32326,Generation:1,CreationTimestamp:2019-10-30 13:01:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-30 13:01:35 +0000 UTC 2019-10-30 13:01:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-30 13:01:37 +0000 UTC 2019-10-30 13:01:35 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-6865c98b76" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 30 13:01:39.301: INFO: New ReplicaSet "test-cleanup-deployment-6865c98b76" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76,GenerateName:,Namespace:deployment-7705,SelfLink:/apis/apps/v1/namespaces/deployment-7705/replicasets/test-cleanup-deployment-6865c98b76,UID:67031878-fb15-11e9-ad48-fa163ee0935a,ResourceVersion:32316,Generation:1,CreationTimestamp:2019-10-30 13:01:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 66fdba3a-fb15-11e9-a053-fa163e61542c 0xc0009c9367 0xc0009c9368}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 30 13:01:39.307: INFO: Pod "test-cleanup-deployment-6865c98b76-6fcn5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76-6fcn5,GenerateName:test-cleanup-deployment-6865c98b76-,Namespace:deployment-7705,SelfLink:/api/v1/namespaces/deployment-7705/pods/test-cleanup-deployment-6865c98b76-6fcn5,UID:6704942c-fb15-11e9-ad48-fa163ee0935a,ResourceVersion:32315,Generation:0,CreationTimestamp:2019-10-30 13:01:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.5.133/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-6865c98b76 67031878-fb15-11e9-ad48-fa163ee0935a 0xc0009c9cc7 0xc0009c9cc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5klwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5klwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-5klwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:koris-pipeline-56683fb-92514359-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0009c9db0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0009c9e00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 13:01:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 13:01:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 13:01:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-30 13:01:35 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.32,PodIP:10.233.5.133,StartTime:2019-10-30 13:01:35 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-30 13:01:37 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://c59f7b44fce71482999445973590f72b29a53c8be34d1ba2027aaa2dc872af3d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 13:01:39.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7705" for this suite.
Oct 30 13:01:47.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 13:01:47.655: INFO: namespace deployment-7705 deletion completed in 8.335835388s

â€¢ [SLOW TEST:17.568 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Oct 30 13:01:47.657: INFO: >>> kubeConfig: /tmp/kubeconfig-984085711
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-6e793647-fb15-11e9-91af-623cf93d857c
STEP: Creating a pod to test consume secrets
Oct 30 13:01:47.824: INFO: Waiting up to 5m0s for pod "pod-secrets-6e7c7f01-fb15-11e9-91af-623cf93d857c" in namespace "secrets-9357" to be "success or failure"
Oct 30 13:01:47.832: INFO: Pod "pod-secrets-6e7c7f01-fb15-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.986144ms
Oct 30 13:01:49.842: INFO: Pod "pod-secrets-6e7c7f01-fb15-11e9-91af-623cf93d857c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018121615s
Oct 30 13:01:51.852: INFO: Pod "pod-secrets-6e7c7f01-fb15-11e9-91af-623cf93d857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028255623s
STEP: Saw pod success
Oct 30 13:01:51.852: INFO: Pod "pod-secrets-6e7c7f01-fb15-11e9-91af-623cf93d857c" satisfied condition "success or failure"
Oct 30 13:01:51.861: INFO: Trying to get logs from node koris-pipeline-56683fb-92514359-node-1 pod pod-secrets-6e7c7f01-fb15-11e9-91af-623cf93d857c container secret-volume-test: <nil>
STEP: delete the pod
Oct 30 13:01:51.910: INFO: Waiting for pod pod-secrets-6e7c7f01-fb15-11e9-91af-623cf93d857c to disappear
Oct 30 13:01:51.921: INFO: Pod pod-secrets-6e7c7f01-fb15-11e9-91af-623cf93d857c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Oct 30 13:01:51.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9357" for this suite.
Oct 30 13:01:58.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 30 13:01:58.294: INFO: namespace secrets-9357 deletion completed in 6.362816243s

â€¢ [SLOW TEST:10.637 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.8-beta.0.27+211047e9a19225/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSOct 30 13:01:58.295: INFO: Running AfterSuite actions on all nodes
Oct 30 13:01:58.295: INFO: Running AfterSuite actions on node 1
Oct 30 13:01:58.295: INFO: Skipping dumping logs from cluster

Ran 204 of 3586 Specs in 5900.604 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3382 Skipped PASS

Ginkgo ran 1 suite in 1h38m22.229955351s
Test Suite Passed
